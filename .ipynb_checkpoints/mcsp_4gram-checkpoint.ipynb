{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import utility.Data_loader as D\n",
    "from utility.Model import MCSP\n",
    "from utility.Custom import CustomDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "1th- epoch: 0, train_loss = 273.0189424753189, train_acc = 0.35270144387517466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DTools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.4962756052141527:\n",
      "1th- epoch: 1, train_loss = 212.3257361650467, train_acc = 0.5421518397764322\n",
      "test Acc 0.5661080074487895:\n",
      "1th- epoch: 2, train_loss = 170.3467539548874, train_acc = 0.5671867722403353\n",
      "test Acc 0.5777467411545624:\n",
      "1th- epoch: 3, train_loss = 142.06177991628647, train_acc = 0.6305309734513275\n",
      "test Acc 0.7090316573556797:\n",
      "1th- epoch: 4, train_loss = 122.41265916824341, train_acc = 0.7370749883558454\n",
      "test Acc 0.770949720670391:\n",
      "1th- epoch: 5, train_loss = 106.924001455307, train_acc = 0.7671169073125291\n",
      "test Acc 0.787243947858473:\n",
      "1th- epoch: 6, train_loss = 94.07356196641922, train_acc = 0.7815556590591523\n",
      "test Acc 0.8054003724394786:\n",
      "1th- epoch: 7, train_loss = 83.49960860610008, train_acc = 0.803679552864462\n",
      "test Acc 0.8310055865921788:\n",
      "1th- epoch: 8, train_loss = 74.69137147068977, train_acc = 0.828365160689334\n",
      "test Acc 0.8463687150837989:\n",
      "1th- epoch: 9, train_loss = 67.04343339800835, train_acc = 0.8550302748020494\n",
      "test Acc 0.8682495344506518:\n",
      "1th- epoch: 10, train_loss = 60.21609736979008, train_acc = 0.8808802980903586\n",
      "test Acc 0.8924581005586593:\n",
      "1th- epoch: 11, train_loss = 54.116357281804085, train_acc = 0.9054494643688868\n",
      "test Acc 0.914804469273743:\n",
      "1th- epoch: 12, train_loss = 48.72866705060005, train_acc = 0.927806241266884\n",
      "test Acc 0.9343575418994413:\n",
      "1th- epoch: 13, train_loss = 44.02767278254032, train_acc = 0.9391010712622264\n",
      "test Acc 0.9404096834264432:\n",
      "1th- epoch: 14, train_loss = 39.96829143166542, train_acc = 0.9448067070330693\n",
      "test Acc 0.9422718808193669:\n",
      "1th- epoch: 15, train_loss = 36.493113465607166, train_acc = 0.9487657196087564\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 16, train_loss = 33.53665938973427, train_acc = 0.9510945505356311\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 17, train_loss = 31.026129506528378, train_acc = 0.9528411737307871\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 18, train_loss = 28.888522006571293, train_acc = 0.9550535631113182\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 19, train_loss = 27.06007743626833, train_acc = 0.9572659524918491\n",
      "test Acc 0.952048417132216:\n",
      "1th- epoch: 20, train_loss = 25.48622816801071, train_acc = 0.9609920819748486\n",
      "test Acc 0.9543761638733705:\n",
      "1th- epoch: 21, train_loss = 24.12304924428463, train_acc = 0.9648346530041919\n",
      "test Acc 0.9581005586592178:\n",
      "1th- epoch: 22, train_loss = 22.93233233690262, train_acc = 0.9666977177456917\n",
      "test Acc 0.9594972067039106:\n",
      "1th- epoch: 23, train_loss = 21.88333199545741, train_acc = 0.9682114578481602\n",
      "test Acc 0.9604283054003724:\n",
      "1th- epoch: 24, train_loss = 20.95010717958212, train_acc = 0.9687936655798789\n",
      "test Acc 0.9618249534450651:\n",
      "1th- epoch: 25, train_loss = 20.113231729716063, train_acc = 0.9692594317652539\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 26, train_loss = 19.357957128435373, train_acc = 0.969608756404285\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 27, train_loss = 18.671773340553045, train_acc = 0.9707731718677224\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 28, train_loss = 18.043404310941696, train_acc = 0.9711224965067536\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 29, train_loss = 17.464939575642347, train_acc = 0.9713553795994411\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 30, train_loss = 16.929646722972393, train_acc = 0.971821145784816\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 31, train_loss = 16.431981448084116, train_acc = 0.9725197950628784\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 32, train_loss = 15.967388689517975, train_acc = 0.9733348858872846\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 33, train_loss = 15.531930033117533, train_acc = 0.9736842105263158\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 34, train_loss = 15.122572060674429, train_acc = 0.9741499767116907\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 35, train_loss = 14.73621765896678, train_acc = 0.9747321844434094\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 36, train_loss = 14.370548866689205, train_acc = 0.9749650675360969\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 37, train_loss = 14.023574989289045, train_acc = 0.9755472752678156\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 38, train_loss = 13.693508446216583, train_acc = 0.9760130414531905\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 39, train_loss = 13.37898126244545, train_acc = 0.9764788076385654\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 40, train_loss = 13.07858294248581, train_acc = 0.9764788076385654\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 41, train_loss = 12.7913624830544, train_acc = 0.9764788076385654\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 42, train_loss = 12.515670597553253, train_acc = 0.9771774569166278\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 43, train_loss = 12.250692550092936, train_acc = 0.9775267815556591\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 44, train_loss = 11.99596894159913, train_acc = 0.9777596646483465\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 45, train_loss = 11.750676300376654, train_acc = 0.9786911970190965\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 46, train_loss = 11.514425229281187, train_acc = 0.9789240801117839\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 47, train_loss = 11.286672439426184, train_acc = 0.9791569632044713\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 48, train_loss = 11.066790904849768, train_acc = 0.9792734047508151\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 49, train_loss = 10.85448595136404, train_acc = 0.9792734047508151\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 50, train_loss = 10.649372439831495, train_acc = 0.9793898462971589\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 51, train_loss = 10.450999073684216, train_acc = 0.9799720540288775\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 52, train_loss = 10.25911963917315, train_acc = 0.9804378202142524\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 53, train_loss = 10.07344943471253, train_acc = 0.9811364694923148\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 54, train_loss = 9.893879652023315, train_acc = 0.9818351187703773\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 55, train_loss = 9.719950338825583, train_acc = 0.9824173265020959\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 56, train_loss = 9.55126872472465, train_acc = 0.9826502095947834\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 57, train_loss = 9.387701321393251, train_acc = 0.9826502095947834\n",
      "test Acc 0.972998137802607:\n",
      "1th- epoch: 58, train_loss = 9.228980207815766, train_acc = 0.9827666511411272\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 59, train_loss = 9.074925296008587, train_acc = 0.9828830926874709\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 60, train_loss = 8.925357427448034, train_acc = 0.9832324173265021\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 61, train_loss = 8.78013932146132, train_acc = 0.9833488588728458\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 62, train_loss = 8.638828789815307, train_acc = 0.9834653004191896\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 63, train_loss = 8.501432860270143, train_acc = 0.9838146250582208\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 64, train_loss = 8.367719691246748, train_acc = 0.984163949697252\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 65, train_loss = 8.237541047856212, train_acc = 0.9843968327899395\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 66, train_loss = 8.11069768294692, train_acc = 0.9845132743362832\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 67, train_loss = 7.986912624910474, train_acc = 0.9849790405216581\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 68, train_loss = 7.8662602715194225, train_acc = 0.9849790405216581\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 69, train_loss = 7.748636081814766, train_acc = 0.9852119236143456\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 70, train_loss = 7.633861931040883, train_acc = 0.985444806707033\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 71, train_loss = 7.52178392931819, train_acc = 0.9855612482533768\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 72, train_loss = 7.412342304363847, train_acc = 0.9856776897997206\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 73, train_loss = 7.305403012782335, train_acc = 0.9860270144387517\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 74, train_loss = 7.200918342918158, train_acc = 0.9860270144387517\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 75, train_loss = 7.098819697275758, train_acc = 0.9861434559850955\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 76, train_loss = 6.999043516814709, train_acc = 0.986376339077783\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 77, train_loss = 6.901411145925522, train_acc = 0.9866092221704704\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 78, train_loss = 6.805928960442543, train_acc = 0.9870749883558454\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 79, train_loss = 6.7123828157782555, train_acc = 0.9870749883558454\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 80, train_loss = 6.6207243502140045, train_acc = 0.9870749883558454\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 81, train_loss = 6.531025251373649, train_acc = 0.9871914299021891\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 82, train_loss = 6.4430500138551, train_acc = 0.9874243129948765\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 83, train_loss = 6.356915041804314, train_acc = 0.9878900791802515\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 84, train_loss = 6.272385846823454, train_acc = 0.9881229622729389\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 85, train_loss = 6.189635379239917, train_acc = 0.9883558453656265\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 86, train_loss = 6.108400918543339, train_acc = 0.9885887284583139\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 87, train_loss = 6.028722317889333, train_acc = 0.9889380530973452\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 88, train_loss = 5.950639890506864, train_acc = 0.9889380530973452\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 89, train_loss = 5.874066881835461, train_acc = 0.9889380530973452\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 90, train_loss = 5.798807637766004, train_acc = 0.9891709361900326\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 91, train_loss = 5.724988359957933, train_acc = 0.98940381928272\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 92, train_loss = 5.652457040734589, train_acc = 0.98940381928272\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 93, train_loss = 5.5811041770502925, train_acc = 0.9895202608290639\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 94, train_loss = 5.51110356580466, train_acc = 0.9896367023754076\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 95, train_loss = 5.44227687921375, train_acc = 0.9899860270144387\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 96, train_loss = 5.374664139002562, train_acc = 0.9899860270144387\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 97, train_loss = 5.3081935327500105, train_acc = 0.9905682347461574\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 98, train_loss = 5.2429608618840575, train_acc = 0.9906846762925011\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 99, train_loss = 5.1786960531026125, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 100, train_loss = 5.115565238520503, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 101, train_loss = 5.0534578850492835, train_acc = 0.9910340009315324\n",
      "test Acc 0.9823091247672253:\n",
      "1th- epoch: 102, train_loss = 4.992347390390933, train_acc = 0.9911504424778761\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 103, train_loss = 4.932151371613145, train_acc = 0.9910340009315324\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 104, train_loss = 4.873093322850764, train_acc = 0.9911504424778761\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 105, train_loss = 4.814834994263947, train_acc = 0.9912668840242198\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 106, train_loss = 4.757704745046794, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 107, train_loss = 4.7013926124200225, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 108, train_loss = 4.646230285987258, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 109, train_loss = 4.59180957544595, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 110, train_loss = 4.538379821926355, train_acc = 0.9918490917559385\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 111, train_loss = 4.485717943869531, train_acc = 0.9919655333022822\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 112, train_loss = 4.434066281653941, train_acc = 0.992081974848626\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 113, train_loss = 4.383226860314608, train_acc = 0.9921984163949698\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 114, train_loss = 4.333088214509189, train_acc = 0.9923148579413135\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 115, train_loss = 4.283915834501386, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 116, train_loss = 4.235548269934952, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 117, train_loss = 4.1877530831843615, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 118, train_loss = 4.14095148537308, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 119, train_loss = 4.094794259406626, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 120, train_loss = 4.049237309023738, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 121, train_loss = 4.004642547108233, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 122, train_loss = 3.960444795899093, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 123, train_loss = 3.9172082664445043, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 124, train_loss = 3.8745114309713244, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 125, train_loss = 3.8325324580073357, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 126, train_loss = 3.7911466117948294, train_acc = 0.9937121564974383\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 127, train_loss = 3.75042818300426, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 128, train_loss = 3.710331459529698, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 129, train_loss = 3.6709789596498013, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 130, train_loss = 3.6323418440297246, train_acc = 0.9944108057755007\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 131, train_loss = 3.5942288944497705, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 132, train_loss = 3.5567127717658877, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 133, train_loss = 3.5199717096984386, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 134, train_loss = 3.483571390621364, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 135, train_loss = 3.4480088921263814, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 136, train_loss = 3.4130164980888367, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 137, train_loss = 3.3784808851778507, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 138, train_loss = 3.344528046436608, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 139, train_loss = 3.311183017678559, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 140, train_loss = 3.278386940713972, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 141, train_loss = 3.246105330530554, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 142, train_loss = 3.2144444002769887, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 143, train_loss = 3.1833087927661836, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 144, train_loss = 3.1527164466679096, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 145, train_loss = 3.122687244322151, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 146, train_loss = 3.0932172401808202, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 147, train_loss = 3.064135155174881, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 148, train_loss = 3.035702593624592, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 149, train_loss = 3.0077104829251766, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 150, train_loss = 2.980185702443123, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 151, train_loss = 2.9531835839152336, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 152, train_loss = 2.9264916270039976, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 153, train_loss = 2.900359623134136, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 154, train_loss = 2.874525897204876, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 155, train_loss = 2.8492346755228937, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 156, train_loss = 2.8243823717348278, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 157, train_loss = 2.7999029993079603, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 158, train_loss = 2.775824952404946, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 159, train_loss = 2.7521184193901718, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 160, train_loss = 2.7288709077984095, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 161, train_loss = 2.7059672162868083, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 162, train_loss = 2.6833425951190293, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 163, train_loss = 2.6611112537793815, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 164, train_loss = 2.6393998037092388, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 165, train_loss = 2.6178303086198866, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 166, train_loss = 2.596777932252735, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 167, train_loss = 2.5760950692929327, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 168, train_loss = 2.555598109960556, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 169, train_loss = 2.5355788241140544, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 170, train_loss = 2.5157793276011944, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 171, train_loss = 2.4963408149778843, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 172, train_loss = 2.4773026504553854, train_acc = 0.9966231951560317\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 173, train_loss = 2.4584346651099622, train_acc = 0.9966231951560317\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 174, train_loss = 2.43996025621891, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 175, train_loss = 2.4217499494552612, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 176, train_loss = 2.4037781842052937, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 177, train_loss = 2.386154480278492, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 178, train_loss = 2.3688128837384284, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 179, train_loss = 2.3516655773855746, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 180, train_loss = 2.3349056355655193, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 181, train_loss = 2.3183060623705387, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 182, train_loss = 2.3020213446579874, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 183, train_loss = 2.2860058024525642, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 184, train_loss = 2.270110961049795, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 185, train_loss = 2.25448659947142, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 186, train_loss = 2.239192056003958, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 187, train_loss = 2.223995042499155, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 188, train_loss = 2.2091586948372424, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 189, train_loss = 2.1945395483635366, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 190, train_loss = 2.1799709163606167, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 191, train_loss = 2.1658463564235717, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 192, train_loss = 2.151759351370856, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 193, train_loss = 2.1380283075850457, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 194, train_loss = 2.124322296353057, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 195, train_loss = 2.111086404649541, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 196, train_loss = 2.097851386992261, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 197, train_loss = 2.0847480557858944, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 198, train_loss = 2.072011210024357, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 199, train_loss = 2.0593262191396207, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 200, train_loss = 2.0469983990769833, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 201, train_loss = 2.0346710334997624, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 202, train_loss = 2.0225851486902684, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 203, train_loss = 2.0107214238960296, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 204, train_loss = 1.9989727835636586, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 205, train_loss = 1.9874635103624314, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 206, train_loss = 1.9760266989469528, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 207, train_loss = 1.9649281476158649, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 208, train_loss = 1.953780873445794, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 209, train_loss = 1.942898963810876, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 210, train_loss = 1.9321852922439575, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 211, train_loss = 1.921663322718814, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 212, train_loss = 1.911151857348159, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 213, train_loss = 1.9010332252364606, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 214, train_loss = 1.8907612338662148, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 215, train_loss = 1.8809104177635163, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 216, train_loss = 1.8710563096683472, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 217, train_loss = 1.8614345751702785, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 218, train_loss = 1.8518831927794963, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 219, train_loss = 1.842513121664524, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 220, train_loss = 1.8331355962436646, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 221, train_loss = 1.8240610994398594, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 222, train_loss = 1.8150460000615567, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 223, train_loss = 1.8060953195672482, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 224, train_loss = 1.797323164762929, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 225, train_loss = 1.7887600313406438, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 226, train_loss = 1.7801788437645882, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 227, train_loss = 1.771814275532961, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 228, train_loss = 1.763514868915081, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 229, train_loss = 1.7553346306085587, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 230, train_loss = 1.7472339619416744, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 231, train_loss = 1.7393307697493583, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 232, train_loss = 1.731450654566288, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 233, train_loss = 1.7237363259773701, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 234, train_loss = 1.7160034142434597, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 235, train_loss = 1.7085583817679435, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 236, train_loss = 1.7010716993827373, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 237, train_loss = 1.6937160454690456, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 238, train_loss = 1.6863986428361386, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 239, train_loss = 1.6793087210971862, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 240, train_loss = 1.6721468691248447, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 241, train_loss = 1.6652019557077438, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 242, train_loss = 1.6582486492116004, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 243, train_loss = 1.6515420463401824, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 244, train_loss = 1.6446843408048153, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 245, train_loss = 1.6381046276073903, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 246, train_loss = 1.6314429566264153, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 247, train_loss = 1.6249619598966092, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 248, train_loss = 1.6185261856298894, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 249, train_loss = 1.6121993698179722, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 250, train_loss = 1.6058651792118326, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 251, train_loss = 1.5997667238116264, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 252, train_loss = 1.593466175138019, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 253, train_loss = 1.587470052181743, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 254, train_loss = 1.5814162753522396, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 255, train_loss = 1.575603118748404, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 256, train_loss = 1.5696556692710146, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 257, train_loss = 1.5638441257178783, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 258, train_loss = 1.5580861208727583, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 259, train_loss = 1.5524499689927325, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 260, train_loss = 1.5467851100256667, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 261, train_loss = 1.5412628129124641, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 262, train_loss = 1.535840231925249, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 263, train_loss = 1.5303383829304948, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 264, train_loss = 1.5250120274722576, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 265, train_loss = 1.5196822410216555, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 266, train_loss = 1.5144749569008127, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 267, train_loss = 1.509278749465011, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 268, train_loss = 1.5041081570088863, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 269, train_loss = 1.4990954411914572, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 270, train_loss = 1.493995739147067, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 271, train_loss = 1.4890605863183737, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 272, train_loss = 1.4840944031020626, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 273, train_loss = 1.4792401740560308, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 274, train_loss = 1.4743547713151202, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 275, train_loss = 1.4696530811488628, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 276, train_loss = 1.4648650350281969, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 277, train_loss = 1.460202923626639, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 278, train_loss = 1.4555775510380045, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 279, train_loss = 1.4508723964681849, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 280, train_loss = 1.4464744987199083, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 281, train_loss = 1.4419409669935703, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 282, train_loss = 1.437500731437467, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 283, train_loss = 1.4330155526986346, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 284, train_loss = 1.428753693937324, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 285, train_loss = 1.4243326298892498, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 286, train_loss = 1.4201419887831435, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 287, train_loss = 1.4158075848827139, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 288, train_loss = 1.4117379573872313, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 289, train_loss = 1.4074834337225184, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 290, train_loss = 1.4034080654382706, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 291, train_loss = 1.3992588905384764, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 292, train_loss = 1.3953544894466177, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 293, train_loss = 1.3912046030163765, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 294, train_loss = 1.387372087687254, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 295, train_loss = 1.383377805352211, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 296, train_loss = 1.3795461667468771, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 297, train_loss = 1.37574954086449, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 298, train_loss = 1.3718529604375362, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 299, train_loss = 1.3681378649780527, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 300, train_loss = 1.3643403662135825, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 301, train_loss = 1.3606887956848368, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 302, train_loss = 1.357032465399243, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 303, train_loss = 1.3533605871489272, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 304, train_loss = 1.34967613092158, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 305, train_loss = 1.3461580300936475, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 306, train_loss = 1.342573738307692, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 307, train_loss = 1.3391079095890746, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 308, train_loss = 1.335529439151287, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 309, train_loss = 1.3321504605701193, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 310, train_loss = 1.3286689383676276, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 311, train_loss = 1.3253481996944174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 312, train_loss = 1.3218448547413573, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 313, train_loss = 1.3185120957205072, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 314, train_loss = 1.3153175165643916, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 315, train_loss = 1.3118910329649225, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 316, train_loss = 1.3087993487715721, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 317, train_loss = 1.3054462894797325, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 318, train_loss = 1.3023624928900972, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 319, train_loss = 1.2990769495954737, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 320, train_loss = 1.2960449209203944, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 321, train_loss = 1.2928518069675192, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 322, train_loss = 1.2897691676625982, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 323, train_loss = 1.2867946898331866, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 324, train_loss = 1.2836284885415807, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 325, train_loss = 1.2806581085314974, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 326, train_loss = 1.2775965941837057, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 327, train_loss = 1.2746520327636972, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 328, train_loss = 1.2716356652090326, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 329, train_loss = 1.2688476691255346, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 330, train_loss = 1.2658837275812402, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 331, train_loss = 1.2629959931364283, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 332, train_loss = 1.2600493493373506, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 333, train_loss = 1.25725033757044, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 334, train_loss = 1.2544795659487136, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 335, train_loss = 1.25154297798872, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 336, train_loss = 1.24886453646468, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 337, train_loss = 1.2461051319842227, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 338, train_loss = 1.243279690563213, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 339, train_loss = 1.2406463523511775, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 340, train_loss = 1.2379258858854882, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 341, train_loss = 1.2350751794874668, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 342, train_loss = 1.232489490241278, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 343, train_loss = 1.2299101141397841, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 344, train_loss = 1.2271494902670383, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 345, train_loss = 1.2246089316904545, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 346, train_loss = 1.222115722775925, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 347, train_loss = 1.2194671941106208, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 348, train_loss = 1.2170713879168034, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 349, train_loss = 1.2144701766665094, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 350, train_loss = 1.2120207187836058, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 351, train_loss = 1.209606519609224, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 352, train_loss = 1.2071530111134052, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 353, train_loss = 1.204700646281708, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 354, train_loss = 1.2023637667298317, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 355, train_loss = 1.1999214527313598, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 356, train_loss = 1.1974950109724887, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 357, train_loss = 1.1952614883775823, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 358, train_loss = 1.192875628650654, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 359, train_loss = 1.1905939541757107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 360, train_loss = 1.188199742406141, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 361, train_loss = 1.1859770615701564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 362, train_loss = 1.1836489823763259, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 363, train_loss = 1.1814715887303464, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 364, train_loss = 1.1792283058166504, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 365, train_loss = 1.1770461785490625, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 366, train_loss = 1.1747211565379985, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 367, train_loss = 1.1725358714465983, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 368, train_loss = 1.1704412785475142, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 369, train_loss = 1.1682036084239371, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 370, train_loss = 1.1661283162538894, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 371, train_loss = 1.1640347788925283, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 372, train_loss = 1.1617973272805102, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 373, train_loss = 1.1597838190500624, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 374, train_loss = 1.1576932668685913, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 375, train_loss = 1.1555261959438212, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 376, train_loss = 1.1535376372630708, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 377, train_loss = 1.1515429790015332, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 378, train_loss = 1.149387230456341, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 379, train_loss = 1.1475548222661018, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 380, train_loss = 1.1453838857705705, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 381, train_loss = 1.1434150114655495, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 382, train_loss = 1.1414641353185289, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 383, train_loss = 1.1395983708207496, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 384, train_loss = 1.1375683397054672, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 385, train_loss = 1.1356613759999163, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 386, train_loss = 1.1337156780064106, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 387, train_loss = 1.1317019847338088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 388, train_loss = 1.1299074453418143, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 389, train_loss = 1.1278884559869766, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 390, train_loss = 1.1261100831325166, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 391, train_loss = 1.1241622480447404, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 392, train_loss = 1.1225083458120935, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 393, train_loss = 1.1204111042316072, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 394, train_loss = 1.1188773823087104, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 395, train_loss = 1.1168136385385878, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 396, train_loss = 1.115088488906622, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 397, train_loss = 1.1133247812394984, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 398, train_loss = 1.1115559724275954, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 399, train_loss = 1.109745676338207, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 400, train_loss = 1.1080184243619442, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 401, train_loss = 1.1063444204628468, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 402, train_loss = 1.1044392734766006, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 403, train_loss = 1.1028802593355067, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 404, train_loss = 1.1011146418750286, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 405, train_loss = 1.0993114188313484, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 406, train_loss = 1.0977098469738849, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 407, train_loss = 1.0960672609508038, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 408, train_loss = 1.0942805384402163, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 409, train_loss = 1.092656183987856, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 410, train_loss = 1.0910079826717265, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 411, train_loss = 1.0894122794270515, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 412, train_loss = 1.0876631252467632, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 413, train_loss = 1.086058295040857, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 414, train_loss = 1.0845677356119268, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 415, train_loss = 1.0828036119346507, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 416, train_loss = 1.0812778994441032, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 417, train_loss = 1.0796122898464091, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 418, train_loss = 1.0782117880880833, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 419, train_loss = 1.076564833521843, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 420, train_loss = 1.0749320524628274, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 421, train_loss = 1.0735213433508761, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 422, train_loss = 1.071937594562769, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 423, train_loss = 1.0703423855011351, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 424, train_loss = 1.0689006609027274, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 425, train_loss = 1.0673132215742953, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 426, train_loss = 1.0659463914926164, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 427, train_loss = 1.0642940637771972, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 428, train_loss = 1.06293462094618, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 429, train_loss = 1.0614202829892747, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 430, train_loss = 1.059899119019974, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 431, train_loss = 1.0584026190335862, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 432, train_loss = 1.0570218724315055, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 433, train_loss = 1.0555643613333814, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 434, train_loss = 1.0541015031631105, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 435, train_loss = 1.0526663549244404, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 436, train_loss = 1.0513624834711663, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 437, train_loss = 1.0497519013588317, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 438, train_loss = 1.0484119057655334, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 439, train_loss = 1.0469775411183946, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 440, train_loss = 1.0457174691255204, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 441, train_loss = 1.044219137460459, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 442, train_loss = 1.0429206974804401, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 443, train_loss = 1.0415493858163245, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 444, train_loss = 1.0402317034895532, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 445, train_loss = 1.0387228690087795, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 446, train_loss = 1.0376615685527213, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 447, train_loss = 1.0361282614176162, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 448, train_loss = 1.0348039083182812, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 449, train_loss = 1.033521432429552, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 450, train_loss = 1.0321933254599571, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 451, train_loss = 1.030863991647493, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 452, train_loss = 1.0296552280778997, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 453, train_loss = 1.0283537333016284, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 454, train_loss = 1.0270680747926235, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 455, train_loss = 1.025601884961361, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 456, train_loss = 1.0245525799691677, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 457, train_loss = 1.0232023485004902, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 458, train_loss = 1.0219884937105235, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 459, train_loss = 1.0206438390014227, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 460, train_loss = 1.019592311233282, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 461, train_loss = 1.0182351606490556, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 462, train_loss = 1.0170276015996933, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 463, train_loss = 1.015747336059576, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 464, train_loss = 1.0146212540566921, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 465, train_loss = 1.0132785166206304, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 466, train_loss = 1.012176205724245, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 467, train_loss = 1.010918920248514, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 468, train_loss = 1.0097860718669835, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 469, train_loss = 1.0086348988115788, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 470, train_loss = 1.0074466144142207, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 471, train_loss = 1.0061453431844711, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 472, train_loss = 1.0051508508622646, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 473, train_loss = 1.0038539841771126, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 474, train_loss = 1.0026684651675168, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 475, train_loss = 1.00162466490292, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 476, train_loss = 1.0005474512872752, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 477, train_loss = 0.9993159870209638, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 478, train_loss = 0.9982195695338305, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 479, train_loss = 0.997014449298149, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 480, train_loss = 0.9960083141922951, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 481, train_loss = 0.9947178177535534, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 482, train_loss = 0.9938136078417301, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 483, train_loss = 0.9925617352128029, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 484, train_loss = 0.991471162677044, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 485, train_loss = 0.990443946182495, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 486, train_loss = 0.9893169589340687, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 487, train_loss = 0.9881481615302619, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 488, train_loss = 0.987234964966774, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 489, train_loss = 0.9859991520643234, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 490, train_loss = 0.9851720966398716, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 491, train_loss = 0.9838697662053164, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 492, train_loss = 0.9830226326885168, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 493, train_loss = 0.9817448320391122, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 494, train_loss = 0.9808315187692642, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 495, train_loss = 0.9797927973268088, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 496, train_loss = 0.9787172451615334, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 497, train_loss = 0.9776008402404841, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 498, train_loss = 0.9768481937644538, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 499, train_loss = 0.975544635206461, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                      | 1/30 [06:27<3:07:15, 387.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "2th- epoch: 0, train_loss = 274.0763176679611, train_acc = 0.488122962272939\n",
      "test Acc 0.5600558659217877:\n",
      "2th- epoch: 1, train_loss = 209.5129441022873, train_acc = 0.5600838379133675\n",
      "test Acc 0.5702979515828678:\n",
      "2th- epoch: 2, train_loss = 163.84743732213974, train_acc = 0.5713786679087098\n",
      "test Acc 0.5824022346368715:\n",
      "2th- epoch: 3, train_loss = 137.3664339184761, train_acc = 0.6252911038658593\n",
      "test Acc 0.7039106145251397:\n",
      "2th- epoch: 4, train_loss = 119.08466452360153, train_acc = 0.7334653004191896\n",
      "test Acc 0.7732774674115456:\n",
      "2th- epoch: 5, train_loss = 104.19420674443245, train_acc = 0.7688635305076852\n",
      "test Acc 0.787243947858473:\n",
      "2th- epoch: 6, train_loss = 91.6023630797863, train_acc = 0.7819049836981835\n",
      "test Acc 0.8021415270018621:\n",
      "2th- epoch: 7, train_loss = 81.08481657505035, train_acc = 0.8062412668840242\n",
      "test Acc 0.8300744878957169:\n",
      "2th- epoch: 8, train_loss = 72.25845313072205, train_acc = 0.834536562645552\n",
      "test Acc 0.8589385474860335:\n",
      "2th- epoch: 9, train_loss = 64.65423075854778, train_acc = 0.8697019096413601\n",
      "test Acc 0.8803538175046555:\n",
      "2th- epoch: 10, train_loss = 58.00032475590706, train_acc = 0.8891476478807638\n",
      "test Acc 0.8966480446927374:\n",
      "2th- epoch: 11, train_loss = 52.16809283196926, train_acc = 0.9054494643688868\n",
      "test Acc 0.9134078212290503:\n",
      "2th- epoch: 12, train_loss = 47.08292169868946, train_acc = 0.9239636702375408\n",
      "test Acc 0.931098696461825:\n",
      "2th- epoch: 13, train_loss = 42.679969504475594, train_acc = 0.9381695388914765\n",
      "test Acc 0.9380819366852886:\n",
      "2th- epoch: 14, train_loss = 38.88838295638561, train_acc = 0.9450395901257569\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 15, train_loss = 35.638762541115284, train_acc = 0.9482999534233815\n",
      "test Acc 0.9441340782122905:\n",
      "2th- epoch: 16, train_loss = 32.862984120845795, train_acc = 0.9507452258965999\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 17, train_loss = 30.491980269551277, train_acc = 0.9530740568234746\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 18, train_loss = 28.463309481739998, train_acc = 0.9538891476478808\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 19, train_loss = 26.718301981687546, train_acc = 0.9562179785747554\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 20, train_loss = 25.207634910941124, train_acc = 0.9592454587796926\n",
      "test Acc 0.9534450651769087:\n",
      "2th- epoch: 21, train_loss = 23.892279259860516, train_acc = 0.9622729389846297\n",
      "test Acc 0.9567039106145251:\n",
      "2th- epoch: 22, train_loss = 22.737333171069622, train_acc = 0.9647182114578482\n",
      "test Acc 0.9585661080074488:\n",
      "2th- epoch: 23, train_loss = 21.714580826461315, train_acc = 0.9671634839310667\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 24, train_loss = 20.80017687752843, train_acc = 0.9677456916627852\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 25, train_loss = 19.978246919810772, train_acc = 0.9690265486725663\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 26, train_loss = 19.233736976981163, train_acc = 0.9694923148579413\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 27, train_loss = 18.553439613431692, train_acc = 0.9698416394969726\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 28, train_loss = 17.928794007748365, train_acc = 0.9706567303213787\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 29, train_loss = 17.353496082127094, train_acc = 0.9711224965067536\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 30, train_loss = 16.82076269760728, train_acc = 0.9720540288775035\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 31, train_loss = 16.324996765702963, train_acc = 0.9725197950628784\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 32, train_loss = 15.861744873225689, train_acc = 0.9727526781555659\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 33, train_loss = 15.426019754260778, train_acc = 0.9732184443409408\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 34, train_loss = 15.015455238521099, train_acc = 0.9736842105263158\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 35, train_loss = 14.62746712565422, train_acc = 0.9746157428970657\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 36, train_loss = 14.259855788201094, train_acc = 0.9748486259897532\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 37, train_loss = 13.910706896334887, train_acc = 0.9750815090824406\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 38, train_loss = 13.579311694949865, train_acc = 0.9756637168141593\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 39, train_loss = 13.263955920934677, train_acc = 0.9764788076385654\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 40, train_loss = 12.963412635028362, train_acc = 0.9769445738239404\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 41, train_loss = 12.676495254039764, train_acc = 0.9776432231020028\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 42, train_loss = 12.401717435568571, train_acc = 0.9777596646483465\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 43, train_loss = 12.138126108795404, train_acc = 0.9778761061946902\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 44, train_loss = 11.885303925722837, train_acc = 0.9790405216581276\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 45, train_loss = 11.642711270600557, train_acc = 0.97973917093619\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 46, train_loss = 11.40946163982153, train_acc = 0.9800884955752213\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 47, train_loss = 11.184728555381298, train_acc = 0.9805542617605962\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 48, train_loss = 10.968132678419352, train_acc = 0.9807871448532837\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 49, train_loss = 10.7593506090343, train_acc = 0.9813693525850024\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 50, train_loss = 10.557633180171251, train_acc = 0.9813693525850024\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 51, train_loss = 10.362371949478984, train_acc = 0.9816022356776898\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 52, train_loss = 10.173486663028598, train_acc = 0.981951560316721\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 53, train_loss = 9.990854620933533, train_acc = 0.9824173265020959\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 54, train_loss = 9.81375970505178, train_acc = 0.9825337680484397\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 55, train_loss = 9.642009949311614, train_acc = 0.9827666511411272\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 56, train_loss = 9.475501835346222, train_acc = 0.9831159757801584\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 57, train_loss = 9.313788959756494, train_acc = 0.9833488588728458\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 58, train_loss = 9.156660063192248, train_acc = 0.9835817419655333\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 59, train_loss = 9.00389964133501, train_acc = 0.9835817419655333\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 60, train_loss = 8.855313897132874, train_acc = 0.983698183511877\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 61, train_loss = 8.710663195699453, train_acc = 0.9839310666045645\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 62, train_loss = 8.569948755204678, train_acc = 0.9840475081509082\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 63, train_loss = 8.43271560780704, train_acc = 0.984163949697252\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 64, train_loss = 8.2990833055228, train_acc = 0.9843968327899395\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 65, train_loss = 8.168878711760044, train_acc = 0.9843968327899395\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 66, train_loss = 8.041558343917131, train_acc = 0.9843968327899395\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 67, train_loss = 7.917439738288522, train_acc = 0.9846297158826269\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 68, train_loss = 7.796277392655611, train_acc = 0.9848625989753144\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 69, train_loss = 7.67799230478704, train_acc = 0.9848625989753144\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 70, train_loss = 7.562457259744406, train_acc = 0.9852119236143456\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 71, train_loss = 7.449539797380567, train_acc = 0.9853283651606893\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 72, train_loss = 7.339193005114794, train_acc = 0.9856776897997206\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 73, train_loss = 7.231508145108819, train_acc = 0.9861434559850955\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 74, train_loss = 7.125783823430538, train_acc = 0.986376339077783\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 75, train_loss = 7.022562755271792, train_acc = 0.9867256637168141\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 76, train_loss = 6.921681856736541, train_acc = 0.9869585468095017\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 77, train_loss = 6.822989992797375, train_acc = 0.9870749883558454\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 78, train_loss = 6.726404316723347, train_acc = 0.9875407545412203\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 79, train_loss = 6.631822042167187, train_acc = 0.9877736376339078\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 80, train_loss = 6.538927400484681, train_acc = 0.9881229622729389\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 81, train_loss = 6.4482037872076035, train_acc = 0.9885887284583139\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 82, train_loss = 6.359010394662619, train_acc = 0.9885887284583139\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 83, train_loss = 6.271768661215901, train_acc = 0.9889380530973452\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 84, train_loss = 6.18669887073338, train_acc = 0.9890544946436889\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 85, train_loss = 6.103061327710748, train_acc = 0.9892873777363763\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 86, train_loss = 6.021352183073759, train_acc = 0.98940381928272\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 87, train_loss = 5.941113313660026, train_acc = 0.98940381928272\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 88, train_loss = 5.862565230578184, train_acc = 0.989869585468095\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 89, train_loss = 5.785515947267413, train_acc = 0.9901024685607824\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 90, train_loss = 5.709918275475502, train_acc = 0.9904517931998137\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 91, train_loss = 5.635767670348287, train_acc = 0.9904517931998137\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 92, train_loss = 5.562894832342863, train_acc = 0.9905682347461574\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 93, train_loss = 5.491405438631773, train_acc = 0.9906846762925011\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 94, train_loss = 5.421349225565791, train_acc = 0.9910340009315324\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 95, train_loss = 5.35250217653811, train_acc = 0.9912668840242198\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 96, train_loss = 5.285095144063234, train_acc = 0.9912668840242198\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 97, train_loss = 5.218789244070649, train_acc = 0.9912668840242198\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 98, train_loss = 5.153696046210825, train_acc = 0.9912668840242198\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 99, train_loss = 5.089883022941649, train_acc = 0.9913833255705635\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 100, train_loss = 5.027183325961232, train_acc = 0.9913833255705635\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 101, train_loss = 4.965508292429149, train_acc = 0.9914997671169073\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 102, train_loss = 4.905088577419519, train_acc = 0.9916162086632511\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 103, train_loss = 4.845739510841668, train_acc = 0.9916162086632511\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 104, train_loss = 4.787433248013258, train_acc = 0.9916162086632511\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 105, train_loss = 4.730157243087888, train_acc = 0.9916162086632511\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 106, train_loss = 4.673918374814093, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 107, train_loss = 4.618698372505605, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 108, train_loss = 4.564346628263593, train_acc = 0.9919655333022822\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 109, train_loss = 4.511122422292829, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 110, train_loss = 4.458664339967072, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 111, train_loss = 4.407146982848644, train_acc = 0.9923148579413135\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 112, train_loss = 4.356647850945592, train_acc = 0.9924312994876572\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 113, train_loss = 4.3069457253441215, train_acc = 0.9924312994876572\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 114, train_loss = 4.2581600258126855, train_acc = 0.9925477410340009\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 115, train_loss = 4.210299649275839, train_acc = 0.9926641825803446\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 116, train_loss = 4.163137897849083, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 117, train_loss = 4.117048076353967, train_acc = 0.9931299487657196\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 118, train_loss = 4.071657231077552, train_acc = 0.9931299487657196\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 119, train_loss = 4.026944569312036, train_acc = 0.9932463903120633\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 120, train_loss = 3.9831813871860504, train_acc = 0.9933628318584071\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 121, train_loss = 3.9401254011318088, train_acc = 0.9934792734047508\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 122, train_loss = 3.8978221379220486, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 123, train_loss = 3.8562577785924077, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 124, train_loss = 3.8154295831918716, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 125, train_loss = 3.7752684792503715, train_acc = 0.9935957149510946\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 126, train_loss = 3.735722034238279, train_acc = 0.9937121564974383\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 127, train_loss = 3.696999634616077, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 128, train_loss = 3.6589482286944985, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 129, train_loss = 3.621463849209249, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 130, train_loss = 3.5845622159540653, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 131, train_loss = 3.548495995812118, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 132, train_loss = 3.5129324225708842, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 133, train_loss = 3.4778693495318294, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 134, train_loss = 3.4435544898733497, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 135, train_loss = 3.4097437346354127, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 136, train_loss = 3.37647345662117, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 137, train_loss = 3.3436144711449742, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 138, train_loss = 3.311498918570578, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 139, train_loss = 3.2796909557655454, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 140, train_loss = 3.2484629908576608, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 141, train_loss = 3.21781284827739, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 142, train_loss = 3.1876155519858003, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 143, train_loss = 3.157804255373776, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 144, train_loss = 3.128555533941835, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 145, train_loss = 3.099887551739812, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 146, train_loss = 3.0715254694223404, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 147, train_loss = 3.0437670187093318, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 148, train_loss = 3.0163683420978487, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 149, train_loss = 2.9893910847604275, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 150, train_loss = 2.962958209682256, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 151, train_loss = 2.9366552755236626, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 152, train_loss = 2.9111121273599565, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 153, train_loss = 2.885845829267055, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 154, train_loss = 2.8608747865073383, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 155, train_loss = 2.836254768073559, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 156, train_loss = 2.8122102725319564, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 157, train_loss = 2.7882183962501585, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 158, train_loss = 2.7647933629341424, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 159, train_loss = 2.7416504602879286, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 160, train_loss = 2.7187711470760405, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 161, train_loss = 2.6963835186325014, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 162, train_loss = 2.6743240538053215, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 163, train_loss = 2.652290685568005, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 164, train_loss = 2.6309121339581907, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 165, train_loss = 2.6096885190345347, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 166, train_loss = 2.5887568034231663, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 167, train_loss = 2.568287506699562, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 168, train_loss = 2.5480561568401754, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 169, train_loss = 2.5281247147358954, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 170, train_loss = 2.5085000209510326, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 171, train_loss = 2.4890669137239456, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 172, train_loss = 2.470115436706692, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 173, train_loss = 2.4512665309011936, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 174, train_loss = 2.4327059253118932, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 175, train_loss = 2.4144662930630147, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 176, train_loss = 2.3965816139243543, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 177, train_loss = 2.3788386955857277, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 178, train_loss = 2.3614055798389018, train_acc = 0.9962738705170004\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 179, train_loss = 2.3442415720783174, train_acc = 0.9962738705170004\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 180, train_loss = 2.327327312435955, train_acc = 0.9962738705170004\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 181, train_loss = 2.3107347949407995, train_acc = 0.9962738705170004\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 182, train_loss = 2.294265776872635, train_acc = 0.9962738705170004\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 183, train_loss = 2.2781114033423364, train_acc = 0.9962738705170004\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 184, train_loss = 2.2621829831041396, train_acc = 0.9962738705170004\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 185, train_loss = 2.246561035513878, train_acc = 0.9962738705170004\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 186, train_loss = 2.231135393027216, train_acc = 0.9962738705170004\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 187, train_loss = 2.2158626005984843, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 188, train_loss = 2.200906155165285, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 189, train_loss = 2.1862047067843378, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 190, train_loss = 2.1717441738583148, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 191, train_loss = 2.1574116512201726, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 192, train_loss = 2.1434666700661182, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 193, train_loss = 2.1295084855519235, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 194, train_loss = 2.115788374096155, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 195, train_loss = 2.102429237216711, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 196, train_loss = 2.0890649245120585, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 197, train_loss = 2.076102351071313, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 198, train_loss = 2.0630446933209896, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 199, train_loss = 2.050264631630853, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 200, train_loss = 2.037888028891757, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 201, train_loss = 2.0255347203928977, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 202, train_loss = 2.013480919180438, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 203, train_loss = 2.001488719135523, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 204, train_loss = 1.9896273363847286, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 205, train_loss = 1.9781676307320595, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 206, train_loss = 1.9667233228683472, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 207, train_loss = 1.9554725426714867, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 208, train_loss = 1.9444262199103832, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 209, train_loss = 1.9335636459290981, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 210, train_loss = 1.9226896513719112, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 211, train_loss = 1.912213983712718, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 212, train_loss = 1.9016940370202065, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 213, train_loss = 1.8914903949480504, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 214, train_loss = 1.881195306777954, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 215, train_loss = 1.8712653443217278, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 216, train_loss = 1.8612221616785973, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 217, train_loss = 1.8517398324329406, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 218, train_loss = 1.842140616150573, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 219, train_loss = 1.8325423274654895, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 220, train_loss = 1.8233484376687557, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 221, train_loss = 1.8139783057849854, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 222, train_loss = 1.8049637388903648, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 223, train_loss = 1.7960731759667397, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 224, train_loss = 1.7871647141873837, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 225, train_loss = 1.7783640560228378, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 226, train_loss = 1.769811425358057, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 227, train_loss = 1.7612504847347736, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 228, train_loss = 1.7528928306419402, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 229, train_loss = 1.744649764150381, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 230, train_loss = 1.7366575475316495, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 231, train_loss = 1.7285267673432827, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 232, train_loss = 1.7206650127191097, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 233, train_loss = 1.712894357740879, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 234, train_loss = 1.705125329317525, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 235, train_loss = 1.6974871680140495, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 236, train_loss = 1.6900777518749237, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 237, train_loss = 1.6825665433425456, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 238, train_loss = 1.6754008531570435, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 239, train_loss = 1.6681022730190307, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 240, train_loss = 1.660937751410529, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 241, train_loss = 1.6540420588571578, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 242, train_loss = 1.646931580035016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 243, train_loss = 1.640108535764739, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 244, train_loss = 1.6333550214767456, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 245, train_loss = 1.626543952850625, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 246, train_loss = 1.6199842568021268, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 247, train_loss = 1.6134868115186691, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 248, train_loss = 1.607038116781041, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 249, train_loss = 1.6004825818818063, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 250, train_loss = 1.594307977706194, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 251, train_loss = 1.5879569984972477, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 252, train_loss = 1.5818826742470264, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 253, train_loss = 1.575774474767968, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 254, train_loss = 1.5697912101168185, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 255, train_loss = 1.5637053115060553, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 256, train_loss = 1.5579224651446566, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 257, train_loss = 1.552037090063095, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 258, train_loss = 1.5463583742966875, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 259, train_loss = 1.5407153517007828, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 260, train_loss = 1.5349341370165348, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 261, train_loss = 1.52943290641997, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 262, train_loss = 1.5239384373417124, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 263, train_loss = 1.5184183096280321, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 264, train_loss = 1.513008059351705, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 265, train_loss = 1.5076830895850435, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 266, train_loss = 1.5025045163929462, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 267, train_loss = 1.4972725013503805, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 268, train_loss = 1.49191415309906, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 269, train_loss = 1.4869514716556296, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 270, train_loss = 1.481845891685225, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 271, train_loss = 1.4768811588874087, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 272, train_loss = 1.4720350801944733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 273, train_loss = 1.4670924594393, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 274, train_loss = 1.462243435322307, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 275, train_loss = 1.4573765298118815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 276, train_loss = 1.4527137031545863, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 277, train_loss = 1.4479439271381125, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 278, train_loss = 1.4433723712572828, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 279, train_loss = 1.4388932896545157, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 280, train_loss = 1.4342112665763125, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 281, train_loss = 1.4297258332371712, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 282, train_loss = 1.4251652819802985, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 283, train_loss = 1.4208499217638746, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 284, train_loss = 1.4164504719665274, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 285, train_loss = 1.4121984814992175, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 286, train_loss = 1.4077276699244976, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 287, train_loss = 1.4037191346287727, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 288, train_loss = 1.399308474152349, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 289, train_loss = 1.3952324154088274, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 290, train_loss = 1.391050711274147, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 291, train_loss = 1.3870511092245579, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 292, train_loss = 1.3829209866235033, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 293, train_loss = 1.378992942511104, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 294, train_loss = 1.3749774023890495, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 295, train_loss = 1.3710392290959135, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 296, train_loss = 1.3672130107879639, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 297, train_loss = 1.3632451631128788, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 298, train_loss = 1.3594978699693456, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 299, train_loss = 1.3555792979896069, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 300, train_loss = 1.3519720137119293, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 301, train_loss = 1.3481699178228155, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 302, train_loss = 1.3444714173674583, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 303, train_loss = 1.3409072756767273, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 304, train_loss = 1.3372221464524046, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 305, train_loss = 1.3336809538304806, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 306, train_loss = 1.3301070494344458, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 307, train_loss = 1.3265041994163767, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 308, train_loss = 1.323076439439319, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 309, train_loss = 1.3196014488348737, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 310, train_loss = 1.3161863796412945, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 311, train_loss = 1.3128045300254598, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 312, train_loss = 1.309447705745697, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 313, train_loss = 1.3060839312383905, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 314, train_loss = 1.3027208670973778, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 315, train_loss = 1.2994517782935873, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 316, train_loss = 1.2961875709006563, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 317, train_loss = 1.2929745055735111, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 318, train_loss = 1.2898465506732464, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 319, train_loss = 1.286584941088222, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 320, train_loss = 1.2834151511779055, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 321, train_loss = 1.2803057531127706, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 322, train_loss = 1.2772758280625567, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 323, train_loss = 1.2741400711238384, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 324, train_loss = 1.2711637280881405, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 325, train_loss = 1.268073963583447, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 326, train_loss = 1.2651167860021815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 327, train_loss = 1.2622199319303036, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 328, train_loss = 1.2592749359318987, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 329, train_loss = 1.2562671093037352, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 330, train_loss = 1.2534777472028509, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 331, train_loss = 1.2505094954976812, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 332, train_loss = 1.2476973062148318, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 333, train_loss = 1.244905828149058, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 334, train_loss = 1.2420647044782527, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 335, train_loss = 1.2392939254641533, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 336, train_loss = 1.2366401006584056, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 337, train_loss = 1.2337693746085279, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 338, train_loss = 1.2311666918103583, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 339, train_loss = 1.2283787218038924, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 340, train_loss = 1.22575007006526, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 341, train_loss = 1.2230117569561116, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 342, train_loss = 1.220455676317215, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 343, train_loss = 1.2178099478478543, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 344, train_loss = 1.2153082762961276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 345, train_loss = 1.2126079785521142, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 346, train_loss = 1.2101091034710407, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 347, train_loss = 1.2075827568769455, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 348, train_loss = 1.2050529035623185, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 349, train_loss = 1.202616470574867, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 350, train_loss = 1.2002545247669332, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 351, train_loss = 1.1976886068587191, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 352, train_loss = 1.1952819675207138, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 353, train_loss = 1.1928239315748215, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 354, train_loss = 1.190429167181719, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 355, train_loss = 1.1880594019894488, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 356, train_loss = 1.1857060926849954, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 357, train_loss = 1.183405562012922, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 358, train_loss = 1.1810461630229838, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 359, train_loss = 1.1787587031722069, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 360, train_loss = 1.17646847787546, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 361, train_loss = 1.174201329529751, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 362, train_loss = 1.1719383510644548, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 363, train_loss = 1.1696577842230909, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 364, train_loss = 1.167495374858845, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 365, train_loss = 1.1652354436810128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 366, train_loss = 1.163084280968178, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 367, train_loss = 1.1608578227460384, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 368, train_loss = 1.158732820302248, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 369, train_loss = 1.1566212996840477, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 370, train_loss = 1.1545239339466207, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 371, train_loss = 1.1523751318454742, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 372, train_loss = 1.1502854104037397, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 373, train_loss = 1.1481678485870361, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 374, train_loss = 1.1460642975871451, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 375, train_loss = 1.1440239275689237, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 376, train_loss = 1.1419988125562668, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 377, train_loss = 1.1399752075667493, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 378, train_loss = 1.1380326611106284, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 379, train_loss = 1.135915384918917, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 380, train_loss = 1.134064082056284, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 381, train_loss = 1.1319686025381088, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 382, train_loss = 1.1300614513456821, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 383, train_loss = 1.1281235627830029, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 384, train_loss = 1.1261243037879467, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 385, train_loss = 1.1242621180717833, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 386, train_loss = 1.1223431353573687, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 387, train_loss = 1.1204857739503495, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 388, train_loss = 1.1184593066573143, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 389, train_loss = 1.1166656985878944, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 390, train_loss = 1.1148223454947583, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 391, train_loss = 1.113050103187561, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 392, train_loss = 1.11115037772106, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 393, train_loss = 1.1093517591361888, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 394, train_loss = 1.1074917117948644, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 395, train_loss = 1.1057323341374286, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 396, train_loss = 1.1039106771349907, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 397, train_loss = 1.1021553066675551, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 398, train_loss = 1.100410234183073, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 399, train_loss = 1.0985952951014042, train_acc = 0.9977876106194691\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 400, train_loss = 1.0969110702280886, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 401, train_loss = 1.0952279195189476, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 402, train_loss = 1.0935380421578884, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 403, train_loss = 1.0917054526507854, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 404, train_loss = 1.0900342129170895, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 405, train_loss = 1.0883832785184495, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 406, train_loss = 1.0867181792855263, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 407, train_loss = 1.0850232641096227, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 408, train_loss = 1.0833673092420213, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 409, train_loss = 1.0817872186307795, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 410, train_loss = 1.0801121915574186, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 411, train_loss = 1.0784814071957953, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 412, train_loss = 1.0769198921625502, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 413, train_loss = 1.0751863618497737, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 414, train_loss = 1.0736576579511166, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 415, train_loss = 1.072088015556801, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 416, train_loss = 1.0705463613267057, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 417, train_loss = 1.068986910104286, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 418, train_loss = 1.0673993602395058, train_acc = 0.9980204937121565\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 419, train_loss = 1.0657882802188396, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 420, train_loss = 1.0643055699765682, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 421, train_loss = 1.062737853557337, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 422, train_loss = 1.0612488624756224, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 423, train_loss = 1.0597706486587413, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 424, train_loss = 1.0583114785258658, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 425, train_loss = 1.0567294247448444, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 426, train_loss = 1.0552422913606279, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 427, train_loss = 1.0538170437212102, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 428, train_loss = 1.0522561334073544, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 429, train_loss = 1.0509022970800288, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 430, train_loss = 1.0494004462962039, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 431, train_loss = 1.0479629200999625, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 432, train_loss = 1.0465357800130732, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 433, train_loss = 1.0451032047276385, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 434, train_loss = 1.0437320309574716, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 435, train_loss = 1.0422359083895572, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 436, train_loss = 1.0408969980780967, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 437, train_loss = 1.0395494003896601, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 438, train_loss = 1.0381121188402176, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 439, train_loss = 1.0367575722630136, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 440, train_loss = 1.0353464881773107, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 441, train_loss = 1.034077635675203, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 442, train_loss = 1.0326396077871323, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 443, train_loss = 1.0313448309898376, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 444, train_loss = 1.0299807066912763, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 445, train_loss = 1.0286093540489674, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 446, train_loss = 1.0273216366767883, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 447, train_loss = 1.0260533007676713, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 448, train_loss = 1.0246354888076894, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 449, train_loss = 1.0234297923743725, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 450, train_loss = 1.0220781577227172, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 451, train_loss = 1.0208022010920104, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 452, train_loss = 1.0194828286767006, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 453, train_loss = 1.0183032850327436, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 454, train_loss = 1.0169562672672328, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 455, train_loss = 1.0157055171730462, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 456, train_loss = 1.014521104603773, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 457, train_loss = 1.0132958963513374, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 458, train_loss = 1.0120115255413111, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 459, train_loss = 1.0107264382240828, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 460, train_loss = 1.0095569205877837, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 461, train_loss = 1.0082914009690285, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 462, train_loss = 1.0071014712157194, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 463, train_loss = 1.0058496557176113, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 464, train_loss = 1.0047768292424735, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 465, train_loss = 1.0034566310641821, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 466, train_loss = 1.0023104138672352, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 467, train_loss = 1.0011799534258898, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 468, train_loss = 0.9998841347696725, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 469, train_loss = 0.9988029623928014, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 470, train_loss = 0.9976214257476386, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 471, train_loss = 0.9964966773986816, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 472, train_loss = 0.9953030956385192, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 473, train_loss = 0.9942215333285276, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 474, train_loss = 0.9929278915224131, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 475, train_loss = 0.9919632288219873, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 476, train_loss = 0.9907128823397215, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 477, train_loss = 0.9896877134742681, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 478, train_loss = 0.9884577555058058, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 479, train_loss = 0.9874992184340954, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 480, train_loss = 0.9862521936593112, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 481, train_loss = 0.9852472009661142, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 482, train_loss = 0.984181609004736, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 483, train_loss = 0.9829752569494303, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 484, train_loss = 0.9818842150270939, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 485, train_loss = 0.9808698569831904, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 486, train_loss = 0.979721587151289, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 487, train_loss = 0.9787743277847767, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 488, train_loss = 0.977564492583042, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 489, train_loss = 0.97661373266601, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 490, train_loss = 0.9754984006285667, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 491, train_loss = 0.9745329444704112, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 492, train_loss = 0.9733989747765008, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 493, train_loss = 0.9724996437726077, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 494, train_loss = 0.9713146326539572, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 495, train_loss = 0.9704654105007648, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 496, train_loss = 0.9693305181863252, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 497, train_loss = 0.9683267908694688, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 498, train_loss = 0.967264541744953, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 499, train_loss = 0.9663505318167154, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████▊                                                                    | 2/30 [13:19<3:04:13, 394.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "3th- epoch: 0, train_loss = 276.56144416332245, train_acc = 0.39811364694923146\n",
      "test Acc 0.5060521415270018:\n",
      "3th- epoch: 1, train_loss = 215.7642627954483, train_acc = 0.5370284117373079\n",
      "test Acc 0.568901303538175:\n",
      "3th- epoch: 2, train_loss = 171.42234474420547, train_acc = 0.5673032137866791\n",
      "test Acc 0.5847299813780261:\n",
      "3th- epoch: 3, train_loss = 140.69623452425003, train_acc = 0.6419422449930136\n",
      "test Acc 0.7216014897579144:\n",
      "3th- epoch: 4, train_loss = 118.88175559043884, train_acc = 0.7475547275267815\n",
      "test Acc 0.7821229050279329:\n",
      "3th- epoch: 5, train_loss = 102.16534888744354, train_acc = 0.7851653469958081\n",
      "test Acc 0.8119180633147114:\n",
      "3th- epoch: 6, train_loss = 88.8461886048317, train_acc = 0.8069399161620866\n",
      "test Acc 0.8230912476722533:\n",
      "3th- epoch: 7, train_loss = 78.08852863311768, train_acc = 0.8258034466697718\n",
      "test Acc 0.8496275605214153:\n",
      "3th- epoch: 8, train_loss = 69.13796585798264, train_acc = 0.8581741965533303\n",
      "test Acc 0.8766294227188082:\n",
      "3th- epoch: 9, train_loss = 61.508812606334686, train_acc = 0.8812296227293899\n",
      "test Acc 0.8919925512104283:\n",
      "3th- epoch: 10, train_loss = 54.970306277275085, train_acc = 0.8969492314857941\n",
      "test Acc 0.9050279329608939:\n",
      "3th- epoch: 11, train_loss = 49.371284767985344, train_acc = 0.9172100605496041\n",
      "test Acc 0.9301675977653632:\n",
      "3th- epoch: 12, train_loss = 44.572709396481514, train_acc = 0.9335118770377271\n",
      "test Acc 0.9338919925512105:\n",
      "3th- epoch: 13, train_loss = 40.4601783901453, train_acc = 0.9399161620866325\n",
      "test Acc 0.9371508379888268:\n",
      "3th- epoch: 14, train_loss = 36.94325330853462, train_acc = 0.9445738239403819\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 15, train_loss = 33.94483185559511, train_acc = 0.9474848625989754\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 16, train_loss = 31.389334246516228, train_acc = 0.9495808104331626\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 17, train_loss = 29.20909634232521, train_acc = 0.952491849091756\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 18, train_loss = 27.34357649832964, train_acc = 0.9547042384722869\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 19, train_loss = 25.73887061327696, train_acc = 0.9574988355845365\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 20, train_loss = 24.347695916891098, train_acc = 0.9606427573358174\n",
      "test Acc 0.9534450651769087:\n",
      "3th- epoch: 21, train_loss = 23.13038717955351, train_acc = 0.9632044713553796\n",
      "test Acc 0.9553072625698324:\n",
      "3th- epoch: 22, train_loss = 22.05618215724826, train_acc = 0.965649743828598\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 23, train_loss = 21.100757360458374, train_acc = 0.9676292501164415\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 24, train_loss = 20.244762171059847, train_acc = 0.9687936655798789\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 25, train_loss = 19.472396060824394, train_acc = 0.9693758733115976\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 26, train_loss = 18.770285669714212, train_acc = 0.9701909641360037\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 27, train_loss = 18.128505282104015, train_acc = 0.9710060549604099\n",
      "test Acc 0.962756052141527:\n",
      "3th- epoch: 28, train_loss = 17.53836338967085, train_acc = 0.9712389380530974\n",
      "test Acc 0.9641527001862198:\n",
      "3th- epoch: 29, train_loss = 16.992653273046017, train_acc = 0.9714718211457848\n",
      "test Acc 0.9646182495344506:\n",
      "3th- epoch: 30, train_loss = 16.485949747264385, train_acc = 0.9721704704238472\n",
      "test Acc 0.9646182495344506:\n",
      "3th- epoch: 31, train_loss = 16.01361806690693, train_acc = 0.9729855612482534\n",
      "test Acc 0.9646182495344506:\n",
      "3th- epoch: 32, train_loss = 15.571490403264761, train_acc = 0.9731020027945971\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 33, train_loss = 15.15633961185813, train_acc = 0.9735677689799721\n",
      "test Acc 0.9664804469273743:\n",
      "3th- epoch: 34, train_loss = 14.765420012176037, train_acc = 0.9741499767116907\n",
      "test Acc 0.9664804469273743:\n",
      "3th- epoch: 35, train_loss = 14.396020740270615, train_acc = 0.9743828598043782\n",
      "test Acc 0.9664804469273743:\n",
      "3th- epoch: 36, train_loss = 14.045837063342333, train_acc = 0.9746157428970657\n",
      "test Acc 0.9664804469273743:\n",
      "3th- epoch: 37, train_loss = 13.713758427649736, train_acc = 0.975314392175128\n",
      "test Acc 0.9669459962756052:\n",
      "3th- epoch: 38, train_loss = 13.398404955863953, train_acc = 0.975780158360503\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 39, train_loss = 13.098102264106274, train_acc = 0.9760130414531905\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 40, train_loss = 12.811576373875141, train_acc = 0.9764788076385654\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 41, train_loss = 12.537680484354496, train_acc = 0.9769445738239404\n",
      "test Acc 0.9697392923649907:\n",
      "3th- epoch: 42, train_loss = 12.27527367696166, train_acc = 0.9772938984629715\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 43, train_loss = 12.02345710247755, train_acc = 0.977992547741034\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 44, train_loss = 11.781352050602436, train_acc = 0.9782254308337215\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 45, train_loss = 11.548496410250664, train_acc = 0.9791569632044713\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 46, train_loss = 11.324453923851252, train_acc = 0.9795062878435026\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 47, train_loss = 11.108334448188543, train_acc = 0.9798556124825337\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 48, train_loss = 10.89968273229897, train_acc = 0.980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 49, train_loss = 10.697741033509374, train_acc = 0.98067070330694\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 50, train_loss = 10.50207763724029, train_acc = 0.9809035863996274\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 51, train_loss = 10.31266624480486, train_acc = 0.9810200279459711\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 52, train_loss = 10.129090113565326, train_acc = 0.9812529110386586\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 53, train_loss = 9.950808564200997, train_acc = 0.9813693525850024\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 54, train_loss = 9.778085980564356, train_acc = 0.9816022356776898\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 55, train_loss = 9.610302397981286, train_acc = 0.9818351187703773\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 56, train_loss = 9.44741103425622, train_acc = 0.9821844434094085\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 57, train_loss = 9.289158338680863, train_acc = 0.9824173265020959\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 58, train_loss = 9.135313542559743, train_acc = 0.9825337680484397\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 59, train_loss = 8.985765537247062, train_acc = 0.9828830926874709\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 60, train_loss = 8.840151401236653, train_acc = 0.9828830926874709\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 61, train_loss = 8.698414808139205, train_acc = 0.9831159757801584\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 62, train_loss = 8.560390850529075, train_acc = 0.9834653004191896\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 63, train_loss = 8.425679337233305, train_acc = 0.9835817419655333\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 64, train_loss = 8.294535338878632, train_acc = 0.9838146250582208\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 65, train_loss = 8.166582806035876, train_acc = 0.9840475081509082\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 66, train_loss = 8.041764121502638, train_acc = 0.9842803912435957\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 67, train_loss = 7.920081688091159, train_acc = 0.9846297158826269\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 68, train_loss = 7.8012183010578156, train_acc = 0.9847461574289706\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 69, train_loss = 7.68527158908546, train_acc = 0.9849790405216581\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 70, train_loss = 7.571909921243787, train_acc = 0.9850954820680019\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 71, train_loss = 7.461203956976533, train_acc = 0.9853283651606893\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 72, train_loss = 7.35285485163331, train_acc = 0.9855612482533768\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 73, train_loss = 7.246969120576978, train_acc = 0.9856776897997206\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 74, train_loss = 7.143427211791277, train_acc = 0.9862598975314392\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 75, train_loss = 7.0420203767716885, train_acc = 0.9867256637168141\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 76, train_loss = 6.943040553480387, train_acc = 0.9868421052631579\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 77, train_loss = 6.845940958708525, train_acc = 0.9869585468095017\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 78, train_loss = 6.751040825620294, train_acc = 0.9870749883558454\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 79, train_loss = 6.65815107896924, train_acc = 0.9870749883558454\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 80, train_loss = 6.567090412601829, train_acc = 0.9871914299021891\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 81, train_loss = 6.477940956130624, train_acc = 0.9874243129948765\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 82, train_loss = 6.390480196103454, train_acc = 0.9874243129948765\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 83, train_loss = 6.30480851046741, train_acc = 0.9878900791802515\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 84, train_loss = 6.220816245302558, train_acc = 0.9877736376339078\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 85, train_loss = 6.138570842333138, train_acc = 0.9877736376339078\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 86, train_loss = 6.057789909653366, train_acc = 0.9878900791802515\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 87, train_loss = 5.978677110746503, train_acc = 0.9880065207265952\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 88, train_loss = 5.901121886447072, train_acc = 0.9883558453656265\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 89, train_loss = 5.825011996552348, train_acc = 0.9883558453656265\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 90, train_loss = 5.750256749801338, train_acc = 0.9890544946436889\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 91, train_loss = 5.677008063532412, train_acc = 0.9892873777363763\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 92, train_loss = 5.604991703294218, train_acc = 0.9892873777363763\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 93, train_loss = 5.534126874990761, train_acc = 0.989869585468095\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 94, train_loss = 5.464837475679815, train_acc = 0.989869585468095\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 95, train_loss = 5.396527838893235, train_acc = 0.9902189101071263\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 96, train_loss = 5.3294829009100795, train_acc = 0.99033535165347\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 97, train_loss = 5.263393056578934, train_acc = 0.99033535165347\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 98, train_loss = 5.198312460444868, train_acc = 0.99033535165347\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 99, train_loss = 5.134510385803878, train_acc = 0.9905682347461574\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 100, train_loss = 5.071866072714329, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 101, train_loss = 5.010502661578357, train_acc = 0.990801117838845\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 102, train_loss = 4.950145868584514, train_acc = 0.9911504424778761\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 103, train_loss = 4.890919300727546, train_acc = 0.9911504424778761\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 104, train_loss = 4.83278617169708, train_acc = 0.9912668840242198\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 105, train_loss = 4.775611591525376, train_acc = 0.9913833255705635\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 106, train_loss = 4.71952276583761, train_acc = 0.9916162086632511\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 107, train_loss = 4.66427558939904, train_acc = 0.9917326502095948\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 108, train_loss = 4.6103682685643435, train_acc = 0.9917326502095948\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 109, train_loss = 4.557072582654655, train_acc = 0.9918490917559385\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 110, train_loss = 4.5048317248001695, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 111, train_loss = 4.453425272367895, train_acc = 0.9919655333022822\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 112, train_loss = 4.403003664687276, train_acc = 0.9919655333022822\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 113, train_loss = 4.353514502756298, train_acc = 0.992081974848626\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 114, train_loss = 4.304721781052649, train_acc = 0.992081974848626\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 115, train_loss = 4.256839907728136, train_acc = 0.992081974848626\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 116, train_loss = 4.209805496968329, train_acc = 0.9921984163949698\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 117, train_loss = 4.163502611219883, train_acc = 0.9921984163949698\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 118, train_loss = 4.117981395684183, train_acc = 0.9921984163949698\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 119, train_loss = 4.073391767218709, train_acc = 0.9924312994876572\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 120, train_loss = 4.029431590810418, train_acc = 0.9926641825803446\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 121, train_loss = 3.986286719329655, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 122, train_loss = 3.9438462564721704, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 123, train_loss = 3.9021516358479857, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 124, train_loss = 3.8611314138397574, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 125, train_loss = 3.8207847205922008, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 126, train_loss = 3.781086797825992, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 127, train_loss = 3.7421624148264527, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 128, train_loss = 3.703767616301775, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 129, train_loss = 3.6660624193027616, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 130, train_loss = 3.629033699631691, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 131, train_loss = 3.5925281420350075, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 132, train_loss = 3.5566154336556792, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 133, train_loss = 3.5213005067780614, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 134, train_loss = 3.4864865294657648, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 135, train_loss = 3.452230828348547, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 136, train_loss = 3.4187743621878326, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 137, train_loss = 3.38563932524994, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 138, train_loss = 3.3530772253870964, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 139, train_loss = 3.321079683955759, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 140, train_loss = 3.289405338000506, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 141, train_loss = 3.258665483444929, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 142, train_loss = 3.2280620145611465, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 143, train_loss = 3.197917361278087, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 144, train_loss = 3.1686173416674137, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 145, train_loss = 3.139453209936619, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 146, train_loss = 3.1107149496674538, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 147, train_loss = 3.082692429423332, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 148, train_loss = 3.0547239407896996, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 149, train_loss = 3.0275327493436635, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 150, train_loss = 3.000582151580602, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 151, train_loss = 2.974030802026391, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 152, train_loss = 2.9480145289562643, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 153, train_loss = 2.9222378567792475, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 154, train_loss = 2.89704721653834, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 155, train_loss = 2.8720935066230595, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 156, train_loss = 2.847494464367628, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 157, train_loss = 2.823433368001133, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 158, train_loss = 2.799745249096304, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 159, train_loss = 2.776256827637553, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 160, train_loss = 2.7533080424182117, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 161, train_loss = 2.730504607781768, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 162, train_loss = 2.7080838209949434, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 163, train_loss = 2.685803764965385, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 164, train_loss = 2.6642164140939713, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 165, train_loss = 2.6425995999015868, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 166, train_loss = 2.621625406201929, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 167, train_loss = 2.600709404796362, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 168, train_loss = 2.5803366899490356, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 169, train_loss = 2.560005061328411, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 170, train_loss = 2.5403061024844646, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 171, train_loss = 2.5205909409560263, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 172, train_loss = 2.5013554566539824, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 173, train_loss = 2.4823464029468596, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 174, train_loss = 2.4636951945722103, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 175, train_loss = 2.445225545670837, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 176, train_loss = 2.427128887269646, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 177, train_loss = 2.4092261069454253, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 178, train_loss = 2.3915958739817142, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 179, train_loss = 2.3742976686917245, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 180, train_loss = 2.3572646654210985, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 181, train_loss = 2.3402947508729994, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 182, train_loss = 2.3238470912911, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 183, train_loss = 2.307425341103226, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 184, train_loss = 2.2913546226918697, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 185, train_loss = 2.275562286376953, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 186, train_loss = 2.2598605095408857, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 187, train_loss = 2.244482955429703, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 188, train_loss = 2.2294545099139214, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 189, train_loss = 2.2143996134400368, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 190, train_loss = 2.199644369306043, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 191, train_loss = 2.18512977543287, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 192, train_loss = 2.1708776589948684, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 193, train_loss = 2.156828557373956, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 194, train_loss = 2.1428989816922694, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 195, train_loss = 2.1292619183659554, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 196, train_loss = 2.1157410193700343, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 197, train_loss = 2.1024765260517597, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 198, train_loss = 2.08929197746329, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 199, train_loss = 2.07648749393411, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 200, train_loss = 2.0637218728661537, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 201, train_loss = 2.0512654073536396, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 202, train_loss = 2.0389250963926315, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 203, train_loss = 2.0266793731134385, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 204, train_loss = 2.0148009657859802, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 205, train_loss = 2.0029128107707947, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 206, train_loss = 1.9912161726970226, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 207, train_loss = 1.9798973228316754, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 208, train_loss = 1.9684997152071446, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 209, train_loss = 1.9573400032240897, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 210, train_loss = 1.9463818781077862, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 211, train_loss = 1.9354518291074783, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 212, train_loss = 1.9248236801940948, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 213, train_loss = 1.9144344304222614, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 214, train_loss = 1.9040132239460945, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 215, train_loss = 1.893685319693759, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 216, train_loss = 1.8835989709477872, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 217, train_loss = 1.8738104689400643, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 218, train_loss = 1.8639180983882397, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 219, train_loss = 1.854279575170949, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 220, train_loss = 1.8447476651053876, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 221, train_loss = 1.835509554715827, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 222, train_loss = 1.8261367864906788, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 223, train_loss = 1.817088859854266, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 224, train_loss = 1.8080309827346355, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 225, train_loss = 1.7991059448104352, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 226, train_loss = 1.7905440230388194, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 227, train_loss = 1.7818123262841254, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 228, train_loss = 1.7732599042356014, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 229, train_loss = 1.7648580744862556, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 230, train_loss = 1.7565756004769355, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 231, train_loss = 1.7484541039448231, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 232, train_loss = 1.7403898276388645, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 233, train_loss = 1.7323420222382993, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 234, train_loss = 1.724579666974023, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 235, train_loss = 1.7167224388103932, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 236, train_loss = 1.7091082781553268, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 237, train_loss = 1.701572459191084, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 238, train_loss = 1.6940487821120769, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 239, train_loss = 1.686700151534751, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 240, train_loss = 1.6794944379944354, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 241, train_loss = 1.6722886115312576, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 242, train_loss = 1.6651167385280132, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 243, train_loss = 1.6581330199260265, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 244, train_loss = 1.6512340307235718, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 245, train_loss = 1.6443562023341656, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 246, train_loss = 1.6375750253209844, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 247, train_loss = 1.6309103319654241, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 248, train_loss = 1.6242802975466475, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 249, train_loss = 1.6177193535258994, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 250, train_loss = 1.6112386832246557, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 251, train_loss = 1.6048094431171194, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 252, train_loss = 1.5985970087349415, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 253, train_loss = 1.5922732105245814, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 254, train_loss = 1.5861451154341921, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 255, train_loss = 1.5799129145452753, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 256, train_loss = 1.574032730073668, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 257, train_loss = 1.5679514916846529, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 258, train_loss = 1.5621322765946388, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 259, train_loss = 1.556216991157271, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 260, train_loss = 1.5505225522210822, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 261, train_loss = 1.544754589558579, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 262, train_loss = 1.5391953997313976, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 263, train_loss = 1.533542906283401, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 264, train_loss = 1.5281315309694037, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 265, train_loss = 1.5225779140600935, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 266, train_loss = 1.5172914949944243, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 267, train_loss = 1.5118174329400063, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 268, train_loss = 1.5066422621021047, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 269, train_loss = 1.5013343679020181, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 270, train_loss = 1.4960739873349667, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 271, train_loss = 1.4911273469915614, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 272, train_loss = 1.4858845496783033, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 273, train_loss = 1.4810586869716644, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 274, train_loss = 1.4759637614479288, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 275, train_loss = 1.47119677439332, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 276, train_loss = 1.4662670021643862, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 277, train_loss = 1.4614850071957335, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 278, train_loss = 1.4568165503442287, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 279, train_loss = 1.4520274363458157, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 280, train_loss = 1.4474775990238413, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 281, train_loss = 1.4428082084050402, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 282, train_loss = 1.4382107990095392, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 283, train_loss = 1.4338330453028902, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 284, train_loss = 1.4292498616268858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 285, train_loss = 1.4249037293484434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 286, train_loss = 1.420525455265306, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 287, train_loss = 1.4162678444990888, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 288, train_loss = 1.4118592701852322, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 289, train_loss = 1.407577027915977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 290, train_loss = 1.4034778624773026, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 291, train_loss = 1.3991909747710451, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 292, train_loss = 1.3951038209488615, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 293, train_loss = 1.390986431390047, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 294, train_loss = 1.3870635902276263, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 295, train_loss = 1.3829740174114704, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 296, train_loss = 1.3790442744502798, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 297, train_loss = 1.3750534988939762, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 298, train_loss = 1.3711820170283318, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 299, train_loss = 1.3673512240638956, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 300, train_loss = 1.3635523455450311, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 301, train_loss = 1.3596975021064281, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 302, train_loss = 1.3560144553193823, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 303, train_loss = 1.3522355878958479, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 304, train_loss = 1.3485871143639088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 305, train_loss = 1.344898114562966, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 306, train_loss = 1.3412459852406755, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 307, train_loss = 1.3377034912118688, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 308, train_loss = 1.3341752724954858, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 309, train_loss = 1.3305825380375609, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 310, train_loss = 1.3271215023705736, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 311, train_loss = 1.3235290572047234, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 312, train_loss = 1.3201909363269806, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 313, train_loss = 1.3168398849666119, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 314, train_loss = 1.3133798142662272, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 315, train_loss = 1.3099964248249307, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 316, train_loss = 1.3067575668683276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 317, train_loss = 1.3034335784614086, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 318, train_loss = 1.3001955449581146, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 319, train_loss = 1.296959064900875, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 320, train_loss = 1.2937341021606699, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 321, train_loss = 1.2905487852403894, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 322, train_loss = 1.2874766178429127, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 323, train_loss = 1.2842181585729122, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 324, train_loss = 1.2811209025676362, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 325, train_loss = 1.2781336667831056, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 326, train_loss = 1.2750485315918922, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 327, train_loss = 1.2720085966284387, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 328, train_loss = 1.2690206083352678, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 329, train_loss = 1.2659926700289361, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 330, train_loss = 1.2631351587479003, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 331, train_loss = 1.2600790113210678, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 332, train_loss = 1.2572055645287037, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 333, train_loss = 1.2543183962698095, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 334, train_loss = 1.2515105133061297, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 335, train_loss = 1.2486718259751797, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 336, train_loss = 1.2459012319450267, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 337, train_loss = 1.2430040314793587, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 338, train_loss = 1.2402808330953121, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 339, train_loss = 1.2375192008912563, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 340, train_loss = 1.234855629503727, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 341, train_loss = 1.23209647834301, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 342, train_loss = 1.229377428709995, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 343, train_loss = 1.226709512353409, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 344, train_loss = 1.2240658390219323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 345, train_loss = 1.2214009116287343, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 346, train_loss = 1.2188826489145868, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 347, train_loss = 1.2162341724033467, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 348, train_loss = 1.2137337252497673, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 349, train_loss = 1.211129107803572, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 350, train_loss = 1.208658431947697, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 351, train_loss = 1.2060863773222081, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 352, train_loss = 1.2036226776544936, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 353, train_loss = 1.201091902970802, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 354, train_loss = 1.1986945259268396, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 355, train_loss = 1.1962530389428139, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 356, train_loss = 1.1938199301366694, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 357, train_loss = 1.1914646911318414, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 358, train_loss = 1.189009899913799, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 359, train_loss = 1.186725293577183, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 360, train_loss = 1.1843596522812732, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 361, train_loss = 1.18198337033391, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 362, train_loss = 1.1797587175969966, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 363, train_loss = 1.1774173391168006, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 364, train_loss = 1.1751196831464767, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 365, train_loss = 1.1729001316125505, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 366, train_loss = 1.1706738385255449, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 367, train_loss = 1.168496948957909, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 368, train_loss = 1.16619086638093, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 369, train_loss = 1.1641509483451955, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 370, train_loss = 1.1618272413616069, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 371, train_loss = 1.159698752046097, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 372, train_loss = 1.1576449225540273, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 373, train_loss = 1.1554164849221706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 374, train_loss = 1.1533162233536132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 375, train_loss = 1.1513144013588317, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 376, train_loss = 1.1491721768979914, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 377, train_loss = 1.147071844607126, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 378, train_loss = 1.1451451095636003, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 379, train_loss = 1.142958089709282, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 380, train_loss = 1.1410328820347786, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 381, train_loss = 1.1390356222982518, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 382, train_loss = 1.1369544342160225, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 383, train_loss = 1.135012462735176, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 384, train_loss = 1.1330226361751556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 385, train_loss = 1.1311388897593133, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 386, train_loss = 1.1291165674920194, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 387, train_loss = 1.1271854366059415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 388, train_loss = 1.1252636549179442, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 389, train_loss = 1.123409894586075, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 390, train_loss = 1.1214934426243417, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 391, train_loss = 1.119639876007568, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 392, train_loss = 1.1177028007805347, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 393, train_loss = 1.1159445333178155, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 394, train_loss = 1.1140030163223855, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 395, train_loss = 1.1121844847803004, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 396, train_loss = 1.110428883403074, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 397, train_loss = 1.1085640639066696, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 398, train_loss = 1.1067527395789512, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 399, train_loss = 1.1049718149006367, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 400, train_loss = 1.1031853693420999, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 401, train_loss = 1.1014018853311427, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 402, train_loss = 1.099583035975229, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 403, train_loss = 1.0978671585326083, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 404, train_loss = 1.096180473745335, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 405, train_loss = 1.0945050679147243, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 406, train_loss = 1.0926862855558284, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 407, train_loss = 1.0910202823579311, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 408, train_loss = 1.0893331306870095, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 409, train_loss = 1.0876840452547185, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 410, train_loss = 1.086110511154402, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 411, train_loss = 1.0843219980597496, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 412, train_loss = 1.0826580139691941, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 413, train_loss = 1.0810445435345173, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 414, train_loss = 1.0794355757534504, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 415, train_loss = 1.0777562235598452, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 416, train_loss = 1.0762285416130908, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 417, train_loss = 1.0745899987523444, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 418, train_loss = 1.0729943799669854, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 419, train_loss = 1.0714985144441016, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 420, train_loss = 1.0698404026334174, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 421, train_loss = 1.0682893904740922, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 422, train_loss = 1.0667139838333242, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 423, train_loss = 1.0651986114680767, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 424, train_loss = 1.0636511271004565, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 425, train_loss = 1.062101775140036, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 426, train_loss = 1.0606852670316584, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 427, train_loss = 1.059085089713335, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 428, train_loss = 1.0575989112257957, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 429, train_loss = 1.056216188997496, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 430, train_loss = 1.0545911118388176, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 431, train_loss = 1.053197906643618, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 432, train_loss = 1.051732572435867, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 433, train_loss = 1.050212557107443, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 434, train_loss = 1.0488237304089125, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 435, train_loss = 1.0473834859731141, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 436, train_loss = 1.0459470587375108, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 437, train_loss = 1.0445655050280038, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 438, train_loss = 1.0431907238962594, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 439, train_loss = 1.0417498052120209, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 440, train_loss = 1.0404535295965616, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 441, train_loss = 1.0388992404041346, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 442, train_loss = 1.0376090370118618, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 443, train_loss = 1.0362951358256396, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 444, train_loss = 1.0348109702172223, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 445, train_loss = 1.0335517587664071, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 446, train_loss = 1.0321705341339111, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 447, train_loss = 1.0307886190712452, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 448, train_loss = 1.0294943725166377, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 449, train_loss = 1.0281181149184704, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 450, train_loss = 1.0268964717688505, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 451, train_loss = 1.0254476927220821, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 452, train_loss = 1.024282110243803, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 453, train_loss = 1.0229077016410884, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 454, train_loss = 1.0216273429396097, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 455, train_loss = 1.020312583685154, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 456, train_loss = 1.0191040063800756, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 457, train_loss = 1.0177987478673458, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 458, train_loss = 1.0165528021752834, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 459, train_loss = 1.0153908866050187, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 460, train_loss = 1.0140310972929, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 461, train_loss = 1.0128691283462103, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 462, train_loss = 1.0116230671701487, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 463, train_loss = 1.0104359363613185, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 464, train_loss = 1.0091001043620054, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 465, train_loss = 1.0080272369086742, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 466, train_loss = 1.006683429091936, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 467, train_loss = 1.005630792438751, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 468, train_loss = 1.0043531345727388, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 469, train_loss = 1.003114370018011, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 470, train_loss = 1.0019714695808943, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 471, train_loss = 1.000752031803131, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 472, train_loss = 0.9996401853859425, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 473, train_loss = 0.9984751902520657, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 474, train_loss = 0.9972835493681487, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 475, train_loss = 0.9961513367888983, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 476, train_loss = 0.9949994894268457, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 477, train_loss = 0.9938383313419763, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 478, train_loss = 0.9927547114493791, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 479, train_loss = 0.9915773868560791, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 480, train_loss = 0.9905093436536845, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 481, train_loss = 0.9893334098160267, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 482, train_loss = 0.9882123755814973, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 483, train_loss = 0.9871308691799641, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 484, train_loss = 0.9860269886848982, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 485, train_loss = 0.9848942247626837, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 486, train_loss = 0.9838801845908165, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 487, train_loss = 0.9827453295292798, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 488, train_loss = 0.9816968540253583, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 489, train_loss = 0.9806069135665894, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 490, train_loss = 0.9795871997775976, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 491, train_loss = 0.9784886799752712, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 492, train_loss = 0.9774135276675224, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 493, train_loss = 0.9763375992479268, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 494, train_loss = 0.9753670555946883, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 495, train_loss = 0.9743336910905782, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 496, train_loss = 0.9732699878513813, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 497, train_loss = 0.9722253220679704, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 498, train_loss = 0.9712025262415409, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 499, train_loss = 0.9701380878686905, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▎                                                                 | 3/30 [20:09<2:59:44, 399.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "4th- epoch: 0, train_loss = 273.25902140140533, train_acc = 0.4676292501164415\n",
      "test Acc 0.5558659217877095:\n",
      "4th- epoch: 1, train_loss = 211.36367654800415, train_acc = 0.5596180717279925\n",
      "test Acc 0.5730912476722533:\n",
      "4th- epoch: 2, train_loss = 163.76978069543839, train_acc = 0.573940381928272\n",
      "test Acc 0.6252327746741154:\n",
      "4th- epoch: 3, train_loss = 136.17079919576645, train_acc = 0.6667442943642291\n",
      "test Acc 0.7239292364990689:\n",
      "4th- epoch: 4, train_loss = 116.95814996957779, train_acc = 0.75\n",
      "test Acc 0.7779329608938548:\n",
      "4th- epoch: 5, train_loss = 102.35016363859177, train_acc = 0.7739869585468095\n",
      "test Acc 0.7909683426443203:\n",
      "4th- epoch: 6, train_loss = 90.689671844244, train_acc = 0.7890079180251514\n",
      "test Acc 0.8142458100558659:\n",
      "4th- epoch: 7, train_loss = 81.08104610443115, train_acc = 0.8113646949231486\n",
      "test Acc 0.8314711359404097:\n",
      "4th- epoch: 8, train_loss = 72.86190703511238, train_acc = 0.8327899394503959\n",
      "test Acc 0.8528864059590316:\n",
      "4th- epoch: 9, train_loss = 65.61811570823193, train_acc = 0.8603865859338612\n",
      "test Acc 0.8738361266294227:\n",
      "4th- epoch: 10, train_loss = 59.17604523897171, train_acc = 0.8836748952026083\n",
      "test Acc 0.8933891992551211:\n",
      "4th- epoch: 11, train_loss = 53.481292739510536, train_acc = 0.9048672566371682\n",
      "test Acc 0.9143389199255121:\n",
      "4th- epoch: 12, train_loss = 48.4750394821167, train_acc = 0.9233814625058221\n",
      "test Acc 0.9269087523277467:\n",
      "4th- epoch: 13, train_loss = 44.08975858986378, train_acc = 0.9378202142524453\n",
      "test Acc 0.9366852886405959:\n",
      "4th- epoch: 14, train_loss = 40.2664960026741, train_acc = 0.9448067070330693\n",
      "test Acc 0.9408752327746741:\n",
      "4th- epoch: 15, train_loss = 36.949657648801804, train_acc = 0.9493479273404751\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 16, train_loss = 34.078802309930325, train_acc = 0.9512109920819748\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 17, train_loss = 31.601375229656696, train_acc = 0.9530740568234746\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 18, train_loss = 29.46143940836191, train_acc = 0.9552864462040056\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 19, train_loss = 27.61064935475588, train_acc = 0.9585468095016302\n",
      "test Acc 0.9553072625698324:\n",
      "4th- epoch: 20, train_loss = 26.003903433680534, train_acc = 0.9619236143455985\n",
      "test Acc 0.9581005586592178:\n",
      "4th- epoch: 21, train_loss = 24.599950812757015, train_acc = 0.9641360037261295\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 22, train_loss = 23.365180149674416, train_acc = 0.965649743828598\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 23, train_loss = 22.270746897906065, train_acc = 0.9670470423847228\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 24, train_loss = 21.29439241439104, train_acc = 0.9679785747554728\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 25, train_loss = 20.417604472488165, train_acc = 0.9689101071262226\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 26, train_loss = 19.625243842601776, train_acc = 0.969608756404285\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 27, train_loss = 18.904229782521725, train_acc = 0.97007452258966\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 28, train_loss = 18.243883401155472, train_acc = 0.9710060549604099\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 29, train_loss = 17.635747395455837, train_acc = 0.9715882626921285\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 30, train_loss = 17.07359642162919, train_acc = 0.9719375873311598\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 31, train_loss = 16.5521598495543, train_acc = 0.9724033535165347\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 32, train_loss = 16.06583819910884, train_acc = 0.9728691197019096\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 33, train_loss = 15.610364999622107, train_acc = 0.9739170936190032\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 34, train_loss = 15.18262904882431, train_acc = 0.9742664182580345\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 35, train_loss = 14.779834844172, train_acc = 0.9748486259897532\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 36, train_loss = 14.399792313575745, train_acc = 0.975314392175128\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 37, train_loss = 14.040664874017239, train_acc = 0.9756637168141593\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 38, train_loss = 13.700293503701687, train_acc = 0.9760130414531905\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 39, train_loss = 13.377376887947321, train_acc = 0.9761294829995343\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 40, train_loss = 13.070370689034462, train_acc = 0.9763623660922217\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 41, train_loss = 12.777880012989044, train_acc = 0.9768281322775967\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 42, train_loss = 12.498582035303116, train_acc = 0.9776432231020028\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 43, train_loss = 12.231684524565935, train_acc = 0.9781089892873778\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 44, train_loss = 11.976357113569975, train_acc = 0.9786911970190965\n",
      "test Acc 0.9702048417132216:\n",
      "4th- epoch: 45, train_loss = 11.731519356369972, train_acc = 0.9792734047508151\n",
      "test Acc 0.9702048417132216:\n",
      "4th- epoch: 46, train_loss = 11.496245805174112, train_acc = 0.9793898462971589\n",
      "test Acc 0.9702048417132216:\n",
      "4th- epoch: 47, train_loss = 11.270082425326109, train_acc = 0.97973917093619\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 48, train_loss = 11.052186835557222, train_acc = 0.9798556124825337\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 49, train_loss = 10.842264398932457, train_acc = 0.9798556124825337\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 50, train_loss = 10.639582831412554, train_acc = 0.9800884955752213\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 51, train_loss = 10.44372208416462, train_acc = 0.9804378202142524\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 52, train_loss = 10.25435008853674, train_acc = 0.98067070330694\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 53, train_loss = 10.071066366508603, train_acc = 0.9807871448532837\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 54, train_loss = 9.89348873309791, train_acc = 0.9811364694923148\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 55, train_loss = 9.721253333613276, train_acc = 0.9812529110386586\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 56, train_loss = 9.554112995043397, train_acc = 0.9818351187703773\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 57, train_loss = 9.391817284747958, train_acc = 0.9821844434094085\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 58, train_loss = 9.23399480804801, train_acc = 0.9823008849557522\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 59, train_loss = 9.080593576654792, train_acc = 0.9826502095947834\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 60, train_loss = 8.931364506483078, train_acc = 0.9829995342338146\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 61, train_loss = 8.786040868610144, train_acc = 0.9832324173265021\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 62, train_loss = 8.644494557753205, train_acc = 0.9833488588728458\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 63, train_loss = 8.506629470735788, train_acc = 0.9834653004191896\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 64, train_loss = 8.372304799035192, train_acc = 0.9834653004191896\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 65, train_loss = 8.241465898230672, train_acc = 0.9834653004191896\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 66, train_loss = 8.113836389034986, train_acc = 0.9840475081509082\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 67, train_loss = 7.989127738401294, train_acc = 0.9843968327899395\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 68, train_loss = 7.86744730360806, train_acc = 0.9845132743362832\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 69, train_loss = 7.7483275551348925, train_acc = 0.9846297158826269\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 70, train_loss = 7.63208563067019, train_acc = 0.9848625989753144\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 71, train_loss = 7.51842743717134, train_acc = 0.9852119236143456\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 72, train_loss = 7.407507320865989, train_acc = 0.9855612482533768\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 73, train_loss = 7.299002069979906, train_acc = 0.9857941313460643\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 74, train_loss = 7.192946853116155, train_acc = 0.9860270144387517\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 75, train_loss = 7.0890944339334965, train_acc = 0.9862598975314392\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 76, train_loss = 6.987391587346792, train_acc = 0.986376339077783\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 77, train_loss = 6.887867717072368, train_acc = 0.9864927806241267\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 78, train_loss = 6.790382519364357, train_acc = 0.9868421052631579\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 79, train_loss = 6.694815022870898, train_acc = 0.9870749883558454\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 80, train_loss = 6.601065531373024, train_acc = 0.9876571960875641\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 81, train_loss = 6.509136226028204, train_acc = 0.9877736376339078\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 82, train_loss = 6.418929819017649, train_acc = 0.9878900791802515\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 83, train_loss = 6.330715632066131, train_acc = 0.9878900791802515\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 84, train_loss = 6.243926256895065, train_acc = 0.9881229622729389\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 85, train_loss = 6.158809768036008, train_acc = 0.9881229622729389\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 86, train_loss = 6.075226141139865, train_acc = 0.9884722869119702\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 87, train_loss = 5.993145577609539, train_acc = 0.9884722869119702\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 88, train_loss = 5.912628216668963, train_acc = 0.9888216115510013\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 89, train_loss = 5.833578288555145, train_acc = 0.9889380530973452\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 90, train_loss = 5.755881782621145, train_acc = 0.9890544946436889\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 91, train_loss = 5.679639397189021, train_acc = 0.9892873777363763\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 92, train_loss = 5.604715535417199, train_acc = 0.9896367023754076\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 93, train_loss = 5.531295393593609, train_acc = 0.9896367023754076\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 94, train_loss = 5.459133661352098, train_acc = 0.9899860270144387\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 95, train_loss = 5.388422391377389, train_acc = 0.9899860270144387\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 96, train_loss = 5.3189242873340845, train_acc = 0.9904517931998137\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 97, train_loss = 5.250647361390293, train_acc = 0.9906846762925011\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 98, train_loss = 5.1836585169658065, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 99, train_loss = 5.117857873439789, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 100, train_loss = 5.053244684822857, train_acc = 0.9910340009315324\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 101, train_loss = 4.989783362485468, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 102, train_loss = 4.9274695459753275, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 103, train_loss = 4.8661855002865195, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 104, train_loss = 4.80603299010545, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 105, train_loss = 4.74712464120239, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 106, train_loss = 4.689089214429259, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 107, train_loss = 4.632264859974384, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 108, train_loss = 4.576239920221269, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 109, train_loss = 4.521355416625738, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 110, train_loss = 4.46734016481787, train_acc = 0.9919655333022822\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 111, train_loss = 4.414255221374333, train_acc = 0.9919655333022822\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 112, train_loss = 4.3622962003573775, train_acc = 0.9919655333022822\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 113, train_loss = 4.31108929682523, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 114, train_loss = 4.260853293351829, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 115, train_loss = 4.2115067867562175, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 116, train_loss = 4.163052841089666, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 117, train_loss = 4.115412849932909, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 118, train_loss = 4.068657600320876, train_acc = 0.9924312994876572\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 119, train_loss = 4.022741946391761, train_acc = 0.9924312994876572\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 120, train_loss = 3.977694117464125, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 121, train_loss = 3.9333948520943522, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 122, train_loss = 3.889901403337717, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 123, train_loss = 3.8470275923609734, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 124, train_loss = 3.8050726847723126, train_acc = 0.9931299487657196\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 125, train_loss = 3.763788959942758, train_acc = 0.9931299487657196\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 126, train_loss = 3.723213233985007, train_acc = 0.9931299487657196\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 127, train_loss = 3.6834421260282397, train_acc = 0.9932463903120633\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 128, train_loss = 3.6442980021238327, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 129, train_loss = 3.6058418015018106, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 130, train_loss = 3.5679462691769004, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 131, train_loss = 3.5307740634307265, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 132, train_loss = 3.4941466469317675, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 133, train_loss = 3.458320140838623, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 134, train_loss = 3.423019412904978, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 135, train_loss = 3.3884030180051923, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 136, train_loss = 3.3543556900694966, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 137, train_loss = 3.3208202412351966, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 138, train_loss = 3.2879589088261127, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 139, train_loss = 3.2555219223722816, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 140, train_loss = 3.223722512368113, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 141, train_loss = 3.192329200450331, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 142, train_loss = 3.161500430200249, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 143, train_loss = 3.1311738565564156, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 144, train_loss = 3.101328037213534, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 145, train_loss = 3.072005592752248, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 146, train_loss = 3.043161615729332, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 147, train_loss = 3.0146778565831482, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 148, train_loss = 2.9867956042289734, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 149, train_loss = 2.9593157204799354, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 150, train_loss = 2.9322384134866297, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 151, train_loss = 2.905592802911997, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 152, train_loss = 2.8795283348299563, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 153, train_loss = 2.8537943507544696, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 154, train_loss = 2.8284915387630463, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 155, train_loss = 2.8036358268000185, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 156, train_loss = 2.779178840573877, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 157, train_loss = 2.755136411637068, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 158, train_loss = 2.7315366766415536, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 159, train_loss = 2.708147502038628, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 160, train_loss = 2.6852832003496587, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 161, train_loss = 2.6625904417596757, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 162, train_loss = 2.640263509005308, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 163, train_loss = 2.618239749222994, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 164, train_loss = 2.5968216680921614, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 165, train_loss = 2.575632532592863, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 166, train_loss = 2.554792433977127, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 167, train_loss = 2.53433391219005, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 168, train_loss = 2.514211591333151, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 169, train_loss = 2.4945613257586956, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 170, train_loss = 2.4750972441397607, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 171, train_loss = 2.456080192234367, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 172, train_loss = 2.4373404569923878, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 173, train_loss = 2.418948160018772, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 174, train_loss = 2.4007902913726866, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 175, train_loss = 2.38305189833045, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 176, train_loss = 2.3655061931349337, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 177, train_loss = 2.3483001850545406, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 178, train_loss = 2.331346285995096, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 179, train_loss = 2.3147735805250704, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 180, train_loss = 2.2983849993906915, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 181, train_loss = 2.282277634833008, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 182, train_loss = 2.266478297766298, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 183, train_loss = 2.250896856188774, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 184, train_loss = 2.2355971881188452, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 185, train_loss = 2.220510116312653, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 186, train_loss = 2.205748035106808, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 187, train_loss = 2.191183614078909, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 188, train_loss = 2.1768955192528665, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 189, train_loss = 2.16273952415213, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 190, train_loss = 2.1488924387376755, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 191, train_loss = 2.1351990539114922, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 192, train_loss = 2.1217998787760735, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 193, train_loss = 2.1085427440702915, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 194, train_loss = 2.0955585066694766, train_acc = 0.9968560782487191\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 195, train_loss = 2.082657625200227, train_acc = 0.9968560782487191\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 196, train_loss = 2.0700823094230145, train_acc = 0.9968560782487191\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 197, train_loss = 2.0576137006282806, train_acc = 0.9968560782487191\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 198, train_loss = 2.0453272212762386, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 199, train_loss = 2.0332653496880084, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 200, train_loss = 2.0214904707390815, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 201, train_loss = 2.009792933939025, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 202, train_loss = 1.9982989840209484, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 203, train_loss = 1.9869137208443135, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 204, train_loss = 1.9758035999257118, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 205, train_loss = 1.9648112144786865, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 206, train_loss = 1.9539567579049617, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 207, train_loss = 1.9432492144405842, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 208, train_loss = 1.9327321127057076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 209, train_loss = 1.9223834399599582, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 210, train_loss = 1.9121452830731869, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 211, train_loss = 1.9020439696032554, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 212, train_loss = 1.8921401847619563, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 213, train_loss = 1.8823164887726307, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 214, train_loss = 1.8726980339270085, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 215, train_loss = 1.8631076465826482, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 216, train_loss = 1.8537305418867618, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 217, train_loss = 1.844428587704897, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 218, train_loss = 1.8353170093614608, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 219, train_loss = 1.8262794415932149, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 220, train_loss = 1.8174582559149712, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 221, train_loss = 1.8086073372978717, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 222, train_loss = 1.7999576039146632, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 223, train_loss = 1.7914374880492687, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 224, train_loss = 1.7828973836731166, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 225, train_loss = 1.774666330544278, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 226, train_loss = 1.766464461805299, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 227, train_loss = 1.7582726974505931, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 228, train_loss = 1.750303701730445, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 229, train_loss = 1.7423567411024123, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 230, train_loss = 1.7345760788302869, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 231, train_loss = 1.726828396320343, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 232, train_loss = 1.7192375038284808, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 233, train_loss = 1.711746908724308, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 234, train_loss = 1.7042289909441024, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 235, train_loss = 1.6969306592363864, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 236, train_loss = 1.6897414587438107, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 237, train_loss = 1.6824810926336795, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 238, train_loss = 1.6755129632074386, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 239, train_loss = 1.6685080688912421, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 240, train_loss = 1.66157382610254, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 241, train_loss = 1.6548300732392818, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 242, train_loss = 1.6480827915947884, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 243, train_loss = 1.6413637783844024, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 244, train_loss = 1.6348055403213948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 245, train_loss = 1.628314970759675, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 246, train_loss = 1.621868698624894, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 247, train_loss = 1.6155268450966105, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 248, train_loss = 1.6092604784062132, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 249, train_loss = 1.6030405660858378, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 250, train_loss = 1.5968868607887998, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 251, train_loss = 1.5908119268715382, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 252, train_loss = 1.5848480028798804, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 253, train_loss = 1.5788713470101357, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 254, train_loss = 1.5730666691670194, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 255, train_loss = 1.5672454126179218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 256, train_loss = 1.5615138746798038, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 257, train_loss = 1.5558661818504333, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 258, train_loss = 1.5502567192306742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 259, train_loss = 1.5446964291622862, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 260, train_loss = 1.5392010547220707, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 261, train_loss = 1.5338142601540312, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 262, train_loss = 1.5283709740033373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 263, train_loss = 1.5230912864208221, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 264, train_loss = 1.5178375355899334, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 265, train_loss = 1.5126627484569326, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 266, train_loss = 1.5074773542582989, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 267, train_loss = 1.502466874779202, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 268, train_loss = 1.4973917218158022, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 269, train_loss = 1.4924099171767011, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 270, train_loss = 1.4874865586170927, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 271, train_loss = 1.482605043798685, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 272, train_loss = 1.4777384487679228, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 273, train_loss = 1.4729751920094714, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 274, train_loss = 1.468215192318894, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 275, train_loss = 1.463560144067742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 276, train_loss = 1.458887723623775, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 277, train_loss = 1.4543213173747063, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 278, train_loss = 1.4497331021120772, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 279, train_loss = 1.4452689563622698, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 280, train_loss = 1.440747139393352, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 281, train_loss = 1.4363306500017643, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 282, train_loss = 1.431981454254128, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 283, train_loss = 1.427705885260366, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 284, train_loss = 1.42336079350207, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 285, train_loss = 1.4191464794566855, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 286, train_loss = 1.41486046963837, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 287, train_loss = 1.4107303520431742, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 288, train_loss = 1.4066403222968802, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 289, train_loss = 1.4024342559278011, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 290, train_loss = 1.3984608029713854, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 291, train_loss = 1.3944469802081585, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 292, train_loss = 1.3905152207007632, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 293, train_loss = 1.386582681327127, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 294, train_loss = 1.3825806056847796, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 295, train_loss = 1.3787624575197697, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 296, train_loss = 1.3749075954547152, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 297, train_loss = 1.3712285769870505, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 298, train_loss = 1.3672968074679375, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 299, train_loss = 1.3636550965020433, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 300, train_loss = 1.3599923053989187, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 301, train_loss = 1.356291818083264, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 302, train_loss = 1.3526141941547394, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 303, train_loss = 1.349078075378202, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 304, train_loss = 1.345424079685472, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 305, train_loss = 1.341870223521255, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 306, train_loss = 1.3384381582727656, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 307, train_loss = 1.3350191278150305, train_acc = 0.9975547275267815\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 308, train_loss = 1.331534504890442, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 309, train_loss = 1.3280648676445708, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 310, train_loss = 1.3247460102429613, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 311, train_loss = 1.3213353790342808, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 312, train_loss = 1.3179653448751196, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 313, train_loss = 1.3147095739841461, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 314, train_loss = 1.3114223232259974, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 315, train_loss = 1.3081119619309902, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 316, train_loss = 1.304900965304114, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 317, train_loss = 1.3017429783940315, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 318, train_loss = 1.2985110556473956, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 319, train_loss = 1.2954322682926431, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 320, train_loss = 1.2922656437149271, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 321, train_loss = 1.2892250083386898, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 322, train_loss = 1.2861283868551254, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 323, train_loss = 1.283105360926129, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 324, train_loss = 1.2801153796026483, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 325, train_loss = 1.2770487243542448, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 326, train_loss = 1.274163773865439, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 327, train_loss = 1.2712037625606172, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 328, train_loss = 1.2681441456079483, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 329, train_loss = 1.2653241753578186, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 330, train_loss = 1.2624742674524896, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 331, train_loss = 1.2596938982605934, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 332, train_loss = 1.256777038157452, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 333, train_loss = 1.2540256629581563, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 334, train_loss = 1.2511457639629953, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 335, train_loss = 1.2484630271792412, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 336, train_loss = 1.2457120716571808, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 337, train_loss = 1.2430075543816201, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 338, train_loss = 1.24019144725753, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 339, train_loss = 1.2376248824293725, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 340, train_loss = 1.234946209937334, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 341, train_loss = 1.2323736920952797, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 342, train_loss = 1.2296775517170317, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 343, train_loss = 1.2270941212773323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 344, train_loss = 1.2245373502373695, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 345, train_loss = 1.2220133517985232, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 346, train_loss = 1.2194219243829139, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 347, train_loss = 1.216874287754763, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 348, train_loss = 1.214369274675846, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 349, train_loss = 1.211963505775202, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 350, train_loss = 1.2093842886388302, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 351, train_loss = 1.2070096085662954, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 352, train_loss = 1.2045443765819073, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 353, train_loss = 1.2021887178416364, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 354, train_loss = 1.1997453893418424, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 355, train_loss = 1.1972977742552757, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 356, train_loss = 1.1950390115380287, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 357, train_loss = 1.192688041657675, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 358, train_loss = 1.1902855709195137, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 359, train_loss = 1.1880350895226002, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 360, train_loss = 1.1857491831178777, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 361, train_loss = 1.1834764455561526, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 362, train_loss = 1.1811216312344186, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 363, train_loss = 1.1789851846988313, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 364, train_loss = 1.1766921219532378, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 365, train_loss = 1.1745394517784007, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 366, train_loss = 1.1723364765639417, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 367, train_loss = 1.1700621557538398, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 368, train_loss = 1.167965766042471, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 369, train_loss = 1.1657697496120818, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 370, train_loss = 1.1637139258091338, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 371, train_loss = 1.1614644080400467, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 372, train_loss = 1.159479993104469, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 373, train_loss = 1.157344910025131, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 374, train_loss = 1.1552405133843422, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 375, train_loss = 1.1531448910827748, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 376, train_loss = 1.151046569168102, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 377, train_loss = 1.1491094243829139, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 378, train_loss = 1.1470840250258334, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 379, train_loss = 1.145022929937113, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 380, train_loss = 1.1430836394429207, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 381, train_loss = 1.141091647266876, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 382, train_loss = 1.1391605585813522, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 383, train_loss = 1.1370791221852414, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 384, train_loss = 1.135176292329561, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 385, train_loss = 1.1332379293744452, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 386, train_loss = 1.1313499149982817, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 387, train_loss = 1.1293810941278934, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 388, train_loss = 1.1275751255452633, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 389, train_loss = 1.1256692918832414, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 390, train_loss = 1.1237735549802892, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 391, train_loss = 1.1218885034322739, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 392, train_loss = 1.120100508152973, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 393, train_loss = 1.1182981605525129, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 394, train_loss = 1.1164538872544654, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 395, train_loss = 1.1145723412628286, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 396, train_loss = 1.112776602327358, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 397, train_loss = 1.1110509124700911, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 398, train_loss = 1.109244278341066, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 399, train_loss = 1.1074263726477511, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 400, train_loss = 1.1057467448408715, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 401, train_loss = 1.1040062382817268, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 402, train_loss = 1.102244996756781, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 403, train_loss = 1.1004748940467834, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 404, train_loss = 1.0988797321915627, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 405, train_loss = 1.0971451550722122, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 406, train_loss = 1.0954147477750666, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 407, train_loss = 1.0937241812353022, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 408, train_loss = 1.0920586213469505, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 409, train_loss = 1.090416191786062, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 410, train_loss = 1.088770514994394, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 411, train_loss = 1.0871047042310238, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 412, train_loss = 1.0854512925143354, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 413, train_loss = 1.083885595202446, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 414, train_loss = 1.0822478011250496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 415, train_loss = 1.0807124438579194, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 416, train_loss = 1.0790136903524399, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 417, train_loss = 1.0774953427608125, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 418, train_loss = 1.0758702891762368, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 419, train_loss = 1.0743340514600277, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 420, train_loss = 1.072756679088343, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 421, train_loss = 1.0711725354194641, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 422, train_loss = 1.069687104492914, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 423, train_loss = 1.0681452043354511, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 424, train_loss = 1.0666412214632146, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 425, train_loss = 1.0650597761268727, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 426, train_loss = 1.0636030112509616, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 427, train_loss = 1.0620768305961974, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 428, train_loss = 1.0605802412028424, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 429, train_loss = 1.0590770840644836, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 430, train_loss = 1.0576468507642858, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 431, train_loss = 1.0561934684519656, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 432, train_loss = 1.0547181541915052, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 433, train_loss = 1.0532995574176311, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 434, train_loss = 1.0519077678327449, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 435, train_loss = 1.050469070672989, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 436, train_loss = 1.0490029193460941, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 437, train_loss = 1.0475724066491239, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 438, train_loss = 1.046224221587181, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 439, train_loss = 1.0448146723210812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 440, train_loss = 1.0434564650058746, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 441, train_loss = 1.0420323560829274, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 442, train_loss = 1.0406847037374973, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 443, train_loss = 1.0393866586091463, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 444, train_loss = 1.0379687324166298, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 445, train_loss = 1.0366466132400092, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 446, train_loss = 1.0352371657791082, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 447, train_loss = 1.0339589292707387, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 448, train_loss = 1.032631771027809, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 449, train_loss = 1.031299257039791, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 450, train_loss = 1.0300098173320293, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 451, train_loss = 1.0287159482541028, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 452, train_loss = 1.0274500946106855, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 453, train_loss = 1.026117513567442, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 454, train_loss = 1.0248206382093485, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 455, train_loss = 1.0235487458703574, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 456, train_loss = 1.02228014668799, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 457, train_loss = 1.0209987449052278, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 458, train_loss = 1.0197478657064494, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 459, train_loss = 1.0185044618847314, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 460, train_loss = 1.0172797590494156, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 461, train_loss = 1.0160163380205631, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 462, train_loss = 1.0148799630405847, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 463, train_loss = 1.0135635485348757, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 464, train_loss = 1.012347246200079, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 465, train_loss = 1.0111151027085725, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 466, train_loss = 1.009933065623045, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 467, train_loss = 1.008701785147423, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 468, train_loss = 1.0075171440839767, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 469, train_loss = 1.0063304839131888, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 470, train_loss = 1.0051373851893004, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 471, train_loss = 1.0040399779973086, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 472, train_loss = 1.0028112927975599, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 473, train_loss = 1.0016348982753698, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 474, train_loss = 1.0004564672708511, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 475, train_loss = 0.9993724512460176, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 476, train_loss = 0.9981701200304087, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 477, train_loss = 0.9970477844181005, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 478, train_loss = 0.9958703418669757, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 479, train_loss = 0.9948287519218866, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 480, train_loss = 0.9936597546038684, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 481, train_loss = 0.9926047498884145, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 482, train_loss = 0.991429657995468, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 483, train_loss = 0.9902852897939738, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 484, train_loss = 0.9891989467141684, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 485, train_loss = 0.9880961018207017, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 486, train_loss = 0.9870136467216071, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 487, train_loss = 0.9859292743203696, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 488, train_loss = 0.9848722728493158, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 489, train_loss = 0.9837380573153496, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 490, train_loss = 0.9826804635522421, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 491, train_loss = 0.9817031547427177, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "4th- epoch: 492, train_loss = 0.9806074140069541, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "4th- epoch: 493, train_loss = 0.9795204301772173, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "4th- epoch: 494, train_loss = 0.978491272777319, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "4th- epoch: 495, train_loss = 0.9774385901691858, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "4th- epoch: 496, train_loss = 0.9764158837497234, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "4th- epoch: 497, train_loss = 0.9753737834689673, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "4th- epoch: 498, train_loss = 0.9742865723965224, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "4th- epoch: 499, train_loss = 0.9733269847929478, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████▋                                                               | 4/30 [26:59<2:54:28, 402.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "5th- epoch: 0, train_loss = 273.0972545146942, train_acc = 0.5052398695854681\n",
      "test Acc 0.6000931098696461:\n",
      "5th- epoch: 1, train_loss = 207.23825860023499, train_acc = 0.5763856544014905\n",
      "test Acc 0.5856610800744879:\n",
      "5th- epoch: 2, train_loss = 161.79608845710754, train_acc = 0.6049138332557057\n",
      "test Acc 0.6508379888268156:\n",
      "5th- epoch: 3, train_loss = 133.25664192438126, train_acc = 0.7010945505356311\n",
      "test Acc 0.7560521415270018:\n",
      "5th- epoch: 4, train_loss = 113.30643939971924, train_acc = 0.7612948299953424\n",
      "test Acc 0.7788640595903166:\n",
      "5th- epoch: 5, train_loss = 98.56554558873177, train_acc = 0.7739869585468095\n",
      "test Acc 0.792364990689013:\n",
      "5th- epoch: 6, train_loss = 87.08501181006432, train_acc = 0.7873777363763391\n",
      "test Acc 0.8049348230912476:\n",
      "5th- epoch: 7, train_loss = 77.85012170672417, train_acc = 0.808570097810899\n",
      "test Acc 0.8305400372439479:\n",
      "5th- epoch: 8, train_loss = 70.05380883812904, train_acc = 0.8351187703772706\n",
      "test Acc 0.8556797020484171:\n",
      "5th- epoch: 9, train_loss = 63.16645875573158, train_acc = 0.866208663251048\n",
      "test Acc 0.8845437616387337:\n",
      "5th- epoch: 10, train_loss = 56.982016161084175, train_acc = 0.891243595714951\n",
      "test Acc 0.8994413407821229:\n",
      "5th- epoch: 11, train_loss = 51.46921746432781, train_acc = 0.9112715416860736\n",
      "test Acc 0.9236499068901304:\n",
      "5th- epoch: 12, train_loss = 46.61993581056595, train_acc = 0.9297857475547275\n",
      "test Acc 0.9366852886405959:\n",
      "5th- epoch: 13, train_loss = 42.398704901337624, train_acc = 0.9409641360037261\n",
      "test Acc 0.9399441340782123:\n",
      "5th- epoch: 14, train_loss = 38.75464029610157, train_acc = 0.9465533302282254\n",
      "test Acc 0.9413407821229051:\n",
      "5th- epoch: 15, train_loss = 35.62397538870573, train_acc = 0.9493479273404751\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 16, train_loss = 32.936152659356594, train_acc = 0.9509781089892874\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 17, train_loss = 30.62818381935358, train_acc = 0.9527247321844434\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 18, train_loss = 28.63846541941166, train_acc = 0.9556357708430367\n",
      "test Acc 0.9506517690875232:\n",
      "5th- epoch: 19, train_loss = 26.913787074387074, train_acc = 0.9591290172333489\n",
      "test Acc 0.9539106145251397:\n",
      "5th- epoch: 20, train_loss = 25.40910079330206, train_acc = 0.9608756404285049\n",
      "test Acc 0.9562383612662942:\n",
      "5th- epoch: 21, train_loss = 24.08731421083212, train_acc = 0.9625058220773172\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 22, train_loss = 22.918058410286903, train_acc = 0.9647182114578482\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 23, train_loss = 21.875191248953342, train_acc = 0.9664648346530041\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 24, train_loss = 20.939243510365486, train_acc = 0.9677456916627852\n",
      "test Acc 0.9618249534450651:\n",
      "5th- epoch: 25, train_loss = 20.095187041908503, train_acc = 0.9685607824871915\n",
      "test Acc 0.9618249534450651:\n",
      "5th- epoch: 26, train_loss = 19.329943418502808, train_acc = 0.9692594317652539\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 27, train_loss = 18.632661171257496, train_acc = 0.9703074056823474\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 28, train_loss = 17.99403326958418, train_acc = 0.9710060549604099\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 29, train_loss = 17.40643633902073, train_acc = 0.9717047042384723\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 30, train_loss = 16.862841844558716, train_acc = 0.9720540288775035\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 31, train_loss = 16.357776261866093, train_acc = 0.9724033535165347\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 32, train_loss = 15.886352587491274, train_acc = 0.9732184443409408\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 33, train_loss = 15.44512915238738, train_acc = 0.9734513274336283\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 34, train_loss = 15.03129156306386, train_acc = 0.974033535165347\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 35, train_loss = 14.642102129757404, train_acc = 0.9743828598043782\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 36, train_loss = 14.274935465306044, train_acc = 0.9750815090824406\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 37, train_loss = 13.927913222461939, train_acc = 0.975314392175128\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 38, train_loss = 13.599436279386282, train_acc = 0.975780158360503\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 39, train_loss = 13.287615165114403, train_acc = 0.9765952491849091\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 40, train_loss = 12.99091249331832, train_acc = 0.9771774569166278\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 41, train_loss = 12.707672294229269, train_acc = 0.977992547741034\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 42, train_loss = 12.437013752758503, train_acc = 0.9782254308337215\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 43, train_loss = 12.178126238286495, train_acc = 0.9786911970190965\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 44, train_loss = 11.929940193891525, train_acc = 0.9791569632044713\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 45, train_loss = 11.691976856440306, train_acc = 0.9793898462971589\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 46, train_loss = 11.463163267821074, train_acc = 0.9795062878435026\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 47, train_loss = 11.242762997746468, train_acc = 0.9796227293898463\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 48, train_loss = 11.030055221170187, train_acc = 0.97973917093619\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 49, train_loss = 10.824744202196598, train_acc = 0.980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 50, train_loss = 10.626307046040893, train_acc = 0.9805542617605962\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 51, train_loss = 10.434507064521313, train_acc = 0.9809035863996274\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 52, train_loss = 10.249015130102634, train_acc = 0.9809035863996274\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 53, train_loss = 10.06920300796628, train_acc = 0.9810200279459711\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 54, train_loss = 9.895084336400032, train_acc = 0.9812529110386586\n",
      "test Acc 0.972998137802607:\n",
      "5th- epoch: 55, train_loss = 9.72627947665751, train_acc = 0.9817186772240335\n",
      "test Acc 0.973463687150838:\n",
      "5th- epoch: 56, train_loss = 9.562264459207654, train_acc = 0.981951560316721\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 57, train_loss = 9.402987679466605, train_acc = 0.9821844434094085\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 58, train_loss = 9.248277297243476, train_acc = 0.9825337680484397\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 59, train_loss = 9.097601609304547, train_acc = 0.9831159757801584\n",
      "test Acc 0.9753258845437617:\n",
      "5th- epoch: 60, train_loss = 8.95115216448903, train_acc = 0.9833488588728458\n",
      "test Acc 0.9757914338919925:\n",
      "5th- epoch: 61, train_loss = 8.808528380468488, train_acc = 0.9834653004191896\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 62, train_loss = 8.669576728716493, train_acc = 0.9838146250582208\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 63, train_loss = 8.53412751108408, train_acc = 0.9838146250582208\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 64, train_loss = 8.402217095717788, train_acc = 0.984163949697252\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 65, train_loss = 8.273327745497227, train_acc = 0.9842803912435957\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 66, train_loss = 8.147697117179632, train_acc = 0.9842803912435957\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 67, train_loss = 8.025161992758512, train_acc = 0.9845132743362832\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 68, train_loss = 7.90537491440773, train_acc = 0.9846297158826269\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 69, train_loss = 7.788501627743244, train_acc = 0.9848625989753144\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 70, train_loss = 7.674206119030714, train_acc = 0.9850954820680019\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 71, train_loss = 7.562490873038769, train_acc = 0.9852119236143456\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 72, train_loss = 7.453357147052884, train_acc = 0.9853283651606893\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 73, train_loss = 7.3466525580734015, train_acc = 0.9856776897997206\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 74, train_loss = 7.242366511374712, train_acc = 0.9862598975314392\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 75, train_loss = 7.140206860378385, train_acc = 0.9864927806241267\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 76, train_loss = 7.040212854743004, train_acc = 0.9870749883558454\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 77, train_loss = 6.942312551662326, train_acc = 0.9876571960875641\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 78, train_loss = 6.846331598237157, train_acc = 0.9877736376339078\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 79, train_loss = 6.752402398735285, train_acc = 0.9880065207265952\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 80, train_loss = 6.66026602871716, train_acc = 0.9880065207265952\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 81, train_loss = 6.570029158145189, train_acc = 0.9882394038192828\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 82, train_loss = 6.481507293879986, train_acc = 0.9885887284583139\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 83, train_loss = 6.394748726859689, train_acc = 0.9887051700046576\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 84, train_loss = 6.309531291946769, train_acc = 0.9889380530973452\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 85, train_loss = 6.225914353504777, train_acc = 0.9890544946436889\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 86, train_loss = 6.143972184509039, train_acc = 0.9891709361900326\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 87, train_loss = 6.063618374988437, train_acc = 0.9891709361900326\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 88, train_loss = 5.984671094454825, train_acc = 0.9895202608290639\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 89, train_loss = 5.907182968221605, train_acc = 0.989869585468095\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 90, train_loss = 5.831016669981182, train_acc = 0.989869585468095\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 91, train_loss = 5.7561673847958446, train_acc = 0.9899860270144387\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 92, train_loss = 5.682497212663293, train_acc = 0.9901024685607824\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 93, train_loss = 5.610436052083969, train_acc = 0.99033535165347\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 94, train_loss = 5.539460132829845, train_acc = 0.9904517931998137\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 95, train_loss = 5.46978881303221, train_acc = 0.9904517931998137\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 96, train_loss = 5.401274680159986, train_acc = 0.9904517931998137\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 97, train_loss = 5.334024306386709, train_acc = 0.9909175593851887\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 98, train_loss = 5.2679014634341, train_acc = 0.9910340009315324\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 99, train_loss = 5.202821187674999, train_acc = 0.9911504424778761\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 100, train_loss = 5.138822117820382, train_acc = 0.9911504424778761\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 101, train_loss = 5.075825323350728, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 102, train_loss = 5.013930889777839, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 103, train_loss = 4.953203679062426, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 104, train_loss = 4.893315381370485, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 105, train_loss = 4.834542234428227, train_acc = 0.9916162086632511\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 106, train_loss = 4.776767053641379, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 107, train_loss = 4.719912140630186, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 108, train_loss = 4.664021180011332, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 109, train_loss = 4.608985234983265, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 110, train_loss = 4.5548102436587214, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 111, train_loss = 4.501450312323868, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 112, train_loss = 4.448918517678976, train_acc = 0.9923148579413135\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 113, train_loss = 4.397358833812177, train_acc = 0.9923148579413135\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 114, train_loss = 4.346716736443341, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 115, train_loss = 4.296656767837703, train_acc = 0.9925477410340009\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 116, train_loss = 4.247643115930259, train_acc = 0.9925477410340009\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 117, train_loss = 4.199325210414827, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 118, train_loss = 4.151898148469627, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 119, train_loss = 4.105080905370414, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 120, train_loss = 4.059244981966913, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 121, train_loss = 4.014144679531455, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 122, train_loss = 3.9698009388521314, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 123, train_loss = 3.9261469962075353, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 124, train_loss = 3.883171175606549, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 125, train_loss = 3.8409612784162164, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 126, train_loss = 3.799465631134808, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 127, train_loss = 3.758688949048519, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 128, train_loss = 3.71861519664526, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 129, train_loss = 3.679244720377028, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 130, train_loss = 3.6405786192044616, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 131, train_loss = 3.6023905780166388, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 132, train_loss = 3.56510886317119, train_acc = 0.9937121564974383\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 133, train_loss = 3.5283509674482048, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 134, train_loss = 3.4921394078992307, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 135, train_loss = 3.456757941748947, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 136, train_loss = 3.4217432253062725, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 137, train_loss = 3.3873726124875247, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 138, train_loss = 3.353446704801172, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 139, train_loss = 3.320341683458537, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 140, train_loss = 3.2876036944799125, train_acc = 0.9944108057755007\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 141, train_loss = 3.2555171358399093, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 142, train_loss = 3.2239690483547747, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 143, train_loss = 3.1930706747807562, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 144, train_loss = 3.1624187254346907, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 145, train_loss = 3.1325287562794983, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 146, train_loss = 3.1028633597306907, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 147, train_loss = 3.0738805984146893, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 148, train_loss = 3.045186024159193, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 149, train_loss = 3.0171361938118935, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 150, train_loss = 2.9895162489265203, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 151, train_loss = 2.9621501215733588, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 152, train_loss = 2.9355066032148898, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 153, train_loss = 2.9091875427402556, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 154, train_loss = 2.883017491083592, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 155, train_loss = 2.8577515385113657, train_acc = 0.9952258965999069\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 156, train_loss = 2.8325746678747237, train_acc = 0.9952258965999069\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 157, train_loss = 2.8078799061477184, train_acc = 0.9952258965999069\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 158, train_loss = 2.783602448180318, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 159, train_loss = 2.7596859973855317, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 160, train_loss = 2.7360886014066637, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 161, train_loss = 2.7130245422013104, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 162, train_loss = 2.6902313460595906, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 163, train_loss = 2.667834457475692, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 164, train_loss = 2.6456280457787216, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 165, train_loss = 2.6240789755247533, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 166, train_loss = 2.6025712988339365, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 167, train_loss = 2.581596383359283, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 168, train_loss = 2.560823058243841, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 169, train_loss = 2.5405832626856863, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 170, train_loss = 2.520369546022266, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 171, train_loss = 2.500643067061901, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 172, train_loss = 2.481116692069918, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 173, train_loss = 2.461933286394924, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 174, train_loss = 2.4431010321713984, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 175, train_loss = 2.4244647584855556, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 176, train_loss = 2.4062533653341234, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 177, train_loss = 2.3881594478152692, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 178, train_loss = 2.370537801180035, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 179, train_loss = 2.353072086814791, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 180, train_loss = 2.3359878063201904, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 181, train_loss = 2.3191161900758743, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 182, train_loss = 2.302446187706664, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 183, train_loss = 2.2860888491850346, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 184, train_loss = 2.269960607169196, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 185, train_loss = 2.25417069834657, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 186, train_loss = 2.2384703445713967, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "5th- epoch: 187, train_loss = 2.22312514600344, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 188, train_loss = 2.2080544743221253, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 189, train_loss = 2.193112123757601, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 190, train_loss = 2.178582136752084, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 191, train_loss = 2.1640671603381634, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 192, train_loss = 2.1499584664124995, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 193, train_loss = 2.1359141406137496, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 194, train_loss = 2.1220812152605504, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 195, train_loss = 2.1084781128447503, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 196, train_loss = 2.095184087753296, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 197, train_loss = 2.0818826407194138, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 198, train_loss = 2.068924531340599, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 199, train_loss = 2.056076565058902, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 200, train_loss = 2.043524220585823, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 201, train_loss = 2.0311336431186646, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 202, train_loss = 2.0189257350284606, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 203, train_loss = 2.0069511744659394, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 204, train_loss = 1.9950259265024215, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 205, train_loss = 1.983420907286927, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 206, train_loss = 1.9718863677699119, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 207, train_loss = 1.9606057170312852, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 208, train_loss = 1.9494613136630505, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 209, train_loss = 1.9384043987374753, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 210, train_loss = 1.9276905991137028, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 211, train_loss = 1.9170119985938072, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 212, train_loss = 1.9065682690124959, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 213, train_loss = 1.8961767840664834, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 214, train_loss = 1.885962563334033, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 215, train_loss = 1.875972307054326, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 216, train_loss = 1.8661196890752763, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 217, train_loss = 1.8563289928715676, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 218, train_loss = 1.8467055037617683, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 219, train_loss = 1.837206106632948, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 220, train_loss = 1.8278798784594983, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 221, train_loss = 1.8186435538809747, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 222, train_loss = 1.809652715921402, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 223, train_loss = 1.8005379710812122, train_acc = 0.9970889613414066\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 224, train_loss = 1.791796311037615, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 225, train_loss = 1.7830166171770543, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 226, train_loss = 1.77442941442132, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 227, train_loss = 1.7659662694204599, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 228, train_loss = 1.75757668283768, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 229, train_loss = 1.7493253108114004, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 230, train_loss = 1.7411562644410878, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 231, train_loss = 1.7331204004585743, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 232, train_loss = 1.7252230029553175, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 233, train_loss = 1.7173623770941049, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 234, train_loss = 1.7096161302179098, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 235, train_loss = 1.7019558133324608, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 236, train_loss = 1.6944202395388857, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 237, train_loss = 1.6870106545975432, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 238, train_loss = 1.6795649951091036, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 239, train_loss = 1.6723269695648924, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 240, train_loss = 1.665205163299106, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 241, train_loss = 1.6580236181616783, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 242, train_loss = 1.6510800247779116, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 243, train_loss = 1.6441682936856523, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 244, train_loss = 1.6373541367938742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 245, train_loss = 1.6305877305567265, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 246, train_loss = 1.6239292895188555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 247, train_loss = 1.617386863916181, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 248, train_loss = 1.6107524546096101, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 249, train_loss = 1.604399555712007, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 250, train_loss = 1.5980571260442957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 251, train_loss = 1.5917506689438596, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 252, train_loss = 1.5855962311616167, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 253, train_loss = 1.579384853481315, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 254, train_loss = 1.5734920501708984, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 255, train_loss = 1.5674443393945694, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 256, train_loss = 1.5615049289772287, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 257, train_loss = 1.5556347569217905, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 258, train_loss = 1.5498513951897621, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 259, train_loss = 1.5441043302416801, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 260, train_loss = 1.5384906629333273, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 261, train_loss = 1.5328274542698637, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 262, train_loss = 1.5273381024599075, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 263, train_loss = 1.5218549693236127, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 264, train_loss = 1.5164038179209456, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 265, train_loss = 1.511125830351375, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 266, train_loss = 1.5057420507073402, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 267, train_loss = 1.5005601234734058, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 268, train_loss = 1.495268398313783, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 269, train_loss = 1.4901533760130405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 270, train_loss = 1.4851076839258894, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 271, train_loss = 1.4800653904676437, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 272, train_loss = 1.4750663563609123, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 273, train_loss = 1.4701623333385214, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 274, train_loss = 1.4653108777711168, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 275, train_loss = 1.4604173935949802, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 276, train_loss = 1.4557489529252052, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 277, train_loss = 1.4509466910967603, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 278, train_loss = 1.4462870806455612, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 279, train_loss = 1.4415636347839609, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 280, train_loss = 1.4371279192855582, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 281, train_loss = 1.4324792735278606, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 282, train_loss = 1.4280153078725561, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 283, train_loss = 1.423506331979297, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 284, train_loss = 1.4191665276885033, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 285, train_loss = 1.4148017218103632, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 286, train_loss = 1.4104435816407204, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 287, train_loss = 1.4061013323953375, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 288, train_loss = 1.4018262898316607, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 289, train_loss = 1.3976729115238413, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 290, train_loss = 1.3934335447847843, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 291, train_loss = 1.3893253058195114, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 292, train_loss = 1.3852233290672302, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 293, train_loss = 1.3811440070858225, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 294, train_loss = 1.377138551324606, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 295, train_loss = 1.3730980418622494, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 296, train_loss = 1.3692373832454905, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 297, train_loss = 1.3652326600858942, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 298, train_loss = 1.3614535294473171, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "5th- epoch: 299, train_loss = 1.357543796300888, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "5th- epoch: 300, train_loss = 1.3538026859750971, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "5th- epoch: 301, train_loss = 1.350035491050221, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "5th- epoch: 302, train_loss = 1.3462323831627145, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 303, train_loss = 1.3425721488893032, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 304, train_loss = 1.3388800894608721, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 305, train_loss = 1.33520430943463, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 306, train_loss = 1.3316026602988131, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 307, train_loss = 1.3280519184772857, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 308, train_loss = 1.324444601952564, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 309, train_loss = 1.3209472211892717, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 310, train_loss = 1.3174366590683348, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 311, train_loss = 1.314017727971077, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 312, train_loss = 1.310536839067936, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 313, train_loss = 1.3071542183752172, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 314, train_loss = 1.3037850894033909, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 315, train_loss = 1.3005353771150112, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 316, train_loss = 1.2972331009805202, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 317, train_loss = 1.2939118544454686, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 318, train_loss = 1.2906347115640529, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 319, train_loss = 1.2874902350013144, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 320, train_loss = 1.284327608824242, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 321, train_loss = 1.2811356422607787, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 322, train_loss = 1.2779897600412369, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 323, train_loss = 1.274904000281822, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 324, train_loss = 1.2718090663547628, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 325, train_loss = 1.2687715329229832, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 326, train_loss = 1.2656774458591826, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 327, train_loss = 1.2626997617189772, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 328, train_loss = 1.2596853623981588, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 329, train_loss = 1.2567504954640754, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 330, train_loss = 1.2538339545135386, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 331, train_loss = 1.2508813229505904, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 332, train_loss = 1.248040443926584, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 333, train_loss = 1.2451421146397479, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 334, train_loss = 1.2422849659924395, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 335, train_loss = 1.2394429457490332, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 336, train_loss = 1.2366582776303403, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 337, train_loss = 1.2339226652984507, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 338, train_loss = 1.2311580019886605, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 339, train_loss = 1.2284258914296515, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 340, train_loss = 1.2256679311394691, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 341, train_loss = 1.2230198197066784, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 342, train_loss = 1.2203389815986156, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 343, train_loss = 1.217709546268452, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 344, train_loss = 1.2151536419987679, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 345, train_loss = 1.2124662101268768, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 346, train_loss = 1.2099763776059262, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 347, train_loss = 1.2073802475933917, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 348, train_loss = 1.2048374551231973, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 349, train_loss = 1.2023762886528857, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 350, train_loss = 1.1997997462749481, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 351, train_loss = 1.1974210515618324, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 352, train_loss = 1.1948768844013102, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 353, train_loss = 1.1924340091645718, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 354, train_loss = 1.1900424547493458, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 355, train_loss = 1.187646046280861, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 356, train_loss = 1.1852603157167323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 357, train_loss = 1.1828976037795655, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 358, train_loss = 1.1805735218222253, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 359, train_loss = 1.1781659163534641, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 360, train_loss = 1.1758702148799784, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 361, train_loss = 1.1736105022137053, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 362, train_loss = 1.1713492013514042, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 363, train_loss = 1.1690343208611012, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 364, train_loss = 1.1667471192777157, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 365, train_loss = 1.1645899911527522, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 366, train_loss = 1.1623064962332137, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 367, train_loss = 1.1601361644570716, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 368, train_loss = 1.1579070935840718, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 369, train_loss = 1.155801858752966, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 370, train_loss = 1.153616088151466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 371, train_loss = 1.1514750135247596, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 372, train_loss = 1.1493179500102997, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 373, train_loss = 1.14720468968153, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 374, train_loss = 1.1451692159171216, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 375, train_loss = 1.1429810101981275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 376, train_loss = 1.1410214242641814, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 377, train_loss = 1.1388600778882392, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 378, train_loss = 1.1368602253496647, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 379, train_loss = 1.1348645687103271, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 380, train_loss = 1.1328768220846541, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 381, train_loss = 1.1307897766237147, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 382, train_loss = 1.1288716979324818, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 383, train_loss = 1.1269012739066966, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 384, train_loss = 1.1249210623209365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 385, train_loss = 1.1229961166973226, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 386, train_loss = 1.1210297283832915, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 387, train_loss = 1.1191302053630352, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 388, train_loss = 1.117214810103178, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 389, train_loss = 1.1153388830716722, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 390, train_loss = 1.1134724989533424, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 391, train_loss = 1.1115641705691814, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 392, train_loss = 1.1097409601206891, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 393, train_loss = 1.1078508074278943, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 394, train_loss = 1.1060843517188914, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 395, train_loss = 1.1042386504705064, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 396, train_loss = 1.1023943250183947, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 397, train_loss = 1.1006102487444878, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 398, train_loss = 1.0988546162843704, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 399, train_loss = 1.0970459505915642, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 400, train_loss = 1.0953384091262706, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 401, train_loss = 1.0935186855494976, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 402, train_loss = 1.091883371293079, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 403, train_loss = 1.0900560903246514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 404, train_loss = 1.0883229076862335, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 405, train_loss = 1.0867228992283344, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 406, train_loss = 1.0849366945330985, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 407, train_loss = 1.0832883231341839, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 408, train_loss = 1.0816600223188289, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 409, train_loss = 1.0798977513913997, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 410, train_loss = 1.0783022021059878, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 411, train_loss = 1.076676735014189, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 412, train_loss = 1.0750157137808856, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 413, train_loss = 1.0733978562057018, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 414, train_loss = 1.0717707773146685, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 415, train_loss = 1.0702051532862242, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 416, train_loss = 1.0685851536691189, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 417, train_loss = 1.066985059529543, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 418, train_loss = 1.0654113230702933, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 419, train_loss = 1.0638575330376625, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 420, train_loss = 1.0623659951088484, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 421, train_loss = 1.0607436075806618, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 422, train_loss = 1.0592794592084829, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 423, train_loss = 1.057708092033863, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 424, train_loss = 1.056186887115473, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 425, train_loss = 1.0546943085792009, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 426, train_loss = 1.0531895334424917, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 427, train_loss = 1.0516631752252579, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 428, train_loss = 1.0502371502516326, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 429, train_loss = 1.04864546036697, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 430, train_loss = 1.047242395579815, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 431, train_loss = 1.0456501891312655, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 432, train_loss = 1.0442773861286696, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 433, train_loss = 1.0427691799995955, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 434, train_loss = 1.0414038760063704, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 435, train_loss = 1.0399118823406752, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 436, train_loss = 1.03855649381876, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 437, train_loss = 1.0371269012393896, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 438, train_loss = 1.0357242325844709, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 439, train_loss = 1.0343240747752134, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 440, train_loss = 1.0328937210142612, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 441, train_loss = 1.0316309022309724, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 442, train_loss = 1.0301835238933563, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 443, train_loss = 1.0288164814410266, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 444, train_loss = 1.027557055145735, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 445, train_loss = 1.0260925889015198, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 446, train_loss = 1.0248442304728087, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 447, train_loss = 1.0235567465424538, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 448, train_loss = 1.0221872875990812, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 449, train_loss = 1.0209466479718685, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 450, train_loss = 1.0195696875452995, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 451, train_loss = 1.0182886719703674, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 452, train_loss = 1.0170785846712533, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 453, train_loss = 1.0157285953464452, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 454, train_loss = 1.0145047133264598, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 455, train_loss = 1.0131599555315915, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 456, train_loss = 1.011985920369625, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 457, train_loss = 1.0106897416117135, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 458, train_loss = 1.0094101503491402, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 459, train_loss = 1.0082346039416734, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 460, train_loss = 1.0069824755191803, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 461, train_loss = 1.0056633291242179, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 462, train_loss = 1.00467137247324, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 463, train_loss = 1.0033187307417393, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 464, train_loss = 1.002187234669691, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 465, train_loss = 1.0009536817669868, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 466, train_loss = 0.9997001960873604, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 467, train_loss = 0.9985713213682175, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 468, train_loss = 0.9973957960901316, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 469, train_loss = 0.9962045115826186, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 470, train_loss = 0.9950490668416023, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 471, train_loss = 0.9939105212688446, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 472, train_loss = 0.9927141840162221, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 473, train_loss = 0.9916207095084246, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 474, train_loss = 0.9904725427331869, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 475, train_loss = 0.9892261525092181, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 476, train_loss = 0.9882695687410887, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 477, train_loss = 0.9870593535306398, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 478, train_loss = 0.985947555542225, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 479, train_loss = 0.9848192694189493, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 480, train_loss = 0.9837385763821658, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 481, train_loss = 0.9825364388525486, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 482, train_loss = 0.9815821548399981, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 483, train_loss = 0.9804224284889642, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 484, train_loss = 0.979337772965664, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 485, train_loss = 0.9782873516378459, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 486, train_loss = 0.9771848196687642, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 487, train_loss = 0.9760554110107478, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 488, train_loss = 0.9750779519381467, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 489, train_loss = 0.9739932964148466, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 490, train_loss = 0.9729127387108747, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 491, train_loss = 0.9718895157275256, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 492, train_loss = 0.9707854265870992, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 493, train_loss = 0.9697664380073547, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 494, train_loss = 0.9686961298284587, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 495, train_loss = 0.9677362466754857, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 496, train_loss = 0.9666500737366732, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 497, train_loss = 0.9656760556099471, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 498, train_loss = 0.9646359371545259, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 499, train_loss = 0.9636063799262047, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████▏                                                            | 5/30 [33:49<2:48:36, 404.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "6th- epoch: 0, train_loss = 276.39845073223114, train_acc = 0.4165114112715417\n",
      "test Acc 0.5567970204841713:\n",
      "6th- epoch: 1, train_loss = 214.47018587589264, train_acc = 0.5570563577084303\n",
      "test Acc 0.5675046554934823:\n",
      "6th- epoch: 2, train_loss = 167.44503098726273, train_acc = 0.5698649278062413\n",
      "test Acc 0.5893854748603352:\n",
      "6th- epoch: 3, train_loss = 138.41014593839645, train_acc = 0.6447368421052632\n",
      "test Acc 0.7183426443202979:\n",
      "6th- epoch: 4, train_loss = 118.68853086233139, train_acc = 0.746040987424313\n",
      "test Acc 0.7746741154562383:\n",
      "6th- epoch: 5, train_loss = 103.59522566199303, train_acc = 0.7757335817419655\n",
      "test Acc 0.797486033519553:\n",
      "6th- epoch: 6, train_loss = 91.38036420941353, train_acc = 0.7962272938984629\n",
      "test Acc 0.8175046554934823:\n",
      "6th- epoch: 7, train_loss = 81.39000251889229, train_acc = 0.8134606427573359\n",
      "test Acc 0.8282122905027933:\n",
      "6th- epoch: 8, train_loss = 73.00386610627174, train_acc = 0.8290638099673964\n",
      "test Acc 0.8449720670391061:\n",
      "6th- epoch: 9, train_loss = 65.71418949961662, train_acc = 0.8507219375873312\n",
      "test Acc 0.8705772811918063:\n",
      "6th- epoch: 10, train_loss = 59.2749749571085, train_acc = 0.8765719608756404\n",
      "test Acc 0.8845437616387337:\n",
      "6th- epoch: 11, train_loss = 53.5761811286211, train_acc = 0.8953190498369819\n",
      "test Acc 0.9036312849162011:\n",
      "6th- epoch: 12, train_loss = 48.53922842442989, train_acc = 0.9187238006520727\n",
      "test Acc 0.9273743016759777:\n",
      "6th- epoch: 13, train_loss = 44.096238285303116, train_acc = 0.9342105263157895\n",
      "test Acc 0.9338919925512105:\n",
      "6th- epoch: 14, train_loss = 40.197042778134346, train_acc = 0.9427107591988821\n",
      "test Acc 0.9376163873370578:\n",
      "6th- epoch: 15, train_loss = 36.80364829301834, train_acc = 0.946786213320913\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 16, train_loss = 33.871771425008774, train_acc = 0.9503959012575687\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 17, train_loss = 31.34927312284708, train_acc = 0.952491849091756\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 18, train_loss = 29.186720207333565, train_acc = 0.9543549138332557\n",
      "test Acc 0.9487895716945997:\n",
      "6th- epoch: 19, train_loss = 27.331854842603207, train_acc = 0.9574988355845365\n",
      "test Acc 0.952513966480447:\n",
      "6th- epoch: 20, train_loss = 25.735868476331234, train_acc = 0.9611085235211924\n",
      "test Acc 0.9553072625698324:\n",
      "6th- epoch: 21, train_loss = 24.354948580265045, train_acc = 0.963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "6th- epoch: 22, train_loss = 23.149956837296486, train_acc = 0.9657661853749417\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 23, train_loss = 22.08931080624461, train_acc = 0.9666977177456917\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 24, train_loss = 21.147605657577515, train_acc = 0.9678621332091291\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 25, train_loss = 20.30502350628376, train_acc = 0.9692594317652539\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 26, train_loss = 19.54606691747904, train_acc = 0.9694923148579413\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 27, train_loss = 18.857377376407385, train_acc = 0.9701909641360037\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 28, train_loss = 18.228484325110912, train_acc = 0.970540288775035\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 29, train_loss = 17.650632951408625, train_acc = 0.9708896134140661\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 30, train_loss = 17.116800669580698, train_acc = 0.9715882626921285\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 31, train_loss = 16.621435709297657, train_acc = 0.9725197950628784\n",
      "test Acc 0.9650837988826816:\n",
      "6th- epoch: 32, train_loss = 16.159335300326347, train_acc = 0.9729855612482534\n",
      "test Acc 0.9646182495344506:\n",
      "6th- epoch: 33, train_loss = 15.726453769952059, train_acc = 0.9733348858872846\n",
      "test Acc 0.9650837988826816:\n",
      "6th- epoch: 34, train_loss = 15.319900684058666, train_acc = 0.9735677689799721\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 35, train_loss = 14.936814088374376, train_acc = 0.9739170936190032\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 36, train_loss = 14.574221972376108, train_acc = 0.9741499767116907\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 37, train_loss = 14.230566184967756, train_acc = 0.9742664182580345\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 38, train_loss = 13.903327096253633, train_acc = 0.9747321844434094\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 39, train_loss = 13.591182850301266, train_acc = 0.9749650675360969\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 40, train_loss = 13.292710792273283, train_acc = 0.9754308337214718\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 41, train_loss = 13.006661601364613, train_acc = 0.975780158360503\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 42, train_loss = 12.732051506638527, train_acc = 0.9763623660922217\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 43, train_loss = 12.468404676765203, train_acc = 0.9769445738239404\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 44, train_loss = 12.214841324836016, train_acc = 0.9772938984629715\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 45, train_loss = 11.970997039228678, train_acc = 0.9776432231020028\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 46, train_loss = 11.736157778650522, train_acc = 0.9781089892873778\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 47, train_loss = 11.50962995365262, train_acc = 0.9782254308337215\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 48, train_loss = 11.29091495089233, train_acc = 0.9783418723800652\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 49, train_loss = 11.079303300008178, train_acc = 0.9785747554727526\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 50, train_loss = 10.874686550348997, train_acc = 0.9786911970190965\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 51, train_loss = 10.676657134667039, train_acc = 0.9789240801117839\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 52, train_loss = 10.484843106940389, train_acc = 0.9792734047508151\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 53, train_loss = 10.298897290602326, train_acc = 0.9795062878435026\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 54, train_loss = 10.11852077767253, train_acc = 0.97973917093619\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 55, train_loss = 9.94318607263267, train_acc = 0.9804378202142524\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 56, train_loss = 9.773038594052196, train_acc = 0.9807871448532837\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 57, train_loss = 9.607416303828359, train_acc = 0.9814857941313461\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 58, train_loss = 9.44640276581049, train_acc = 0.9818351187703773\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 59, train_loss = 9.289525918662548, train_acc = 0.981951560316721\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 60, train_loss = 9.136838437989354, train_acc = 0.981951560316721\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 61, train_loss = 8.988280173391104, train_acc = 0.9820680018630648\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 62, train_loss = 8.843719273805618, train_acc = 0.9824173265020959\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 63, train_loss = 8.702900115400553, train_acc = 0.9826502095947834\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 64, train_loss = 8.565574457868934, train_acc = 0.9829995342338146\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 65, train_loss = 8.431734342128038, train_acc = 0.9831159757801584\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 66, train_loss = 8.301297741010785, train_acc = 0.9832324173265021\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 67, train_loss = 8.174048840999603, train_acc = 0.9834653004191896\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 68, train_loss = 8.049831924960017, train_acc = 0.983698183511877\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 69, train_loss = 7.928672332316637, train_acc = 0.9847461574289706\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 70, train_loss = 7.810283962637186, train_acc = 0.9849790405216581\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 71, train_loss = 7.694605998694897, train_acc = 0.9850954820680019\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 72, train_loss = 7.5816531255841255, train_acc = 0.9852119236143456\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 73, train_loss = 7.471204033121467, train_acc = 0.985444806707033\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 74, train_loss = 7.363276455551386, train_acc = 0.9855612482533768\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 75, train_loss = 7.257540930062532, train_acc = 0.9860270144387517\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 76, train_loss = 7.154222870245576, train_acc = 0.9861434559850955\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 77, train_loss = 7.053123055025935, train_acc = 0.9862598975314392\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 78, train_loss = 6.954244736582041, train_acc = 0.9862598975314392\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 79, train_loss = 6.857419732958078, train_acc = 0.9867256637168141\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 80, train_loss = 6.762703202664852, train_acc = 0.9867256637168141\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 81, train_loss = 6.669817151501775, train_acc = 0.9871914299021891\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 82, train_loss = 6.578849880024791, train_acc = 0.9870749883558454\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 83, train_loss = 6.489543689414859, train_acc = 0.9876571960875641\n",
      "test Acc 0.979050279329609:\n",
      "6th- epoch: 84, train_loss = 6.401903830468655, train_acc = 0.9877736376339078\n",
      "test Acc 0.979050279329609:\n",
      "6th- epoch: 85, train_loss = 6.31580687686801, train_acc = 0.9877736376339078\n",
      "test Acc 0.979050279329609:\n",
      "6th- epoch: 86, train_loss = 6.231239174492657, train_acc = 0.9878900791802515\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 87, train_loss = 6.148322991095483, train_acc = 0.9882394038192828\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 88, train_loss = 6.066812174394727, train_acc = 0.9885887284583139\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 89, train_loss = 5.98681571893394, train_acc = 0.9885887284583139\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 90, train_loss = 5.908219839446247, train_acc = 0.9888216115510013\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 91, train_loss = 5.8309730077162385, train_acc = 0.9891709361900326\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 92, train_loss = 5.755143227055669, train_acc = 0.9891709361900326\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 93, train_loss = 5.68061347771436, train_acc = 0.98940381928272\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 94, train_loss = 5.6073275515809655, train_acc = 0.9895202608290639\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 95, train_loss = 5.535341713577509, train_acc = 0.9896367023754076\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 96, train_loss = 5.464383675716817, train_acc = 0.9897531439217513\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 97, train_loss = 5.3946409448981285, train_acc = 0.989869585468095\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 98, train_loss = 5.326089799404144, train_acc = 0.9902189101071263\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 99, train_loss = 5.258587941527367, train_acc = 0.9902189101071263\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 100, train_loss = 5.19228343013674, train_acc = 0.9904517931998137\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 101, train_loss = 5.127008055336773, train_acc = 0.9905682347461574\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 102, train_loss = 5.0628352062776685, train_acc = 0.9906846762925011\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 103, train_loss = 4.999675980769098, train_acc = 0.9909175593851887\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 104, train_loss = 4.937344197183847, train_acc = 0.990801117838845\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 105, train_loss = 4.876120300032198, train_acc = 0.9910340009315324\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 106, train_loss = 4.816111701540649, train_acc = 0.9911504424778761\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 107, train_loss = 4.757054730318487, train_acc = 0.9911504424778761\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 108, train_loss = 4.698991493321955, train_acc = 0.9911504424778761\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 109, train_loss = 4.642086549662054, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 110, train_loss = 4.585944983176887, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 111, train_loss = 4.530734613537788, train_acc = 0.9916162086632511\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 112, train_loss = 4.476603245362639, train_acc = 0.9917326502095948\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 113, train_loss = 4.423162030056119, train_acc = 0.9919655333022822\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 114, train_loss = 4.370735825039446, train_acc = 0.9919655333022822\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 115, train_loss = 4.319075140170753, train_acc = 0.9919655333022822\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 116, train_loss = 4.268354344181716, train_acc = 0.9921984163949698\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 117, train_loss = 4.218552626669407, train_acc = 0.9923148579413135\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 118, train_loss = 4.169678165577352, train_acc = 0.9923148579413135\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 119, train_loss = 4.121595489792526, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 120, train_loss = 4.074391711503267, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 121, train_loss = 4.027983902953565, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 122, train_loss = 3.9824490435421467, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 123, train_loss = 3.937573704868555, train_acc = 0.9928970656730322\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 124, train_loss = 3.8935901829972863, train_acc = 0.9931299487657196\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 125, train_loss = 3.8503279108554125, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 126, train_loss = 3.8078926615417004, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 127, train_loss = 3.766051002778113, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 128, train_loss = 3.7251239512115717, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 129, train_loss = 3.684845364652574, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 130, train_loss = 3.6453633727505803, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 131, train_loss = 3.6065950877964497, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 132, train_loss = 3.5685516223311424, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 133, train_loss = 3.5311256032437086, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 134, train_loss = 3.494353082962334, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 135, train_loss = 3.4582456331700087, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 136, train_loss = 3.4226817046292126, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 137, train_loss = 3.387847438454628, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 138, train_loss = 3.3536227960139513, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 139, train_loss = 3.319954840000719, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 140, train_loss = 3.2869269982911646, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 141, train_loss = 3.254404006060213, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 142, train_loss = 3.222525541204959, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 143, train_loss = 3.1910922899842262, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 144, train_loss = 3.1601416398771107, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 145, train_loss = 3.129903146997094, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 146, train_loss = 3.100031034555286, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 147, train_loss = 3.070693604182452, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 148, train_loss = 3.041919007897377, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 149, train_loss = 3.0136020556092262, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 150, train_loss = 2.985803585499525, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 151, train_loss = 2.958285667002201, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 152, train_loss = 2.9314169459976256, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 153, train_loss = 2.9050333127379417, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 154, train_loss = 2.8788672969676554, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 155, train_loss = 2.8531658314168453, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 156, train_loss = 2.8279546448029578, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 157, train_loss = 2.803277743514627, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 158, train_loss = 2.7787723601795733, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 159, train_loss = 2.754766923841089, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 160, train_loss = 2.7313782102428377, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 161, train_loss = 2.7081496007740498, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 162, train_loss = 2.6853329963050783, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 163, train_loss = 2.6629812815226614, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 164, train_loss = 2.6408141986466944, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 165, train_loss = 2.619132289197296, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 166, train_loss = 2.5977695644833148, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 167, train_loss = 2.576714803930372, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 168, train_loss = 2.5561681441031396, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 169, train_loss = 2.5359217398799956, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 170, train_loss = 2.515839785337448, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 171, train_loss = 2.4963441961444914, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 172, train_loss = 2.477007062640041, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 173, train_loss = 2.4579916037619114, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 174, train_loss = 2.439281389117241, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 175, train_loss = 2.4208003133535385, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 176, train_loss = 2.4026041948236525, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 177, train_loss = 2.3848158777691424, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 178, train_loss = 2.3672514110803604, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 179, train_loss = 2.3499303334392607, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 180, train_loss = 2.332953739911318, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 181, train_loss = 2.316285369452089, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 182, train_loss = 2.2999048815108836, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 183, train_loss = 2.283730541821569, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 184, train_loss = 2.267952758818865, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 185, train_loss = 2.252335336059332, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 186, train_loss = 2.237024007830769, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 187, train_loss = 2.2219516907352954, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 188, train_loss = 2.2071570630650967, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 189, train_loss = 2.1926089997868985, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 190, train_loss = 2.178222142159939, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 191, train_loss = 2.1640529048163444, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 192, train_loss = 2.1501447472255677, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 193, train_loss = 2.1365296852309257, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 194, train_loss = 2.122964261798188, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 195, train_loss = 2.109739578096196, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 196, train_loss = 2.096616951050237, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 197, train_loss = 2.0837660059332848, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 198, train_loss = 2.071095212129876, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 199, train_loss = 2.058652125298977, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 200, train_loss = 2.0463442765176296, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 201, train_loss = 2.034276083111763, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 202, train_loss = 2.022352423518896, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 203, train_loss = 2.0106845286209136, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 204, train_loss = 1.999101534485817, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 205, train_loss = 1.9877060502767563, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 206, train_loss = 1.9765249404590577, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 207, train_loss = 1.9654577374458313, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 208, train_loss = 1.954509821953252, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 209, train_loss = 1.9438495263457298, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 210, train_loss = 1.9332185536623, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 211, train_loss = 1.9229334145784378, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 212, train_loss = 1.9125808998942375, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 213, train_loss = 1.902485464932397, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 214, train_loss = 1.892542564542964, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 215, train_loss = 1.8826483327429742, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 216, train_loss = 1.873002503067255, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 217, train_loss = 1.863400824368, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 218, train_loss = 1.8540494765620679, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 219, train_loss = 1.8446889594197273, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 220, train_loss = 1.8355354282539338, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 221, train_loss = 1.8264893256127834, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 222, train_loss = 1.8174858081620187, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 223, train_loss = 1.808733120560646, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 224, train_loss = 1.8000056967139244, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 225, train_loss = 1.7914683532435447, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 226, train_loss = 1.7829387921374291, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 227, train_loss = 1.7746210594195873, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 228, train_loss = 1.766301779774949, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 229, train_loss = 1.7581796448212117, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 230, train_loss = 1.7501045402605087, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 231, train_loss = 1.7421760074794292, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 232, train_loss = 1.7342772532720119, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 233, train_loss = 1.7265288692433387, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 234, train_loss = 1.7189154711086303, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 235, train_loss = 1.7113256342709064, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 236, train_loss = 1.7038651779294014, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 237, train_loss = 1.6964705511927605, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 238, train_loss = 1.6891366664785892, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 239, train_loss = 1.6820093009155244, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 240, train_loss = 1.6748677615541965, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 241, train_loss = 1.6677303302567452, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 242, train_loss = 1.6608374889474362, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 243, train_loss = 1.6539493340533227, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 244, train_loss = 1.6471680601825938, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 245, train_loss = 1.6404648385941982, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 246, train_loss = 1.6338463512947783, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 247, train_loss = 1.6273027993738651, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 248, train_loss = 1.6208948815474287, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 249, train_loss = 1.6144364029169083, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 250, train_loss = 1.608096718788147, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 251, train_loss = 1.6018792850663885, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 252, train_loss = 1.5956131865968928, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 253, train_loss = 1.5895528569817543, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 254, train_loss = 1.5835013315081596, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 255, train_loss = 1.5775314830243587, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 256, train_loss = 1.571652072132565, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 257, train_loss = 1.5657385885715485, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 258, train_loss = 1.5600065378239378, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 259, train_loss = 1.554327933699824, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 260, train_loss = 1.5485931634902954, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 261, train_loss = 1.5430066846311092, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 262, train_loss = 1.537526528001763, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 263, train_loss = 1.5319399312138557, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 264, train_loss = 1.5266465743770823, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 265, train_loss = 1.5212081037461758, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 266, train_loss = 1.515922854305245, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 267, train_loss = 1.5106505701551214, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 268, train_loss = 1.505549623281695, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 269, train_loss = 1.5004265444586053, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 270, train_loss = 1.4952753372490406, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 271, train_loss = 1.490242193103768, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 272, train_loss = 1.4853345094015822, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 273, train_loss = 1.4804034307599068, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 274, train_loss = 1.4754479514667764, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 275, train_loss = 1.4706301862606779, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 276, train_loss = 1.4659047437598929, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 277, train_loss = 1.4611781475832686, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 278, train_loss = 1.4564720602938905, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 279, train_loss = 1.4518142553279176, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 280, train_loss = 1.4473166055977345, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 281, train_loss = 1.4426367469131947, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 282, train_loss = 1.438191213994287, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 283, train_loss = 1.4337172718951479, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 284, train_loss = 1.4293145214905962, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 285, train_loss = 1.424932555644773, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 286, train_loss = 1.4205313610145822, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 287, train_loss = 1.4163679828634486, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 288, train_loss = 1.4120193807175383, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 289, train_loss = 1.4078049398958683, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 290, train_loss = 1.4036560095846653, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 291, train_loss = 1.3995018551358953, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 292, train_loss = 1.3953979635844007, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 293, train_loss = 1.3912880247225985, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 294, train_loss = 1.3873007483780384, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 295, train_loss = 1.3833437835564837, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 296, train_loss = 1.3794280029833317, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 297, train_loss = 1.375450175255537, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 298, train_loss = 1.37162032967899, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 299, train_loss = 1.3677502373466268, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 300, train_loss = 1.363974099396728, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 301, train_loss = 1.3601055331528187, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 302, train_loss = 1.3564490874996409, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 303, train_loss = 1.3526993282139301, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 304, train_loss = 1.349055548547767, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 305, train_loss = 1.3454169692704454, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 306, train_loss = 1.3417565785348415, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 307, train_loss = 1.3382300399243832, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 308, train_loss = 1.334658501087688, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 309, train_loss = 1.3311488268664107, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 310, train_loss = 1.3276524121174589, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 311, train_loss = 1.324223168194294, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 312, train_loss = 1.3208186961710453, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 313, train_loss = 1.3173467740416527, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 314, train_loss = 1.3139533214271069, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 315, train_loss = 1.31067370751407, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 316, train_loss = 1.3073947926750407, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 317, train_loss = 1.304082584916614, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 318, train_loss = 1.3008971872041002, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 319, train_loss = 1.2976153008639812, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 320, train_loss = 1.2944640418281779, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 321, train_loss = 1.2913226410746574, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 322, train_loss = 1.2881403106148355, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 323, train_loss = 1.2849988068337552, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 324, train_loss = 1.2819205708801746, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 325, train_loss = 1.2788562327623367, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 326, train_loss = 1.2758837032015435, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 327, train_loss = 1.2728355352883227, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 328, train_loss = 1.2697912380099297, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 329, train_loss = 1.2669236275251023, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 330, train_loss = 1.263919026881922, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 331, train_loss = 1.2609581028227694, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 332, train_loss = 1.2580912870471366, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 333, train_loss = 1.2551868346636184, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 334, train_loss = 1.2524424393777736, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 335, train_loss = 1.2494705108110793, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 336, train_loss = 1.2467084067757241, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 337, train_loss = 1.2438847956364043, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 338, train_loss = 1.2411491188104264, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 339, train_loss = 1.2383963987231255, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 340, train_loss = 1.235660174221266, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 341, train_loss = 1.2330194016103633, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 342, train_loss = 1.230283812910784, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 343, train_loss = 1.2276414359803312, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 344, train_loss = 1.2250124203856103, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 345, train_loss = 1.222389126836788, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 346, train_loss = 1.2197935196454637, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 347, train_loss = 1.2171654092962854, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 348, train_loss = 1.214646843553055, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 349, train_loss = 1.2121599353849888, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 350, train_loss = 1.2097242486779578, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 351, train_loss = 1.2071011711959727, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 352, train_loss = 1.2046454598312266, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 353, train_loss = 1.202209095179569, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 354, train_loss = 1.1996794641017914, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 355, train_loss = 1.197222022979986, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 356, train_loss = 1.1948029113118537, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 357, train_loss = 1.1924466875498183, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 358, train_loss = 1.190138318866957, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 359, train_loss = 1.1876962159876712, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 360, train_loss = 1.185454631864559, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 361, train_loss = 1.1830740943551064, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 362, train_loss = 1.180709050328005, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 363, train_loss = 1.1784918904304504, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 364, train_loss = 1.1762122226064093, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 365, train_loss = 1.1739883099799044, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 366, train_loss = 1.1717040476505645, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 367, train_loss = 1.16947965946747, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 368, train_loss = 1.1673097759485245, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 369, train_loss = 1.1650916077196598, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 370, train_loss = 1.162870189815294, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 371, train_loss = 1.160768264264334, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 372, train_loss = 1.1585472784936428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 373, train_loss = 1.1563929083640687, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 374, train_loss = 1.1544281505048275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 375, train_loss = 1.1522464987938292, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 376, train_loss = 1.1501053186948411, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 377, train_loss = 1.1480744418804534, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 378, train_loss = 1.1459915935993195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 379, train_loss = 1.143941072106827, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 380, train_loss = 1.1419686302542686, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 381, train_loss = 1.1398931157891639, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 382, train_loss = 1.1378422230482101, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 383, train_loss = 1.1358942004735582, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 384, train_loss = 1.1338903779978864, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 385, train_loss = 1.1319366370444186, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 386, train_loss = 1.1300039241905324, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 387, train_loss = 1.128015919297468, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 388, train_loss = 1.12613994628191, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 389, train_loss = 1.1241772795910947, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 390, train_loss = 1.1222858093678951, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 391, train_loss = 1.120502095669508, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 392, train_loss = 1.118527336686384, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 393, train_loss = 1.1166314209694974, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 394, train_loss = 1.114755688875448, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 395, train_loss = 1.1129922457039356, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 396, train_loss = 1.1112158472533338, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 397, train_loss = 1.1093055941164494, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 398, train_loss = 1.1075574817950837, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 399, train_loss = 1.1057178651099093, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 400, train_loss = 1.1039879980380647, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 401, train_loss = 1.1022417818312533, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 402, train_loss = 1.1004670386319049, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 403, train_loss = 1.0986967273056507, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 404, train_loss = 1.0970321607892402, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 405, train_loss = 1.0951945396955125, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 406, train_loss = 1.0934783220291138, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 407, train_loss = 1.091915212571621, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 408, train_loss = 1.0901151199941523, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 409, train_loss = 1.0884376156027429, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 410, train_loss = 1.0867686507408507, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 411, train_loss = 1.085174618929159, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 412, train_loss = 1.0835099493269809, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 413, train_loss = 1.0818387742037885, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 414, train_loss = 1.0802557530696504, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 415, train_loss = 1.07864197838353, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 416, train_loss = 1.0768989424104802, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 417, train_loss = 1.075473045289982, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 418, train_loss = 1.0738050689105876, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 419, train_loss = 1.0722325220704079, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 420, train_loss = 1.0706483535468578, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 421, train_loss = 1.0690818801522255, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 422, train_loss = 1.0675151881878264, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 423, train_loss = 1.065907406329643, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 424, train_loss = 1.0644468652899377, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 425, train_loss = 1.0630124782328494, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 426, train_loss = 1.0614003029768355, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 427, train_loss = 1.059839194000233, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 428, train_loss = 1.05840938660549, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 429, train_loss = 1.0568942725658417, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 430, train_loss = 1.0553610709612258, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 431, train_loss = 1.0539717214996926, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 432, train_loss = 1.052462987601757, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 433, train_loss = 1.0509722518618219, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 434, train_loss = 1.0496617679600604, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 435, train_loss = 1.048076209903229, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 436, train_loss = 1.0466731302440166, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 437, train_loss = 1.04526661708951, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 438, train_loss = 1.0438843754527625, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 439, train_loss = 1.0424750397505704, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 440, train_loss = 1.0410446313617285, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 441, train_loss = 1.0396357936260756, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 442, train_loss = 1.0383057085273322, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 443, train_loss = 1.0369427973928396, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 444, train_loss = 1.0356405079364777, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 445, train_loss = 1.0341598515806254, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 446, train_loss = 1.0328134074807167, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 447, train_loss = 1.0315218729374465, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 448, train_loss = 1.030190370976925, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 449, train_loss = 1.0287758471968118, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 450, train_loss = 1.02757278829813, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 451, train_loss = 1.0261384894547518, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 452, train_loss = 1.0248461340961512, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 453, train_loss = 1.0235010112228338, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 454, train_loss = 1.022289577871561, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 455, train_loss = 1.0210331554117147, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 456, train_loss = 1.0197323647735175, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 457, train_loss = 1.0184404291212559, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 458, train_loss = 1.0172292267379817, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 459, train_loss = 1.015805126487976, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 460, train_loss = 1.01475696140551, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 461, train_loss = 1.0133818822505418, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 462, train_loss = 1.0121610338392202, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 463, train_loss = 1.0108910960552748, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 464, train_loss = 1.0097550178470556, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 465, train_loss = 1.0085096545517445, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 466, train_loss = 1.007191682845587, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 467, train_loss = 1.0061839669942856, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 468, train_loss = 1.0048010361788329, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 469, train_loss = 1.0037069295940455, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 470, train_loss = 1.002486638724804, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 471, train_loss = 1.00131911659264, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 472, train_loss = 1.0000980583427008, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 473, train_loss = 0.9989171934721526, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 474, train_loss = 0.9978094908001367, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 475, train_loss = 0.9966492416861001, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 476, train_loss = 0.9955099696817342, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 477, train_loss = 0.9943656139075756, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 478, train_loss = 0.9931294942798559, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 479, train_loss = 0.9921005008218344, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 480, train_loss = 0.9909571458993014, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 481, train_loss = 0.9897567418811377, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 482, train_loss = 0.9887186276318971, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 483, train_loss = 0.9875413986446802, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 484, train_loss = 0.9864479253592435, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 485, train_loss = 0.9853935813007411, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 486, train_loss = 0.9842352581617888, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 487, train_loss = 0.9831685870885849, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 488, train_loss = 0.982160604238743, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 489, train_loss = 0.980964906513691, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 490, train_loss = 0.9799284525215626, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 491, train_loss = 0.9789836679992732, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 492, train_loss = 0.9777353604731616, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 493, train_loss = 0.9768423959612846, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 494, train_loss = 0.975728123128647, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 495, train_loss = 0.9746450161037501, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 496, train_loss = 0.9735013283789158, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 497, train_loss = 0.9725107699632645, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 498, train_loss = 0.9715496562421322, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 499, train_loss = 0.9704509501752909, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████▌                                                          | 6/30 [40:39<2:42:36, 406.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "7th- epoch: 0, train_loss = 272.034716963768, train_acc = 0.4158127619934793\n",
      "test Acc 0.5153631284916201:\n",
      "7th- epoch: 1, train_loss = 208.74744498729706, train_acc = 0.5129250116441546\n",
      "test Acc 0.5442271880819367:\n",
      "7th- epoch: 2, train_loss = 164.0924727320671, train_acc = 0.584536562645552\n",
      "test Acc 0.6354748603351955:\n",
      "7th- epoch: 3, train_loss = 136.3577423095703, train_acc = 0.6837447601304145\n",
      "test Acc 0.7439478584729982:\n",
      "7th- epoch: 4, train_loss = 116.00583577156067, train_acc = 0.7602468560782487\n",
      "test Acc 0.7774674115456238:\n",
      "7th- epoch: 5, train_loss = 100.51993623375893, train_acc = 0.778178854215184\n",
      "test Acc 0.8016759776536313:\n",
      "7th- epoch: 6, train_loss = 88.50162494182587, train_acc = 0.7897065673032138\n",
      "test Acc 0.8086592178770949:\n",
      "7th- epoch: 7, train_loss = 78.9123166501522, train_acc = 0.8018164881229622\n",
      "test Acc 0.8347299813780261:\n",
      "7th- epoch: 8, train_loss = 70.84760296344757, train_acc = 0.8421052631578947\n",
      "test Acc 0.8677839851024208:\n",
      "7th- epoch: 9, train_loss = 63.779540061950684, train_acc = 0.8749417792268281\n",
      "test Acc 0.8854748603351955:\n",
      "7th- epoch: 10, train_loss = 57.48311388492584, train_acc = 0.8948532836516069\n",
      "test Acc 0.9059590316573557:\n",
      "7th- epoch: 11, train_loss = 51.88436208665371, train_acc = 0.9094084769445738\n",
      "test Acc 0.9199255121042831:\n",
      "7th- epoch: 12, train_loss = 46.95923002064228, train_acc = 0.9266418258034467\n",
      "test Acc 0.9352886405959032:\n",
      "7th- epoch: 13, train_loss = 42.66344067454338, train_acc = 0.939683278993945\n",
      "test Acc 0.9390130353817505:\n",
      "7th- epoch: 14, train_loss = 38.945690765976906, train_acc = 0.9464368886818817\n",
      "test Acc 0.9432029795158287:\n",
      "7th- epoch: 15, train_loss = 35.74821384251118, train_acc = 0.9501630181648812\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 16, train_loss = 33.008231073617935, train_acc = 0.9522589659990685\n",
      "test Acc 0.9459962756052142:\n",
      "7th- epoch: 17, train_loss = 30.660206027328968, train_acc = 0.9538891476478808\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 18, train_loss = 28.64093442261219, train_acc = 0.9561015370284117\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 19, train_loss = 26.896714948117733, train_acc = 0.9592454587796926\n",
      "test Acc 0.952513966480447:\n",
      "7th- epoch: 20, train_loss = 25.380731098353863, train_acc = 0.962156497438286\n",
      "test Acc 0.9548417132216015:\n",
      "7th- epoch: 21, train_loss = 24.054342921823263, train_acc = 0.9653004191895669\n",
      "test Acc 0.9585661080074488:\n",
      "7th- epoch: 22, train_loss = 22.88497593253851, train_acc = 0.9666977177456917\n",
      "test Acc 0.9604283054003724:\n",
      "7th- epoch: 23, train_loss = 21.84651743993163, train_acc = 0.9683278993945039\n",
      "test Acc 0.9613594040968343:\n",
      "7th- epoch: 24, train_loss = 20.918451499193907, train_acc = 0.9690265486725663\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 25, train_loss = 20.082359235733747, train_acc = 0.9693758733115976\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 26, train_loss = 19.32391046360135, train_acc = 0.9697251979506288\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 27, train_loss = 18.632122050970793, train_acc = 0.9701909641360037\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 28, train_loss = 17.997814059257507, train_acc = 0.9715882626921285\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 29, train_loss = 17.41294677183032, train_acc = 0.972286911970191\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 30, train_loss = 16.8718101978302, train_acc = 0.9728691197019096\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 31, train_loss = 16.368934031575918, train_acc = 0.9736842105263158\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 32, train_loss = 15.899470709264278, train_acc = 0.9739170936190032\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 33, train_loss = 15.459888577461243, train_acc = 0.9744993013507219\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 34, train_loss = 15.04706771671772, train_acc = 0.9751979506287843\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 35, train_loss = 14.658326543867588, train_acc = 0.9756637168141593\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 36, train_loss = 14.291655845940113, train_acc = 0.9761294829995343\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 37, train_loss = 13.944562427699566, train_acc = 0.9764788076385654\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 38, train_loss = 13.615358743816614, train_acc = 0.9768281322775967\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 39, train_loss = 13.302500929683447, train_acc = 0.9768281322775967\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 40, train_loss = 13.004459291696548, train_acc = 0.9771774569166278\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 41, train_loss = 12.720192078500986, train_acc = 0.9775267815556591\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 42, train_loss = 12.44838210195303, train_acc = 0.9781089892873778\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 43, train_loss = 12.188244063407183, train_acc = 0.9784583139264089\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 44, train_loss = 11.938983898609877, train_acc = 0.9791569632044713\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 45, train_loss = 11.69979789853096, train_acc = 0.9796227293898463\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 46, train_loss = 11.469783037900925, train_acc = 0.9798556124825337\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 47, train_loss = 11.248117741197348, train_acc = 0.9800884955752213\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 48, train_loss = 11.034292582422495, train_acc = 0.9805542617605962\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 49, train_loss = 10.827866218984127, train_acc = 0.9809035863996274\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 50, train_loss = 10.62835455313325, train_acc = 0.9813693525850024\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 51, train_loss = 10.435612421482801, train_acc = 0.9814857941313461\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 52, train_loss = 10.249252274632454, train_acc = 0.9816022356776898\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 53, train_loss = 10.068694427609444, train_acc = 0.9817186772240335\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 54, train_loss = 9.893278384581208, train_acc = 0.9820680018630648\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 55, train_loss = 9.723201181739569, train_acc = 0.9823008849557522\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 56, train_loss = 9.558149203658104, train_acc = 0.9824173265020959\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 57, train_loss = 9.397818867117167, train_acc = 0.9827666511411272\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 58, train_loss = 9.241980431601405, train_acc = 0.9827666511411272\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 59, train_loss = 9.090420132502913, train_acc = 0.9828830926874709\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 60, train_loss = 8.942817309871316, train_acc = 0.9834653004191896\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 61, train_loss = 8.799240117892623, train_acc = 0.9835817419655333\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 62, train_loss = 8.65944766998291, train_acc = 0.9839310666045645\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 63, train_loss = 8.523322530090809, train_acc = 0.9843968327899395\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 64, train_loss = 8.39059155061841, train_acc = 0.9845132743362832\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 65, train_loss = 8.261142125353217, train_acc = 0.9845132743362832\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 66, train_loss = 8.13475601375103, train_acc = 0.9845132743362832\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 67, train_loss = 8.01158382371068, train_acc = 0.9846297158826269\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 68, train_loss = 7.891439456492662, train_acc = 0.9849790405216581\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 69, train_loss = 7.773984050378203, train_acc = 0.985444806707033\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 70, train_loss = 7.659365229308605, train_acc = 0.9857941313460643\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 71, train_loss = 7.547268832102418, train_acc = 0.9860270144387517\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 72, train_loss = 7.437754113227129, train_acc = 0.9861434559850955\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 73, train_loss = 7.330771012231708, train_acc = 0.9861434559850955\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 74, train_loss = 7.225946053862572, train_acc = 0.9862598975314392\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 75, train_loss = 7.123458465561271, train_acc = 0.9862598975314392\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 76, train_loss = 7.023036500439048, train_acc = 0.9864927806241267\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 77, train_loss = 6.924792317673564, train_acc = 0.9868421052631579\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 78, train_loss = 6.828548276796937, train_acc = 0.9870749883558454\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 79, train_loss = 6.734320571646094, train_acc = 0.9869585468095017\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 80, train_loss = 6.641916882246733, train_acc = 0.9869585468095017\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 81, train_loss = 6.551508747041225, train_acc = 0.9875407545412203\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 82, train_loss = 6.462862363085151, train_acc = 0.9878900791802515\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 83, train_loss = 6.376216404139996, train_acc = 0.9880065207265952\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 84, train_loss = 6.291074359789491, train_acc = 0.9880065207265952\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 85, train_loss = 6.207636037841439, train_acc = 0.9881229622729389\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 86, train_loss = 6.125862509012222, train_acc = 0.9883558453656265\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 87, train_loss = 6.04541976749897, train_acc = 0.9885887284583139\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 88, train_loss = 5.966575315222144, train_acc = 0.9887051700046576\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 89, train_loss = 5.889113452285528, train_acc = 0.9889380530973452\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 90, train_loss = 5.813134148716927, train_acc = 0.9891709361900326\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 91, train_loss = 5.738620927557349, train_acc = 0.9891709361900326\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 92, train_loss = 5.66538299806416, train_acc = 0.9895202608290639\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 93, train_loss = 5.593552779406309, train_acc = 0.9897531439217513\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 94, train_loss = 5.522894876077771, train_acc = 0.9902189101071263\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 95, train_loss = 5.453458499163389, train_acc = 0.9904517931998137\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 96, train_loss = 5.385156680829823, train_acc = 0.9904517931998137\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 97, train_loss = 5.318250038661063, train_acc = 0.990801117838845\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 98, train_loss = 5.252360425889492, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 99, train_loss = 5.187596593983471, train_acc = 0.9912668840242198\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 100, train_loss = 5.123905344866216, train_acc = 0.9913833255705635\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 101, train_loss = 5.061286605894566, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 102, train_loss = 4.999786987900734, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 103, train_loss = 4.939257596619427, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 104, train_loss = 4.879675948061049, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 105, train_loss = 4.821106701157987, train_acc = 0.9919655333022822\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 106, train_loss = 4.7635567942634225, train_acc = 0.9919655333022822\n",
      "test Acc 0.9827746741154563:\n",
      "7th- epoch: 107, train_loss = 4.706865723244846, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "7th- epoch: 108, train_loss = 4.651073620654643, train_acc = 0.9923148579413135\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 109, train_loss = 4.596327943727374, train_acc = 0.9923148579413135\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 110, train_loss = 4.5423290329054, train_acc = 0.9923148579413135\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 111, train_loss = 4.489354538731277, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 112, train_loss = 4.437180906534195, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 113, train_loss = 4.385897816158831, train_acc = 0.9925477410340009\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 114, train_loss = 4.33563151396811, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 115, train_loss = 4.286102411337197, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 116, train_loss = 4.23724144231528, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 117, train_loss = 4.189424413256347, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 118, train_loss = 4.142340975813568, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 119, train_loss = 4.096018430776894, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 120, train_loss = 4.0505971778184175, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 121, train_loss = 4.005792058072984, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 122, train_loss = 3.9619335792958736, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 123, train_loss = 3.9187073446810246, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 124, train_loss = 3.876217127777636, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 125, train_loss = 3.834281673654914, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 126, train_loss = 3.7932888185605407, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 127, train_loss = 3.7527546230703592, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 128, train_loss = 3.7131429007276893, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 129, train_loss = 3.673993708565831, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 130, train_loss = 3.635649469681084, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 131, train_loss = 3.5977981025353074, train_acc = 0.9932463903120633\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 132, train_loss = 3.5608033519238234, train_acc = 0.9937121564974383\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 133, train_loss = 3.524203131906688, train_acc = 0.9937121564974383\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 134, train_loss = 3.4884920148178935, train_acc = 0.9937121564974383\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 135, train_loss = 3.453108372166753, train_acc = 0.993828598043782\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 136, train_loss = 3.4184772637672722, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 137, train_loss = 3.3842586339451373, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 138, train_loss = 3.350757166277617, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 139, train_loss = 3.3179435948841274, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 140, train_loss = 3.28534759581089, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 141, train_loss = 3.2534912298433483, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 142, train_loss = 3.2222399786114693, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 143, train_loss = 3.1912766373716295, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 144, train_loss = 3.1610828302800655, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 145, train_loss = 3.1312635499052703, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 146, train_loss = 3.1019414253532887, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 147, train_loss = 3.0730001614429057, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 148, train_loss = 3.0448169745504856, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 149, train_loss = 3.016708992421627, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 150, train_loss = 2.989323318004608, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 151, train_loss = 2.9622707590460777, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 152, train_loss = 2.9356773528270423, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 153, train_loss = 2.9095118907280266, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 154, train_loss = 2.8838881538249552, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 155, train_loss = 2.8585505932569504, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 156, train_loss = 2.8337823334150016, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 157, train_loss = 2.8092479039914906, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 158, train_loss = 2.7851521619595587, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 159, train_loss = 2.7615186939947307, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 160, train_loss = 2.738107679411769, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 161, train_loss = 2.715209808666259, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 162, train_loss = 2.692645974457264, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 163, train_loss = 2.670343850273639, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 164, train_loss = 2.6484536812640727, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 165, train_loss = 2.6268802625127137, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 166, train_loss = 2.60575924674049, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 167, train_loss = 2.5849590045399964, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 168, train_loss = 2.5643252287991345, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 169, train_loss = 2.544311673846096, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 170, train_loss = 2.5241619744338095, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 171, train_loss = 2.5046819145791233, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 172, train_loss = 2.485386798158288, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 173, train_loss = 2.466466138139367, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 174, train_loss = 2.447743218857795, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 175, train_loss = 2.429385165218264, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 176, train_loss = 2.4112841188907623, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 177, train_loss = 2.393485134933144, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 178, train_loss = 2.376027902122587, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 179, train_loss = 2.3589405552484095, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 180, train_loss = 2.3418625108897686, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 181, train_loss = 2.3251477726735175, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 182, train_loss = 2.308856800198555, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 183, train_loss = 2.2927048318088055, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 184, train_loss = 2.2768012336455286, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 185, train_loss = 2.2611843422055244, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 186, train_loss = 2.2457313637714833, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 187, train_loss = 2.230642316164449, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 188, train_loss = 2.21560974791646, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 189, train_loss = 2.201012476114556, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 190, train_loss = 2.1865328948479146, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 191, train_loss = 2.172340888530016, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 192, train_loss = 2.158361737849191, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 193, train_loss = 2.1445883873384446, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 194, train_loss = 2.1308493812102824, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 195, train_loss = 2.117597034899518, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 196, train_loss = 2.1046289142686874, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 197, train_loss = 2.091550040990114, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 198, train_loss = 2.0788344393949956, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 199, train_loss = 2.0663125663995743, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 200, train_loss = 2.0539182040374726, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 201, train_loss = 2.0418214339297265, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 202, train_loss = 2.0296994149684906, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 203, train_loss = 2.0179937556385994, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 204, train_loss = 2.0063098780810833, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 205, train_loss = 1.9948999732732773, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 206, train_loss = 1.9836296092253178, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 207, train_loss = 1.9724170789122581, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 208, train_loss = 1.9615355331916362, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 209, train_loss = 1.9507498815655708, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 210, train_loss = 1.9400859873276204, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 211, train_loss = 1.9297203198075294, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 212, train_loss = 1.9192379713058472, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 213, train_loss = 1.9091681241989136, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 214, train_loss = 1.8991400997620076, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 215, train_loss = 1.8892452109139413, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 216, train_loss = 1.8795228737872094, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 217, train_loss = 1.8698834776878357, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 218, train_loss = 1.8604231763165444, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 219, train_loss = 1.8510314635932446, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 220, train_loss = 1.8418379921931773, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 221, train_loss = 1.832675263285637, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 222, train_loss = 1.8237751349806786, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 223, train_loss = 1.814836610108614, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 224, train_loss = 1.806110029341653, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 225, train_loss = 1.7973339285235852, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 226, train_loss = 1.7889084592461586, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 227, train_loss = 1.7805162344593555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 228, train_loss = 1.7720830328762531, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 229, train_loss = 1.7640490632038563, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 230, train_loss = 1.7558635871391743, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 231, train_loss = 1.7479459133464843, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 232, train_loss = 1.7400279890280217, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 233, train_loss = 1.7322459544520825, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 234, train_loss = 1.724524871679023, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 235, train_loss = 1.7169457662384957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 236, train_loss = 1.7094673190731555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 237, train_loss = 1.7021144616883248, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 238, train_loss = 1.6947792060673237, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 239, train_loss = 1.6875252041500062, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 240, train_loss = 1.6803647701162845, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 241, train_loss = 1.673410375835374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 242, train_loss = 1.6663305300753564, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 243, train_loss = 1.6595346964895725, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 244, train_loss = 1.6527473019668832, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 245, train_loss = 1.6460014121839777, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 246, train_loss = 1.6394160216441378, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 247, train_loss = 1.6327817911515012, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 248, train_loss = 1.6263512944569811, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 249, train_loss = 1.61987030133605, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 250, train_loss = 1.6135213089874014, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 251, train_loss = 1.6072938367724419, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 252, train_loss = 1.6010661075124517, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 253, train_loss = 1.594914255081676, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 254, train_loss = 1.5888584926724434, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 255, train_loss = 1.5828741838922724, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 256, train_loss = 1.576965825050138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 257, train_loss = 1.5711276717483997, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 258, train_loss = 1.56527077651117, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 259, train_loss = 1.5596105518052354, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 260, train_loss = 1.554001378477551, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 261, train_loss = 1.5483141368022189, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 262, train_loss = 1.5427992126205936, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 263, train_loss = 1.5373166985809803, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 264, train_loss = 1.5319169188151136, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 265, train_loss = 1.5265376096358523, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 266, train_loss = 1.5212163925170898, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 267, train_loss = 1.515961061581038, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 268, train_loss = 1.5107713304460049, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 269, train_loss = 1.505731231183745, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 270, train_loss = 1.5004898365586996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 271, train_loss = 1.4953477469971403, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 272, train_loss = 1.4904164019972086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 273, train_loss = 1.4854589998722076, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 274, train_loss = 1.480541024939157, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 275, train_loss = 1.4757704442599788, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 276, train_loss = 1.4708437646040693, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 277, train_loss = 1.4661019904306158, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 278, train_loss = 1.4613848669687286, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 279, train_loss = 1.4568054439732805, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 280, train_loss = 1.4521253785351291, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 281, train_loss = 1.4474570719758049, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 282, train_loss = 1.4428634227951989, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 283, train_loss = 1.4385462831705809, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 284, train_loss = 1.4340602811425924, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 285, train_loss = 1.4295757418731228, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 286, train_loss = 1.4252307818969712, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 287, train_loss = 1.4209421208361164, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 288, train_loss = 1.4167096527526155, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 289, train_loss = 1.4123700266936794, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 290, train_loss = 1.408344216644764, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 291, train_loss = 1.4040721716592088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 292, train_loss = 1.3999107299605384, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 293, train_loss = 1.3958812411874533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 294, train_loss = 1.3919660268584266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 295, train_loss = 1.3878323206445202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 296, train_loss = 1.3839434403926134, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 297, train_loss = 1.3800461534410715, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 298, train_loss = 1.3760926177492365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 299, train_loss = 1.3722364673158154, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 300, train_loss = 1.3684636689722538, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 301, train_loss = 1.3646278275409713, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 302, train_loss = 1.360724519356154, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 303, train_loss = 1.3571762008359656, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 304, train_loss = 1.3534134806832299, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 305, train_loss = 1.3497350793331861, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 306, train_loss = 1.3462075609713793, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 307, train_loss = 1.342549296678044, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 308, train_loss = 1.3389955615857616, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 309, train_loss = 1.3355205915868282, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 310, train_loss = 1.3319663120200858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 311, train_loss = 1.3284989880630746, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 312, train_loss = 1.3250414859503508, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 313, train_loss = 1.3215940644731745, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 314, train_loss = 1.3183099137386307, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 315, train_loss = 1.3149384626885876, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 316, train_loss = 1.311580203473568, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 317, train_loss = 1.3082477723946795, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 318, train_loss = 1.3049810249358416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 319, train_loss = 1.3017858105013147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 320, train_loss = 1.2984687511925586, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 321, train_loss = 1.295326367020607, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 322, train_loss = 1.2922112606465816, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 323, train_loss = 1.2890580967068672, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 324, train_loss = 1.2860221502487548, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 325, train_loss = 1.2828952024574392, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 326, train_loss = 1.2798157061333768, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 327, train_loss = 1.2766993927652948, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 328, train_loss = 1.2737814001739025, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 329, train_loss = 1.2708147552912124, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 330, train_loss = 1.267849559604656, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 331, train_loss = 1.2648468799889088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 332, train_loss = 1.261966819583904, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 333, train_loss = 1.2591267675161362, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 334, train_loss = 1.256175038695801, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 335, train_loss = 1.2533783267135732, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 336, train_loss = 1.250585601956118, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 337, train_loss = 1.2477877463097684, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 338, train_loss = 1.244989583909046, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 339, train_loss = 1.2421863712370396, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 340, train_loss = 1.2394977224175818, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 341, train_loss = 1.236798271536827, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 342, train_loss = 1.2340193179552443, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 343, train_loss = 1.2313942449982278, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 344, train_loss = 1.2288039959967136, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 345, train_loss = 1.2261141265626065, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 346, train_loss = 1.2234533540904522, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 347, train_loss = 1.2209541636402719, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 348, train_loss = 1.218343372165691, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 349, train_loss = 1.215822160243988, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 350, train_loss = 1.213329128921032, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 351, train_loss = 1.2107338843052275, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 352, train_loss = 1.208315419673454, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 353, train_loss = 1.2057975840871222, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 354, train_loss = 1.2034340326790698, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 355, train_loss = 1.200911847234238, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 356, train_loss = 1.1984489299356937, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 357, train_loss = 1.1961264933343045, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 358, train_loss = 1.1936970092356205, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 359, train_loss = 1.1913604835863225, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 360, train_loss = 1.189024964987766, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 361, train_loss = 1.1865910763735883, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 362, train_loss = 1.1843398560886271, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 363, train_loss = 1.182109306275379, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 364, train_loss = 1.1797838037018664, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 365, train_loss = 1.1774331766064279, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 366, train_loss = 1.1753050908446312, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 367, train_loss = 1.1731040080194362, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 368, train_loss = 1.1707966935937293, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 369, train_loss = 1.1686374197597615, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 370, train_loss = 1.1663544264738448, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 371, train_loss = 1.1642534099519253, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 372, train_loss = 1.1621623101527803, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 373, train_loss = 1.159959938377142, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 374, train_loss = 1.1577727695112117, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 375, train_loss = 1.1557829938828945, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 376, train_loss = 1.1536347195506096, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 377, train_loss = 1.151508687704336, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 378, train_loss = 1.1494852031464688, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 379, train_loss = 1.1473709878628142, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 380, train_loss = 1.1453978903591633, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 381, train_loss = 1.1431502774357796, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 382, train_loss = 1.1412486645276658, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 383, train_loss = 1.1392438734765165, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 384, train_loss = 1.137203123420477, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 385, train_loss = 1.1351956973667257, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 386, train_loss = 1.1332613813574426, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 387, train_loss = 1.1312688651378267, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 388, train_loss = 1.129350143193733, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 389, train_loss = 1.1274206563830376, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 390, train_loss = 1.1255574499373324, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 391, train_loss = 1.1236066060955636, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 392, train_loss = 1.1217799087171443, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 393, train_loss = 1.119847456633579, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 394, train_loss = 1.1180395881528966, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 395, train_loss = 1.1161822527647018, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 396, train_loss = 1.1143881678581238, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 397, train_loss = 1.112546131014824, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 398, train_loss = 1.1106782245333306, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 399, train_loss = 1.1088610452716239, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 400, train_loss = 1.107207344204653, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 401, train_loss = 1.1053853283519857, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 402, train_loss = 1.1035540401935577, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 403, train_loss = 1.1017941522295587, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 404, train_loss = 1.1001611153478734, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 405, train_loss = 1.0982999044354074, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 406, train_loss = 1.096682708710432, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 407, train_loss = 1.094874796748627, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 408, train_loss = 1.0933047098224051, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 409, train_loss = 1.0915502458810806, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 410, train_loss = 1.0898733350331895, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 411, train_loss = 1.0882618874311447, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 412, train_loss = 1.0866005557472818, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 413, train_loss = 1.084822740405798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 414, train_loss = 1.0833260516519658, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 415, train_loss = 1.0815866949851625, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 416, train_loss = 1.0800883074407466, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 417, train_loss = 1.0784105844795704, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 418, train_loss = 1.076851858466398, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 419, train_loss = 1.0751844656770118, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 420, train_loss = 1.0737420693039894, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 421, train_loss = 1.0721155504579656, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 422, train_loss = 1.0705177895724773, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 423, train_loss = 1.069041296839714, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 424, train_loss = 1.0674591933493502, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 425, train_loss = 1.065973115444649, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 426, train_loss = 1.0644354062969796, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 427, train_loss = 1.062838602811098, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 428, train_loss = 1.061432698101271, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 429, train_loss = 1.0598453134298325, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 430, train_loss = 1.058417887717951, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 431, train_loss = 1.0569461857085116, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 432, train_loss = 1.0554253210430034, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 433, train_loss = 1.0540498246846255, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 434, train_loss = 1.0525538648071233, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 435, train_loss = 1.0510293220577296, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 436, train_loss = 1.0497073928418104, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 437, train_loss = 1.0482900825736579, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 438, train_loss = 1.0467876618204173, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 439, train_loss = 1.0454363847675268, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 440, train_loss = 1.0439911310968455, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 441, train_loss = 1.0425743609666824, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 442, train_loss = 1.0412745028734207, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 443, train_loss = 1.039849696069723, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 444, train_loss = 1.0383922196924686, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 445, train_loss = 1.0371939515171107, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 446, train_loss = 1.0357286632061005, train_acc = 0.9981369352585002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 447, train_loss = 1.034343813866144, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 448, train_loss = 1.033119149506092, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 449, train_loss = 1.0317224773170892, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 450, train_loss = 1.0303657849726733, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 451, train_loss = 1.0290876204671804, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 452, train_loss = 1.027749229222536, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 453, train_loss = 1.0264009038510267, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 454, train_loss = 1.0251712625322398, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 455, train_loss = 1.0238503267464694, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 456, train_loss = 1.0225947660801467, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 457, train_loss = 1.0213058106601238, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 458, train_loss = 1.0199541337788105, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 459, train_loss = 1.0187392433581408, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 460, train_loss = 1.017543030291563, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 461, train_loss = 1.0161939201352652, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 462, train_loss = 1.0150222194788512, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 463, train_loss = 1.013746865093708, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 464, train_loss = 1.0124884819088038, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 465, train_loss = 1.011322000384098, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 466, train_loss = 1.0101087751390878, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 467, train_loss = 1.0087710867228452, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 468, train_loss = 1.0076547203061637, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 469, train_loss = 1.0064467104675714, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 470, train_loss = 1.0052116190490779, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 471, train_loss = 1.0040691010653973, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 472, train_loss = 1.002876723796362, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 473, train_loss = 1.0016276625392493, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 474, train_loss = 1.0005565024912357, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 475, train_loss = 0.9993371243181173, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 476, train_loss = 0.9982046770455781, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 477, train_loss = 0.9970775532128755, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 478, train_loss = 0.9959231702086981, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 479, train_loss = 0.9947280710039195, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 480, train_loss = 0.9936457773146685, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 481, train_loss = 0.9925388346018735, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 482, train_loss = 0.9913348518311977, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 483, train_loss = 0.9903203236463014, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 484, train_loss = 0.9891634161176626, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 485, train_loss = 0.9880470583739225, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 486, train_loss = 0.9869922436773777, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 487, train_loss = 0.9858686079678591, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 488, train_loss = 0.9847447872161865, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 489, train_loss = 0.9837247307004873, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 490, train_loss = 0.9826265374722425, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 491, train_loss = 0.9814812814292964, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 492, train_loss = 0.980550372361904, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 493, train_loss = 0.9793775739672128, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 494, train_loss = 0.9784199210407678, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 495, train_loss = 0.9772913791239262, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 496, train_loss = 0.9762687819602434, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 497, train_loss = 0.9752596715989057, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 498, train_loss = 0.9741465014813002, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "7th- epoch: 499, train_loss = 0.9731558300554752, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████████████                                                        | 7/30 [47:30<2:36:16, 407.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "8th- epoch: 0, train_loss = 269.2855461835861, train_acc = 0.42198416394969723\n",
      "test Acc 0.4748603351955307:\n",
      "8th- epoch: 1, train_loss = 206.22997188568115, train_acc = 0.5012808570097811\n",
      "test Acc 0.5670391061452514:\n",
      "8th- epoch: 2, train_loss = 162.7536136507988, train_acc = 0.5787144853283651\n",
      "test Acc 0.62756052141527:\n",
      "8th- epoch: 3, train_loss = 134.86115181446075, train_acc = 0.6764089427107592\n",
      "test Acc 0.7406890130353817:\n",
      "8th- epoch: 4, train_loss = 115.31726735830307, train_acc = 0.7564042850489054\n",
      "test Acc 0.7774674115456238:\n",
      "8th- epoch: 5, train_loss = 100.45084539055824, train_acc = 0.7761993479273405\n",
      "test Acc 0.7993482309124768:\n",
      "8th- epoch: 6, train_loss = 88.53947919607162, train_acc = 0.8010013972985561\n",
      "test Acc 0.8221601489757915:\n",
      "8th- epoch: 7, train_loss = 78.80981633067131, train_acc = 0.817768979972054\n",
      "test Acc 0.8389199255121043:\n",
      "8th- epoch: 8, train_loss = 70.60586416721344, train_acc = 0.8418723800652073\n",
      "test Acc 0.8575418994413407:\n",
      "8th- epoch: 9, train_loss = 63.484692722558975, train_acc = 0.8666744294364229\n",
      "test Acc 0.8817504655493482:\n",
      "8th- epoch: 10, train_loss = 57.25159028172493, train_acc = 0.8850721937587331\n",
      "test Acc 0.9003724394785847:\n",
      "8th- epoch: 11, train_loss = 51.78788374364376, train_acc = 0.9063809967396367\n",
      "test Acc 0.914804469273743:\n",
      "8th- epoch: 12, train_loss = 46.99802367389202, train_acc = 0.9273404750815091\n",
      "test Acc 0.9343575418994413:\n",
      "8th- epoch: 13, train_loss = 42.810170605778694, train_acc = 0.9392175128085701\n",
      "test Acc 0.9385474860335196:\n",
      "8th- epoch: 14, train_loss = 39.16354711353779, train_acc = 0.945388914764788\n",
      "test Acc 0.9418063314711359:\n",
      "8th- epoch: 15, train_loss = 36.001947432756424, train_acc = 0.9492314857941313\n",
      "test Acc 0.9445996275605214:\n",
      "8th- epoch: 16, train_loss = 33.2683295160532, train_acc = 0.9510945505356311\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 17, train_loss = 30.908527739346027, train_acc = 0.9531904983698184\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 18, train_loss = 28.871839195489883, train_acc = 0.9548206800186306\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 19, train_loss = 27.10801637172699, train_acc = 0.9570330693991617\n",
      "test Acc 0.952513966480447:\n",
      "8th- epoch: 20, train_loss = 25.575110837817192, train_acc = 0.959944108057755\n",
      "test Acc 0.9553072625698324:\n",
      "8th- epoch: 21, train_loss = 24.2363806553185, train_acc = 0.9641360037261295\n",
      "test Acc 0.9594972067039106:\n",
      "8th- epoch: 22, train_loss = 23.058474615216255, train_acc = 0.9673963670237541\n",
      "test Acc 0.9604283054003724:\n",
      "8th- epoch: 23, train_loss = 22.014062240719795, train_acc = 0.9686772240335352\n",
      "test Acc 0.9599627560521415:\n",
      "8th- epoch: 24, train_loss = 21.081160500645638, train_acc = 0.9693758733115976\n",
      "test Acc 0.9604283054003724:\n",
      "8th- epoch: 25, train_loss = 20.241758927702904, train_acc = 0.9698416394969726\n",
      "test Acc 0.9613594040968343:\n",
      "8th- epoch: 26, train_loss = 19.481176000088453, train_acc = 0.970540288775035\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 27, train_loss = 18.78831898421049, train_acc = 0.9713553795994411\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 28, train_loss = 18.153451338410378, train_acc = 0.9715882626921285\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 29, train_loss = 17.567975528538227, train_acc = 0.971821145784816\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 30, train_loss = 17.025404881685972, train_acc = 0.9721704704238472\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 31, train_loss = 16.519621789455414, train_acc = 0.9733348858872846\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 32, train_loss = 16.046836726367474, train_acc = 0.9739170936190032\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 33, train_loss = 15.603732518851757, train_acc = 0.9748486259897532\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 34, train_loss = 15.186709478497505, train_acc = 0.975314392175128\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 35, train_loss = 14.792939931154251, train_acc = 0.9754308337214718\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 36, train_loss = 14.420260705053806, train_acc = 0.9755472752678156\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 37, train_loss = 14.067038133740425, train_acc = 0.975780158360503\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 38, train_loss = 13.731473408639431, train_acc = 0.9761294829995343\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 39, train_loss = 13.412282388657331, train_acc = 0.9763623660922217\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 40, train_loss = 13.108319103717804, train_acc = 0.9765952491849091\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 41, train_loss = 12.818279135972261, train_acc = 0.9768281322775967\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 42, train_loss = 12.541129056364298, train_acc = 0.9774103400093154\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 43, train_loss = 12.275976531207561, train_acc = 0.9778761061946902\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 44, train_loss = 12.021882850676775, train_acc = 0.9785747554727526\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 45, train_loss = 11.778118260204792, train_acc = 0.9788076385654402\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 46, train_loss = 11.543819591403008, train_acc = 0.9790405216581276\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 47, train_loss = 11.31827786564827, train_acc = 0.9791569632044713\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 48, train_loss = 11.100769400596619, train_acc = 0.9795062878435026\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 49, train_loss = 10.891038827598095, train_acc = 0.9798556124825337\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 50, train_loss = 10.688505973666906, train_acc = 0.980204937121565\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 51, train_loss = 10.492661818861961, train_acc = 0.9803213786679087\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 52, train_loss = 10.303066831082106, train_acc = 0.9805542617605962\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 53, train_loss = 10.119309302419424, train_acc = 0.98067070330694\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 54, train_loss = 9.941036142408848, train_acc = 0.9810200279459711\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 55, train_loss = 9.767864882946014, train_acc = 0.9817186772240335\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 56, train_loss = 9.59988365881145, train_acc = 0.9820680018630648\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 57, train_loss = 9.436386371031404, train_acc = 0.9823008849557522\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 58, train_loss = 9.277395024895668, train_acc = 0.9824173265020959\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 59, train_loss = 9.122564746066928, train_acc = 0.9823008849557522\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 60, train_loss = 8.971689717844129, train_acc = 0.9825337680484397\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 61, train_loss = 8.824726378545165, train_acc = 0.9827666511411272\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 62, train_loss = 8.681623488664627, train_acc = 0.9832324173265021\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 63, train_loss = 8.541966928169131, train_acc = 0.9838146250582208\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 64, train_loss = 8.405985718593001, train_acc = 0.9839310666045645\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 65, train_loss = 8.27345010638237, train_acc = 0.9842803912435957\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 66, train_loss = 8.144136322662234, train_acc = 0.9843968327899395\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 67, train_loss = 8.017702547833323, train_acc = 0.9843968327899395\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 68, train_loss = 7.894161494448781, train_acc = 0.9848625989753144\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 69, train_loss = 7.7735321670770645, train_acc = 0.9849790405216581\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 70, train_loss = 7.655701316893101, train_acc = 0.9853283651606893\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 71, train_loss = 7.540479753166437, train_acc = 0.985444806707033\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 72, train_loss = 7.427746703848243, train_acc = 0.985444806707033\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 73, train_loss = 7.317478628829122, train_acc = 0.9855612482533768\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 74, train_loss = 7.209627954289317, train_acc = 0.9856776897997206\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 75, train_loss = 7.104264101013541, train_acc = 0.9857941313460643\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 76, train_loss = 7.001190038397908, train_acc = 0.9861434559850955\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 77, train_loss = 6.9003753792494535, train_acc = 0.9861434559850955\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 78, train_loss = 6.801603700965643, train_acc = 0.9862598975314392\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 79, train_loss = 6.7051686104387045, train_acc = 0.9868421052631579\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 80, train_loss = 6.61075434461236, train_acc = 0.9870749883558454\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 81, train_loss = 6.518208246678114, train_acc = 0.9876571960875641\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 82, train_loss = 6.427611967548728, train_acc = 0.9881229622729389\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 83, train_loss = 6.338733112439513, train_acc = 0.9884722869119702\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 84, train_loss = 6.251640908420086, train_acc = 0.9884722869119702\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 85, train_loss = 6.166217925027013, train_acc = 0.9887051700046576\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 86, train_loss = 6.082626758143306, train_acc = 0.9888216115510013\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 87, train_loss = 6.000574178993702, train_acc = 0.9891709361900326\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 88, train_loss = 5.920177498832345, train_acc = 0.9892873777363763\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 89, train_loss = 5.841142240911722, train_acc = 0.98940381928272\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 90, train_loss = 5.763630459085107, train_acc = 0.9896367023754076\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 91, train_loss = 5.687552196905017, train_acc = 0.9899860270144387\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 92, train_loss = 5.61291379481554, train_acc = 0.99033535165347\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 93, train_loss = 5.539514282718301, train_acc = 0.9906846762925011\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 94, train_loss = 5.4673981331288815, train_acc = 0.9909175593851887\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 95, train_loss = 5.396769506856799, train_acc = 0.9910340009315324\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 96, train_loss = 5.3272821474820375, train_acc = 0.9911504424778761\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 97, train_loss = 5.25909620616585, train_acc = 0.9912668840242198\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 98, train_loss = 5.19234982971102, train_acc = 0.9911504424778761\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 99, train_loss = 5.126667397096753, train_acc = 0.9911504424778761\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 100, train_loss = 5.062197802588344, train_acc = 0.9912668840242198\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 101, train_loss = 4.998950965702534, train_acc = 0.9914997671169073\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 102, train_loss = 4.936763062141836, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 103, train_loss = 4.875821978785098, train_acc = 0.9916162086632511\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 104, train_loss = 4.81589662656188, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 105, train_loss = 4.757066790945828, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 106, train_loss = 4.699482555501163, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 107, train_loss = 4.642871045507491, train_acc = 0.992081974848626\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 108, train_loss = 4.587347469292581, train_acc = 0.992081974848626\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 109, train_loss = 4.532878532074392, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 110, train_loss = 4.479434336535633, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 111, train_loss = 4.4269513776525855, train_acc = 0.9919655333022822\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 112, train_loss = 4.375428865663707, train_acc = 0.992081974848626\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 113, train_loss = 4.324906934984028, train_acc = 0.9921984163949698\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 114, train_loss = 4.275310067459941, train_acc = 0.9924312994876572\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 115, train_loss = 4.226532545872033, train_acc = 0.9926641825803446\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 116, train_loss = 4.178765086457133, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 117, train_loss = 4.131898588500917, train_acc = 0.9930135072193759\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 118, train_loss = 4.085689252242446, train_acc = 0.9931299487657196\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 119, train_loss = 4.0404451889917254, train_acc = 0.9932463903120633\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 120, train_loss = 3.9960130928084254, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 121, train_loss = 3.952447078190744, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 122, train_loss = 3.9095298843458295, train_acc = 0.9935957149510946\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 123, train_loss = 3.867447718977928, train_acc = 0.9935957149510946\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 124, train_loss = 3.82617565151304, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 125, train_loss = 3.7855629147961736, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 126, train_loss = 3.7457865830510855, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 127, train_loss = 3.7067641401663423, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 128, train_loss = 3.668416299857199, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 129, train_loss = 3.6307541402056813, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 130, train_loss = 3.5936068342998624, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 131, train_loss = 3.5572920460253954, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 132, train_loss = 3.521513150073588, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 133, train_loss = 3.48638750705868, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 134, train_loss = 3.4519534343853593, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 135, train_loss = 3.417979720979929, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 136, train_loss = 3.384699105285108, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 137, train_loss = 3.352021916769445, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 138, train_loss = 3.3199239019304514, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 139, train_loss = 3.2882955418899655, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 140, train_loss = 3.2573137381114066, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 141, train_loss = 3.2267179149203002, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 142, train_loss = 3.196782285813242, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 143, train_loss = 3.1673605032265186, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 144, train_loss = 3.1384076825343072, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 145, train_loss = 3.1099456059746444, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 146, train_loss = 3.0819558184593916, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 147, train_loss = 3.054363898932934, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 148, train_loss = 3.0271462299861014, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 149, train_loss = 3.0004876065067947, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 150, train_loss = 2.974191143643111, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 151, train_loss = 2.9482459891587496, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 152, train_loss = 2.9228062871843576, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 153, train_loss = 2.897846383973956, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 154, train_loss = 2.873201247304678, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 155, train_loss = 2.848895564675331, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 156, train_loss = 2.825063564348966, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 157, train_loss = 2.8015299905091524, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 158, train_loss = 2.77846055990085, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 159, train_loss = 2.7555911913514137, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 160, train_loss = 2.7331128288060427, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 161, train_loss = 2.710847517941147, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 162, train_loss = 2.6889935159124434, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 163, train_loss = 2.6674414104782045, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 164, train_loss = 2.6461653648875654, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 165, train_loss = 2.625274823512882, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 166, train_loss = 2.6045863232575357, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 167, train_loss = 2.5843223719857633, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 168, train_loss = 2.5643093711696565, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 169, train_loss = 2.544654631521553, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 170, train_loss = 2.525141905993223, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 171, train_loss = 2.506128823850304, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 172, train_loss = 2.4872169606387615, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 173, train_loss = 2.4686797983013093, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 174, train_loss = 2.4503786861896515, train_acc = 0.9962738705170004\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 175, train_loss = 2.4323634481988847, train_acc = 0.9962738705170004\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 176, train_loss = 2.4146880358457565, train_acc = 0.9962738705170004\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 177, train_loss = 2.3971652663312852, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 178, train_loss = 2.3799156113527715, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 179, train_loss = 2.3629424148239195, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 180, train_loss = 2.3460908755660057, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 181, train_loss = 2.3296035900712013, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 182, train_loss = 2.3133845403790474, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 183, train_loss = 2.2973064281977713, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 184, train_loss = 2.2815424925647676, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 185, train_loss = 2.2660275287926197, train_acc = 0.9967396367023754\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 186, train_loss = 2.250690469983965, train_acc = 0.9967396367023754\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 187, train_loss = 2.2356016002595425, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 188, train_loss = 2.2207208960317075, train_acc = 0.9967396367023754\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 189, train_loss = 2.2061082422733307, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 190, train_loss = 2.191640119999647, train_acc = 0.9967396367023754\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 191, train_loss = 2.1774726435542107, train_acc = 0.9967396367023754\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 192, train_loss = 2.1633798889815807, train_acc = 0.9967396367023754\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 193, train_loss = 2.1495917674619704, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 194, train_loss = 2.1359405156690627, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 195, train_loss = 2.122523798374459, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 196, train_loss = 2.109368149191141, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 197, train_loss = 2.096269973786548, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 198, train_loss = 2.0834356595296413, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 199, train_loss = 2.0707369807641953, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 200, train_loss = 2.058199546067044, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 201, train_loss = 2.0459062419831753, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 202, train_loss = 2.0337123337667435, train_acc = 0.9969725197950629\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 203, train_loss = 2.0217309780418873, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 204, train_loss = 2.0098503939807415, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 205, train_loss = 1.9981613222043961, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 206, train_loss = 1.986690228106454, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 207, train_loss = 1.9753062576055527, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 208, train_loss = 1.9640626769978553, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 209, train_loss = 1.9530431814491749, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 210, train_loss = 1.9420864395797253, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 211, train_loss = 1.9312823067884892, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 212, train_loss = 1.920638958690688, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 213, train_loss = 1.9100759488064796, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 214, train_loss = 1.899662833660841, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 215, train_loss = 1.8894088107626885, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 216, train_loss = 1.8793079368770123, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 217, train_loss = 1.8693287670612335, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 218, train_loss = 1.8594827067572623, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 219, train_loss = 1.8498294975142926, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 220, train_loss = 1.840174663811922, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 221, train_loss = 1.830802109092474, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 222, train_loss = 1.8213907715398818, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 223, train_loss = 1.8121770545840263, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 224, train_loss = 1.802919190376997, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 225, train_loss = 1.7938858170527965, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 226, train_loss = 1.7849245939869434, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 227, train_loss = 1.776035914896056, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 228, train_loss = 1.7673628542106599, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 229, train_loss = 1.7586134176235646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 230, train_loss = 1.7502658378798515, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 231, train_loss = 1.741771787405014, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 232, train_loss = 1.7335999372880906, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 233, train_loss = 1.7253723505418748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 234, train_loss = 1.7173353496473283, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 235, train_loss = 1.709361606510356, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 236, train_loss = 1.701546624302864, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 237, train_loss = 1.6937786873895675, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 238, train_loss = 1.686139726312831, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 239, train_loss = 1.678646309999749, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 240, train_loss = 1.671150829643011, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 241, train_loss = 1.6638115581590682, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 242, train_loss = 1.6566415715496987, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 243, train_loss = 1.6494576148688793, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 244, train_loss = 1.6423744682688266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 245, train_loss = 1.6354039658326656, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 246, train_loss = 1.6285268429201096, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 247, train_loss = 1.621696637244895, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 248, train_loss = 1.6150424716761336, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 249, train_loss = 1.608383240760304, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 250, train_loss = 1.6018670374760404, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 251, train_loss = 1.5954410830745474, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 252, train_loss = 1.5890371451387182, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 253, train_loss = 1.5827590388944373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 254, train_loss = 1.57655730843544, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 255, train_loss = 1.57037351524923, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 256, train_loss = 1.5643312223255634, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 257, train_loss = 1.5583241818239912, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 258, train_loss = 1.5523628493538126, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 259, train_loss = 1.5465650744736195, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 260, train_loss = 1.5407206838717684, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 261, train_loss = 1.5350194027414545, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 262, train_loss = 1.5293349152198061, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 263, train_loss = 1.5237281756708398, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 264, train_loss = 1.5182848585536703, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 265, train_loss = 1.5127311249962077, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 266, train_loss = 1.507391789346002, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 267, train_loss = 1.5020139900734648, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 268, train_loss = 1.496774739236571, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 269, train_loss = 1.4915092686424032, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 270, train_loss = 1.4863553270697594, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 271, train_loss = 1.4813405275344849, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 272, train_loss = 1.4761673944303766, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 273, train_loss = 1.4712141441414133, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 274, train_loss = 1.4662653977284208, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 275, train_loss = 1.4614410573849455, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 276, train_loss = 1.4566146656870842, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 277, train_loss = 1.451783308177255, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 278, train_loss = 1.4470725556602702, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 279, train_loss = 1.4423474123468623, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 280, train_loss = 1.4377786243567243, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 281, train_loss = 1.4331501176347956, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 282, train_loss = 1.4286454567918554, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 283, train_loss = 1.4240580312907696, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 284, train_loss = 1.4197478344431147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 285, train_loss = 1.415271262289025, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 286, train_loss = 1.4109062751522288, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 287, train_loss = 1.4066500341286883, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 288, train_loss = 1.4023880660533905, train_acc = 0.9974382859804378\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 289, train_loss = 1.3981058473000303, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 290, train_loss = 1.393961351364851, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 291, train_loss = 1.3898218361428007, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 292, train_loss = 1.3857065103948116, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 293, train_loss = 1.381709799170494, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 294, train_loss = 1.3776446332922205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 295, train_loss = 1.3736663088202477, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 296, train_loss = 1.369704489945434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 297, train_loss = 1.3657805137336254, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 298, train_loss = 1.361910231411457, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 299, train_loss = 1.3581039482960477, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 300, train_loss = 1.3542944403598085, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 301, train_loss = 1.3505863348254934, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 302, train_loss = 1.3467899957904592, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 303, train_loss = 1.343119795084931, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 304, train_loss = 1.339414638816379, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 305, train_loss = 1.33584873622749, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 306, train_loss = 1.3322742705931887, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 307, train_loss = 1.3286159858107567, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 308, train_loss = 1.3250990957021713, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 309, train_loss = 1.3216039227554575, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 310, train_loss = 1.3181537328055128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 311, train_loss = 1.3146977511933073, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 312, train_loss = 1.3113033398985863, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 313, train_loss = 1.3079030079534277, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 314, train_loss = 1.3045554967829958, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 315, train_loss = 1.3012900265166536, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 316, train_loss = 1.2979556148638949, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 317, train_loss = 1.294716245145537, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 318, train_loss = 1.2914348915219307, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 319, train_loss = 1.2883209200808778, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 320, train_loss = 1.2851570571074262, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 321, train_loss = 1.2819398579886183, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 322, train_loss = 1.2788936384022236, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 323, train_loss = 1.2757504197652452, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 324, train_loss = 1.272681315720547, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 325, train_loss = 1.2696138533647172, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 326, train_loss = 1.2666881357436068, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 327, train_loss = 1.2636541413958184, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 328, train_loss = 1.2607064147596247, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 329, train_loss = 1.2577554285526276, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 330, train_loss = 1.2548613187973388, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 331, train_loss = 1.2519779838621616, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 332, train_loss = 1.2490562622551806, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 333, train_loss = 1.2462743583018892, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 334, train_loss = 1.2434371262788773, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 335, train_loss = 1.240671779960394, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 336, train_loss = 1.2378946132957935, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 337, train_loss = 1.2351304677431472, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 338, train_loss = 1.2324023246765137, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 339, train_loss = 1.229746365279425, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 340, train_loss = 1.2270008039777167, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 341, train_loss = 1.2243528601829894, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 342, train_loss = 1.2217479459941387, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 343, train_loss = 1.2190623544156551, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 344, train_loss = 1.2165267665986903, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 345, train_loss = 1.2138708718121052, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 346, train_loss = 1.2113452765042894, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 347, train_loss = 1.208812701224815, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 348, train_loss = 1.2062061242759228, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 349, train_loss = 1.2038205129210837, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 350, train_loss = 1.2012831668253057, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 351, train_loss = 1.1988128498196602, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 352, train_loss = 1.1963111807708628, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 353, train_loss = 1.193909392983187, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 354, train_loss = 1.1915219736401923, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 355, train_loss = 1.1891146749258041, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 356, train_loss = 1.1867388275568374, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 357, train_loss = 1.1843349051778205, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 358, train_loss = 1.1820318475365639, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 359, train_loss = 1.1797760377521627, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 360, train_loss = 1.1773505248129368, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 361, train_loss = 1.1751051234896295, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 362, train_loss = 1.172836157202255, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 363, train_loss = 1.170532772957813, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 364, train_loss = 1.1683114928309806, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 365, train_loss = 1.1661343525047414, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 366, train_loss = 1.1638719352777116, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 367, train_loss = 1.1617320254445076, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 368, train_loss = 1.1595980313722976, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 369, train_loss = 1.1573372197453864, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 370, train_loss = 1.15524174523307, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 371, train_loss = 1.1531607086653821, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 372, train_loss = 1.1509949453175068, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 373, train_loss = 1.1488481138949282, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 374, train_loss = 1.1468418203294277, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 375, train_loss = 1.1447187599842437, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 376, train_loss = 1.142667729407549, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 377, train_loss = 1.1406721360981464, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 378, train_loss = 1.1385982756619342, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 379, train_loss = 1.1366042171721347, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 380, train_loss = 1.1346466193790548, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 381, train_loss = 1.1325789068941958, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 382, train_loss = 1.130692030012142, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 383, train_loss = 1.128670610487461, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 384, train_loss = 1.1267463627154939, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 385, train_loss = 1.1248293208773248, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 386, train_loss = 1.1229343960876577, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 387, train_loss = 1.120962471992243, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 388, train_loss = 1.119077656418085, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 389, train_loss = 1.117249496281147, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 390, train_loss = 1.1153964474797249, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 391, train_loss = 1.1135057981009595, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 392, train_loss = 1.1116556164924987, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 393, train_loss = 1.1098735121195205, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 394, train_loss = 1.10801612585783, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 395, train_loss = 1.1061717619304545, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 396, train_loss = 1.1045030529494397, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 397, train_loss = 1.1026379242539406, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 398, train_loss = 1.1009191473131068, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 399, train_loss = 1.0990637031500228, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 400, train_loss = 1.0973528723116033, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 401, train_loss = 1.0956015673582442, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 402, train_loss = 1.093970509886276, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 403, train_loss = 1.0921977795660496, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 404, train_loss = 1.0904425705666654, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 405, train_loss = 1.088750773400534, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 406, train_loss = 1.0871654624934308, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 407, train_loss = 1.0854061755235307, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 408, train_loss = 1.0837895385921001, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 409, train_loss = 1.082131924747955, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 410, train_loss = 1.080496194481384, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 411, train_loss = 1.078940701961983, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 412, train_loss = 1.077234589785803, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 413, train_loss = 1.075651726394426, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "8th- epoch: 414, train_loss = 1.0740942085976712, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 415, train_loss = 1.0724902227520943, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 416, train_loss = 1.0708845257759094, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 417, train_loss = 1.0693179083173163, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 418, train_loss = 1.0677779167890549, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 419, train_loss = 1.0662498411838897, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 420, train_loss = 1.064668143808376, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 421, train_loss = 1.0631300683016889, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 422, train_loss = 1.0616228505969048, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 423, train_loss = 1.0601577323977835, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 424, train_loss = 1.058545024425257, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 425, train_loss = 1.057144609570969, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 426, train_loss = 1.0556503596599214, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 427, train_loss = 1.0540561552043073, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 428, train_loss = 1.0527185660903342, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 429, train_loss = 1.0512258596718311, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 430, train_loss = 1.0497871227562428, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 431, train_loss = 1.0482555938069709, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 432, train_loss = 1.0468850446050055, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 433, train_loss = 1.0454818954167422, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 434, train_loss = 1.0440706784429494, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 435, train_loss = 1.0425406098365784, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 436, train_loss = 1.0411959389748517, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 437, train_loss = 1.0397725453076418, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 438, train_loss = 1.0383650486764964, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 439, train_loss = 1.0369726096687373, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 440, train_loss = 1.0354815361497458, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 441, train_loss = 1.034254348516697, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 442, train_loss = 1.0328233440814074, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 443, train_loss = 1.0314275572600309, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 444, train_loss = 1.0302184050378855, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 445, train_loss = 1.0288217191991862, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 446, train_loss = 1.0274775487778243, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 447, train_loss = 1.0261449441313744, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 448, train_loss = 1.024888706713682, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 449, train_loss = 1.0235407364962157, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 450, train_loss = 1.0222641552390996, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 451, train_loss = 1.0210131419298705, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 452, train_loss = 1.0196660930814687, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 453, train_loss = 1.0184284523129463, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 454, train_loss = 1.0171514625253621, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 455, train_loss = 1.0158804804086685, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 456, train_loss = 1.0145909214916173, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 457, train_loss = 1.0134063512086868, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 458, train_loss = 1.0120586392877158, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 459, train_loss = 1.011003788560629, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 460, train_loss = 1.0096976148488466, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 461, train_loss = 1.008408216148382, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 462, train_loss = 1.0072751492261887, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 463, train_loss = 1.0059969623980578, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 464, train_loss = 1.0048511649074499, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 465, train_loss = 1.0036226423981134, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 466, train_loss = 1.0024409368634224, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 467, train_loss = 1.0013091762957629, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 468, train_loss = 1.000114201247925, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 469, train_loss = 0.9989575035870075, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 470, train_loss = 0.997758574783802, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 471, train_loss = 0.9965472556650639, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 472, train_loss = 0.9954590524139348, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 473, train_loss = 0.9943307104113046, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 474, train_loss = 0.9931761634943541, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 475, train_loss = 0.9920854208467063, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 476, train_loss = 0.9909537012281362, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 477, train_loss = 0.9896983938815538, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 478, train_loss = 0.9886128716170788, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 479, train_loss = 0.9875400538148824, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 480, train_loss = 0.9864844257535879, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 481, train_loss = 0.9853043916227762, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 482, train_loss = 0.984209688991541, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 483, train_loss = 0.983221348375082, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 484, train_loss = 0.9821027057769243, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 485, train_loss = 0.9809899069368839, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 486, train_loss = 0.9799360843899194, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 487, train_loss = 0.978777714073658, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 488, train_loss = 0.9778638258576393, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 489, train_loss = 0.976754117757082, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 490, train_loss = 0.9756935785117093, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 491, train_loss = 0.9746795284154359, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 492, train_loss = 0.9736274716851767, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 493, train_loss = 0.9725731884536799, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 494, train_loss = 0.9715298339724541, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 495, train_loss = 0.9704291944799479, train_acc = 0.9981369352585002\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 496, train_loss = 0.9695316615107004, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 497, train_loss = 0.9684599550964776, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 498, train_loss = 0.9674956897797529, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 499, train_loss = 0.9664875703456346, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|███████████████████▍                                                     | 8/30 [54:21<2:29:48, 408.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "9th- epoch: 0, train_loss = 269.1080302000046, train_acc = 0.4704238472286912\n",
      "test Acc 0.49906890130353815:\n",
      "9th- epoch: 1, train_loss = 202.33082032203674, train_acc = 0.5227061015370285\n",
      "test Acc 0.5670391061452514:\n",
      "9th- epoch: 2, train_loss = 158.37259179353714, train_acc = 0.5883791336748952\n",
      "test Acc 0.6391992551210428:\n",
      "9th- epoch: 3, train_loss = 131.91828954219818, train_acc = 0.6885188635305077\n",
      "test Acc 0.7351024208566108:\n",
      "9th- epoch: 4, train_loss = 113.03441798686981, train_acc = 0.7578015836050302\n",
      "test Acc 0.7811918063314711:\n",
      "9th- epoch: 5, train_loss = 98.56710237264633, train_acc = 0.7851653469958081\n",
      "test Acc 0.8086592178770949:\n",
      "9th- epoch: 6, train_loss = 86.96203747391701, train_acc = 0.8096180717279925\n",
      "test Acc 0.8268156424581006:\n",
      "9th- epoch: 7, train_loss = 77.43603083491325, train_acc = 0.8252212389380531\n",
      "test Acc 0.8365921787709497:\n",
      "9th- epoch: 8, train_loss = 69.36799257993698, train_acc = 0.8423381462505822\n",
      "test Acc 0.8584729981378026:\n",
      "9th- epoch: 9, train_loss = 62.37923802435398, train_acc = 0.8680717279925477\n",
      "test Acc 0.88268156424581:\n",
      "9th- epoch: 10, train_loss = 56.28043842315674, train_acc = 0.88996273870517\n",
      "test Acc 0.8994413407821229:\n",
      "9th- epoch: 11, train_loss = 50.95071451365948, train_acc = 0.912435957149511\n",
      "test Acc 0.9241154562383612:\n",
      "9th- epoch: 12, train_loss = 46.28911791741848, train_acc = 0.9321145784816023\n",
      "test Acc 0.9315642458100558:\n",
      "9th- epoch: 13, train_loss = 42.225841760635376, train_acc = 0.941895668374476\n",
      "test Acc 0.9357541899441341:\n",
      "9th- epoch: 14, train_loss = 38.69976618885994, train_acc = 0.9457382394038193\n",
      "test Acc 0.9399441340782123:\n",
      "9th- epoch: 15, train_loss = 35.653696812689304, train_acc = 0.9489986027014439\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 16, train_loss = 33.02894505858421, train_acc = 0.9507452258965999\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 17, train_loss = 30.76284582912922, train_acc = 0.9522589659990685\n",
      "test Acc 0.946927374301676:\n",
      "9th- epoch: 18, train_loss = 28.803372099995613, train_acc = 0.9557522123893806\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 19, train_loss = 27.101019352674484, train_acc = 0.9574988355845365\n",
      "test Acc 0.9506517690875232:\n",
      "9th- epoch: 20, train_loss = 25.613655261695385, train_acc = 0.9602934326967862\n",
      "test Acc 0.9543761638733705:\n",
      "9th- epoch: 21, train_loss = 24.305518843233585, train_acc = 0.9626222636236609\n",
      "test Acc 0.9543761638733705:\n",
      "9th- epoch: 22, train_loss = 23.14662940055132, train_acc = 0.9637866790870983\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 23, train_loss = 22.11376015841961, train_acc = 0.9654168607359106\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 24, train_loss = 21.1869159899652, train_acc = 0.9677456916627852\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 25, train_loss = 20.349141515791416, train_acc = 0.9692594317652539\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 26, train_loss = 19.58719937130809, train_acc = 0.97007452258966\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 27, train_loss = 18.89048033952713, train_acc = 0.970540288775035\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 28, train_loss = 18.250713370740414, train_acc = 0.9707731718677224\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 29, train_loss = 17.659985523670912, train_acc = 0.9713553795994411\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 30, train_loss = 17.112115401774645, train_acc = 0.9720540288775035\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 31, train_loss = 16.602564625442028, train_acc = 0.9728691197019096\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 32, train_loss = 16.126930110156536, train_acc = 0.9732184443409408\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 33, train_loss = 15.680804163217545, train_acc = 0.9736842105263158\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 34, train_loss = 15.26147624105215, train_acc = 0.9741499767116907\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 35, train_loss = 14.866533041000366, train_acc = 0.9746157428970657\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 36, train_loss = 14.492991350591183, train_acc = 0.9747321844434094\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 37, train_loss = 14.139162261039019, train_acc = 0.9748486259897532\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 38, train_loss = 13.803499348461628, train_acc = 0.9755472752678156\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 39, train_loss = 13.484518609941006, train_acc = 0.9758965999068467\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 40, train_loss = 13.180712938308716, train_acc = 0.9764788076385654\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 41, train_loss = 12.890997976064682, train_acc = 0.9771774569166278\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 42, train_loss = 12.614128347486258, train_acc = 0.9771774569166278\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 43, train_loss = 12.349071484059095, train_acc = 0.9775267815556591\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 44, train_loss = 12.09506481513381, train_acc = 0.9782254308337215\n",
      "test Acc 0.9702048417132216:\n",
      "9th- epoch: 45, train_loss = 11.8509520329535, train_acc = 0.9785747554727526\n",
      "test Acc 0.9702048417132216:\n",
      "9th- epoch: 46, train_loss = 11.615990683436394, train_acc = 0.9790405216581276\n",
      "test Acc 0.9702048417132216:\n",
      "9th- epoch: 47, train_loss = 11.389682337641716, train_acc = 0.97973917093619\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 48, train_loss = 11.171314880251884, train_acc = 0.9799720540288775\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 49, train_loss = 10.960277415812016, train_acc = 0.9805542617605962\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 50, train_loss = 10.75636788457632, train_acc = 0.9805542617605962\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 51, train_loss = 10.55929953418672, train_acc = 0.9809035863996274\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 52, train_loss = 10.368558902293444, train_acc = 0.9809035863996274\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 53, train_loss = 10.183899642899632, train_acc = 0.9811364694923148\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 54, train_loss = 10.004692275077105, train_acc = 0.9813693525850024\n",
      "test Acc 0.9720670391061452:\n",
      "9th- epoch: 55, train_loss = 9.830815574154258, train_acc = 0.9817186772240335\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 56, train_loss = 9.661959543824196, train_acc = 0.981951560316721\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 57, train_loss = 9.497919101268053, train_acc = 0.9825337680484397\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 58, train_loss = 9.338604236021638, train_acc = 0.9828830926874709\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 59, train_loss = 9.183727966621518, train_acc = 0.9829995342338146\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 60, train_loss = 9.032961400225759, train_acc = 0.9832324173265021\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 61, train_loss = 8.886254033073783, train_acc = 0.9833488588728458\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 62, train_loss = 8.74324263446033, train_acc = 0.9834653004191896\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 63, train_loss = 8.60384638980031, train_acc = 0.9834653004191896\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 64, train_loss = 8.467939330264926, train_acc = 0.983698183511877\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 65, train_loss = 8.335319202393293, train_acc = 0.9842803912435957\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 66, train_loss = 8.206032995134592, train_acc = 0.9845132743362832\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 67, train_loss = 8.07986605539918, train_acc = 0.9845132743362832\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 68, train_loss = 7.95684433542192, train_acc = 0.9848625989753144\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 69, train_loss = 7.836874445900321, train_acc = 0.9849790405216581\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 70, train_loss = 7.719555577263236, train_acc = 0.9855612482533768\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 71, train_loss = 7.604988802224398, train_acc = 0.9857941313460643\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 72, train_loss = 7.492986531928182, train_acc = 0.985910572892408\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 73, train_loss = 7.383652361109853, train_acc = 0.9861434559850955\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 74, train_loss = 7.276669142767787, train_acc = 0.9861434559850955\n",
      "test Acc 0.9771880819366853:\n",
      "9th- epoch: 75, train_loss = 7.172014961019158, train_acc = 0.9862598975314392\n",
      "test Acc 0.9771880819366853:\n",
      "9th- epoch: 76, train_loss = 7.069631010293961, train_acc = 0.986376339077783\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 77, train_loss = 6.969498245045543, train_acc = 0.9864927806241267\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 78, train_loss = 6.871355023235083, train_acc = 0.9866092221704704\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 79, train_loss = 6.775406321510673, train_acc = 0.9866092221704704\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 80, train_loss = 6.681321866810322, train_acc = 0.9869585468095017\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 81, train_loss = 6.589236859232187, train_acc = 0.9870749883558454\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 82, train_loss = 6.49891553632915, train_acc = 0.9873078714485328\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 83, train_loss = 6.410476146265864, train_acc = 0.9875407545412203\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 84, train_loss = 6.323845537379384, train_acc = 0.9875407545412203\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 85, train_loss = 6.23888879828155, train_acc = 0.9883558453656265\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 86, train_loss = 6.155557053163648, train_acc = 0.9884722869119702\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 87, train_loss = 6.074001181870699, train_acc = 0.9887051700046576\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 88, train_loss = 5.993856569752097, train_acc = 0.9887051700046576\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 89, train_loss = 5.915279395878315, train_acc = 0.9889380530973452\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 90, train_loss = 5.838106566108763, train_acc = 0.9892873777363763\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 91, train_loss = 5.762361157685518, train_acc = 0.9892873777363763\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 92, train_loss = 5.688134434632957, train_acc = 0.98940381928272\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 93, train_loss = 5.61534499656409, train_acc = 0.9895202608290639\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 94, train_loss = 5.543900866992772, train_acc = 0.9897531439217513\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 95, train_loss = 5.4738093772903085, train_acc = 0.989869585468095\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 96, train_loss = 5.404991644434631, train_acc = 0.989869585468095\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 97, train_loss = 5.337480912916362, train_acc = 0.9901024685607824\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 98, train_loss = 5.271091304719448, train_acc = 0.99033535165347\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 99, train_loss = 5.205973679199815, train_acc = 0.9906846762925011\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 100, train_loss = 5.141909358091652, train_acc = 0.9910340009315324\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 101, train_loss = 5.079032149165869, train_acc = 0.9910340009315324\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 102, train_loss = 5.0172417452558875, train_acc = 0.9910340009315324\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 103, train_loss = 4.956519811414182, train_acc = 0.9911504424778761\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 104, train_loss = 4.896923852153122, train_acc = 0.9912668840242198\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 105, train_loss = 4.838323657400906, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 106, train_loss = 4.780728147365153, train_acc = 0.9914997671169073\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 107, train_loss = 4.724254407919943, train_acc = 0.9917326502095948\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 108, train_loss = 4.668535155244172, train_acc = 0.9917326502095948\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 109, train_loss = 4.613901671953499, train_acc = 0.9918490917559385\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 110, train_loss = 4.560088594444096, train_acc = 0.9918490917559385\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 111, train_loss = 4.507164424285293, train_acc = 0.9921984163949698\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 112, train_loss = 4.455083935521543, train_acc = 0.9923148579413135\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 113, train_loss = 4.4040307104587555, train_acc = 0.9924312994876572\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 114, train_loss = 4.3538362151011825, train_acc = 0.9925477410340009\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 115, train_loss = 4.304604867473245, train_acc = 0.9925477410340009\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 116, train_loss = 4.25616953894496, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 117, train_loss = 4.208643698133528, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 118, train_loss = 4.161760832183063, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 119, train_loss = 4.115736401639879, train_acc = 0.9928970656730322\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 120, train_loss = 4.070610911585391, train_acc = 0.9930135072193759\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 121, train_loss = 4.026097611524165, train_acc = 0.9930135072193759\n",
      "test Acc 0.9846368715083799:\n",
      "9th- epoch: 122, train_loss = 3.9823131198063493, train_acc = 0.9931299487657196\n",
      "test Acc 0.9846368715083799:\n",
      "9th- epoch: 123, train_loss = 3.939336486160755, train_acc = 0.9931299487657196\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 124, train_loss = 3.8971396312117577, train_acc = 0.9933628318584071\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 125, train_loss = 3.855607993900776, train_acc = 0.9935957149510946\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 126, train_loss = 3.814777111634612, train_acc = 0.9935957149510946\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 127, train_loss = 3.7746401289477944, train_acc = 0.9935957149510946\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 128, train_loss = 3.7351786233484745, train_acc = 0.993828598043782\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 129, train_loss = 3.6963950423523784, train_acc = 0.9939450395901258\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 130, train_loss = 3.65822213049978, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 131, train_loss = 3.620793110691011, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 132, train_loss = 3.5839595566503704, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 133, train_loss = 3.5478217899799347, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 134, train_loss = 3.512237039860338, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 135, train_loss = 3.4772347533144057, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 136, train_loss = 3.442871751729399, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 137, train_loss = 3.409088948275894, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 138, train_loss = 3.3757582888938487, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 139, train_loss = 3.343073545023799, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 140, train_loss = 3.310986889526248, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 141, train_loss = 3.279353065416217, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 142, train_loss = 3.248387722764164, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 143, train_loss = 3.217811305075884, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 144, train_loss = 3.187742022331804, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 145, train_loss = 3.15811832761392, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 146, train_loss = 3.129074110183865, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 147, train_loss = 3.1005171821452677, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 148, train_loss = 3.072406271006912, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 149, train_loss = 3.044679128099233, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 150, train_loss = 3.0174172166734934, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 151, train_loss = 2.990724428091198, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 152, train_loss = 2.9643373023718596, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 153, train_loss = 2.9383923155255616, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 154, train_loss = 2.912764084059745, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 155, train_loss = 2.887609662953764, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 156, train_loss = 2.862862856592983, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 157, train_loss = 2.8385564633645117, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 158, train_loss = 2.814525327179581, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 159, train_loss = 2.7908906950615346, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 160, train_loss = 2.767637837678194, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 161, train_loss = 2.744814842939377, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 162, train_loss = 2.7221616855822504, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 163, train_loss = 2.699702539946884, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 164, train_loss = 2.6776354983448982, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 165, train_loss = 2.6559907370246947, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 166, train_loss = 2.6346509135328233, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 167, train_loss = 2.61363128433004, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 168, train_loss = 2.5928659639321268, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 169, train_loss = 2.5724427164532244, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 170, train_loss = 2.552370818797499, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 171, train_loss = 2.5325359203852713, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 172, train_loss = 2.513016329612583, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 173, train_loss = 2.4938118322752416, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 174, train_loss = 2.4748326553963125, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 175, train_loss = 2.456136332359165, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 176, train_loss = 2.4376993738114834, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 177, train_loss = 2.4194380291737616, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 178, train_loss = 2.401601122226566, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 179, train_loss = 2.3839887394569814, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 180, train_loss = 2.3665785912889987, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 181, train_loss = 2.3494536739308387, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 182, train_loss = 2.332562481286004, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 183, train_loss = 2.3158533435780555, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 184, train_loss = 2.299490025965497, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 185, train_loss = 2.2832714803516865, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 186, train_loss = 2.267305937828496, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 187, train_loss = 2.2515839238185436, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 188, train_loss = 2.236106716096401, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 189, train_loss = 2.2208466094452888, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 190, train_loss = 2.2057981702964753, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 191, train_loss = 2.1909721232950687, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 192, train_loss = 2.1763530720490962, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 193, train_loss = 2.1620089448988438, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 194, train_loss = 2.147779290797189, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 195, train_loss = 2.133799600182101, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 196, train_loss = 2.119991338578984, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 197, train_loss = 2.10636804997921, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 198, train_loss = 2.0930332902353257, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 199, train_loss = 2.079792684642598, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 200, train_loss = 2.0667281933128834, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 201, train_loss = 2.0539477567654103, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 202, train_loss = 2.041255260584876, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 203, train_loss = 2.028857556404546, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 204, train_loss = 2.0165663100779057, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 205, train_loss = 2.0045232761185616, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 206, train_loss = 1.9926359616219997, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 207, train_loss = 1.980896693887189, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 208, train_loss = 1.9693315725307912, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 209, train_loss = 1.9579768653493375, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 210, train_loss = 1.9466501486022025, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 211, train_loss = 1.9355644322931767, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 212, train_loss = 1.9245602439623326, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 213, train_loss = 1.9137511539738625, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 214, train_loss = 1.90304409340024, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 215, train_loss = 1.8925668883603066, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 216, train_loss = 1.8822292524855584, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 217, train_loss = 1.8720293764490634, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 218, train_loss = 1.861822221428156, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 219, train_loss = 1.8519388511776924, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 220, train_loss = 1.842002556892112, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 221, train_loss = 1.8323258857708424, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 222, train_loss = 1.822643992723897, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 223, train_loss = 1.813155135838315, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 224, train_loss = 1.8037513047456741, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 225, train_loss = 1.7945504747331142, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 226, train_loss = 1.7855041597504169, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 227, train_loss = 1.7765244070906192, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 228, train_loss = 1.7677039590198547, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 229, train_loss = 1.7590566861908883, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 230, train_loss = 1.7504821233451366, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 231, train_loss = 1.742074417648837, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 232, train_loss = 1.7336979757528752, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 233, train_loss = 1.7255327489692718, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 234, train_loss = 1.7174781349021941, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 235, train_loss = 1.7094628971535712, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 236, train_loss = 1.7016330969054252, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 237, train_loss = 1.6938572351355106, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 238, train_loss = 1.6862173775443807, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 239, train_loss = 1.6787273014197126, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 240, train_loss = 1.671208800165914, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 241, train_loss = 1.6639373376965523, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 242, train_loss = 1.6566628441214561, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 243, train_loss = 1.6495521912584081, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 244, train_loss = 1.6425374062964693, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 245, train_loss = 1.6355360621819273, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 246, train_loss = 1.628644680022262, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 247, train_loss = 1.62195296457503, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 248, train_loss = 1.6152016384294257, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 249, train_loss = 1.6086226353654638, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 250, train_loss = 1.6020490527153015, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 251, train_loss = 1.5956761240959167, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 252, train_loss = 1.589298435836099, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 253, train_loss = 1.5829294435679913, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 254, train_loss = 1.5768141312291846, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 255, train_loss = 1.570680900127627, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 256, train_loss = 1.564610150991939, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 257, train_loss = 1.5585967475781217, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 258, train_loss = 1.5527411922812462, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 259, train_loss = 1.5468490334460512, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 260, train_loss = 1.5410928031196818, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 261, train_loss = 1.5353845866629854, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 262, train_loss = 1.5297288732836023, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 263, train_loss = 1.5242170604178682, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 264, train_loss = 1.5186624316265807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 265, train_loss = 1.5131815262138844, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 266, train_loss = 1.5078395257005468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 267, train_loss = 1.502510454505682, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 268, train_loss = 1.4972711080918089, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 269, train_loss = 1.4920330519089475, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 270, train_loss = 1.4869276644894853, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 271, train_loss = 1.4818051730981097, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 272, train_loss = 1.4767533565172926, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 273, train_loss = 1.4717652375111356, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 274, train_loss = 1.4668307887623087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 275, train_loss = 1.4619446074357256, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 276, train_loss = 1.4571077302098274, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 277, train_loss = 1.4523267671465874, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 278, train_loss = 1.4475652327528223, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 279, train_loss = 1.44290643685963, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 280, train_loss = 1.4383572278311476, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 281, train_loss = 1.433693944127299, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 282, train_loss = 1.4291587757179514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 283, train_loss = 1.4247344881296158, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 284, train_loss = 1.4202192475786433, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 285, train_loss = 1.4158591093728319, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 286, train_loss = 1.4115768721094355, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 287, train_loss = 1.4072131775319576, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 288, train_loss = 1.4030078375944868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 289, train_loss = 1.3986617425689474, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 290, train_loss = 1.394401359022595, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 291, train_loss = 1.3903598673641682, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 292, train_loss = 1.3861917754402384, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 293, train_loss = 1.3822544874856248, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 294, train_loss = 1.3781724460422993, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 295, train_loss = 1.3741806633770466, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 296, train_loss = 1.3704021461308002, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 297, train_loss = 1.3663808392593637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 298, train_loss = 1.3625716069946066, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 299, train_loss = 1.358755599707365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 300, train_loss = 1.3549569075694308, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 301, train_loss = 1.351331915706396, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 302, train_loss = 1.3475540280342102, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 303, train_loss = 1.343909151852131, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 304, train_loss = 1.340241356403567, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 305, train_loss = 1.336739081889391, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 306, train_loss = 1.3330762622645125, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 307, train_loss = 1.3294688513269648, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 308, train_loss = 1.326195971458219, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 309, train_loss = 1.3225744018564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 310, train_loss = 1.3191935829818249, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 311, train_loss = 1.315723691135645, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 312, train_loss = 1.3124187476933002, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 313, train_loss = 1.30901511880802, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 314, train_loss = 1.3057603649795055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 315, train_loss = 1.3023516771499999, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 316, train_loss = 1.2992337768082507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 317, train_loss = 1.2958120976691134, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 318, train_loss = 1.2927335041458718, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 319, train_loss = 1.2895278495852835, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 320, train_loss = 1.2863261687452905, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 321, train_loss = 1.2832607750897296, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 322, train_loss = 1.280133428692352, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 323, train_loss = 1.2771173777873628, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 324, train_loss = 1.2739963680505753, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 325, train_loss = 1.27106947574066, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 326, train_loss = 1.2679172816569917, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 327, train_loss = 1.2650889952783473, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 328, train_loss = 1.262044082104694, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 329, train_loss = 1.2592992198769934, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 330, train_loss = 1.2562362787430175, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 331, train_loss = 1.2534472085535526, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 332, train_loss = 1.2505436750943772, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 333, train_loss = 1.2477694153785706, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 334, train_loss = 1.2449363668565638, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 335, train_loss = 1.2421937361359596, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 336, train_loss = 1.2393983428482898, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 337, train_loss = 1.2367186918854713, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 338, train_loss = 1.2339406932587735, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 339, train_loss = 1.2312647837097757, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 340, train_loss = 1.2286733239889145, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 341, train_loss = 1.2260101077263243, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 342, train_loss = 1.2233798143570311, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 343, train_loss = 1.2207177306408994, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 344, train_loss = 1.218079277605284, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 345, train_loss = 1.2156192536349408, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 346, train_loss = 1.2130347229540348, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 347, train_loss = 1.2104893761570565, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 348, train_loss = 1.2079491217737086, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 349, train_loss = 1.2055907994508743, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 350, train_loss = 1.203074845194351, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 351, train_loss = 1.2005558547680266, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 352, train_loss = 1.1982432889635675, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 353, train_loss = 1.1957732414011844, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 354, train_loss = 1.1933928181533702, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 355, train_loss = 1.1909929874236695, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 356, train_loss = 1.1886439534719102, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 357, train_loss = 1.1863539281184785, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 358, train_loss = 1.1839452683925629, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 359, train_loss = 1.181710549921263, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 360, train_loss = 1.1794093710486777, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 361, train_loss = 1.177177497476805, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 362, train_loss = 1.17488232254982, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 363, train_loss = 1.1726132606272586, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 364, train_loss = 1.1704299884731881, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 365, train_loss = 1.1681965664029121, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 366, train_loss = 1.1661485483055003, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 367, train_loss = 1.1637916080653667, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 368, train_loss = 1.161783543706406, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 369, train_loss = 1.1595977557008155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 370, train_loss = 1.1575587565894239, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 371, train_loss = 1.155318594246637, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 372, train_loss = 1.153312070935499, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 373, train_loss = 1.1511688667233102, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 374, train_loss = 1.149147593707312, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 375, train_loss = 1.1470310402219184, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 376, train_loss = 1.1451531003112905, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 377, train_loss = 1.143008079379797, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 378, train_loss = 1.1410334333777428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 379, train_loss = 1.1390253665740602, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 380, train_loss = 1.1371148352627642, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 381, train_loss = 1.1351558131282218, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 382, train_loss = 1.1332152361865155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 383, train_loss = 1.1311834640800953, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 384, train_loss = 1.1292949455673806, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 385, train_loss = 1.1274018895928748, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 386, train_loss = 1.125479073554743, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 387, train_loss = 1.123602605133783, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 388, train_loss = 1.1216902546584606, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 389, train_loss = 1.1198741545085795, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 390, train_loss = 1.117987057834398, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 391, train_loss = 1.116062492132187, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 392, train_loss = 1.1144157971139066, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 393, train_loss = 1.1125729854102246, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 394, train_loss = 1.1107320387964137, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 395, train_loss = 1.108850562304724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 396, train_loss = 1.1072680242359638, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 397, train_loss = 1.105359461158514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 398, train_loss = 1.1036139180068858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 399, train_loss = 1.1019234868581407, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 400, train_loss = 1.1001397955114953, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 401, train_loss = 1.0983895671670325, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 402, train_loss = 1.0967429143493064, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 403, train_loss = 1.0950222040410154, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 404, train_loss = 1.093320980668068, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 405, train_loss = 1.091788510500919, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 406, train_loss = 1.0899348706007004, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 407, train_loss = 1.0883584233815782, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 408, train_loss = 1.086739756166935, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 409, train_loss = 1.0851030561025254, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 410, train_loss = 1.0834082812070847, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 411, train_loss = 1.081761371344328, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 412, train_loss = 1.0802768071298487, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 413, train_loss = 1.0785925189848058, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 414, train_loss = 1.0770917783374898, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 415, train_loss = 1.0755232572555542, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 416, train_loss = 1.0739230227773078, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 417, train_loss = 1.0724447394604795, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 418, train_loss = 1.070736660331022, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 419, train_loss = 1.069251346110832, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 420, train_loss = 1.0678085957770236, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 421, train_loss = 1.0661958741548005, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 422, train_loss = 1.0647236692311708, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 423, train_loss = 1.0632660289702471, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 424, train_loss = 1.0616324568691198, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 425, train_loss = 1.0602118795213755, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 426, train_loss = 1.0587792284786701, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 427, train_loss = 1.05720361447311, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 428, train_loss = 1.0558431943354663, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 429, train_loss = 1.0544447265565395, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 430, train_loss = 1.0529217571020126, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 431, train_loss = 1.0514831157925073, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 432, train_loss = 1.0500727829930838, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 433, train_loss = 1.0487178315815981, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 434, train_loss = 1.0472719160316046, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 435, train_loss = 1.0458685668709222, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 436, train_loss = 1.0445248186588287, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 437, train_loss = 1.0430425119993743, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 438, train_loss = 1.0416217905876692, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 439, train_loss = 1.0403463169932365, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 440, train_loss = 1.0389465428888798, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 441, train_loss = 1.0375184938311577, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 442, train_loss = 1.036295601486927, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 443, train_loss = 1.034829430282116, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 444, train_loss = 1.0336109176278114, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 445, train_loss = 1.0323329418897629, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 446, train_loss = 1.030959894269472, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 447, train_loss = 1.0296374869940337, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 448, train_loss = 1.02834746366716, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 449, train_loss = 1.026962154865032, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 450, train_loss = 1.0258116299810354, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 451, train_loss = 1.024478485196596, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 452, train_loss = 1.0232864072022494, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 453, train_loss = 1.0218716263771057, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 454, train_loss = 1.0206998735666275, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 455, train_loss = 1.0194302424788475, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 456, train_loss = 1.0181110464036465, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 457, train_loss = 1.0170087429287378, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 458, train_loss = 1.0156266590056475, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 459, train_loss = 1.0145741291344166, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 460, train_loss = 1.0132601422665175, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 461, train_loss = 1.0120491186680738, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 462, train_loss = 1.0108575920166913, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 463, train_loss = 1.0096245693566743, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 464, train_loss = 1.0085185207426548, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 465, train_loss = 1.007132899016142, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 466, train_loss = 1.0060387700796127, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 467, train_loss = 1.0049121913907584, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 468, train_loss = 1.0036950843932573, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 469, train_loss = 1.0025634380581323, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 470, train_loss = 1.001418368279701, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 471, train_loss = 1.0001760683953762, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 472, train_loss = 0.9991918615996838, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 473, train_loss = 0.9979289223847445, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 474, train_loss = 0.996848251670599, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 475, train_loss = 0.9957338695821818, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 476, train_loss = 0.9946206559834536, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 477, train_loss = 0.9934428234992083, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 478, train_loss = 0.9924056244490203, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 479, train_loss = 0.9912658507528249, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 480, train_loss = 0.9901245770452078, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 481, train_loss = 0.9890627848508302, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 482, train_loss = 0.9879924120905343, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 483, train_loss = 0.9869350530207157, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 484, train_loss = 0.9857388561067637, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 485, train_loss = 0.9847673773765564, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 486, train_loss = 0.983678857475752, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 487, train_loss = 0.982559084892273, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 488, train_loss = 0.9816134124994278, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 489, train_loss = 0.9804160681960639, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 490, train_loss = 0.9795051018300001, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 491, train_loss = 0.9784418021736201, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 492, train_loss = 0.9773685919644777, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 493, train_loss = 0.9763393315079156, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 494, train_loss = 0.9753258613345679, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 495, train_loss = 0.9743335036037024, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 496, train_loss = 0.9733049062488135, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 497, train_loss = 0.9722340553998947, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 498, train_loss = 0.9713052771985531, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 499, train_loss = 0.9702286757528782, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████████████▎                                                 | 9/30 [1:01:12<2:23:16, 409.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "10th- epoch: 0, train_loss = 274.34496533870697, train_acc = 0.4491150442477876\n",
      "test Acc 0.5470204841713222:\n",
      "10th- epoch: 1, train_loss = 211.03029012680054, train_acc = 0.5522822543083372\n",
      "test Acc 0.5647113594040968:\n",
      "10th- epoch: 2, train_loss = 162.9469723701477, train_acc = 0.577899394503959\n",
      "test Acc 0.6121973929236499:\n",
      "10th- epoch: 3, train_loss = 134.52943754196167, train_acc = 0.6709361900326036\n",
      "test Acc 0.7388268156424581:\n",
      "10th- epoch: 4, train_loss = 115.01604169607162, train_acc = 0.7533768048439683\n",
      "test Acc 0.7742085661080075:\n",
      "10th- epoch: 5, train_loss = 99.72142678499222, train_acc = 0.7715416860735911\n",
      "test Acc 0.7970204841713222:\n",
      "10th- epoch: 6, train_loss = 87.71094346046448, train_acc = 0.7846995808104331\n",
      "test Acc 0.8081936685288641:\n",
      "10th- epoch: 7, train_loss = 78.06895613670349, train_acc = 0.8095016301816488\n",
      "test Acc 0.835195530726257:\n",
      "10th- epoch: 8, train_loss = 69.91594645380974, train_acc = 0.8425710293432697\n",
      "test Acc 0.8654562383612663:\n",
      "10th- epoch: 9, train_loss = 62.75539314746857, train_acc = 0.8706334420121099\n",
      "test Acc 0.88268156424581:\n",
      "10th- epoch: 10, train_loss = 56.38814252614975, train_acc = 0.8963670237540755\n",
      "test Acc 0.909217877094972:\n",
      "10th- epoch: 11, train_loss = 50.75929208099842, train_acc = 0.9203539823008849\n",
      "test Acc 0.9301675977653632:\n",
      "10th- epoch: 12, train_loss = 45.83993265032768, train_acc = 0.9350256171401956\n",
      "test Acc 0.9380819366852886:\n",
      "10th- epoch: 13, train_loss = 41.586769208312035, train_acc = 0.9422449930135072\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 14, train_loss = 37.94157633185387, train_acc = 0.9469026548672567\n",
      "test Acc 0.9436685288640596:\n",
      "10th- epoch: 15, train_loss = 34.832514345645905, train_acc = 0.9499301350721937\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 16, train_loss = 32.18928702920675, train_acc = 0.9527247321844434\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 17, train_loss = 29.94012439250946, train_acc = 0.9548206800186306\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 18, train_loss = 28.01815277338028, train_acc = 0.9580810433162552\n",
      "test Acc 0.952048417132216:\n",
      "10th- epoch: 19, train_loss = 26.365875504910946, train_acc = 0.9614578481602236\n",
      "test Acc 0.9553072625698324:\n",
      "10th- epoch: 20, train_loss = 24.935767203569412, train_acc = 0.9636702375407545\n",
      "test Acc 0.9562383612662942:\n",
      "10th- epoch: 21, train_loss = 23.687286607921124, train_acc = 0.9655333022822543\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 22, train_loss = 22.588529251515865, train_acc = 0.9670470423847228\n",
      "test Acc 0.9608938547486033:\n",
      "10th- epoch: 23, train_loss = 21.614228777587414, train_acc = 0.9679785747554728\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 24, train_loss = 20.744148559868336, train_acc = 0.9689101071262226\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 25, train_loss = 19.960654117166996, train_acc = 0.9692594317652539\n",
      "test Acc 0.9608938547486033:\n",
      "10th- epoch: 26, train_loss = 19.2505357041955, train_acc = 0.9693758733115976\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 27, train_loss = 18.603038623929024, train_acc = 0.969608756404285\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 28, train_loss = 18.00882474705577, train_acc = 0.9699580810433163\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 29, train_loss = 17.460002299398184, train_acc = 0.9703074056823474\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 30, train_loss = 16.95079367607832, train_acc = 0.9711224965067536\n",
      "test Acc 0.9641527001862198:\n",
      "10th- epoch: 31, train_loss = 16.476246517151594, train_acc = 0.9715882626921285\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 32, train_loss = 16.032227907329798, train_acc = 0.9727526781555659\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 33, train_loss = 15.615512534976006, train_acc = 0.9729855612482534\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 34, train_loss = 15.222983349114656, train_acc = 0.9736842105263158\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 35, train_loss = 14.851685747504234, train_acc = 0.9742664182580345\n",
      "test Acc 0.9664804469273743:\n",
      "10th- epoch: 36, train_loss = 14.499570716172457, train_acc = 0.9746157428970657\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 37, train_loss = 14.164749834686518, train_acc = 0.9749650675360969\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 38, train_loss = 13.845911975950003, train_acc = 0.9751979506287843\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 39, train_loss = 13.541682347655296, train_acc = 0.9754308337214718\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 40, train_loss = 13.250498101115227, train_acc = 0.9760130414531905\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 41, train_loss = 12.971544817090034, train_acc = 0.9760130414531905\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 42, train_loss = 12.704082001000643, train_acc = 0.976245924545878\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 43, train_loss = 12.44724814221263, train_acc = 0.9764788076385654\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 44, train_loss = 12.200120992958546, train_acc = 0.9770610153702841\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 45, train_loss = 11.961804587393999, train_acc = 0.9776432231020028\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 46, train_loss = 11.73177531734109, train_acc = 0.977992547741034\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 47, train_loss = 11.509816199541092, train_acc = 0.9784583139264089\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 48, train_loss = 11.295188209041953, train_acc = 0.9789240801117839\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 49, train_loss = 11.087616050615907, train_acc = 0.97973917093619\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 50, train_loss = 10.886821260675788, train_acc = 0.9803213786679087\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 51, train_loss = 10.692245053127408, train_acc = 0.9804378202142524\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 52, train_loss = 10.50368819385767, train_acc = 0.9809035863996274\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 53, train_loss = 10.32076720148325, train_acc = 0.9810200279459711\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 54, train_loss = 10.14320969209075, train_acc = 0.9811364694923148\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 55, train_loss = 9.97085589170456, train_acc = 0.9812529110386586\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 56, train_loss = 9.803169345483184, train_acc = 0.9814857941313461\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 57, train_loss = 9.6401291731745, train_acc = 0.9818351187703773\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 58, train_loss = 9.481233911588788, train_acc = 0.9821844434094085\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 59, train_loss = 9.326523773372173, train_acc = 0.9824173265020959\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 60, train_loss = 9.175656795501709, train_acc = 0.9827666511411272\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 61, train_loss = 9.028695346787572, train_acc = 0.9829995342338146\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 62, train_loss = 8.88531973771751, train_acc = 0.9832324173265021\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 63, train_loss = 8.745131202042103, train_acc = 0.9834653004191896\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 64, train_loss = 8.608241088688374, train_acc = 0.983698183511877\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 65, train_loss = 8.474466415122151, train_acc = 0.9839310666045645\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 66, train_loss = 8.343802582472563, train_acc = 0.9840475081509082\n",
      "test Acc 0.9771880819366853:\n",
      "10th- epoch: 67, train_loss = 8.216292154043913, train_acc = 0.9840475081509082\n",
      "test Acc 0.9771880819366853:\n",
      "10th- epoch: 68, train_loss = 8.091711362823844, train_acc = 0.984163949697252\n",
      "test Acc 0.9771880819366853:\n",
      "10th- epoch: 69, train_loss = 7.969963880255818, train_acc = 0.9842803912435957\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 70, train_loss = 7.850917439907789, train_acc = 0.9843968327899395\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 71, train_loss = 7.734597388654947, train_acc = 0.9845132743362832\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 72, train_loss = 7.62073365226388, train_acc = 0.9850954820680019\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 73, train_loss = 7.509504860267043, train_acc = 0.9860270144387517\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 74, train_loss = 7.400513093918562, train_acc = 0.9861434559850955\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 75, train_loss = 7.2938185427337885, train_acc = 0.9860270144387517\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 76, train_loss = 7.189295753836632, train_acc = 0.9861434559850955\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 77, train_loss = 7.087060574442148, train_acc = 0.986376339077783\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 78, train_loss = 6.986909341067076, train_acc = 0.9866092221704704\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 79, train_loss = 6.888699708506465, train_acc = 0.9869585468095017\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 80, train_loss = 6.792801110073924, train_acc = 0.9869585468095017\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 81, train_loss = 6.698742436245084, train_acc = 0.9870749883558454\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 82, train_loss = 6.606565674766898, train_acc = 0.9876571960875641\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 83, train_loss = 6.51624515093863, train_acc = 0.9876571960875641\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 84, train_loss = 6.427718387916684, train_acc = 0.9877736376339078\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 85, train_loss = 6.340864496305585, train_acc = 0.9882394038192828\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 86, train_loss = 6.255569487810135, train_acc = 0.9883558453656265\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 87, train_loss = 6.171990951523185, train_acc = 0.9884722869119702\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 88, train_loss = 6.0898798909038305, train_acc = 0.9885887284583139\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 89, train_loss = 6.009166928008199, train_acc = 0.9888216115510013\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 90, train_loss = 5.929844543337822, train_acc = 0.9891709361900326\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 91, train_loss = 5.852188600227237, train_acc = 0.9895202608290639\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 92, train_loss = 5.7758198250085115, train_acc = 0.9897531439217513\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 93, train_loss = 5.700722947716713, train_acc = 0.989869585468095\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 94, train_loss = 5.627035431563854, train_acc = 0.9899860270144387\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 95, train_loss = 5.554602529853582, train_acc = 0.9902189101071263\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 96, train_loss = 5.483597410842776, train_acc = 0.99033535165347\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 97, train_loss = 5.413749633356929, train_acc = 0.9904517931998137\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 98, train_loss = 5.345103332772851, train_acc = 0.9905682347461574\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 99, train_loss = 5.27761448174715, train_acc = 0.9906846762925011\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 100, train_loss = 5.211508132517338, train_acc = 0.990801117838845\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 101, train_loss = 5.14643095806241, train_acc = 0.9910340009315324\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 102, train_loss = 5.08241256698966, train_acc = 0.9910340009315324\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 103, train_loss = 5.0197104923427105, train_acc = 0.9910340009315324\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 104, train_loss = 4.957844562828541, train_acc = 0.9911504424778761\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 105, train_loss = 4.897192286327481, train_acc = 0.9911504424778761\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 106, train_loss = 4.837453205138445, train_acc = 0.9913833255705635\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 107, train_loss = 4.7788694920018315, train_acc = 0.9914997671169073\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 108, train_loss = 4.721175306476653, train_acc = 0.9918490917559385\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 109, train_loss = 4.664360138587654, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 110, train_loss = 4.608717177063227, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 111, train_loss = 4.553801386617124, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 112, train_loss = 4.499994109384716, train_acc = 0.9919655333022822\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 113, train_loss = 4.447008173912764, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 114, train_loss = 4.3950994266197085, train_acc = 0.992081974848626\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 115, train_loss = 4.343797959387302, train_acc = 0.9921984163949698\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 116, train_loss = 4.293494697660208, train_acc = 0.9921984163949698\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 117, train_loss = 4.243927179835737, train_acc = 0.9925477410340009\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 118, train_loss = 4.195216099731624, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 119, train_loss = 4.147346599958837, train_acc = 0.9927806241266884\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 120, train_loss = 4.10015429276973, train_acc = 0.9927806241266884\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 121, train_loss = 4.053902287967503, train_acc = 0.9927806241266884\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 122, train_loss = 4.0083974217996, train_acc = 0.9927806241266884\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 123, train_loss = 3.9636669540777802, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 124, train_loss = 3.919605345465243, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 125, train_loss = 3.876393119804561, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 126, train_loss = 3.833874181844294, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 127, train_loss = 3.791998028755188, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 128, train_loss = 3.750951544381678, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 129, train_loss = 3.7104770857840776, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 130, train_loss = 3.670863670296967, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 131, train_loss = 3.6317725935950875, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 132, train_loss = 3.5933587485924363, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 133, train_loss = 3.555604003369808, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 134, train_loss = 3.518434406258166, train_acc = 0.9934792734047508\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 135, train_loss = 3.482013982720673, train_acc = 0.9934792734047508\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 136, train_loss = 3.446161408908665, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 137, train_loss = 3.410927915945649, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 138, train_loss = 3.3762273835018277, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 139, train_loss = 3.342215689830482, train_acc = 0.9937121564974383\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 140, train_loss = 3.3087339820340276, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 141, train_loss = 3.2757963314652443, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 142, train_loss = 3.243474298156798, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 143, train_loss = 3.211530555970967, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 144, train_loss = 3.1803717631846666, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 145, train_loss = 3.149492817930877, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 146, train_loss = 3.1192651921883225, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 147, train_loss = 3.089352681301534, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 148, train_loss = 3.0601265458390117, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 149, train_loss = 3.031292572617531, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 150, train_loss = 3.003016697242856, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 151, train_loss = 2.9751151301898062, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 152, train_loss = 2.947917520534247, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 153, train_loss = 2.9208553596399724, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 154, train_loss = 2.8944741911254823, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 155, train_loss = 2.868367056827992, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 156, train_loss = 2.8428134550340474, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 157, train_loss = 2.817591296043247, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 158, train_loss = 2.792793691623956, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 159, train_loss = 2.7685127425938845, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 160, train_loss = 2.7445199615322053, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 161, train_loss = 2.7210113909095526, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 162, train_loss = 2.6978504229336977, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 163, train_loss = 2.6750402338802814, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 164, train_loss = 2.6526369168423116, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 165, train_loss = 2.6306884768418968, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 166, train_loss = 2.609004771336913, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 167, train_loss = 2.587724544107914, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 168, train_loss = 2.5667031719349325, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 169, train_loss = 2.54626931110397, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 170, train_loss = 2.525882326066494, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 171, train_loss = 2.5060268323868513, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 172, train_loss = 2.48644159687683, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 173, train_loss = 2.467186230700463, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 174, train_loss = 2.4481553020887077, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 175, train_loss = 2.4295979137532413, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 176, train_loss = 2.411226929631084, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 177, train_loss = 2.393198487814516, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 178, train_loss = 2.3754486218094826, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 179, train_loss = 2.358086958527565, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 180, train_loss = 2.3408999759703875, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 181, train_loss = 2.3239147942513227, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 182, train_loss = 2.307363790925592, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 183, train_loss = 2.291010866407305, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 184, train_loss = 2.2749216039665043, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 185, train_loss = 2.259067988023162, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 186, train_loss = 2.2435371335595846, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 187, train_loss = 2.228252667468041, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 188, train_loss = 2.2130482234060764, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 189, train_loss = 2.1982940770685673, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 190, train_loss = 2.1835887082852423, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 191, train_loss = 2.1693261810578406, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 192, train_loss = 2.1551257483661175, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 193, train_loss = 2.1412755995988846, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 194, train_loss = 2.1274780607782304, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 195, train_loss = 2.114031009376049, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 196, train_loss = 2.1007276200689375, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 197, train_loss = 2.087621594313532, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 198, train_loss = 2.0747223508078605, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 199, train_loss = 2.0622054773848504, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 200, train_loss = 2.049588681431487, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 201, train_loss = 2.0373670496046543, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 202, train_loss = 2.0252371232490987, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 203, train_loss = 2.013405089499429, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 204, train_loss = 2.001529850065708, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 205, train_loss = 1.989963299361989, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 206, train_loss = 1.978412763448432, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 207, train_loss = 1.9673542007803917, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 208, train_loss = 1.956133498577401, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 209, train_loss = 1.9453978277742863, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 210, train_loss = 1.9347044106107205, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 211, train_loss = 1.9241364139597863, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 212, train_loss = 1.9136809494812042, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 213, train_loss = 1.9035598449409008, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 214, train_loss = 1.8933832098264247, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 215, train_loss = 1.8834151264745742, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 216, train_loss = 1.8736943639814854, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 217, train_loss = 1.864008828997612, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 218, train_loss = 1.854354216484353, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 219, train_loss = 1.8450050198007375, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 220, train_loss = 1.8358189549762756, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 221, train_loss = 1.8266229580622166, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 222, train_loss = 1.8175250496715307, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 223, train_loss = 1.8086773522663862, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 224, train_loss = 1.7998202107846737, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 225, train_loss = 1.7912973463535309, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 226, train_loss = 1.7826248810160905, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 227, train_loss = 1.7742214545141906, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 228, train_loss = 1.7659949008375406, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 229, train_loss = 1.7576917819678783, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 230, train_loss = 1.7495984800625592, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 231, train_loss = 1.7416846174746752, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 232, train_loss = 1.733697936637327, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 233, train_loss = 1.7259855028241873, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 234, train_loss = 1.718245979398489, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 235, train_loss = 1.710617585806176, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 236, train_loss = 1.7030378493946046, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 237, train_loss = 1.6957370073068887, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 238, train_loss = 1.688389454735443, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 239, train_loss = 1.6811133220326155, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 240, train_loss = 1.6740219339262694, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 241, train_loss = 1.6669393617194146, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 242, train_loss = 1.6599939204752445, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 243, train_loss = 1.6530621256679296, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "10th- epoch: 244, train_loss = 1.6463397673796862, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 245, train_loss = 1.6394806951284409, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 246, train_loss = 1.6329948205966502, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 247, train_loss = 1.6264105464797467, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 248, train_loss = 1.6199190989136696, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 249, train_loss = 1.6134071822743863, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 250, train_loss = 1.6070905178785324, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 251, train_loss = 1.6007870349567384, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 252, train_loss = 1.5946692128200084, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 253, train_loss = 1.588487882167101, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 254, train_loss = 1.5824740442913026, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 255, train_loss = 1.5763497836887836, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 256, train_loss = 1.5705303034046665, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 257, train_loss = 1.5647947856923565, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 258, train_loss = 1.5589033098658547, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 259, train_loss = 1.5531694634119049, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 260, train_loss = 1.5475612779846415, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 261, train_loss = 1.5419021571287885, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 262, train_loss = 1.5364815728971735, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 263, train_loss = 1.5308963283896446, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 264, train_loss = 1.525457621901296, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 265, train_loss = 1.520054973079823, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 266, train_loss = 1.514882143586874, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 267, train_loss = 1.5095227038254961, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 268, train_loss = 1.5043846213957295, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 269, train_loss = 1.499165253713727, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 270, train_loss = 1.4940346349030733, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 271, train_loss = 1.4889463819563389, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 272, train_loss = 1.483959281235002, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 273, train_loss = 1.4789710566401482, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 274, train_loss = 1.4740384457400069, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 275, train_loss = 1.4692407548427582, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 276, train_loss = 1.4644003497669473, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 277, train_loss = 1.4596938230097294, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 278, train_loss = 1.4549997946014628, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 279, train_loss = 1.4503387982258573, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 280, train_loss = 1.445792472572066, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 281, train_loss = 1.44126847141888, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 282, train_loss = 1.4367411310086027, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 283, train_loss = 1.4323596047470346, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 284, train_loss = 1.4278292134404182, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 285, train_loss = 1.4235430223634467, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 286, train_loss = 1.4191830245545134, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 287, train_loss = 1.414994727820158, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 288, train_loss = 1.4106724386801943, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 289, train_loss = 1.4065316965570673, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 290, train_loss = 1.4023512402782217, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 291, train_loss = 1.3982114953687415, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 292, train_loss = 1.394201240153052, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 293, train_loss = 1.390089925378561, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 294, train_loss = 1.3860653452575207, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 295, train_loss = 1.3820580592146143, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 296, train_loss = 1.3782398365437984, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 297, train_loss = 1.3744432603707537, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 298, train_loss = 1.3705261312425137, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 299, train_loss = 1.3666460178792477, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 300, train_loss = 1.3628211542963982, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 301, train_loss = 1.3590766513952985, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 302, train_loss = 1.3555121769895777, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 303, train_loss = 1.3516555888345465, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 304, train_loss = 1.3480735967168584, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 305, train_loss = 1.3445697786519304, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 306, train_loss = 1.3408633582293987, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 307, train_loss = 1.3373014777898788, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 308, train_loss = 1.3337852793047205, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 309, train_loss = 1.3303118596086279, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 310, train_loss = 1.3269355185329914, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 311, train_loss = 1.3234358528861776, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 312, train_loss = 1.3199386484920979, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 313, train_loss = 1.3167480441043153, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 314, train_loss = 1.313358181505464, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 315, train_loss = 1.3099008612334728, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 316, train_loss = 1.3066017975797877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 317, train_loss = 1.3034708747873083, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 318, train_loss = 1.3002456650137901, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 319, train_loss = 1.296982484520413, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 320, train_loss = 1.2937726738164201, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 321, train_loss = 1.2905870899558067, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 322, train_loss = 1.2876846803119406, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 323, train_loss = 1.2843839997658506, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 324, train_loss = 1.2813462851336226, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 325, train_loss = 1.2783150486648083, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 326, train_loss = 1.275380408973433, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 327, train_loss = 1.2721245797583833, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 328, train_loss = 1.2693239711225033, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 329, train_loss = 1.266238246113062, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 330, train_loss = 1.2633356066653505, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 331, train_loss = 1.2605100063374266, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 332, train_loss = 1.2576265670359135, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 333, train_loss = 1.2546655498445034, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 334, train_loss = 1.2519823337788694, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 335, train_loss = 1.2491054783458821, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 336, train_loss = 1.2462924818391912, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 337, train_loss = 1.2436140142381191, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 338, train_loss = 1.2408365719020367, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 339, train_loss = 1.2381289079785347, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 340, train_loss = 1.2353497694130056, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 341, train_loss = 1.2328544681076892, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 342, train_loss = 1.2301397037808783, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 343, train_loss = 1.2274479381740093, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 344, train_loss = 1.2248906269669533, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 345, train_loss = 1.2222919625346549, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 346, train_loss = 1.2196015765075572, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 347, train_loss = 1.2172731111641042, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 348, train_loss = 1.2145301066339016, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 349, train_loss = 1.2122052796185017, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 350, train_loss = 1.2095778162474744, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 351, train_loss = 1.207122903317213, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 352, train_loss = 1.2047242012922652, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 353, train_loss = 1.2022231009905227, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 354, train_loss = 1.1997437762911431, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 355, train_loss = 1.19737658649683, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 356, train_loss = 1.1950900231604464, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 357, train_loss = 1.1926721234922297, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 358, train_loss = 1.1903471114928834, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 359, train_loss = 1.1879489943385124, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 360, train_loss = 1.1856757290661335, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 361, train_loss = 1.1833979859948158, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 362, train_loss = 1.1810263569350354, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 363, train_loss = 1.178856520622503, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 364, train_loss = 1.176654641807545, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 365, train_loss = 1.1742783921654336, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 366, train_loss = 1.1719734582002275, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 367, train_loss = 1.1700294924085028, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 368, train_loss = 1.167704685300123, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 369, train_loss = 1.1656942504341714, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 370, train_loss = 1.163376934826374, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 371, train_loss = 1.1612376607954502, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 372, train_loss = 1.1591439892654307, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 373, train_loss = 1.1570286166970618, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 374, train_loss = 1.1548674653167836, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 375, train_loss = 1.1528764553368092, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 376, train_loss = 1.1508347975905053, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 377, train_loss = 1.148701346188318, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 378, train_loss = 1.1466297060251236, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 379, train_loss = 1.1446112170815468, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 380, train_loss = 1.1426188573241234, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 381, train_loss = 1.1406641229987144, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 382, train_loss = 1.1387561559677124, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 383, train_loss = 1.1365544659201987, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 384, train_loss = 1.1349007859826088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 385, train_loss = 1.1327052761917002, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 386, train_loss = 1.130904474586714, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 387, train_loss = 1.1288425761158578, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 388, train_loss = 1.1271116845309734, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 389, train_loss = 1.1251300424337387, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 390, train_loss = 1.1231966304476373, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 391, train_loss = 1.121353518217802, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 392, train_loss = 1.119518416642677, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 393, train_loss = 1.117601826786995, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 394, train_loss = 1.1157187086646445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 395, train_loss = 1.1140064622159116, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 396, train_loss = 1.1121491802041419, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 397, train_loss = 1.1104253332014196, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 398, train_loss = 1.1086209279601462, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 399, train_loss = 1.1068613938987255, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 400, train_loss = 1.1050778913195245, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 401, train_loss = 1.103134190023411, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 402, train_loss = 1.1016061480040662, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 403, train_loss = 1.0997788732056506, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 404, train_loss = 1.0979828548734076, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 405, train_loss = 1.0964038173551671, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 406, train_loss = 1.094611035019625, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 407, train_loss = 1.093038936436642, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 408, train_loss = 1.0913067373330705, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 409, train_loss = 1.0893544902210124, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 410, train_loss = 1.0880734423990361, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 411, train_loss = 1.0862885167007335, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 412, train_loss = 1.084511887282133, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 413, train_loss = 1.08291619643569, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 414, train_loss = 1.0813283249735832, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 415, train_loss = 1.0796894803643227, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 416, train_loss = 1.0781759333913215, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 417, train_loss = 1.0767202426795848, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 418, train_loss = 1.075010072439909, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 419, train_loss = 1.0734251402318478, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 420, train_loss = 1.071927148848772, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 421, train_loss = 1.0703280046582222, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 422, train_loss = 1.0687721582944505, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 423, train_loss = 1.0672642551362514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 424, train_loss = 1.065678735554684, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 425, train_loss = 1.0644062508945353, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 426, train_loss = 1.0626350032980554, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 427, train_loss = 1.0612648452515714, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 428, train_loss = 1.0597498354618438, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 429, train_loss = 1.058192990720272, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 430, train_loss = 1.0567113210563548, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 431, train_loss = 1.055383042723406, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 432, train_loss = 1.0538712565903552, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 433, train_loss = 1.0524984896183014, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 434, train_loss = 1.0509315033559687, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 435, train_loss = 1.0495012228493579, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 436, train_loss = 1.0481294989585876, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 437, train_loss = 1.0469335268135183, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 438, train_loss = 1.0452921514515765, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 439, train_loss = 1.0440248623490334, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 440, train_loss = 1.0425147277419455, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 441, train_loss = 1.0411287409369834, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 442, train_loss = 1.0398060803418048, train_acc = 0.9981369352585002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 443, train_loss = 1.0385448522865772, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 444, train_loss = 1.0370495903189294, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 445, train_loss = 1.0357692849938758, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 446, train_loss = 1.0344763323664665, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 447, train_loss = 1.0329681200091727, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 448, train_loss = 1.0318655682203826, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 449, train_loss = 1.0303464705648366, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 450, train_loss = 1.0291242425737437, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 451, train_loss = 1.0277279702422675, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 452, train_loss = 1.0264409569499549, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 453, train_loss = 1.025192736327881, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 454, train_loss = 1.023912706732517, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 455, train_loss = 1.022723462432623, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 456, train_loss = 1.0213251796958502, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 457, train_loss = 1.0201584746537264, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 458, train_loss = 1.0188060117361601, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 459, train_loss = 1.0175830212829169, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 460, train_loss = 1.0163070559501648, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 461, train_loss = 1.015091056615347, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 462, train_loss = 1.0138600369391497, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 463, train_loss = 1.0126448695955332, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 464, train_loss = 1.0115192010998726, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 465, train_loss = 1.010161036014324, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 466, train_loss = 1.0089668432774488, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 467, train_loss = 1.0077500343322754, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 468, train_loss = 1.006638372928137, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 469, train_loss = 1.0054065560398158, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 470, train_loss = 1.0041856914758682, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 471, train_loss = 1.0030306031403597, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 472, train_loss = 1.0019793634710368, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 473, train_loss = 1.0007753434183542, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 474, train_loss = 0.9995722485182341, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 475, train_loss = 0.9983771902916487, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 476, train_loss = 0.9972644584777299, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 477, train_loss = 0.996143888682127, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 478, train_loss = 0.9950544983148575, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 479, train_loss = 0.9938306783733424, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 480, train_loss = 0.9928222522139549, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 481, train_loss = 0.99157989397645, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 482, train_loss = 0.990533454954857, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 483, train_loss = 0.989391485840315, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 484, train_loss = 0.9883672309515532, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 485, train_loss = 0.9872461035847664, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 486, train_loss = 0.9860469611885492, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 487, train_loss = 0.9850881608726922, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 488, train_loss = 0.9839258119463921, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 489, train_loss = 0.9828794362547342, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 490, train_loss = 0.9817838010785636, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 491, train_loss = 0.9807514051499311, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 492, train_loss = 0.9796058970096055, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 493, train_loss = 0.9786693379282951, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 494, train_loss = 0.9775906552968081, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 495, train_loss = 0.9764742901024874, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 496, train_loss = 0.9754658105375711, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 497, train_loss = 0.974463939666748, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 498, train_loss = 0.9734782129526138, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 499, train_loss = 0.9724781289696693, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████▎                                              | 10/30 [1:08:05<2:16:48, 410.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "11th- epoch: 0, train_loss = 274.8056355714798, train_acc = 0.40824406148113646\n",
      "test Acc 0.5288640595903166:\n",
      "11th- epoch: 1, train_loss = 210.46363949775696, train_acc = 0.5525151374010246\n",
      "test Acc 0.5707635009310987:\n",
      "11th- epoch: 2, train_loss = 166.20372158288956, train_acc = 0.5724266418258035\n",
      "test Acc 0.5819366852886406:\n",
      "11th- epoch: 3, train_loss = 138.09959250688553, train_acc = 0.6339077782952958\n",
      "test Acc 0.712756052141527:\n",
      "11th- epoch: 4, train_loss = 118.37266832590103, train_acc = 0.7447601304145319\n",
      "test Acc 0.7797951582867784:\n",
      "11th- epoch: 5, train_loss = 102.65136671066284, train_acc = 0.7901723334885887\n",
      "test Acc 0.8105214152700186:\n",
      "11th- epoch: 6, train_loss = 89.6066991686821, train_acc = 0.8118304611085235\n",
      "test Acc 0.8305400372439479:\n",
      "11th- epoch: 7, train_loss = 78.99001547694206, train_acc = 0.8256870051234281\n",
      "test Acc 0.8370577281191807:\n",
      "11th- epoch: 8, train_loss = 70.24752512574196, train_acc = 0.8376804843968327\n",
      "test Acc 0.8547486033519553:\n",
      "11th- epoch: 9, train_loss = 62.87000101804733, train_acc = 0.8591057289240801\n",
      "test Acc 0.87756052141527:\n",
      "11th- epoch: 10, train_loss = 56.560431241989136, train_acc = 0.8868188169538892\n",
      "test Acc 0.8933891992551211:\n",
      "11th- epoch: 11, train_loss = 51.10005974769592, train_acc = 0.9076618537494178\n",
      "test Acc 0.9213221601489758:\n",
      "11th- epoch: 12, train_loss = 46.32746610045433, train_acc = 0.9289706567303214\n",
      "test Acc 0.936219739292365:\n",
      "11th- epoch: 13, train_loss = 42.15230904519558, train_acc = 0.9402654867256637\n",
      "test Acc 0.9408752327746741:\n",
      "11th- epoch: 14, train_loss = 38.51549178361893, train_acc = 0.9470190964136004\n",
      "test Acc 0.9441340782122905:\n",
      "11th- epoch: 15, train_loss = 35.366631634533405, train_acc = 0.9500465766185375\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 16, train_loss = 32.656812489032745, train_acc = 0.952491849091756\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 17, train_loss = 30.32611493766308, train_acc = 0.9544713553795995\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 18, train_loss = 28.31795397400856, train_acc = 0.9563344201210993\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 19, train_loss = 26.582299016416073, train_acc = 0.9574988355845365\n",
      "test Acc 0.9529795158286778:\n",
      "11th- epoch: 20, train_loss = 25.07524225115776, train_acc = 0.9608756404285049\n",
      "test Acc 0.9557728119180633:\n",
      "11th- epoch: 21, train_loss = 23.757208351045847, train_acc = 0.9641360037261295\n",
      "test Acc 0.9562383612662942:\n",
      "11th- epoch: 22, train_loss = 22.59633431583643, train_acc = 0.9666977177456917\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 23, train_loss = 21.56746031343937, train_acc = 0.9678621332091291\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 24, train_loss = 20.648973986506462, train_acc = 0.9692594317652539\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 25, train_loss = 19.824029244482517, train_acc = 0.9701909641360037\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 26, train_loss = 19.078169893473387, train_acc = 0.9707731718677224\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 27, train_loss = 18.399396259337664, train_acc = 0.9715882626921285\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 28, train_loss = 17.77768313884735, train_acc = 0.9726362366092222\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 29, train_loss = 17.205510396510363, train_acc = 0.9731020027945971\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 30, train_loss = 16.676501967012882, train_acc = 0.9731020027945971\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 31, train_loss = 16.185302641242743, train_acc = 0.9733348858872846\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 32, train_loss = 15.726893164217472, train_acc = 0.9733348858872846\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 33, train_loss = 15.297715436667204, train_acc = 0.9734513274336283\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 34, train_loss = 14.895055741071701, train_acc = 0.9735677689799721\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 35, train_loss = 14.51581672206521, train_acc = 0.974033535165347\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 36, train_loss = 14.157288286834955, train_acc = 0.974033535165347\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 37, train_loss = 13.81726735457778, train_acc = 0.974033535165347\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 38, train_loss = 13.494351860135794, train_acc = 0.9746157428970657\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 39, train_loss = 13.187141437083483, train_acc = 0.9750815090824406\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 40, train_loss = 12.89405319467187, train_acc = 0.975314392175128\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 41, train_loss = 12.613791968673468, train_acc = 0.9760130414531905\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 42, train_loss = 12.345456343144178, train_acc = 0.9764788076385654\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 43, train_loss = 12.088089041411877, train_acc = 0.9764788076385654\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 44, train_loss = 11.840693708509207, train_acc = 0.9771774569166278\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 45, train_loss = 11.602706417441368, train_acc = 0.9776432231020028\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 46, train_loss = 11.373768534511328, train_acc = 0.9781089892873778\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 47, train_loss = 11.153102330863476, train_acc = 0.9790405216581276\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 48, train_loss = 10.940290831029415, train_acc = 0.9792734047508151\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 49, train_loss = 10.734773352742195, train_acc = 0.9800884955752213\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 50, train_loss = 10.53605879470706, train_acc = 0.9809035863996274\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 51, train_loss = 10.343716580420732, train_acc = 0.9813693525850024\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 52, train_loss = 10.157392129302025, train_acc = 0.9813693525850024\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 53, train_loss = 9.976776372641325, train_acc = 0.9813693525850024\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 54, train_loss = 9.801663633435965, train_acc = 0.9817186772240335\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 55, train_loss = 9.631589271128178, train_acc = 0.9823008849557522\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 56, train_loss = 9.466702343896031, train_acc = 0.9824173265020959\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 57, train_loss = 9.306437497958541, train_acc = 0.9828830926874709\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 58, train_loss = 9.150783436372876, train_acc = 0.9829995342338146\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 59, train_loss = 8.999163012951612, train_acc = 0.9832324173265021\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 60, train_loss = 8.85164199769497, train_acc = 0.9834653004191896\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 61, train_loss = 8.70805793441832, train_acc = 0.9835817419655333\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 62, train_loss = 8.56799796782434, train_acc = 0.9838146250582208\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 63, train_loss = 8.431531155481935, train_acc = 0.9840475081509082\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 64, train_loss = 8.298449415713549, train_acc = 0.984163949697252\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 65, train_loss = 8.168701061978936, train_acc = 0.9842803912435957\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 66, train_loss = 8.042079655453563, train_acc = 0.9842803912435957\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 67, train_loss = 7.918733837082982, train_acc = 0.9846297158826269\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 68, train_loss = 7.798359831795096, train_acc = 0.9848625989753144\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 69, train_loss = 7.680644096806645, train_acc = 0.9849790405216581\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 70, train_loss = 7.565578646957874, train_acc = 0.9850954820680019\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 71, train_loss = 7.453102741390467, train_acc = 0.9852119236143456\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 72, train_loss = 7.343281449750066, train_acc = 0.985444806707033\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 73, train_loss = 7.235906379297376, train_acc = 0.9856776897997206\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 74, train_loss = 7.130963426083326, train_acc = 0.9857941313460643\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 75, train_loss = 7.028299987316132, train_acc = 0.9861434559850955\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 76, train_loss = 6.927891133353114, train_acc = 0.9871914299021891\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 77, train_loss = 6.829663619399071, train_acc = 0.9873078714485328\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 78, train_loss = 6.7335112523287535, train_acc = 0.9874243129948765\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 79, train_loss = 6.639419302344322, train_acc = 0.9875407545412203\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 80, train_loss = 6.547168616205454, train_acc = 0.9877736376339078\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 81, train_loss = 6.4569954089820385, train_acc = 0.9881229622729389\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 82, train_loss = 6.368600780144334, train_acc = 0.9882394038192828\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 83, train_loss = 6.282098462805152, train_acc = 0.9887051700046576\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 84, train_loss = 6.197293138131499, train_acc = 0.9890544946436889\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 85, train_loss = 6.114180453121662, train_acc = 0.9892873777363763\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 86, train_loss = 6.032706819474697, train_acc = 0.9892873777363763\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 87, train_loss = 5.952857729047537, train_acc = 0.98940381928272\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 88, train_loss = 5.874643664807081, train_acc = 0.9896367023754076\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 89, train_loss = 5.797844467684627, train_acc = 0.9897531439217513\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 90, train_loss = 5.722621530294418, train_acc = 0.9899860270144387\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 91, train_loss = 5.64870354346931, train_acc = 0.9902189101071263\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 92, train_loss = 5.57630648650229, train_acc = 0.9904517931998137\n",
      "test Acc 0.9818435754189944:\n",
      "11th- epoch: 93, train_loss = 5.505185186862946, train_acc = 0.9904517931998137\n",
      "test Acc 0.9813780260707635:\n",
      "11th- epoch: 94, train_loss = 5.435342963784933, train_acc = 0.9904517931998137\n",
      "test Acc 0.9813780260707635:\n",
      "11th- epoch: 95, train_loss = 5.366771647706628, train_acc = 0.9904517931998137\n",
      "test Acc 0.9818435754189944:\n",
      "11th- epoch: 96, train_loss = 5.299507949501276, train_acc = 0.9909175593851887\n",
      "test Acc 0.9823091247672253:\n",
      "11th- epoch: 97, train_loss = 5.233408959582448, train_acc = 0.9910340009315324\n",
      "test Acc 0.9823091247672253:\n",
      "11th- epoch: 98, train_loss = 5.168494388461113, train_acc = 0.9911504424778761\n",
      "test Acc 0.9823091247672253:\n",
      "11th- epoch: 99, train_loss = 5.104658253490925, train_acc = 0.9914997671169073\n",
      "test Acc 0.9823091247672253:\n",
      "11th- epoch: 100, train_loss = 5.042014674283564, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 101, train_loss = 4.9805091340094805, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 102, train_loss = 4.920020089484751, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 103, train_loss = 4.860624345950782, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 104, train_loss = 4.802362769842148, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 105, train_loss = 4.744988995604217, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 106, train_loss = 4.688830914907157, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 107, train_loss = 4.633593167178333, train_acc = 0.9918490917559385\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 108, train_loss = 4.579422756098211, train_acc = 0.9918490917559385\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 109, train_loss = 4.526128361932933, train_acc = 0.9918490917559385\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 110, train_loss = 4.473841053433716, train_acc = 0.9919655333022822\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 111, train_loss = 4.42238484788686, train_acc = 0.9921984163949698\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 112, train_loss = 4.371891559101641, train_acc = 0.9921984163949698\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 113, train_loss = 4.322033767588437, train_acc = 0.9923148579413135\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 114, train_loss = 4.2730301739647985, train_acc = 0.9923148579413135\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 115, train_loss = 4.225006974302232, train_acc = 0.9923148579413135\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 116, train_loss = 4.177782966755331, train_acc = 0.9923148579413135\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 117, train_loss = 4.13140123616904, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 118, train_loss = 4.085770405828953, train_acc = 0.9927806241266884\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 119, train_loss = 4.041011719964445, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 120, train_loss = 3.9968369426205754, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 121, train_loss = 3.9535940466448665, train_acc = 0.9927806241266884\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 122, train_loss = 3.911096013151109, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 123, train_loss = 3.869297116063535, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 124, train_loss = 3.8282134626060724, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 125, train_loss = 3.787841341458261, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 126, train_loss = 3.7481012335047126, train_acc = 0.9931299487657196\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 127, train_loss = 3.7091490970924497, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 128, train_loss = 3.67065844591707, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 129, train_loss = 3.633057371713221, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 130, train_loss = 3.5959335453808308, train_acc = 0.9937121564974383\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 131, train_loss = 3.559393604286015, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 132, train_loss = 3.523650763556361, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 133, train_loss = 3.488251325674355, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 134, train_loss = 3.4535629097372293, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 135, train_loss = 3.419586897827685, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 136, train_loss = 3.385810642503202, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 137, train_loss = 3.3526451969519258, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 138, train_loss = 3.320063194260001, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 139, train_loss = 3.2878488823771477, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 140, train_loss = 3.256252189166844, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 141, train_loss = 3.2251747408881783, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 142, train_loss = 3.1946653882041574, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 143, train_loss = 3.1646100943908095, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 144, train_loss = 3.135075996629894, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 145, train_loss = 3.106001584790647, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 146, train_loss = 3.0773557904176414, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 147, train_loss = 3.049248145893216, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 148, train_loss = 3.0215397900901735, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 149, train_loss = 2.994347205851227, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 150, train_loss = 2.967557007446885, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 151, train_loss = 2.9410937973298132, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 152, train_loss = 2.9151590787805617, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 153, train_loss = 2.8895480916835368, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 154, train_loss = 2.864339849445969, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 155, train_loss = 2.8395540602505207, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 156, train_loss = 2.8152183182537556, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 157, train_loss = 2.791114988271147, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 158, train_loss = 2.7674999237060547, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 159, train_loss = 2.7441535629332066, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 160, train_loss = 2.7212718999944627, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 161, train_loss = 2.69864072650671, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 162, train_loss = 2.676397426519543, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 163, train_loss = 2.6544374539516866, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 164, train_loss = 2.6328546409495175, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 165, train_loss = 2.6115927626378834, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 166, train_loss = 2.5906399828381836, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 167, train_loss = 2.5699666026048362, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 168, train_loss = 2.5497016981244087, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 169, train_loss = 2.5296751554124057, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 170, train_loss = 2.509992465376854, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 171, train_loss = 2.4905917192809284, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 172, train_loss = 2.471494682598859, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 173, train_loss = 2.4526412594132125, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 174, train_loss = 2.434119457844645, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 175, train_loss = 2.4158840947784483, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 176, train_loss = 2.397820123936981, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 177, train_loss = 2.3800824880599976, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 178, train_loss = 2.362599160987884, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 179, train_loss = 2.345430410001427, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 180, train_loss = 2.328427302185446, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 181, train_loss = 2.311763672158122, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 182, train_loss = 2.295159174595028, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 183, train_loss = 2.279012557119131, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 184, train_loss = 2.26295085856691, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 185, train_loss = 2.247307500336319, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "11th- epoch: 186, train_loss = 2.23174279788509, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 187, train_loss = 2.216570395976305, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 188, train_loss = 2.2015918754041195, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 189, train_loss = 2.186797382775694, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 190, train_loss = 2.172360982745886, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 191, train_loss = 2.157994733657688, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 192, train_loss = 2.1439693928696215, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 193, train_loss = 2.130049414932728, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 194, train_loss = 2.1164524033665657, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 195, train_loss = 2.1030112258158624, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 196, train_loss = 2.089765665587038, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 197, train_loss = 2.076772975269705, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 198, train_loss = 2.0638862166088074, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 199, train_loss = 2.0512101117055863, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 200, train_loss = 2.0388012330513448, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 201, train_loss = 2.026556157739833, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 202, train_loss = 2.0145115244667977, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 203, train_loss = 2.002597787650302, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 204, train_loss = 1.990921827731654, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 205, train_loss = 1.9793284449260682, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 206, train_loss = 1.9680155366659164, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 207, train_loss = 1.9568353928625584, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 208, train_loss = 1.945742568699643, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 209, train_loss = 1.9349440101068467, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 210, train_loss = 1.924123102100566, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 211, train_loss = 1.9136797972023487, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 212, train_loss = 1.9032219126820564, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 213, train_loss = 1.8930532149970531, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 214, train_loss = 1.8829720739740878, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 215, train_loss = 1.8730125960428268, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 216, train_loss = 1.8631876818835735, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 217, train_loss = 1.8535194944124669, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 218, train_loss = 1.844033831031993, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 219, train_loss = 1.8345867458265275, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 220, train_loss = 1.8253823544364423, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 221, train_loss = 1.8162311862688512, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 222, train_loss = 1.8072416458744556, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 223, train_loss = 1.7983090088237077, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 224, train_loss = 1.7895491600502282, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 225, train_loss = 1.7809272750746459, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 226, train_loss = 1.7724046565126628, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 227, train_loss = 1.7639462382066995, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 228, train_loss = 1.755625108955428, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 229, train_loss = 1.7475115780252963, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 230, train_loss = 1.7394266065675765, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 231, train_loss = 1.7314283289015293, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 232, train_loss = 1.7235021963715553, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 233, train_loss = 1.7157373453956097, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 234, train_loss = 1.7080325484275818, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 235, train_loss = 1.700448392657563, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 236, train_loss = 1.6929787658154964, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 237, train_loss = 1.6855223153252155, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 238, train_loss = 1.6782492871861905, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 239, train_loss = 1.6710542179644108, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 240, train_loss = 1.66391592589207, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 241, train_loss = 1.6568498450797051, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 242, train_loss = 1.649938226910308, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 243, train_loss = 1.6430694709997624, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 244, train_loss = 1.6362194281537086, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 245, train_loss = 1.6295486092567444, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 246, train_loss = 1.6228788197040558, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 247, train_loss = 1.616347275674343, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 248, train_loss = 1.6098689448554069, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 249, train_loss = 1.6035243310034275, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 250, train_loss = 1.5971589770633727, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 251, train_loss = 1.5908991310279816, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 252, train_loss = 1.5847260665614158, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 253, train_loss = 1.578622619388625, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 254, train_loss = 1.5725631404202431, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 255, train_loss = 1.5665993230650201, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 256, train_loss = 1.560703344643116, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 257, train_loss = 1.5548739855876192, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 258, train_loss = 1.5491347374627367, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 259, train_loss = 1.5434647165238857, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 260, train_loss = 1.5376906333258376, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 261, train_loss = 1.532232136814855, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 262, train_loss = 1.5265991588821635, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 263, train_loss = 1.5211859667906538, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 264, train_loss = 1.5157595885684714, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 265, train_loss = 1.5104006392648444, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 266, train_loss = 1.5050807358929887, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 267, train_loss = 1.4999134739628062, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 268, train_loss = 1.4945856122067198, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 269, train_loss = 1.4895222820341587, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 270, train_loss = 1.4845166938612238, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 271, train_loss = 1.4794668356189504, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 272, train_loss = 1.4745285274693742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 273, train_loss = 1.469526675879024, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 274, train_loss = 1.4647534936666489, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 275, train_loss = 1.4599625741830096, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 276, train_loss = 1.4551810435950756, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 277, train_loss = 1.4504664776613936, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 278, train_loss = 1.4458275599172339, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 279, train_loss = 1.441203746944666, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 280, train_loss = 1.4366811998188496, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 281, train_loss = 1.4321120170643553, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 282, train_loss = 1.4276534505188465, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 283, train_loss = 1.4232489032438025, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 284, train_loss = 1.4188425118336454, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 285, train_loss = 1.4144820546498522, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 286, train_loss = 1.4102027019253, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 287, train_loss = 1.4059678924968466, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 288, train_loss = 1.4017057679593563, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 289, train_loss = 1.3975404538214207, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 290, train_loss = 1.3935012556612492, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 291, train_loss = 1.3893627958605066, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 292, train_loss = 1.3853094378719106, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 293, train_loss = 1.3812870109686628, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 294, train_loss = 1.3773236125707626, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 295, train_loss = 1.3733877142658457, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 296, train_loss = 1.3694402104010805, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 297, train_loss = 1.3655375441303477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 298, train_loss = 1.3618256399640813, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 299, train_loss = 1.3579650794854388, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 300, train_loss = 1.3541754819452763, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 301, train_loss = 1.3505218625068665, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 302, train_loss = 1.3467677483567968, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 303, train_loss = 1.3431269290158525, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 304, train_loss = 1.339478511363268, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 305, train_loss = 1.335948470979929, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 306, train_loss = 1.332338836044073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 307, train_loss = 1.3287222037324682, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 308, train_loss = 1.3253723680973053, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 309, train_loss = 1.3218100741505623, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 310, train_loss = 1.3183861983707175, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 311, train_loss = 1.314947672188282, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 312, train_loss = 1.3116060631582513, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 313, train_loss = 1.308247713954188, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 314, train_loss = 1.305009396164678, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 315, train_loss = 1.301585822016932, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 316, train_loss = 1.2983458092203364, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 317, train_loss = 1.2951473878929392, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 318, train_loss = 1.2919407673180103, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 319, train_loss = 1.288624274195172, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 320, train_loss = 1.2856254739454016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 321, train_loss = 1.2824333881726488, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 322, train_loss = 1.2792847430100664, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 323, train_loss = 1.2762765834340826, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 324, train_loss = 1.2732057323446497, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 325, train_loss = 1.2701495526125655, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 326, train_loss = 1.2672175168991089, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 327, train_loss = 1.26423839724157, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 328, train_loss = 1.261292097507976, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 329, train_loss = 1.2584308063378558, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 330, train_loss = 1.2554861108073965, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 331, train_loss = 1.2525800255825743, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 332, train_loss = 1.2498765276977792, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 333, train_loss = 1.2469704014947638, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 334, train_loss = 1.2441875139484182, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 335, train_loss = 1.241431011527311, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 336, train_loss = 1.2386122432653792, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 337, train_loss = 1.23583421605872, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 338, train_loss = 1.233292589604389, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 339, train_loss = 1.2304773392970674, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 340, train_loss = 1.227884764492046, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 341, train_loss = 1.225246648013126, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 342, train_loss = 1.2225970029830933, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 343, train_loss = 1.2199375207419507, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 344, train_loss = 1.2174105371232145, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 345, train_loss = 1.214786006778013, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 346, train_loss = 1.2122405345435254, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 347, train_loss = 1.2097423411905766, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 348, train_loss = 1.2072442695498466, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 349, train_loss = 1.204710756719578, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 350, train_loss = 1.2023709031636827, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 351, train_loss = 1.199794877320528, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 352, train_loss = 1.197358461737167, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 353, train_loss = 1.1950479100341909, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 354, train_loss = 1.1925810153479688, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 355, train_loss = 1.1902014054358006, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 356, train_loss = 1.1878464358742349, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 357, train_loss = 1.1855239545111544, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 358, train_loss = 1.1831602255697362, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 359, train_loss = 1.1809197503025644, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 360, train_loss = 1.178675560920965, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 361, train_loss = 1.1762800440192223, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 362, train_loss = 1.1740747417206876, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 363, train_loss = 1.1718963347375393, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 364, train_loss = 1.1695958549971692, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 365, train_loss = 1.1673511117696762, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 366, train_loss = 1.1652464630897157, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 367, train_loss = 1.1630262273247354, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 368, train_loss = 1.1608380663092248, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 369, train_loss = 1.1587054319679737, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 370, train_loss = 1.1566766425967216, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 371, train_loss = 1.154503233730793, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 372, train_loss = 1.1523867298965342, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 373, train_loss = 1.1502737614209764, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 374, train_loss = 1.1483238587970845, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 375, train_loss = 1.1460725329816341, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 376, train_loss = 1.1441360960598104, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 377, train_loss = 1.1420644621248357, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 378, train_loss = 1.1401669519837014, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 379, train_loss = 1.1380598942632787, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 380, train_loss = 1.1360912856762297, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 381, train_loss = 1.1341239933972247, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 382, train_loss = 1.1322692409157753, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 383, train_loss = 1.130212680727709, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 384, train_loss = 1.128293003886938, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 385, train_loss = 1.1263122360105626, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 386, train_loss = 1.12454579398036, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 387, train_loss = 1.1225468615884893, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 388, train_loss = 1.1206551703508012, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 389, train_loss = 1.1187969967722893, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 390, train_loss = 1.1169713959097862, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 391, train_loss = 1.1151603199541569, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 392, train_loss = 1.1133218233590014, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 393, train_loss = 1.1114796536858194, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 394, train_loss = 1.109647634148132, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 395, train_loss = 1.107886616140604, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 396, train_loss = 1.1061362400650978, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 397, train_loss = 1.1042810293729417, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 398, train_loss = 1.1025477846269496, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 399, train_loss = 1.100744402676355, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 400, train_loss = 1.09910774853779, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 401, train_loss = 1.0972791885142215, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 402, train_loss = 1.0955584633047692, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 403, train_loss = 1.093873281031847, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 404, train_loss = 1.0921900893445127, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 405, train_loss = 1.0904083351488225, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 406, train_loss = 1.0888970717787743, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 407, train_loss = 1.0870873779058456, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 408, train_loss = 1.0855164267122746, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 409, train_loss = 1.083818156272173, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 410, train_loss = 1.0821149162948132, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 411, train_loss = 1.0807823252980597, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 412, train_loss = 1.078980017453432, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 413, train_loss = 1.0773402117192745, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 414, train_loss = 1.0758111402392387, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 415, train_loss = 1.0742332388763316, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 416, train_loss = 1.0726431694929488, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 417, train_loss = 1.0711442318861373, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 418, train_loss = 1.0694421281223185, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 419, train_loss = 1.067968179762829, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 420, train_loss = 1.0665181279182434, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 421, train_loss = 1.064985549717676, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 422, train_loss = 1.0634153832797892, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 423, train_loss = 1.0618569130892865, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 424, train_loss = 1.060374182939995, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 425, train_loss = 1.0590212494134903, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 426, train_loss = 1.0574936270713806, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 427, train_loss = 1.056015022099018, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 428, train_loss = 1.0544619522988796, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 429, train_loss = 1.052938902110327, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 430, train_loss = 1.051660243421793, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 431, train_loss = 1.0502038833801635, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 432, train_loss = 1.048712256073486, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 433, train_loss = 1.0472412618692033, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 434, train_loss = 1.0458444629912265, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 435, train_loss = 1.0444621319766156, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 436, train_loss = 1.0430491976439953, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 437, train_loss = 1.041695301712025, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 438, train_loss = 1.0403602582518943, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 439, train_loss = 1.038920568942558, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 440, train_loss = 1.0375066709821112, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 441, train_loss = 1.0362503242795356, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 442, train_loss = 1.0348213501274586, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 443, train_loss = 1.0334958036546595, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 444, train_loss = 1.0321329608559608, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 445, train_loss = 1.030811486125458, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 446, train_loss = 1.0295933063025586, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 447, train_loss = 1.028176549822092, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 448, train_loss = 1.0268741995096207, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 449, train_loss = 1.0256018203799613, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 450, train_loss = 1.0243029345874675, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 451, train_loss = 1.02295357856201, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 452, train_loss = 1.0217154920101166, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 453, train_loss = 1.0204774041776545, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 454, train_loss = 1.0191639314289205, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 455, train_loss = 1.0179284488258418, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 456, train_loss = 1.016712694108719, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 457, train_loss = 1.0155406035482883, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 458, train_loss = 1.0141702530381735, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 459, train_loss = 1.0129780384304468, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 460, train_loss = 1.0116925475595053, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 461, train_loss = 1.0104815339145716, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 462, train_loss = 1.0093575107457582, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 463, train_loss = 1.0080943951907102, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 464, train_loss = 1.0069705868663732, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 465, train_loss = 1.0057807440462057, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 466, train_loss = 1.0044724059698638, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 467, train_loss = 1.0034227830765303, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 468, train_loss = 1.0021494465472642, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 469, train_loss = 1.000970912486082, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 470, train_loss = 0.9998826409282628, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 471, train_loss = 0.9986738041043282, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 472, train_loss = 0.9975103127362672, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 473, train_loss = 0.9964580858650152, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 474, train_loss = 0.9952511228621006, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 475, train_loss = 0.9940921415982302, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 476, train_loss = 0.9930692426860332, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 477, train_loss = 0.99189162752009, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 478, train_loss = 0.990739685803419, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 479, train_loss = 0.9897597171366215, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 480, train_loss = 0.9885204707679804, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 481, train_loss = 0.9874698457715567, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 482, train_loss = 0.986395181476837, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 483, train_loss = 0.9852821864187717, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 484, train_loss = 0.9841437377035618, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 485, train_loss = 0.9830909209849779, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 486, train_loss = 0.9820108525454998, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 487, train_loss = 0.9810266991553362, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 488, train_loss = 0.9799223815498408, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 489, train_loss = 0.978763493389124, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 490, train_loss = 0.9777484089136124, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 491, train_loss = 0.9767724946141243, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 492, train_loss = 0.975697190820938, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 493, train_loss = 0.9746964561345521, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 494, train_loss = 0.9735689473745879, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 495, train_loss = 0.9727013036608696, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 496, train_loss = 0.9716186647710856, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 497, train_loss = 0.9706320253608283, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 498, train_loss = 0.9695456860063132, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 499, train_loss = 0.9685389809310436, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████▋                                            | 11/30 [1:14:57<2:10:10, 411.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "12th- epoch: 0, train_loss = 273.1527338027954, train_acc = 0.4693758733115976\n",
      "test Acc 0.5279329608938548:\n",
      "12th- epoch: 1, train_loss = 208.6258351802826, train_acc = 0.5534466697717746\n",
      "test Acc 0.5707635009310987:\n",
      "12th- epoch: 2, train_loss = 160.71232748031616, train_acc = 0.5839543549138333\n",
      "test Acc 0.62756052141527:\n",
      "12th- epoch: 3, train_loss = 133.4271919131279, train_acc = 0.6828132277596647\n",
      "test Acc 0.7462756052141527:\n",
      "12th- epoch: 4, train_loss = 114.30802100896835, train_acc = 0.7590824406148113\n",
      "test Acc 0.7783985102420856:\n",
      "12th- epoch: 5, train_loss = 99.36298787593842, train_acc = 0.7750349324639031\n",
      "test Acc 0.7951582867783985:\n",
      "12th- epoch: 6, train_loss = 87.29926657676697, train_acc = 0.7955286446204005\n",
      "test Acc 0.818901303538175:\n",
      "12th- epoch: 7, train_loss = 77.45396390557289, train_acc = 0.8195156031672101\n",
      "test Acc 0.8421787709497207:\n",
      "12th- epoch: 8, train_loss = 69.10048314929008, train_acc = 0.8453656264555194\n",
      "test Acc 0.8691806331471136:\n",
      "12th- epoch: 9, train_loss = 61.79690317809582, train_acc = 0.8757568700512343\n",
      "test Acc 0.8943202979515829:\n",
      "12th- epoch: 10, train_loss = 55.35401074588299, train_acc = 0.9005589194224499\n",
      "test Acc 0.9152700186219739:\n",
      "12th- epoch: 11, train_loss = 49.71949255466461, train_acc = 0.9218677224033535\n",
      "test Acc 0.9329608938547486:\n",
      "12th- epoch: 12, train_loss = 44.85209982097149, train_acc = 0.9389846297158826\n",
      "test Acc 0.9380819366852886:\n",
      "12th- epoch: 13, train_loss = 40.68618796765804, train_acc = 0.9432929669306008\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 14, train_loss = 37.139528401196, train_acc = 0.9472519795062878\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 15, train_loss = 34.127050928771496, train_acc = 0.9500465766185375\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 16, train_loss = 31.56675234436989, train_acc = 0.9522589659990685\n",
      "test Acc 0.9492551210428305:\n",
      "12th- epoch: 17, train_loss = 29.384639389812946, train_acc = 0.9542384722869119\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 18, train_loss = 27.51433727145195, train_acc = 0.9566837447601304\n",
      "test Acc 0.9548417132216015:\n",
      "12th- epoch: 19, train_loss = 25.90273290872574, train_acc = 0.9600605496040987\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 20, train_loss = 24.50387991964817, train_acc = 0.9633209129017233\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 21, train_loss = 23.280766505748034, train_acc = 0.9657661853749417\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 22, train_loss = 22.202691309154034, train_acc = 0.9675128085700978\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 23, train_loss = 21.245223958045244, train_acc = 0.9684443409408477\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 24, train_loss = 20.388624470680952, train_acc = 0.9692594317652539\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 25, train_loss = 19.615937888622284, train_acc = 0.9699580810433163\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 26, train_loss = 18.913794443011284, train_acc = 0.9704238472286912\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 27, train_loss = 18.272130772471428, train_acc = 0.9711224965067536\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 28, train_loss = 17.68181288614869, train_acc = 0.971821145784816\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 29, train_loss = 17.135819353163242, train_acc = 0.9721704704238472\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 30, train_loss = 16.62911805137992, train_acc = 0.9725197950628784\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 31, train_loss = 16.156773943454027, train_acc = 0.9734513274336283\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 32, train_loss = 15.714837569743395, train_acc = 0.9739170936190032\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 33, train_loss = 15.300054538995028, train_acc = 0.9742664182580345\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 34, train_loss = 14.90924697369337, train_acc = 0.9746157428970657\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 35, train_loss = 14.539774533361197, train_acc = 0.9749650675360969\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 36, train_loss = 14.189854558557272, train_acc = 0.9754308337214718\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 37, train_loss = 13.85760160535574, train_acc = 0.9756637168141593\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 38, train_loss = 13.541110500693321, train_acc = 0.9761294829995343\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 39, train_loss = 13.239054646342993, train_acc = 0.9763623660922217\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 40, train_loss = 12.949997961521149, train_acc = 0.9765952491849091\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 41, train_loss = 12.672795290127397, train_acc = 0.9770610153702841\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 42, train_loss = 12.406573420390487, train_acc = 0.9772938984629715\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 43, train_loss = 12.150246284902096, train_acc = 0.9777596646483465\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 44, train_loss = 11.903381001204252, train_acc = 0.977992547741034\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 45, train_loss = 11.665464276447892, train_acc = 0.9782254308337215\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 46, train_loss = 11.435945140197873, train_acc = 0.9785747554727526\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 47, train_loss = 11.214315367862582, train_acc = 0.9792734047508151\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 48, train_loss = 11.000446958467364, train_acc = 0.9793898462971589\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 49, train_loss = 10.793885016813874, train_acc = 0.97973917093619\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 50, train_loss = 10.593575393781066, train_acc = 0.980204937121565\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 51, train_loss = 10.399396093562245, train_acc = 0.9803213786679087\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 52, train_loss = 10.210921216756105, train_acc = 0.9805542617605962\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 53, train_loss = 10.027952771633863, train_acc = 0.9811364694923148\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 54, train_loss = 9.850280813872814, train_acc = 0.9816022356776898\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 55, train_loss = 9.678066061809659, train_acc = 0.9823008849557522\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 56, train_loss = 9.5106449034065, train_acc = 0.9824173265020959\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 57, train_loss = 9.347830405458808, train_acc = 0.9825337680484397\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 58, train_loss = 9.189444065093994, train_acc = 0.9826502095947834\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 59, train_loss = 9.035501865670085, train_acc = 0.9829995342338146\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 60, train_loss = 8.885723868384957, train_acc = 0.9833488588728458\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 61, train_loss = 8.739857474341989, train_acc = 0.9834653004191896\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 62, train_loss = 8.598047740757465, train_acc = 0.983698183511877\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 63, train_loss = 8.459909707307816, train_acc = 0.984163949697252\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 64, train_loss = 8.325424136593938, train_acc = 0.984163949697252\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 65, train_loss = 8.194367583841085, train_acc = 0.9843968327899395\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 66, train_loss = 8.06662131845951, train_acc = 0.9847461574289706\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 67, train_loss = 7.942042039707303, train_acc = 0.9850954820680019\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 68, train_loss = 7.820691043511033, train_acc = 0.9853283651606893\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 69, train_loss = 7.7023765705525875, train_acc = 0.9856776897997206\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 70, train_loss = 7.586995987221599, train_acc = 0.985910572892408\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 71, train_loss = 7.4743877444416285, train_acc = 0.9862598975314392\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 72, train_loss = 7.364538408815861, train_acc = 0.9862598975314392\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 73, train_loss = 7.257348895072937, train_acc = 0.9862598975314392\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 74, train_loss = 7.15257978066802, train_acc = 0.986376339077783\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 75, train_loss = 7.050111532211304, train_acc = 0.9867256637168141\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 76, train_loss = 6.949794402346015, train_acc = 0.9867256637168141\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 77, train_loss = 6.851578712463379, train_acc = 0.9871914299021891\n",
      "test Acc 0.9799813780260708:\n",
      "12th- epoch: 78, train_loss = 6.755487849935889, train_acc = 0.9875407545412203\n",
      "test Acc 0.9799813780260708:\n",
      "12th- epoch: 79, train_loss = 6.661534750834107, train_acc = 0.9878900791802515\n",
      "test Acc 0.9799813780260708:\n",
      "12th- epoch: 80, train_loss = 6.569564500823617, train_acc = 0.9880065207265952\n",
      "test Acc 0.9799813780260708:\n",
      "12th- epoch: 81, train_loss = 6.479412827640772, train_acc = 0.9881229622729389\n",
      "test Acc 0.9804469273743017:\n",
      "12th- epoch: 82, train_loss = 6.391057223081589, train_acc = 0.9881229622729389\n",
      "test Acc 0.9804469273743017:\n",
      "12th- epoch: 83, train_loss = 6.304356445558369, train_acc = 0.9881229622729389\n",
      "test Acc 0.9799813780260708:\n",
      "12th- epoch: 84, train_loss = 6.21957245003432, train_acc = 0.9884722869119702\n",
      "test Acc 0.9799813780260708:\n",
      "12th- epoch: 85, train_loss = 6.136481045745313, train_acc = 0.9888216115510013\n",
      "test Acc 0.9799813780260708:\n",
      "12th- epoch: 86, train_loss = 6.054897089488804, train_acc = 0.9891709361900326\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 87, train_loss = 5.975068093277514, train_acc = 0.9892873777363763\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 88, train_loss = 5.896754185669124, train_acc = 0.9895202608290639\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 89, train_loss = 5.819986253976822, train_acc = 0.989869585468095\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 90, train_loss = 5.744529819115996, train_acc = 0.989869585468095\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 91, train_loss = 5.670570535585284, train_acc = 0.9901024685607824\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 92, train_loss = 5.5978326527401805, train_acc = 0.99033535165347\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 93, train_loss = 5.526436338201165, train_acc = 0.9905682347461574\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 94, train_loss = 5.456334521062672, train_acc = 0.9906846762925011\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 95, train_loss = 5.387520653195679, train_acc = 0.9911504424778761\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 96, train_loss = 5.319849904626608, train_acc = 0.9912668840242198\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 97, train_loss = 5.253391379490495, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 98, train_loss = 5.18809190671891, train_acc = 0.9914997671169073\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 99, train_loss = 5.123841106891632, train_acc = 0.9914997671169073\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 100, train_loss = 5.060890017077327, train_acc = 0.9916162086632511\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 101, train_loss = 4.9988008281216025, train_acc = 0.9916162086632511\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 102, train_loss = 4.937836488708854, train_acc = 0.9917326502095948\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 103, train_loss = 4.8777778604999185, train_acc = 0.9917326502095948\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 104, train_loss = 4.818664352409542, train_acc = 0.992081974848626\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 105, train_loss = 4.760626971721649, train_acc = 0.992081974848626\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 106, train_loss = 4.703564123250544, train_acc = 0.9921984163949698\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 107, train_loss = 4.647428742609918, train_acc = 0.9923148579413135\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 108, train_loss = 4.592226102016866, train_acc = 0.9924312994876572\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 109, train_loss = 4.538017774000764, train_acc = 0.9924312994876572\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 110, train_loss = 4.484686512500048, train_acc = 0.9924312994876572\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 111, train_loss = 4.432187621481717, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 112, train_loss = 4.380650734528899, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 113, train_loss = 4.330045588314533, train_acc = 0.9925477410340009\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 114, train_loss = 4.280089347623289, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 115, train_loss = 4.231083636172116, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 116, train_loss = 4.182878375984728, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 117, train_loss = 4.135508781298995, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 118, train_loss = 4.088939270935953, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 119, train_loss = 4.0431087911129, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 120, train_loss = 3.9980547530576587, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 121, train_loss = 3.9536622865125537, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 122, train_loss = 3.909996695816517, train_acc = 0.9928970656730322\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 123, train_loss = 3.867051483131945, train_acc = 0.9931299487657196\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 124, train_loss = 3.824763326905668, train_acc = 0.9931299487657196\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 125, train_loss = 3.783122051972896, train_acc = 0.9932463903120633\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 126, train_loss = 3.742236337158829, train_acc = 0.9933628318584071\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 127, train_loss = 3.7019027303904295, train_acc = 0.9935957149510946\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 128, train_loss = 3.6623760326765478, train_acc = 0.9935957149510946\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 129, train_loss = 3.6234528217464685, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 130, train_loss = 3.585061244200915, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 131, train_loss = 3.5474023669958115, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 132, train_loss = 3.510225518140942, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 133, train_loss = 3.4737248267047107, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 134, train_loss = 3.4378021149896085, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 135, train_loss = 3.4024999705143273, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 136, train_loss = 3.36780841415748, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 137, train_loss = 3.3336898423731327, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 138, train_loss = 3.3001658520661294, train_acc = 0.9944108057755007\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 139, train_loss = 3.2671086131595075, train_acc = 0.9944108057755007\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 140, train_loss = 3.234711453318596, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 141, train_loss = 3.202815809752792, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 142, train_loss = 3.1714179911650717, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 143, train_loss = 3.140721100848168, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 144, train_loss = 3.1103176339529455, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 145, train_loss = 3.080521233845502, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 146, train_loss = 3.0512348730117083, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 147, train_loss = 3.0224645123817027, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 148, train_loss = 2.9941709586419165, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 149, train_loss = 2.966379168909043, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 150, train_loss = 2.9390061981976032, train_acc = 0.9952258965999069\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 151, train_loss = 2.912144923582673, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 152, train_loss = 2.885654505342245, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 153, train_loss = 2.859746051952243, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 154, train_loss = 2.83409458771348, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 155, train_loss = 2.809002436697483, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 156, train_loss = 2.7841383651830256, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 157, train_loss = 2.7598743848502636, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 158, train_loss = 2.735974022652954, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 159, train_loss = 2.7124515189789236, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 160, train_loss = 2.689364279154688, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 161, train_loss = 2.666622960474342, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 162, train_loss = 2.644335883203894, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 163, train_loss = 2.622435254510492, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 164, train_loss = 2.600856177508831, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 165, train_loss = 2.579610229935497, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 166, train_loss = 2.558715267572552, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 167, train_loss = 2.538233259227127, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 168, train_loss = 2.518011933658272, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 169, train_loss = 2.498235374689102, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 170, train_loss = 2.4786790260113776, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 171, train_loss = 2.459538874682039, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 172, train_loss = 2.4406599975191057, train_acc = 0.9962738705170004\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 173, train_loss = 2.4221745852846652, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 174, train_loss = 2.4038914765696973, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 175, train_loss = 2.385963086038828, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 176, train_loss = 2.3683876991271973, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 177, train_loss = 2.3509588974993676, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 178, train_loss = 2.333892076043412, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 179, train_loss = 2.3171469022054225, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 180, train_loss = 2.3005267456173897, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 181, train_loss = 2.284392536850646, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 182, train_loss = 2.2683100786525756, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 183, train_loss = 2.2525505758821964, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 184, train_loss = 2.2370709653478116, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 185, train_loss = 2.2218001869041473, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 186, train_loss = 2.206855262396857, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 187, train_loss = 2.1919670552015305, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 188, train_loss = 2.177515098126605, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 189, train_loss = 2.1630967173259705, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 190, train_loss = 2.148993119597435, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 191, train_loss = 2.135106296511367, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 192, train_loss = 2.121372665045783, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 193, train_loss = 2.107842656550929, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 194, train_loss = 2.0945404656231403, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 195, train_loss = 2.0814393397886306, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 196, train_loss = 2.0685201671440154, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 197, train_loss = 2.055778853595257, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 198, train_loss = 2.0432871531229466, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 199, train_loss = 2.0309703696984798, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 200, train_loss = 2.018801183672622, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 201, train_loss = 2.006813757121563, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 202, train_loss = 1.9949410718400031, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 203, train_loss = 1.983331486582756, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 204, train_loss = 1.9718124493956566, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 205, train_loss = 1.9605243988335133, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 206, train_loss = 1.9492990162689239, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 207, train_loss = 1.938297063112259, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 208, train_loss = 1.927467219531536, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 209, train_loss = 1.9167745870072395, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 210, train_loss = 1.9062456276733428, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 211, train_loss = 1.8958073146641254, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 212, train_loss = 1.8855777580756694, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 213, train_loss = 1.8754700075369328, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 214, train_loss = 1.8654530011117458, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 215, train_loss = 1.8556794587057084, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 216, train_loss = 1.8459938478190452, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 217, train_loss = 1.836487453430891, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 218, train_loss = 1.827000907389447, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 219, train_loss = 1.8177641481161118, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 220, train_loss = 1.8086133487522602, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 221, train_loss = 1.7995978717226535, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 222, train_loss = 1.7907099712174386, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 223, train_loss = 1.7818523086607456, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 224, train_loss = 1.7733569841366261, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 225, train_loss = 1.7647735986392945, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 226, train_loss = 1.7563165239989758, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 227, train_loss = 1.7480466403067112, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 228, train_loss = 1.739904941408895, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 229, train_loss = 1.731764646829106, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 230, train_loss = 1.7238331834087148, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 231, train_loss = 1.7159765176475048, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 232, train_loss = 1.7081497497856617, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 233, train_loss = 1.7005378603935242, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 234, train_loss = 1.6929110897472128, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 235, train_loss = 1.6854258589446545, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 236, train_loss = 1.6780430873623118, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 237, train_loss = 1.67079448455479, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 238, train_loss = 1.6635383715620264, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 239, train_loss = 1.6564358113100752, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 240, train_loss = 1.649441716610454, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 241, train_loss = 1.6424733897438273, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 242, train_loss = 1.6356616789707914, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 243, train_loss = 1.6288989906897768, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 244, train_loss = 1.6222570153186098, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 245, train_loss = 1.615688931196928, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 246, train_loss = 1.6091259891400114, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 247, train_loss = 1.6026822999119759, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 248, train_loss = 1.596383061259985, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 249, train_loss = 1.5900867296149954, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 250, train_loss = 1.5838661268353462, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 251, train_loss = 1.5778112933039665, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 252, train_loss = 1.5716977715492249, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 253, train_loss = 1.5656518191099167, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 254, train_loss = 1.5598459703614935, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 255, train_loss = 1.55397702625487, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 256, train_loss = 1.548160438775085, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 257, train_loss = 1.5424602528801188, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 258, train_loss = 1.536848052055575, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 259, train_loss = 1.531195491552353, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 260, train_loss = 1.5257441500434652, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 261, train_loss = 1.5202463157474995, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 262, train_loss = 1.5148426046362147, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 263, train_loss = 1.5095062088221312, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 264, train_loss = 1.5042497931281105, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 265, train_loss = 1.4989612264325842, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 266, train_loss = 1.493824366480112, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 267, train_loss = 1.488774316967465, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 268, train_loss = 1.4836684688925743, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 269, train_loss = 1.478616108535789, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 270, train_loss = 1.4737229980528355, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 271, train_loss = 1.46877144894097, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 272, train_loss = 1.4639657152583823, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 273, train_loss = 1.4592109074583277, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 274, train_loss = 1.4544394314289093, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 275, train_loss = 1.4497179178288206, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 276, train_loss = 1.4450549632310867, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 277, train_loss = 1.4404647374758497, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 278, train_loss = 1.4359580278396606, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 279, train_loss = 1.431421191780828, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 280, train_loss = 1.4269714219262823, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 281, train_loss = 1.4225280918180943, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 282, train_loss = 1.418163629830815, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 283, train_loss = 1.4138088537147269, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 284, train_loss = 1.4095015289494768, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 285, train_loss = 1.4053445383906364, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 286, train_loss = 1.4010677946498618, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 287, train_loss = 1.3969229100039229, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 288, train_loss = 1.392847822397016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 289, train_loss = 1.3887173049151897, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 290, train_loss = 1.3846137089421973, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 291, train_loss = 1.3806953566381708, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 292, train_loss = 1.3766931755235419, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 293, train_loss = 1.3727385377278551, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 294, train_loss = 1.3688998905709013, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 295, train_loss = 1.3649364622542635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 296, train_loss = 1.3611364202806726, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 297, train_loss = 1.357450100244023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 298, train_loss = 1.353581034927629, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 299, train_loss = 1.3498894249787554, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 300, train_loss = 1.3462337677483447, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 301, train_loss = 1.342557632655371, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 302, train_loss = 1.3388980788295157, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 303, train_loss = 1.3353234765236266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 304, train_loss = 1.3317746979300864, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 305, train_loss = 1.3282973815803416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 306, train_loss = 1.324723461002577, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 307, train_loss = 1.321278028190136, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 308, train_loss = 1.3178605387802236, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 309, train_loss = 1.3145245015621185, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 310, train_loss = 1.3111008790438063, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 311, train_loss = 1.3078002358670346, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 312, train_loss = 1.3044501841068268, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 313, train_loss = 1.301186225085985, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 314, train_loss = 1.29795042675687, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 315, train_loss = 1.2947258588974364, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 316, train_loss = 1.2914332735235803, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 317, train_loss = 1.288431269407738, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 318, train_loss = 1.2851659692823887, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 319, train_loss = 1.282016923010815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 320, train_loss = 1.2789834973518737, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 321, train_loss = 1.2759965534205548, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 322, train_loss = 1.2728092546458356, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 323, train_loss = 1.2698685924406163, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 324, train_loss = 1.2668573061819188, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 325, train_loss = 1.263889028399717, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 326, train_loss = 1.260974412143696, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 327, train_loss = 1.2580097678001039, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 328, train_loss = 1.2551195013220422, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 329, train_loss = 1.2523220379953273, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 330, train_loss = 1.2494656977360137, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 331, train_loss = 1.2465678416192532, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 332, train_loss = 1.2437956668436527, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 333, train_loss = 1.240979439287912, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 334, train_loss = 1.238156730949413, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 335, train_loss = 1.2354839481413364, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 336, train_loss = 1.2328269357676618, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 337, train_loss = 1.2299975653295405, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 338, train_loss = 1.2273124406929128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 339, train_loss = 1.2247173935174942, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 340, train_loss = 1.2219974373583682, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 341, train_loss = 1.2193328030407429, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 342, train_loss = 1.2168150494690053, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 343, train_loss = 1.214206624776125, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 344, train_loss = 1.211705420166254, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 345, train_loss = 1.2090965546667576, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 346, train_loss = 1.2065986494417302, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 347, train_loss = 1.2041198164224625, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 348, train_loss = 1.2015886716544628, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 349, train_loss = 1.1991393094067462, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 350, train_loss = 1.1967398251290433, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 351, train_loss = 1.1942629205877893, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 352, train_loss = 1.1919884569942951, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 353, train_loss = 1.189532385498751, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 354, train_loss = 1.187185148417484, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 355, train_loss = 1.1847854380612262, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 356, train_loss = 1.1825196246500127, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 357, train_loss = 1.1802260118420236, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 358, train_loss = 1.177848109335173, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 359, train_loss = 1.1756622157990932, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 360, train_loss = 1.1734438774292357, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 361, train_loss = 1.1710696195368655, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 362, train_loss = 1.1689224690198898, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 363, train_loss = 1.1667798918788321, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 364, train_loss = 1.1644920694525354, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 365, train_loss = 1.1622888160054572, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 366, train_loss = 1.1601594015955925, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 367, train_loss = 1.1580534887616523, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 368, train_loss = 1.155865001201164, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 369, train_loss = 1.1538260604138486, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 370, train_loss = 1.1516574558918364, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 371, train_loss = 1.1495608314871788, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 372, train_loss = 1.1475520680542104, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 373, train_loss = 1.1454341945354827, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 374, train_loss = 1.1434572264552116, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 375, train_loss = 1.1413628819282167, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 376, train_loss = 1.139438020705711, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 377, train_loss = 1.137332382320892, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 378, train_loss = 1.1354613763396628, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 379, train_loss = 1.133422575891018, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 380, train_loss = 1.1314020206336863, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 381, train_loss = 1.1294927981798537, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 382, train_loss = 1.127632764459122, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 383, train_loss = 1.1256212356383912, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 384, train_loss = 1.1238064083154313, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 385, train_loss = 1.1218369516427629, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 386, train_loss = 1.119932531088125, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 387, train_loss = 1.118133029609453, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 388, train_loss = 1.1162817354197614, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 389, train_loss = 1.1143701511318795, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 390, train_loss = 1.1126073288614862, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 391, train_loss = 1.1107471858267672, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 392, train_loss = 1.1089234538376331, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 393, train_loss = 1.1071078578825109, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 394, train_loss = 1.1053775722975843, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 395, train_loss = 1.103590312122833, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 396, train_loss = 1.1018224482540973, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 397, train_loss = 1.1000717654824257, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 398, train_loss = 1.098246991634369, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 399, train_loss = 1.0965822984580882, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 400, train_loss = 1.0947908560629003, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 401, train_loss = 1.0930848034913652, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 402, train_loss = 1.0914357242290862, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 403, train_loss = 1.089730514853727, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 404, train_loss = 1.087973027199041, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 405, train_loss = 1.086327914148569, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 406, train_loss = 1.084679200022947, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 407, train_loss = 1.0830541253089905, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 408, train_loss = 1.0813714787364006, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 409, train_loss = 1.079756924242247, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 410, train_loss = 1.0781065275368746, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 411, train_loss = 1.0765079632401466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 412, train_loss = 1.0749688459036406, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 413, train_loss = 1.073358374327654, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 414, train_loss = 1.0717570458946284, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 415, train_loss = 1.070271064847475, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 416, train_loss = 1.0685879699885845, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 417, train_loss = 1.0670921889541205, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 418, train_loss = 1.0655323477985803, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 419, train_loss = 1.064065370708704, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 420, train_loss = 1.0625337114033755, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 421, train_loss = 1.0609749592840672, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 422, train_loss = 1.059462372213602, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 423, train_loss = 1.0580214212241117, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 424, train_loss = 1.056497116893297, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 425, train_loss = 1.0549714043736458, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 426, train_loss = 1.0535904541611671, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 427, train_loss = 1.0520741045475006, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 428, train_loss = 1.0506321812572423, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 429, train_loss = 1.049261004984146, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 430, train_loss = 1.0477794657053892, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 431, train_loss = 1.0463154117169324, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 432, train_loss = 1.0448685698211193, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 433, train_loss = 1.043574328214163, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 434, train_loss = 1.0421232866647188, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 435, train_loss = 1.0407319155929144, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 436, train_loss = 1.0393380038440228, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 437, train_loss = 1.037925978511339, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 438, train_loss = 1.0365980801580008, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 439, train_loss = 1.0351909647288267, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 440, train_loss = 1.033832067012554, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 441, train_loss = 1.032546134054428, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 442, train_loss = 1.0312484850583132, train_acc = 0.9979040521658128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 443, train_loss = 1.0298181685211603, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 444, train_loss = 1.028564420848852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 445, train_loss = 1.0272022200224455, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 446, train_loss = 1.0258870186808053, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 447, train_loss = 1.0245679741201457, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 448, train_loss = 1.0233335308730602, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 449, train_loss = 1.0219622378645, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 450, train_loss = 1.0207758309843484, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 451, train_loss = 1.0193950260581914, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 452, train_loss = 1.0181540747580584, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 453, train_loss = 1.0169421819446143, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 454, train_loss = 1.015648826956749, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 455, train_loss = 1.014419606566662, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 456, train_loss = 1.0131319301726762, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 457, train_loss = 1.011957543581957, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 458, train_loss = 1.0107482435705606, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 459, train_loss = 1.0095153860747814, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 460, train_loss = 1.0082912780344486, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 461, train_loss = 1.0071121752262115, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 462, train_loss = 1.005864700913662, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 463, train_loss = 1.0047050304710865, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 464, train_loss = 1.0035466800036374, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 465, train_loss = 1.0023090740141924, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 466, train_loss = 1.0011644115147647, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 467, train_loss = 1.0000191144645214, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 468, train_loss = 0.9988139532506466, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 469, train_loss = 0.9976715433003847, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 470, train_loss = 0.9965310332772788, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 471, train_loss = 0.9953783141972963, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 472, train_loss = 0.9942888940277044, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 473, train_loss = 0.9930575316247996, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 474, train_loss = 0.9919983334839344, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 475, train_loss = 0.9908779449760914, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 476, train_loss = 0.9897503443062305, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 477, train_loss = 0.988612317800289, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 478, train_loss = 0.987543453782564, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 479, train_loss = 0.9864518344402313, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 480, train_loss = 0.9852988794445992, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 481, train_loss = 0.9842922315001488, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 482, train_loss = 0.9831750951707363, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 483, train_loss = 0.9820592502655927, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 484, train_loss = 0.9810415121319238, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 485, train_loss = 0.9799716758134309, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 486, train_loss = 0.9788582610490266, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 487, train_loss = 0.9778334001603071, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 488, train_loss = 0.9768116672930773, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 489, train_loss = 0.9756732645037118, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 490, train_loss = 0.9747330596146639, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 491, train_loss = 0.97365197664476, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 492, train_loss = 0.9725366309285164, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 493, train_loss = 0.9716343320906162, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 494, train_loss = 0.9705688605608884, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 495, train_loss = 0.9694938994944096, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 496, train_loss = 0.9685152620077133, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 497, train_loss = 0.9675117855367716, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 498, train_loss = 0.9664988989534322, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 499, train_loss = 0.965535399824148, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████                                          | 12/30 [1:21:50<2:03:27, 411.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "13th- epoch: 0, train_loss = 271.6422630548477, train_acc = 0.4261760596180717\n",
      "test Acc 0.4897579143389199:\n",
      "13th- epoch: 1, train_loss = 203.89775276184082, train_acc = 0.5018630647414998\n",
      "test Acc 0.5521415270018621:\n",
      "13th- epoch: 2, train_loss = 160.26618856191635, train_acc = 0.5758034466697718\n",
      "test Acc 0.6149906890130353:\n",
      "13th- epoch: 3, train_loss = 134.8238669037819, train_acc = 0.6708197484862599\n",
      "test Acc 0.7378957169459963:\n",
      "13th- epoch: 4, train_loss = 115.80234390497208, train_acc = 0.7559385188635305\n",
      "test Acc 0.7839851024208566:\n",
      "13th- epoch: 5, train_loss = 100.61317977309227, train_acc = 0.78959012575687\n",
      "test Acc 0.8128491620111732:\n",
      "13th- epoch: 6, train_loss = 88.27926310896873, train_acc = 0.8088029809035864\n",
      "test Acc 0.8235567970204841:\n",
      "13th- epoch: 7, train_loss = 78.26933035254478, train_acc = 0.8230088495575221\n",
      "test Acc 0.8370577281191807:\n",
      "13th- epoch: 8, train_loss = 69.9336616396904, train_acc = 0.8363996273870516\n",
      "test Acc 0.8482309124767226:\n",
      "13th- epoch: 9, train_loss = 62.82795596122742, train_acc = 0.8542151839776432\n",
      "test Acc 0.8738361266294227:\n",
      "13th- epoch: 10, train_loss = 56.68728323280811, train_acc = 0.8833255705635771\n",
      "test Acc 0.9008379888268156:\n",
      "13th- epoch: 11, train_loss = 51.3101060539484, train_acc = 0.9123195156031673\n",
      "test Acc 0.9231843575418994:\n",
      "13th- epoch: 12, train_loss = 46.57091461122036, train_acc = 0.9326967862133209\n",
      "test Acc 0.9352886405959032:\n",
      "13th- epoch: 13, train_loss = 42.40106126666069, train_acc = 0.9422449930135072\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 14, train_loss = 38.75360031425953, train_acc = 0.9470190964136004\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 15, train_loss = 35.59173808246851, train_acc = 0.94981369352585\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 16, train_loss = 32.8709305152297, train_acc = 0.952491849091756\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 17, train_loss = 30.53361465781927, train_acc = 0.9549371215649743\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 18, train_loss = 28.52579802274704, train_acc = 0.9571495109455054\n",
      "test Acc 0.952048417132216:\n",
      "13th- epoch: 19, train_loss = 26.795265957713127, train_acc = 0.959944108057755\n",
      "test Acc 0.9543761638733705:\n",
      "13th- epoch: 20, train_loss = 25.294195413589478, train_acc = 0.9628551467163484\n",
      "test Acc 0.957169459962756:\n",
      "13th- epoch: 21, train_loss = 23.982368860393763, train_acc = 0.9659990684676293\n",
      "test Acc 0.9594972067039106:\n",
      "13th- epoch: 22, train_loss = 22.828271452337503, train_acc = 0.9669306008383791\n",
      "test Acc 0.9613594040968343:\n",
      "13th- epoch: 23, train_loss = 21.804745137691498, train_acc = 0.9689101071262226\n",
      "test Acc 0.9618249534450651:\n",
      "13th- epoch: 24, train_loss = 20.890118315815926, train_acc = 0.9693758733115976\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 25, train_loss = 20.06723590940237, train_acc = 0.97007452258966\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 26, train_loss = 19.321223232895136, train_acc = 0.9703074056823474\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 27, train_loss = 18.64073457568884, train_acc = 0.970540288775035\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 28, train_loss = 18.016017399728298, train_acc = 0.9713553795994411\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 29, train_loss = 17.439742606133223, train_acc = 0.9724033535165347\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 30, train_loss = 16.905735436826944, train_acc = 0.9729855612482534\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 31, train_loss = 16.4087086468935, train_acc = 0.9733348858872846\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 32, train_loss = 15.943424198776484, train_acc = 0.9739170936190032\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 33, train_loss = 15.507193867117167, train_acc = 0.974033535165347\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 34, train_loss = 15.097083326429129, train_acc = 0.9744993013507219\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 35, train_loss = 14.710245188325644, train_acc = 0.9744993013507219\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 36, train_loss = 14.344143450260162, train_acc = 0.9744993013507219\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 37, train_loss = 13.99709989503026, train_acc = 0.9748486259897532\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 38, train_loss = 13.667487859725952, train_acc = 0.9751979506287843\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 39, train_loss = 13.353720653802156, train_acc = 0.9756637168141593\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 40, train_loss = 13.054604552686214, train_acc = 0.9758965999068467\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 41, train_loss = 12.768732320517302, train_acc = 0.9763623660922217\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 42, train_loss = 12.495183862745762, train_acc = 0.9769445738239404\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 43, train_loss = 12.233249317854643, train_acc = 0.9774103400093154\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 44, train_loss = 11.98172527179122, train_acc = 0.9781089892873778\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 45, train_loss = 11.739972602576017, train_acc = 0.9784583139264089\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 46, train_loss = 11.507354687899351, train_acc = 0.9791569632044713\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 47, train_loss = 11.28347672894597, train_acc = 0.9793898462971589\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 48, train_loss = 11.06784687563777, train_acc = 0.9795062878435026\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 49, train_loss = 10.859732296317816, train_acc = 0.9796227293898463\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 50, train_loss = 10.65864209830761, train_acc = 0.9796227293898463\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 51, train_loss = 10.46422927826643, train_acc = 0.9800884955752213\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 52, train_loss = 10.27641398459673, train_acc = 0.9805542617605962\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 53, train_loss = 10.094475198537111, train_acc = 0.9810200279459711\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 54, train_loss = 9.918488509953022, train_acc = 0.9814857941313461\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 55, train_loss = 9.748071856796741, train_acc = 0.9821844434094085\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 56, train_loss = 9.582737639546394, train_acc = 0.9825337680484397\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 57, train_loss = 9.422271616756916, train_acc = 0.9828830926874709\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 58, train_loss = 9.266596980392933, train_acc = 0.9831159757801584\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 59, train_loss = 9.115312715992332, train_acc = 0.9831159757801584\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 60, train_loss = 8.968143839389086, train_acc = 0.9833488588728458\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 61, train_loss = 8.82507012039423, train_acc = 0.9835817419655333\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 62, train_loss = 8.685705874115229, train_acc = 0.9838146250582208\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 63, train_loss = 8.549818886443973, train_acc = 0.9838146250582208\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 64, train_loss = 8.41729841940105, train_acc = 0.9838146250582208\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 65, train_loss = 8.288124253973365, train_acc = 0.9839310666045645\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 66, train_loss = 8.162183228880167, train_acc = 0.984163949697252\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 67, train_loss = 8.039072751998901, train_acc = 0.9846297158826269\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 68, train_loss = 7.919034691527486, train_acc = 0.9848625989753144\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 69, train_loss = 7.801821634173393, train_acc = 0.9848625989753144\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 70, train_loss = 7.6873456835746765, train_acc = 0.9852119236143456\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 71, train_loss = 7.575574278831482, train_acc = 0.985444806707033\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 72, train_loss = 7.466237643733621, train_acc = 0.9860270144387517\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 73, train_loss = 7.359216585755348, train_acc = 0.9861434559850955\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 74, train_loss = 7.254503605887294, train_acc = 0.986376339077783\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 75, train_loss = 7.152291836217046, train_acc = 0.9864927806241267\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 76, train_loss = 7.052134359255433, train_acc = 0.9867256637168141\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 77, train_loss = 6.954095371067524, train_acc = 0.9869585468095017\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 78, train_loss = 6.858069432899356, train_acc = 0.9871914299021891\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 79, train_loss = 6.764103673398495, train_acc = 0.9871914299021891\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 80, train_loss = 6.672026099637151, train_acc = 0.9871914299021891\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 81, train_loss = 6.581672551110387, train_acc = 0.9875407545412203\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 82, train_loss = 6.493193801492453, train_acc = 0.9876571960875641\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 83, train_loss = 6.406520780175924, train_acc = 0.9876571960875641\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 84, train_loss = 6.32139552757144, train_acc = 0.9877736376339078\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 85, train_loss = 6.23785861954093, train_acc = 0.9882394038192828\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 86, train_loss = 6.156056083738804, train_acc = 0.9883558453656265\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 87, train_loss = 6.075549490749836, train_acc = 0.9887051700046576\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 88, train_loss = 5.996588567271829, train_acc = 0.9887051700046576\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 89, train_loss = 5.919143399223685, train_acc = 0.9887051700046576\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 90, train_loss = 5.842913342639804, train_acc = 0.9888216115510013\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 91, train_loss = 5.768022648990154, train_acc = 0.9889380530973452\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 92, train_loss = 5.694453312084079, train_acc = 0.9890544946436889\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 93, train_loss = 5.622159969061613, train_acc = 0.98940381928272\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 94, train_loss = 5.550987245514989, train_acc = 0.9896367023754076\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 95, train_loss = 5.481214310973883, train_acc = 0.9897531439217513\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 96, train_loss = 5.412515437230468, train_acc = 0.9897531439217513\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 97, train_loss = 5.344951892271638, train_acc = 0.9902189101071263\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 98, train_loss = 5.278536606580019, train_acc = 0.99033535165347\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 99, train_loss = 5.213183026760817, train_acc = 0.9905682347461574\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 100, train_loss = 5.148823399096727, train_acc = 0.990801117838845\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 101, train_loss = 5.085521316155791, train_acc = 0.9910340009315324\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 102, train_loss = 5.0233712159097195, train_acc = 0.9910340009315324\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 103, train_loss = 4.962262832559645, train_acc = 0.9910340009315324\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 104, train_loss = 4.902191378176212, train_acc = 0.9911504424778761\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 105, train_loss = 4.843050464056432, train_acc = 0.9912668840242198\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 106, train_loss = 4.784961243160069, train_acc = 0.9912668840242198\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 107, train_loss = 4.72768195066601, train_acc = 0.9912668840242198\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 108, train_loss = 4.6714446702972054, train_acc = 0.9912668840242198\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 109, train_loss = 4.616074960678816, train_acc = 0.9911504424778761\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 110, train_loss = 4.561602232977748, train_acc = 0.9913833255705635\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 111, train_loss = 4.508063090965152, train_acc = 0.9916162086632511\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 112, train_loss = 4.455525611527264, train_acc = 0.9919655333022822\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 113, train_loss = 4.403712929226458, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 114, train_loss = 4.352712193503976, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 115, train_loss = 4.302496722899377, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 116, train_loss = 4.253267233259976, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 117, train_loss = 4.204836896620691, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 118, train_loss = 4.157146138139069, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 119, train_loss = 4.110251189209521, train_acc = 0.9924312994876572\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 120, train_loss = 4.064179762266576, train_acc = 0.9925477410340009\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 121, train_loss = 4.018791993148625, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 122, train_loss = 3.9741907557472587, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 123, train_loss = 3.930266998708248, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 124, train_loss = 3.8871305296197534, train_acc = 0.9925477410340009\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 125, train_loss = 3.8446673965081573, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 126, train_loss = 3.8030075822025537, train_acc = 0.9928970656730322\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 127, train_loss = 3.761902262456715, train_acc = 0.9932463903120633\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 128, train_loss = 3.7218635259196162, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 129, train_loss = 3.6822004169225693, train_acc = 0.9934792734047508\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 130, train_loss = 3.6432877657935023, train_acc = 0.9934792734047508\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 131, train_loss = 3.605191208422184, train_acc = 0.9935957149510946\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 132, train_loss = 3.5674880212172866, train_acc = 0.9937121564974383\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 133, train_loss = 3.530634667724371, train_acc = 0.9937121564974383\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 134, train_loss = 3.4942820873111486, train_acc = 0.9937121564974383\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 135, train_loss = 3.458576056174934, train_acc = 0.9939450395901258\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 136, train_loss = 3.423422914929688, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 137, train_loss = 3.388916030526161, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 138, train_loss = 3.354861964471638, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 139, train_loss = 3.321541449986398, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 140, train_loss = 3.288621283136308, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 141, train_loss = 3.2563098231330514, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 142, train_loss = 3.2246232638135552, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 143, train_loss = 3.1932993326336145, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 144, train_loss = 3.162673466373235, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 145, train_loss = 3.132477250415832, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 146, train_loss = 3.102778045460582, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 147, train_loss = 3.073486452922225, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 148, train_loss = 3.0448233620263636, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 149, train_loss = 3.0165414572693408, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 150, train_loss = 2.9888333124108613, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 151, train_loss = 2.96145990351215, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 152, train_loss = 2.9346231296658516, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 153, train_loss = 2.9081995650194585, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 154, train_loss = 2.8821195433847606, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 155, train_loss = 2.856565569061786, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 156, train_loss = 2.8314197226427495, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 157, train_loss = 2.8067055591382086, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 158, train_loss = 2.782449906691909, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 159, train_loss = 2.7584359007887542, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 160, train_loss = 2.7350565511733294, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 161, train_loss = 2.71194066433236, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 162, train_loss = 2.689147939439863, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 163, train_loss = 2.666742066387087, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 164, train_loss = 2.644710250198841, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 165, train_loss = 2.623145265970379, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 166, train_loss = 2.6018134453333914, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 167, train_loss = 2.5808963775634766, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 168, train_loss = 2.560278296470642, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 169, train_loss = 2.540019733365625, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 170, train_loss = 2.520076621323824, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 171, train_loss = 2.5005264952778816, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 172, train_loss = 2.4812133559025824, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 173, train_loss = 2.4622685299254954, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 174, train_loss = 2.4436637721955776, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 175, train_loss = 2.4252710402943194, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 176, train_loss = 2.4071652428247035, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 177, train_loss = 2.3894316679798067, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 178, train_loss = 2.3720389059744775, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 179, train_loss = 2.35482025379315, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 180, train_loss = 2.337790661957115, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 181, train_loss = 2.3212317042052746, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 182, train_loss = 2.304688800126314, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 183, train_loss = 2.2887158491648734, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 184, train_loss = 2.2727034823037684, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 185, train_loss = 2.256984708365053, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 186, train_loss = 2.2416862533427775, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 187, train_loss = 2.2264891043305397, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 188, train_loss = 2.21150009566918, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 189, train_loss = 2.1968313083052635, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 190, train_loss = 2.1824229336343706, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 191, train_loss = 2.16814307263121, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 192, train_loss = 2.1541219279170036, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 193, train_loss = 2.1403191227000207, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 194, train_loss = 2.126785597531125, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 195, train_loss = 2.113393157720566, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 196, train_loss = 2.1001762461382896, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 197, train_loss = 2.087235213490203, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 198, train_loss = 2.0744852509815246, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 199, train_loss = 2.061767203034833, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 200, train_loss = 2.0494544866960496, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 201, train_loss = 2.0372915093321353, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 202, train_loss = 2.0251391616184264, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 203, train_loss = 2.013421778799966, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 204, train_loss = 2.00151618453674, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 205, train_loss = 1.989844833733514, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 206, train_loss = 1.9782456867396832, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 207, train_loss = 1.9670171339530498, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 208, train_loss = 1.9559986803214997, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 209, train_loss = 1.9450488947331905, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 210, train_loss = 1.9345730419736356, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 211, train_loss = 1.9238256204407662, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 212, train_loss = 1.9135676037985831, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 213, train_loss = 1.9032516293227673, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 214, train_loss = 1.8931403271853924, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 215, train_loss = 1.8832951325457543, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 216, train_loss = 1.873401879100129, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 217, train_loss = 1.8638406209647655, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 218, train_loss = 1.8541386958677322, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 219, train_loss = 1.844939221860841, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 220, train_loss = 1.8355328552424908, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 221, train_loss = 1.8264630648773164, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 222, train_loss = 1.8173425011336803, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 223, train_loss = 1.808544561266899, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 224, train_loss = 1.7996694147586823, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 225, train_loss = 1.7910369287710637, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 226, train_loss = 1.7825245521962643, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 227, train_loss = 1.7740749828517437, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 228, train_loss = 1.7657185432035476, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 229, train_loss = 1.7574102201033384, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 230, train_loss = 1.7493107474874705, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 231, train_loss = 1.7412753470707685, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 232, train_loss = 1.7333269864320755, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 233, train_loss = 1.7255395886022598, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 234, train_loss = 1.717724246205762, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 235, train_loss = 1.7101472944486886, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 236, train_loss = 1.7026275780517608, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 237, train_loss = 1.6951532277744263, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 238, train_loss = 1.687804191140458, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 239, train_loss = 1.6805383402388543, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 240, train_loss = 1.6733973175287247, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 241, train_loss = 1.6663308565039188, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 242, train_loss = 1.6592393070459366, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 243, train_loss = 1.652343715308234, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 244, train_loss = 1.6454649853985757, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 245, train_loss = 1.6387353874742985, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 246, train_loss = 1.6319782112259418, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 247, train_loss = 1.6254839163739234, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 248, train_loss = 1.618880084482953, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 249, train_loss = 1.6124209736008197, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 250, train_loss = 1.6059861544054002, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 251, train_loss = 1.5997492410242558, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 252, train_loss = 1.59344230836723, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 253, train_loss = 1.5874006425729021, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 254, train_loss = 1.581093086511828, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 255, train_loss = 1.575205646455288, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 256, train_loss = 1.569137740880251, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 257, train_loss = 1.5633462257683277, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 258, train_loss = 1.557421556324698, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 259, train_loss = 1.5517204701900482, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 260, train_loss = 1.5460207933792844, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 261, train_loss = 1.5403346121311188, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 262, train_loss = 1.5347618348896503, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 263, train_loss = 1.5293572085211053, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 264, train_loss = 1.5237795425346121, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 265, train_loss = 1.5183397084474564, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 266, train_loss = 1.5132057456066832, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 267, train_loss = 1.507729092030786, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 268, train_loss = 1.5026165656745434, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 269, train_loss = 1.4973665227880701, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 270, train_loss = 1.49229419848416, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 271, train_loss = 1.487229929654859, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 272, train_loss = 1.4822941335150972, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 273, train_loss = 1.477221354842186, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 274, train_loss = 1.4723985580494627, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 275, train_loss = 1.467404925613664, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 276, train_loss = 1.4626074930420145, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 277, train_loss = 1.4578501842916012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 278, train_loss = 1.4531720665981993, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 279, train_loss = 1.4483898194739595, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 280, train_loss = 1.4439000971615314, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 281, train_loss = 1.439307173131965, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 282, train_loss = 1.4347829011967406, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 283, train_loss = 1.4301074160030112, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 284, train_loss = 1.425880497903563, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 285, train_loss = 1.4213245684513822, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 286, train_loss = 1.4171249195933342, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 287, train_loss = 1.4127406304469332, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 288, train_loss = 1.408480390906334, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 289, train_loss = 1.4040802642703056, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 290, train_loss = 1.3999800259480253, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 291, train_loss = 1.3957813208689913, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 292, train_loss = 1.3916347896447405, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 293, train_loss = 1.387470617890358, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 294, train_loss = 1.3834159845719114, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 295, train_loss = 1.379396803677082, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 296, train_loss = 1.3754854263970628, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 297, train_loss = 1.3715654449770227, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 298, train_loss = 1.3677363023161888, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 299, train_loss = 1.3638470657169819, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 300, train_loss = 1.3600069718668237, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 301, train_loss = 1.3561779422452673, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 302, train_loss = 1.35258822015021, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 303, train_loss = 1.348737827152945, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 304, train_loss = 1.345047598122619, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 305, train_loss = 1.3414004420628771, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 306, train_loss = 1.3377462761709467, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 307, train_loss = 1.3342017183313146, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 308, train_loss = 1.3306993519654498, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 309, train_loss = 1.3271384313702583, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 310, train_loss = 1.3235855711391196, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 311, train_loss = 1.320302685140632, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 312, train_loss = 1.316838026046753, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 313, train_loss = 1.3134200560161844, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 314, train_loss = 1.3099801950156689, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 315, train_loss = 1.3066629506647587, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 316, train_loss = 1.3034218723187223, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 317, train_loss = 1.3000295037636533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 318, train_loss = 1.2967655720422044, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 319, train_loss = 1.2935993360588327, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 320, train_loss = 1.2903466759016737, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 321, train_loss = 1.2872472368180752, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 322, train_loss = 1.2841582633554935, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 323, train_loss = 1.2809538220753893, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 324, train_loss = 1.2779616316547617, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 325, train_loss = 1.2748469276120886, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 326, train_loss = 1.2719212099909782, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 327, train_loss = 1.2688691293587908, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 328, train_loss = 1.2658146569738165, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 329, train_loss = 1.262914395541884, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 330, train_loss = 1.259924154728651, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 331, train_loss = 1.2569640377769247, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 332, train_loss = 1.2541092485189438, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 333, train_loss = 1.251226581633091, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 334, train_loss = 1.2483870263095014, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 335, train_loss = 1.2455537083442323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "13th- epoch: 336, train_loss = 1.2427347898483276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 337, train_loss = 1.2399403390591033, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 338, train_loss = 1.2371897175908089, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 339, train_loss = 1.2345854490995407, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 340, train_loss = 1.2317598524386995, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 341, train_loss = 1.2291321270167828, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 342, train_loss = 1.2264189782436006, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 343, train_loss = 1.2238211718504317, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 344, train_loss = 1.221269981295336, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 345, train_loss = 1.2185484158690087, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 346, train_loss = 1.215972177684307, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 347, train_loss = 1.2134748970274813, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 348, train_loss = 1.2108059749007225, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 349, train_loss = 1.2085025322739966, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 350, train_loss = 1.2058329544961452, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 351, train_loss = 1.2033761503989808, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 352, train_loss = 1.2009727880358696, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 353, train_loss = 1.1984938557143323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 354, train_loss = 1.1960372515022755, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 355, train_loss = 1.1937158058281057, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 356, train_loss = 1.1913137485389598, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 357, train_loss = 1.1889037527143955, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 358, train_loss = 1.1866061079199426, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 359, train_loss = 1.184210469305981, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 360, train_loss = 1.1818082642857917, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 361, train_loss = 1.179647992074024, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 362, train_loss = 1.177326473116409, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 363, train_loss = 1.1749235168099403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 364, train_loss = 1.1728223375976086, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 365, train_loss = 1.1705486190621741, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 366, train_loss = 1.168289841443766, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 367, train_loss = 1.1661554376478307, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 368, train_loss = 1.1639641461079009, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 369, train_loss = 1.1616810820996761, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 370, train_loss = 1.159744928299915, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 371, train_loss = 1.1575112181599252, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 372, train_loss = 1.1554515374009497, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 373, train_loss = 1.1532920462195762, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 374, train_loss = 1.151206560432911, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 375, train_loss = 1.1491222220356576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 376, train_loss = 1.1469998682732694, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 377, train_loss = 1.144859780848492, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 378, train_loss = 1.1428528800606728, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 379, train_loss = 1.1408889517188072, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 380, train_loss = 1.1389298029243946, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 381, train_loss = 1.1367120295763016, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 382, train_loss = 1.13480594009161, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 383, train_loss = 1.1328112657065503, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 384, train_loss = 1.1309774580295198, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 385, train_loss = 1.1290988984401338, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 386, train_loss = 1.1269533224403858, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 387, train_loss = 1.125175988941919, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 388, train_loss = 1.123129952698946, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 389, train_loss = 1.1214427550439723, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 390, train_loss = 1.1193578342790715, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 391, train_loss = 1.1176997795701027, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 392, train_loss = 1.1157480788533576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 393, train_loss = 1.1138521482353099, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 394, train_loss = 1.111974060535431, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 395, train_loss = 1.1102243053610437, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 396, train_loss = 1.1083510841126554, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 397, train_loss = 1.1066444006864913, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 398, train_loss = 1.1048014710540883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 399, train_loss = 1.103061945468653, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 400, train_loss = 1.1013109485502355, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 401, train_loss = 1.0995272435247898, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 402, train_loss = 1.0977553874254227, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 403, train_loss = 1.096101111441385, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 404, train_loss = 1.0943414096836932, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 405, train_loss = 1.0926994656329043, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 406, train_loss = 1.0908904187381268, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 407, train_loss = 1.089243859052658, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 408, train_loss = 1.087579071521759, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 409, train_loss = 1.085958857089281, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 410, train_loss = 1.084285983175505, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 411, train_loss = 1.0826089742477052, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 412, train_loss = 1.080958201258909, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 413, train_loss = 1.079451646655798, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 414, train_loss = 1.0777643446926959, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 415, train_loss = 1.076196191192139, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 416, train_loss = 1.074588604271412, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 417, train_loss = 1.073109007149469, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 418, train_loss = 1.071423228830099, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 419, train_loss = 1.0700088714365847, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 420, train_loss = 1.0681958596105687, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 421, train_loss = 1.0668822030420415, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 422, train_loss = 1.0652162755723111, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 423, train_loss = 1.0638067449326627, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 424, train_loss = 1.062221200496424, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 425, train_loss = 1.0606824979186058, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 426, train_loss = 1.0592585665290244, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 427, train_loss = 1.0577018670737743, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 428, train_loss = 1.0561683041159995, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 429, train_loss = 1.0547511763870716, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 430, train_loss = 1.0532039068639278, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 431, train_loss = 1.0519294515252113, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 432, train_loss = 1.0503296380047686, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 433, train_loss = 1.0490308565204032, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 434, train_loss = 1.0474333192105405, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 435, train_loss = 1.0462357488577254, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 436, train_loss = 1.0445905961096287, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 437, train_loss = 1.0433455209131353, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 438, train_loss = 1.0417952475254424, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 439, train_loss = 1.0405240406398661, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 440, train_loss = 1.0390672385692596, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 441, train_loss = 1.0378308395738713, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 442, train_loss = 1.0364270110731013, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 443, train_loss = 1.0349510696833022, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 444, train_loss = 1.0336912907660007, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 445, train_loss = 1.0322846944327466, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 446, train_loss = 1.0309860172565095, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 447, train_loss = 1.0296261981129646, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 448, train_loss = 1.0283174800570123, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 449, train_loss = 1.0270134409074672, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 450, train_loss = 1.0256808797712438, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 451, train_loss = 1.0243560274248011, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 452, train_loss = 1.0230540695483796, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 453, train_loss = 1.0217393773491494, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 454, train_loss = 1.020475058525335, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 455, train_loss = 1.0191841907799244, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 456, train_loss = 1.017986143619055, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 457, train_loss = 1.0166675932705402, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 458, train_loss = 1.0153853533265647, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 459, train_loss = 1.0141666531562805, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 460, train_loss = 1.0129388508794364, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 461, train_loss = 1.0116614090802614, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 462, train_loss = 1.0103346730174962, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 463, train_loss = 1.0093183033168316, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 464, train_loss = 1.0079213467834052, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 465, train_loss = 1.0069036011991557, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 466, train_loss = 1.0054422418179456, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 467, train_loss = 1.0044955747725908, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 468, train_loss = 1.003077952802414, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 469, train_loss = 1.0020060750248376, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 470, train_loss = 1.0008215407433454, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 471, train_loss = 0.9996290554699954, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 472, train_loss = 0.9984724571404513, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 473, train_loss = 0.9973352352681104, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 474, train_loss = 0.9961005536315497, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 475, train_loss = 0.9951762147247791, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 476, train_loss = 0.9937616884708405, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 477, train_loss = 0.9927609264850616, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 478, train_loss = 0.9916441155073699, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 479, train_loss = 0.9904785292746965, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 480, train_loss = 0.9892488171753939, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 481, train_loss = 0.9884023418126162, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 482, train_loss = 0.987057408929104, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 483, train_loss = 0.986178919672966, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 484, train_loss = 0.9848180090484675, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 485, train_loss = 0.9838385221955832, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 486, train_loss = 0.982814626157051, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 487, train_loss = 0.981658643722767, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 488, train_loss = 0.9805074743926525, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 489, train_loss = 0.9796387689711992, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 490, train_loss = 0.9783952782454435, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 491, train_loss = 0.9773974989948329, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 492, train_loss = 0.9763690630497877, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 493, train_loss = 0.9753336595895234, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 494, train_loss = 0.9741632752120495, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 495, train_loss = 0.9733717826602515, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 496, train_loss = 0.97215380644775, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 497, train_loss = 0.9711631101963576, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 498, train_loss = 0.9701848452386912, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 499, train_loss = 0.9691608560679015, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████▎                                       | 13/30 [1:28:42<1:56:39, 411.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "14th- epoch: 0, train_loss = 273.475625872612, train_acc = 0.4438751746623195\n",
      "test Acc 0.5153631284916201:\n",
      "14th- epoch: 1, train_loss = 210.27596747875214, train_acc = 0.5415696320447135\n",
      "test Acc 0.5670391061452514:\n",
      "14th- epoch: 2, train_loss = 162.94991493225098, train_acc = 0.5772007452258966\n",
      "test Acc 0.6080074487895717:\n",
      "14th- epoch: 3, train_loss = 136.08136922121048, train_acc = 0.6603400093153237\n",
      "test Acc 0.7243947858472998:\n",
      "14th- epoch: 4, train_loss = 117.11096334457397, train_acc = 0.7444108057755007\n",
      "test Acc 0.7737430167597765:\n",
      "14th- epoch: 5, train_loss = 102.20768684148788, train_acc = 0.7732883092687471\n",
      "test Acc 0.8002793296089385:\n",
      "14th- epoch: 6, train_loss = 89.79627850651741, train_acc = 0.8048439683278994\n",
      "test Acc 0.824487895716946:\n",
      "14th- epoch: 7, train_loss = 79.43596684932709, train_acc = 0.8209129017233349\n",
      "test Acc 0.840316573556797:\n",
      "14th- epoch: 8, train_loss = 70.71097043156624, train_acc = 0.8395435491383325\n",
      "test Acc 0.8566108007448789:\n",
      "14th- epoch: 9, train_loss = 63.20193803310394, train_acc = 0.8635305076851421\n",
      "test Acc 0.8784916201117319:\n",
      "14th- epoch: 10, train_loss = 56.69463628530502, train_acc = 0.8855379599441081\n",
      "test Acc 0.8975791433891993:\n",
      "14th- epoch: 11, train_loss = 51.071266159415245, train_acc = 0.9032370749883558\n",
      "test Acc 0.9194599627560521:\n",
      "14th- epoch: 12, train_loss = 46.22215212881565, train_acc = 0.9275733581741965\n",
      "test Acc 0.9329608938547486:\n",
      "14th- epoch: 13, train_loss = 42.046094462275505, train_acc = 0.9395668374476013\n",
      "test Acc 0.9352886405959032:\n",
      "14th- epoch: 14, train_loss = 38.452760085463524, train_acc = 0.9437587331159758\n",
      "test Acc 0.9404096834264432:\n",
      "14th- epoch: 15, train_loss = 35.36438837647438, train_acc = 0.9481835118770378\n",
      "test Acc 0.9432029795158287:\n",
      "14th- epoch: 16, train_loss = 32.71012952178717, train_acc = 0.9503959012575687\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 17, train_loss = 30.426289595663548, train_acc = 0.9523754075454122\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 18, train_loss = 28.45734254270792, train_acc = 0.9544713553795995\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 19, train_loss = 26.753212854266167, train_acc = 0.9571495109455054\n",
      "test Acc 0.9539106145251397:\n",
      "14th- epoch: 20, train_loss = 25.270033486187458, train_acc = 0.9602934326967862\n",
      "test Acc 0.9553072625698324:\n",
      "14th- epoch: 21, train_loss = 23.971352968364954, train_acc = 0.9626222636236609\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 22, train_loss = 22.825801216065884, train_acc = 0.9657661853749417\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 23, train_loss = 21.808443263173103, train_acc = 0.9673963670237541\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 24, train_loss = 20.89742609858513, train_acc = 0.9679785747554728\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 25, train_loss = 20.076187379658222, train_acc = 0.9687936655798789\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 26, train_loss = 19.331558164209127, train_acc = 0.9694923148579413\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 27, train_loss = 18.65277460590005, train_acc = 0.9704238472286912\n",
      "test Acc 0.9636871508379888:\n",
      "14th- epoch: 28, train_loss = 18.030387420207262, train_acc = 0.9707731718677224\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 29, train_loss = 17.457007214426994, train_acc = 0.9710060549604099\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 30, train_loss = 16.926246162503958, train_acc = 0.9712389380530974\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 31, train_loss = 16.43195103481412, train_acc = 0.9720540288775035\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 32, train_loss = 15.969726577401161, train_acc = 0.9724033535165347\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 33, train_loss = 15.537098307162523, train_acc = 0.9729855612482534\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 34, train_loss = 15.131129305809736, train_acc = 0.9733348858872846\n",
      "test Acc 0.9641527001862198:\n",
      "14th- epoch: 35, train_loss = 14.749015886336565, train_acc = 0.9744993013507219\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 36, train_loss = 14.387849267572165, train_acc = 0.9746157428970657\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 37, train_loss = 14.045745383948088, train_acc = 0.9744993013507219\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 38, train_loss = 13.721370190382004, train_acc = 0.9748486259897532\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 39, train_loss = 13.412684567272663, train_acc = 0.975314392175128\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 40, train_loss = 13.118584040552378, train_acc = 0.9755472752678156\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 41, train_loss = 12.837719548493624, train_acc = 0.9758965999068467\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 42, train_loss = 12.569007001817226, train_acc = 0.9763623660922217\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 43, train_loss = 12.311290234327316, train_acc = 0.9765952491849091\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 44, train_loss = 12.063831947743893, train_acc = 0.9774103400093154\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 45, train_loss = 11.825768653303385, train_acc = 0.9782254308337215\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 46, train_loss = 11.596937596797943, train_acc = 0.9789240801117839\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 47, train_loss = 11.376470647752285, train_acc = 0.9793898462971589\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 48, train_loss = 11.164126373827457, train_acc = 0.9796227293898463\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 49, train_loss = 10.959070978686213, train_acc = 0.9803213786679087\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 50, train_loss = 10.761214761063457, train_acc = 0.9805542617605962\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 51, train_loss = 10.56963679753244, train_acc = 0.9809035863996274\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 52, train_loss = 10.384239669889212, train_acc = 0.9812529110386586\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 53, train_loss = 10.204563098028302, train_acc = 0.9813693525850024\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 54, train_loss = 10.030337763950229, train_acc = 0.9817186772240335\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 55, train_loss = 9.861180251464248, train_acc = 0.9818351187703773\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 56, train_loss = 9.697257680818439, train_acc = 0.9820680018630648\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 57, train_loss = 9.537940384820104, train_acc = 0.9824173265020959\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 58, train_loss = 9.383061528205872, train_acc = 0.9824173265020959\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 59, train_loss = 9.232476688921452, train_acc = 0.9829995342338146\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 60, train_loss = 9.086059538647532, train_acc = 0.9831159757801584\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 61, train_loss = 8.943325750529766, train_acc = 0.9833488588728458\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 62, train_loss = 8.804023629054427, train_acc = 0.9835817419655333\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 63, train_loss = 8.668179251253605, train_acc = 0.9835817419655333\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 64, train_loss = 8.535609889775515, train_acc = 0.9839310666045645\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 65, train_loss = 8.40642842464149, train_acc = 0.9839310666045645\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 66, train_loss = 8.280189238488674, train_acc = 0.9843968327899395\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 67, train_loss = 8.157088985666633, train_acc = 0.9845132743362832\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 68, train_loss = 8.036585930734873, train_acc = 0.9846297158826269\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 69, train_loss = 7.918890351429582, train_acc = 0.9847461574289706\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 70, train_loss = 7.803762245923281, train_acc = 0.9848625989753144\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 71, train_loss = 7.69156676158309, train_acc = 0.9852119236143456\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 72, train_loss = 7.581952819600701, train_acc = 0.9852119236143456\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 73, train_loss = 7.474694954231381, train_acc = 0.9852119236143456\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 74, train_loss = 7.369685331359506, train_acc = 0.985444806707033\n",
      "test Acc 0.9799813780260708:\n",
      "14th- epoch: 75, train_loss = 7.267129268497229, train_acc = 0.9855612482533768\n",
      "test Acc 0.9799813780260708:\n",
      "14th- epoch: 76, train_loss = 7.1666322480887175, train_acc = 0.9856776897997206\n",
      "test Acc 0.9799813780260708:\n",
      "14th- epoch: 77, train_loss = 7.068245008587837, train_acc = 0.985910572892408\n",
      "test Acc 0.9799813780260708:\n",
      "14th- epoch: 78, train_loss = 6.971927151083946, train_acc = 0.9860270144387517\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 79, train_loss = 6.877702632918954, train_acc = 0.9864927806241267\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 80, train_loss = 6.785254754126072, train_acc = 0.9870749883558454\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 81, train_loss = 6.69480112567544, train_acc = 0.9877736376339078\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 82, train_loss = 6.606268923729658, train_acc = 0.9884722869119702\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 83, train_loss = 6.519166734069586, train_acc = 0.9885887284583139\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 84, train_loss = 6.43379507958889, train_acc = 0.9889380530973452\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 85, train_loss = 6.350086074322462, train_acc = 0.9890544946436889\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 86, train_loss = 6.267873131670058, train_acc = 0.9889380530973452\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 87, train_loss = 6.187320887111127, train_acc = 0.9891709361900326\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 88, train_loss = 6.108158553950489, train_acc = 0.9896367023754076\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 89, train_loss = 6.030492258258164, train_acc = 0.9896367023754076\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 90, train_loss = 5.954119833186269, train_acc = 0.9897531439217513\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 91, train_loss = 5.879269518889487, train_acc = 0.989869585468095\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 92, train_loss = 5.805458421818912, train_acc = 0.9899860270144387\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 93, train_loss = 5.733035194687545, train_acc = 0.9901024685607824\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 94, train_loss = 5.6617842661216855, train_acc = 0.99033535165347\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 95, train_loss = 5.59200675226748, train_acc = 0.9905682347461574\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 96, train_loss = 5.523178422823548, train_acc = 0.9906846762925011\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 97, train_loss = 5.455692403949797, train_acc = 0.990801117838845\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 98, train_loss = 5.389220949262381, train_acc = 0.990801117838845\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 99, train_loss = 5.323886097408831, train_acc = 0.9910340009315324\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 100, train_loss = 5.259749959222972, train_acc = 0.9911504424778761\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 101, train_loss = 5.196531289257109, train_acc = 0.9911504424778761\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 102, train_loss = 5.134442982263863, train_acc = 0.9912668840242198\n",
      "test Acc 0.9818435754189944:\n",
      "14th- epoch: 103, train_loss = 5.073380070738494, train_acc = 0.9912668840242198\n",
      "test Acc 0.9818435754189944:\n",
      "14th- epoch: 104, train_loss = 5.013098181225359, train_acc = 0.9914997671169073\n",
      "test Acc 0.9823091247672253:\n",
      "14th- epoch: 105, train_loss = 4.954126146622002, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "14th- epoch: 106, train_loss = 4.895917941816151, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "14th- epoch: 107, train_loss = 4.838666643947363, train_acc = 0.9914997671169073\n",
      "test Acc 0.9823091247672253:\n",
      "14th- epoch: 108, train_loss = 4.782272235490382, train_acc = 0.9918490917559385\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 109, train_loss = 4.726826281286776, train_acc = 0.992081974848626\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 110, train_loss = 4.6723462007939816, train_acc = 0.9921984163949698\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 111, train_loss = 4.618776902556419, train_acc = 0.9921984163949698\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 112, train_loss = 4.565992356278002, train_acc = 0.9921984163949698\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 113, train_loss = 4.51394950132817, train_acc = 0.9921984163949698\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 114, train_loss = 4.463006069883704, train_acc = 0.9921984163949698\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 115, train_loss = 4.412645095027983, train_acc = 0.992081974848626\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 116, train_loss = 4.363146083429456, train_acc = 0.992081974848626\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 117, train_loss = 4.31439390219748, train_acc = 0.9923148579413135\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 118, train_loss = 4.266583095304668, train_acc = 0.9925477410340009\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 119, train_loss = 4.219439587555826, train_acc = 0.9925477410340009\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 120, train_loss = 4.172947779297829, train_acc = 0.9925477410340009\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 121, train_loss = 4.1273667719215155, train_acc = 0.9926641825803446\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 122, train_loss = 4.082323146052659, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 123, train_loss = 4.0380835719406605, train_acc = 0.9927806241266884\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 124, train_loss = 3.994606132619083, train_acc = 0.9927806241266884\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 125, train_loss = 3.95183552056551, train_acc = 0.9930135072193759\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 126, train_loss = 3.9097096510231495, train_acc = 0.9930135072193759\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 127, train_loss = 3.8683811919763684, train_acc = 0.9930135072193759\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 128, train_loss = 3.8276319578289986, train_acc = 0.9930135072193759\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 129, train_loss = 3.7875304431654513, train_acc = 0.9930135072193759\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 130, train_loss = 3.7481161481700838, train_acc = 0.9930135072193759\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 131, train_loss = 3.7093301438726485, train_acc = 0.9931299487657196\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 132, train_loss = 3.6710010315291584, train_acc = 0.9932463903120633\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 133, train_loss = 3.6333482614718378, train_acc = 0.9933628318584071\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 134, train_loss = 3.5962662994861603, train_acc = 0.9933628318584071\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 135, train_loss = 3.559719188604504, train_acc = 0.9933628318584071\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 136, train_loss = 3.5238617793656886, train_acc = 0.9934792734047508\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 137, train_loss = 3.4885555058717728, train_acc = 0.9937121564974383\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 138, train_loss = 3.4537553675472736, train_acc = 0.993828598043782\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 139, train_loss = 3.4195931279100478, train_acc = 0.993828598043782\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 140, train_loss = 3.3859898350201547, train_acc = 0.9939450395901258\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 141, train_loss = 3.3529599346220493, train_acc = 0.9939450395901258\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 142, train_loss = 3.320309971924871, train_acc = 0.9939450395901258\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 143, train_loss = 3.288429534062743, train_acc = 0.994294364229157\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 144, train_loss = 3.2568699326366186, train_acc = 0.994294364229157\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 145, train_loss = 3.2259841500781476, train_acc = 0.9944108057755007\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 146, train_loss = 3.1954231350682676, train_acc = 0.9944108057755007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 147, train_loss = 3.1654885448515415, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 148, train_loss = 3.135985368862748, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 149, train_loss = 3.1069085504859686, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 150, train_loss = 3.0784066412597895, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 151, train_loss = 3.0502816936932504, train_acc = 0.9945272473218444\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 152, train_loss = 3.022591814864427, train_acc = 0.9945272473218444\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 153, train_loss = 2.995374182239175, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 154, train_loss = 2.9686375432647765, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 155, train_loss = 2.9423333355225623, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 156, train_loss = 2.916311542969197, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 157, train_loss = 2.890730292070657, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 158, train_loss = 2.8657345571555197, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 159, train_loss = 2.8409466934390366, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 160, train_loss = 2.8165281540714204, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 161, train_loss = 2.792664895299822, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 162, train_loss = 2.7689789682626724, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 163, train_loss = 2.7457723021507263, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 164, train_loss = 2.7229601689614356, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 165, train_loss = 2.7004088670946658, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 166, train_loss = 2.6783331260085106, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 167, train_loss = 2.656518876552582, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 168, train_loss = 2.6351089156232774, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 169, train_loss = 2.6139743528328836, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 170, train_loss = 2.5933622419834137, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 171, train_loss = 2.572838334366679, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 172, train_loss = 2.5528123807162046, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 173, train_loss = 2.533035766799003, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 174, train_loss = 2.513591606169939, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 175, train_loss = 2.494367573875934, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 176, train_loss = 2.475638484582305, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 177, train_loss = 2.457010992569849, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 178, train_loss = 2.4387284356635064, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 179, train_loss = 2.420730647398159, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 180, train_loss = 2.4030308939982206, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 181, train_loss = 2.3855179909151047, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 182, train_loss = 2.368320443900302, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 183, train_loss = 2.3514101821929216, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 184, train_loss = 2.334831041516736, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 185, train_loss = 2.3183976355940104, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 186, train_loss = 2.3022534381598234, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 187, train_loss = 2.286360340891406, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 188, train_loss = 2.270623217104003, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 189, train_loss = 2.2552515554707497, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 190, train_loss = 2.239988214103505, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 191, train_loss = 2.225019946694374, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 192, train_loss = 2.210308442590758, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 193, train_loss = 2.195791858015582, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 194, train_loss = 2.1813830237369984, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 195, train_loss = 2.167290721088648, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 196, train_loss = 2.153406812576577, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 197, train_loss = 2.1396175536792725, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 198, train_loss = 2.1261535224039108, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 199, train_loss = 2.11284951120615, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 200, train_loss = 2.099628907861188, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 201, train_loss = 2.0868021983187646, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 202, train_loss = 2.073911003768444, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 203, train_loss = 2.061469905078411, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 204, train_loss = 2.0489627942442894, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 205, train_loss = 2.0367592859547585, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 206, train_loss = 2.0246956795454025, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 207, train_loss = 2.0128330253064632, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 208, train_loss = 2.001105150906369, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 209, train_loss = 1.9896196499466896, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 210, train_loss = 1.978174911113456, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 211, train_loss = 1.9670884150546044, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 212, train_loss = 1.9559783414006233, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 213, train_loss = 1.9451150845270604, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 214, train_loss = 1.9343324303627014, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 215, train_loss = 1.9238186180591583, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 216, train_loss = 1.9133501499891281, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 217, train_loss = 1.903109862236306, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 218, train_loss = 1.892921980470419, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 219, train_loss = 1.8829944767057896, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 220, train_loss = 1.8730970174074173, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 221, train_loss = 1.863468088209629, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 222, train_loss = 1.853789184242487, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 223, train_loss = 1.8443617895245552, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 224, train_loss = 1.8349852859973907, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 225, train_loss = 1.8258210308849812, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 226, train_loss = 1.8167225930374116, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 227, train_loss = 1.8077993865590543, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 228, train_loss = 1.7988927848637104, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 229, train_loss = 1.7902192933252081, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 230, train_loss = 1.7816297548124567, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 231, train_loss = 1.773142609745264, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 232, train_loss = 1.764694677083753, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 233, train_loss = 1.7565474262228236, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 234, train_loss = 1.748276329250075, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 235, train_loss = 1.7403720567235723, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 236, train_loss = 1.7323295524111018, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 237, train_loss = 1.7245474805822596, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 238, train_loss = 1.716672113747336, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 239, train_loss = 1.7090958034386858, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 240, train_loss = 1.701558493077755, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 241, train_loss = 1.6941039761295542, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 242, train_loss = 1.6867218700936064, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 243, train_loss = 1.6794515835354105, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 244, train_loss = 1.6722526947269216, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 245, train_loss = 1.6651997404405847, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 246, train_loss = 1.658134630532004, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 247, train_loss = 1.6513115962734446, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 248, train_loss = 1.6443827586481348, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 249, train_loss = 1.6376708211610094, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 250, train_loss = 1.6309305019676685, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 251, train_loss = 1.6244313642382622, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 252, train_loss = 1.6178190322825685, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 253, train_loss = 1.611369427293539, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 254, train_loss = 1.6049476141342893, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 255, train_loss = 1.598708258359693, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 256, train_loss = 1.5924145877361298, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 257, train_loss = 1.5862526769051328, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 258, train_loss = 1.5801437447080389, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 259, train_loss = 1.5741479123244062, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 260, train_loss = 1.5681782265892252, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 261, train_loss = 1.5623214952647686, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 262, train_loss = 1.5564817363629118, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 263, train_loss = 1.5506875576684251, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 264, train_loss = 1.5450231930008158, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 265, train_loss = 1.539369836449623, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 266, train_loss = 1.5338360033929348, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 267, train_loss = 1.5283144389977679, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 268, train_loss = 1.5228821063647047, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 269, train_loss = 1.5174870764603838, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 270, train_loss = 1.512134594260715, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 271, train_loss = 1.5068515291204676, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 272, train_loss = 1.5017000958323479, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 273, train_loss = 1.4965055584907532, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 274, train_loss = 1.491401817649603, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 275, train_loss = 1.486253034323454, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 276, train_loss = 1.4813459689030424, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 277, train_loss = 1.4763657847652212, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 278, train_loss = 1.471468130708672, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 279, train_loss = 1.4666228195419535, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 280, train_loss = 1.4618466285755858, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 281, train_loss = 1.4570212761173025, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 282, train_loss = 1.4523482024669647, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 283, train_loss = 1.4476837789407, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 284, train_loss = 1.4430791152408347, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 285, train_loss = 1.4385086571564898, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 286, train_loss = 1.4339277012040839, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 287, train_loss = 1.4294526688754559, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 288, train_loss = 1.4250612445175648, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 289, train_loss = 1.4206106761703268, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 290, train_loss = 1.416299263597466, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 291, train_loss = 1.4119303239276633, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 292, train_loss = 1.4077284807572141, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 293, train_loss = 1.4034986297483556, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 294, train_loss = 1.3993192265625112, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 295, train_loss = 1.3951269686222076, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 296, train_loss = 1.3910766914486885, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 297, train_loss = 1.3869503997266293, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 298, train_loss = 1.3829927195911296, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 299, train_loss = 1.378980750858318, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 300, train_loss = 1.374993771314621, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 301, train_loss = 1.371089109510649, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 302, train_loss = 1.3672136415843852, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 303, train_loss = 1.363326332240831, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 304, train_loss = 1.3596372182364576, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 305, train_loss = 1.3558156602084637, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 306, train_loss = 1.3520604471559636, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 307, train_loss = 1.3483716498012654, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 308, train_loss = 1.344643920660019, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 309, train_loss = 1.3410306138102897, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 310, train_loss = 1.3374782291357405, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 311, train_loss = 1.3338691008393653, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 312, train_loss = 1.330402969091665, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 313, train_loss = 1.326802468567621, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 314, train_loss = 1.3233958768541925, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 315, train_loss = 1.3199253517086618, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 316, train_loss = 1.3164773757453077, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 317, train_loss = 1.3130936088855378, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 318, train_loss = 1.3097314263577573, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 319, train_loss = 1.3063844082062133, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 320, train_loss = 1.3031042267684825, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 321, train_loss = 1.2998741008341312, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 322, train_loss = 1.2966190315783024, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 323, train_loss = 1.293402702838648, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 324, train_loss = 1.2902672055060975, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 325, train_loss = 1.2870695988531224, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 326, train_loss = 1.2839890544419177, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 327, train_loss = 1.280819843232166, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 328, train_loss = 1.2777220134739764, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 329, train_loss = 1.2747529434855096, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 330, train_loss = 1.2717048774356954, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 331, train_loss = 1.268637303262949, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 332, train_loss = 1.265749475627672, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 333, train_loss = 1.2627191208302975, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 334, train_loss = 1.2598485660855658, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 335, train_loss = 1.2569105264847167, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 336, train_loss = 1.2540713523630984, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 337, train_loss = 1.2511667273938656, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 338, train_loss = 1.2483124062418938, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 339, train_loss = 1.2455350160598755, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 340, train_loss = 1.2427477166056633, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 341, train_loss = 1.239977331191767, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 342, train_loss = 1.23725938051939, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 343, train_loss = 1.2344364486634731, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 344, train_loss = 1.2318026373977773, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 345, train_loss = 1.2290811464190483, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 346, train_loss = 1.2264184367959388, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 347, train_loss = 1.223841826140415, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 348, train_loss = 1.2211857053334825, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 349, train_loss = 1.2186187480692752, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 350, train_loss = 1.215940238267649, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 351, train_loss = 1.2134473870391957, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 352, train_loss = 1.2109099800582044, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 353, train_loss = 1.208396351605188, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 354, train_loss = 1.2059316337108612, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 355, train_loss = 1.203360750048887, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 356, train_loss = 1.2009509168565273, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 357, train_loss = 1.198492741852533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 358, train_loss = 1.196146633476019, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 359, train_loss = 1.1937060207128525, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 360, train_loss = 1.1913491760496981, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 361, train_loss = 1.1889826369588263, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 362, train_loss = 1.1865586030180566, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 363, train_loss = 1.1842995907063596, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 364, train_loss = 1.1819517861003987, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 365, train_loss = 1.1796482826466672, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 366, train_loss = 1.1774521544575691, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 367, train_loss = 1.1751646672491916, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 368, train_loss = 1.17286741361022, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 369, train_loss = 1.1706799007952213, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 370, train_loss = 1.168426688760519, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 371, train_loss = 1.1662484146654606, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 372, train_loss = 1.1640423747594468, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 373, train_loss = 1.1618146796827205, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 374, train_loss = 1.1597342627937905, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 375, train_loss = 1.1575070631806739, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 376, train_loss = 1.1554626996512525, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 377, train_loss = 1.1533772771363147, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 378, train_loss = 1.1512431452865712, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 379, train_loss = 1.14921286952449, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 380, train_loss = 1.147110900550615, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 381, train_loss = 1.1450793892145157, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 382, train_loss = 1.1430395903880708, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 383, train_loss = 1.141078206419479, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 384, train_loss = 1.1389992162585258, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 385, train_loss = 1.1370785335893743, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 386, train_loss = 1.1351089800300542, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 387, train_loss = 1.1331164799630642, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 388, train_loss = 1.1311603734793607, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 389, train_loss = 1.1291794752178248, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 390, train_loss = 1.1272874412534293, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 391, train_loss = 1.125395284354454, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 392, train_loss = 1.1234459057450294, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 393, train_loss = 1.1216452457010746, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 394, train_loss = 1.119718095898861, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 395, train_loss = 1.1178476413188037, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 396, train_loss = 1.1160046359000262, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 397, train_loss = 1.11418847242021, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 398, train_loss = 1.11233594888472, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 399, train_loss = 1.1105655916035175, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 400, train_loss = 1.1087002642452717, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 401, train_loss = 1.106969946384197, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 402, train_loss = 1.1051713886263315, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 403, train_loss = 1.103405423462391, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 404, train_loss = 1.1015864461660385, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 405, train_loss = 1.0998812119069044, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 406, train_loss = 1.098189794778591, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 407, train_loss = 1.0963848581013735, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 408, train_loss = 1.094677214830881, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 409, train_loss = 1.0929694337246474, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 410, train_loss = 1.0912283807992935, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 411, train_loss = 1.0895743879082147, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 412, train_loss = 1.087880970299011, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 413, train_loss = 1.0861641479132231, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 414, train_loss = 1.0844967179000378, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 415, train_loss = 1.082888233155245, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 416, train_loss = 1.0811455758812372, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 417, train_loss = 1.0794623394904193, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 418, train_loss = 1.0778621348144952, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 419, train_loss = 1.076161158591276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 420, train_loss = 1.0745380645093974, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 421, train_loss = 1.072902293264633, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 422, train_loss = 1.0713266680540983, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 423, train_loss = 1.0697336395678576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 424, train_loss = 1.0681811049580574, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 425, train_loss = 1.066676681250101, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 426, train_loss = 1.0651508966984693, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 427, train_loss = 1.063594209641451, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 428, train_loss = 1.0621448159217834, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 429, train_loss = 1.0605274575354997, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 430, train_loss = 1.0591593546268996, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 431, train_loss = 1.057547959178919, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 432, train_loss = 1.056136508792406, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 433, train_loss = 1.0546163022518158, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 434, train_loss = 1.0532499266264495, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 435, train_loss = 1.051727178186411, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 436, train_loss = 1.0503179343941156, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 437, train_loss = 1.0488636431691702, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 438, train_loss = 1.0474858569505159, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 439, train_loss = 1.0460604342224542, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 440, train_loss = 1.0446384859678801, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 441, train_loss = 1.0432515206339303, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 442, train_loss = 1.041832908987999, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 443, train_loss = 1.0405146429839078, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 444, train_loss = 1.0390871862473432, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 445, train_loss = 1.0377159689960536, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 446, train_loss = 1.0363441084919032, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 447, train_loss = 1.0350527167320251, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 448, train_loss = 1.033707677066559, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 449, train_loss = 1.0323423793015536, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 450, train_loss = 1.031047868222231, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 451, train_loss = 1.029722989856964, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 452, train_loss = 1.028375436872011, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 453, train_loss = 1.0270961461064871, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 454, train_loss = 1.0257646664977074, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 455, train_loss = 1.024500952422386, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 456, train_loss = 1.02321245521307, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 457, train_loss = 1.021971376001602, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 458, train_loss = 1.020634916931158, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 459, train_loss = 1.0194317698478699, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 460, train_loss = 1.018152521312004, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 461, train_loss = 1.016889113932848, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 462, train_loss = 1.015662266552681, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 463, train_loss = 1.0144379971025046, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 464, train_loss = 1.0131939413549844, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 465, train_loss = 1.0120047939417418, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 466, train_loss = 1.0107207223773003, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 467, train_loss = 1.00957652926445, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 468, train_loss = 1.0083175810577814, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 469, train_loss = 1.0071259016694967, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 470, train_loss = 1.0059649845061358, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 471, train_loss = 1.004811566323042, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 472, train_loss = 1.0035991271433886, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 473, train_loss = 1.0024246821703855, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 474, train_loss = 1.0012464001774788, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 475, train_loss = 1.0001471601426601, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 476, train_loss = 0.9990036897361279, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 477, train_loss = 0.9978312402963638, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 478, train_loss = 0.9966812183556613, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 479, train_loss = 0.9955325114133302, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 480, train_loss = 0.9944029984471854, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 481, train_loss = 0.9932906577887479, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 482, train_loss = 0.9922107035818044, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 483, train_loss = 0.9910903126001358, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 484, train_loss = 0.9899865674378816, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 485, train_loss = 0.9888525754213333, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 486, train_loss = 0.9877174086868763, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 487, train_loss = 0.9866543759999331, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 488, train_loss = 0.985652506351471, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 489, train_loss = 0.9844732272031251, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 490, train_loss = 0.9835040693578776, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 491, train_loss = 0.982338654488558, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 492, train_loss = 0.9813297030923422, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 493, train_loss = 0.980227646738058, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 494, train_loss = 0.9792210260930005, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 495, train_loss = 0.9781571378407534, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 496, train_loss = 0.9770986288785934, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 497, train_loss = 0.9760921187698841, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 498, train_loss = 0.9749770487251226, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 499, train_loss = 0.9739148641529027, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████████████████████████▋                                     | 14/30 [1:35:34<1:49:47, 411.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "15th- epoch: 0, train_loss = 269.6178718805313, train_acc = 0.50966464834653\n",
      "test Acc 0.5581936685288641:\n",
      "15th- epoch: 1, train_loss = 206.388316988945, train_acc = 0.5608989287377736\n",
      "test Acc 0.5702979515828678:\n",
      "15th- epoch: 2, train_loss = 162.54910534620285, train_acc = 0.5742897065673032\n",
      "test Acc 0.6014897579143389:\n",
      "15th- epoch: 3, train_loss = 135.8161392211914, train_acc = 0.6468327899394504\n",
      "test Acc 0.7150837988826816:\n",
      "15th- epoch: 4, train_loss = 117.24842154979706, train_acc = 0.7371914299021891\n",
      "test Acc 0.771415270018622:\n",
      "15th- epoch: 5, train_loss = 102.77476674318314, train_acc = 0.783884489986027\n",
      "test Acc 0.8142458100558659:\n",
      "15th- epoch: 6, train_loss = 90.79799976944923, train_acc = 0.80985095482068\n",
      "test Acc 0.8282122905027933:\n",
      "15th- epoch: 7, train_loss = 80.78073540329933, train_acc = 0.8187005123428039\n",
      "test Acc 0.8361266294227188:\n",
      "15th- epoch: 8, train_loss = 72.3094753921032, train_acc = 0.8357009781089892\n",
      "test Acc 0.8538175046554934:\n",
      "15th- epoch: 9, train_loss = 64.95330893993378, train_acc = 0.8584070796460177\n",
      "test Acc 0.8710428305400373:\n",
      "15th- epoch: 10, train_loss = 58.474328964948654, train_acc = 0.8802980903586399\n",
      "test Acc 0.8896648044692738:\n",
      "15th- epoch: 11, train_loss = 52.770032331347466, train_acc = 0.9010246856078249\n",
      "test Acc 0.9129422718808193:\n",
      "15th- epoch: 12, train_loss = 47.77171428501606, train_acc = 0.9237307871448532\n",
      "test Acc 0.9315642458100558:\n",
      "15th- epoch: 13, train_loss = 43.41904218494892, train_acc = 0.9377037727061015\n",
      "test Acc 0.9376163873370578:\n",
      "15th- epoch: 14, train_loss = 39.648819506168365, train_acc = 0.9437587331159758\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 15, train_loss = 36.3885602504015, train_acc = 0.9469026548672567\n",
      "test Acc 0.9441340782122905:\n",
      "15th- epoch: 16, train_loss = 33.57545734196901, train_acc = 0.9496972519795063\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 17, train_loss = 31.14845412224531, train_acc = 0.9519096413600373\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 18, train_loss = 29.052301317453384, train_acc = 0.9542384722869119\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 19, train_loss = 27.236291021108627, train_acc = 0.9574988355845365\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 20, train_loss = 25.65520004928112, train_acc = 0.9605263157894737\n",
      "test Acc 0.9529795158286778:\n",
      "15th- epoch: 21, train_loss = 24.271789595484734, train_acc = 0.9629715882626921\n",
      "test Acc 0.957169459962756:\n",
      "15th- epoch: 22, train_loss = 23.05370171740651, train_acc = 0.9657661853749417\n",
      "test Acc 0.9604283054003724:\n",
      "15th- epoch: 23, train_loss = 21.97539608180523, train_acc = 0.9673963670237541\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 24, train_loss = 21.014222014695406, train_acc = 0.9683278993945039\n",
      "test Acc 0.9622905027932961:\n",
      "15th- epoch: 25, train_loss = 20.149689696729183, train_acc = 0.9689101071262226\n",
      "test Acc 0.962756052141527:\n",
      "15th- epoch: 26, train_loss = 19.36716902628541, train_acc = 0.9694923148579413\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 27, train_loss = 18.654905397444963, train_acc = 0.9703074056823474\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 28, train_loss = 18.003156580030918, train_acc = 0.9715882626921285\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 29, train_loss = 17.4037670083344, train_acc = 0.9728691197019096\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 30, train_loss = 16.850316628813744, train_acc = 0.9731020027945971\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 31, train_loss = 16.337691366672516, train_acc = 0.9734513274336283\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 32, train_loss = 15.861360341310501, train_acc = 0.9741499767116907\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 33, train_loss = 15.41633464768529, train_acc = 0.9747321844434094\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 34, train_loss = 14.999056097120047, train_acc = 0.9750815090824406\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 35, train_loss = 14.606362856924534, train_acc = 0.975314392175128\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 36, train_loss = 14.235861469060183, train_acc = 0.9756637168141593\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 37, train_loss = 13.88550829142332, train_acc = 0.9761294829995343\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 38, train_loss = 13.553791668266058, train_acc = 0.9769445738239404\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 39, train_loss = 13.239080287516117, train_acc = 0.9778761061946902\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 40, train_loss = 12.93995662778616, train_acc = 0.9784583139264089\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 41, train_loss = 12.65487227961421, train_acc = 0.9791569632044713\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 42, train_loss = 12.382665276527405, train_acc = 0.9792734047508151\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 43, train_loss = 12.12223369255662, train_acc = 0.97973917093619\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 44, train_loss = 11.87263147905469, train_acc = 0.9798556124825337\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 45, train_loss = 11.63340924680233, train_acc = 0.9800884955752213\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 46, train_loss = 11.403636571019888, train_acc = 0.9803213786679087\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 47, train_loss = 11.18265462294221, train_acc = 0.9804378202142524\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 48, train_loss = 10.96976063027978, train_acc = 0.9809035863996274\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 49, train_loss = 10.764794275164604, train_acc = 0.9811364694923148\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 50, train_loss = 10.566859539598227, train_acc = 0.9812529110386586\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 51, train_loss = 10.375392626971006, train_acc = 0.9814857941313461\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 52, train_loss = 10.190238654613495, train_acc = 0.9820680018630648\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 53, train_loss = 10.010996866971254, train_acc = 0.9823008849557522\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 54, train_loss = 9.837375536561012, train_acc = 0.9824173265020959\n",
      "test Acc 0.9748603351955307:\n",
      "15th- epoch: 55, train_loss = 9.669080270454288, train_acc = 0.9826502095947834\n",
      "test Acc 0.9748603351955307:\n",
      "15th- epoch: 56, train_loss = 9.505748959258199, train_acc = 0.9826502095947834\n",
      "test Acc 0.9748603351955307:\n",
      "15th- epoch: 57, train_loss = 9.347259014844894, train_acc = 0.9828830926874709\n",
      "test Acc 0.9748603351955307:\n",
      "15th- epoch: 58, train_loss = 9.19319056533277, train_acc = 0.9828830926874709\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 59, train_loss = 9.043334310874343, train_acc = 0.9831159757801584\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 60, train_loss = 8.897395877167583, train_acc = 0.9833488588728458\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 61, train_loss = 8.755226714536548, train_acc = 0.9835817419655333\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 62, train_loss = 8.616990614682436, train_acc = 0.9839310666045645\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 63, train_loss = 8.482175968587399, train_acc = 0.984163949697252\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 64, train_loss = 8.350944053381681, train_acc = 0.9846297158826269\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 65, train_loss = 8.22283659875393, train_acc = 0.9847461574289706\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 66, train_loss = 8.097937811166048, train_acc = 0.9847461574289706\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 67, train_loss = 7.975970624014735, train_acc = 0.9848625989753144\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 68, train_loss = 7.856956837698817, train_acc = 0.9850954820680019\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 69, train_loss = 7.7406852673739195, train_acc = 0.9852119236143456\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 70, train_loss = 7.627008598297834, train_acc = 0.9852119236143456\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 71, train_loss = 7.515865178778768, train_acc = 0.9853283651606893\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 72, train_loss = 7.407244672998786, train_acc = 0.9855612482533768\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 73, train_loss = 7.300932290032506, train_acc = 0.985910572892408\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 74, train_loss = 7.1970459669828415, train_acc = 0.9860270144387517\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 75, train_loss = 7.095214316621423, train_acc = 0.986376339077783\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 76, train_loss = 6.995235741138458, train_acc = 0.9866092221704704\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 77, train_loss = 6.897343477234244, train_acc = 0.9867256637168141\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 78, train_loss = 6.801343683153391, train_acc = 0.9867256637168141\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 79, train_loss = 6.707367051392794, train_acc = 0.9868421052631579\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 80, train_loss = 6.61525247618556, train_acc = 0.9868421052631579\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 81, train_loss = 6.525194624438882, train_acc = 0.9869585468095017\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 82, train_loss = 6.4368582889437675, train_acc = 0.9870749883558454\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 83, train_loss = 6.350214237347245, train_acc = 0.9870749883558454\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 84, train_loss = 6.265264432877302, train_acc = 0.9875407545412203\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 85, train_loss = 6.181890914216638, train_acc = 0.9876571960875641\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 86, train_loss = 6.100026460364461, train_acc = 0.9880065207265952\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 87, train_loss = 6.019754933193326, train_acc = 0.9883558453656265\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 88, train_loss = 5.94092577137053, train_acc = 0.9884722869119702\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 89, train_loss = 5.863495385274291, train_acc = 0.9884722869119702\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 90, train_loss = 5.787480251863599, train_acc = 0.9888216115510013\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 91, train_loss = 5.712796961888671, train_acc = 0.9891709361900326\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 92, train_loss = 5.639254447072744, train_acc = 0.9892873777363763\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 93, train_loss = 5.567216074094176, train_acc = 0.9895202608290639\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 94, train_loss = 5.496357794851065, train_acc = 0.9895202608290639\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 95, train_loss = 5.4267114493995905, train_acc = 0.9897531439217513\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 96, train_loss = 5.358214696869254, train_acc = 0.9901024685607824\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 97, train_loss = 5.290898140519857, train_acc = 0.9901024685607824\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 98, train_loss = 5.224655898287892, train_acc = 0.9904517931998137\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 99, train_loss = 5.15960057079792, train_acc = 0.9905682347461574\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 100, train_loss = 5.095507072284818, train_acc = 0.9906846762925011\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 101, train_loss = 5.032436518929899, train_acc = 0.9909175593851887\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 102, train_loss = 4.97047942597419, train_acc = 0.9912668840242198\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 103, train_loss = 4.909586695954204, train_acc = 0.9913833255705635\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 104, train_loss = 4.849785855971277, train_acc = 0.9914997671169073\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 105, train_loss = 4.790815834887326, train_acc = 0.9914997671169073\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 106, train_loss = 4.733150749467313, train_acc = 0.9917326502095948\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 107, train_loss = 4.676220953464508, train_acc = 0.9917326502095948\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 108, train_loss = 4.620313549414277, train_acc = 0.9918490917559385\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 109, train_loss = 4.565371172502637, train_acc = 0.9918490917559385\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 110, train_loss = 4.511323817074299, train_acc = 0.9919655333022822\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 111, train_loss = 4.457986192777753, train_acc = 0.9921984163949698\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 112, train_loss = 4.40562348626554, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 113, train_loss = 4.354038496501744, train_acc = 0.9926641825803446\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 114, train_loss = 4.30327580217272, train_acc = 0.9926641825803446\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 115, train_loss = 4.253207157365978, train_acc = 0.9928970656730322\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 116, train_loss = 4.204179096035659, train_acc = 0.9931299487657196\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 117, train_loss = 4.155704623088241, train_acc = 0.9932463903120633\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 118, train_loss = 4.1080745393410325, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 119, train_loss = 4.061332277953625, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 120, train_loss = 4.01523426361382, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 121, train_loss = 3.969911058433354, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 122, train_loss = 3.9253497794270515, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 123, train_loss = 3.881629512645304, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 124, train_loss = 3.8385336780920625, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 125, train_loss = 3.796116502955556, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 126, train_loss = 3.7546690376475453, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 127, train_loss = 3.7138318317011, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 128, train_loss = 3.673495444469154, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 129, train_loss = 3.634138516150415, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 130, train_loss = 3.5953436493873596, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 131, train_loss = 3.557279816828668, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 132, train_loss = 3.5198194179683924, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 133, train_loss = 3.4829943459481, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 134, train_loss = 3.4468919029459357, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 135, train_loss = 3.4114370960742235, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 136, train_loss = 3.376608781516552, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 137, train_loss = 3.342247293330729, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 138, train_loss = 3.3086029971018434, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 139, train_loss = 3.2755807116627693, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 140, train_loss = 3.2430066354572773, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 141, train_loss = 3.211125111207366, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 142, train_loss = 3.1796924555674195, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 143, train_loss = 3.1490017119795084, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 144, train_loss = 3.118561907671392, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 145, train_loss = 3.088773373514414, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 146, train_loss = 3.059518034569919, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 147, train_loss = 3.030636948533356, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 148, train_loss = 3.002350280061364, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 149, train_loss = 2.974610694218427, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 150, train_loss = 2.9472697637975216, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 151, train_loss = 2.920422174036503, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 152, train_loss = 2.894028540700674, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 153, train_loss = 2.8681393242441118, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 154, train_loss = 2.842607457190752, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 155, train_loss = 2.817495500203222, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 156, train_loss = 2.7929801209829748, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 157, train_loss = 2.7687235386110842, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 158, train_loss = 2.7448614328168333, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 159, train_loss = 2.7213626108132303, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 160, train_loss = 2.6983125135302544, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 161, train_loss = 2.6756819882430136, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 162, train_loss = 2.653271995484829, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 163, train_loss = 2.6313612810336053, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 164, train_loss = 2.609790913760662, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 165, train_loss = 2.588598970323801, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 166, train_loss = 2.5677778287790716, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 167, train_loss = 2.547338642179966, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 168, train_loss = 2.5271795131266117, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 169, train_loss = 2.507456415798515, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 170, train_loss = 2.4879724555648863, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 171, train_loss = 2.468938851263374, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 172, train_loss = 2.4500504680909216, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 173, train_loss = 2.4316026531159878, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 174, train_loss = 2.4133440763689578, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 175, train_loss = 2.3955084420740604, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 176, train_loss = 2.3778370856307447, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 177, train_loss = 2.3604642301797867, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 178, train_loss = 2.3435004465281963, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 179, train_loss = 2.326665258500725, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 180, train_loss = 2.3100949190557003, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 181, train_loss = 2.29402648890391, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 182, train_loss = 2.278034321963787, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 183, train_loss = 2.262307172175497, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 184, train_loss = 2.2468162872828543, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 185, train_loss = 2.23158814990893, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 186, train_loss = 2.2167310207150877, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 187, train_loss = 2.2018957533873618, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 188, train_loss = 2.1874509998597205, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 189, train_loss = 2.1731709600426257, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 190, train_loss = 2.1590063660405576, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 191, train_loss = 2.1451668911613524, train_acc = 0.9968560782487191\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 192, train_loss = 2.131525499280542, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 193, train_loss = 2.1182221635244787, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 194, train_loss = 2.1049812086857855, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 195, train_loss = 2.0918930335901678, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 196, train_loss = 2.0791878141462803, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 197, train_loss = 2.066487640142441, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 198, train_loss = 2.054131880402565, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 199, train_loss = 2.0418474711477757, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 200, train_loss = 2.029885958880186, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 201, train_loss = 2.017940703779459, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 202, train_loss = 2.00630442914553, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 203, train_loss = 1.9949260938446969, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 204, train_loss = 1.9836062018293887, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 205, train_loss = 1.972397517412901, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 206, train_loss = 1.9614971193950623, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 207, train_loss = 1.9507821712177247, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 208, train_loss = 1.9400857724249363, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 209, train_loss = 1.929624367505312, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 210, train_loss = 1.919265688629821, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 211, train_loss = 1.909157642396167, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 212, train_loss = 1.8990117646753788, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 213, train_loss = 1.8890774745959789, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 214, train_loss = 1.8794147882144898, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 215, train_loss = 1.8698269345331937, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 216, train_loss = 1.8602861643303186, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 217, train_loss = 1.8509067881386727, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 218, train_loss = 1.841756918700412, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 219, train_loss = 1.8326937214005738, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 220, train_loss = 1.823657200904563, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 221, train_loss = 1.8148376364260912, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 222, train_loss = 1.806093393592164, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 223, train_loss = 1.7975018073339015, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 224, train_loss = 1.7891087506432086, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 225, train_loss = 1.7806532632093877, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 226, train_loss = 1.7724228526931256, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 227, train_loss = 1.7642455361783504, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 228, train_loss = 1.7562630611937493, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 229, train_loss = 1.7482137668412179, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 230, train_loss = 1.7403737257700413, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 231, train_loss = 1.7326638847589493, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 232, train_loss = 1.7250135850626975, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 233, train_loss = 1.71748207625933, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 234, train_loss = 1.7100303892511874, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 235, train_loss = 1.7026559300720692, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 236, train_loss = 1.6954081777948886, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 237, train_loss = 1.688215509057045, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 238, train_loss = 1.6811211209278554, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 239, train_loss = 1.6740969058591872, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 240, train_loss = 1.6672338917851448, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 241, train_loss = 1.6602988839149475, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 242, train_loss = 1.6536527711432427, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 243, train_loss = 1.6469051043968648, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 244, train_loss = 1.6402838106732816, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 245, train_loss = 1.6338502317667007, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 246, train_loss = 1.6273720562458038, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 247, train_loss = 1.6209876115899533, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 248, train_loss = 1.6146715842187405, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 249, train_loss = 1.608439140021801, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 250, train_loss = 1.6023007594048977, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 251, train_loss = 1.5962237443309277, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 252, train_loss = 1.5901732903439552, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 253, train_loss = 1.5843042321503162, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 254, train_loss = 1.5783163930755109, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 255, train_loss = 1.5725750338751823, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 256, train_loss = 1.5668210845906287, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 257, train_loss = 1.5610940357437357, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 258, train_loss = 1.555478377849795, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 259, train_loss = 1.5498822890222073, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 260, train_loss = 1.544406209141016, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 261, train_loss = 1.5389730123570189, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 262, train_loss = 1.5335945263504982, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 263, train_loss = 1.5281875183572993, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 264, train_loss = 1.5229608478257433, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 265, train_loss = 1.5177295791218057, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 266, train_loss = 1.5125755481421947, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 267, train_loss = 1.5074182326206937, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 268, train_loss = 1.5023830706486478, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 269, train_loss = 1.4973832989344373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 270, train_loss = 1.4924021909246221, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 271, train_loss = 1.4875629456946626, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 272, train_loss = 1.4826389774680138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 273, train_loss = 1.477874675183557, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 274, train_loss = 1.473091093241237, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 275, train_loss = 1.4683145619928837, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 276, train_loss = 1.4635715471813455, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 277, train_loss = 1.459005312412046, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 278, train_loss = 1.4543541396269575, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 279, train_loss = 1.4498345913598314, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 280, train_loss = 1.4453882252564654, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 281, train_loss = 1.440947794704698, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 282, train_loss = 1.4365210073301569, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 283, train_loss = 1.4321368932724, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 284, train_loss = 1.4278608759632334, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 285, train_loss = 1.4235736057162285, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 286, train_loss = 1.4192911721765995, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 287, train_loss = 1.4151220495114103, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 288, train_loss = 1.4110274476697668, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 289, train_loss = 1.406890838057734, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 290, train_loss = 1.402811655192636, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 291, train_loss = 1.3987443210789934, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 292, train_loss = 1.3947407813975587, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 293, train_loss = 1.39069504046347, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 294, train_loss = 1.3868753165006638, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 295, train_loss = 1.3828593641519547, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 296, train_loss = 1.3789927512407303, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 297, train_loss = 1.3751846849918365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 298, train_loss = 1.3713584430515766, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 299, train_loss = 1.367599904537201, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 300, train_loss = 1.3638789542019367, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 301, train_loss = 1.3601911179721355, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 302, train_loss = 1.3564621856203303, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 303, train_loss = 1.3528894558548927, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 304, train_loss = 1.3492525542387739, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 305, train_loss = 1.3457797119626775, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 306, train_loss = 1.3421258106827736, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 307, train_loss = 1.3386540735373273, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 308, train_loss = 1.3351428707828745, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 309, train_loss = 1.3316522712120786, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 310, train_loss = 1.328342292457819, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 311, train_loss = 1.3249125642469153, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 312, train_loss = 1.3216158598661423, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 313, train_loss = 1.3181721828877926, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 314, train_loss = 1.314965749741532, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 315, train_loss = 1.3115780676016584, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 316, train_loss = 1.308471567928791, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 317, train_loss = 1.3051482239970937, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 318, train_loss = 1.3020227825036272, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 319, train_loss = 1.2987589426338673, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 320, train_loss = 1.2957406118512154, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 321, train_loss = 1.2925534881651402, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 322, train_loss = 1.2895583423087373, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 323, train_loss = 1.2864602021872997, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 324, train_loss = 1.283433279604651, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 325, train_loss = 1.280351735651493, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 326, train_loss = 1.2774432537844405, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 327, train_loss = 1.2745054550468922, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 328, train_loss = 1.271457509486936, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 329, train_loss = 1.268682068795897, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 330, train_loss = 1.265703254728578, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 331, train_loss = 1.2628529419889674, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 332, train_loss = 1.2600596422562376, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 333, train_loss = 1.257150188088417, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 334, train_loss = 1.2543483227491379, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 335, train_loss = 1.251556184142828, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 336, train_loss = 1.248843333334662, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 337, train_loss = 1.2459846945712343, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 338, train_loss = 1.24342690652702, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 339, train_loss = 1.2405839810380712, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 340, train_loss = 1.2379912274191156, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 341, train_loss = 1.2352603847393766, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 342, train_loss = 1.2327380081405863, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 343, train_loss = 1.2300882613053545, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 344, train_loss = 1.2275232151150703, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 345, train_loss = 1.2249206652049907, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 346, train_loss = 1.2224000245332718, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 347, train_loss = 1.219870276749134, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 348, train_loss = 1.217388158023823, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 349, train_loss = 1.2148743855650537, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 350, train_loss = 1.2123762468690984, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 351, train_loss = 1.2099311389029026, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 352, train_loss = 1.207488228857983, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 353, train_loss = 1.205188135325443, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 354, train_loss = 1.2026453353464603, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 355, train_loss = 1.200335118919611, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 356, train_loss = 1.197965422004927, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 357, train_loss = 1.1956517833168618, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 358, train_loss = 1.1932411628658883, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 359, train_loss = 1.1910301744937897, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 360, train_loss = 1.1886634950642474, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 361, train_loss = 1.1864553813938983, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 362, train_loss = 1.1841602201457135, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 363, train_loss = 1.1818850089912303, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 364, train_loss = 1.1796777099370956, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 365, train_loss = 1.177505659579765, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 366, train_loss = 1.175262079865206, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 367, train_loss = 1.1730587929487228, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 368, train_loss = 1.1709494118695147, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 369, train_loss = 1.1687455996870995, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 370, train_loss = 1.1665924564003944, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 371, train_loss = 1.164415753155481, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 372, train_loss = 1.1623783757095225, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 373, train_loss = 1.160144743800629, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 374, train_loss = 1.1581674925982952, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 375, train_loss = 1.1561111298506148, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 376, train_loss = 1.1539736005361192, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 377, train_loss = 1.1519899182021618, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 378, train_loss = 1.1499165569548495, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 379, train_loss = 1.1480075120925903, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 380, train_loss = 1.1459690530900843, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 381, train_loss = 1.1440165837411769, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 382, train_loss = 1.1419589817523956, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 383, train_loss = 1.1400750850443728, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 384, train_loss = 1.1381399482488632, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 385, train_loss = 1.1362598699633963, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 386, train_loss = 1.1342591059510596, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 387, train_loss = 1.1324223105912097, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 388, train_loss = 1.1304591596126556, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 389, train_loss = 1.1286724358797073, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 390, train_loss = 1.1267368718981743, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 391, train_loss = 1.1249068242614157, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 392, train_loss = 1.1230029873549938, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 393, train_loss = 1.1212255954742432, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 394, train_loss = 1.1193937733769417, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 395, train_loss = 1.1176610042457469, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 396, train_loss = 1.115792389959097, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 397, train_loss = 1.1140735720400698, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 398, train_loss = 1.112282868474722, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 399, train_loss = 1.1104309484362602, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 400, train_loss = 1.1087671145796776, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 401, train_loss = 1.107011016458273, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 402, train_loss = 1.1053162875468843, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 403, train_loss = 1.1035486198961735, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 404, train_loss = 1.1018008875544183, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 405, train_loss = 1.1002219666843303, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 406, train_loss = 1.098442692309618, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 407, train_loss = 1.0968833689694293, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 408, train_loss = 1.095128717541229, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 409, train_loss = 1.09354492649436, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 410, train_loss = 1.0918138760025613, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 411, train_loss = 1.09017213183688, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 412, train_loss = 1.0886115282773972, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 413, train_loss = 1.086926578253042, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 414, train_loss = 1.085362949699629, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 415, train_loss = 1.0838607487385161, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 416, train_loss = 1.0821280777454376, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 417, train_loss = 1.0806026856298558, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 418, train_loss = 1.0789966794545762, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 419, train_loss = 1.0774617952411063, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 420, train_loss = 1.075896929949522, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 421, train_loss = 1.074415910989046, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 422, train_loss = 1.0728912465274334, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 423, train_loss = 1.0713575420086272, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 424, train_loss = 1.0698729828000069, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 425, train_loss = 1.0683313856716268, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 426, train_loss = 1.0668275256757624, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 427, train_loss = 1.0653419345617294, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 428, train_loss = 1.0638940272037871, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 429, train_loss = 1.0624050733749755, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 430, train_loss = 1.0609360759262927, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 431, train_loss = 1.0595444192294963, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 432, train_loss = 1.058112520724535, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 433, train_loss = 1.0566404809360392, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 434, train_loss = 1.0551951092784293, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 435, train_loss = 1.0538071642513387, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 436, train_loss = 1.0524218417704105, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 437, train_loss = 1.0509962290525436, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 438, train_loss = 1.0496084069018252, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 439, train_loss = 1.0482570205931552, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 440, train_loss = 1.0468456248636357, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 441, train_loss = 1.045441708236467, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 442, train_loss = 1.044114325195551, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 443, train_loss = 1.0428283375804313, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 444, train_loss = 1.0413672886788845, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 445, train_loss = 1.0401037844712846, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 446, train_loss = 1.0387420753831975, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 447, train_loss = 1.0374518620665185, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 448, train_loss = 1.0361375684733503, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 449, train_loss = 1.0348582056467421, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 450, train_loss = 1.0335213703219779, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 451, train_loss = 1.0322175398468971, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 452, train_loss = 1.0309557343716733, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 453, train_loss = 1.029608943790663, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 454, train_loss = 1.02833416685462, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 455, train_loss = 1.027051503479015, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 456, train_loss = 1.0258563819224946, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 457, train_loss = 1.024476898193825, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 458, train_loss = 1.023302121728193, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 459, train_loss = 1.02203956869198, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 460, train_loss = 1.0207844066317193, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 461, train_loss = 1.0196124985814095, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 462, train_loss = 1.0183515436947346, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 463, train_loss = 1.017122735560406, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 464, train_loss = 1.0159593646530993, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 465, train_loss = 1.0146876946091652, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 466, train_loss = 1.0135580251808278, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 467, train_loss = 1.0123425386846066, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 468, train_loss = 1.0110832887585275, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 469, train_loss = 1.009950716048479, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 470, train_loss = 1.008724006533157, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 471, train_loss = 1.0075962890987284, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 472, train_loss = 1.006408043205738, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 473, train_loss = 1.0052497324941214, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 474, train_loss = 1.004124748200411, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 475, train_loss = 1.0029703167674597, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 476, train_loss = 1.0018345763382968, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 477, train_loss = 1.0007080920040607, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 478, train_loss = 0.9995992680487689, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 479, train_loss = 0.9984501861035824, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 480, train_loss = 0.9973134559986647, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 481, train_loss = 0.9961531025764998, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 482, train_loss = 0.9951706416904926, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 483, train_loss = 0.994021475315094, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 484, train_loss = 0.9928820207715034, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 485, train_loss = 0.9918224339780863, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 486, train_loss = 0.9907781332731247, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 487, train_loss = 0.9896157582697924, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 488, train_loss = 0.9886039731500205, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 489, train_loss = 0.9874926494958345, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 490, train_loss = 0.9864416184427682, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 491, train_loss = 0.9853783374128398, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 492, train_loss = 0.9843593662080821, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 493, train_loss = 0.9832667844893876, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 494, train_loss = 0.9822626622917596, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 495, train_loss = 0.9811609660682734, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 496, train_loss = 0.9801544460060541, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 497, train_loss = 0.9791453406214714, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 498, train_loss = 0.978115689009428, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 499, train_loss = 0.97707093381905, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████                                   | 15/30 [1:42:27<1:43:04, 412.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "16th- epoch: 0, train_loss = 280.5362091064453, train_acc = 0.41942244993013506\n",
      "test Acc 0.5665735567970205:\n",
      "16th- epoch: 1, train_loss = 221.38287150859833, train_acc = 0.5683511877037727\n",
      "test Acc 0.5702979515828678:\n",
      "16th- epoch: 2, train_loss = 167.1710723042488, train_acc = 0.5812761993479273\n",
      "test Acc 0.6256983240223464:\n",
      "16th- epoch: 3, train_loss = 136.19360840320587, train_acc = 0.6789706567303214\n",
      "test Acc 0.7304469273743017:\n",
      "16th- epoch: 4, train_loss = 115.4057879447937, train_acc = 0.7515137401024685\n",
      "test Acc 0.7718808193668529:\n",
      "16th- epoch: 5, train_loss = 99.97457417845726, train_acc = 0.7707265952491849\n",
      "test Acc 0.7900372439478585:\n",
      "16th- epoch: 6, train_loss = 87.9420502781868, train_acc = 0.7855146716348393\n",
      "test Acc 0.8123836126629422:\n",
      "16th- epoch: 7, train_loss = 78.23548966646194, train_acc = 0.8132277596646483\n",
      "test Acc 0.8324022346368715:\n",
      "16th- epoch: 8, train_loss = 70.044258415699, train_acc = 0.8358174196553331\n",
      "test Acc 0.8542830540037244:\n",
      "16th- epoch: 9, train_loss = 62.903412729501724, train_acc = 0.8629482999534234\n",
      "test Acc 0.8766294227188082:\n",
      "16th- epoch: 10, train_loss = 56.61819784343243, train_acc = 0.8854215183977643\n",
      "test Acc 0.8985102420856611:\n",
      "16th- epoch: 11, train_loss = 51.097246527671814, train_acc = 0.9090591523055426\n",
      "test Acc 0.9203910614525139:\n",
      "16th- epoch: 12, train_loss = 46.26703521609306, train_acc = 0.9309501630181649\n",
      "test Acc 0.9343575418994413:\n",
      "16th- epoch: 13, train_loss = 42.06308726966381, train_acc = 0.9407312529110387\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 14, train_loss = 38.423379093408585, train_acc = 0.9446902654867256\n",
      "test Acc 0.9432029795158287:\n",
      "16th- epoch: 15, train_loss = 35.28641825169325, train_acc = 0.9493479273404751\n",
      "test Acc 0.9445996275605214:\n",
      "16th- epoch: 16, train_loss = 32.58870217949152, train_acc = 0.952026082906381\n",
      "test Acc 0.9473929236499069:\n",
      "16th- epoch: 17, train_loss = 30.266171045601368, train_acc = 0.9537727061015371\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 18, train_loss = 28.263026349246502, train_acc = 0.9556357708430367\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 19, train_loss = 26.53001146763563, train_acc = 0.9585468095016302\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 20, train_loss = 25.022701650857925, train_acc = 0.9606427573358174\n",
      "test Acc 0.9539106145251397:\n",
      "16th- epoch: 21, train_loss = 23.70522740855813, train_acc = 0.9637866790870983\n",
      "test Acc 0.9581005586592178:\n",
      "16th- epoch: 22, train_loss = 22.544886756688356, train_acc = 0.9670470423847228\n",
      "test Acc 0.9581005586592178:\n",
      "16th- epoch: 23, train_loss = 21.515755876898766, train_acc = 0.9685607824871915\n",
      "test Acc 0.9594972067039106:\n",
      "16th- epoch: 24, train_loss = 20.59683385118842, train_acc = 0.9693758733115976\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 25, train_loss = 19.77070612832904, train_acc = 0.9698416394969726\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 26, train_loss = 19.023336477577686, train_acc = 0.9703074056823474\n",
      "test Acc 0.9613594040968343:\n",
      "16th- epoch: 27, train_loss = 18.34332137927413, train_acc = 0.970540288775035\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 28, train_loss = 17.72079722583294, train_acc = 0.9715882626921285\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 29, train_loss = 17.1477827206254, train_acc = 0.9715882626921285\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 30, train_loss = 16.617260232567787, train_acc = 0.971821145784816\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 31, train_loss = 16.12365849688649, train_acc = 0.9725197950628784\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 32, train_loss = 15.662762571126223, train_acc = 0.9731020027945971\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 33, train_loss = 15.23050706461072, train_acc = 0.9735677689799721\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 34, train_loss = 14.824127703905106, train_acc = 0.9738006520726595\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 35, train_loss = 14.441148411482573, train_acc = 0.9742664182580345\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 36, train_loss = 14.07877640798688, train_acc = 0.9749650675360969\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 37, train_loss = 13.735290016978979, train_acc = 0.9754308337214718\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 38, train_loss = 13.408993396908045, train_acc = 0.975780158360503\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 39, train_loss = 13.09878047555685, train_acc = 0.9767116907312529\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 40, train_loss = 12.803339522331953, train_acc = 0.9775267815556591\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 41, train_loss = 12.521370150148869, train_acc = 0.9777596646483465\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 42, train_loss = 12.251898281276226, train_acc = 0.9782254308337215\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 43, train_loss = 11.993697013705969, train_acc = 0.9786911970190965\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 44, train_loss = 11.745887264609337, train_acc = 0.9790405216581276\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 45, train_loss = 11.507657648995519, train_acc = 0.9793898462971589\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 46, train_loss = 11.278416849672794, train_acc = 0.9799720540288775\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 47, train_loss = 11.057754006236792, train_acc = 0.9803213786679087\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 48, train_loss = 10.845184862613678, train_acc = 0.980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 49, train_loss = 10.639937097206712, train_acc = 0.9805542617605962\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 50, train_loss = 10.441621674224734, train_acc = 0.9810200279459711\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 51, train_loss = 10.249593945220113, train_acc = 0.9810200279459711\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 52, train_loss = 10.063890689983964, train_acc = 0.9813693525850024\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 53, train_loss = 9.883853994309902, train_acc = 0.9814857941313461\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 54, train_loss = 9.709317168220878, train_acc = 0.9818351187703773\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 55, train_loss = 9.539885239675641, train_acc = 0.9821844434094085\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 56, train_loss = 9.375363651663065, train_acc = 0.9825337680484397\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 57, train_loss = 9.215495448559523, train_acc = 0.9829995342338146\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 58, train_loss = 9.060074554756284, train_acc = 0.9831159757801584\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 59, train_loss = 8.908844523131847, train_acc = 0.9832324173265021\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 60, train_loss = 8.761660035699606, train_acc = 0.9839310666045645\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 61, train_loss = 8.618258344009519, train_acc = 0.9842803912435957\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 62, train_loss = 8.478703709319234, train_acc = 0.9842803912435957\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 63, train_loss = 8.34270142763853, train_acc = 0.9846297158826269\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 64, train_loss = 8.210134245455265, train_acc = 0.9846297158826269\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 65, train_loss = 8.080648761242628, train_acc = 0.9846297158826269\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 66, train_loss = 7.954246737062931, train_acc = 0.9846297158826269\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 67, train_loss = 7.830901423469186, train_acc = 0.9848625989753144\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 68, train_loss = 7.710080768913031, train_acc = 0.9850954820680019\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 69, train_loss = 7.592100052163005, train_acc = 0.9850954820680019\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 70, train_loss = 7.476619563996792, train_acc = 0.9853283651606893\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 71, train_loss = 7.363915365189314, train_acc = 0.9856776897997206\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 72, train_loss = 7.253748469054699, train_acc = 0.985910572892408\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 73, train_loss = 7.145937696099281, train_acc = 0.9860270144387517\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 74, train_loss = 7.040594385936856, train_acc = 0.9861434559850955\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 75, train_loss = 6.9375391360372305, train_acc = 0.9861434559850955\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 76, train_loss = 6.836685538291931, train_acc = 0.9864927806241267\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 77, train_loss = 6.737840225920081, train_acc = 0.9864927806241267\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 78, train_loss = 6.641257958486676, train_acc = 0.9869585468095017\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 79, train_loss = 6.546563349664211, train_acc = 0.9873078714485328\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 80, train_loss = 6.453705253079534, train_acc = 0.9881229622729389\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 81, train_loss = 6.362934438511729, train_acc = 0.9883558453656265\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 82, train_loss = 6.273686608299613, train_acc = 0.9884722869119702\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 83, train_loss = 6.186390554532409, train_acc = 0.9888216115510013\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 84, train_loss = 6.100897014141083, train_acc = 0.9890544946436889\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 85, train_loss = 6.017165749333799, train_acc = 0.9896367023754076\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 86, train_loss = 5.935012053698301, train_acc = 0.9899860270144387\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 87, train_loss = 5.8545620404183865, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 88, train_loss = 5.775539310649037, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 89, train_loss = 5.698197706602514, train_acc = 0.99033535165347\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 90, train_loss = 5.622210782952607, train_acc = 0.99033535165347\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 91, train_loss = 5.547522620297968, train_acc = 0.99033535165347\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 92, train_loss = 5.474422632716596, train_acc = 0.9904517931998137\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 93, train_loss = 5.402465444989502, train_acc = 0.9904517931998137\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 94, train_loss = 5.332162226550281, train_acc = 0.9906846762925011\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 95, train_loss = 5.263052214868367, train_acc = 0.9906846762925011\n",
      "test Acc 0.9795158286778398:\n",
      "16th- epoch: 96, train_loss = 5.195235127583146, train_acc = 0.990801117838845\n",
      "test Acc 0.9795158286778398:\n",
      "16th- epoch: 97, train_loss = 5.128685767762363, train_acc = 0.990801117838845\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 98, train_loss = 5.063602105714381, train_acc = 0.9912668840242198\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 99, train_loss = 4.999508862383664, train_acc = 0.9912668840242198\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 100, train_loss = 4.936720471829176, train_acc = 0.9912668840242198\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 101, train_loss = 4.8749990444630384, train_acc = 0.9912668840242198\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 102, train_loss = 4.814534901641309, train_acc = 0.9913833255705635\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 103, train_loss = 4.754974971525371, train_acc = 0.9913833255705635\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 104, train_loss = 4.69659059215337, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 105, train_loss = 4.6392334420233965, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 106, train_loss = 4.582995632663369, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 107, train_loss = 4.527771950699389, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 108, train_loss = 4.473466634750366, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 109, train_loss = 4.420100028626621, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 110, train_loss = 4.367889916524291, train_acc = 0.9916162086632511\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 111, train_loss = 4.316451750695705, train_acc = 0.9917326502095948\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 112, train_loss = 4.266191953793168, train_acc = 0.9918490917559385\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 113, train_loss = 4.216633242554963, train_acc = 0.9919655333022822\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 114, train_loss = 4.168196189217269, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 115, train_loss = 4.1204268131405115, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 116, train_loss = 4.073656535707414, train_acc = 0.9925477410340009\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 117, train_loss = 4.0277819549664855, train_acc = 0.9926641825803446\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 118, train_loss = 3.982515231706202, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 119, train_loss = 3.93826568312943, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 120, train_loss = 3.8946773912757635, train_acc = 0.9932463903120633\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 121, train_loss = 3.852141173556447, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 122, train_loss = 3.810029834508896, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 123, train_loss = 3.7686911514028907, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 124, train_loss = 3.7281681979075074, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 125, train_loss = 3.6882914220914245, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 126, train_loss = 3.64896553568542, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 127, train_loss = 3.6104116132482886, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 128, train_loss = 3.5724641559645534, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 129, train_loss = 3.5353714181110263, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 130, train_loss = 3.4988170857541263, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 131, train_loss = 3.462746301665902, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 132, train_loss = 3.4276176430284977, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 133, train_loss = 3.392912098672241, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 134, train_loss = 3.3589247851632535, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 135, train_loss = 3.3251646403223276, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 136, train_loss = 3.292372405529022, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 137, train_loss = 3.2598703783005476, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 138, train_loss = 3.228052655234933, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 139, train_loss = 3.1965818568132818, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 140, train_loss = 3.165866283234209, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 141, train_loss = 3.135498416144401, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 142, train_loss = 3.105607556644827, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 143, train_loss = 3.0763159058988094, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 144, train_loss = 3.0474758711643517, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 145, train_loss = 3.019141263794154, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 146, train_loss = 2.9911245205439627, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 147, train_loss = 2.9638415654189885, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 148, train_loss = 2.936839550267905, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 149, train_loss = 2.9103717100806534, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 150, train_loss = 2.8842481835745275, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 151, train_loss = 2.8586287149228156, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 152, train_loss = 2.833453110884875, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 153, train_loss = 2.808649756014347, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 154, train_loss = 2.784251954872161, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 155, train_loss = 2.7604124103672802, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 156, train_loss = 2.736578221898526, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 157, train_loss = 2.713547803927213, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 158, train_loss = 2.6905751526355743, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 159, train_loss = 2.668265995103866, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 160, train_loss = 2.64606647612527, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 161, train_loss = 2.624357010703534, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 162, train_loss = 2.6030745045281947, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 163, train_loss = 2.581963590811938, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 164, train_loss = 2.5612631794065237, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 165, train_loss = 2.540880663320422, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 166, train_loss = 2.5207961262203753, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 167, train_loss = 2.500888761598617, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 168, train_loss = 2.481585867702961, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 169, train_loss = 2.4623503498733044, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 170, train_loss = 2.44350110553205, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 171, train_loss = 2.4250133871100843, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 172, train_loss = 2.4068407607264817, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 173, train_loss = 2.388812540564686, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 174, train_loss = 2.371252009179443, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 175, train_loss = 2.353857235517353, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 176, train_loss = 2.3367867320775986, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 177, train_loss = 2.3199026281945407, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 178, train_loss = 2.3033611089922488, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 179, train_loss = 2.2870495561510324, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 180, train_loss = 2.2709788917563856, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 181, train_loss = 2.2552526802755892, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 182, train_loss = 2.2395878478419036, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 183, train_loss = 2.224315829575062, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 184, train_loss = 2.2091413747984916, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 185, train_loss = 2.1944648262578994, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 186, train_loss = 2.1797912686597556, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 187, train_loss = 2.165368800982833, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 188, train_loss = 2.1512130189221352, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 189, train_loss = 2.137214284390211, train_acc = 0.9967396367023754\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 190, train_loss = 2.123381295008585, train_acc = 0.9967396367023754\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 191, train_loss = 2.1098577037919313, train_acc = 0.9967396367023754\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 192, train_loss = 2.096591780660674, train_acc = 0.9967396367023754\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 193, train_loss = 2.083372615277767, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 194, train_loss = 2.070276279002428, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 195, train_loss = 2.057639704318717, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 196, train_loss = 2.044920242158696, train_acc = 0.9968560782487191\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 197, train_loss = 2.0325311322230846, train_acc = 0.9968560782487191\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 198, train_loss = 2.0201745964586735, train_acc = 0.9968560782487191\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 199, train_loss = 2.0082355737686157, train_acc = 0.9968560782487191\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 200, train_loss = 1.9962846252601594, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 201, train_loss = 1.9845592118799686, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 202, train_loss = 1.973016396164894, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 203, train_loss = 1.961624712916091, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 204, train_loss = 1.9505500209052116, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 205, train_loss = 1.9394797571003437, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 206, train_loss = 1.9285880352836102, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 207, train_loss = 1.9178280520718545, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 208, train_loss = 1.9073998592793941, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 209, train_loss = 1.8968807582277805, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 210, train_loss = 1.8867133248131722, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 211, train_loss = 1.8765229966957122, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 212, train_loss = 1.8666898782830685, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 213, train_loss = 1.856720793992281, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 214, train_loss = 1.8470327965915203, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 215, train_loss = 1.8375992488581687, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 216, train_loss = 1.8281393821816891, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 217, train_loss = 1.8189516614656895, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 218, train_loss = 1.809773676097393, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 219, train_loss = 1.8006794166285545, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 220, train_loss = 1.7919124464970082, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 221, train_loss = 1.7830751340370625, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 222, train_loss = 1.7743808664381504, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 223, train_loss = 1.7658478294033557, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 224, train_loss = 1.757502106251195, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 225, train_loss = 1.749150037765503, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 226, train_loss = 1.7409940597135574, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 227, train_loss = 1.7329497064929456, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 228, train_loss = 1.7248662349302322, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 229, train_loss = 1.7171325099188834, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 230, train_loss = 1.7092359624803066, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 231, train_loss = 1.701617268146947, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 232, train_loss = 1.6940359484869987, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 233, train_loss = 1.686621032655239, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 234, train_loss = 1.6791701142210513, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 235, train_loss = 1.6719735898077488, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 236, train_loss = 1.6648048881907016, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 237, train_loss = 1.657624565064907, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 238, train_loss = 1.6506433959584683, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 239, train_loss = 1.6437187945703045, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 240, train_loss = 1.6368883630493656, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 241, train_loss = 1.6300500904908404, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 242, train_loss = 1.623446024954319, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 243, train_loss = 1.6168898282339796, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 244, train_loss = 1.6103805688908324, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 245, train_loss = 1.603985762805678, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 246, train_loss = 1.5975522299995646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 247, train_loss = 1.591241710470058, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 248, train_loss = 1.5850562868872657, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 249, train_loss = 1.5789803508669138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 250, train_loss = 1.572849377989769, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 251, train_loss = 1.5669041177025065, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 252, train_loss = 1.5609933597734198, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 253, train_loss = 1.5551674527814612, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 254, train_loss = 1.5493553541600704, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 255, train_loss = 1.54369230940938, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 256, train_loss = 1.537920510978438, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 257, train_loss = 1.5324434178182855, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 258, train_loss = 1.5268560001859441, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 259, train_loss = 1.5214335545897484, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 260, train_loss = 1.516083842725493, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 261, train_loss = 1.5106343863299116, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 262, train_loss = 1.5054093463113531, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 263, train_loss = 1.5001023188233376, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 264, train_loss = 1.4950832104077563, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 265, train_loss = 1.48983683437109, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 266, train_loss = 1.4847897663712502, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 267, train_loss = 1.4797647123923525, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 268, train_loss = 1.4748085489263758, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 269, train_loss = 1.469974361360073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 270, train_loss = 1.4650208490202203, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 271, train_loss = 1.4602398239076138, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 272, train_loss = 1.4555439911782742, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 273, train_loss = 1.450781607418321, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 274, train_loss = 1.4461605151882395, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 275, train_loss = 1.4415370523929596, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 276, train_loss = 1.43697939068079, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 277, train_loss = 1.4323890147497877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 278, train_loss = 1.4280161410570145, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 279, train_loss = 1.423565293313004, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 280, train_loss = 1.419129958958365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 281, train_loss = 1.4148478707065806, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 282, train_loss = 1.4104772806167603, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 283, train_loss = 1.4061935680219904, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 284, train_loss = 1.4019351353636011, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 285, train_loss = 1.3978582980344072, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 286, train_loss = 1.3936543924501166, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 287, train_loss = 1.389575943350792, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 288, train_loss = 1.385496199131012, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 289, train_loss = 1.381499526440166, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 290, train_loss = 1.3775167675921693, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 291, train_loss = 1.3736333599081263, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 292, train_loss = 1.3696347387740389, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 293, train_loss = 1.3657632693648338, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 294, train_loss = 1.361915381043218, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 295, train_loss = 1.3581352705368772, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 296, train_loss = 1.3543407818069682, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 297, train_loss = 1.35072496405337, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 298, train_loss = 1.346942332922481, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 299, train_loss = 1.343311837525107, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 300, train_loss = 1.3396270287921652, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 301, train_loss = 1.3361103447386995, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 302, train_loss = 1.3325902795186266, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 303, train_loss = 1.3290953735122457, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 304, train_loss = 1.3255542007973418, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 305, train_loss = 1.3221054846653715, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 306, train_loss = 1.3186909122159705, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 307, train_loss = 1.315356146544218, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 308, train_loss = 1.3119026297936216, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 309, train_loss = 1.3085939114680514, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 310, train_loss = 1.3052868656814098, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 311, train_loss = 1.3020438539097086, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 312, train_loss = 1.2987360693514347, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 313, train_loss = 1.2956275244941935, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 314, train_loss = 1.292307193041779, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 315, train_loss = 1.289161328226328, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 316, train_loss = 1.2859840865130536, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 317, train_loss = 1.283010105311405, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 318, train_loss = 1.279849776357878, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 319, train_loss = 1.276812945783604, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 320, train_loss = 1.2738175044651143, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 321, train_loss = 1.2707666804199107, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 322, train_loss = 1.2677557915449142, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 323, train_loss = 1.2647881880402565, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 324, train_loss = 1.2617847584187984, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 325, train_loss = 1.258986537635792, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 326, train_loss = 1.256070103496313, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 327, train_loss = 1.2531999510829337, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 328, train_loss = 1.2503759761457331, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 329, train_loss = 1.247537734627258, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 330, train_loss = 1.2446723667089827, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 331, train_loss = 1.2420440601999871, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 332, train_loss = 1.239141286641825, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 333, train_loss = 1.2365119966561906, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 334, train_loss = 1.2337222720379941, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 335, train_loss = 1.2311164389248006, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 336, train_loss = 1.228347351134289, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 337, train_loss = 1.2257249814574607, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 338, train_loss = 1.223085594654549, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 339, train_loss = 1.220583375543356, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 340, train_loss = 1.218021349341143, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 341, train_loss = 1.2153163366019726, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 342, train_loss = 1.2128397698397748, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 343, train_loss = 1.210335320502054, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 344, train_loss = 1.2078343865578063, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 345, train_loss = 1.205341201275587, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 346, train_loss = 1.2028575651347637, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 347, train_loss = 1.2003683410584927, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 348, train_loss = 1.1979716296191327, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 349, train_loss = 1.1956571253831498, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 350, train_loss = 1.1931914314627647, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 351, train_loss = 1.1908595350687392, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 352, train_loss = 1.188388531387318, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 353, train_loss = 1.186166651546955, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 354, train_loss = 1.1837826358969323, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 355, train_loss = 1.1814856591518037, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 356, train_loss = 1.1791575849056244, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 357, train_loss = 1.176868310838472, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 358, train_loss = 1.1746848213369958, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 359, train_loss = 1.1724770292639732, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 360, train_loss = 1.170152326405514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 361, train_loss = 1.1680980858509429, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 362, train_loss = 1.1657581974868663, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 363, train_loss = 1.1636728818411939, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 364, train_loss = 1.161447302729357, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 365, train_loss = 1.1593339157407172, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 366, train_loss = 1.1571663742070086, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 367, train_loss = 1.155128454149235, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 368, train_loss = 1.1529199195210822, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 369, train_loss = 1.150909459858667, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 370, train_loss = 1.1487776177818887, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 371, train_loss = 1.1467758205835707, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 372, train_loss = 1.1447160827810876, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 373, train_loss = 1.1426996998488903, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 374, train_loss = 1.1407039078767411, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 375, train_loss = 1.1386623879079707, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 376, train_loss = 1.1366933758254163, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 377, train_loss = 1.1347432248294353, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 378, train_loss = 1.132742268324364, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 379, train_loss = 1.130839327990543, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 380, train_loss = 1.1289087422192097, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 381, train_loss = 1.127007166563999, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 382, train_loss = 1.1250228248536587, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 383, train_loss = 1.1232039034366608, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 384, train_loss = 1.121361834288109, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 385, train_loss = 1.1194843351840973, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 386, train_loss = 1.1176583468914032, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 387, train_loss = 1.1158284855191596, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 388, train_loss = 1.1139236229355447, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 389, train_loss = 1.1121456797118299, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 390, train_loss = 1.1102434259955771, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 391, train_loss = 1.1084934237296693, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 392, train_loss = 1.1067043269868009, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 393, train_loss = 1.1048892550170422, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 394, train_loss = 1.1032366640865803, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 395, train_loss = 1.1015087626874447, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 396, train_loss = 1.0996390742366202, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 397, train_loss = 1.09801410761429, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 398, train_loss = 1.0962660759687424, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 399, train_loss = 1.0945417508482933, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 400, train_loss = 1.0928532555699348, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 401, train_loss = 1.0911228519980796, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 402, train_loss = 1.0895403623580933, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 403, train_loss = 1.0878528865869157, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 404, train_loss = 1.086182055354584, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 405, train_loss = 1.084566990553867, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 406, train_loss = 1.0829111548955552, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 407, train_loss = 1.0813184243743308, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 408, train_loss = 1.0797401368618011, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 409, train_loss = 1.0780813731253147, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 410, train_loss = 1.0766024490003474, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 411, train_loss = 1.0749586981837638, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 412, train_loss = 1.073353047191631, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 413, train_loss = 1.0719182628090493, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 414, train_loss = 1.0702309955959208, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 415, train_loss = 1.0687024655635469, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 416, train_loss = 1.067304885655176, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 417, train_loss = 1.0656394573743455, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 418, train_loss = 1.0640767092700116, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 419, train_loss = 1.0626235802774318, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 420, train_loss = 1.0611629064078443, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 421, train_loss = 1.0596593866939656, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 422, train_loss = 1.058162262022961, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 423, train_loss = 1.0566751683945768, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 424, train_loss = 1.0552509402041323, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 425, train_loss = 1.0536943823099136, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 426, train_loss = 1.0523451156914234, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 427, train_loss = 1.0509905914368574, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 428, train_loss = 1.0494675437512342, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 429, train_loss = 1.0481143780052662, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 430, train_loss = 1.046616554260254, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 431, train_loss = 1.0451514112355653, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 432, train_loss = 1.043797604739666, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 433, train_loss = 1.0423855508270208, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 434, train_loss = 1.0410804959537927, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 435, train_loss = 1.039691080659395, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 436, train_loss = 1.038269260287052, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 437, train_loss = 1.0368830549123231, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 438, train_loss = 1.0356609001755714, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 439, train_loss = 1.0342350366117898, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 440, train_loss = 1.03286019837833, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 441, train_loss = 1.0315181327459868, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 442, train_loss = 1.0301535464823246, train_acc = 0.9980204937121565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 443, train_loss = 1.0288965018989984, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 444, train_loss = 1.0274748851952609, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 445, train_loss = 1.0263018893601838, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 446, train_loss = 1.0249629455211107, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 447, train_loss = 1.0236466390488204, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 448, train_loss = 1.0224230202438775, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 449, train_loss = 1.0211296640336514, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 450, train_loss = 1.01985639706254, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 451, train_loss = 1.01856698593474, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 452, train_loss = 1.017336209624773, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 453, train_loss = 1.016209496796364, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 454, train_loss = 1.0149378230271395, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 455, train_loss = 1.0135770241322462, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 456, train_loss = 1.0124184228479862, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 457, train_loss = 1.0111688213946763, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 458, train_loss = 1.0099568826553877, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 459, train_loss = 1.0087905029358808, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 460, train_loss = 1.0076280211505946, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 461, train_loss = 1.0063297376036644, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 462, train_loss = 1.0051178013382014, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 463, train_loss = 1.0039845394494478, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 464, train_loss = 1.002844894916052, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 465, train_loss = 1.0016606375575066, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 466, train_loss = 1.0004234140214976, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 467, train_loss = 0.9993279936315957, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 468, train_loss = 0.9981573236582335, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 469, train_loss = 0.9970060400664806, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 470, train_loss = 0.9957731937465724, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 471, train_loss = 0.9947893346252386, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 472, train_loss = 0.9936790789070074, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 473, train_loss = 0.9924297245743219, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 474, train_loss = 0.9914461659791414, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 475, train_loss = 0.9901812871394213, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 476, train_loss = 0.9890380712749902, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 477, train_loss = 0.988042738288641, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 478, train_loss = 0.986943855881691, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 479, train_loss = 0.9858230898680631, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 480, train_loss = 0.9847310446202755, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 481, train_loss = 0.9836652552185114, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 482, train_loss = 0.9825183898210526, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 483, train_loss = 0.9814457446336746, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 484, train_loss = 0.9803429953753948, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 485, train_loss = 0.9794501302239951, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 486, train_loss = 0.9783876066503581, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 487, train_loss = 0.9773575862345751, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 488, train_loss = 0.9762254779634532, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 489, train_loss = 0.9752495040593203, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 490, train_loss = 0.974175968527561, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 491, train_loss = 0.9730981426837388, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 492, train_loss = 0.972167299449211, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 493, train_loss = 0.9710378001036588, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 494, train_loss = 0.970117269695038, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 495, train_loss = 0.9689596891403198, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 496, train_loss = 0.9680018027720507, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 497, train_loss = 0.9669228667917196, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 498, train_loss = 0.9660352915525436, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 499, train_loss = 0.9650455228984356, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████▎                                | 16/30 [1:49:18<1:36:05, 411.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "17th- epoch: 0, train_loss = 273.6767966747284, train_acc = 0.48265020959478344\n",
      "test Acc 0.5623836126629422:\n",
      "17th- epoch: 1, train_loss = 208.3318761587143, train_acc = 0.5617140195621798\n",
      "test Acc 0.563780260707635:\n",
      "17th- epoch: 2, train_loss = 158.68529951572418, train_acc = 0.5853516534699581\n",
      "test Acc 0.6550279329608939:\n",
      "17th- epoch: 3, train_loss = 131.14260601997375, train_acc = 0.7078481602235678\n",
      "test Acc 0.7565176908752328:\n",
      "17th- epoch: 4, train_loss = 112.09759336709976, train_acc = 0.7624592454587797\n",
      "test Acc 0.7811918063314711:\n",
      "17th- epoch: 5, train_loss = 97.35274001955986, train_acc = 0.7761993479273405\n",
      "test Acc 0.8016759776536313:\n",
      "17th- epoch: 6, train_loss = 85.63935327529907, train_acc = 0.7986725663716814\n",
      "test Acc 0.8263500931098696:\n",
      "17th- epoch: 7, train_loss = 76.12508398294449, train_acc = 0.8235910572892408\n",
      "test Acc 0.8514897579143389:\n",
      "17th- epoch: 8, train_loss = 68.05198127031326, train_acc = 0.8594550535631114\n",
      "test Acc 0.8766294227188082:\n",
      "17th- epoch: 9, train_loss = 60.98809723556042, train_acc = 0.8818118304611086\n",
      "test Acc 0.8915270018621974:\n",
      "17th- epoch: 10, train_loss = 54.79623703658581, train_acc = 0.9006753609687936\n",
      "test Acc 0.909683426443203:\n",
      "17th- epoch: 11, train_loss = 49.42998614907265, train_acc = 0.9204704238472287\n",
      "test Acc 0.9259776536312849:\n",
      "17th- epoch: 12, train_loss = 44.82325953245163, train_acc = 0.9338612016767582\n",
      "test Acc 0.9352886405959032:\n",
      "17th- epoch: 13, train_loss = 40.87945517897606, train_acc = 0.9415463437354448\n",
      "test Acc 0.9390130353817505:\n",
      "17th- epoch: 14, train_loss = 37.502917528152466, train_acc = 0.9462040055891943\n",
      "test Acc 0.9422718808193669:\n",
      "17th- epoch: 15, train_loss = 34.607456766068935, train_acc = 0.9489986027014439\n",
      "test Acc 0.9445996275605214:\n",
      "17th- epoch: 16, train_loss = 32.119002148509026, train_acc = 0.951560316721006\n",
      "test Acc 0.9459962756052142:\n",
      "17th- epoch: 17, train_loss = 29.97493153810501, train_acc = 0.9528411737307871\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 18, train_loss = 28.11887726932764, train_acc = 0.9551700046576619\n",
      "test Acc 0.9501862197392924:\n",
      "17th- epoch: 19, train_loss = 26.50614557415247, train_acc = 0.9586632510479739\n",
      "test Acc 0.952513966480447:\n",
      "17th- epoch: 20, train_loss = 25.096972577273846, train_acc = 0.9614578481602236\n",
      "test Acc 0.9567039106145251:\n",
      "17th- epoch: 21, train_loss = 23.856292568147182, train_acc = 0.9633209129017233\n",
      "test Acc 0.9594972067039106:\n",
      "17th- epoch: 22, train_loss = 22.75532216578722, train_acc = 0.965649743828598\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 23, train_loss = 21.772529508918524, train_acc = 0.9670470423847228\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 24, train_loss = 20.888940744102, train_acc = 0.9678621332091291\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 25, train_loss = 20.088926054537296, train_acc = 0.9691429902189101\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 26, train_loss = 19.36080865561962, train_acc = 0.9699580810433163\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 27, train_loss = 18.694274358451366, train_acc = 0.9706567303213787\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 28, train_loss = 18.080523505806923, train_acc = 0.9711224965067536\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 29, train_loss = 17.512783586978912, train_acc = 0.9713553795994411\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 30, train_loss = 16.9857463426888, train_acc = 0.9717047042384723\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 31, train_loss = 16.494497790932655, train_acc = 0.9727526781555659\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 32, train_loss = 16.03516973927617, train_acc = 0.9732184443409408\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 33, train_loss = 15.603967823088169, train_acc = 0.9733348858872846\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 34, train_loss = 15.197848338633776, train_acc = 0.9738006520726595\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 35, train_loss = 14.813981968909502, train_acc = 0.9742664182580345\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 36, train_loss = 14.450242102146149, train_acc = 0.9750815090824406\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 37, train_loss = 14.105198718607426, train_acc = 0.9754308337214718\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 38, train_loss = 13.777466259896755, train_acc = 0.9758965999068467\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 39, train_loss = 13.465144746005535, train_acc = 0.9761294829995343\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 40, train_loss = 13.166718147695065, train_acc = 0.9763623660922217\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 41, train_loss = 12.881264623254538, train_acc = 0.9764788076385654\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 42, train_loss = 12.60824490338564, train_acc = 0.9767116907312529\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 43, train_loss = 12.346478138118982, train_acc = 0.9771774569166278\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 44, train_loss = 12.094963774085045, train_acc = 0.9775267815556591\n",
      "test Acc 0.9702048417132216:\n",
      "17th- epoch: 45, train_loss = 11.852891121059656, train_acc = 0.9777596646483465\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 46, train_loss = 11.619421433657408, train_acc = 0.977992547741034\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 47, train_loss = 11.394329741597176, train_acc = 0.9782254308337215\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 48, train_loss = 11.177208241075277, train_acc = 0.9785747554727526\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 49, train_loss = 10.96775658801198, train_acc = 0.9792734047508151\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 50, train_loss = 10.765201073139906, train_acc = 0.9799720540288775\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 51, train_loss = 10.569077953696251, train_acc = 0.9803213786679087\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 52, train_loss = 10.379052851349115, train_acc = 0.9804378202142524\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 53, train_loss = 10.194966208189726, train_acc = 0.9809035863996274\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 54, train_loss = 10.01637102290988, train_acc = 0.9812529110386586\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 55, train_loss = 9.84321367368102, train_acc = 0.9814857941313461\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 56, train_loss = 9.675084818154573, train_acc = 0.981951560316721\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 57, train_loss = 9.511694949120283, train_acc = 0.9820680018630648\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 58, train_loss = 9.3527926877141, train_acc = 0.9823008849557522\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 59, train_loss = 9.198066398501396, train_acc = 0.9823008849557522\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 60, train_loss = 9.047519279643893, train_acc = 0.9826502095947834\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 61, train_loss = 8.900872817263007, train_acc = 0.9827666511411272\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 62, train_loss = 8.757915353402495, train_acc = 0.9832324173265021\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 63, train_loss = 8.618847493082285, train_acc = 0.983698183511877\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 64, train_loss = 8.483227595686913, train_acc = 0.9842803912435957\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 65, train_loss = 8.351028075441718, train_acc = 0.9843968327899395\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 66, train_loss = 8.222072480246425, train_acc = 0.9846297158826269\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 67, train_loss = 8.096219526603818, train_acc = 0.9847461574289706\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 68, train_loss = 7.973122805356979, train_acc = 0.9849790405216581\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 69, train_loss = 7.853003669530153, train_acc = 0.9853283651606893\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 70, train_loss = 7.735553123056889, train_acc = 0.9855612482533768\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 71, train_loss = 7.620750250294805, train_acc = 0.9857941313460643\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 72, train_loss = 7.508542541414499, train_acc = 0.9857941313460643\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 73, train_loss = 7.398741349577904, train_acc = 0.9857941313460643\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 74, train_loss = 7.291307372972369, train_acc = 0.9860270144387517\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 75, train_loss = 7.1860530115664005, train_acc = 0.9864927806241267\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 76, train_loss = 7.083080664277077, train_acc = 0.9864927806241267\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 77, train_loss = 6.982185667380691, train_acc = 0.9867256637168141\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 78, train_loss = 6.883389484137297, train_acc = 0.9870749883558454\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 79, train_loss = 6.786495752632618, train_acc = 0.9873078714485328\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 80, train_loss = 6.691521767526865, train_acc = 0.9874243129948765\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 81, train_loss = 6.598532484844327, train_acc = 0.9876571960875641\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 82, train_loss = 6.507254047319293, train_acc = 0.9876571960875641\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 83, train_loss = 6.417732423171401, train_acc = 0.9882394038192828\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 84, train_loss = 6.329877816140652, train_acc = 0.9884722869119702\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 85, train_loss = 6.243788383901119, train_acc = 0.9885887284583139\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 86, train_loss = 6.159342963248491, train_acc = 0.9885887284583139\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 87, train_loss = 6.076383706182241, train_acc = 0.9888216115510013\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 88, train_loss = 5.995077984407544, train_acc = 0.9891709361900326\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 89, train_loss = 5.915313072502613, train_acc = 0.9892873777363763\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 90, train_loss = 5.837012154981494, train_acc = 0.9895202608290639\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 91, train_loss = 5.759925862774253, train_acc = 0.9895202608290639\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 92, train_loss = 5.684457713738084, train_acc = 0.9897531439217513\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 93, train_loss = 5.610223039984703, train_acc = 0.9897531439217513\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 94, train_loss = 5.537544680759311, train_acc = 0.9897531439217513\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 95, train_loss = 5.465964652597904, train_acc = 0.9901024685607824\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 96, train_loss = 5.395717829465866, train_acc = 0.9902189101071263\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 97, train_loss = 5.326678607612848, train_acc = 0.99033535165347\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 98, train_loss = 5.259049952030182, train_acc = 0.9904517931998137\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 99, train_loss = 5.192446317523718, train_acc = 0.990801117838845\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 100, train_loss = 5.127008491195738, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 101, train_loss = 5.062771242111921, train_acc = 0.9911504424778761\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 102, train_loss = 4.9994795843958855, train_acc = 0.9913833255705635\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 103, train_loss = 4.937222616747022, train_acc = 0.9914997671169073\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 104, train_loss = 4.876045188866556, train_acc = 0.9914997671169073\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 105, train_loss = 4.815902944654226, train_acc = 0.9913833255705635\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 106, train_loss = 4.756704435683787, train_acc = 0.9913833255705635\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 107, train_loss = 4.6984945656731725, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 108, train_loss = 4.641230643726885, train_acc = 0.9916162086632511\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 109, train_loss = 4.584805019199848, train_acc = 0.9918490917559385\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 110, train_loss = 4.5294891865924, train_acc = 0.9919655333022822\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 111, train_loss = 4.475017277523875, train_acc = 0.992081974848626\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 112, train_loss = 4.421492205001414, train_acc = 0.9924312994876572\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 113, train_loss = 4.3687886437401175, train_acc = 0.9924312994876572\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 114, train_loss = 4.31705801282078, train_acc = 0.9924312994876572\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 115, train_loss = 4.266242981888354, train_acc = 0.9925477410340009\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 116, train_loss = 4.21616827044636, train_acc = 0.9928970656730322\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 117, train_loss = 4.1670334273949265, train_acc = 0.9931299487657196\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 118, train_loss = 4.118853099644184, train_acc = 0.9932463903120633\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 119, train_loss = 4.071359366178513, train_acc = 0.9932463903120633\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 120, train_loss = 4.024756743572652, train_acc = 0.9933628318584071\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 121, train_loss = 3.978927361778915, train_acc = 0.9933628318584071\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 122, train_loss = 3.9338683988898993, train_acc = 0.9934792734047508\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 123, train_loss = 3.889642077498138, train_acc = 0.9934792734047508\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 124, train_loss = 3.8461208203807473, train_acc = 0.9935957149510946\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 125, train_loss = 3.8035215996205807, train_acc = 0.9937121564974383\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 126, train_loss = 3.7614069217815995, train_acc = 0.9937121564974383\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 127, train_loss = 3.7201627967879176, train_acc = 0.9937121564974383\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 128, train_loss = 3.679524543695152, train_acc = 0.9937121564974383\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 129, train_loss = 3.6395880533382297, train_acc = 0.9937121564974383\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 130, train_loss = 3.6003133030608296, train_acc = 0.993828598043782\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 131, train_loss = 3.5617395155131817, train_acc = 0.993828598043782\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 132, train_loss = 3.523894597776234, train_acc = 0.993828598043782\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 133, train_loss = 3.486660876311362, train_acc = 0.993828598043782\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 134, train_loss = 3.4501622831448913, train_acc = 0.9939450395901258\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 135, train_loss = 3.41428757738322, train_acc = 0.9940614811364695\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 136, train_loss = 3.3789613284170628, train_acc = 0.9941779226828132\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 137, train_loss = 3.3441872084513307, train_acc = 0.994294364229157\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 138, train_loss = 3.310138759203255, train_acc = 0.9944108057755007\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 139, train_loss = 3.2766779297962785, train_acc = 0.9945272473218444\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 140, train_loss = 3.2436003321781754, train_acc = 0.9945272473218444\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 141, train_loss = 3.211236910894513, train_acc = 0.9945272473218444\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 142, train_loss = 3.179353255778551, train_acc = 0.9946436888681882\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 143, train_loss = 3.147971556056291, train_acc = 0.9946436888681882\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 144, train_loss = 3.1172245871275663, train_acc = 0.9947601304145319\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 145, train_loss = 3.0869475696235895, train_acc = 0.9947601304145319\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 146, train_loss = 3.057150776963681, train_acc = 0.9948765719608756\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 147, train_loss = 3.0279160737991333, train_acc = 0.9951094550535631\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 148, train_loss = 2.999171485658735, train_acc = 0.9951094550535631\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 149, train_loss = 2.9708897322416306, train_acc = 0.9953423381462506\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 150, train_loss = 2.9432140202261508, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 151, train_loss = 2.9159069932065904, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 152, train_loss = 2.8890952109359205, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 153, train_loss = 2.862745285499841, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 154, train_loss = 2.8369268644601107, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 155, train_loss = 2.8114125169813633, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 156, train_loss = 2.7863462450914085, train_acc = 0.995575221238938\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 157, train_loss = 2.7617246047593653, train_acc = 0.9956916627852818\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 158, train_loss = 2.7374376780353487, train_acc = 0.9956916627852818\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 159, train_loss = 2.713607989717275, train_acc = 0.9956916627852818\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 160, train_loss = 2.6902528046630323, train_acc = 0.9956916627852818\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 161, train_loss = 2.6672531627118587, train_acc = 0.9956916627852818\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 162, train_loss = 2.6445676647126675, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 163, train_loss = 2.6224044072441757, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 164, train_loss = 2.600463408511132, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 165, train_loss = 2.5791806210763752, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 166, train_loss = 2.558049764018506, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 167, train_loss = 2.5374515685252845, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 168, train_loss = 2.5171480886638165, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 169, train_loss = 2.497161090373993, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 170, train_loss = 2.477548446971923, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 171, train_loss = 2.4583648913539946, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 172, train_loss = 2.4393761572428048, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 173, train_loss = 2.4207673482596874, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 174, train_loss = 2.402406644076109, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 175, train_loss = 2.384449732955545, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 176, train_loss = 2.366661735344678, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 177, train_loss = 2.3492613807320595, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 178, train_loss = 2.3321408755145967, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 179, train_loss = 2.3152238838374615, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 180, train_loss = 2.2987622707150877, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 181, train_loss = 2.2823410504497588, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 182, train_loss = 2.2663817764259875, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 183, train_loss = 2.2506051412783563, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 184, train_loss = 2.235033582895994, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 185, train_loss = 2.21966390311718, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 186, train_loss = 2.2047330278437585, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 187, train_loss = 2.1898170064669102, train_acc = 0.9966231951560317\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 188, train_loss = 2.1752976637799293, train_acc = 0.9966231951560317\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 189, train_loss = 2.160925341071561, train_acc = 0.9966231951560317\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 190, train_loss = 2.146779637783766, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 191, train_loss = 2.132847836939618, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 192, train_loss = 2.1192069861572236, train_acc = 0.9966231951560317\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 193, train_loss = 2.1057647056877613, train_acc = 0.9966231951560317\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 194, train_loss = 2.092387745855376, train_acc = 0.9966231951560317\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 195, train_loss = 2.079419445246458, train_acc = 0.9966231951560317\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 196, train_loss = 2.0664935745298862, train_acc = 0.9966231951560317\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 197, train_loss = 2.0538879844825715, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 198, train_loss = 2.0413837942760438, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 199, train_loss = 2.0291114214342088, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 200, train_loss = 2.016998181818053, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 201, train_loss = 2.0050809283275157, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 202, train_loss = 1.9933482892811298, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 203, train_loss = 1.981760673224926, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 204, train_loss = 1.9704141791444272, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 205, train_loss = 1.959119415609166, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 206, train_loss = 1.9481325324159116, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 207, train_loss = 1.9372421477455646, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 208, train_loss = 1.926512110978365, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 209, train_loss = 1.9159590874332935, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 210, train_loss = 1.9055611577350646, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 211, train_loss = 1.8953322742599994, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 212, train_loss = 1.8851746283471584, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 213, train_loss = 1.8753255184274167, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 214, train_loss = 1.8655015092808753, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 215, train_loss = 1.8558495219331235, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 216, train_loss = 1.846409736899659, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 217, train_loss = 1.836930550634861, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 218, train_loss = 1.8277707621455193, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 219, train_loss = 1.818619119701907, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 220, train_loss = 1.8095791328232735, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 221, train_loss = 1.800743120489642, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 222, train_loss = 1.7920494228601456, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 223, train_loss = 1.7834000289440155, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 224, train_loss = 1.7748760618269444, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 225, train_loss = 1.766554680885747, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 226, train_loss = 1.7582050238270313, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 227, train_loss = 1.7500403772573918, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 228, train_loss = 1.7420144714415073, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 229, train_loss = 1.7340734612662345, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 230, train_loss = 1.7262129038572311, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 231, train_loss = 1.7184912289958447, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 232, train_loss = 1.7107781618833542, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 233, train_loss = 1.7033158466219902, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 234, train_loss = 1.6958015251439065, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 235, train_loss = 1.6884642466902733, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 236, train_loss = 1.6812072396278381, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 237, train_loss = 1.6740446450421587, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 238, train_loss = 1.6669597862055525, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 239, train_loss = 1.65998498222325, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 240, train_loss = 1.652999841957353, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 241, train_loss = 1.6461651623249054, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 242, train_loss = 1.6394896606216207, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 243, train_loss = 1.632844208390452, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 244, train_loss = 1.626218743622303, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 245, train_loss = 1.6197434602072462, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 246, train_loss = 1.6132815778255463, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 247, train_loss = 1.6069738926598802, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 248, train_loss = 1.6006710802903399, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 249, train_loss = 1.594477684586309, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 250, train_loss = 1.5883961146464571, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 251, train_loss = 1.582292584120296, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 252, train_loss = 1.57627597078681, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 253, train_loss = 1.5704073123633862, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 254, train_loss = 1.5645201107254252, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 255, train_loss = 1.5587320463964716, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 256, train_loss = 1.5530702508985996, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 257, train_loss = 1.5473731545498595, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 258, train_loss = 1.541753469617106, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 259, train_loss = 1.5361758396029472, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 260, train_loss = 1.5307078683981672, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 261, train_loss = 1.525340672582388, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 262, train_loss = 1.5198948433389887, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 263, train_loss = 1.5146367674460635, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 264, train_loss = 1.5093936398625374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 265, train_loss = 1.5041987734148279, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 266, train_loss = 1.4990950176725164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 267, train_loss = 1.493920974433422, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 268, train_loss = 1.4889484631130472, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 269, train_loss = 1.4839857941260561, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 270, train_loss = 1.4790111841866747, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 271, train_loss = 1.4741174665978178, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 272, train_loss = 1.4693705016979948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 273, train_loss = 1.4645486796507612, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 274, train_loss = 1.4598894404480234, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 275, train_loss = 1.455169290304184, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 276, train_loss = 1.4505705473711714, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 277, train_loss = 1.4460209695389494, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 278, train_loss = 1.4413934163749218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 279, train_loss = 1.4369171634316444, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 280, train_loss = 1.4325045682489872, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 281, train_loss = 1.4281028223922476, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 282, train_loss = 1.4237514348933473, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 283, train_loss = 1.4194310456514359, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 284, train_loss = 1.4151432724902406, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 285, train_loss = 1.4108705011894926, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 286, train_loss = 1.406654460937716, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 287, train_loss = 1.4025302293011919, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 288, train_loss = 1.3984451642027125, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 289, train_loss = 1.3943277125945315, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 290, train_loss = 1.3903263980755582, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 291, train_loss = 1.3862866485724226, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 292, train_loss = 1.382352982996963, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 293, train_loss = 1.3783876126399264, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 294, train_loss = 1.3745105974376202, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 295, train_loss = 1.3706823860993609, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 296, train_loss = 1.3668022652855143, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 297, train_loss = 1.3630426687886938, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 298, train_loss = 1.3592660004505888, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 299, train_loss = 1.3555809134850278, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 300, train_loss = 1.3518840497126803, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 301, train_loss = 1.3482951037585735, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 302, train_loss = 1.3446042723953724, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 303, train_loss = 1.3410788750043139, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 304, train_loss = 1.337483057170175, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 305, train_loss = 1.3339370166067965, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 306, train_loss = 1.3304630580241792, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 307, train_loss = 1.3271107512409799, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 308, train_loss = 1.323550087690819, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 309, train_loss = 1.3201928734779358, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 310, train_loss = 1.316941361874342, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 311, train_loss = 1.3134657057817094, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 312, train_loss = 1.31026565405773, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 313, train_loss = 1.3069203905761242, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 314, train_loss = 1.3035977706313133, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 315, train_loss = 1.300559688359499, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 316, train_loss = 1.2972651844029315, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 317, train_loss = 1.2941315335338004, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 318, train_loss = 1.2909070340101607, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 319, train_loss = 1.287830491841305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 320, train_loss = 1.284723969816696, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 321, train_loss = 1.2816473059356213, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 322, train_loss = 1.278687484562397, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 323, train_loss = 1.275621107488405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 324, train_loss = 1.2726638354361057, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 325, train_loss = 1.269666701555252, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 326, train_loss = 1.26677207153989, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 327, train_loss = 1.263840404630173, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 328, train_loss = 1.260991229384672, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 329, train_loss = 1.2580446973443031, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 330, train_loss = 1.2553186875884421, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 331, train_loss = 1.252467421174515, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 332, train_loss = 1.249617327004671, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 333, train_loss = 1.2468493941123597, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 334, train_loss = 1.244124275923241, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 335, train_loss = 1.2414028855855577, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 336, train_loss = 1.238761242479086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 337, train_loss = 1.235985390841961, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 338, train_loss = 1.2334230902488343, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 339, train_loss = 1.230716958642006, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 340, train_loss = 1.2281045379932038, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 341, train_loss = 1.2254154831171036, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 342, train_loss = 1.22291685763048, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 343, train_loss = 1.2203201006050222, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 344, train_loss = 1.2177511366899125, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 345, train_loss = 1.2152159251272678, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 346, train_loss = 1.2127131086890586, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 347, train_loss = 1.2102461904287338, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 348, train_loss = 1.2077431045472622, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 349, train_loss = 1.2052983443136327, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 350, train_loss = 1.2028751348261721, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 351, train_loss = 1.2004379630088806, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 352, train_loss = 1.1980896915192716, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 353, train_loss = 1.1956867277622223, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 354, train_loss = 1.1932935416698456, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 355, train_loss = 1.1909777447581291, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 356, train_loss = 1.1886552187497728, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 357, train_loss = 1.1863251328468323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 358, train_loss = 1.1840658076107502, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 359, train_loss = 1.1817584000527859, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 360, train_loss = 1.179484597116243, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 361, train_loss = 1.1772380980546586, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 362, train_loss = 1.1750410683453083, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 363, train_loss = 1.1728532898123376, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 364, train_loss = 1.1706221103668213, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 365, train_loss = 1.1684227821533568, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 366, train_loss = 1.1662800833582878, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 367, train_loss = 1.1640710991923697, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 368, train_loss = 1.162004801153671, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 369, train_loss = 1.1598107479512691, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 370, train_loss = 1.1578275014762767, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 371, train_loss = 1.1556883218581788, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 372, train_loss = 1.1536252908408642, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 373, train_loss = 1.1515348044340499, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 374, train_loss = 1.1494988066260703, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 375, train_loss = 1.1474118220503442, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 376, train_loss = 1.145460408180952, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 377, train_loss = 1.1434141236240976, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 378, train_loss = 1.1415144155616872, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 379, train_loss = 1.1394091459806077, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 380, train_loss = 1.1374704440240748, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 381, train_loss = 1.13557604822563, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 382, train_loss = 1.1336704815621488, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 383, train_loss = 1.1316709307138808, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 384, train_loss = 1.1297837657039054, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 385, train_loss = 1.1278371661901474, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 386, train_loss = 1.126031852036249, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 387, train_loss = 1.1240751159493811, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 388, train_loss = 1.1222821387345903, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 389, train_loss = 1.120386678725481, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 390, train_loss = 1.118531292944681, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 391, train_loss = 1.1167063663597219, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 392, train_loss = 1.1149838740820996, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 393, train_loss = 1.1131254409556277, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 394, train_loss = 1.1113069492275827, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 395, train_loss = 1.1095636363024823, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 396, train_loss = 1.1077860295772552, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 397, train_loss = 1.1060083930497058, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 398, train_loss = 1.1042989094858058, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 399, train_loss = 1.102538036822807, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 400, train_loss = 1.1008167887921445, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 401, train_loss = 1.0991185394232161, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 402, train_loss = 1.0973774579470046, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 403, train_loss = 1.0957980901002884, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 404, train_loss = 1.0940307813580148, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 405, train_loss = 1.0923003926873207, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 406, train_loss = 1.0906775879557244, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 407, train_loss = 1.0890398025512695, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 408, train_loss = 1.0874150320887566, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 409, train_loss = 1.085780791938305, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 410, train_loss = 1.0841173268854618, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 411, train_loss = 1.0825660824775696, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 412, train_loss = 1.080909475684166, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 413, train_loss = 1.079411686718231, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 414, train_loss = 1.0777505064907018, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 415, train_loss = 1.0761970952153206, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 416, train_loss = 1.0746301040053368, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 417, train_loss = 1.073086641728878, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 418, train_loss = 1.0715436351893004, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 419, train_loss = 1.0700153286161367, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 420, train_loss = 1.0684579548833426, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 421, train_loss = 1.0669470106658991, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 422, train_loss = 1.065465939551359, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 423, train_loss = 1.063990884780651, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 424, train_loss = 1.0624540783464909, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 425, train_loss = 1.0609890520572662, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 426, train_loss = 1.0595007514057215, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 427, train_loss = 1.0580698077974375, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 428, train_loss = 1.056625065713888, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 429, train_loss = 1.055215777218109, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 430, train_loss = 1.0536969254317228, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 431, train_loss = 1.0522893741726875, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 432, train_loss = 1.0508080497384071, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 433, train_loss = 1.0494768507778645, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 434, train_loss = 1.0480328723788261, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 435, train_loss = 1.0467123264970724, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 436, train_loss = 1.045259049773449, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 437, train_loss = 1.0438837321999017, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 438, train_loss = 1.0424693214299623, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 439, train_loss = 1.0412656354310457, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 440, train_loss = 1.0397533228097018, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 441, train_loss = 1.0384257063269615, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 442, train_loss = 1.0370498237607535, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 443, train_loss = 1.0358124884369317, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 444, train_loss = 1.034422251075739, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 445, train_loss = 1.0331436693668365, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 446, train_loss = 1.0317833460867405, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 447, train_loss = 1.0305718469026033, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 448, train_loss = 1.0292298942804337, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 449, train_loss = 1.028010650217766, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 450, train_loss = 1.0265843520464841, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 451, train_loss = 1.0254010446369648, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 452, train_loss = 1.0240454748272896, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 453, train_loss = 1.0228680434229318, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 454, train_loss = 1.0215339660644531, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 455, train_loss = 1.0203442039492074, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 456, train_loss = 1.0190283382835332, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 457, train_loss = 1.0178844183683395, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 458, train_loss = 1.0166300646960735, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 459, train_loss = 1.0154250202176627, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 460, train_loss = 1.0141356835665647, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 461, train_loss = 1.0129886964859907, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 462, train_loss = 1.0117172611353453, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 463, train_loss = 1.010632410645485, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 464, train_loss = 1.009314727038145, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 465, train_loss = 1.0082163289189339, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 466, train_loss = 1.0069187743065413, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 467, train_loss = 1.0059166476130486, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 468, train_loss = 1.0046406425535679, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 469, train_loss = 1.0035554505884647, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 470, train_loss = 1.0023084121348802, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 471, train_loss = 1.0012704034743365, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 472, train_loss = 1.0000318909587804, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 473, train_loss = 0.998917675256962, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 474, train_loss = 0.9977697046997491, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 475, train_loss = 0.9966523026523646, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 476, train_loss = 0.995554049819475, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 477, train_loss = 0.9943446765246335, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 478, train_loss = 0.9932934654352721, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 479, train_loss = 0.9921777161362115, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 480, train_loss = 0.9910973459482193, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 481, train_loss = 0.990021787583828, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 482, train_loss = 0.9889974370598793, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 483, train_loss = 0.9878448930976447, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 484, train_loss = 0.9867387289705221, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 485, train_loss = 0.9857112293539103, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 486, train_loss = 0.9846380141971167, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 487, train_loss = 0.983664275467163, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 488, train_loss = 0.9824747865495738, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 489, train_loss = 0.9814704035816249, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 490, train_loss = 0.980459425598383, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 491, train_loss = 0.9793389700353146, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 492, train_loss = 0.9783505462110043, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 493, train_loss = 0.9772963511350099, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 494, train_loss = 0.9763201599416789, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 495, train_loss = 0.9752956467273179, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 496, train_loss = 0.9743018187582493, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 497, train_loss = 0.9732306934893131, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 498, train_loss = 0.9723062390985433, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 499, train_loss = 0.9712571861746255, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████▋                              | 17/30 [1:56:09<1:29:08, 411.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "18th- epoch: 0, train_loss = 271.89724147319794, train_acc = 0.48136935258500235\n",
      "test Acc 0.569366852886406:\n",
      "18th- epoch: 1, train_loss = 204.78324449062347, train_acc = 0.5611318118304611\n",
      "test Acc 0.5647113594040968:\n",
      "18th- epoch: 2, train_loss = 159.70210766792297, train_acc = 0.5767349790405216\n",
      "test Acc 0.6294227188081937:\n",
      "18th- epoch: 3, train_loss = 133.62573552131653, train_acc = 0.672100605496041\n",
      "test Acc 0.7351024208566108:\n",
      "18th- epoch: 4, train_loss = 115.49241036176682, train_acc = 0.7515137401024685\n",
      "test Acc 0.7807262569832403:\n",
      "18th- epoch: 5, train_loss = 101.01707556843758, train_acc = 0.7749184909175594\n",
      "test Acc 0.8016759776536313:\n",
      "18th- epoch: 6, train_loss = 88.99377238750458, train_acc = 0.799720540288775\n",
      "test Acc 0.8291433891992551:\n",
      "18th- epoch: 7, train_loss = 79.00304794311523, train_acc = 0.8232417326502096\n",
      "test Acc 0.8491620111731844:\n",
      "18th- epoch: 8, train_loss = 70.56435143947601, train_acc = 0.8492081974848626\n",
      "test Acc 0.8691806331471136:\n",
      "18th- epoch: 9, train_loss = 63.24818789958954, train_acc = 0.8742431299487657\n",
      "test Acc 0.8873370577281192:\n",
      "18th- epoch: 10, train_loss = 56.81884253025055, train_acc = 0.8898462971588262\n",
      "test Acc 0.9017690875232774:\n",
      "18th- epoch: 11, train_loss = 51.17720675468445, train_acc = 0.9087098276665114\n",
      "test Acc 0.9231843575418994:\n",
      "18th- epoch: 12, train_loss = 46.26633147895336, train_acc = 0.9279226828132278\n",
      "test Acc 0.9385474860335196:\n",
      "18th- epoch: 13, train_loss = 42.033098295331, train_acc = 0.9431765253842571\n",
      "test Acc 0.9436685288640596:\n",
      "18th- epoch: 14, train_loss = 38.4032426327467, train_acc = 0.948067070330694\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 15, train_loss = 35.298306219279766, train_acc = 0.9508616674429436\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 16, train_loss = 32.641472302377224, train_acc = 0.9529576152771309\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 17, train_loss = 30.36133435368538, train_acc = 0.9548206800186306\n",
      "test Acc 0.9515828677839852:\n",
      "18th- epoch: 18, train_loss = 28.39529623091221, train_acc = 0.956450861667443\n",
      "test Acc 0.952048417132216:\n",
      "18th- epoch: 19, train_loss = 26.690691992640495, train_acc = 0.9584303679552865\n",
      "test Acc 0.952513966480447:\n",
      "18th- epoch: 20, train_loss = 25.203619174659252, train_acc = 0.9614578481602236\n",
      "test Acc 0.9567039106145251:\n",
      "18th- epoch: 21, train_loss = 23.898948531597853, train_acc = 0.9636702375407545\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 22, train_loss = 22.747273050248623, train_acc = 0.9670470423847228\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 23, train_loss = 21.72314366325736, train_acc = 0.9682114578481602\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 24, train_loss = 20.806379232555628, train_acc = 0.9686772240335352\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 25, train_loss = 19.980582736432552, train_acc = 0.9691429902189101\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 26, train_loss = 19.232374638319016, train_acc = 0.9697251979506288\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 27, train_loss = 18.550159852951765, train_acc = 0.9701909641360037\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 28, train_loss = 17.924898643046618, train_acc = 0.970540288775035\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 29, train_loss = 17.34875339642167, train_acc = 0.9712389380530974\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 30, train_loss = 16.815739035606384, train_acc = 0.9720540288775035\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 31, train_loss = 16.32095168530941, train_acc = 0.9728691197019096\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 32, train_loss = 15.859547063708305, train_acc = 0.9731020027945971\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 33, train_loss = 15.427843902260065, train_acc = 0.9733348858872846\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 34, train_loss = 15.022270485758781, train_acc = 0.9734513274336283\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 35, train_loss = 14.640168890357018, train_acc = 0.9739170936190032\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 36, train_loss = 14.279350604861975, train_acc = 0.974033535165347\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 37, train_loss = 13.937874019145966, train_acc = 0.9747321844434094\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 38, train_loss = 13.61415433138609, train_acc = 0.9750815090824406\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 39, train_loss = 13.306417178362608, train_acc = 0.9754308337214718\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 40, train_loss = 13.013135761022568, train_acc = 0.9756637168141593\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 41, train_loss = 12.732876237481833, train_acc = 0.975780158360503\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 42, train_loss = 12.464808132499456, train_acc = 0.9761294829995343\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 43, train_loss = 12.20776728913188, train_acc = 0.9767116907312529\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 44, train_loss = 11.961069840937853, train_acc = 0.9769445738239404\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 45, train_loss = 11.724053975194693, train_acc = 0.9778761061946902\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 46, train_loss = 11.495833989232779, train_acc = 0.9788076385654402\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 47, train_loss = 11.276011042296886, train_acc = 0.9793898462971589\n",
      "test Acc 0.9711359404096834:\n",
      "18th- epoch: 48, train_loss = 11.06390631571412, train_acc = 0.97973917093619\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 49, train_loss = 10.859353970736265, train_acc = 0.9799720540288775\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 50, train_loss = 10.661752425134182, train_acc = 0.9803213786679087\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 51, train_loss = 10.47083730995655, train_acc = 0.98067070330694\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 52, train_loss = 10.286023320630193, train_acc = 0.9807871448532837\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 53, train_loss = 10.107019631192088, train_acc = 0.9810200279459711\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 54, train_loss = 9.933261370286345, train_acc = 0.9816022356776898\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 55, train_loss = 9.764348074793816, train_acc = 0.9820680018630648\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 56, train_loss = 9.600354941561818, train_acc = 0.9820680018630648\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 57, train_loss = 9.44098025932908, train_acc = 0.9824173265020959\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 58, train_loss = 9.285947458818555, train_acc = 0.9826502095947834\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 59, train_loss = 9.135048685595393, train_acc = 0.9829995342338146\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 60, train_loss = 8.988153038546443, train_acc = 0.9829995342338146\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 61, train_loss = 8.845045618712902, train_acc = 0.9833488588728458\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 62, train_loss = 8.705429676920176, train_acc = 0.9835817419655333\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 63, train_loss = 8.569213356822729, train_acc = 0.9840475081509082\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 64, train_loss = 8.436309261247516, train_acc = 0.9843968327899395\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 65, train_loss = 8.306505719199777, train_acc = 0.9846297158826269\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 66, train_loss = 8.17973418906331, train_acc = 0.985444806707033\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 67, train_loss = 8.055804314091802, train_acc = 0.9855612482533768\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 68, train_loss = 7.934773461893201, train_acc = 0.9856776897997206\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 69, train_loss = 7.816280119121075, train_acc = 0.9857941313460643\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 70, train_loss = 7.7006611078977585, train_acc = 0.9861434559850955\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 71, train_loss = 7.587358867749572, train_acc = 0.9861434559850955\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 72, train_loss = 7.476683193817735, train_acc = 0.9861434559850955\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 73, train_loss = 7.368161855265498, train_acc = 0.9861434559850955\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 74, train_loss = 7.262002190575004, train_acc = 0.9864927806241267\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 75, train_loss = 7.157853459939361, train_acc = 0.9868421052631579\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 76, train_loss = 7.056005284190178, train_acc = 0.9869585468095017\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 77, train_loss = 6.956237688660622, train_acc = 0.9869585468095017\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 78, train_loss = 6.858298672363162, train_acc = 0.9869585468095017\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 79, train_loss = 6.762430531904101, train_acc = 0.9869585468095017\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 80, train_loss = 6.668248267844319, train_acc = 0.9874243129948765\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 81, train_loss = 6.575985673815012, train_acc = 0.9875407545412203\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 82, train_loss = 6.485508546233177, train_acc = 0.9876571960875641\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 83, train_loss = 6.396867774426937, train_acc = 0.9877736376339078\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 84, train_loss = 6.3096545599401, train_acc = 0.9881229622729389\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 85, train_loss = 6.224167037755251, train_acc = 0.9884722869119702\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 86, train_loss = 6.140228403732181, train_acc = 0.9888216115510013\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 87, train_loss = 6.0578890554606915, train_acc = 0.9891709361900326\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 88, train_loss = 5.977153040468693, train_acc = 0.9891709361900326\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 89, train_loss = 5.8978056609630585, train_acc = 0.9892873777363763\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 90, train_loss = 5.820022037252784, train_acc = 0.9892873777363763\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 91, train_loss = 5.743351217359304, train_acc = 0.9892873777363763\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 92, train_loss = 5.668298250064254, train_acc = 0.98940381928272\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 93, train_loss = 5.5944546312093735, train_acc = 0.98940381928272\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 94, train_loss = 5.522015165537596, train_acc = 0.9897531439217513\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 95, train_loss = 5.450900364667177, train_acc = 0.989869585468095\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 96, train_loss = 5.381138096563518, train_acc = 0.9899860270144387\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 97, train_loss = 5.3123905612155795, train_acc = 0.9905682347461574\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 98, train_loss = 5.244981869123876, train_acc = 0.9906846762925011\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 99, train_loss = 5.1788920452818274, train_acc = 0.9910340009315324\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 100, train_loss = 5.113762430846691, train_acc = 0.9909175593851887\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 101, train_loss = 5.049825764261186, train_acc = 0.9912668840242198\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 102, train_loss = 4.987015925347805, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 103, train_loss = 4.925497406162322, train_acc = 0.9913833255705635\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 104, train_loss = 4.864796825684607, train_acc = 0.9913833255705635\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 105, train_loss = 4.8054295387119055, train_acc = 0.9913833255705635\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 106, train_loss = 4.747002378106117, train_acc = 0.9914997671169073\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 107, train_loss = 4.68981175031513, train_acc = 0.9917326502095948\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 108, train_loss = 4.633422304876149, train_acc = 0.9918490917559385\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 109, train_loss = 4.578194422647357, train_acc = 0.992081974848626\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 110, train_loss = 4.524137605912983, train_acc = 0.9921984163949698\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 111, train_loss = 4.4706423515453935, train_acc = 0.9925477410340009\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 112, train_loss = 4.418415698222816, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 113, train_loss = 4.367148134857416, train_acc = 0.9928970656730322\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 114, train_loss = 4.316531114280224, train_acc = 0.9928970656730322\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 115, train_loss = 4.267038565129042, train_acc = 0.9928970656730322\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 116, train_loss = 4.218484031036496, train_acc = 0.9932463903120633\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 117, train_loss = 4.170594867318869, train_acc = 0.9932463903120633\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 118, train_loss = 4.123658166266978, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 119, train_loss = 4.0775117967277765, train_acc = 0.9934792734047508\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 120, train_loss = 4.0324553148821, train_acc = 0.9935957149510946\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 121, train_loss = 3.987995552830398, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 122, train_loss = 3.9445203905925155, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 123, train_loss = 3.9017319083213806, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 124, train_loss = 3.859812218695879, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 125, train_loss = 3.8184561990201473, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 126, train_loss = 3.7780538694933057, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 127, train_loss = 3.7380917817354202, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 128, train_loss = 3.6990251997485757, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 129, train_loss = 3.6605030735954642, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 130, train_loss = 3.622721609659493, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 131, train_loss = 3.585474598221481, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 132, train_loss = 3.549194692634046, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 133, train_loss = 3.5131992986425757, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 134, train_loss = 3.4779751924797893, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 135, train_loss = 3.4434105455875397, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 136, train_loss = 3.4092841502279043, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 137, train_loss = 3.375904953107238, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 138, train_loss = 3.342914855107665, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 139, train_loss = 3.3106599738821387, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 140, train_loss = 3.27891309838742, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 141, train_loss = 3.2478453097864985, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 142, train_loss = 3.216838008724153, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 143, train_loss = 3.186705205589533, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 144, train_loss = 3.157011261675507, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 145, train_loss = 3.127788803074509, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 146, train_loss = 3.099122792482376, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 147, train_loss = 3.0706927343271673, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 148, train_loss = 3.0429892227984965, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 149, train_loss = 3.015624528285116, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 150, train_loss = 2.9886723370291293, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 151, train_loss = 2.9622004949487746, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 152, train_loss = 2.936134514864534, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 153, train_loss = 2.9105720459483564, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 154, train_loss = 2.8853226862847805, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 155, train_loss = 2.860435740556568, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 156, train_loss = 2.835994426161051, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 157, train_loss = 2.811872538179159, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 158, train_loss = 2.788229653146118, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 159, train_loss = 2.7648888886906207, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 160, train_loss = 2.7418529577553272, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 161, train_loss = 2.7192630036734045, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 162, train_loss = 2.696820420678705, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 163, train_loss = 2.674894541501999, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 164, train_loss = 2.653246229980141, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 165, train_loss = 2.6320837535895407, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 166, train_loss = 2.6110391207039356, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 167, train_loss = 2.5903698378242552, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 168, train_loss = 2.570096969604492, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 169, train_loss = 2.550067376345396, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 170, train_loss = 2.530374591704458, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 171, train_loss = 2.5108241154812276, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 172, train_loss = 2.4918243610300124, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 173, train_loss = 2.4729454652406275, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 174, train_loss = 2.4544561221264303, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 175, train_loss = 2.4361577332019806, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 176, train_loss = 2.4180742860771716, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 177, train_loss = 2.4004019335843623, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 178, train_loss = 2.382884755730629, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 179, train_loss = 2.3656705752946436, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 180, train_loss = 2.3488683491013944, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 181, train_loss = 2.331915105227381, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 182, train_loss = 2.31559486547485, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 183, train_loss = 2.2990494654513896, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 184, train_loss = 2.28317259112373, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 185, train_loss = 2.267209615558386, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 186, train_loss = 2.25164782255888, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 187, train_loss = 2.2363601312972605, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 188, train_loss = 2.2210645810700953, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 189, train_loss = 2.206299126148224, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 190, train_loss = 2.1913602761924267, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 191, train_loss = 2.177067821379751, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 192, train_loss = 2.1626313566230237, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 193, train_loss = 2.1486878395080566, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 194, train_loss = 2.1346055429894477, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 195, train_loss = 2.121153536019847, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 196, train_loss = 2.1074146169703454, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 197, train_loss = 2.094343637349084, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 198, train_loss = 2.0811340995132923, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 199, train_loss = 2.0683245323598385, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 200, train_loss = 2.0556529834866524, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 201, train_loss = 2.043043728917837, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 202, train_loss = 2.0307697728276253, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 203, train_loss = 2.018590836552903, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 204, train_loss = 2.0067191359121352, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 205, train_loss = 1.994867704808712, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 206, train_loss = 1.9833172373473644, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 207, train_loss = 1.9719167847651988, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 208, train_loss = 1.9605714741628617, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 209, train_loss = 1.9496133613865823, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 210, train_loss = 1.9386136196553707, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 211, train_loss = 1.9278762266039848, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 212, train_loss = 1.91737004625611, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 213, train_loss = 1.90666513890028, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 214, train_loss = 1.896630535600707, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 215, train_loss = 1.8863153010606766, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 216, train_loss = 1.87630233168602, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 217, train_loss = 1.8665769819635898, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 218, train_loss = 1.8568154636304826, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 219, train_loss = 1.847183832200244, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 220, train_loss = 1.837794803082943, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 221, train_loss = 1.828529515536502, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 222, train_loss = 1.8192422601860017, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 223, train_loss = 1.810407182900235, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 224, train_loss = 1.8014735653996468, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 225, train_loss = 1.7925474755465984, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 226, train_loss = 1.7841107684653252, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 227, train_loss = 1.7755077295005322, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 228, train_loss = 1.7670156012754887, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 229, train_loss = 1.7588798876386136, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 230, train_loss = 1.75058959168382, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 231, train_loss = 1.7426133342087269, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 232, train_loss = 1.7344734284561127, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 233, train_loss = 1.7267790001351386, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 234, train_loss = 1.718908266397193, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 235, train_loss = 1.7112384240608662, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 236, train_loss = 1.703745398670435, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 237, train_loss = 1.6963134978432208, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 238, train_loss = 1.6888568873982877, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 239, train_loss = 1.6815404470544308, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 240, train_loss = 1.674482088536024, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 241, train_loss = 1.6673490989487618, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 242, train_loss = 1.6603500668425113, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 243, train_loss = 1.6532974827568978, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 244, train_loss = 1.646583791822195, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 245, train_loss = 1.6398174825590104, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 246, train_loss = 1.6331380046904087, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 247, train_loss = 1.6265598882455379, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 248, train_loss = 1.6199624141445383, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 249, train_loss = 1.6137029168894514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 250, train_loss = 1.6072746949503198, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 251, train_loss = 1.6010206900537014, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 252, train_loss = 1.5948132773628458, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 253, train_loss = 1.5886120274662971, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 254, train_loss = 1.5826270108809695, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 255, train_loss = 1.5766602667281404, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 256, train_loss = 1.5707314722239971, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 257, train_loss = 1.5648165866732597, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 258, train_loss = 1.558966938406229, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 259, train_loss = 1.553383349091746, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 260, train_loss = 1.5476877862820402, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 261, train_loss = 1.5421392694115639, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 262, train_loss = 1.5365437716245651, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 263, train_loss = 1.5309740168740973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 264, train_loss = 1.5256850235164165, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 265, train_loss = 1.5204106891760603, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 266, train_loss = 1.5150360278785229, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 267, train_loss = 1.5097383012762293, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 268, train_loss = 1.5046589821577072, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 269, train_loss = 1.4994129948318005, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 270, train_loss = 1.4944002790143713, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 271, train_loss = 1.4894659804413095, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 272, train_loss = 1.4843706153333187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 273, train_loss = 1.479541178792715, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 274, train_loss = 1.4747087234864011, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 275, train_loss = 1.4698174856603146, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 276, train_loss = 1.4650034630903974, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 277, train_loss = 1.4604078022530302, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 278, train_loss = 1.45575650036335, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 279, train_loss = 1.4510797871043906, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 280, train_loss = 1.4465024881064892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 281, train_loss = 1.4420204845955595, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 282, train_loss = 1.4375174157321453, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 283, train_loss = 1.4331007885048166, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 284, train_loss = 1.428677806048654, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 285, train_loss = 1.4243197118630633, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 286, train_loss = 1.419997582794167, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 287, train_loss = 1.415736003429629, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 288, train_loss = 1.411535651772283, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 289, train_loss = 1.4074013158679008, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 290, train_loss = 1.4031916869571432, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 291, train_loss = 1.3991225300123915, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 292, train_loss = 1.3950527968117967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 293, train_loss = 1.3910228622844443, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 294, train_loss = 1.387050280929543, train_acc = 0.9974382859804378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 295, train_loss = 1.3830703757703304, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "18th- epoch: 296, train_loss = 1.379233560175635, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "18th- epoch: 297, train_loss = 1.3752851350000128, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "18th- epoch: 298, train_loss = 1.3715254478156567, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "18th- epoch: 299, train_loss = 1.3675570884952322, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "18th- epoch: 300, train_loss = 1.3639628402888775, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "18th- epoch: 301, train_loss = 1.3601300144800916, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "18th- epoch: 302, train_loss = 1.3564503627130762, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "18th- epoch: 303, train_loss = 1.3527219655225053, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 304, train_loss = 1.3491285467753187, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 305, train_loss = 1.3454841015627608, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 306, train_loss = 1.3418974069645628, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 307, train_loss = 1.3384352251887321, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 308, train_loss = 1.334858525544405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 309, train_loss = 1.3313546081772074, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 310, train_loss = 1.3278435232350603, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 311, train_loss = 1.324461355805397, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 312, train_loss = 1.3209881024667993, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 313, train_loss = 1.3177578076720238, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 314, train_loss = 1.3143860349664465, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 315, train_loss = 1.311013630242087, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 316, train_loss = 1.3078916855156422, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 317, train_loss = 1.3045559028396383, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 318, train_loss = 1.301378903328441, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 319, train_loss = 1.298149043112062, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 320, train_loss = 1.2950328774750233, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 321, train_loss = 1.2918482484528795, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 322, train_loss = 1.2887554516782984, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 323, train_loss = 1.285597499459982, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 324, train_loss = 1.2825094213476405, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 325, train_loss = 1.2794976842706092, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 326, train_loss = 1.2763845038716681, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 327, train_loss = 1.273457732051611, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 328, train_loss = 1.27045814570738, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 329, train_loss = 1.2676223938469775, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 330, train_loss = 1.2646620546584018, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 331, train_loss = 1.261895780742634, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 332, train_loss = 1.2589227805729024, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 333, train_loss = 1.25611463439418, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 334, train_loss = 1.2533140107989311, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 335, train_loss = 1.2505284647340886, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 336, train_loss = 1.2478047274053097, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 337, train_loss = 1.2450319143827073, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 338, train_loss = 1.242237298458349, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 339, train_loss = 1.239643920212984, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 340, train_loss = 1.2369589458103292, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 341, train_loss = 1.2342430117423646, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 342, train_loss = 1.2316601897473447, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 343, train_loss = 1.2290499855880626, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 344, train_loss = 1.226416417688597, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 345, train_loss = 1.2238819698686711, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 346, train_loss = 1.2212863005697727, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 347, train_loss = 1.2188352445955388, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 348, train_loss = 1.2162603189353831, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 349, train_loss = 1.2138152867555618, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 350, train_loss = 1.2113194328849204, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 351, train_loss = 1.2088852089946158, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 352, train_loss = 1.2063614577054977, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 353, train_loss = 1.2040283493697643, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 354, train_loss = 1.2016005789046176, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 355, train_loss = 1.1992901315097697, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 356, train_loss = 1.196765395521652, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 357, train_loss = 1.1944680313463323, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 358, train_loss = 1.1921937030856498, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 359, train_loss = 1.1898796160821803, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 360, train_loss = 1.1875231650774367, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 361, train_loss = 1.1853606502409093, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 362, train_loss = 1.1830360342864878, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 363, train_loss = 1.1807727962732315, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 364, train_loss = 1.1785153808887117, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 365, train_loss = 1.176298073201906, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 366, train_loss = 1.1741311252117157, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 367, train_loss = 1.1719315946102142, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 368, train_loss = 1.1696798466145992, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 369, train_loss = 1.1676217839121819, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 370, train_loss = 1.1655090898275375, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 371, train_loss = 1.1633345820009708, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 372, train_loss = 1.161267176270485, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 373, train_loss = 1.15905860561179, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 374, train_loss = 1.1570566967129707, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 375, train_loss = 1.1549487809534185, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 376, train_loss = 1.1529690909083001, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 377, train_loss = 1.1509038098156452, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 378, train_loss = 1.148881307512056, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 379, train_loss = 1.1468201142852195, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 380, train_loss = 1.1448677144944668, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 381, train_loss = 1.1428839502041228, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 382, train_loss = 1.1409453551168554, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 383, train_loss = 1.138902224600315, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 384, train_loss = 1.13707471761154, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 385, train_loss = 1.1350298796896823, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 386, train_loss = 1.1332293513114564, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 387, train_loss = 1.1312662797863595, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 388, train_loss = 1.1293650406296365, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 389, train_loss = 1.1274551053647883, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 390, train_loss = 1.1257045741076581, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 391, train_loss = 1.1237442319397815, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 392, train_loss = 1.1219401682610624, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 393, train_loss = 1.120064154267311, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 394, train_loss = 1.1183350483770482, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 395, train_loss = 1.116435977339279, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 396, train_loss = 1.1146954235737212, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 397, train_loss = 1.1128811302478425, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 398, train_loss = 1.1111962075228803, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 399, train_loss = 1.109361357986927, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 400, train_loss = 1.1076789597864263, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 401, train_loss = 1.105826698243618, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 402, train_loss = 1.1042227509315126, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 403, train_loss = 1.1024080527131446, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 404, train_loss = 1.1007575218682177, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 405, train_loss = 1.099044854461681, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 406, train_loss = 1.0973950773477554, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 407, train_loss = 1.095702238380909, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 408, train_loss = 1.0941024509374984, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 409, train_loss = 1.0923531465232372, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 410, train_loss = 1.0907031235401519, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 411, train_loss = 1.0890508691663854, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 412, train_loss = 1.087552176148165, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 413, train_loss = 1.085885168344248, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 414, train_loss = 1.0841769936378114, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 415, train_loss = 1.0826248886878602, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 416, train_loss = 1.0810618313844316, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 417, train_loss = 1.079495194077026, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 418, train_loss = 1.077925978868734, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 419, train_loss = 1.0763293455238454, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 420, train_loss = 1.0747993725235574, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 421, train_loss = 1.0732810385525227, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 422, train_loss = 1.0717007741332054, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 423, train_loss = 1.0702425676281564, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 424, train_loss = 1.06874244537903, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 425, train_loss = 1.067173087329138, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 426, train_loss = 1.0656968069379218, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 427, train_loss = 1.0643236066098325, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 428, train_loss = 1.0626971150632016, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 429, train_loss = 1.0612547273631208, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 430, train_loss = 1.0598953415756114, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 431, train_loss = 1.0584083758294582, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 432, train_loss = 1.056964746385347, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 433, train_loss = 1.0554156017606147, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 434, train_loss = 1.0541434449260123, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 435, train_loss = 1.0526683938805945, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 436, train_loss = 1.0512308639590628, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 437, train_loss = 1.049802877008915, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 438, train_loss = 1.0484452421369497, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 439, train_loss = 1.047118902206421, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 440, train_loss = 1.0457077100872993, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 441, train_loss = 1.0442526750266552, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 442, train_loss = 1.0430163939890917, train_acc = 0.9981369352585002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 443, train_loss = 1.0416282378137112, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 444, train_loss = 1.0403161905705929, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 445, train_loss = 1.0389647943375167, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 446, train_loss = 1.0375751977262553, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 447, train_loss = 1.0363323675992433, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 448, train_loss = 1.0349428206682205, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 449, train_loss = 1.0336079237458762, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 450, train_loss = 1.032371774315834, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 451, train_loss = 1.031000883638626, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 452, train_loss = 1.0298063096997794, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 453, train_loss = 1.028496477752924, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 454, train_loss = 1.027121089398861, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 455, train_loss = 1.0259246130881365, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 456, train_loss = 1.0246886735258158, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 457, train_loss = 1.023403355240589, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 458, train_loss = 1.0222248012723867, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 459, train_loss = 1.020928240061039, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 460, train_loss = 1.0196812426147517, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 461, train_loss = 1.0184378611447755, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 462, train_loss = 1.0173152945935726, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 463, train_loss = 1.0159797531960066, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 464, train_loss = 1.0148418409225997, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 465, train_loss = 1.0135238443908747, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 466, train_loss = 1.0124045039119665, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 467, train_loss = 1.011256626487011, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 468, train_loss = 1.010139599442482, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 469, train_loss = 1.0088054252264556, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 470, train_loss = 1.007707272976404, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 471, train_loss = 1.0065275405941065, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 472, train_loss = 1.0053868144750595, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 473, train_loss = 1.0042202783224639, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 474, train_loss = 1.0030682931246702, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 475, train_loss = 1.001820153236622, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 476, train_loss = 1.0008365263638552, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 477, train_loss = 0.9996378111245576, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 478, train_loss = 0.9984540653822478, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 479, train_loss = 0.9974127126333769, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 480, train_loss = 0.9963482320308685, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 481, train_loss = 0.9951754485664424, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 482, train_loss = 0.9940510094165802, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 483, train_loss = 0.9929335663618986, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 484, train_loss = 0.9919024532136973, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 485, train_loss = 0.9907728806138039, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 486, train_loss = 0.9897027015686035, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 487, train_loss = 0.9885310853424016, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 488, train_loss = 0.9876016713678837, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 489, train_loss = 0.98643177995109, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 490, train_loss = 0.9854933159949724, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 491, train_loss = 0.9843280141649302, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 492, train_loss = 0.9833357209863607, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 493, train_loss = 0.9822654935123865, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 494, train_loss = 0.981200280279154, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 495, train_loss = 0.9801761284470558, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 496, train_loss = 0.9791407994925976, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 497, train_loss = 0.9781113763747271, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 498, train_loss = 0.9770739438536111, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 499, train_loss = 0.9760661485197488, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████                            | 18/30 [2:02:59<1:22:14, 411.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "19th- epoch: 0, train_loss = 273.36229288578033, train_acc = 0.4465533302282254\n",
      "test Acc 0.5181564245810056:\n",
      "19th- epoch: 1, train_loss = 211.0255628824234, train_acc = 0.5433162552398696\n",
      "test Acc 0.5726256983240223:\n",
      "19th- epoch: 2, train_loss = 164.8792484998703, train_acc = 0.572193758733116\n",
      "test Acc 0.5819366852886406:\n",
      "19th- epoch: 3, train_loss = 138.03164148330688, train_acc = 0.6333255705635771\n",
      "test Acc 0.7099627560521415:\n",
      "19th- epoch: 4, train_loss = 119.11426198482513, train_acc = 0.7390544946436889\n",
      "test Acc 0.771415270018622:\n",
      "19th- epoch: 5, train_loss = 103.69481772184372, train_acc = 0.7739869585468095\n",
      "test Acc 0.7965549348230913:\n",
      "19th- epoch: 6, train_loss = 90.78696757555008, train_acc = 0.8012342803912436\n",
      "test Acc 0.8216945996275605:\n",
      "19th- epoch: 7, train_loss = 80.13412061333656, train_acc = 0.8178854215183977\n",
      "test Acc 0.8342644320297952:\n",
      "19th- epoch: 8, train_loss = 71.19885817170143, train_acc = 0.8376804843968327\n",
      "test Acc 0.8608007448789572:\n",
      "19th- epoch: 9, train_loss = 63.49547430872917, train_acc = 0.8713320912901723\n",
      "test Acc 0.8878026070763501:\n",
      "19th- epoch: 10, train_loss = 56.79319201409817, train_acc = 0.891243595714951\n",
      "test Acc 0.904562383612663:\n",
      "19th- epoch: 11, train_loss = 50.98351188004017, train_acc = 0.9168607359105729\n",
      "test Acc 0.9269087523277467:\n",
      "19th- epoch: 12, train_loss = 45.98163828253746, train_acc = 0.9336283185840708\n",
      "test Acc 0.9371508379888268:\n",
      "19th- epoch: 13, train_loss = 41.69958336651325, train_acc = 0.9406148113646949\n",
      "test Acc 0.9385474860335196:\n",
      "19th- epoch: 14, train_loss = 38.05567492544651, train_acc = 0.9445738239403819\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 15, train_loss = 34.971017710864544, train_acc = 0.9485328365160689\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 16, train_loss = 32.35820581763983, train_acc = 0.9507452258965999\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 17, train_loss = 30.13948582112789, train_acc = 0.952491849091756\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 18, train_loss = 28.244263216853142, train_acc = 0.9547042384722869\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 19, train_loss = 26.61413748562336, train_acc = 0.9572659524918491\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 20, train_loss = 25.20021376758814, train_acc = 0.9605263157894737\n",
      "test Acc 0.9548417132216015:\n",
      "19th- epoch: 21, train_loss = 23.962528623640537, train_acc = 0.9634373544480671\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 22, train_loss = 22.87074038013816, train_acc = 0.965649743828598\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 23, train_loss = 21.898277938365936, train_acc = 0.9671634839310667\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 24, train_loss = 21.025477707386017, train_acc = 0.9683278993945039\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 25, train_loss = 20.236415691673756, train_acc = 0.9687936655798789\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 26, train_loss = 19.518893867731094, train_acc = 0.969608756404285\n",
      "test Acc 0.9632216014897579:\n",
      "19th- epoch: 27, train_loss = 18.862815979868174, train_acc = 0.9698416394969726\n",
      "test Acc 0.9636871508379888:\n",
      "19th- epoch: 28, train_loss = 18.258786272257566, train_acc = 0.9703074056823474\n",
      "test Acc 0.9641527001862198:\n",
      "19th- epoch: 29, train_loss = 17.6990656144917, train_acc = 0.9706567303213787\n",
      "test Acc 0.9646182495344506:\n",
      "19th- epoch: 30, train_loss = 17.17871403694153, train_acc = 0.9710060549604099\n",
      "test Acc 0.9646182495344506:\n",
      "19th- epoch: 31, train_loss = 16.692810863256454, train_acc = 0.9713553795994411\n",
      "test Acc 0.9641527001862198:\n",
      "19th- epoch: 32, train_loss = 16.237280294299126, train_acc = 0.971821145784816\n",
      "test Acc 0.9650837988826816:\n",
      "19th- epoch: 33, train_loss = 15.808944344520569, train_acc = 0.9719375873311598\n",
      "test Acc 0.9655493482309124:\n",
      "19th- epoch: 34, train_loss = 15.404763344675303, train_acc = 0.9725197950628784\n",
      "test Acc 0.9655493482309124:\n",
      "19th- epoch: 35, train_loss = 15.022992957383394, train_acc = 0.9726362366092222\n",
      "test Acc 0.9660148975791434:\n",
      "19th- epoch: 36, train_loss = 14.661381881684065, train_acc = 0.9732184443409408\n",
      "test Acc 0.9669459962756052:\n",
      "19th- epoch: 37, train_loss = 14.317761790007353, train_acc = 0.9741499767116907\n",
      "test Acc 0.9669459962756052:\n",
      "19th- epoch: 38, train_loss = 13.990622337907553, train_acc = 0.9746157428970657\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 39, train_loss = 13.678307544440031, train_acc = 0.9747321844434094\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 40, train_loss = 13.379680324345827, train_acc = 0.9749650675360969\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 41, train_loss = 13.093740362673998, train_acc = 0.9751979506287843\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 42, train_loss = 12.819302186369896, train_acc = 0.9754308337214718\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 43, train_loss = 12.555530291050673, train_acc = 0.9760130414531905\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 44, train_loss = 12.302075240761042, train_acc = 0.9764788076385654\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 45, train_loss = 12.05829607322812, train_acc = 0.9767116907312529\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 46, train_loss = 11.82318876311183, train_acc = 0.9768281322775967\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 47, train_loss = 11.596435572952032, train_acc = 0.9776432231020028\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 48, train_loss = 11.377176351845264, train_acc = 0.9784583139264089\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 49, train_loss = 11.165064603090286, train_acc = 0.9791569632044713\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 50, train_loss = 10.959631476551294, train_acc = 0.9796227293898463\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 51, train_loss = 10.760770875960588, train_acc = 0.9800884955752213\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 52, train_loss = 10.567924745380878, train_acc = 0.980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 53, train_loss = 10.380944654345512, train_acc = 0.9805542617605962\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 54, train_loss = 10.19945328682661, train_acc = 0.98067070330694\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 55, train_loss = 10.023184057325125, train_acc = 0.9811364694923148\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 56, train_loss = 9.851690862327814, train_acc = 0.981951560316721\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 57, train_loss = 9.684666108340025, train_acc = 0.9823008849557522\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 58, train_loss = 9.522142058238387, train_acc = 0.9824173265020959\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 59, train_loss = 9.363911157473922, train_acc = 0.9825337680484397\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 60, train_loss = 9.209582487121224, train_acc = 0.9827666511411272\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 61, train_loss = 9.059036649763584, train_acc = 0.9827666511411272\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 62, train_loss = 8.912371387705207, train_acc = 0.9828830926874709\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 63, train_loss = 8.769430266693234, train_acc = 0.9829995342338146\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 64, train_loss = 8.629967475309968, train_acc = 0.9831159757801584\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 65, train_loss = 8.493983460590243, train_acc = 0.9833488588728458\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 66, train_loss = 8.361213561147451, train_acc = 0.9835817419655333\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 67, train_loss = 8.231540016829967, train_acc = 0.983698183511877\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 68, train_loss = 8.105048896744847, train_acc = 0.983698183511877\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 69, train_loss = 7.981414217501879, train_acc = 0.9842803912435957\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 70, train_loss = 7.8608475886285305, train_acc = 0.9845132743362832\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 71, train_loss = 7.742944227531552, train_acc = 0.9849790405216581\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 72, train_loss = 7.627942059189081, train_acc = 0.9852119236143456\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 73, train_loss = 7.51532407104969, train_acc = 0.985444806707033\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 74, train_loss = 7.40527961216867, train_acc = 0.9855612482533768\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 75, train_loss = 7.297567879781127, train_acc = 0.9856776897997206\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 76, train_loss = 7.192143056541681, train_acc = 0.9857941313460643\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 77, train_loss = 7.088943852111697, train_acc = 0.9860270144387517\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 78, train_loss = 6.9881424978375435, train_acc = 0.9860270144387517\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 79, train_loss = 6.889355968683958, train_acc = 0.9860270144387517\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 80, train_loss = 6.7926583755761385, train_acc = 0.986376339077783\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 81, train_loss = 6.6978834215551615, train_acc = 0.9868421052631579\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 82, train_loss = 6.605064518749714, train_acc = 0.9875407545412203\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 83, train_loss = 6.5140624195337296, train_acc = 0.9880065207265952\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 84, train_loss = 6.424965700134635, train_acc = 0.9881229622729389\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 85, train_loss = 6.337529096752405, train_acc = 0.9884722869119702\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 86, train_loss = 6.251792037859559, train_acc = 0.9887051700046576\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 87, train_loss = 6.167609861120582, train_acc = 0.9887051700046576\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 88, train_loss = 6.085068004205823, train_acc = 0.9888216115510013\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 89, train_loss = 6.004006301984191, train_acc = 0.9890544946436889\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 90, train_loss = 5.92462208494544, train_acc = 0.9892873777363763\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 91, train_loss = 5.846530828624964, train_acc = 0.9897531439217513\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 92, train_loss = 5.769762082025409, train_acc = 0.989869585468095\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 93, train_loss = 5.694460669532418, train_acc = 0.9902189101071263\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 94, train_loss = 5.620378710329533, train_acc = 0.9904517931998137\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 95, train_loss = 5.54782454110682, train_acc = 0.9905682347461574\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 96, train_loss = 5.4764981381595135, train_acc = 0.9906846762925011\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 97, train_loss = 5.40644277445972, train_acc = 0.990801117838845\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 98, train_loss = 5.337761204689741, train_acc = 0.9910340009315324\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 99, train_loss = 5.270156087353826, train_acc = 0.9910340009315324\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 100, train_loss = 5.203955609351397, train_acc = 0.9911504424778761\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 101, train_loss = 5.138770831748843, train_acc = 0.9912668840242198\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 102, train_loss = 5.074768178164959, train_acc = 0.9912668840242198\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 103, train_loss = 5.012041976675391, train_acc = 0.9912668840242198\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 104, train_loss = 4.950290071777999, train_acc = 0.9913833255705635\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 105, train_loss = 4.8896785425022244, train_acc = 0.9918490917559385\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 106, train_loss = 4.830175231210887, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 107, train_loss = 4.7717574732378125, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 108, train_loss = 4.714368500746787, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 109, train_loss = 4.657947565428913, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 110, train_loss = 4.60252860467881, train_acc = 0.9917326502095948\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 111, train_loss = 4.548074196092784, train_acc = 0.9918490917559385\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 112, train_loss = 4.494622057303786, train_acc = 0.9918490917559385\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 113, train_loss = 4.442080561071634, train_acc = 0.9918490917559385\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 114, train_loss = 4.390335317701101, train_acc = 0.9919655333022822\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 115, train_loss = 4.339662184938788, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 116, train_loss = 4.289748757146299, train_acc = 0.9919655333022822\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 117, train_loss = 4.240786026231945, train_acc = 0.992081974848626\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 118, train_loss = 4.192707994952798, train_acc = 0.9921984163949698\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 119, train_loss = 4.145237599499524, train_acc = 0.9923148579413135\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 120, train_loss = 4.098750284872949, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 121, train_loss = 4.053016402758658, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 122, train_loss = 4.008038993924856, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 123, train_loss = 3.963953481055796, train_acc = 0.9928970656730322\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 124, train_loss = 3.9204489663243294, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 125, train_loss = 3.877748580649495, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 126, train_loss = 3.8357747672125697, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 127, train_loss = 3.7944400822743773, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 128, train_loss = 3.7539140237495303, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 129, train_loss = 3.7140196496620774, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 130, train_loss = 3.674838830716908, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 131, train_loss = 3.6363879879936576, train_acc = 0.9935957149510946\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 132, train_loss = 3.598556773737073, train_acc = 0.9935957149510946\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 133, train_loss = 3.5613212613388896, train_acc = 0.9937121564974383\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 134, train_loss = 3.524790939874947, train_acc = 0.993828598043782\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 135, train_loss = 3.48874369263649, train_acc = 0.9939450395901258\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 136, train_loss = 3.4534530779346824, train_acc = 0.9939450395901258\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 137, train_loss = 3.418633875437081, train_acc = 0.9939450395901258\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 138, train_loss = 3.384481528773904, train_acc = 0.9940614811364695\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 139, train_loss = 3.3508442351594567, train_acc = 0.9941779226828132\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 140, train_loss = 3.317653293721378, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 141, train_loss = 3.285215954296291, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 142, train_loss = 3.2532112998887897, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 143, train_loss = 3.2216457137838006, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 144, train_loss = 3.190831427462399, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 145, train_loss = 3.1604860639199615, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 146, train_loss = 3.1306789880618453, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 147, train_loss = 3.1013820925727487, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 148, train_loss = 3.0725447395816445, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 149, train_loss = 3.0441999174654484, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 150, train_loss = 3.0164309688843787, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 151, train_loss = 2.9889035685919225, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 152, train_loss = 2.96195244602859, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 153, train_loss = 2.9354827404022217, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 154, train_loss = 2.90942948916927, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 155, train_loss = 2.883703547064215, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 156, train_loss = 2.8584273792803288, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 157, train_loss = 2.8335903608240187, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 158, train_loss = 2.809183742851019, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 159, train_loss = 2.7851421707309783, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 160, train_loss = 2.761394219007343, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 161, train_loss = 2.738212684635073, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 162, train_loss = 2.7152198725380003, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 163, train_loss = 2.692653053905815, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 164, train_loss = 2.6703583146445453, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 165, train_loss = 2.6484668534249067, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 166, train_loss = 2.626902673859149, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 167, train_loss = 2.6056415890343487, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 168, train_loss = 2.5847201459109783, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 169, train_loss = 2.564181346911937, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 170, train_loss = 2.5439210613258183, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 171, train_loss = 2.523973315488547, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 172, train_loss = 2.5044257105328143, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 173, train_loss = 2.4850233900360763, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 174, train_loss = 2.465924696996808, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 175, train_loss = 2.447149171959609, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 176, train_loss = 2.4287976031191647, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 177, train_loss = 2.4105472271330655, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 178, train_loss = 2.39268111390993, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 179, train_loss = 2.374979353044182, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 180, train_loss = 2.357657228130847, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 181, train_loss = 2.3404203192330897, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 182, train_loss = 2.3235795497894287, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 183, train_loss = 2.3070244095288217, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 184, train_loss = 2.2906259926967323, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 185, train_loss = 2.2744851573370397, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 186, train_loss = 2.258689073380083, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 187, train_loss = 2.243017145898193, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 188, train_loss = 2.2276212708093226, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 189, train_loss = 2.2125195362605155, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 190, train_loss = 2.197633116040379, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 191, train_loss = 2.182862378656864, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 192, train_loss = 2.168432375881821, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 193, train_loss = 2.1541412197984755, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 194, train_loss = 2.1401351653039455, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 195, train_loss = 2.126321293413639, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 196, train_loss = 2.112770760897547, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 197, train_loss = 2.0993427000939846, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 198, train_loss = 2.0861061960458755, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 199, train_loss = 2.0730812065303326, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 200, train_loss = 2.0603387765586376, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 201, train_loss = 2.0476963482797146, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 202, train_loss = 2.0352299835067242, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 203, train_loss = 2.022957398323342, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 204, train_loss = 2.0109034217894077, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 205, train_loss = 1.9990009106695652, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 206, train_loss = 1.987240358022973, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 207, train_loss = 1.975680987117812, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 208, train_loss = 1.9643534619826823, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 209, train_loss = 1.9530861254315823, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 210, train_loss = 1.9421078599989414, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 211, train_loss = 1.9312294262927026, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 212, train_loss = 1.9205248069483787, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 213, train_loss = 1.9100051496643573, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 214, train_loss = 1.8996103194076568, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 215, train_loss = 1.889375016093254, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 216, train_loss = 1.879293866455555, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 217, train_loss = 1.8693652674555779, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 218, train_loss = 1.8595460578799248, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 219, train_loss = 1.849928629817441, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 220, train_loss = 1.8404181625228375, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 221, train_loss = 1.8309897631406784, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 222, train_loss = 1.8217493009287864, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 223, train_loss = 1.8126683756709099, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 224, train_loss = 1.8035747148096561, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 225, train_loss = 1.794772284803912, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 226, train_loss = 1.785931744845584, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 227, train_loss = 1.7773462794721127, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 228, train_loss = 1.7688298758585006, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 229, train_loss = 1.76043343055062, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 230, train_loss = 1.7521155651193112, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 231, train_loss = 1.7439907740335912, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 232, train_loss = 1.7358473849017173, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 233, train_loss = 1.727921796264127, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 234, train_loss = 1.7200833037495613, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 235, train_loss = 1.7123319159727544, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 236, train_loss = 1.7047063384670764, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 237, train_loss = 1.697091180831194, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 238, train_loss = 1.6896905067842454, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 239, train_loss = 1.6822717003524303, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 240, train_loss = 1.675019932212308, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 241, train_loss = 1.6678140435833484, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 242, train_loss = 1.6606897935271263, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 243, train_loss = 1.6537502855062485, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 244, train_loss = 1.6467502054292709, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 245, train_loss = 1.6399792295414954, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 246, train_loss = 1.6330948323011398, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 247, train_loss = 1.626557933865115, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 248, train_loss = 1.6198702256660908, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 249, train_loss = 1.6133315401384607, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 250, train_loss = 1.6069568073144183, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 251, train_loss = 1.6005578698823228, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 252, train_loss = 1.5943119389703497, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 253, train_loss = 1.588083378970623, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 254, train_loss = 1.5819371454417706, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 255, train_loss = 1.5758809013059363, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 256, train_loss = 1.5698490204522386, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 257, train_loss = 1.5639587007462978, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 258, train_loss = 1.5580047158291563, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 259, train_loss = 1.5522941537201405, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 260, train_loss = 1.546544740558602, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 261, train_loss = 1.5408876948058605, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 262, train_loss = 1.5352784395217896, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 263, train_loss = 1.5297298604855314, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 264, train_loss = 1.524205213994719, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 265, train_loss = 1.5188681123545393, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 266, train_loss = 1.5134745389223099, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 267, train_loss = 1.508125344873406, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 268, train_loss = 1.5029119240352884, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 269, train_loss = 1.4977739192545414, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 270, train_loss = 1.4925763793289661, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 271, train_loss = 1.4875484009971842, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 272, train_loss = 1.4825033321976662, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 273, train_loss = 1.477569411159493, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 274, train_loss = 1.4725701212882996, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 275, train_loss = 1.4678299874067307, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 276, train_loss = 1.462915811687708, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 277, train_loss = 1.4581888169050217, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 278, train_loss = 1.4534530168166384, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 279, train_loss = 1.4488095305860043, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 280, train_loss = 1.4441563884029165, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 281, train_loss = 1.4395816127071157, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 282, train_loss = 1.435056726098992, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 283, train_loss = 1.4305664090206847, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 284, train_loss = 1.4260853690793738, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 285, train_loss = 1.4216736318776384, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 286, train_loss = 1.417343651293777, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 287, train_loss = 1.4129776830086485, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 288, train_loss = 1.408701897948049, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 289, train_loss = 1.4045587094733492, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 290, train_loss = 1.4002893343567848, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 291, train_loss = 1.396147720515728, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 292, train_loss = 1.391972472309135, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 293, train_loss = 1.3879421366145834, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 294, train_loss = 1.3838487738976255, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 295, train_loss = 1.379904579371214, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 296, train_loss = 1.3758911589393392, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 297, train_loss = 1.3719772970071062, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 298, train_loss = 1.368137383251451, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 299, train_loss = 1.3642402589321136, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 300, train_loss = 1.3604892380535603, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 301, train_loss = 1.3566532818367705, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 302, train_loss = 1.352970009087585, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 303, train_loss = 1.3491399213671684, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 304, train_loss = 1.3455740312347189, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 305, train_loss = 1.341874004690908, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 306, train_loss = 1.3383069994160905, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 307, train_loss = 1.3346858968725428, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 308, train_loss = 1.331161922425963, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 309, train_loss = 1.3276748346397653, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 310, train_loss = 1.3241838192334399, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 311, train_loss = 1.3207099126884714, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 312, train_loss = 1.317335126339458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 313, train_loss = 1.3139036893844604, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 314, train_loss = 1.3105114238569513, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 315, train_loss = 1.307251077145338, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 316, train_loss = 1.3039154820144176, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 317, train_loss = 1.300605796277523, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 318, train_loss = 1.2974431961774826, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 319, train_loss = 1.2941899771103635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 320, train_loss = 1.2909864485263824, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 321, train_loss = 1.2878850487759337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 322, train_loss = 1.2846258481731638, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 323, train_loss = 1.2815926000475883, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 324, train_loss = 1.2785189859569073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 325, train_loss = 1.2754712862079032, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 326, train_loss = 1.2723957213456742, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 327, train_loss = 1.2694201382691972, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 328, train_loss = 1.266437218815554, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 329, train_loss = 1.2634966323967092, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 330, train_loss = 1.2605266409809701, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 331, train_loss = 1.2576741998200305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 332, train_loss = 1.2547019210760482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 333, train_loss = 1.25189645960927, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 334, train_loss = 1.2490157944266684, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 335, train_loss = 1.2462570890784264, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 336, train_loss = 1.2434223654563539, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 337, train_loss = 1.240702896087896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 338, train_loss = 1.2378637765650637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 339, train_loss = 1.235227931290865, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 340, train_loss = 1.2324332644348033, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 341, train_loss = 1.2297874838113785, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 342, train_loss = 1.227091660082806, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 343, train_loss = 1.224510457366705, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 344, train_loss = 1.2218457509879954, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 345, train_loss = 1.219225658744108, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 346, train_loss = 1.216680119454395, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 347, train_loss = 1.2141033236985095, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 348, train_loss = 1.2115481098298915, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 349, train_loss = 1.2090490919654258, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 350, train_loss = 1.2065167265827768, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 351, train_loss = 1.2040874809026718, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 352, train_loss = 1.201547096192371, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 353, train_loss = 1.1991090141236782, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 354, train_loss = 1.1967114570434205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 355, train_loss = 1.194271216809284, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 356, train_loss = 1.1918601803481579, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 357, train_loss = 1.18952016037656, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 358, train_loss = 1.1871655968134291, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 359, train_loss = 1.1848244977300055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 360, train_loss = 1.1825138181447983, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 361, train_loss = 1.1802119836211205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 362, train_loss = 1.1779098485712893, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 363, train_loss = 1.1756269969046116, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 364, train_loss = 1.1733633528347127, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 365, train_loss = 1.1711420975625515, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 366, train_loss = 1.1689160677487962, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 367, train_loss = 1.1667189014260657, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 368, train_loss = 1.1645260688965209, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 369, train_loss = 1.1623763267998584, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 370, train_loss = 1.1601917247171514, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 371, train_loss = 1.1580444537103176, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 372, train_loss = 1.1558977377717383, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 373, train_loss = 1.1538339592516422, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 374, train_loss = 1.1516680258209817, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 375, train_loss = 1.1496269119088538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 376, train_loss = 1.1475068554282188, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 377, train_loss = 1.145557461946737, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 378, train_loss = 1.1434359401464462, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 379, train_loss = 1.1414718801970594, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 380, train_loss = 1.139387006580364, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 381, train_loss = 1.1374479196965694, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 382, train_loss = 1.1354327946901321, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 383, train_loss = 1.1335231152479537, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 384, train_loss = 1.1315668411552906, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 385, train_loss = 1.1295227122609504, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 386, train_loss = 1.127688143402338, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 387, train_loss = 1.1257651771302335, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 388, train_loss = 1.1238162107765675, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 389, train_loss = 1.1219870808417909, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 390, train_loss = 1.1200298319454305, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 391, train_loss = 1.1182337912614457, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 392, train_loss = 1.1163474880158901, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 393, train_loss = 1.1145350709557533, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 394, train_loss = 1.1126211608643644, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 395, train_loss = 1.110856066166889, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 396, train_loss = 1.109043013304472, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 397, train_loss = 1.1072059559519403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 398, train_loss = 1.10547685372876, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 399, train_loss = 1.1036892794072628, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 400, train_loss = 1.1019226871430874, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 401, train_loss = 1.1001871774788015, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 402, train_loss = 1.0984086841344833, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 403, train_loss = 1.0966618247330189, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 404, train_loss = 1.0949363757972606, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 405, train_loss = 1.0931677159969695, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 406, train_loss = 1.0915831749443896, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 407, train_loss = 1.0898182652890682, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 408, train_loss = 1.0881808449630626, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 409, train_loss = 1.0864827421610244, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 410, train_loss = 1.0848561910097487, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 411, train_loss = 1.0832298559253104, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 412, train_loss = 1.081571505696047, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 413, train_loss = 1.0798923025722615, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 414, train_loss = 1.0783797726035118, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 415, train_loss = 1.0767611687188037, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 416, train_loss = 1.0751325425808318, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 417, train_loss = 1.0735391887719743, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 418, train_loss = 1.0720166191458702, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 419, train_loss = 1.0704535146360286, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 420, train_loss = 1.0688619489665143, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 421, train_loss = 1.0672968166763894, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 422, train_loss = 1.065803736448288, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 423, train_loss = 1.0642671535606496, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 424, train_loss = 1.0627761234645732, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 425, train_loss = 1.0612795439665206, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 426, train_loss = 1.0597388856112957, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 427, train_loss = 1.0582907609641552, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 428, train_loss = 1.0567340441048145, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 429, train_loss = 1.0553470912273042, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 430, train_loss = 1.0537950198049657, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 431, train_loss = 1.0523887028102763, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 432, train_loss = 1.0509551887516864, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 433, train_loss = 1.0494113278982695, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 434, train_loss = 1.048081743210787, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 435, train_loss = 1.0465918220579624, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 436, train_loss = 1.0451949623820838, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 437, train_loss = 1.0437822354433592, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 438, train_loss = 1.0424062448146287, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 439, train_loss = 1.0409239518048707, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 440, train_loss = 1.0395981880428735, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 441, train_loss = 1.0382273072900716, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 442, train_loss = 1.0368177915515844, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 443, train_loss = 1.0354831578733865, train_acc = 0.9980204937121565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 444, train_loss = 1.0341565248963889, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 445, train_loss = 1.0327314039168414, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 446, train_loss = 1.031433035939699, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 447, train_loss = 1.0301178023219109, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 448, train_loss = 1.0288036167621613, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 449, train_loss = 1.0274052023887634, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 450, train_loss = 1.0261071982386056, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 451, train_loss = 1.024892191082472, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 452, train_loss = 1.0235695702431258, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 453, train_loss = 1.0222433867456857, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 454, train_loss = 1.021010564028984, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 455, train_loss = 1.0196955924329814, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 456, train_loss = 1.018404302507406, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 457, train_loss = 1.0172117451729719, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 458, train_loss = 1.0159103013575077, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 459, train_loss = 1.0146792903542519, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 460, train_loss = 1.0134937850234564, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 461, train_loss = 1.012158884346718, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 462, train_loss = 1.010979096085066, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 463, train_loss = 1.0097424474952277, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 464, train_loss = 1.0085361897945404, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 465, train_loss = 1.0072649121284485, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 466, train_loss = 1.0061040818691254, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 467, train_loss = 1.0049135833978653, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 468, train_loss = 1.0037459755840246, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 469, train_loss = 1.002528636396164, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 470, train_loss = 1.0014011040329933, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 471, train_loss = 1.000182898103958, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 472, train_loss = 0.9990731415746268, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 473, train_loss = 0.9978248675761279, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 474, train_loss = 0.9967026623489801, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 475, train_loss = 0.9955623758432921, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 476, train_loss = 0.9943723777832929, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 477, train_loss = 0.9932496324181557, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 478, train_loss = 0.9920967978832778, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 479, train_loss = 0.9910316939058248, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 480, train_loss = 0.9898520968854427, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 481, train_loss = 0.9887804923055228, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 482, train_loss = 0.9876525724830572, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 483, train_loss = 0.986501889914507, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 484, train_loss = 0.9854818271996919, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 485, train_loss = 0.9843885153532028, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 486, train_loss = 0.9832527103426401, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 487, train_loss = 0.9821480835380498, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 488, train_loss = 0.9810957958397921, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 489, train_loss = 0.9799727934005205, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 490, train_loss = 0.9790071671304759, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 491, train_loss = 0.9778689009544905, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 492, train_loss = 0.9768403259513434, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 493, train_loss = 0.9758391554059926, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 494, train_loss = 0.9746755907835905, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 495, train_loss = 0.9737624898552895, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 496, train_loss = 0.9726525532605592, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 497, train_loss = 0.9716434230504092, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 498, train_loss = 0.9705760031938553, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 499, train_loss = 0.9695831388235092, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|████████████████████████████████████████████▎                         | 19/30 [2:09:50<1:15:20, 410.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "20th- epoch: 0, train_loss = 272.2020231485367, train_acc = 0.4832324173265021\n",
      "test Acc 0.5670391061452514:\n",
      "20th- epoch: 1, train_loss = 208.0800462961197, train_acc = 0.5628784350256172\n",
      "test Acc 0.5721601489757915:\n",
      "20th- epoch: 2, train_loss = 163.14752954244614, train_acc = 0.577433628318584\n",
      "test Acc 0.6121973929236499:\n",
      "20th- epoch: 3, train_loss = 136.3222255706787, train_acc = 0.6563809967396367\n",
      "test Acc 0.7141527001862198:\n",
      "20th- epoch: 4, train_loss = 117.1331917643547, train_acc = 0.7392873777363763\n",
      "test Acc 0.7774674115456238:\n",
      "20th- epoch: 5, train_loss = 102.22830992937088, train_acc = 0.7884257102934327\n",
      "test Acc 0.8161080074487895:\n",
      "20th- epoch: 6, train_loss = 89.9310836493969, train_acc = 0.810316721006055\n",
      "test Acc 0.8310055865921788:\n",
      "20th- epoch: 7, train_loss = 79.55787658691406, train_acc = 0.828365160689334\n",
      "test Acc 0.8393854748603352:\n",
      "20th- epoch: 8, train_loss = 70.73854777216911, train_acc = 0.8410572892408011\n",
      "test Acc 0.8561452513966481:\n",
      "20th- epoch: 9, train_loss = 63.20182949304581, train_acc = 0.8644620400558919\n",
      "test Acc 0.8729050279329609:\n",
      "20th- epoch: 10, train_loss = 56.762104868888855, train_acc = 0.8876339077782953\n",
      "test Acc 0.8961824953445066:\n",
      "20th- epoch: 11, train_loss = 51.25570969283581, train_acc = 0.9054494643688868\n",
      "test Acc 0.9120111731843575:\n",
      "20th- epoch: 12, train_loss = 46.51967296004295, train_acc = 0.921634839310666\n",
      "test Acc 0.9264432029795159:\n",
      "20th- epoch: 13, train_loss = 42.42339116334915, train_acc = 0.9371215649743828\n",
      "test Acc 0.936219739292365:\n",
      "20th- epoch: 14, train_loss = 38.866662353277206, train_acc = 0.9451560316721006\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 15, train_loss = 35.7733029127121, train_acc = 0.9489986027014439\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 16, train_loss = 33.086607210338116, train_acc = 0.9517931998136935\n",
      "test Acc 0.946927374301676:\n",
      "20th- epoch: 17, train_loss = 30.75724210590124, train_acc = 0.9540055891942245\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 18, train_loss = 28.73650076240301, train_acc = 0.9570330693991617\n",
      "test Acc 0.952513966480447:\n",
      "20th- epoch: 19, train_loss = 26.978208534419537, train_acc = 0.9601769911504425\n",
      "test Acc 0.9534450651769087:\n",
      "20th- epoch: 20, train_loss = 25.443710550665855, train_acc = 0.962156497438286\n",
      "test Acc 0.9557728119180633:\n",
      "20th- epoch: 21, train_loss = 24.097969938069582, train_acc = 0.9644853283651607\n",
      "test Acc 0.9567039106145251:\n",
      "20th- epoch: 22, train_loss = 22.91078868880868, train_acc = 0.9662319515603167\n",
      "test Acc 0.9590316573556797:\n",
      "20th- epoch: 23, train_loss = 21.857141867280006, train_acc = 0.9683278993945039\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 24, train_loss = 20.91620182991028, train_acc = 0.9697251979506288\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 25, train_loss = 20.07025968655944, train_acc = 0.9703074056823474\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 26, train_loss = 19.304898716509342, train_acc = 0.9710060549604099\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 27, train_loss = 18.607641749083996, train_acc = 0.9715882626921285\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 28, train_loss = 17.969047978520393, train_acc = 0.9725197950628784\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 29, train_loss = 17.38114870712161, train_acc = 0.9728691197019096\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 30, train_loss = 16.83710777387023, train_acc = 0.9734513274336283\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 31, train_loss = 16.33157742023468, train_acc = 0.9738006520726595\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 32, train_loss = 15.85997923836112, train_acc = 0.9739170936190032\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 33, train_loss = 15.418655350804329, train_acc = 0.9742664182580345\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 34, train_loss = 15.004421181976795, train_acc = 0.9747321844434094\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 35, train_loss = 14.614352226257324, train_acc = 0.9751979506287843\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 36, train_loss = 14.245824802666903, train_acc = 0.9756637168141593\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 37, train_loss = 13.897061917930841, train_acc = 0.975780158360503\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 38, train_loss = 13.566301103681326, train_acc = 0.9761294829995343\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 39, train_loss = 13.251405291259289, train_acc = 0.9764788076385654\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 40, train_loss = 12.951472289860249, train_acc = 0.9768281322775967\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 41, train_loss = 12.665107399225235, train_acc = 0.9772938984629715\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 42, train_loss = 12.39134244993329, train_acc = 0.9776432231020028\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 43, train_loss = 12.12910757213831, train_acc = 0.9785747554727526\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 44, train_loss = 11.87765995413065, train_acc = 0.9788076385654402\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 45, train_loss = 11.636356115341187, train_acc = 0.9798556124825337\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 46, train_loss = 11.404118116945028, train_acc = 0.9804378202142524\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 47, train_loss = 11.18062487989664, train_acc = 0.9809035863996274\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 48, train_loss = 10.964839950203896, train_acc = 0.9809035863996274\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 49, train_loss = 10.756524421274662, train_acc = 0.9810200279459711\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 50, train_loss = 10.55505170673132, train_acc = 0.9810200279459711\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 51, train_loss = 10.360165275633335, train_acc = 0.9812529110386586\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 52, train_loss = 10.171422118321061, train_acc = 0.9817186772240335\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 53, train_loss = 9.988383490592241, train_acc = 0.9820680018630648\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 54, train_loss = 9.811048211529851, train_acc = 0.9820680018630648\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 55, train_loss = 9.638906905427575, train_acc = 0.9823008849557522\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 56, train_loss = 9.471785437315702, train_acc = 0.9825337680484397\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 57, train_loss = 9.309190358966589, train_acc = 0.9826502095947834\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 58, train_loss = 9.151129806414247, train_acc = 0.9827666511411272\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 59, train_loss = 8.997395876795053, train_acc = 0.9828830926874709\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 60, train_loss = 8.8478173147887, train_acc = 0.9832324173265021\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 61, train_loss = 8.702213468030095, train_acc = 0.9835817419655333\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 62, train_loss = 8.560297602787614, train_acc = 0.983698183511877\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 63, train_loss = 8.421973068267107, train_acc = 0.9840475081509082\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 64, train_loss = 8.287168337032199, train_acc = 0.9842803912435957\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 65, train_loss = 8.155797243118286, train_acc = 0.9845132743362832\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 66, train_loss = 8.027636658400297, train_acc = 0.9847461574289706\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 67, train_loss = 7.902659190818667, train_acc = 0.9848625989753144\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 68, train_loss = 7.780667154118419, train_acc = 0.985444806707033\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 69, train_loss = 7.661691248416901, train_acc = 0.985444806707033\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 70, train_loss = 7.545349622145295, train_acc = 0.9855612482533768\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 71, train_loss = 7.431784940883517, train_acc = 0.9857941313460643\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 72, train_loss = 7.320668315514922, train_acc = 0.985910572892408\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 73, train_loss = 7.212163230404258, train_acc = 0.9860270144387517\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 74, train_loss = 7.106098361313343, train_acc = 0.9866092221704704\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 75, train_loss = 7.002383248880506, train_acc = 0.9867256637168141\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 76, train_loss = 6.900939399376512, train_acc = 0.9869585468095017\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 77, train_loss = 6.801654227077961, train_acc = 0.9869585468095017\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 78, train_loss = 6.704542266204953, train_acc = 0.9870749883558454\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 79, train_loss = 6.609549785032868, train_acc = 0.9871914299021891\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 80, train_loss = 6.516527460888028, train_acc = 0.9877736376339078\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 81, train_loss = 6.425471136346459, train_acc = 0.9878900791802515\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 82, train_loss = 6.336188342422247, train_acc = 0.9880065207265952\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 83, train_loss = 6.248804455623031, train_acc = 0.9880065207265952\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 84, train_loss = 6.163251109421253, train_acc = 0.9887051700046576\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 85, train_loss = 6.079419387504458, train_acc = 0.9889380530973452\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 86, train_loss = 5.997243421152234, train_acc = 0.9889380530973452\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 87, train_loss = 5.916842573322356, train_acc = 0.9890544946436889\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 88, train_loss = 5.837984963320196, train_acc = 0.9897531439217513\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 89, train_loss = 5.7606855714693666, train_acc = 0.9899860270144387\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 90, train_loss = 5.684880795888603, train_acc = 0.99033535165347\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 91, train_loss = 5.610699323005974, train_acc = 0.9904517931998137\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 92, train_loss = 5.537942562252283, train_acc = 0.9905682347461574\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 93, train_loss = 5.466520973481238, train_acc = 0.9905682347461574\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 94, train_loss = 5.396464886143804, train_acc = 0.9905682347461574\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 95, train_loss = 5.327786226756871, train_acc = 0.9904517931998137\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 96, train_loss = 5.260462148115039, train_acc = 0.99033535165347\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 97, train_loss = 5.1944664139300585, train_acc = 0.99033535165347\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 98, train_loss = 5.129599678330123, train_acc = 0.9906846762925011\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 99, train_loss = 5.066078822128475, train_acc = 0.990801117838845\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 100, train_loss = 5.003641191869974, train_acc = 0.9910340009315324\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 101, train_loss = 4.942429483868182, train_acc = 0.9911504424778761\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 102, train_loss = 4.882331124506891, train_acc = 0.9912668840242198\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 103, train_loss = 4.8233930952847, train_acc = 0.9914997671169073\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 104, train_loss = 4.765419059433043, train_acc = 0.9913833255705635\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 105, train_loss = 4.70857054181397, train_acc = 0.9913833255705635\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 106, train_loss = 4.652690597809851, train_acc = 0.9916162086632511\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 107, train_loss = 4.598018849268556, train_acc = 0.9917326502095948\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 108, train_loss = 4.544209471903741, train_acc = 0.9918490917559385\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 109, train_loss = 4.491510062478483, train_acc = 0.9918490917559385\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 110, train_loss = 4.43952118139714, train_acc = 0.9918490917559385\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 111, train_loss = 4.388511976227164, train_acc = 0.992081974848626\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 112, train_loss = 4.338467830792069, train_acc = 0.992081974848626\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 113, train_loss = 4.28916971385479, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 114, train_loss = 4.24090834800154, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 115, train_loss = 4.193424339406192, train_acc = 0.9924312994876572\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 116, train_loss = 4.146877306513488, train_acc = 0.9925477410340009\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 117, train_loss = 4.101196083240211, train_acc = 0.9928970656730322\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 118, train_loss = 4.056349009275436, train_acc = 0.9930135072193759\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 119, train_loss = 4.012339520268142, train_acc = 0.9931299487657196\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 120, train_loss = 3.9690326573327184, train_acc = 0.9932463903120633\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 121, train_loss = 3.926397838629782, train_acc = 0.9932463903120633\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 122, train_loss = 3.884666098281741, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 123, train_loss = 3.8434913996607065, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 124, train_loss = 3.8030158514156938, train_acc = 0.9934792734047508\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 125, train_loss = 3.7634278489276767, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 126, train_loss = 3.7243979377672076, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 127, train_loss = 3.6860637851059437, train_acc = 0.9937121564974383\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 128, train_loss = 3.6484024738892913, train_acc = 0.9937121564974383\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 129, train_loss = 3.611459457781166, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 130, train_loss = 3.575036756694317, train_acc = 0.9939450395901258\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 131, train_loss = 3.539354793727398, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 132, train_loss = 3.5042626573704183, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 133, train_loss = 3.4696873011998832, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 134, train_loss = 3.435838016215712, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 135, train_loss = 3.4024424669332802, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 136, train_loss = 3.3695827894844115, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 137, train_loss = 3.3373948712833226, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 138, train_loss = 3.305686552077532, train_acc = 0.9944108057755007\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 139, train_loss = 3.27439650753513, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 140, train_loss = 3.2436324045993388, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 141, train_loss = 3.2133951112627983, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 142, train_loss = 3.183582816272974, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 143, train_loss = 3.154415190219879, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 144, train_loss = 3.125728655140847, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 145, train_loss = 3.0974629428237677, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 146, train_loss = 3.0697892722673714, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 147, train_loss = 3.042297502979636, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 148, train_loss = 3.0153595842421055, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 149, train_loss = 2.988990899641067, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 150, train_loss = 2.962897663936019, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 151, train_loss = 2.937196325045079, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 152, train_loss = 2.911990745458752, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 153, train_loss = 2.887072928249836, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 154, train_loss = 2.862800022121519, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 155, train_loss = 2.8386572506278753, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 156, train_loss = 2.8150671650655568, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 157, train_loss = 2.7917295396327972, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 158, train_loss = 2.7687727767042816, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 159, train_loss = 2.7462144517339766, train_acc = 0.9952258965999069\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 160, train_loss = 2.7239328366704285, train_acc = 0.9952258965999069\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 161, train_loss = 2.7020937209017575, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 162, train_loss = 2.68059106124565, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 163, train_loss = 2.659254359547049, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 164, train_loss = 2.6383572653867304, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 165, train_loss = 2.617866780143231, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 166, train_loss = 2.597565008327365, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 167, train_loss = 2.5776629713363945, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 168, train_loss = 2.5579449315555394, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 169, train_loss = 2.5385784483514726, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 170, train_loss = 2.519366050604731, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 171, train_loss = 2.500453337561339, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 172, train_loss = 2.4818899570964277, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 173, train_loss = 2.463496417272836, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 174, train_loss = 2.445411443710327, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 175, train_loss = 2.4274909584783018, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 176, train_loss = 2.409977060975507, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 177, train_loss = 2.3925288270693272, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 178, train_loss = 2.3754143472760916, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 179, train_loss = 2.3585847162175924, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 180, train_loss = 2.3420118875801563, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 181, train_loss = 2.3256105568725616, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 182, train_loss = 2.3095305289607495, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 183, train_loss = 2.2936867501121014, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 184, train_loss = 2.2779987032990903, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 185, train_loss = 2.2625142212491482, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 186, train_loss = 2.247249974636361, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 187, train_loss = 2.2323032207787037, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 188, train_loss = 2.217493334086612, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 189, train_loss = 2.202920164912939, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 190, train_loss = 2.188553323270753, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 191, train_loss = 2.1743586224038154, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 192, train_loss = 2.1605074293911457, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 193, train_loss = 2.1466115303337574, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 194, train_loss = 2.133248994825408, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 195, train_loss = 2.119762983173132, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 196, train_loss = 2.1066460001748055, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 197, train_loss = 2.0936466839630157, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 198, train_loss = 2.0808248308021575, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 199, train_loss = 2.0680492743849754, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 200, train_loss = 2.055571789620444, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 201, train_loss = 2.0431618615984917, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 202, train_loss = 2.0309573721606284, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 203, train_loss = 2.0189599867444485, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 204, train_loss = 2.0070829179603606, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 205, train_loss = 1.9953487440943718, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 206, train_loss = 1.983736239373684, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 207, train_loss = 1.9723988634068519, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 208, train_loss = 1.9611093178391457, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 209, train_loss = 1.950016277609393, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 210, train_loss = 1.9390432473737746, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 211, train_loss = 1.9282474990468472, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 212, train_loss = 1.9175310358405113, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 213, train_loss = 1.9069951437413692, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 214, train_loss = 1.8965211857575923, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 215, train_loss = 1.8863657612819225, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 216, train_loss = 1.876138899475336, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 217, train_loss = 1.8661715562921017, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 218, train_loss = 1.8561719495337456, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 219, train_loss = 1.8463988353032619, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 220, train_loss = 1.8367333970963955, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 221, train_loss = 1.8271981899160892, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 222, train_loss = 1.8177876833360642, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 223, train_loss = 1.8084954309742898, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 224, train_loss = 1.7993612512946129, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 225, train_loss = 1.790324677946046, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 226, train_loss = 1.7814902178943157, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 227, train_loss = 1.7727022159378976, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 228, train_loss = 1.7639985717833042, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 229, train_loss = 1.755497460020706, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 230, train_loss = 1.7470923780929297, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 231, train_loss = 1.7387009505182505, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 232, train_loss = 1.730586605728604, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 233, train_loss = 1.722470230073668, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 234, train_loss = 1.7144868839532137, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 235, train_loss = 1.706641041324474, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 236, train_loss = 1.69889508059714, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 237, train_loss = 1.6912005426129326, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 238, train_loss = 1.683661020011641, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 239, train_loss = 1.676202941685915, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 240, train_loss = 1.668849709094502, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 241, train_loss = 1.6616163266589865, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 242, train_loss = 1.6544760899851099, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 243, train_loss = 1.647379081696272, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 244, train_loss = 1.6404487875988707, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 245, train_loss = 1.6335615329444408, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 246, train_loss = 1.6268110101809725, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 247, train_loss = 1.6201009576907381, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 248, train_loss = 1.6134350163629279, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 249, train_loss = 1.6069338904926553, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 250, train_loss = 1.6004942083964124, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 251, train_loss = 1.5941043557832018, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 252, train_loss = 1.587817101390101, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 253, train_loss = 1.5815762765705585, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 254, train_loss = 1.5754471383988857, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 255, train_loss = 1.5693634586641565, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 256, train_loss = 1.5633644411573187, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 257, train_loss = 1.5574670732021332, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 258, train_loss = 1.5516395444283262, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 259, train_loss = 1.5458485881099477, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 260, train_loss = 1.5401470822980627, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 261, train_loss = 1.534441038966179, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 262, train_loss = 1.528910013497807, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 263, train_loss = 1.5234186438610777, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 264, train_loss = 1.5179108418524265, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 265, train_loss = 1.5125488577177748, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 266, train_loss = 1.5071898015448824, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 267, train_loss = 1.501947303651832, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 268, train_loss = 1.4967215483775362, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 269, train_loss = 1.4915448538959026, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 270, train_loss = 1.486431110650301, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 271, train_loss = 1.4813560942420736, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 272, train_loss = 1.4763918766984716, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 273, train_loss = 1.471451859921217, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 274, train_loss = 1.4665842714020982, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 275, train_loss = 1.4616787880659103, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 276, train_loss = 1.4568799486150965, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 277, train_loss = 1.4521712908754125, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 278, train_loss = 1.4474556185305119, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 279, train_loss = 1.4428667649626732, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 280, train_loss = 1.4382472150027752, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 281, train_loss = 1.4336945427348837, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 282, train_loss = 1.4292163042118773, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 283, train_loss = 1.4246680414071307, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 284, train_loss = 1.4203624738147482, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 285, train_loss = 1.4159256307175383, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 286, train_loss = 1.4116225875914097, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 287, train_loss = 1.4073796967277303, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 288, train_loss = 1.4030925953993574, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 289, train_loss = 1.3989945128560066, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 290, train_loss = 1.3947183539858088, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 291, train_loss = 1.3906577453017235, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 292, train_loss = 1.3865402601659298, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 293, train_loss = 1.3825117163360119, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 294, train_loss = 1.378548347740434, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 295, train_loss = 1.3745729265501723, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 296, train_loss = 1.3706544563174248, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 297, train_loss = 1.3667704413528554, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 298, train_loss = 1.362906324386131, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 299, train_loss = 1.3590794056653976, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 300, train_loss = 1.3553616504068486, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 301, train_loss = 1.351542481512297, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 302, train_loss = 1.3478650252218358, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 303, train_loss = 1.3441744248266332, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 304, train_loss = 1.3405065375263803, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 305, train_loss = 1.33689484000206, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 306, train_loss = 1.3332982647116296, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 307, train_loss = 1.3297301505808719, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 308, train_loss = 1.3262223824858665, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 309, train_loss = 1.3227769583463669, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 310, train_loss = 1.3193096481263638, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 311, train_loss = 1.315892602025997, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 312, train_loss = 1.312483824789524, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 313, train_loss = 1.3091223289375193, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 314, train_loss = 1.305830965458881, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 315, train_loss = 1.3025130021269433, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 316, train_loss = 1.2991921938955784, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 317, train_loss = 1.2959743973915465, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 318, train_loss = 1.292773601890076, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 319, train_loss = 1.2896022002096288, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 320, train_loss = 1.28645920753479, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 321, train_loss = 1.2832564450800419, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 322, train_loss = 1.2801772356033325, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 323, train_loss = 1.2770695288782008, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 324, train_loss = 1.2740424486692064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 325, train_loss = 1.270978070795536, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 326, train_loss = 1.2680227234959602, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 327, train_loss = 1.2649820459191687, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 328, train_loss = 1.2620519126649015, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 329, train_loss = 1.259141334623564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 330, train_loss = 1.256255106360186, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 331, train_loss = 1.2532968309824355, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 332, train_loss = 1.2504681858117692, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 333, train_loss = 1.2476444740896113, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 334, train_loss = 1.2447952305083163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 335, train_loss = 1.2420124150812626, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 336, train_loss = 1.2392496739630587, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 337, train_loss = 1.23646055534482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 338, train_loss = 1.2338003441691399, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 339, train_loss = 1.2310536255245097, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 340, train_loss = 1.2283731599454768, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 341, train_loss = 1.2257051641936414, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 342, train_loss = 1.2230766068096273, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 343, train_loss = 1.2205207918887027, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 344, train_loss = 1.217843383550644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 345, train_loss = 1.2153014205396175, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 346, train_loss = 1.2127520988578908, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 347, train_loss = 1.2101934365928173, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 348, train_loss = 1.2076616622507572, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 349, train_loss = 1.2051611244678497, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 350, train_loss = 1.2027443908154964, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 351, train_loss = 1.2002460062503815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 352, train_loss = 1.1978084121947177, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 353, train_loss = 1.1953840243513696, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 354, train_loss = 1.1929806408588775, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 355, train_loss = 1.1905473793740384, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 356, train_loss = 1.1882572695612907, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 357, train_loss = 1.1858021020889282, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 358, train_loss = 1.1835607078974135, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 359, train_loss = 1.1812281273305416, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 360, train_loss = 1.1789098854060285, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 361, train_loss = 1.1766238125856034, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 362, train_loss = 1.1744429034297355, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 363, train_loss = 1.1721151632373221, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 364, train_loss = 1.1698664364521392, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 365, train_loss = 1.16770839196397, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 366, train_loss = 1.1654309022123925, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 367, train_loss = 1.1633331291377544, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 368, train_loss = 1.1610959780518897, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 369, train_loss = 1.158897377550602, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 370, train_loss = 1.156770685047377, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 371, train_loss = 1.1546664225752465, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 372, train_loss = 1.1526013973052613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 373, train_loss = 1.1504720225930214, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 374, train_loss = 1.1483765629236586, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 375, train_loss = 1.146332727104891, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 376, train_loss = 1.144272018224001, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 377, train_loss = 1.1422851358656771, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 378, train_loss = 1.1402773658628576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 379, train_loss = 1.138260914653074, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 380, train_loss = 1.136334830254782, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 381, train_loss = 1.1343123453552835, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 382, train_loss = 1.1323723669047467, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 383, train_loss = 1.1303764184121974, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 384, train_loss = 1.128462569147814, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 385, train_loss = 1.1265107803046703, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 386, train_loss = 1.1246071010828018, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 387, train_loss = 1.1227626551990397, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 388, train_loss = 1.1208074018359184, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 389, train_loss = 1.118996209173929, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 390, train_loss = 1.1171098574995995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 391, train_loss = 1.1152603005175479, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 392, train_loss = 1.1134048129315488, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 393, train_loss = 1.1116184082929976, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 394, train_loss = 1.1098258209531195, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 395, train_loss = 1.1079670625331346, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 396, train_loss = 1.1061727864143904, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 397, train_loss = 1.1043782271444798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 398, train_loss = 1.1026981858012732, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 399, train_loss = 1.100803048670059, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 400, train_loss = 1.0991398555634078, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 401, train_loss = 1.0972956828773022, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 402, train_loss = 1.0956625826656818, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 403, train_loss = 1.093921773135662, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 404, train_loss = 1.0922279035148676, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 405, train_loss = 1.0905790527758654, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 406, train_loss = 1.0888745412230492, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 407, train_loss = 1.0871573338808957, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 408, train_loss = 1.085568156093359, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 409, train_loss = 1.0838790821435396, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 410, train_loss = 1.0823372279701289, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 411, train_loss = 1.0806726031005383, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 412, train_loss = 1.0790359092352446, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 413, train_loss = 1.0774621789751109, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 414, train_loss = 1.0758341041801032, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 415, train_loss = 1.074215234577423, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 416, train_loss = 1.0726638796331827, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 417, train_loss = 1.0711065928044263, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 418, train_loss = 1.069568416714901, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 419, train_loss = 1.0679594799876213, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 420, train_loss = 1.0664562918245792, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 421, train_loss = 1.0649674584565219, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 422, train_loss = 1.0634600284101907, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 423, train_loss = 1.0618445947766304, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 424, train_loss = 1.0604630199668463, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 425, train_loss = 1.0588935290870722, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 426, train_loss = 1.0574117985961493, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 427, train_loss = 1.0559167489409447, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 428, train_loss = 1.0544567530450877, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 429, train_loss = 1.0528586556611117, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 430, train_loss = 1.0514697854814585, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 431, train_loss = 1.0499525132181589, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 432, train_loss = 1.0484579789044801, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 433, train_loss = 1.047130312770605, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 434, train_loss = 1.0455559616384562, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 435, train_loss = 1.0441149485704955, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 436, train_loss = 1.0427326696517412, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 437, train_loss = 1.0413149197993334, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 438, train_loss = 1.0399035153386649, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 439, train_loss = 1.038406167179346, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 440, train_loss = 1.0371313144860324, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 441, train_loss = 1.0356281200947706, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 442, train_loss = 1.0343706073763315, train_acc = 0.9980204937121565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 443, train_loss = 1.0330078788101673, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 444, train_loss = 1.0315551372768823, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 445, train_loss = 1.030279294907814, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 446, train_loss = 1.0288234502077103, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 447, train_loss = 1.0276141526701394, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 448, train_loss = 1.0262062698602676, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 449, train_loss = 1.0249304994940758, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 450, train_loss = 1.0236268987355288, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 451, train_loss = 1.0222910977900028, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 452, train_loss = 1.0210849990544375, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 453, train_loss = 1.0197464475932065, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 454, train_loss = 1.0184656443598215, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 455, train_loss = 1.0172491148114204, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 456, train_loss = 1.0159935653209686, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 457, train_loss = 1.014729779213667, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 458, train_loss = 1.0133849109115545, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 459, train_loss = 1.012218660354847, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 460, train_loss = 1.0109297223389149, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 461, train_loss = 1.009771895915037, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 462, train_loss = 1.0085817513463553, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 463, train_loss = 1.0072007688286249, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 464, train_loss = 1.0060794378223363, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 465, train_loss = 1.0047591254115105, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 466, train_loss = 1.0036521255970001, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 467, train_loss = 1.0024258519115392, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 468, train_loss = 1.0012160601618234, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 469, train_loss = 1.0000273821351584, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 470, train_loss = 0.9988436500134412, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 471, train_loss = 0.9976705511508044, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 472, train_loss = 0.9966202564537525, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 473, train_loss = 0.9954319484531879, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 474, train_loss = 0.9942896105349064, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 475, train_loss = 0.9931070196034852, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 476, train_loss = 0.992055956274271, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 477, train_loss = 0.9908132292330265, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 478, train_loss = 0.9897732871177141, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 479, train_loss = 0.9886305245163385, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 480, train_loss = 0.9875408982334193, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 481, train_loss = 0.986505006760126, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 482, train_loss = 0.9853494390845299, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 483, train_loss = 0.9842183676955756, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 484, train_loss = 0.9832641022803728, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 485, train_loss = 0.9820679699478205, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 486, train_loss = 0.9810608389379922, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 487, train_loss = 0.9798912654223386, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 488, train_loss = 0.9789094775915146, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 489, train_loss = 0.9778417150082532, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 490, train_loss = 0.9767411810753401, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 491, train_loss = 0.9757290320994798, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 492, train_loss = 0.9746693956258241, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 493, train_loss = 0.973667249083519, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 494, train_loss = 0.9726015739142895, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 495, train_loss = 0.9716300653817598, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 496, train_loss = 0.9706119435431901, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 497, train_loss = 0.9694952467980329, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 498, train_loss = 0.9685755794344004, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 499, train_loss = 0.9674869328737259, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████▋                       | 20/30 [2:16:40<1:08:27, 410.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "21th- epoch: 0, train_loss = 265.8747628927231, train_acc = 0.3693525850023288\n",
      "test Acc 0.4958100558659218:\n",
      "21th- epoch: 1, train_loss = 204.35671412944794, train_acc = 0.5485561248253377\n",
      "test Acc 0.5707635009310987:\n",
      "21th- epoch: 2, train_loss = 164.58977526426315, train_acc = 0.5703306939916162\n",
      "test Acc 0.5865921787709497:\n",
      "21th- epoch: 3, train_loss = 138.8213112950325, train_acc = 0.6350721937587331\n",
      "test Acc 0.712756052141527:\n",
      "21th- epoch: 4, train_loss = 120.58802992105484, train_acc = 0.7367256637168141\n",
      "test Acc 0.7704841713221602:\n",
      "21th- epoch: 5, train_loss = 105.64601072669029, train_acc = 0.7688635305076852\n",
      "test Acc 0.7993482309124768:\n",
      "21th- epoch: 6, train_loss = 92.85134467482567, train_acc = 0.7880763856544015\n",
      "test Acc 0.8100558659217877:\n",
      "21th- epoch: 7, train_loss = 82.19620037078857, train_acc = 0.8028644620400559\n",
      "test Acc 0.8342644320297952:\n",
      "21th- epoch: 8, train_loss = 73.29983854293823, train_acc = 0.8334885887284583\n",
      "test Acc 0.861266294227188:\n",
      "21th- epoch: 9, train_loss = 65.62542274594307, train_acc = 0.8641127154168607\n",
      "test Acc 0.8803538175046555:\n",
      "21th- epoch: 10, train_loss = 58.86830276250839, train_acc = 0.8893805309734514\n",
      "test Acc 0.8994413407821229:\n",
      "21th- epoch: 11, train_loss = 52.896454736590385, train_acc = 0.9098742431299488\n",
      "test Acc 0.9199255121042831:\n",
      "21th- epoch: 12, train_loss = 47.64877545833588, train_acc = 0.9275733581741965\n",
      "test Acc 0.9320297951582868:\n",
      "21th- epoch: 13, train_loss = 43.07972668111324, train_acc = 0.9410805775500699\n",
      "test Acc 0.9385474860335196:\n",
      "21th- epoch: 14, train_loss = 39.14561416208744, train_acc = 0.9456217978574756\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 15, train_loss = 35.78956490755081, train_acc = 0.9491150442477876\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 16, train_loss = 32.94232269376516, train_acc = 0.9513274336283186\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 17, train_loss = 30.527160853147507, train_acc = 0.9522589659990685\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 18, train_loss = 28.47085189819336, train_acc = 0.9545877969259432\n",
      "test Acc 0.9506517690875232:\n",
      "21th- epoch: 19, train_loss = 26.70991449803114, train_acc = 0.9568001863064741\n",
      "test Acc 0.9539106145251397:\n",
      "21th- epoch: 20, train_loss = 25.191171251237392, train_acc = 0.96040987424313\n",
      "test Acc 0.957635009310987:\n",
      "21th- epoch: 21, train_loss = 23.8712597489357, train_acc = 0.9642524452724732\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 22, train_loss = 22.71461820974946, train_acc = 0.9675128085700978\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 23, train_loss = 21.691458087414503, train_acc = 0.9680950163018165\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 24, train_loss = 20.779406037181616, train_acc = 0.969608756404285\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 25, train_loss = 19.9601741284132, train_acc = 0.9701909641360037\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 26, train_loss = 19.21929259598255, train_acc = 0.9708896134140661\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 27, train_loss = 18.544789221137762, train_acc = 0.9708896134140661\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 28, train_loss = 17.926483150571585, train_acc = 0.9712389380530974\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 29, train_loss = 17.356999158859253, train_acc = 0.971821145784816\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 30, train_loss = 16.829939533025026, train_acc = 0.9727526781555659\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 31, train_loss = 16.339803468436003, train_acc = 0.9731020027945971\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 32, train_loss = 15.882046218961477, train_acc = 0.9733348858872846\n",
      "test Acc 0.9669459962756052:\n",
      "21th- epoch: 33, train_loss = 15.452839892357588, train_acc = 0.974033535165347\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 34, train_loss = 15.048708606511354, train_acc = 0.9743828598043782\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 35, train_loss = 14.667752966284752, train_acc = 0.9748486259897532\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 36, train_loss = 14.307973511517048, train_acc = 0.9756637168141593\n",
      "test Acc 0.9674115456238361:\n",
      "21th- epoch: 37, train_loss = 13.96687988191843, train_acc = 0.9760130414531905\n",
      "test Acc 0.9674115456238361:\n",
      "21th- epoch: 38, train_loss = 13.642710570245981, train_acc = 0.9761294829995343\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 39, train_loss = 13.334173742681742, train_acc = 0.9764788076385654\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 40, train_loss = 13.039980482310057, train_acc = 0.9767116907312529\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 41, train_loss = 12.759033370763063, train_acc = 0.9770610153702841\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 42, train_loss = 12.490310803055763, train_acc = 0.9777596646483465\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 43, train_loss = 12.232375849038363, train_acc = 0.9778761061946902\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 44, train_loss = 11.984831783920527, train_acc = 0.9786911970190965\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 45, train_loss = 11.746910814195871, train_acc = 0.9791569632044713\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 46, train_loss = 11.517851073294878, train_acc = 0.9793898462971589\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 47, train_loss = 11.2972450889647, train_acc = 0.9796227293898463\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 48, train_loss = 11.08449573814869, train_acc = 0.9803213786679087\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 49, train_loss = 10.879193309694529, train_acc = 0.9805542617605962\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 50, train_loss = 10.680885031819344, train_acc = 0.9807871448532837\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 51, train_loss = 10.489123933017254, train_acc = 0.9811364694923148\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 52, train_loss = 10.303500533103943, train_acc = 0.9816022356776898\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 53, train_loss = 10.123581260442734, train_acc = 0.981951560316721\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 54, train_loss = 9.949078310281038, train_acc = 0.9821844434094085\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 55, train_loss = 9.779615856707096, train_acc = 0.9821844434094085\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 56, train_loss = 9.615042474120855, train_acc = 0.9823008849557522\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 57, train_loss = 9.455079792067409, train_acc = 0.9825337680484397\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 58, train_loss = 9.299468057230115, train_acc = 0.9826502095947834\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 59, train_loss = 9.148171799257398, train_acc = 0.9827666511411272\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 60, train_loss = 9.000900354236364, train_acc = 0.9829995342338146\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 61, train_loss = 8.857321936637163, train_acc = 0.9831159757801584\n",
      "test Acc 0.9767225325884544:\n",
      "21th- epoch: 62, train_loss = 8.717465566471219, train_acc = 0.9835817419655333\n",
      "test Acc 0.9767225325884544:\n",
      "21th- epoch: 63, train_loss = 8.581108605489135, train_acc = 0.9840475081509082\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 64, train_loss = 8.448082135990262, train_acc = 0.9843968327899395\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 65, train_loss = 8.318323567509651, train_acc = 0.9846297158826269\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 66, train_loss = 8.19177263788879, train_acc = 0.9846297158826269\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 67, train_loss = 8.068333799019456, train_acc = 0.9848625989753144\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 68, train_loss = 7.947903692722321, train_acc = 0.9850954820680019\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 69, train_loss = 7.830313261598349, train_acc = 0.9852119236143456\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 70, train_loss = 7.715392583981156, train_acc = 0.9853283651606893\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 71, train_loss = 7.6031988356262445, train_acc = 0.9853283651606893\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 72, train_loss = 7.493529973551631, train_acc = 0.985444806707033\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 73, train_loss = 7.3863965552300215, train_acc = 0.9855612482533768\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 74, train_loss = 7.281544564291835, train_acc = 0.9856776897997206\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 75, train_loss = 7.179041063413024, train_acc = 0.9857941313460643\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 76, train_loss = 7.078711699694395, train_acc = 0.9860270144387517\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 77, train_loss = 6.980513095855713, train_acc = 0.9861434559850955\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 78, train_loss = 6.884307758882642, train_acc = 0.9862598975314392\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 79, train_loss = 6.789980713278055, train_acc = 0.9866092221704704\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 80, train_loss = 6.697540381923318, train_acc = 0.9867256637168141\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 81, train_loss = 6.607005396857858, train_acc = 0.9874243129948765\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 82, train_loss = 6.518276039510965, train_acc = 0.9875407545412203\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 83, train_loss = 6.43126461096108, train_acc = 0.9880065207265952\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 84, train_loss = 6.345814349129796, train_acc = 0.9883558453656265\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 85, train_loss = 6.262106725946069, train_acc = 0.9884722869119702\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 86, train_loss = 6.179946845397353, train_acc = 0.9887051700046576\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 87, train_loss = 6.099417125806212, train_acc = 0.9891709361900326\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 88, train_loss = 6.0201534032821655, train_acc = 0.9891709361900326\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 89, train_loss = 5.942501302808523, train_acc = 0.9892873777363763\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 90, train_loss = 5.866171041503549, train_acc = 0.9892873777363763\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 91, train_loss = 5.791259618476033, train_acc = 0.9891709361900326\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 92, train_loss = 5.717736402526498, train_acc = 0.9892873777363763\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 93, train_loss = 5.645528424531221, train_acc = 0.9896367023754076\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 94, train_loss = 5.574586117640138, train_acc = 0.9897531439217513\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 95, train_loss = 5.504882236942649, train_acc = 0.9897531439217513\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 96, train_loss = 5.436333496123552, train_acc = 0.989869585468095\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 97, train_loss = 5.369072558358312, train_acc = 0.9902189101071263\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 98, train_loss = 5.302936842665076, train_acc = 0.9904517931998137\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 99, train_loss = 5.237913116812706, train_acc = 0.9906846762925011\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 100, train_loss = 5.174085828475654, train_acc = 0.990801117838845\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 101, train_loss = 5.111247423104942, train_acc = 0.9909175593851887\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 102, train_loss = 5.049583127722144, train_acc = 0.9909175593851887\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 103, train_loss = 4.988894336856902, train_acc = 0.9910340009315324\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 104, train_loss = 4.929112266749144, train_acc = 0.9910340009315324\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 105, train_loss = 4.870428535155952, train_acc = 0.9911504424778761\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 106, train_loss = 4.812628290615976, train_acc = 0.9911504424778761\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 107, train_loss = 4.755789044313133, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 108, train_loss = 4.69997990783304, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 109, train_loss = 4.645108201541007, train_acc = 0.9916162086632511\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 110, train_loss = 4.59098793938756, train_acc = 0.992081974848626\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 111, train_loss = 4.537923715077341, train_acc = 0.9923148579413135\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 112, train_loss = 4.485497635789216, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 113, train_loss = 4.433881779201329, train_acc = 0.9924312994876572\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 114, train_loss = 4.383414757438004, train_acc = 0.9925477410340009\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 115, train_loss = 4.3335885759443045, train_acc = 0.9926641825803446\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 116, train_loss = 4.284783735871315, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 117, train_loss = 4.236613965593278, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 118, train_loss = 4.189368463121355, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 119, train_loss = 4.142894223332405, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 120, train_loss = 4.097158784978092, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 121, train_loss = 4.052227825857699, train_acc = 0.9928970656730322\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 122, train_loss = 4.007972244173288, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 123, train_loss = 3.9645392457023263, train_acc = 0.9931299487657196\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 124, train_loss = 3.9215976987034082, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 125, train_loss = 3.8797583440318704, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 126, train_loss = 3.838276513852179, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 127, train_loss = 3.7976530883461237, train_acc = 0.9935957149510946\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 128, train_loss = 3.7577077113091946, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 129, train_loss = 3.7184390304610133, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 130, train_loss = 3.6798175796866417, train_acc = 0.9939450395901258\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 131, train_loss = 3.641773466952145, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 132, train_loss = 3.604460776783526, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 133, train_loss = 3.567718011327088, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 134, train_loss = 3.531536590307951, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 135, train_loss = 3.496009328402579, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 136, train_loss = 3.461071810685098, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 137, train_loss = 3.426701309159398, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 138, train_loss = 3.392938588745892, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 139, train_loss = 3.3596899462863803, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 140, train_loss = 3.326982452534139, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 141, train_loss = 3.2947360454127192, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 142, train_loss = 3.263212147168815, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 143, train_loss = 3.2319886814802885, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 144, train_loss = 3.2012787321582437, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 145, train_loss = 3.1708896374329925, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 146, train_loss = 3.141036307439208, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 147, train_loss = 3.1116629582829773, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 148, train_loss = 3.0827725934796035, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 149, train_loss = 3.0540956780314445, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 150, train_loss = 3.026221625506878, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 151, train_loss = 2.9988489006645977, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 152, train_loss = 2.9717405415140092, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 153, train_loss = 2.9452931340783834, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 154, train_loss = 2.9190396410413086, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 155, train_loss = 2.893262051511556, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 156, train_loss = 2.867759771179408, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 157, train_loss = 2.842811686452478, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 158, train_loss = 2.818145591765642, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 159, train_loss = 2.794087538961321, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 160, train_loss = 2.770166495349258, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 161, train_loss = 2.746630343142897, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 162, train_loss = 2.7233314546756446, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 163, train_loss = 2.700548738706857, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 164, train_loss = 2.677986301481724, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 165, train_loss = 2.65598974423483, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 166, train_loss = 2.6341756298206747, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 167, train_loss = 2.612873896956444, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 168, train_loss = 2.5915995980612934, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 169, train_loss = 2.5707602333277464, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 170, train_loss = 2.549935831222683, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 171, train_loss = 2.529601166024804, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 172, train_loss = 2.5096450322307646, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 173, train_loss = 2.4903201260603964, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 174, train_loss = 2.4709239304065704, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 175, train_loss = 2.4520164779387414, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 176, train_loss = 2.433403348084539, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 177, train_loss = 2.4151004566811025, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 178, train_loss = 2.3970634252764285, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 179, train_loss = 2.3791101067326963, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 180, train_loss = 2.3617375171743333, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 181, train_loss = 2.3443823135457933, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 182, train_loss = 2.3275374709628522, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 183, train_loss = 2.310701528098434, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 184, train_loss = 2.2942233593203127, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 185, train_loss = 2.2780915633775294, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 186, train_loss = 2.262132635805756, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 187, train_loss = 2.246350215282291, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 188, train_loss = 2.2308607227168977, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 189, train_loss = 2.2155770496465266, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 190, train_loss = 2.2005519554950297, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 191, train_loss = 2.1857978492043912, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 192, train_loss = 2.1712872311472893, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 193, train_loss = 2.157014606986195, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 194, train_loss = 2.1428086683154106, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 195, train_loss = 2.1288656988181174, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 196, train_loss = 2.11519318446517, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 197, train_loss = 2.1016580858267844, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 198, train_loss = 2.0884163044393063, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 199, train_loss = 2.0753905288875103, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 200, train_loss = 2.062561595113948, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 201, train_loss = 2.0498920145910233, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 202, train_loss = 2.037436639191583, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 203, train_loss = 2.0250959906261414, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 204, train_loss = 2.0131134130060673, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 205, train_loss = 2.0010399643797427, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 206, train_loss = 1.9894116024952382, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 207, train_loss = 1.9777954369783401, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 208, train_loss = 1.966357160359621, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 209, train_loss = 1.9550884738564491, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 210, train_loss = 1.9439937323331833, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 211, train_loss = 1.9331502739805728, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 212, train_loss = 1.9223432454746217, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 213, train_loss = 1.9118125264067203, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 214, train_loss = 1.9012747097294778, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 215, train_loss = 1.8909535992424935, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 216, train_loss = 1.8808073464315385, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 217, train_loss = 1.8706941939890385, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 218, train_loss = 1.8607312317471951, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 219, train_loss = 1.851022941293195, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 220, train_loss = 1.8412937633693218, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 221, train_loss = 1.8318293876945972, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 222, train_loss = 1.8225073653738946, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 223, train_loss = 1.8130858142394572, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 224, train_loss = 1.804122808156535, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 225, train_loss = 1.7950561966281384, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 226, train_loss = 1.786186798242852, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 227, train_loss = 1.7774559471290559, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 228, train_loss = 1.7687203213572502, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 229, train_loss = 1.7604116525035352, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 230, train_loss = 1.7519120152574033, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 231, train_loss = 1.7437815729063004, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 232, train_loss = 1.735606086673215, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 233, train_loss = 1.7276446993928403, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 234, train_loss = 1.7196463693398982, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 235, train_loss = 1.7119097660761327, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 236, train_loss = 1.704166492447257, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 237, train_loss = 1.6965441696811467, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 238, train_loss = 1.6890616975724697, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 239, train_loss = 1.6816349625587463, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 240, train_loss = 1.6743508782237768, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 241, train_loss = 1.667158494470641, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 242, train_loss = 1.6599810284096748, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 243, train_loss = 1.6529559835325927, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 244, train_loss = 1.6460640609730035, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 245, train_loss = 1.6392440404742956, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 246, train_loss = 1.6324561797082424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 247, train_loss = 1.6258020214736462, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 248, train_loss = 1.6191550691146404, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 249, train_loss = 1.612730786204338, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 250, train_loss = 1.6061618376988918, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 251, train_loss = 1.5998333643656224, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 252, train_loss = 1.593471422791481, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 253, train_loss = 1.5873352389317006, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 254, train_loss = 1.5812010404188186, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 255, train_loss = 1.5751410487573594, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 256, train_loss = 1.5690681997220963, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 257, train_loss = 1.563223077566363, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 258, train_loss = 1.557393342256546, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 259, train_loss = 1.5515317544341087, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 260, train_loss = 1.5458123398711905, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 261, train_loss = 1.5401110971579328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 262, train_loss = 1.5345303267240524, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 263, train_loss = 1.5290807845303789, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 264, train_loss = 1.5235607661306858, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 265, train_loss = 1.518117181956768, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 266, train_loss = 1.5128890374908224, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 267, train_loss = 1.5074526742100716, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 268, train_loss = 1.5022368021309376, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 269, train_loss = 1.497200238169171, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 270, train_loss = 1.4919247813522816, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 271, train_loss = 1.4868521131575108, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 272, train_loss = 1.4818746024975553, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 273, train_loss = 1.4768972644815221, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 274, train_loss = 1.47202819341328, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 275, train_loss = 1.4671433480689302, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 276, train_loss = 1.462324028252624, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 277, train_loss = 1.4575742644956335, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 278, train_loss = 1.4528530947864056, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 279, train_loss = 1.4482324806740507, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 280, train_loss = 1.4435932263731956, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 281, train_loss = 1.4390373677015305, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 282, train_loss = 1.4344850182533264, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 283, train_loss = 1.4300523350248113, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 284, train_loss = 1.4257075674831867, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 285, train_loss = 1.421281211078167, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 286, train_loss = 1.4168684569885954, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 287, train_loss = 1.4125709956279024, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 288, train_loss = 1.4083672600099817, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 289, train_loss = 1.4041725049028173, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 290, train_loss = 1.3999583324184641, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 291, train_loss = 1.3958172624697909, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 292, train_loss = 1.3917250806698576, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 293, train_loss = 1.3876922652125359, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 294, train_loss = 1.3837158357491717, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 295, train_loss = 1.37966313585639, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 296, train_loss = 1.375863928347826, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 297, train_loss = 1.3719372091582045, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 298, train_loss = 1.3679419122636318, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 299, train_loss = 1.3641800632467493, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 300, train_loss = 1.3604916023323312, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 301, train_loss = 1.3567165086278692, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 302, train_loss = 1.352879274636507, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 303, train_loss = 1.3492381870746613, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 304, train_loss = 1.3455876099178568, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 305, train_loss = 1.3420143550029024, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 306, train_loss = 1.3384558284888044, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 307, train_loss = 1.3347748393425718, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 308, train_loss = 1.3312460394809023, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 309, train_loss = 1.327715834020637, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 310, train_loss = 1.3243041969835758, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 311, train_loss = 1.3208300223341212, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 312, train_loss = 1.3174734277417883, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 313, train_loss = 1.314047715277411, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 314, train_loss = 1.31077177322004, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 315, train_loss = 1.307402970851399, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 316, train_loss = 1.3041076051304117, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 317, train_loss = 1.3010015612235293, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 318, train_loss = 1.297655084519647, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 319, train_loss = 1.2944221583893523, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 320, train_loss = 1.2912521933903918, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 321, train_loss = 1.2880854370305315, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 322, train_loss = 1.2849975948920473, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 323, train_loss = 1.2819105945527554, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 324, train_loss = 1.278810415416956, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 325, train_loss = 1.2757578691234812, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 326, train_loss = 1.2727520925691351, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 327, train_loss = 1.26970699056983, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 328, train_loss = 1.2668096907436848, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 329, train_loss = 1.263821548433043, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 330, train_loss = 1.2608981827506796, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 331, train_loss = 1.2580388858914375, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 332, train_loss = 1.255097092478536, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 333, train_loss = 1.2522728008916602, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 334, train_loss = 1.2495399987092242, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 335, train_loss = 1.2466575292637572, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 336, train_loss = 1.2438404560089111, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 337, train_loss = 1.2411189265549183, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 338, train_loss = 1.238406973599922, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 339, train_loss = 1.235662939667236, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 340, train_loss = 1.2329782098531723, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 341, train_loss = 1.2302659775014035, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 342, train_loss = 1.2276943127508275, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 343, train_loss = 1.2249958614702336, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 344, train_loss = 1.2224030022625811, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 345, train_loss = 1.219863135367632, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 346, train_loss = 1.217250915884506, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 347, train_loss = 1.2146467504207976, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 348, train_loss = 1.2121322639286518, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 349, train_loss = 1.2096319149131887, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 350, train_loss = 1.207147054374218, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 351, train_loss = 1.2046373200719245, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 352, train_loss = 1.2022321310942061, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 353, train_loss = 1.1997867015306838, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 354, train_loss = 1.197352944582235, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 355, train_loss = 1.1949016166036017, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 356, train_loss = 1.192535964131821, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 357, train_loss = 1.1902404961292632, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 358, train_loss = 1.1878053421969526, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 359, train_loss = 1.185454335063696, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 360, train_loss = 1.1832140634651296, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 361, train_loss = 1.1808642372488976, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 362, train_loss = 1.178580106527079, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 363, train_loss = 1.17628713947488, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 364, train_loss = 1.1741471526329406, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 365, train_loss = 1.1718558085267432, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 366, train_loss = 1.1697259470820427, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 367, train_loss = 1.1673418159480207, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 368, train_loss = 1.1652510613203049, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 369, train_loss = 1.1630470231175423, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 370, train_loss = 1.1609301405842416, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 371, train_loss = 1.1587501901085488, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 372, train_loss = 1.1567121322150342, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 373, train_loss = 1.1544919510488398, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 374, train_loss = 1.1524892188608646, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 375, train_loss = 1.1503302578930743, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 376, train_loss = 1.1482616551220417, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 377, train_loss = 1.1462451207335107, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 378, train_loss = 1.1442342375521548, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 379, train_loss = 1.1421261057257652, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 380, train_loss = 1.1401952442829497, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 381, train_loss = 1.1381862771813758, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 382, train_loss = 1.1362368811969645, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 383, train_loss = 1.1342912204563618, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 384, train_loss = 1.1322787056560628, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 385, train_loss = 1.1302882966701873, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 386, train_loss = 1.1284458587761037, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 387, train_loss = 1.1265481213922612, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 388, train_loss = 1.1246195584535599, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 389, train_loss = 1.1227022732491605, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 390, train_loss = 1.1209053210914135, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 391, train_loss = 1.1190019498462789, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 392, train_loss = 1.1172075768117793, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 393, train_loss = 1.1153762675821781, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 394, train_loss = 1.1134740362758748, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 395, train_loss = 1.1116892285645008, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 396, train_loss = 1.1098629261250608, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 397, train_loss = 1.1081056247348897, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 398, train_loss = 1.1063239599461667, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 399, train_loss = 1.1046047669951804, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 400, train_loss = 1.102801253378857, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 401, train_loss = 1.1011218813364394, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 402, train_loss = 1.0992821591789834, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 403, train_loss = 1.097650287032593, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 404, train_loss = 1.0959221075172536, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 405, train_loss = 1.0942379335756414, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 406, train_loss = 1.092520332604181, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 407, train_loss = 1.0908272142405622, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 408, train_loss = 1.0892182464594953, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 409, train_loss = 1.087525013834238, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 410, train_loss = 1.0859413792495616, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 411, train_loss = 1.0842493076925166, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 412, train_loss = 1.0826232979889028, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 413, train_loss = 1.0809492357075214, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 414, train_loss = 1.0794451248948462, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 415, train_loss = 1.0778208188712597, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 416, train_loss = 1.07626723498106, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 417, train_loss = 1.0746373844449408, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 418, train_loss = 1.073042509437073, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 419, train_loss = 1.0715047133271582, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 420, train_loss = 1.0699613615870476, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 421, train_loss = 1.0684755754773505, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 422, train_loss = 1.0669474403257482, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 423, train_loss = 1.0653929549152963, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 424, train_loss = 1.0638977934722789, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 425, train_loss = 1.0623819728498347, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 426, train_loss = 1.0608414734597318, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 427, train_loss = 1.0594347715377808, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 428, train_loss = 1.0578871841426007, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 429, train_loss = 1.056483582884539, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 430, train_loss = 1.0550353080034256, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 431, train_loss = 1.0535036896471865, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 432, train_loss = 1.052167847752571, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 433, train_loss = 1.0506898474995978, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 434, train_loss = 1.0491913084988482, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 435, train_loss = 1.0477756622130983, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 436, train_loss = 1.0464736160938628, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 437, train_loss = 1.0450030378997326, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 438, train_loss = 1.0435988729004748, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 439, train_loss = 1.0421046378905885, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 440, train_loss = 1.0408788385684602, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 441, train_loss = 1.0394849454169162, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 442, train_loss = 1.0381115364725702, train_acc = 0.9980204937121565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 443, train_loss = 1.0367715221946128, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 444, train_loss = 1.0353709608316422, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 445, train_loss = 1.0339778698980808, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 446, train_loss = 1.0326711882953532, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 447, train_loss = 1.0314700876479037, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 448, train_loss = 1.0300944857299328, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 449, train_loss = 1.0287908812169917, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 450, train_loss = 1.027487215877045, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 451, train_loss = 1.0260584143106826, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 452, train_loss = 1.0249131533200853, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 453, train_loss = 1.0235514690284617, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 454, train_loss = 1.0223034148511942, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 455, train_loss = 1.0209464579820633, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 456, train_loss = 1.019748892635107, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 457, train_loss = 1.0183831167814787, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 458, train_loss = 1.0172642208635807, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 459, train_loss = 1.0159352608025074, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 460, train_loss = 1.0147554650902748, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 461, train_loss = 1.0135500791075174, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 462, train_loss = 1.0123031412658747, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 463, train_loss = 1.0110698603093624, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 464, train_loss = 1.009823622793192, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 465, train_loss = 1.008660715073347, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 466, train_loss = 1.0074250623583794, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 467, train_loss = 1.006271847843891, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 468, train_loss = 1.0051612928509712, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 469, train_loss = 1.0039018864335958, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 470, train_loss = 1.0027392183837947, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 471, train_loss = 1.0016659597458784, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 472, train_loss = 1.0004054456949234, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 473, train_loss = 0.9992886111140251, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 474, train_loss = 0.9980917634966318, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 475, train_loss = 0.9970047486422118, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 476, train_loss = 0.9958886106905993, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 477, train_loss = 0.9946869263949338, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 478, train_loss = 0.9936240998504218, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 479, train_loss = 0.9925035151245538, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 480, train_loss = 0.9914079569280148, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 481, train_loss = 0.9902467715146486, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 482, train_loss = 0.989175913244253, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 483, train_loss = 0.9880327992141247, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 484, train_loss = 0.9870085877773818, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 485, train_loss = 0.9859028247592505, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 486, train_loss = 0.9847586241958197, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 487, train_loss = 0.9838061729969922, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 488, train_loss = 0.9826308166084345, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 489, train_loss = 0.9816655392351095, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 490, train_loss = 0.9805755838751793, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 491, train_loss = 0.979514447360998, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 492, train_loss = 0.9784744294884149, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 493, train_loss = 0.9774309918284416, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 494, train_loss = 0.9763608438370284, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 495, train_loss = 0.9753506270644721, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 496, train_loss = 0.9743995653989259, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 497, train_loss = 0.9732155129313469, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 498, train_loss = 0.9723004499974195, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 499, train_loss = 0.9713034021260682, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████                     | 21/30 [2:23:35<1:01:47, 411.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "22th- epoch: 0, train_loss = 272.6870068311691, train_acc = 0.4556357708430368\n",
      "test Acc 0.5526070763500931:\n",
      "22th- epoch: 1, train_loss = 210.84733831882477, train_acc = 0.554145319049837\n",
      "test Acc 0.5633147113594041:\n",
      "22th- epoch: 2, train_loss = 164.3911343216896, train_acc = 0.5645086166744294\n",
      "test Acc 0.5684357541899442:\n",
      "22th- epoch: 3, train_loss = 138.65887987613678, train_acc = 0.6273870517000466\n",
      "test Acc 0.7122905027932961:\n",
      "22th- epoch: 4, train_loss = 120.69465756416321, train_acc = 0.7376571960875641\n",
      "test Acc 0.7723463687150838:\n",
      "22th- epoch: 5, train_loss = 105.76848840713501, train_acc = 0.7679319981369352\n",
      "test Acc 0.792830540037244:\n",
      "22th- epoch: 6, train_loss = 93.0406848192215, train_acc = 0.7813227759664648\n",
      "test Acc 0.8081936685288641:\n",
      "22th- epoch: 7, train_loss = 82.4723998606205, train_acc = 0.8048439683278994\n",
      "test Acc 0.8282122905027933:\n",
      "22th- epoch: 8, train_loss = 73.61422032117844, train_acc = 0.8275500698649279\n",
      "test Acc 0.8552141527001862:\n",
      "22th- epoch: 9, train_loss = 65.9394371509552, train_acc = 0.8628318584070797\n",
      "test Acc 0.88268156424581:\n",
      "22th- epoch: 10, train_loss = 59.16290745139122, train_acc = 0.8879832324173265\n",
      "test Acc 0.9050279329608939:\n",
      "22th- epoch: 11, train_loss = 53.199873208999634, train_acc = 0.908011178388449\n",
      "test Acc 0.9180633147113594:\n",
      "22th- epoch: 12, train_loss = 48.02568732202053, train_acc = 0.928272007452259\n",
      "test Acc 0.9366852886405959:\n",
      "22th- epoch: 13, train_loss = 43.58074548840523, train_acc = 0.9409641360037261\n",
      "test Acc 0.9394785847299814:\n",
      "22th- epoch: 14, train_loss = 39.77018181979656, train_acc = 0.9444573823940382\n",
      "test Acc 0.9445996275605214:\n",
      "22th- epoch: 15, train_loss = 36.50248660892248, train_acc = 0.9489986027014439\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 16, train_loss = 33.697647497057915, train_acc = 0.9512109920819748\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 17, train_loss = 31.284766770899296, train_acc = 0.9538891476478808\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 18, train_loss = 29.203666172921658, train_acc = 0.9554028877503493\n",
      "test Acc 0.952048417132216:\n",
      "22th- epoch: 19, train_loss = 27.402001284062862, train_acc = 0.9580810433162552\n",
      "test Acc 0.9553072625698324:\n",
      "22th- epoch: 20, train_loss = 25.834558367729187, train_acc = 0.9613414066138798\n",
      "test Acc 0.957169459962756:\n",
      "22th- epoch: 21, train_loss = 24.46330263465643, train_acc = 0.9637866790870983\n",
      "test Acc 0.9585661080074488:\n",
      "22th- epoch: 22, train_loss = 23.25610726699233, train_acc = 0.9657661853749417\n",
      "test Acc 0.962756052141527:\n",
      "22th- epoch: 23, train_loss = 22.187315966933966, train_acc = 0.9671634839310667\n",
      "test Acc 0.9636871508379888:\n",
      "22th- epoch: 24, train_loss = 21.23328422382474, train_acc = 0.9691429902189101\n",
      "test Acc 0.9636871508379888:\n",
      "22th- epoch: 25, train_loss = 20.375813242048025, train_acc = 0.9697251979506288\n",
      "test Acc 0.9632216014897579:\n",
      "22th- epoch: 26, train_loss = 19.600004956126213, train_acc = 0.97007452258966\n",
      "test Acc 0.9632216014897579:\n",
      "22th- epoch: 27, train_loss = 18.893517930060625, train_acc = 0.970540288775035\n",
      "test Acc 0.9636871508379888:\n",
      "22th- epoch: 28, train_loss = 18.246826983988285, train_acc = 0.9707731718677224\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 29, train_loss = 17.651933651417494, train_acc = 0.971821145784816\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 30, train_loss = 17.100947685539722, train_acc = 0.9724033535165347\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 31, train_loss = 16.58912568166852, train_acc = 0.9732184443409408\n",
      "test Acc 0.9646182495344506:\n",
      "22th- epoch: 32, train_loss = 16.112051378935575, train_acc = 0.9741499767116907\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 33, train_loss = 15.666464142501354, train_acc = 0.9746157428970657\n",
      "test Acc 0.9646182495344506:\n",
      "22th- epoch: 34, train_loss = 15.24833021685481, train_acc = 0.9747321844434094\n",
      "test Acc 0.9646182495344506:\n",
      "22th- epoch: 35, train_loss = 14.854469858109951, train_acc = 0.9748486259897532\n",
      "test Acc 0.9655493482309124:\n",
      "22th- epoch: 36, train_loss = 14.481825225055218, train_acc = 0.9751979506287843\n",
      "test Acc 0.9664804469273743:\n",
      "22th- epoch: 37, train_loss = 14.128395035862923, train_acc = 0.9754308337214718\n",
      "test Acc 0.9669459962756052:\n",
      "22th- epoch: 38, train_loss = 13.792749874293804, train_acc = 0.9756637168141593\n",
      "test Acc 0.9683426443202979:\n",
      "22th- epoch: 39, train_loss = 13.47337806969881, train_acc = 0.975780158360503\n",
      "test Acc 0.9683426443202979:\n",
      "22th- epoch: 40, train_loss = 13.16873598471284, train_acc = 0.9760130414531905\n",
      "test Acc 0.9683426443202979:\n",
      "22th- epoch: 41, train_loss = 12.87779438123107, train_acc = 0.9764788076385654\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 42, train_loss = 12.599682867527008, train_acc = 0.9772938984629715\n",
      "test Acc 0.9702048417132216:\n",
      "22th- epoch: 43, train_loss = 12.333205316215754, train_acc = 0.9774103400093154\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 44, train_loss = 12.077351678162813, train_acc = 0.9781089892873778\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 45, train_loss = 11.83152962103486, train_acc = 0.9785747554727526\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 46, train_loss = 11.594849212095141, train_acc = 0.9788076385654402\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 47, train_loss = 11.366583434864879, train_acc = 0.9792734047508151\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 48, train_loss = 11.146108532324433, train_acc = 0.9791569632044713\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 49, train_loss = 10.932989183813334, train_acc = 0.9800884955752213\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 50, train_loss = 10.726823629811406, train_acc = 0.980204937121565\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 51, train_loss = 10.52724458090961, train_acc = 0.9803213786679087\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 52, train_loss = 10.334137691184878, train_acc = 0.9809035863996274\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 53, train_loss = 10.146881803870201, train_acc = 0.9811364694923148\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 54, train_loss = 9.965183153748512, train_acc = 0.9813693525850024\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 55, train_loss = 9.788829002529383, train_acc = 0.981951560316721\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 56, train_loss = 9.61758167296648, train_acc = 0.9820680018630648\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 57, train_loss = 9.451379237696528, train_acc = 0.9820680018630648\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 58, train_loss = 9.289771476760507, train_acc = 0.9824173265020959\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 59, train_loss = 9.132559446617961, train_acc = 0.9824173265020959\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 60, train_loss = 8.979213943704963, train_acc = 0.9827666511411272\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 61, train_loss = 8.830207088962197, train_acc = 0.9831159757801584\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 62, train_loss = 8.684782331809402, train_acc = 0.9839310666045645\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 63, train_loss = 8.543223686516285, train_acc = 0.984163949697252\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 64, train_loss = 8.405454846099019, train_acc = 0.9845132743362832\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 65, train_loss = 8.271061271429062, train_acc = 0.9850954820680019\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 66, train_loss = 8.14019344933331, train_acc = 0.9852119236143456\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 67, train_loss = 8.01245061866939, train_acc = 0.9853283651606893\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 68, train_loss = 7.887920485809445, train_acc = 0.9855612482533768\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 69, train_loss = 7.766334315761924, train_acc = 0.9856776897997206\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 70, train_loss = 7.647887900471687, train_acc = 0.9860270144387517\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 71, train_loss = 7.531911389902234, train_acc = 0.9860270144387517\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 72, train_loss = 7.418677411973476, train_acc = 0.9861434559850955\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 73, train_loss = 7.30802689306438, train_acc = 0.9864927806241267\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 74, train_loss = 7.1998302433639765, train_acc = 0.9868421052631579\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 75, train_loss = 7.093989960849285, train_acc = 0.9868421052631579\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 76, train_loss = 6.990747323259711, train_acc = 0.9868421052631579\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 77, train_loss = 6.889569040387869, train_acc = 0.9868421052631579\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 78, train_loss = 6.790757915005088, train_acc = 0.9869585468095017\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 79, train_loss = 6.693742487579584, train_acc = 0.9874243129948765\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 80, train_loss = 6.59900370053947, train_acc = 0.9878900791802515\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 81, train_loss = 6.506130661815405, train_acc = 0.9880065207265952\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 82, train_loss = 6.415412837639451, train_acc = 0.9883558453656265\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 83, train_loss = 6.326339438557625, train_acc = 0.9883558453656265\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 84, train_loss = 6.239267706871033, train_acc = 0.9884722869119702\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 85, train_loss = 6.153992929495871, train_acc = 0.9889380530973452\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 86, train_loss = 6.070236851461232, train_acc = 0.9890544946436889\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 87, train_loss = 5.988280936144292, train_acc = 0.98940381928272\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 88, train_loss = 5.9078069077804685, train_acc = 0.9896367023754076\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 89, train_loss = 5.829069911502302, train_acc = 0.9896367023754076\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 90, train_loss = 5.751753643155098, train_acc = 0.9899860270144387\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 91, train_loss = 5.676146124489605, train_acc = 0.9901024685607824\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 92, train_loss = 5.6017450746148825, train_acc = 0.9904517931998137\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 93, train_loss = 5.528948844410479, train_acc = 0.9905682347461574\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 94, train_loss = 5.4573219465091825, train_acc = 0.9906846762925011\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 95, train_loss = 5.387156349606812, train_acc = 0.9912668840242198\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 96, train_loss = 5.318200962617993, train_acc = 0.9916162086632511\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 97, train_loss = 5.250502336770296, train_acc = 0.9916162086632511\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 98, train_loss = 5.184117319993675, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 99, train_loss = 5.119023791514337, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 100, train_loss = 5.054923240095377, train_acc = 0.9914997671169073\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 101, train_loss = 4.992099544033408, train_acc = 0.9917326502095948\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 102, train_loss = 4.930297612212598, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "22th- epoch: 103, train_loss = 4.869640205055475, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "22th- epoch: 104, train_loss = 4.809995195828378, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "22th- epoch: 105, train_loss = 4.751637167297304, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "22th- epoch: 106, train_loss = 4.6940799271687865, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "22th- epoch: 107, train_loss = 4.637679412029684, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 108, train_loss = 4.582358276471496, train_acc = 0.9923148579413135\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 109, train_loss = 4.527852589264512, train_acc = 0.9923148579413135\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 110, train_loss = 4.474360494874418, train_acc = 0.9925477410340009\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 111, train_loss = 4.4219737676903605, train_acc = 0.9926641825803446\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 112, train_loss = 4.3704164028167725, train_acc = 0.9928970656730322\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 113, train_loss = 4.3198255421593785, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 114, train_loss = 4.2701707147061825, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 115, train_loss = 4.221491203643382, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 116, train_loss = 4.173557019792497, train_acc = 0.9931299487657196\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 117, train_loss = 4.126702950336039, train_acc = 0.9932463903120633\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 118, train_loss = 4.0803677048534155, train_acc = 0.9932463903120633\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 119, train_loss = 4.034965846687555, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 120, train_loss = 3.990468037314713, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 121, train_loss = 3.9466432789340615, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 122, train_loss = 3.9037486780434847, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 123, train_loss = 3.861462628468871, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 124, train_loss = 3.8200895823538303, train_acc = 0.9932463903120633\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 125, train_loss = 3.7793920496478677, train_acc = 0.9935957149510946\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 126, train_loss = 3.7394122947007418, train_acc = 0.9937121564974383\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 127, train_loss = 3.6997210728004575, train_acc = 0.9939450395901258\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 128, train_loss = 3.6609780322760344, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 129, train_loss = 3.622833010740578, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 130, train_loss = 3.585404389537871, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 131, train_loss = 3.5485794758424163, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 132, train_loss = 3.512393934186548, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 133, train_loss = 3.4769476410001516, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 134, train_loss = 3.441974494140595, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 135, train_loss = 3.4076797398738563, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 136, train_loss = 3.3739861459471285, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 137, train_loss = 3.340858209412545, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 138, train_loss = 3.3082981021143496, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 139, train_loss = 3.2762880311347544, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 140, train_loss = 3.244792108889669, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 141, train_loss = 3.21384863415733, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 142, train_loss = 3.18342610495165, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 143, train_loss = 3.1533476603217423, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 144, train_loss = 3.1239151037298143, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 145, train_loss = 3.0949136312119663, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 146, train_loss = 3.06637791544199, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 147, train_loss = 3.0383890122175217, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 148, train_loss = 3.010541193652898, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 149, train_loss = 2.9833733714185655, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 150, train_loss = 2.9567340896464884, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 151, train_loss = 2.930478684604168, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 152, train_loss = 2.9045890332199633, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 153, train_loss = 2.8793508112430573, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 154, train_loss = 2.854244401678443, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 155, train_loss = 2.8296948950737715, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 156, train_loss = 2.8055430334061384, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 157, train_loss = 2.7817977187223732, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 158, train_loss = 2.7583184838294983, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 159, train_loss = 2.7352466993033886, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 160, train_loss = 2.7125583104789257, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 161, train_loss = 2.6901980848051608, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 162, train_loss = 2.668193227145821, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 163, train_loss = 2.6464905426837504, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 164, train_loss = 2.625141797121614, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 165, train_loss = 2.6041642390191555, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 166, train_loss = 2.583409484475851, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 167, train_loss = 2.5630381195805967, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 168, train_loss = 2.5428976640105247, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 169, train_loss = 2.523117110133171, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 170, train_loss = 2.5036340430378914, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 171, train_loss = 2.484528081957251, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 172, train_loss = 2.465560821350664, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 173, train_loss = 2.4469259530305862, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 174, train_loss = 2.4286141097545624, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 175, train_loss = 2.4105435921810567, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 176, train_loss = 2.3926210054196417, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 177, train_loss = 2.3751207925379276, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 178, train_loss = 2.35781038319692, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 179, train_loss = 2.340700073633343, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 180, train_loss = 2.3239365480840206, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 181, train_loss = 2.307417843490839, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 182, train_loss = 2.29120625811629, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 183, train_loss = 2.2750838547945023, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 184, train_loss = 2.259249000577256, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 185, train_loss = 2.243716253666207, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 186, train_loss = 2.2283827278297395, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 187, train_loss = 2.213328032521531, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 188, train_loss = 2.19846489909105, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 189, train_loss = 2.1838096503634006, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 190, train_loss = 2.16947203502059, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 191, train_loss = 2.1552289475221187, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 192, train_loss = 2.1412830390036106, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 193, train_loss = 2.12755382549949, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 194, train_loss = 2.113954149186611, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 195, train_loss = 2.1005891747772694, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 196, train_loss = 2.0873677507042885, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 197, train_loss = 2.0745291709899902, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 198, train_loss = 2.061723879305646, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 199, train_loss = 2.0492105099838227, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 200, train_loss = 2.0367999710142612, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 201, train_loss = 2.0247235149145126, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 202, train_loss = 2.0127201329451054, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 203, train_loss = 2.000894855707884, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 204, train_loss = 1.9892799966037273, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 205, train_loss = 1.97785813244991, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 206, train_loss = 1.9665756996255368, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 207, train_loss = 1.9554540414828807, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 208, train_loss = 1.9445242460351437, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 209, train_loss = 1.9337375822942704, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 210, train_loss = 1.9230998046696186, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 211, train_loss = 1.912574778078124, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 212, train_loss = 1.9023228622972965, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 213, train_loss = 1.8920532043557614, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 214, train_loss = 1.88207255047746, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 215, train_loss = 1.8721403118688613, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 216, train_loss = 1.8624217845499516, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 217, train_loss = 1.8528308682143688, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 218, train_loss = 1.8433555748779327, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 219, train_loss = 1.834022032795474, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 220, train_loss = 1.824808357981965, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 221, train_loss = 1.815739656565711, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 222, train_loss = 1.806774564087391, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 223, train_loss = 1.7979543420951813, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 224, train_loss = 1.789245281368494, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 225, train_loss = 1.7806163877248764, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 226, train_loss = 1.7722249638754874, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 227, train_loss = 1.7638240419328213, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 228, train_loss = 1.755596895935014, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 229, train_loss = 1.747406616806984, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 230, train_loss = 1.7393893760163337, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 231, train_loss = 1.7314913272857666, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 232, train_loss = 1.723580814898014, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 233, train_loss = 1.715926582692191, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 234, train_loss = 1.7082680612802505, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 235, train_loss = 1.7006897267419845, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 236, train_loss = 1.6933443907182664, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 237, train_loss = 1.685923015116714, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 238, train_loss = 1.678732113330625, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 239, train_loss = 1.6714965415885672, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 240, train_loss = 1.6644413532922044, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 241, train_loss = 1.6574722342193127, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 242, train_loss = 1.650571142672561, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 243, train_loss = 1.6437061416218057, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 244, train_loss = 1.636987982899882, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 245, train_loss = 1.6303381944308057, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 246, train_loss = 1.6237800046801567, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 247, train_loss = 1.6172107545426115, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 248, train_loss = 1.6108525755116716, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 249, train_loss = 1.6044296311447397, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 250, train_loss = 1.598173982114531, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 251, train_loss = 1.5919475493719801, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 252, train_loss = 1.5858748791506514, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 253, train_loss = 1.57973015808966, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 254, train_loss = 1.573766422807239, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 255, train_loss = 1.5677954429993406, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 256, train_loss = 1.561942165135406, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 257, train_loss = 1.556123349815607, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 258, train_loss = 1.5503777079284191, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 259, train_loss = 1.5446823127567768, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 260, train_loss = 1.5390601245453581, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 261, train_loss = 1.5334807261824608, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 262, train_loss = 1.5280269471695647, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 263, train_loss = 1.5225441021611914, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 264, train_loss = 1.5171820372343063, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 265, train_loss = 1.5118295177817345, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 266, train_loss = 1.5066035886993632, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 267, train_loss = 1.5014126040041447, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 268, train_loss = 1.4962032748153433, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 269, train_loss = 1.4911428889026865, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 270, train_loss = 1.4861146869370714, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 271, train_loss = 1.4810818955302238, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 272, train_loss = 1.4761633450398222, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 273, train_loss = 1.4713093787431717, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 274, train_loss = 1.4665065394947305, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 275, train_loss = 1.461709183990024, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 276, train_loss = 1.456974633038044, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 277, train_loss = 1.452304574311711, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 278, train_loss = 1.4477315843105316, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 279, train_loss = 1.4431094899773598, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 280, train_loss = 1.4386117135873064, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 281, train_loss = 1.4340761750936508, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 282, train_loss = 1.429696905077435, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 283, train_loss = 1.4252413721987978, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 284, train_loss = 1.4208967089653015, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 285, train_loss = 1.4166183322668076, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 286, train_loss = 1.4122565673897043, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 287, train_loss = 1.4080757176270708, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 288, train_loss = 1.4038127114763483, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 289, train_loss = 1.3996768755605444, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 290, train_loss = 1.395554301678203, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 291, train_loss = 1.3915147135267034, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 292, train_loss = 1.387433665455319, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 293, train_loss = 1.3834772309055552, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 294, train_loss = 1.3794881167123094, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 295, train_loss = 1.3756034597754478, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 296, train_loss = 1.3717282911529765, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 297, train_loss = 1.367892473936081, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 298, train_loss = 1.3640307387104258, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 299, train_loss = 1.3602589443325996, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 300, train_loss = 1.3565041633555666, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 301, train_loss = 1.3527324199676514, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 302, train_loss = 1.3490461260080338, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 303, train_loss = 1.345387864857912, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 304, train_loss = 1.3417705284664407, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 305, train_loss = 1.338161384104751, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 306, train_loss = 1.3346331007778645, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 307, train_loss = 1.3311175940325484, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 308, train_loss = 1.3275971288094297, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 309, train_loss = 1.324164006859064, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 310, train_loss = 1.3207296443870291, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 311, train_loss = 1.3173452218761668, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 312, train_loss = 1.3139653044636361, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 313, train_loss = 1.3106653851573355, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 314, train_loss = 1.3073157109320164, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 315, train_loss = 1.3040640726685524, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 316, train_loss = 1.3008185786311515, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 317, train_loss = 1.2975412905216217, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 318, train_loss = 1.294451791793108, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 319, train_loss = 1.2911811185185798, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 320, train_loss = 1.2880595165188424, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 321, train_loss = 1.2849335658247583, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 322, train_loss = 1.2818972319364548, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 323, train_loss = 1.27879311516881, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 324, train_loss = 1.2757383572752587, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 325, train_loss = 1.2726602877373807, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 326, train_loss = 1.2697503554518335, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 327, train_loss = 1.2667229088838212, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 328, train_loss = 1.2638417544658296, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 329, train_loss = 1.2609234365518205, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 330, train_loss = 1.2580211770837195, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 331, train_loss = 1.2551118272240274, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 332, train_loss = 1.2522714820806868, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 333, train_loss = 1.2494995519518852, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 334, train_loss = 1.246630905836355, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 335, train_loss = 1.2438725816900842, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 336, train_loss = 1.2411468997597694, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 337, train_loss = 1.2384180650115013, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 338, train_loss = 1.2358057548408397, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 339, train_loss = 1.2330553904175758, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 340, train_loss = 1.2303169394726865, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 341, train_loss = 1.2277153693139553, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 342, train_loss = 1.2250057918136008, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 343, train_loss = 1.22247977060033, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 344, train_loss = 1.2198323694174178, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 345, train_loss = 1.217279092699755, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 346, train_loss = 1.2147070057690144, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 347, train_loss = 1.2122433160548098, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 348, train_loss = 1.2096761825378053, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 349, train_loss = 1.2072593581979163, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 350, train_loss = 1.2047290988266468, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 351, train_loss = 1.2024177871644497, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 352, train_loss = 1.199793326377403, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 353, train_loss = 1.1974432903225534, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 354, train_loss = 1.195027248293627, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 355, train_loss = 1.192707126319874, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 356, train_loss = 1.1902947102789767, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 357, train_loss = 1.1879590054159053, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 358, train_loss = 1.1855946990544908, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 359, train_loss = 1.1833111482555978, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 360, train_loss = 1.1810309030115604, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 361, train_loss = 1.178685447841417, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 362, train_loss = 1.1764875687658787, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 363, train_loss = 1.1741408755187877, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 364, train_loss = 1.1719817581470124, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 365, train_loss = 1.1696736986632459, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 366, train_loss = 1.1675883270800114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 367, train_loss = 1.1653124925796874, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 368, train_loss = 1.1631494276225567, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 369, train_loss = 1.1609713546931744, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 370, train_loss = 1.158816710114479, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 371, train_loss = 1.1567013251478784, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 372, train_loss = 1.1546040723915212, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 373, train_loss = 1.1525262432987802, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 374, train_loss = 1.1504268310964108, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 375, train_loss = 1.1484109039301984, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 376, train_loss = 1.1463146395981312, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 377, train_loss = 1.1442892961204052, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 378, train_loss = 1.1422493532299995, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 379, train_loss = 1.1402424213592894, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 380, train_loss = 1.138230747252237, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 381, train_loss = 1.1361984511022456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 382, train_loss = 1.1343195848166943, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 383, train_loss = 1.1322676787967794, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 384, train_loss = 1.130395919084549, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 385, train_loss = 1.128484123677481, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 386, train_loss = 1.1265262700617313, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 387, train_loss = 1.1246141009032726, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 388, train_loss = 1.1227673987741582, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 389, train_loss = 1.1208870907430537, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 390, train_loss = 1.1190076458151452, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 391, train_loss = 1.1171988348360173, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 392, train_loss = 1.1153423699433915, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 393, train_loss = 1.1135272880201228, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 394, train_loss = 1.1116312543745153, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 395, train_loss = 1.1099350054864772, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 396, train_loss = 1.1080526150763035, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 397, train_loss = 1.1063610563869588, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 398, train_loss = 1.1045365706086159, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 399, train_loss = 1.1028190925717354, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 400, train_loss = 1.1010657250881195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 401, train_loss = 1.0993074377183802, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 402, train_loss = 1.0976293931598775, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 403, train_loss = 1.095875110477209, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 404, train_loss = 1.0942067503929138, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 405, train_loss = 1.0925048229401, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 406, train_loss = 1.0908686282928102, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 407, train_loss = 1.089133720844984, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 408, train_loss = 1.0875274104182608, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 409, train_loss = 1.085851527750492, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 410, train_loss = 1.0841932532493956, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 411, train_loss = 1.0826265240903012, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 412, train_loss = 1.080930418043863, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 413, train_loss = 1.0793671645224094, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 414, train_loss = 1.0777141104335897, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 415, train_loss = 1.07621954503702, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 416, train_loss = 1.0745445129578002, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 417, train_loss = 1.0730621379916556, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 418, train_loss = 1.0714056665892713, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 419, train_loss = 1.06996302556945, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 420, train_loss = 1.068342138081789, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 421, train_loss = 1.0668277827498969, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 422, train_loss = 1.0653034287097398, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 423, train_loss = 1.06378492465592, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 424, train_loss = 1.0623164884746075, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 425, train_loss = 1.0607657879590988, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 426, train_loss = 1.0593495132925455, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 427, train_loss = 1.0578149209322874, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 428, train_loss = 1.0563589371740818, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 429, train_loss = 1.0549177142383996, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 430, train_loss = 1.0534648137690965, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 431, train_loss = 1.05203272527433, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 432, train_loss = 1.0505567267537117, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 433, train_loss = 1.0492109879851341, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 434, train_loss = 1.0477154739201069, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 435, train_loss = 1.0463753963413183, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 436, train_loss = 1.0449148043990135, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 437, train_loss = 1.0435340938565787, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 438, train_loss = 1.042197611182928, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 439, train_loss = 1.0407914569077548, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 440, train_loss = 1.039388433098793, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 441, train_loss = 1.0380942834017333, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 442, train_loss = 1.0367144818010274, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 443, train_loss = 1.0353880673646927, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 444, train_loss = 1.0340511190297548, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 445, train_loss = 1.0327254608273506, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 446, train_loss = 1.0313496564922389, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 447, train_loss = 1.030088738858467, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 448, train_loss = 1.0287984112801496, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 449, train_loss = 1.0274253947136458, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 450, train_loss = 1.0262384911475237, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 451, train_loss = 1.0248543744382914, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 452, train_loss = 1.0236379715206567, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 453, train_loss = 1.0223306007683277, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 454, train_loss = 1.0210827750561293, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 455, train_loss = 1.0197832621634007, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 456, train_loss = 1.01852928349399, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 457, train_loss = 1.017289782554144, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 458, train_loss = 1.0160285793244839, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 459, train_loss = 1.0148888329567853, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 460, train_loss = 1.0135813603701536, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 461, train_loss = 1.0124158561229706, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 462, train_loss = 1.0111639300885145, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 463, train_loss = 1.0099657252430916, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 464, train_loss = 1.0087637690303382, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 465, train_loss = 1.0075963350536767, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 466, train_loss = 1.0063667967915535, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 467, train_loss = 1.0051780616340693, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 468, train_loss = 1.0040153799054679, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 469, train_loss = 1.002847071737051, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 470, train_loss = 1.001714310288662, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 471, train_loss = 1.0005144911410753, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 472, train_loss = 0.999399588763481, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 473, train_loss = 0.9984319346549455, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 474, train_loss = 0.9970801249146461, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 475, train_loss = 0.9959760395286139, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 476, train_loss = 0.9948530582187232, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 477, train_loss = 0.9937147609889507, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 478, train_loss = 0.9926145300269127, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 479, train_loss = 0.9914584110083524, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 480, train_loss = 0.9905913149414118, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 481, train_loss = 0.9893357902765274, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 482, train_loss = 0.988208994269371, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 483, train_loss = 0.9871586287918035, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 484, train_loss = 0.9861945745942649, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 485, train_loss = 0.98504969975329, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 486, train_loss = 0.9839559035899583, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 487, train_loss = 0.9827998280525208, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 488, train_loss = 0.9819815171358641, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 489, train_loss = 0.9807643443346024, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 490, train_loss = 0.9796677666308824, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 491, train_loss = 0.9787275865674019, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 492, train_loss = 0.9777473993599415, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 493, train_loss = 0.9765661880373955, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 494, train_loss = 0.9756525196135044, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 495, train_loss = 0.9745405924913939, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 496, train_loss = 0.9736920110881329, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 497, train_loss = 0.9725548835995141, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 498, train_loss = 0.971511530369753, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 499, train_loss = 0.9704898099007551, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|████████████████████████████████████████████████████▊                   | 22/30 [2:30:25<54:52, 411.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "23th- epoch: 0, train_loss = 267.9323762655258, train_acc = 0.43013507219375874\n",
      "test Acc 0.5400372439478585:\n",
      "23th- epoch: 1, train_loss = 202.565083861351, train_acc = 0.5584536562645552\n",
      "test Acc 0.5698324022346368:\n",
      "23th- epoch: 2, train_loss = 159.01794224977493, train_acc = 0.5834885887284583\n",
      "test Acc 0.63268156424581:\n",
      "23th- epoch: 3, train_loss = 132.72920113801956, train_acc = 0.6757102934326968\n",
      "test Acc 0.7351024208566108:\n",
      "23th- epoch: 4, train_loss = 114.25987684726715, train_acc = 0.7538425710293433\n",
      "test Acc 0.7816573556797021:\n",
      "23th- epoch: 5, train_loss = 99.99622756242752, train_acc = 0.7800419189566837\n",
      "test Acc 0.8012104283054003:\n",
      "23th- epoch: 6, train_loss = 88.30872195959091, train_acc = 0.8008849557522124\n",
      "test Acc 0.8235567970204841:\n",
      "23th- epoch: 7, train_loss = 78.45235392451286, train_acc = 0.8214951094550536\n",
      "test Acc 0.8435754189944135:\n",
      "23th- epoch: 8, train_loss = 69.95176443457603, train_acc = 0.8471122496506753\n",
      "test Acc 0.8608007448789572:\n",
      "23th- epoch: 9, train_loss = 62.51733262836933, train_acc = 0.8724965067536097\n",
      "test Acc 0.8845437616387337:\n",
      "23th- epoch: 10, train_loss = 56.02721652388573, train_acc = 0.8943875174662319\n",
      "test Acc 0.9073556797020484:\n",
      "23th- epoch: 11, train_loss = 50.406226098537445, train_acc = 0.9168607359105729\n",
      "test Acc 0.9292364990689013:\n",
      "23th- epoch: 12, train_loss = 45.564171597361565, train_acc = 0.9350256171401956\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 13, train_loss = 41.402104541659355, train_acc = 0.9445738239403819\n",
      "test Acc 0.9427374301675978:\n",
      "23th- epoch: 14, train_loss = 37.83116716146469, train_acc = 0.9478341872380065\n",
      "test Acc 0.9436685288640596:\n",
      "23th- epoch: 15, train_loss = 34.770141050219536, train_acc = 0.9505123428039124\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 16, train_loss = 32.1476361900568, train_acc = 0.9517931998136935\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 17, train_loss = 29.901305817067623, train_acc = 0.9548206800186306\n",
      "test Acc 0.9543761638733705:\n",
      "23th- epoch: 18, train_loss = 27.97070538252592, train_acc = 0.9574988355845365\n",
      "test Acc 0.9557728119180633:\n",
      "23th- epoch: 19, train_loss = 26.303813099861145, train_acc = 0.9605263157894737\n",
      "test Acc 0.9557728119180633:\n",
      "23th- epoch: 20, train_loss = 24.855955332517624, train_acc = 0.9630880298090359\n",
      "test Acc 0.957169459962756:\n",
      "23th- epoch: 21, train_loss = 23.589876480400562, train_acc = 0.9650675360968793\n",
      "test Acc 0.9599627560521415:\n",
      "23th- epoch: 22, train_loss = 22.474182423204184, train_acc = 0.9670470423847228\n",
      "test Acc 0.9622905027932961:\n",
      "23th- epoch: 23, train_loss = 21.48438961431384, train_acc = 0.9686772240335352\n",
      "test Acc 0.9632216014897579:\n",
      "23th- epoch: 24, train_loss = 20.60014747828245, train_acc = 0.9698416394969726\n",
      "test Acc 0.9636871508379888:\n",
      "23th- epoch: 25, train_loss = 19.804398264735937, train_acc = 0.970540288775035\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 26, train_loss = 19.083608347922564, train_acc = 0.9711224965067536\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 27, train_loss = 18.426323622465134, train_acc = 0.9713553795994411\n",
      "test Acc 0.9636871508379888:\n",
      "23th- epoch: 28, train_loss = 17.823467951267958, train_acc = 0.971821145784816\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 29, train_loss = 17.2680802680552, train_acc = 0.9725197950628784\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 30, train_loss = 16.75340399891138, train_acc = 0.9729855612482534\n",
      "test Acc 0.9650837988826816:\n",
      "23th- epoch: 31, train_loss = 16.274476055055857, train_acc = 0.9734513274336283\n",
      "test Acc 0.9660148975791434:\n",
      "23th- epoch: 32, train_loss = 15.826763663440943, train_acc = 0.9738006520726595\n",
      "test Acc 0.9664804469273743:\n",
      "23th- epoch: 33, train_loss = 15.406364995986223, train_acc = 0.9741499767116907\n",
      "test Acc 0.9669459962756052:\n",
      "23th- epoch: 34, train_loss = 15.010377902537584, train_acc = 0.9741499767116907\n",
      "test Acc 0.9669459962756052:\n",
      "23th- epoch: 35, train_loss = 14.63658807054162, train_acc = 0.9744993013507219\n",
      "test Acc 0.9674115456238361:\n",
      "23th- epoch: 36, train_loss = 14.28268925100565, train_acc = 0.9751979506287843\n",
      "test Acc 0.9674115456238361:\n",
      "23th- epoch: 37, train_loss = 13.946560364216566, train_acc = 0.9754308337214718\n",
      "test Acc 0.9674115456238361:\n",
      "23th- epoch: 38, train_loss = 13.626823369413614, train_acc = 0.9756637168141593\n",
      "test Acc 0.9674115456238361:\n",
      "23th- epoch: 39, train_loss = 13.32221694290638, train_acc = 0.9760130414531905\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 40, train_loss = 13.031171794980764, train_acc = 0.9764788076385654\n",
      "test Acc 0.9683426443202979:\n",
      "23th- epoch: 41, train_loss = 12.752751417458057, train_acc = 0.9768281322775967\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 42, train_loss = 12.486047107726336, train_acc = 0.9770610153702841\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 43, train_loss = 12.230276327580214, train_acc = 0.9775267815556591\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 44, train_loss = 11.984835766255856, train_acc = 0.977992547741034\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 45, train_loss = 11.748419560492039, train_acc = 0.9782254308337215\n",
      "test Acc 0.9697392923649907:\n",
      "23th- epoch: 46, train_loss = 11.521010089665651, train_acc = 0.9784583139264089\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 47, train_loss = 11.302052265033126, train_acc = 0.9789240801117839\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 48, train_loss = 11.090926779434085, train_acc = 0.9795062878435026\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 49, train_loss = 10.88720639795065, train_acc = 0.9796227293898463\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 50, train_loss = 10.690320648252964, train_acc = 0.97973917093619\n",
      "test Acc 0.9716014897579144:\n",
      "23th- epoch: 51, train_loss = 10.499896600842476, train_acc = 0.9799720540288775\n",
      "test Acc 0.9716014897579144:\n",
      "23th- epoch: 52, train_loss = 10.315170982852578, train_acc = 0.980204937121565\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 53, train_loss = 10.135844530537724, train_acc = 0.9803213786679087\n",
      "test Acc 0.9725325884543762:\n",
      "23th- epoch: 54, train_loss = 9.961936822161078, train_acc = 0.9810200279459711\n",
      "test Acc 0.9725325884543762:\n",
      "23th- epoch: 55, train_loss = 9.793075997382402, train_acc = 0.9816022356776898\n",
      "test Acc 0.9725325884543762:\n",
      "23th- epoch: 56, train_loss = 9.62919593974948, train_acc = 0.981951560316721\n",
      "test Acc 0.9725325884543762:\n",
      "23th- epoch: 57, train_loss = 9.469940569251776, train_acc = 0.9821844434094085\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 58, train_loss = 9.315102713182569, train_acc = 0.9826502095947834\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 59, train_loss = 9.164508687332273, train_acc = 0.9827666511411272\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 60, train_loss = 9.017760714516044, train_acc = 0.9828830926874709\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 61, train_loss = 8.87498084269464, train_acc = 0.9833488588728458\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 62, train_loss = 8.735909752547741, train_acc = 0.9834653004191896\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 63, train_loss = 8.600222012028098, train_acc = 0.9834653004191896\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 64, train_loss = 8.467974092811346, train_acc = 0.9834653004191896\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 65, train_loss = 8.339065643027425, train_acc = 0.983698183511877\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 66, train_loss = 8.213150726631284, train_acc = 0.9839310666045645\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 67, train_loss = 8.090150535106659, train_acc = 0.984163949697252\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 68, train_loss = 7.970143152400851, train_acc = 0.9845132743362832\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 69, train_loss = 7.8530329540371895, train_acc = 0.9847461574289706\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 70, train_loss = 7.738500760868192, train_acc = 0.9848625989753144\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 71, train_loss = 7.62647370994091, train_acc = 0.9853283651606893\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 72, train_loss = 7.5168712474405766, train_acc = 0.985444806707033\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 73, train_loss = 7.409633249044418, train_acc = 0.9856776897997206\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 74, train_loss = 7.304832808673382, train_acc = 0.9860270144387517\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 75, train_loss = 7.202410101890564, train_acc = 0.9860270144387517\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 76, train_loss = 7.102065881714225, train_acc = 0.986376339077783\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 77, train_loss = 7.003770360723138, train_acc = 0.9867256637168141\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 78, train_loss = 6.907437210902572, train_acc = 0.9867256637168141\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 79, train_loss = 6.81300150975585, train_acc = 0.9868421052631579\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 80, train_loss = 6.720389680936933, train_acc = 0.9869585468095017\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 81, train_loss = 6.629679879173636, train_acc = 0.9870749883558454\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 82, train_loss = 6.540855225175619, train_acc = 0.9876571960875641\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 83, train_loss = 6.453810017555952, train_acc = 0.9882394038192828\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 84, train_loss = 6.368381023406982, train_acc = 0.9883558453656265\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 85, train_loss = 6.284504475072026, train_acc = 0.9884722869119702\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 86, train_loss = 6.202248038724065, train_acc = 0.9887051700046576\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 87, train_loss = 6.121539058163762, train_acc = 0.9891709361900326\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 88, train_loss = 6.042296411469579, train_acc = 0.9892873777363763\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 89, train_loss = 5.9645128808915615, train_acc = 0.9892873777363763\n",
      "test Acc 0.978584729981378:\n",
      "23th- epoch: 90, train_loss = 5.888124104589224, train_acc = 0.98940381928272\n",
      "test Acc 0.978584729981378:\n",
      "23th- epoch: 91, train_loss = 5.813183294609189, train_acc = 0.9896367023754076\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 92, train_loss = 5.739502038806677, train_acc = 0.9897531439217513\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 93, train_loss = 5.667173506692052, train_acc = 0.9901024685607824\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 94, train_loss = 5.596191244199872, train_acc = 0.9902189101071263\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 95, train_loss = 5.52642753534019, train_acc = 0.9902189101071263\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 96, train_loss = 5.457902094349265, train_acc = 0.99033535165347\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 97, train_loss = 5.390566089190543, train_acc = 0.9904517931998137\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 98, train_loss = 5.324462261982262, train_acc = 0.9905682347461574\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 99, train_loss = 5.259423564188182, train_acc = 0.9904517931998137\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 100, train_loss = 5.195527044124901, train_acc = 0.990801117838845\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 101, train_loss = 5.132669393904507, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 102, train_loss = 5.070736947469413, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 103, train_loss = 5.009824141860008, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 104, train_loss = 4.949846342206001, train_acc = 0.9910340009315324\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 105, train_loss = 4.890881896018982, train_acc = 0.9911504424778761\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 106, train_loss = 4.832826265133917, train_acc = 0.9913833255705635\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 107, train_loss = 4.775658265687525, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 108, train_loss = 4.719602197408676, train_acc = 0.9918490917559385\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 109, train_loss = 4.664315157569945, train_acc = 0.9918490917559385\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 110, train_loss = 4.609942162409425, train_acc = 0.992081974848626\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 111, train_loss = 4.5565086137503386, train_acc = 0.9921984163949698\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 112, train_loss = 4.503804514184594, train_acc = 0.9924312994876572\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 113, train_loss = 4.452064243145287, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 114, train_loss = 4.401052062399685, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 115, train_loss = 4.350840547122061, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 116, train_loss = 4.301445149816573, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 117, train_loss = 4.252761306241155, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 118, train_loss = 4.204875934869051, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 119, train_loss = 4.157772650942206, train_acc = 0.9928970656730322\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 120, train_loss = 4.1113984091207385, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 121, train_loss = 4.065760877914727, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 122, train_loss = 4.0208062790334225, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 123, train_loss = 3.976608294993639, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 124, train_loss = 3.933136015199125, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 125, train_loss = 3.890325939282775, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 126, train_loss = 3.8482200670987368, train_acc = 0.9931299487657196\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 127, train_loss = 3.8067722534760833, train_acc = 0.9931299487657196\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 128, train_loss = 3.7658825628459454, train_acc = 0.9931299487657196\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 129, train_loss = 3.7257909551262856, train_acc = 0.9931299487657196\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 130, train_loss = 3.6862541483715177, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 131, train_loss = 3.647323696874082, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 132, train_loss = 3.6091100173071027, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 133, train_loss = 3.5713691944256425, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 134, train_loss = 3.5342300683259964, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 135, train_loss = 3.4977587489411235, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 136, train_loss = 3.4619280109182, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 137, train_loss = 3.4265882624313235, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 138, train_loss = 3.39194905012846, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 139, train_loss = 3.3577782306820154, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 140, train_loss = 3.3242824096232653, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 141, train_loss = 3.2912302734330297, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 142, train_loss = 3.258784149773419, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 143, train_loss = 3.22658418584615, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 144, train_loss = 3.195215937681496, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 145, train_loss = 3.1641396563500166, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 146, train_loss = 3.133694597519934, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 147, train_loss = 3.1036277562379837, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 148, train_loss = 3.0742049985565245, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 149, train_loss = 3.0452292803674936, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 150, train_loss = 3.016650837380439, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 151, train_loss = 2.9885704233311117, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 152, train_loss = 2.961148552596569, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 153, train_loss = 2.9339504968374968, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 154, train_loss = 2.9073421102948487, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 155, train_loss = 2.8811438903212547, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 156, train_loss = 2.855406119953841, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 157, train_loss = 2.8299737251363695, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 158, train_loss = 2.805101040750742, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 159, train_loss = 2.780593329574913, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 160, train_loss = 2.7564734015613794, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 161, train_loss = 2.7327279429882765, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 162, train_loss = 2.7093350091017783, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 163, train_loss = 2.6865318696945906, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 164, train_loss = 2.6638140100985765, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 165, train_loss = 2.641620935406536, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 166, train_loss = 2.6197735243476927, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 167, train_loss = 2.5981701095588505, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 168, train_loss = 2.577009489759803, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 169, train_loss = 2.5562068284489214, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 170, train_loss = 2.5356191736645997, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 171, train_loss = 2.515533034224063, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 172, train_loss = 2.495675515383482, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 173, train_loss = 2.476093466859311, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 174, train_loss = 2.4568428047932684, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 175, train_loss = 2.437895072158426, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 176, train_loss = 2.4192767147906125, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 177, train_loss = 2.401079684495926, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 178, train_loss = 2.3829943225719035, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 179, train_loss = 2.3653073981404305, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 180, train_loss = 2.3478353787213564, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 181, train_loss = 2.3307705936022103, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 182, train_loss = 2.313944797962904, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 183, train_loss = 2.2973112501204014, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 184, train_loss = 2.281005488242954, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 185, train_loss = 2.2648944505490363, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 186, train_loss = 2.249096293002367, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 187, train_loss = 2.233480277005583, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 188, train_loss = 2.218122810125351, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 189, train_loss = 2.2031187005341053, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 190, train_loss = 2.188332026358694, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 191, train_loss = 2.173769185785204, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 192, train_loss = 2.159471822436899, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 193, train_loss = 2.145238799508661, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 194, train_loss = 2.131349163595587, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 195, train_loss = 2.1177075407467782, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 196, train_loss = 2.104158888105303, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 197, train_loss = 2.0908541169483215, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 198, train_loss = 2.077850853325799, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 199, train_loss = 2.0648925963323563, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 200, train_loss = 2.0522712655365467, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 201, train_loss = 2.0397930790204555, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 202, train_loss = 2.0274944875855, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 203, train_loss = 2.0153195448219776, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 204, train_loss = 2.0034001283347607, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 205, train_loss = 1.9916476297657937, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 206, train_loss = 1.9800295059103519, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 207, train_loss = 1.9686885923147202, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 208, train_loss = 1.957434703828767, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 209, train_loss = 1.9463351320009679, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 210, train_loss = 1.9354870840907097, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 211, train_loss = 1.924698704155162, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 212, train_loss = 1.9141087506432086, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 213, train_loss = 1.9037114854436368, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 214, train_loss = 1.89334483188577, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 215, train_loss = 1.8832526113837957, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 216, train_loss = 1.8732068773824722, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 217, train_loss = 1.8634183097165078, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 218, train_loss = 1.8536307725589722, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 219, train_loss = 1.844031723914668, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 220, train_loss = 1.8346254229545593, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 221, train_loss = 1.82527856528759, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 222, train_loss = 1.8161191183608025, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 223, train_loss = 1.8070220239460468, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 224, train_loss = 1.7981308822054416, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 225, train_loss = 1.7892784017603844, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 226, train_loss = 1.78068108856678, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 227, train_loss = 1.7720473669469357, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 228, train_loss = 1.7636725802440196, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 229, train_loss = 1.7553330473601818, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 230, train_loss = 1.747091592522338, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 231, train_loss = 1.739067715825513, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 232, train_loss = 1.7309516805689782, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 233, train_loss = 1.723122451454401, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 234, train_loss = 1.7153092336375266, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 235, train_loss = 1.707635958911851, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 236, train_loss = 1.7001131598372012, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 237, train_loss = 1.692526635946706, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 238, train_loss = 1.6852240562438965, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 239, train_loss = 1.6778717215638608, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 240, train_loss = 1.670591623755172, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 241, train_loss = 1.6635323960799724, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 242, train_loss = 1.6564813517034054, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 243, train_loss = 1.6495315607171506, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 244, train_loss = 1.6426891770679504, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 245, train_loss = 1.6359751410782337, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 246, train_loss = 1.6291808623354882, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 247, train_loss = 1.622653305530548, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 248, train_loss = 1.615990673424676, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 249, train_loss = 1.6096324857790023, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 250, train_loss = 1.6032058894634247, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 251, train_loss = 1.5969114415347576, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 252, train_loss = 1.5906946260947734, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 253, train_loss = 1.5845007337629795, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 254, train_loss = 1.5784349006135017, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 255, train_loss = 1.572334056138061, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 256, train_loss = 1.5664934013038874, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 257, train_loss = 1.5605783188948408, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 258, train_loss = 1.5547225991031155, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 259, train_loss = 1.5489479521056637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 260, train_loss = 1.5433290979126468, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 261, train_loss = 1.5375850921263918, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 262, train_loss = 1.5321295509347692, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 263, train_loss = 1.5265399608761072, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 264, train_loss = 1.5212138599017635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 265, train_loss = 1.5158085295697674, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 266, train_loss = 1.5104132499545813, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 267, train_loss = 1.5052080856403336, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 268, train_loss = 1.4999576105037704, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 269, train_loss = 1.4948639957001433, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 270, train_loss = 1.4896963903447613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 271, train_loss = 1.4846202718326822, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 272, train_loss = 1.4797244562068954, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 273, train_loss = 1.474706353037618, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 274, train_loss = 1.46984702849295, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 275, train_loss = 1.4649835582822561, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 276, train_loss = 1.4601989375660196, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 277, train_loss = 1.4555694492300972, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 278, train_loss = 1.4507993273437023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 279, train_loss = 1.4460921175777912, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 280, train_loss = 1.4416101779788733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 281, train_loss = 1.4369623009115458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 282, train_loss = 1.432488332153298, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 283, train_loss = 1.4280371939530596, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 284, train_loss = 1.423574591637589, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "23th- epoch: 285, train_loss = 1.4192258771508932, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "23th- epoch: 286, train_loss = 1.4148155177244917, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 287, train_loss = 1.4105262545635924, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 288, train_loss = 1.4062715048203245, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 289, train_loss = 1.4019687908003107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 290, train_loss = 1.3979194884886965, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 291, train_loss = 1.3938574051717296, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 292, train_loss = 1.3896949030458927, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 293, train_loss = 1.3856430345913395, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 294, train_loss = 1.38165948970709, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 295, train_loss = 1.3776524234563112, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 296, train_loss = 1.3737875440856442, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 297, train_loss = 1.3699175094952807, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 298, train_loss = 1.3660682290792465, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 299, train_loss = 1.3621935857227072, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 300, train_loss = 1.3584637604653835, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 301, train_loss = 1.354614874930121, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 302, train_loss = 1.3510029775789008, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 303, train_loss = 1.347339991480112, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 304, train_loss = 1.343728462816216, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 305, train_loss = 1.3400968523928896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 306, train_loss = 1.3364578485488892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 307, train_loss = 1.3330028057098389, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 308, train_loss = 1.3293878063559532, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 309, train_loss = 1.3259211331605911, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 310, train_loss = 1.322496154694818, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 311, train_loss = 1.3190195597708225, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 312, train_loss = 1.315666905255057, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 313, train_loss = 1.3122749725589529, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 314, train_loss = 1.3089330481598154, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 315, train_loss = 1.3055655708303675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 316, train_loss = 1.302321376861073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 317, train_loss = 1.2990856455871835, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 318, train_loss = 1.295796143473126, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 319, train_loss = 1.2926261412212625, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 320, train_loss = 1.2893976730993018, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 321, train_loss = 1.2863384000957012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 322, train_loss = 1.2831460746238008, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 323, train_loss = 1.2800330333411694, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 324, train_loss = 1.2770193765172735, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 325, train_loss = 1.2739770399639383, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 326, train_loss = 1.270935115753673, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 327, train_loss = 1.2678906060755253, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 328, train_loss = 1.2649855887284502, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 329, train_loss = 1.2620606124401093, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 330, train_loss = 1.2590688368072733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 331, train_loss = 1.256209570914507, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 332, train_loss = 1.2533776400377974, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 333, train_loss = 1.2505381976952776, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 334, train_loss = 1.2477528154850006, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 335, train_loss = 1.2448928194353357, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 336, train_loss = 1.2421517508337274, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 337, train_loss = 1.2394614070653915, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 338, train_loss = 1.2366380505263805, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 339, train_loss = 1.2339817906613462, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 340, train_loss = 1.2312766301329248, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 341, train_loss = 1.2286151734297164, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 342, train_loss = 1.2260017159278505, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 343, train_loss = 1.2233203637297265, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 344, train_loss = 1.2207628798787482, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 345, train_loss = 1.2181370432372205, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 346, train_loss = 1.215687233954668, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 347, train_loss = 1.2129900853033178, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 348, train_loss = 1.2105931006371975, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 349, train_loss = 1.2080049949581735, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 350, train_loss = 1.2055815694038756, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 351, train_loss = 1.2031041805748828, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 352, train_loss = 1.2006850925390609, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 353, train_loss = 1.1981361657381058, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 354, train_loss = 1.1959062826936133, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 355, train_loss = 1.1934178434312344, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 356, train_loss = 1.1911142866010778, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 357, train_loss = 1.1886587117915042, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 358, train_loss = 1.1863972929422744, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 359, train_loss = 1.184049426286947, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 360, train_loss = 1.1817819215357304, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 361, train_loss = 1.1794435431365855, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 362, train_loss = 1.177223229140509, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 363, train_loss = 1.1748818469350226, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 364, train_loss = 1.1726838772301562, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 365, train_loss = 1.1704562629456632, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 366, train_loss = 1.1683271254296415, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 367, train_loss = 1.1660696392063983, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 368, train_loss = 1.163901458203327, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 369, train_loss = 1.1617755591869354, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 370, train_loss = 1.1595912116463296, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 371, train_loss = 1.1575691451434977, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 372, train_loss = 1.1553260262007825, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 373, train_loss = 1.153255810320843, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 374, train_loss = 1.1512721379403956, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 375, train_loss = 1.1490789465606213, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 376, train_loss = 1.1470645082299598, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 377, train_loss = 1.145103411108721, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 378, train_loss = 1.1429534765775315, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 379, train_loss = 1.1410498768091202, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 380, train_loss = 1.1390073262155056, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 381, train_loss = 1.136991926759947, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 382, train_loss = 1.1350642132456414, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 383, train_loss = 1.1330128572881222, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 384, train_loss = 1.1311812661588192, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 385, train_loss = 1.1292764954268932, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 386, train_loss = 1.1273136176168919, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 387, train_loss = 1.1253615232999437, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 388, train_loss = 1.1235458416049369, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 389, train_loss = 1.1216952565009706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 390, train_loss = 1.1196961042587645, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 391, train_loss = 1.11790880310582, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 392, train_loss = 1.1161368303000927, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 393, train_loss = 1.1141471713781357, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 394, train_loss = 1.112484399229288, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 395, train_loss = 1.1106549613177776, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 396, train_loss = 1.1087352633476257, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 397, train_loss = 1.1070825904607773, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 398, train_loss = 1.1052528631989844, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 399, train_loss = 1.103539930016268, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 400, train_loss = 1.101764700084459, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 401, train_loss = 1.0999881264870055, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 402, train_loss = 1.0982925817370415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 403, train_loss = 1.0965136525337584, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 404, train_loss = 1.094830334186554, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 405, train_loss = 1.0931525242631324, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 406, train_loss = 1.0913875090773217, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 407, train_loss = 1.0898535326123238, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 408, train_loss = 1.0881759722833522, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 409, train_loss = 1.0864354993100278, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 410, train_loss = 1.084810892760288, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 411, train_loss = 1.08329737681197, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 412, train_loss = 1.0815507409279235, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 413, train_loss = 1.0799248020048253, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 414, train_loss = 1.078448299318552, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 415, train_loss = 1.0767224170267582, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 416, train_loss = 1.0752296261489391, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 417, train_loss = 1.0736324042081833, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 418, train_loss = 1.072009998082649, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 419, train_loss = 1.070509320765268, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 420, train_loss = 1.0688847390119918, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 421, train_loss = 1.0674146463279612, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 422, train_loss = 1.0658121419255622, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 423, train_loss = 1.064337192743551, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 424, train_loss = 1.0628327205777168, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 425, train_loss = 1.061338706582319, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 426, train_loss = 1.059769018262159, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 427, train_loss = 1.0583189291064627, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 428, train_loss = 1.056859202682972, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 429, train_loss = 1.0554312355816364, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 430, train_loss = 1.053891733288765, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 431, train_loss = 1.0525543428957462, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 432, train_loss = 1.0510421034996398, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 433, train_loss = 1.049638032913208, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 434, train_loss = 1.0481421773438342, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 435, train_loss = 1.0469015960698016, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 436, train_loss = 1.045297512144316, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 437, train_loss = 1.0439568745787255, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 438, train_loss = 1.0425515845417976, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 439, train_loss = 1.0412693098187447, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 440, train_loss = 1.039823802828323, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 441, train_loss = 1.0384495283360593, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 442, train_loss = 1.0371053566341288, train_acc = 0.9980204937121565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 443, train_loss = 1.035764551430475, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 444, train_loss = 1.0343885980546474, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 445, train_loss = 1.0329966321587563, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 446, train_loss = 1.0317580464179628, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 447, train_loss = 1.030369886488188, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 448, train_loss = 1.0290318342740647, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 449, train_loss = 1.0277398328180425, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 450, train_loss = 1.0264443643391132, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 451, train_loss = 1.025192619592417, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 452, train_loss = 1.0238173616235144, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 453, train_loss = 1.0225749909877777, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 454, train_loss = 1.0213081799447536, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 455, train_loss = 1.0200468773837201, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 456, train_loss = 1.018747626512777, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 457, train_loss = 1.0174804218113422, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 458, train_loss = 1.0162970796227455, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 459, train_loss = 1.0150511413812637, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 460, train_loss = 1.013753631443251, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 461, train_loss = 1.0125369404850062, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 462, train_loss = 1.011341913283104, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 463, train_loss = 1.0102196956577245, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 464, train_loss = 1.0089065743086394, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 465, train_loss = 1.007766264170641, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 466, train_loss = 1.0065119042992592, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 467, train_loss = 1.0054118794796523, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 468, train_loss = 1.0041262482700404, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 469, train_loss = 1.0030277272162493, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 470, train_loss = 1.0018449127674103, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 471, train_loss = 1.0006552636623383, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 472, train_loss = 0.9995362882909831, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 473, train_loss = 0.9983759025635663, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 474, train_loss = 0.9972035624086857, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 475, train_loss = 0.9961384534835815, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 476, train_loss = 0.9949348171649035, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 477, train_loss = 0.9938760312797967, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 478, train_loss = 0.9927261720004026, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 479, train_loss = 0.9915953911840916, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 480, train_loss = 0.9904587368073408, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 481, train_loss = 0.9893645619449671, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 482, train_loss = 0.9883003992435988, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 483, train_loss = 0.9871549867093563, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 484, train_loss = 0.9861174436809961, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 485, train_loss = 0.9849978759884834, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 486, train_loss = 0.9839248185453471, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 487, train_loss = 0.9828024506568909, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 488, train_loss = 0.9817378272709902, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 489, train_loss = 0.9807147321698721, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 490, train_loss = 0.9796250810322817, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 491, train_loss = 0.9786529081466142, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 492, train_loss = 0.9775581347348634, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 493, train_loss = 0.9765147206780966, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 494, train_loss = 0.9755449866352137, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 495, train_loss = 0.9744532220065594, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 496, train_loss = 0.9734666099247988, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 497, train_loss = 0.9724426344037056, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 498, train_loss = 0.971421825379366, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "23th- epoch: 499, train_loss = 0.9703788310289383, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████████████████████████████▏                | 23/30 [2:37:17<48:00, 411.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "24th- epoch: 0, train_loss = 271.488551735878, train_acc = 0.39531904983698185\n",
      "test Acc 0.5288640595903166:\n",
      "24th- epoch: 1, train_loss = 210.21031665802002, train_acc = 0.5515836050302748\n",
      "test Acc 0.5670391061452514:\n",
      "24th- epoch: 2, train_loss = 164.9155061841011, train_acc = 0.581858407079646\n",
      "test Acc 0.6261638733705773:\n",
      "24th- epoch: 3, train_loss = 136.33697766065598, train_acc = 0.678272007452259\n",
      "test Acc 0.744413407821229:\n",
      "24th- epoch: 4, train_loss = 116.60985851287842, train_acc = 0.7568700512342804\n",
      "test Acc 0.7793296089385475:\n",
      "24th- epoch: 5, train_loss = 101.54383724927902, train_acc = 0.7764322310200279\n",
      "test Acc 0.797486033519553:\n",
      "24th- epoch: 6, train_loss = 89.60131606459618, train_acc = 0.7891243595714951\n",
      "test Acc 0.8044692737430168:\n",
      "24th- epoch: 7, train_loss = 79.99256789684296, train_acc = 0.8111318118304611\n",
      "test Acc 0.8286778398510242:\n",
      "24th- epoch: 8, train_loss = 71.97465592622757, train_acc = 0.83011178388449\n",
      "test Acc 0.845437616387337:\n",
      "24th- epoch: 9, train_loss = 65.0162806212902, train_acc = 0.8501397298556125\n",
      "test Acc 0.8640595903165735:\n",
      "24th- epoch: 10, train_loss = 58.862990871071815, train_acc = 0.8740102468560782\n",
      "test Acc 0.888733705772812:\n",
      "24th- epoch: 11, train_loss = 53.399098843336105, train_acc = 0.8962505822077317\n",
      "test Acc 0.9082867783985102:\n",
      "24th- epoch: 12, train_loss = 48.540919318795204, train_acc = 0.9190731252911039\n",
      "test Acc 0.9283054003724395:\n",
      "24th- epoch: 13, train_loss = 44.231370851397514, train_acc = 0.9367722403353517\n",
      "test Acc 0.9357541899441341:\n",
      "24th- epoch: 14, train_loss = 40.43369632959366, train_acc = 0.9435258500232883\n",
      "test Acc 0.9390130353817505:\n",
      "24th- epoch: 15, train_loss = 37.11461138725281, train_acc = 0.9485328365160689\n",
      "test Acc 0.9422718808193669:\n",
      "24th- epoch: 16, train_loss = 34.23417064547539, train_acc = 0.951560316721006\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 17, train_loss = 31.743646763265133, train_acc = 0.9536562645551933\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 18, train_loss = 29.592291429638863, train_acc = 0.955519329296693\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 19, train_loss = 27.73042856901884, train_acc = 0.9585468095016302\n",
      "test Acc 0.9534450651769087:\n",
      "24th- epoch: 20, train_loss = 26.11290016770363, train_acc = 0.9608756404285049\n",
      "test Acc 0.9557728119180633:\n",
      "24th- epoch: 21, train_loss = 24.7008957862854, train_acc = 0.9636702375407545\n",
      "test Acc 0.9608938547486033:\n",
      "24th- epoch: 22, train_loss = 23.459974508732557, train_acc = 0.9663483931066604\n",
      "test Acc 0.9613594040968343:\n",
      "24th- epoch: 23, train_loss = 22.36074658855796, train_acc = 0.9683278993945039\n",
      "test Acc 0.9618249534450651:\n",
      "24th- epoch: 24, train_loss = 21.380742076784372, train_acc = 0.9692594317652539\n",
      "test Acc 0.9608938547486033:\n",
      "24th- epoch: 25, train_loss = 20.502160146832466, train_acc = 0.9693758733115976\n",
      "test Acc 0.9613594040968343:\n",
      "24th- epoch: 26, train_loss = 19.70857958495617, train_acc = 0.9698416394969726\n",
      "test Acc 0.9613594040968343:\n",
      "24th- epoch: 27, train_loss = 18.987241555005312, train_acc = 0.9706567303213787\n",
      "test Acc 0.9632216014897579:\n",
      "24th- epoch: 28, train_loss = 18.327962055802345, train_acc = 0.9712389380530974\n",
      "test Acc 0.9636871508379888:\n",
      "24th- epoch: 29, train_loss = 17.72210654616356, train_acc = 0.9719375873311598\n",
      "test Acc 0.9632216014897579:\n",
      "24th- epoch: 30, train_loss = 17.16218750923872, train_acc = 0.9726362366092222\n",
      "test Acc 0.9636871508379888:\n",
      "24th- epoch: 31, train_loss = 16.64208109304309, train_acc = 0.9733348858872846\n",
      "test Acc 0.9646182495344506:\n",
      "24th- epoch: 32, train_loss = 16.157070200890303, train_acc = 0.9739170936190032\n",
      "test Acc 0.9646182495344506:\n",
      "24th- epoch: 33, train_loss = 15.703257266432047, train_acc = 0.9742664182580345\n",
      "test Acc 0.9646182495344506:\n",
      "24th- epoch: 34, train_loss = 15.277858730405569, train_acc = 0.9746157428970657\n",
      "test Acc 0.9650837988826816:\n",
      "24th- epoch: 35, train_loss = 14.877682078629732, train_acc = 0.9748486259897532\n",
      "test Acc 0.9660148975791434:\n",
      "24th- epoch: 36, train_loss = 14.500324979424477, train_acc = 0.9751979506287843\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 37, train_loss = 14.143072225153446, train_acc = 0.9755472752678156\n",
      "test Acc 0.9678770949720671:\n",
      "24th- epoch: 38, train_loss = 13.803782846778631, train_acc = 0.9755472752678156\n",
      "test Acc 0.9678770949720671:\n",
      "24th- epoch: 39, train_loss = 13.481119189411402, train_acc = 0.9758965999068467\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 40, train_loss = 13.17370293661952, train_acc = 0.976245924545878\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 41, train_loss = 12.880205649882555, train_acc = 0.9765952491849091\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 42, train_loss = 12.599579963833094, train_acc = 0.9774103400093154\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 43, train_loss = 12.330967467278242, train_acc = 0.9776432231020028\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 44, train_loss = 12.073539428412914, train_acc = 0.9782254308337215\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 45, train_loss = 11.826580587774515, train_acc = 0.9789240801117839\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 46, train_loss = 11.588998563587666, train_acc = 0.9793898462971589\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 47, train_loss = 11.36023573949933, train_acc = 0.9795062878435026\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 48, train_loss = 11.139695908874273, train_acc = 0.9800884955752213\n",
      "test Acc 0.9711359404096834:\n",
      "24th- epoch: 49, train_loss = 10.927139677107334, train_acc = 0.9807871448532837\n",
      "test Acc 0.9711359404096834:\n",
      "24th- epoch: 50, train_loss = 10.721813160926104, train_acc = 0.9809035863996274\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 51, train_loss = 10.5231953561306, train_acc = 0.9812529110386586\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 52, train_loss = 10.331091731786728, train_acc = 0.9814857941313461\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 53, train_loss = 10.145420093089342, train_acc = 0.9814857941313461\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 54, train_loss = 9.965146897360682, train_acc = 0.9817186772240335\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 55, train_loss = 9.79031539708376, train_acc = 0.9821844434094085\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 56, train_loss = 9.62076180242002, train_acc = 0.9824173265020959\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 57, train_loss = 9.455924352630973, train_acc = 0.9826502095947834\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 58, train_loss = 9.29567190259695, train_acc = 0.9827666511411272\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 59, train_loss = 9.139806205406785, train_acc = 0.9828830926874709\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 60, train_loss = 8.988189622759819, train_acc = 0.9829995342338146\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 61, train_loss = 8.84066822566092, train_acc = 0.9833488588728458\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 62, train_loss = 8.697087790817022, train_acc = 0.9833488588728458\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 63, train_loss = 8.557135226204991, train_acc = 0.9833488588728458\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 64, train_loss = 8.420841533690691, train_acc = 0.983698183511877\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 65, train_loss = 8.288040140643716, train_acc = 0.9839310666045645\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 66, train_loss = 8.158288285136223, train_acc = 0.9842803912435957\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 67, train_loss = 8.031862784177065, train_acc = 0.9843968327899395\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 68, train_loss = 7.908355712890625, train_acc = 0.9846297158826269\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 69, train_loss = 7.787823185324669, train_acc = 0.9848625989753144\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 70, train_loss = 7.669966027140617, train_acc = 0.9853283651606893\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 71, train_loss = 7.5549752451479435, train_acc = 0.9855612482533768\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 72, train_loss = 7.442396255210042, train_acc = 0.9856776897997206\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 73, train_loss = 7.33238841407001, train_acc = 0.9860270144387517\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 74, train_loss = 7.224965529516339, train_acc = 0.9860270144387517\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 75, train_loss = 7.11999024450779, train_acc = 0.986376339077783\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 76, train_loss = 7.017274817451835, train_acc = 0.9864927806241267\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 77, train_loss = 6.916718430817127, train_acc = 0.9869585468095017\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 78, train_loss = 6.818466389551759, train_acc = 0.9870749883558454\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 79, train_loss = 6.7222850397229195, train_acc = 0.9870749883558454\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 80, train_loss = 6.628156270831823, train_acc = 0.9876571960875641\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 81, train_loss = 6.5358687322586775, train_acc = 0.9877736376339078\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 82, train_loss = 6.445462644100189, train_acc = 0.9877736376339078\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 83, train_loss = 6.356792092323303, train_acc = 0.9882394038192828\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 84, train_loss = 6.2697490602731705, train_acc = 0.9884722869119702\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 85, train_loss = 6.184587387368083, train_acc = 0.9884722869119702\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 86, train_loss = 6.1009770799428225, train_acc = 0.9885887284583139\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 87, train_loss = 6.019096793606877, train_acc = 0.9889380530973452\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 88, train_loss = 5.938737146556377, train_acc = 0.9890544946436889\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 89, train_loss = 5.85999408736825, train_acc = 0.9890544946436889\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 90, train_loss = 5.782640751451254, train_acc = 0.98940381928272\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 91, train_loss = 5.706788005307317, train_acc = 0.9895202608290639\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 92, train_loss = 5.632259162142873, train_acc = 0.9896367023754076\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 93, train_loss = 5.559138000011444, train_acc = 0.9896367023754076\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 94, train_loss = 5.4874225771054626, train_acc = 0.9899860270144387\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 95, train_loss = 5.4168451596051455, train_acc = 0.99033535165347\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 96, train_loss = 5.347656591795385, train_acc = 0.99033535165347\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 97, train_loss = 5.279599802568555, train_acc = 0.990801117838845\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 98, train_loss = 5.212882542051375, train_acc = 0.990801117838845\n",
      "test Acc 0.9795158286778398:\n",
      "24th- epoch: 99, train_loss = 5.147308600135148, train_acc = 0.990801117838845\n",
      "test Acc 0.9795158286778398:\n",
      "24th- epoch: 100, train_loss = 5.082832184620202, train_acc = 0.9909175593851887\n",
      "test Acc 0.9795158286778398:\n",
      "24th- epoch: 101, train_loss = 5.019392388872802, train_acc = 0.9910340009315324\n",
      "test Acc 0.9795158286778398:\n",
      "24th- epoch: 102, train_loss = 4.957061448134482, train_acc = 0.9911504424778761\n",
      "test Acc 0.9799813780260708:\n",
      "24th- epoch: 103, train_loss = 4.8959352085366845, train_acc = 0.9916162086632511\n",
      "test Acc 0.9799813780260708:\n",
      "24th- epoch: 104, train_loss = 4.835757411085069, train_acc = 0.9918490917559385\n",
      "test Acc 0.9799813780260708:\n",
      "24th- epoch: 105, train_loss = 4.776697872206569, train_acc = 0.9918490917559385\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 106, train_loss = 4.7186597334221005, train_acc = 0.9918490917559385\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 107, train_loss = 4.661591515876353, train_acc = 0.9919655333022822\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 108, train_loss = 4.6055929232388735, train_acc = 0.992081974848626\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 109, train_loss = 4.550456608645618, train_acc = 0.9921984163949698\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 110, train_loss = 4.4963046768680215, train_acc = 0.9923148579413135\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 111, train_loss = 4.443141766823828, train_acc = 0.9925477410340009\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 112, train_loss = 4.3909249091520905, train_acc = 0.9925477410340009\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 113, train_loss = 4.339550093747675, train_acc = 0.9926641825803446\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 114, train_loss = 4.289331098087132, train_acc = 0.9926641825803446\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 115, train_loss = 4.239696330390871, train_acc = 0.9926641825803446\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 116, train_loss = 4.191172586753964, train_acc = 0.9927806241266884\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 117, train_loss = 4.143388505093753, train_acc = 0.9930135072193759\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 118, train_loss = 4.096578515134752, train_acc = 0.9930135072193759\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 119, train_loss = 4.050609012134373, train_acc = 0.9930135072193759\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 120, train_loss = 4.005319491028786, train_acc = 0.9930135072193759\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 121, train_loss = 3.960962272249162, train_acc = 0.9933628318584071\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 122, train_loss = 3.9174208752810955, train_acc = 0.9934792734047508\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 123, train_loss = 3.8744758339598775, train_acc = 0.9935957149510946\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 124, train_loss = 3.832517033442855, train_acc = 0.9935957149510946\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 125, train_loss = 3.7912389216944575, train_acc = 0.9937121564974383\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 126, train_loss = 3.750604453496635, train_acc = 0.9935957149510946\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 127, train_loss = 3.7107465118169785, train_acc = 0.9937121564974383\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 128, train_loss = 3.671432743780315, train_acc = 0.9937121564974383\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 129, train_loss = 3.632809146307409, train_acc = 0.9937121564974383\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 130, train_loss = 3.5948130069300532, train_acc = 0.9939450395901258\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 131, train_loss = 3.5574717884883285, train_acc = 0.9939450395901258\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 132, train_loss = 3.520818956196308, train_acc = 0.9940614811364695\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 133, train_loss = 3.4848013250157237, train_acc = 0.9940614811364695\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 134, train_loss = 3.4491557758301497, train_acc = 0.9940614811364695\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 135, train_loss = 3.4143047481775284, train_acc = 0.9940614811364695\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 136, train_loss = 3.3799174446612597, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 137, train_loss = 3.3461546944454312, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 138, train_loss = 3.3130207424983382, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 139, train_loss = 3.280422492418438, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 140, train_loss = 3.24831048771739, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 141, train_loss = 3.216961155179888, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 142, train_loss = 3.1859572590328753, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 143, train_loss = 3.155510746408254, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 144, train_loss = 3.1255475147627294, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 145, train_loss = 3.0961986067704856, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 146, train_loss = 3.0670639742165804, train_acc = 0.9946436888681882\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 147, train_loss = 3.038635690230876, train_acc = 0.9946436888681882\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 148, train_loss = 3.010474272072315, train_acc = 0.9947601304145319\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 149, train_loss = 2.9830266926437616, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 150, train_loss = 2.955929145216942, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 151, train_loss = 2.9291199487634003, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 152, train_loss = 2.9029417098499835, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 153, train_loss = 2.8771085902117193, train_acc = 0.9952258965999069\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 154, train_loss = 2.8517157970927656, train_acc = 0.9952258965999069\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 155, train_loss = 2.8268030737526715, train_acc = 0.9952258965999069\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 156, train_loss = 2.802178559359163, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 157, train_loss = 2.778062463272363, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 158, train_loss = 2.7542161592282355, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 159, train_loss = 2.7308097444474697, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 160, train_loss = 2.707749504595995, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 161, train_loss = 2.685025632381439, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 162, train_loss = 2.6626648381352425, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 163, train_loss = 2.640790639910847, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 164, train_loss = 2.619216730352491, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 165, train_loss = 2.5977988592348993, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 166, train_loss = 2.5769750378094614, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 167, train_loss = 2.556335894856602, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 168, train_loss = 2.536142833530903, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 169, train_loss = 2.5162314660847187, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 170, train_loss = 2.4966380656696856, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 171, train_loss = 2.4773520841263235, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 172, train_loss = 2.458271972835064, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 173, train_loss = 2.4396277628839016, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 174, train_loss = 2.4211432188749313, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 175, train_loss = 2.4029623442329466, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 176, train_loss = 2.3850251971744, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 177, train_loss = 2.3673140057362616, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 178, train_loss = 2.34998357668519, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 179, train_loss = 2.3328950232826173, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 180, train_loss = 2.3160548084415495, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 181, train_loss = 2.299392888788134, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 182, train_loss = 2.283038499299437, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 183, train_loss = 2.2669598646461964, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 184, train_loss = 2.251010084990412, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 185, train_loss = 2.2354522235691547, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 186, train_loss = 2.2199763082899153, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 187, train_loss = 2.204857360571623, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 188, train_loss = 2.1899100292939693, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 189, train_loss = 2.175194377778098, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 190, train_loss = 2.160834605572745, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 191, train_loss = 2.146649933187291, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 192, train_loss = 2.1325504581909627, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 193, train_loss = 2.118762645870447, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 194, train_loss = 2.105214636772871, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 195, train_loss = 2.0918366846162826, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 196, train_loss = 2.078781871823594, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 197, train_loss = 2.0657709937077016, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 198, train_loss = 2.0529385569971055, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 199, train_loss = 2.040587627561763, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 200, train_loss = 2.0280856154859066, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 201, train_loss = 2.0159902535378933, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 202, train_loss = 2.003981828689575, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 203, train_loss = 1.9920547604560852, train_acc = 0.9972054028877504\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 204, train_loss = 1.9805406257510185, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 205, train_loss = 1.9691032629925758, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 206, train_loss = 1.9577652737498283, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 207, train_loss = 1.9467506993096322, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 208, train_loss = 1.935811882140115, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 209, train_loss = 1.92498242482543, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 210, train_loss = 1.9144429378211498, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 211, train_loss = 1.903934846399352, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 212, train_loss = 1.8937070034444332, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 213, train_loss = 1.8834774929564446, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 214, train_loss = 1.8734677087049931, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 215, train_loss = 1.863606580765918, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 216, train_loss = 1.8538018155377358, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 217, train_loss = 1.8443939934950322, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 218, train_loss = 1.8349122416693717, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 219, train_loss = 1.8255793701391667, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 220, train_loss = 1.8165452952962369, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 221, train_loss = 1.8074393384158611, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 222, train_loss = 1.7985526646953076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 223, train_loss = 1.7897575397510082, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 224, train_loss = 1.7811340279877186, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 225, train_loss = 1.7726184811908752, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 226, train_loss = 1.7642626415472478, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 227, train_loss = 1.75580516573973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 228, train_loss = 1.7476669400930405, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 229, train_loss = 1.7396370160859078, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 230, train_loss = 1.7316378664691001, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 231, train_loss = 1.7237142648082227, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 232, train_loss = 1.7159906688611954, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 233, train_loss = 1.7083539974410087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 234, train_loss = 1.7008167009335011, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 235, train_loss = 1.6933561600744724, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 236, train_loss = 1.6859163381159306, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 237, train_loss = 1.6786470387596637, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 238, train_loss = 1.6715551924426109, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 239, train_loss = 1.6644212007522583, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 240, train_loss = 1.6574213728308678, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 241, train_loss = 1.6505390541860834, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 242, train_loss = 1.643636537133716, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 243, train_loss = 1.636942291050218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 244, train_loss = 1.6302297748625278, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 245, train_loss = 1.623663286329247, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 246, train_loss = 1.6171268820762634, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 247, train_loss = 1.6106839390704408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 248, train_loss = 1.6043862303486094, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 249, train_loss = 1.5979672881076112, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 250, train_loss = 1.591826026677154, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 251, train_loss = 1.585707113146782, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 252, train_loss = 1.5795666886260733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 253, train_loss = 1.573580615222454, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 254, train_loss = 1.567612525075674, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 255, train_loss = 1.561777868657373, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 256, train_loss = 1.555912047624588, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 257, train_loss = 1.5502084493637085, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 258, train_loss = 1.5445861680200323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 259, train_loss = 1.5388717328896746, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 260, train_loss = 1.5333898278186098, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 261, train_loss = 1.5278597697615623, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 262, train_loss = 1.5224097868194804, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 263, train_loss = 1.5170588406035677, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 264, train_loss = 1.511677642702125, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 265, train_loss = 1.5063659673323855, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 266, train_loss = 1.501277486444451, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 267, train_loss = 1.496051506488584, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 268, train_loss = 1.49108376854565, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 269, train_loss = 1.4859749848255888, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 270, train_loss = 1.4810111945262179, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 271, train_loss = 1.476057787775062, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 272, train_loss = 1.4712077230215073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 273, train_loss = 1.4664196148514748, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 274, train_loss = 1.4615623193094507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 275, train_loss = 1.4569578170776367, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 276, train_loss = 1.4521984917810187, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 277, train_loss = 1.4475383324315771, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 278, train_loss = 1.443021733313799, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 279, train_loss = 1.4384255049517378, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 280, train_loss = 1.4339794976403937, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 281, train_loss = 1.4294819856295362, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 282, train_loss = 1.4251227416098118, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 283, train_loss = 1.4207730032503605, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 284, train_loss = 1.416396390646696, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 285, train_loss = 1.4122449966380373, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 286, train_loss = 1.407902117818594, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 287, train_loss = 1.4037178134312853, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 288, train_loss = 1.3995217109331861, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 289, train_loss = 1.395511295646429, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 290, train_loss = 1.3913745457539335, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 291, train_loss = 1.3873930299887434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 292, train_loss = 1.3833433078834787, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 293, train_loss = 1.3794344352791086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 294, train_loss = 1.3755273533752188, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 295, train_loss = 1.3716293399920687, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 296, train_loss = 1.367837498546578, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 297, train_loss = 1.3639408821472898, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 298, train_loss = 1.3602410232415423, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 299, train_loss = 1.3565619563451037, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 300, train_loss = 1.3528383262455463, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 301, train_loss = 1.349138967692852, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 302, train_loss = 1.3455117779085413, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 303, train_loss = 1.3419515466084704, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 304, train_loss = 1.3384272083640099, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 305, train_loss = 1.3348299525678158, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 306, train_loss = 1.3313441997161135, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 307, train_loss = 1.3278752280166373, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 308, train_loss = 1.324424066930078, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 309, train_loss = 1.3210256757447496, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 310, train_loss = 1.317670957534574, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 311, train_loss = 1.3143384518334642, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 312, train_loss = 1.3109622882911935, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 313, train_loss = 1.307740032672882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 314, train_loss = 1.3044826524564996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 315, train_loss = 1.3012442825129256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 316, train_loss = 1.297965427278541, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 317, train_loss = 1.2949139265110716, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 318, train_loss = 1.291599739342928, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 319, train_loss = 1.2886137291789055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 320, train_loss = 1.2854336860473268, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 321, train_loss = 1.2824012227356434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 322, train_loss = 1.2793172473902814, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 323, train_loss = 1.2763396290247329, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 324, train_loss = 1.2733586144750006, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 325, train_loss = 1.270353239029646, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 326, train_loss = 1.2674010011251085, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 327, train_loss = 1.264575348526705, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 328, train_loss = 1.2615930761094205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 329, train_loss = 1.2587335395510308, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 330, train_loss = 1.2558835012023337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 331, train_loss = 1.2530952654778957, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 332, train_loss = 1.2502555809915066, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 333, train_loss = 1.2474494029884227, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 334, train_loss = 1.24469119933201, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 335, train_loss = 1.2419918688829057, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 336, train_loss = 1.2393191928858869, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 337, train_loss = 1.2365294570918195, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 338, train_loss = 1.2339174163644202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 339, train_loss = 1.2312986689503305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 340, train_loss = 1.2285544251208194, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 341, train_loss = 1.2260319143533707, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 342, train_loss = 1.2234082793002017, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 343, train_loss = 1.2208411755855195, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 344, train_loss = 1.2183069686288945, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 345, train_loss = 1.2157538893516175, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 346, train_loss = 1.2132311736349948, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 347, train_loss = 1.2107737610931508, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 348, train_loss = 1.2082735461299308, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 349, train_loss = 1.205786969512701, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 350, train_loss = 1.2033771474962123, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 351, train_loss = 1.2009700437192805, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 352, train_loss = 1.1985708276624791, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 353, train_loss = 1.19616075232625, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 354, train_loss = 1.1937663455610164, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 355, train_loss = 1.1914603995974176, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 356, train_loss = 1.1891787486965768, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 357, train_loss = 1.186782956123352, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 358, train_loss = 1.1845574739272706, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 359, train_loss = 1.182182177901268, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 360, train_loss = 1.1800027750432491, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 361, train_loss = 1.1776878598029725, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 362, train_loss = 1.1754890394513495, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 363, train_loss = 1.1732233054935932, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 364, train_loss = 1.1711225646431558, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 365, train_loss = 1.1688895027036779, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 366, train_loss = 1.1666926145553589, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 367, train_loss = 1.1645478990976699, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 368, train_loss = 1.162486879795324, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 369, train_loss = 1.1602950927917846, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 370, train_loss = 1.15821474295808, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 371, train_loss = 1.156088761985302, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 372, train_loss = 1.1540489780600183, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 373, train_loss = 1.1519305109977722, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 374, train_loss = 1.1499570049345493, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 375, train_loss = 1.1478698439896107, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 376, train_loss = 1.145844290673267, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 377, train_loss = 1.1438543125987053, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 378, train_loss = 1.141874309629202, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 379, train_loss = 1.1398835976724513, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 380, train_loss = 1.1378686825628392, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 381, train_loss = 1.1359006017446518, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 382, train_loss = 1.1339524177019484, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 383, train_loss = 1.1321112017030828, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 384, train_loss = 1.1301414904301055, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 385, train_loss = 1.1282188122277148, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 386, train_loss = 1.1263445727527142, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 387, train_loss = 1.1244828539784066, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 388, train_loss = 1.1225886109168641, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 389, train_loss = 1.1207472917740233, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 390, train_loss = 1.1188951507210732, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 391, train_loss = 1.1170674326713197, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 392, train_loss = 1.11524000269128, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 393, train_loss = 1.1134145818650723, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 394, train_loss = 1.1116344705224037, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 395, train_loss = 1.1099438145756721, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 396, train_loss = 1.1080522127449512, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 397, train_loss = 1.1063605013187043, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 398, train_loss = 1.104641705751419, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 399, train_loss = 1.102825806767214, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 400, train_loss = 1.1011765487492085, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 401, train_loss = 1.0994656570255756, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 402, train_loss = 1.0977104318444617, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 403, train_loss = 1.0959927688236348, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 404, train_loss = 1.0942529092426412, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 405, train_loss = 1.0926821331377141, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 406, train_loss = 1.0910542135243304, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 407, train_loss = 1.089341688901186, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 408, train_loss = 1.0876742005348206, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 409, train_loss = 1.0860937274992466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 410, train_loss = 1.0844831627910025, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 411, train_loss = 1.0828702946309932, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 412, train_loss = 1.0812336442177184, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 413, train_loss = 1.0796998317237012, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 414, train_loss = 1.0781288680736907, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 415, train_loss = 1.0764577289228328, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 416, train_loss = 1.0748855781857856, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 417, train_loss = 1.0733712402288802, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 418, train_loss = 1.0718459698255174, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 419, train_loss = 1.0703190925414674, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 420, train_loss = 1.0688452869653702, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 421, train_loss = 1.0671586394309998, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 422, train_loss = 1.065783053636551, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 423, train_loss = 1.0641782470047474, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 424, train_loss = 1.0626742827589624, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 425, train_loss = 1.061327539384365, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 426, train_loss = 1.0597868636250496, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 427, train_loss = 1.0583080686628819, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 428, train_loss = 1.0568580590188503, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 429, train_loss = 1.055411505221855, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 430, train_loss = 1.0539848121698014, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 431, train_loss = 1.0525290618243162, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 432, train_loss = 1.0511114882829133, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 433, train_loss = 1.0496655479073524, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 434, train_loss = 1.0483100550773088, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 435, train_loss = 1.0467823719081935, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 436, train_loss = 1.0454912247660104, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 437, train_loss = 1.0440793124435004, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 438, train_loss = 1.0426943649945315, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 439, train_loss = 1.0413264458475169, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 440, train_loss = 1.0399614622292574, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 441, train_loss = 1.0386431837978307, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 442, train_loss = 1.0371986938116606, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 443, train_loss = 1.0359592636523303, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 444, train_loss = 1.0345481919648591, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 445, train_loss = 1.0332236637768801, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 446, train_loss = 1.0319565224053804, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 447, train_loss = 1.030617494136095, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 448, train_loss = 1.0292585218849126, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 449, train_loss = 1.0280508399009705, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 450, train_loss = 1.0267885265348013, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 451, train_loss = 1.0253962365386542, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 452, train_loss = 1.024179750442272, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 453, train_loss = 1.022909036517376, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 454, train_loss = 1.0216064279375132, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 455, train_loss = 1.020426211267477, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 456, train_loss = 1.0190697684884071, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 457, train_loss = 1.0179170407354832, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 458, train_loss = 1.0166853914561216, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 459, train_loss = 1.0153946826758329, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 460, train_loss = 1.014163427054882, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 461, train_loss = 1.012932470679516, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 462, train_loss = 1.011796352773672, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 463, train_loss = 1.0105738627316896, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 464, train_loss = 1.0093623039720114, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 465, train_loss = 1.0082084611058235, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 466, train_loss = 1.0069514686765615, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 467, train_loss = 1.0058156276645605, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 468, train_loss = 1.0046904645860195, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 469, train_loss = 1.003464379668003, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 470, train_loss = 1.002336397767067, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 471, train_loss = 1.001173261553049, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 472, train_loss = 0.9999882901611272, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 473, train_loss = 0.9988906333746854, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 474, train_loss = 0.9977572659554426, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 475, train_loss = 0.9966292902827263, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 476, train_loss = 0.995447968452936, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 477, train_loss = 0.9943867027759552, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 478, train_loss = 0.9931929036974907, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 479, train_loss = 0.9921327531337738, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 480, train_loss = 0.9910803722741548, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 481, train_loss = 0.9899244879779872, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 482, train_loss = 0.9888293892145157, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 483, train_loss = 0.9877676019968931, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 484, train_loss = 0.9866312518715858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 485, train_loss = 0.9856015096011106, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 486, train_loss = 0.9845350421965122, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 487, train_loss = 0.9834694216551725, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 488, train_loss = 0.9823335756955203, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 489, train_loss = 0.9813918024301529, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 490, train_loss = 0.9802305065095425, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 491, train_loss = 0.9792155660688877, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 492, train_loss = 0.9782159154710826, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 493, train_loss = 0.9771727671322878, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 494, train_loss = 0.9761334943177644, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 495, train_loss = 0.9751102055015508, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 496, train_loss = 0.9740488243696745, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 497, train_loss = 0.973003551363945, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 498, train_loss = 0.9720971559581812, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 499, train_loss = 0.971039609372383, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████▌              | 24/30 [2:44:11<41:13, 412.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "25th- epoch: 0, train_loss = 273.53405570983887, train_acc = 0.4668141592920354\n",
      "test Acc 0.5628491620111732:\n",
      "25th- epoch: 1, train_loss = 211.91493237018585, train_acc = 0.5627619934792734\n",
      "test Acc 0.5679702048417132:\n",
      "25th- epoch: 2, train_loss = 163.2055195569992, train_acc = 0.5716115510013973\n",
      "test Acc 0.5819366852886406:\n",
      "25th- epoch: 3, train_loss = 136.62176489830017, train_acc = 0.6237773637633908\n",
      "test Acc 0.6992551210428305:\n",
      "25th- epoch: 4, train_loss = 117.94794726371765, train_acc = 0.7373078714485328\n",
      "test Acc 0.7793296089385475:\n",
      "25th- epoch: 5, train_loss = 102.4235517680645, train_acc = 0.788309268747089\n",
      "test Acc 0.8105214152700186:\n",
      "25th- epoch: 6, train_loss = 89.3480144739151, train_acc = 0.812063344201211\n",
      "test Acc 0.8282122905027933:\n",
      "25th- epoch: 7, train_loss = 78.61722534894943, train_acc = 0.8267349790405216\n",
      "test Acc 0.8365921787709497:\n",
      "25th- epoch: 8, train_loss = 69.72283440828323, train_acc = 0.8408244061481136\n",
      "test Acc 0.8547486033519553:\n",
      "25th- epoch: 9, train_loss = 62.224835842847824, train_acc = 0.8722636236609222\n",
      "test Acc 0.8836126629422719:\n",
      "25th- epoch: 10, train_loss = 55.82353065907955, train_acc = 0.8933395435491384\n",
      "test Acc 0.9017690875232774:\n",
      "25th- epoch: 11, train_loss = 50.31409239768982, train_acc = 0.9166278528178854\n",
      "test Acc 0.9250465549348231:\n",
      "25th- epoch: 12, train_loss = 45.55466386675835, train_acc = 0.9335118770377271\n",
      "test Acc 0.9352886405959032:\n",
      "25th- epoch: 13, train_loss = 41.45010721683502, train_acc = 0.9415463437354448\n",
      "test Acc 0.9385474860335196:\n",
      "25th- epoch: 14, train_loss = 37.920597955584526, train_acc = 0.9459711224965067\n",
      "test Acc 0.9404096834264432:\n",
      "25th- epoch: 15, train_loss = 34.890281938016415, train_acc = 0.9487657196087564\n",
      "test Acc 0.9445996275605214:\n",
      "25th- epoch: 16, train_loss = 32.291442446410656, train_acc = 0.952026082906381\n",
      "test Acc 0.9464618249534451:\n",
      "25th- epoch: 17, train_loss = 30.056180752813816, train_acc = 0.955519329296693\n",
      "test Acc 0.9497206703910615:\n",
      "25th- epoch: 18, train_loss = 28.12551035732031, train_acc = 0.9583139264089428\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 19, train_loss = 26.449405044317245, train_acc = 0.9613414066138798\n",
      "test Acc 0.952513966480447:\n",
      "25th- epoch: 20, train_loss = 24.986109234392643, train_acc = 0.9625058220773172\n",
      "test Acc 0.952513966480447:\n",
      "25th- epoch: 21, train_loss = 23.70086418837309, train_acc = 0.9646017699115044\n",
      "test Acc 0.9539106145251397:\n",
      "25th- epoch: 22, train_loss = 22.56466943025589, train_acc = 0.9659990684676293\n",
      "test Acc 0.957635009310987:\n",
      "25th- epoch: 23, train_loss = 21.553703635931015, train_acc = 0.9680950163018165\n",
      "test Acc 0.9604283054003724:\n",
      "25th- epoch: 24, train_loss = 20.648513555526733, train_acc = 0.9686772240335352\n",
      "test Acc 0.9613594040968343:\n",
      "25th- epoch: 25, train_loss = 19.83246275037527, train_acc = 0.9699580810433163\n",
      "test Acc 0.9618249534450651:\n",
      "25th- epoch: 26, train_loss = 19.091548774391413, train_acc = 0.9708896134140661\n",
      "test Acc 0.962756052141527:\n",
      "25th- epoch: 27, train_loss = 18.415079917758703, train_acc = 0.9714718211457848\n",
      "test Acc 0.9632216014897579:\n",
      "25th- epoch: 28, train_loss = 17.79508461803198, train_acc = 0.971821145784816\n",
      "test Acc 0.9632216014897579:\n",
      "25th- epoch: 29, train_loss = 17.22339439764619, train_acc = 0.9720540288775035\n",
      "test Acc 0.9641527001862198:\n",
      "25th- epoch: 30, train_loss = 16.693933479487896, train_acc = 0.9731020027945971\n",
      "test Acc 0.9650837988826816:\n",
      "25th- epoch: 31, train_loss = 16.201757945120335, train_acc = 0.9739170936190032\n",
      "test Acc 0.9646182495344506:\n",
      "25th- epoch: 32, train_loss = 15.742201518267393, train_acc = 0.9741499767116907\n",
      "test Acc 0.9646182495344506:\n",
      "25th- epoch: 33, train_loss = 15.312131352722645, train_acc = 0.9743828598043782\n",
      "test Acc 0.9655493482309124:\n",
      "25th- epoch: 34, train_loss = 14.907756332308054, train_acc = 0.9746157428970657\n",
      "test Acc 0.9655493482309124:\n",
      "25th- epoch: 35, train_loss = 14.525882042944431, train_acc = 0.9747321844434094\n",
      "test Acc 0.9655493482309124:\n",
      "25th- epoch: 36, train_loss = 14.16466012224555, train_acc = 0.9747321844434094\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 37, train_loss = 13.822194542735815, train_acc = 0.9748486259897532\n",
      "test Acc 0.9655493482309124:\n",
      "25th- epoch: 38, train_loss = 13.496470917016268, train_acc = 0.9754308337214718\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 39, train_loss = 13.186126478016376, train_acc = 0.975780158360503\n",
      "test Acc 0.9664804469273743:\n",
      "25th- epoch: 40, train_loss = 12.89015880599618, train_acc = 0.9761294829995343\n",
      "test Acc 0.9674115456238361:\n",
      "25th- epoch: 41, train_loss = 12.607408456504345, train_acc = 0.9764788076385654\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 42, train_loss = 12.336755782365799, train_acc = 0.9767116907312529\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 43, train_loss = 12.077499683946371, train_acc = 0.9775267815556591\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 44, train_loss = 11.828654240816832, train_acc = 0.9781089892873778\n",
      "test Acc 0.9683426443202979:\n",
      "25th- epoch: 45, train_loss = 11.589431092143059, train_acc = 0.9785747554727526\n",
      "test Acc 0.9692737430167597:\n",
      "25th- epoch: 46, train_loss = 11.359202783554792, train_acc = 0.9796227293898463\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 47, train_loss = 11.13723435997963, train_acc = 0.9798556124825337\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 48, train_loss = 10.923124689608812, train_acc = 0.9803213786679087\n",
      "test Acc 0.9711359404096834:\n",
      "25th- epoch: 49, train_loss = 10.716570941731334, train_acc = 0.9805542617605962\n",
      "test Acc 0.9716014897579144:\n",
      "25th- epoch: 50, train_loss = 10.517047058790922, train_acc = 0.9807871448532837\n",
      "test Acc 0.9716014897579144:\n",
      "25th- epoch: 51, train_loss = 10.323878342285752, train_acc = 0.9812529110386586\n",
      "test Acc 0.9716014897579144:\n",
      "25th- epoch: 52, train_loss = 10.136697575449944, train_acc = 0.9813693525850024\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 53, train_loss = 9.955435520038009, train_acc = 0.9814857941313461\n",
      "test Acc 0.9725325884543762:\n",
      "25th- epoch: 54, train_loss = 9.779689637944102, train_acc = 0.9816022356776898\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 55, train_loss = 9.6091776676476, train_acc = 0.9817186772240335\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 56, train_loss = 9.443375071510673, train_acc = 0.9824173265020959\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 57, train_loss = 9.282231932505965, train_acc = 0.9824173265020959\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 58, train_loss = 9.125332837924361, train_acc = 0.9826502095947834\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 59, train_loss = 8.972573455423117, train_acc = 0.9828830926874709\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 60, train_loss = 8.823908809572458, train_acc = 0.9833488588728458\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 61, train_loss = 8.679206052795053, train_acc = 0.9835817419655333\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 62, train_loss = 8.53818746469915, train_acc = 0.9838146250582208\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 63, train_loss = 8.400819914415479, train_acc = 0.9838146250582208\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 64, train_loss = 8.266917331144214, train_acc = 0.9839310666045645\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 65, train_loss = 8.136270020157099, train_acc = 0.9842803912435957\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 66, train_loss = 8.008765758946538, train_acc = 0.9843968327899395\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 67, train_loss = 7.884469589218497, train_acc = 0.9846297158826269\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 68, train_loss = 7.763050328940153, train_acc = 0.9847461574289706\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 69, train_loss = 7.644610138610005, train_acc = 0.9847461574289706\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 70, train_loss = 7.528856681659818, train_acc = 0.9848625989753144\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 71, train_loss = 7.4159174878150225, train_acc = 0.9849790405216581\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 72, train_loss = 7.305371534079313, train_acc = 0.985444806707033\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 73, train_loss = 7.197342632338405, train_acc = 0.9855612482533768\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 74, train_loss = 7.091764487326145, train_acc = 0.9857941313460643\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 75, train_loss = 6.98838041909039, train_acc = 0.9860270144387517\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 76, train_loss = 6.887223707512021, train_acc = 0.9861434559850955\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 77, train_loss = 6.788254609331489, train_acc = 0.9864927806241267\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 78, train_loss = 6.691473748534918, train_acc = 0.9867256637168141\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 79, train_loss = 6.596649546176195, train_acc = 0.9869585468095017\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 80, train_loss = 6.50390705652535, train_acc = 0.9869585468095017\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 81, train_loss = 6.412956262007356, train_acc = 0.9875407545412203\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 82, train_loss = 6.323801528662443, train_acc = 0.9876571960875641\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 83, train_loss = 6.2363605704158545, train_acc = 0.9882394038192828\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 84, train_loss = 6.150612344965339, train_acc = 0.9883558453656265\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 85, train_loss = 6.066543711349368, train_acc = 0.9889380530973452\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 86, train_loss = 5.984024330042303, train_acc = 0.9890544946436889\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 87, train_loss = 5.903204150497913, train_acc = 0.9892873777363763\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 88, train_loss = 5.823847318999469, train_acc = 0.98940381928272\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 89, train_loss = 5.745919487439096, train_acc = 0.98940381928272\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 90, train_loss = 5.669586759991944, train_acc = 0.9897531439217513\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 91, train_loss = 5.594649822451174, train_acc = 0.989869585468095\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 92, train_loss = 5.521171533502638, train_acc = 0.9899860270144387\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 93, train_loss = 5.448880746029317, train_acc = 0.99033535165347\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 94, train_loss = 5.377972586080432, train_acc = 0.99033535165347\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 95, train_loss = 5.308367629535496, train_acc = 0.9904517931998137\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 96, train_loss = 5.240015342831612, train_acc = 0.9904517931998137\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 97, train_loss = 5.1728291204199195, train_acc = 0.9906846762925011\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 98, train_loss = 5.106849480420351, train_acc = 0.9911504424778761\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 99, train_loss = 5.041889289394021, train_acc = 0.9911504424778761\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 100, train_loss = 4.978205400519073, train_acc = 0.9912668840242198\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 101, train_loss = 4.91549585480243, train_acc = 0.9913833255705635\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 102, train_loss = 4.853896112181246, train_acc = 0.9914997671169073\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 103, train_loss = 4.793461889028549, train_acc = 0.9913833255705635\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 104, train_loss = 4.734055308625102, train_acc = 0.9913833255705635\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 105, train_loss = 4.675643688999116, train_acc = 0.9913833255705635\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 106, train_loss = 4.61840521171689, train_acc = 0.9912668840242198\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 107, train_loss = 4.562108966521919, train_acc = 0.9911504424778761\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 108, train_loss = 4.506806277669966, train_acc = 0.9912668840242198\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 109, train_loss = 4.452506076544523, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 110, train_loss = 4.399256309494376, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 111, train_loss = 4.347043034620583, train_acc = 0.992081974848626\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 112, train_loss = 4.295568019151688, train_acc = 0.9925477410340009\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 113, train_loss = 4.244984324090183, train_acc = 0.9927806241266884\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 114, train_loss = 4.195562609471381, train_acc = 0.9928970656730322\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 115, train_loss = 4.146996038965881, train_acc = 0.9931299487657196\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 116, train_loss = 4.0991803565993905, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 117, train_loss = 4.052281458862126, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 118, train_loss = 4.006259729154408, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 119, train_loss = 3.9609492560848594, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 120, train_loss = 3.9163674460723996, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 121, train_loss = 3.872695730999112, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 122, train_loss = 3.8298769434913993, train_acc = 0.9937121564974383\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 123, train_loss = 3.787843636237085, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 124, train_loss = 3.746482596732676, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 125, train_loss = 3.7061461145058274, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 126, train_loss = 3.6663220608606935, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 127, train_loss = 3.626997415907681, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 128, train_loss = 3.5888265687972307, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 129, train_loss = 3.55101743619889, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 130, train_loss = 3.514045742806047, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 131, train_loss = 3.4775282996706665, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 132, train_loss = 3.4417812903411686, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 133, train_loss = 3.406510441098362, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 134, train_loss = 3.372117415536195, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 135, train_loss = 3.3381436127237976, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 136, train_loss = 3.3047075024805963, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 137, train_loss = 3.2720845812000334, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 138, train_loss = 3.239712947513908, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 139, train_loss = 3.208171085920185, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 140, train_loss = 3.1770251649431884, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 141, train_loss = 3.1467057187110186, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 142, train_loss = 3.1166762127541006, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 143, train_loss = 3.087091281544417, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 144, train_loss = 3.0581821971572936, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 145, train_loss = 3.029526696074754, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 146, train_loss = 3.0015205815434456, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 147, train_loss = 2.9738553152419627, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 148, train_loss = 2.9467329843901098, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 149, train_loss = 2.9201346072368324, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 150, train_loss = 2.8938739695586264, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 151, train_loss = 2.868114786222577, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 152, train_loss = 2.8427517246454954, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 153, train_loss = 2.817833499982953, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 154, train_loss = 2.7933202940039337, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 155, train_loss = 2.7690100953914225, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 156, train_loss = 2.7453894806094468, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 157, train_loss = 2.721988656092435, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 158, train_loss = 2.699029414448887, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 159, train_loss = 2.676181126385927, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 160, train_loss = 2.653976982459426, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 161, train_loss = 2.631948173046112, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 162, train_loss = 2.6105485507287085, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 163, train_loss = 2.5891763637773693, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 164, train_loss = 2.568421462085098, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 165, train_loss = 2.547908376902342, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 166, train_loss = 2.527771558612585, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 167, train_loss = 2.5078958342783153, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 168, train_loss = 2.4883883609436452, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 169, train_loss = 2.4690997232683003, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 170, train_loss = 2.4503058530390263, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 171, train_loss = 2.4316816073842347, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 172, train_loss = 2.4133370821364224, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 173, train_loss = 2.3953212592750788, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 174, train_loss = 2.377519541885704, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 175, train_loss = 2.3600130290724337, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 176, train_loss = 2.342771444004029, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 177, train_loss = 2.325910327490419, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 178, train_loss = 2.3092767759226263, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 179, train_loss = 2.2927667442709208, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 180, train_loss = 2.2766837887465954, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 181, train_loss = 2.260738879442215, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 182, train_loss = 2.2452137395739555, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 183, train_loss = 2.2297734953463078, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 184, train_loss = 2.2145448091905564, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 185, train_loss = 2.199742675991729, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 186, train_loss = 2.185032683191821, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 187, train_loss = 2.17048221337609, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 188, train_loss = 2.1563431073445827, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 189, train_loss = 2.142318790080026, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 190, train_loss = 2.1284368101041764, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 191, train_loss = 2.1149312790948898, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 192, train_loss = 2.1013790529686958, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 193, train_loss = 2.0883483812212944, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 194, train_loss = 2.075257482705638, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 195, train_loss = 2.0624726861715317, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 196, train_loss = 2.0496948584914207, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 197, train_loss = 2.03738259896636, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 198, train_loss = 2.0250290620606393, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 199, train_loss = 2.0129206851124763, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 200, train_loss = 2.0009215238969773, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 201, train_loss = 1.9891919221263379, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 202, train_loss = 1.9774172243196517, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 203, train_loss = 1.9660348233301193, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 204, train_loss = 1.954701405018568, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 205, train_loss = 1.9435527697205544, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 206, train_loss = 1.9326622348744422, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 207, train_loss = 1.9218127590138465, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 208, train_loss = 1.9112355771940202, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 209, train_loss = 1.9007579449098557, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 210, train_loss = 1.8904252152424306, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 211, train_loss = 1.8802896041888744, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 212, train_loss = 1.8703940373379737, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 213, train_loss = 1.8604050639551133, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 214, train_loss = 1.8507859755773097, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 215, train_loss = 1.8411413382273167, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 216, train_loss = 1.8318005439359695, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 217, train_loss = 1.8223906059283763, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 218, train_loss = 1.8133027728181332, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 219, train_loss = 1.8042835555970669, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 220, train_loss = 1.7952806912362576, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 221, train_loss = 1.786548312753439, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 222, train_loss = 1.7778367947321385, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 223, train_loss = 1.7692713774740696, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 224, train_loss = 1.760851117549464, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 225, train_loss = 1.7525010127574205, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 226, train_loss = 1.7444297845941037, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 227, train_loss = 1.7361798759084195, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 228, train_loss = 1.7283397254068404, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 229, train_loss = 1.720317157683894, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 230, train_loss = 1.7126636903267354, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 231, train_loss = 1.7049571089446545, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 232, train_loss = 1.69737361127045, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 233, train_loss = 1.6898284554481506, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 234, train_loss = 1.6825800040969625, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 235, train_loss = 1.6751864490797743, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 236, train_loss = 1.6680615892400965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 237, train_loss = 1.6609231705078855, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 238, train_loss = 1.6539681069552898, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 239, train_loss = 1.647025752812624, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 240, train_loss = 1.6402092339703813, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 241, train_loss = 1.6334502311656252, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 242, train_loss = 1.6267733002314344, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 243, train_loss = 1.6201590175041929, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 244, train_loss = 1.6137158101191744, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 245, train_loss = 1.6072573872515932, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 246, train_loss = 1.6008977940073237, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 247, train_loss = 1.5946083130547777, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 248, train_loss = 1.5883371978998184, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 249, train_loss = 1.5822444768855348, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 250, train_loss = 1.57624903076794, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 251, train_loss = 1.5702205958077684, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 252, train_loss = 1.5642754869768396, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 253, train_loss = 1.5584103179862723, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 254, train_loss = 1.5526594370603561, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 255, train_loss = 1.5468829659512267, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 256, train_loss = 1.541266292333603, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 257, train_loss = 1.535635175765492, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 258, train_loss = 1.5301286429166794, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 259, train_loss = 1.524636628688313, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 260, train_loss = 1.5192600525915623, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 261, train_loss = 1.513857470243238, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 262, train_loss = 1.5086056286236271, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 263, train_loss = 1.5032706359634176, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 264, train_loss = 1.498122655437328, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 265, train_loss = 1.4930223617702723, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 266, train_loss = 1.487921103835106, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 267, train_loss = 1.4828815758228302, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 268, train_loss = 1.4779139360180125, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 269, train_loss = 1.47296419122722, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 270, train_loss = 1.4681605225196108, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 271, train_loss = 1.463310974300839, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 272, train_loss = 1.4585670890519395, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 273, train_loss = 1.4537178240716457, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 274, train_loss = 1.449153265566565, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 275, train_loss = 1.4444812797009945, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 276, train_loss = 1.439907127409242, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 277, train_loss = 1.435425722389482, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 278, train_loss = 1.43092657008674, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 279, train_loss = 1.4264535555848852, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 280, train_loss = 1.4220497285714373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 281, train_loss = 1.417725327075459, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 282, train_loss = 1.4133326137671247, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 283, train_loss = 1.4091324793407694, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 284, train_loss = 1.4049241481116042, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 285, train_loss = 1.4007321732351556, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 286, train_loss = 1.3965153470635414, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 287, train_loss = 1.3924806267023087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 288, train_loss = 1.388449802994728, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 289, train_loss = 1.3843626864254475, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 290, train_loss = 1.3803645645966753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 291, train_loss = 1.3764125183224678, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 292, train_loss = 1.3724550070473924, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 293, train_loss = 1.368679367005825, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 294, train_loss = 1.3647009892156348, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 295, train_loss = 1.3609644770622253, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 296, train_loss = 1.357086875825189, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 297, train_loss = 1.3534015776822343, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 298, train_loss = 1.3496809540083632, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 299, train_loss = 1.346003013313748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 300, train_loss = 1.3422916842391714, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 301, train_loss = 1.3387097381055355, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 302, train_loss = 1.3350336899165995, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 303, train_loss = 1.3315716025535949, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 304, train_loss = 1.3279694952070713, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 305, train_loss = 1.324597715109121, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 306, train_loss = 1.3210630950634368, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 307, train_loss = 1.3177151356940158, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 308, train_loss = 1.3142143686418422, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 309, train_loss = 1.3108765122597106, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 310, train_loss = 1.3075720543856733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 311, train_loss = 1.3042006616597064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 312, train_loss = 1.3009401696617715, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 313, train_loss = 1.2977380976080894, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 314, train_loss = 1.294481745630037, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 315, train_loss = 1.2912515054340474, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 316, train_loss = 1.2882017108495347, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 317, train_loss = 1.28496302413987, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 318, train_loss = 1.281929214776028, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 319, train_loss = 1.278765941679012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 320, train_loss = 1.275723112106789, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 321, train_loss = 1.2727136015892029, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 322, train_loss = 1.2696806329186074, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 323, train_loss = 1.2667737429146655, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 324, train_loss = 1.2636909559369087, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 325, train_loss = 1.2608051138813607, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 326, train_loss = 1.2579603952472098, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 327, train_loss = 1.254955030977726, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 328, train_loss = 1.2521352755720727, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 329, train_loss = 1.2492579109966755, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 330, train_loss = 1.2464618484373204, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 331, train_loss = 1.2436094979639165, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 332, train_loss = 1.2408960188622586, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 333, train_loss = 1.2381488246028312, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 334, train_loss = 1.2353604597155936, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 335, train_loss = 1.2327543869614601, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 336, train_loss = 1.2300238224561326, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 337, train_loss = 1.2273313477635384, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 338, train_loss = 1.2247265602345578, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 339, train_loss = 1.2220893551711924, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 340, train_loss = 1.2196231447160244, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 341, train_loss = 1.2168190603260882, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 342, train_loss = 1.2143504421110265, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 343, train_loss = 1.2118520376388915, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 344, train_loss = 1.2092333026230335, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 345, train_loss = 1.2067540809512138, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 346, train_loss = 1.204320017248392, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 347, train_loss = 1.2017684007878415, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 348, train_loss = 1.1993713999981992, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 349, train_loss = 1.1969340394134633, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 350, train_loss = 1.194484043866396, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 351, train_loss = 1.192080042033922, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 352, train_loss = 1.1897570652072318, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 353, train_loss = 1.1873129469458945, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 354, train_loss = 1.1849045467679389, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 355, train_loss = 1.182707142084837, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 356, train_loss = 1.1802695033256896, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 357, train_loss = 1.1780273889307864, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 358, train_loss = 1.1756875577266328, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 359, train_loss = 1.1734233808820136, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 360, train_loss = 1.1712126160855405, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 361, train_loss = 1.1689539514482021, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 362, train_loss = 1.1667413388495333, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 363, train_loss = 1.1645710244774818, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "25th- epoch: 364, train_loss = 1.1623546009068377, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 365, train_loss = 1.1601381090586074, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 366, train_loss = 1.1580032234196551, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 367, train_loss = 1.1558158012921922, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 368, train_loss = 1.1538555100560188, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 369, train_loss = 1.1515572008793242, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 370, train_loss = 1.1496684390003793, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 371, train_loss = 1.1474198798532598, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 372, train_loss = 1.145481565326918, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 373, train_loss = 1.1432932441239245, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 374, train_loss = 1.1413987477426417, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 375, train_loss = 1.1392079603974707, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 376, train_loss = 1.1372658659820445, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 377, train_loss = 1.1352598543162458, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 378, train_loss = 1.133317704021465, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 379, train_loss = 1.1313374477322213, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 380, train_loss = 1.1293678085203283, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 381, train_loss = 1.1274105794727802, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 382, train_loss = 1.1256477944552898, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 383, train_loss = 1.1236160956323147, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 384, train_loss = 1.1219031077926047, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 385, train_loss = 1.1198196299374104, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 386, train_loss = 1.1180709339678288, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 387, train_loss = 1.1161030654911883, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 388, train_loss = 1.1142400801181793, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 389, train_loss = 1.112432433932554, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 390, train_loss = 1.1106367620523088, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 391, train_loss = 1.108829905570019, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 392, train_loss = 1.1071451393072493, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 393, train_loss = 1.1051980306510814, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 394, train_loss = 1.1036226724390872, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 395, train_loss = 1.1017434410750866, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 396, train_loss = 1.099991012364626, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 397, train_loss = 1.0981862234766595, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 398, train_loss = 1.096568902314175, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 399, train_loss = 1.0947607320849784, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 400, train_loss = 1.0931504580075853, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 401, train_loss = 1.0913038651342504, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 402, train_loss = 1.0897333398461342, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 403, train_loss = 1.0881676288845483, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 404, train_loss = 1.0863845981657505, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 405, train_loss = 1.0847017193736974, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 406, train_loss = 1.0831680508854333, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 407, train_loss = 1.081465552240843, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 408, train_loss = 1.079874819755787, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 409, train_loss = 1.0782116068003234, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 410, train_loss = 1.0766462882456835, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 411, train_loss = 1.0750825280847494, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 412, train_loss = 1.07355647534132, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 413, train_loss = 1.0719020503165666, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 414, train_loss = 1.0703586861491203, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 415, train_loss = 1.068807739764452, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 416, train_loss = 1.0673368275165558, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 417, train_loss = 1.0656728024187032, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 418, train_loss = 1.0643144051136915, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 419, train_loss = 1.0627396926283836, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 420, train_loss = 1.0611956367793027, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 421, train_loss = 1.059696651995182, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 422, train_loss = 1.0581695934233721, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 423, train_loss = 1.0567563163640443, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 424, train_loss = 1.0552532176079694, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 425, train_loss = 1.0537773010728415, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 426, train_loss = 1.0523629101517145, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 427, train_loss = 1.051016644894844, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 428, train_loss = 1.049432449042797, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 429, train_loss = 1.0480923379363958, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 430, train_loss = 1.0466603586974088, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 431, train_loss = 1.0451892515120562, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 432, train_loss = 1.0437815388140734, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 433, train_loss = 1.0423513390123844, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 434, train_loss = 1.0410772524774075, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 435, train_loss = 1.0396309345960617, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 436, train_loss = 1.0382238999009132, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 437, train_loss = 1.036854720354313, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 438, train_loss = 1.0354384730162565, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 439, train_loss = 1.0341328109207097, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 440, train_loss = 1.0328712897899095, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 441, train_loss = 1.0315376756188925, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 442, train_loss = 1.0301436260342598, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 443, train_loss = 1.0289183917047922, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 444, train_loss = 1.0275655885634478, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 445, train_loss = 1.0262936353683472, train_acc = 0.9981369352585002\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 446, train_loss = 1.024912162363762, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 447, train_loss = 1.0236754044890404, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 448, train_loss = 1.0224941484630108, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 449, train_loss = 1.0210758087632712, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 450, train_loss = 1.0199021448788699, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 451, train_loss = 1.0184979041514453, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 452, train_loss = 1.017275890946621, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 453, train_loss = 1.0161763293144759, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 454, train_loss = 1.014763663202757, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 455, train_loss = 1.0136044161918107, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 456, train_loss = 1.012372363358736, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 457, train_loss = 1.0111166586575564, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 458, train_loss = 1.0099863857030869, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 459, train_loss = 1.008690999209648, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 460, train_loss = 1.007494250923628, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 461, train_loss = 1.0063338428735733, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 462, train_loss = 1.0051314843294676, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 463, train_loss = 1.004010366887087, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 464, train_loss = 1.0027871491911355, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 465, train_loss = 1.001543864607811, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 466, train_loss = 1.000418266892666, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 467, train_loss = 0.9993305442330893, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 468, train_loss = 0.9981725886464119, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 469, train_loss = 0.9969680830836296, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 470, train_loss = 0.9959641123714391, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 471, train_loss = 0.9947222346963827, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 472, train_loss = 0.9936324904265348, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 473, train_loss = 0.9924509587290231, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 474, train_loss = 0.991467796266079, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 475, train_loss = 0.9901835074124392, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 476, train_loss = 0.9891533094050828, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 477, train_loss = 0.9879859983921051, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 478, train_loss = 0.9870263983902987, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 479, train_loss = 0.9858025001885835, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 480, train_loss = 0.9848142427799758, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 481, train_loss = 0.9836159298720304, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 482, train_loss = 0.982638530433178, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 483, train_loss = 0.9815494505164679, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 484, train_loss = 0.9805188663303852, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 485, train_loss = 0.9794911853969097, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 486, train_loss = 0.9783023297786713, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 487, train_loss = 0.9773949024674948, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 488, train_loss = 0.9762753558752593, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 489, train_loss = 0.9752356124517974, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 490, train_loss = 0.9742120938899461, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 491, train_loss = 0.9732181752624456, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 492, train_loss = 0.9722385182976723, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 493, train_loss = 0.9710804422793444, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 494, train_loss = 0.9702691063284874, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 495, train_loss = 0.9691660491225775, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 496, train_loss = 0.9681467277405318, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 497, train_loss = 0.967126302421093, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 498, train_loss = 0.9660905500350054, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 499, train_loss = 0.9652349390089512, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████            | 25/30 [2:51:04<34:22, 412.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "26th- epoch: 0, train_loss = 269.9168654680252, train_acc = 0.44899860270144387\n",
      "test Acc 0.5353817504655494:\n",
      "26th- epoch: 1, train_loss = 209.11950993537903, train_acc = 0.5515836050302748\n",
      "test Acc 0.5698324022346368:\n",
      "26th- epoch: 2, train_loss = 165.97418797016144, train_acc = 0.5745225896599907\n",
      "test Acc 0.5996275605214153:\n",
      "26th- epoch: 3, train_loss = 137.53423529863358, train_acc = 0.6582440614811365\n",
      "test Acc 0.7313780260707635:\n",
      "26th- epoch: 4, train_loss = 117.28207868337631, train_acc = 0.7526781555659059\n",
      "test Acc 0.7760707635009311:\n",
      "26th- epoch: 5, train_loss = 101.48113092780113, train_acc = 0.7729389846297159\n",
      "test Acc 0.7984171322160148:\n",
      "26th- epoch: 6, train_loss = 88.98804607987404, train_acc = 0.7955286446204005\n",
      "test Acc 0.8221601489757915:\n",
      "26th- epoch: 7, train_loss = 79.05081677436829, train_acc = 0.8189333954354914\n",
      "test Acc 0.8375232774674115:\n",
      "26th- epoch: 8, train_loss = 70.75868520140648, train_acc = 0.843735444806707\n",
      "test Acc 0.8566108007448789:\n",
      "26th- epoch: 9, train_loss = 63.49637797474861, train_acc = 0.8706334420121099\n",
      "test Acc 0.8817504655493482:\n",
      "26th- epoch: 10, train_loss = 57.017774522304535, train_acc = 0.8927573358174197\n",
      "test Acc 0.9036312849162011:\n",
      "26th- epoch: 11, train_loss = 51.279110327363014, train_acc = 0.9182580344666977\n",
      "test Acc 0.9283054003724395:\n",
      "26th- epoch: 12, train_loss = 46.266216948628426, train_acc = 0.936655798789008\n",
      "test Acc 0.9366852886405959:\n",
      "26th- epoch: 13, train_loss = 41.93284386396408, train_acc = 0.9436422915696321\n",
      "test Acc 0.9413407821229051:\n",
      "26th- epoch: 14, train_loss = 38.212997779250145, train_acc = 0.9472519795062878\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 15, train_loss = 35.03411852568388, train_acc = 0.9510945505356311\n",
      "test Acc 0.9450651769087524:\n",
      "26th- epoch: 16, train_loss = 32.327947713434696, train_acc = 0.952491849091756\n",
      "test Acc 0.9450651769087524:\n",
      "26th- epoch: 17, train_loss = 30.02326637506485, train_acc = 0.9545877969259432\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 18, train_loss = 28.05338454246521, train_acc = 0.9579646017699115\n",
      "test Acc 0.9534450651769087:\n",
      "26th- epoch: 19, train_loss = 26.360548496246338, train_acc = 0.9613414066138798\n",
      "test Acc 0.957635009310987:\n",
      "26th- epoch: 20, train_loss = 24.896715708076954, train_acc = 0.9648346530041919\n",
      "test Acc 0.9585661080074488:\n",
      "26th- epoch: 21, train_loss = 23.620650809258223, train_acc = 0.9666977177456917\n",
      "test Acc 0.9594972067039106:\n",
      "26th- epoch: 22, train_loss = 22.49914838373661, train_acc = 0.9677456916627852\n",
      "test Acc 0.9608938547486033:\n",
      "26th- epoch: 23, train_loss = 21.505656998604536, train_acc = 0.9693758733115976\n",
      "test Acc 0.9608938547486033:\n",
      "26th- epoch: 24, train_loss = 20.617747884243727, train_acc = 0.9699580810433163\n",
      "test Acc 0.9604283054003724:\n",
      "26th- epoch: 25, train_loss = 19.81766629219055, train_acc = 0.9706567303213787\n",
      "test Acc 0.9608938547486033:\n",
      "26th- epoch: 26, train_loss = 19.091560948640108, train_acc = 0.9711224965067536\n",
      "test Acc 0.9613594040968343:\n",
      "26th- epoch: 27, train_loss = 18.428179401904345, train_acc = 0.9720540288775035\n",
      "test Acc 0.9608938547486033:\n",
      "26th- epoch: 28, train_loss = 17.818970303982496, train_acc = 0.9728691197019096\n",
      "test Acc 0.9608938547486033:\n",
      "26th- epoch: 29, train_loss = 17.255773838609457, train_acc = 0.9731020027945971\n",
      "test Acc 0.9618249534450651:\n",
      "26th- epoch: 30, train_loss = 16.733160246163607, train_acc = 0.9734513274336283\n",
      "test Acc 0.9622905027932961:\n",
      "26th- epoch: 31, train_loss = 16.246643006801605, train_acc = 0.9736842105263158\n",
      "test Acc 0.9622905027932961:\n",
      "26th- epoch: 32, train_loss = 15.79170037433505, train_acc = 0.974033535165347\n",
      "test Acc 0.9632216014897579:\n",
      "26th- epoch: 33, train_loss = 15.364868886768818, train_acc = 0.9744993013507219\n",
      "test Acc 0.9641527001862198:\n",
      "26th- epoch: 34, train_loss = 14.963177189230919, train_acc = 0.9754308337214718\n",
      "test Acc 0.9655493482309124:\n",
      "26th- epoch: 35, train_loss = 14.583937473595142, train_acc = 0.9754308337214718\n",
      "test Acc 0.9655493482309124:\n",
      "26th- epoch: 36, train_loss = 14.224777337163687, train_acc = 0.9756637168141593\n",
      "test Acc 0.9660148975791434:\n",
      "26th- epoch: 37, train_loss = 13.884085714817047, train_acc = 0.9756637168141593\n",
      "test Acc 0.9664804469273743:\n",
      "26th- epoch: 38, train_loss = 13.560154188424349, train_acc = 0.9758965999068467\n",
      "test Acc 0.9664804469273743:\n",
      "26th- epoch: 39, train_loss = 13.251407720148563, train_acc = 0.9760130414531905\n",
      "test Acc 0.9664804469273743:\n",
      "26th- epoch: 40, train_loss = 12.95676688849926, train_acc = 0.9763623660922217\n",
      "test Acc 0.9674115456238361:\n",
      "26th- epoch: 41, train_loss = 12.674377378076315, train_acc = 0.9764788076385654\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 42, train_loss = 12.403597619384527, train_acc = 0.9771774569166278\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 43, train_loss = 12.144311428070068, train_acc = 0.9774103400093154\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 44, train_loss = 11.895569376647472, train_acc = 0.9776432231020028\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 45, train_loss = 11.656583983451128, train_acc = 0.9782254308337215\n",
      "test Acc 0.9688081936685289:\n",
      "26th- epoch: 46, train_loss = 11.426931776106358, train_acc = 0.9786911970190965\n",
      "test Acc 0.9688081936685289:\n",
      "26th- epoch: 47, train_loss = 11.205605156719685, train_acc = 0.9792734047508151\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 48, train_loss = 10.992086183279753, train_acc = 0.97973917093619\n",
      "test Acc 0.9697392923649907:\n",
      "26th- epoch: 49, train_loss = 10.785881951451302, train_acc = 0.9798556124825337\n",
      "test Acc 0.9697392923649907:\n",
      "26th- epoch: 50, train_loss = 10.586605045944452, train_acc = 0.9803213786679087\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 51, train_loss = 10.393987327814102, train_acc = 0.9805542617605962\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 52, train_loss = 10.207514993846416, train_acc = 0.9809035863996274\n",
      "test Acc 0.9706703910614525:\n",
      "26th- epoch: 53, train_loss = 10.026954092085361, train_acc = 0.9814857941313461\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 54, train_loss = 9.851897474378347, train_acc = 0.9817186772240335\n",
      "test Acc 0.9720670391061452:\n",
      "26th- epoch: 55, train_loss = 9.682186968624592, train_acc = 0.9818351187703773\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 56, train_loss = 9.51737436838448, train_acc = 0.9820680018630648\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 57, train_loss = 9.357252592220902, train_acc = 0.9824173265020959\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 58, train_loss = 9.201648255810142, train_acc = 0.9827666511411272\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 59, train_loss = 9.050535345450044, train_acc = 0.9829995342338146\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 60, train_loss = 8.903509614989161, train_acc = 0.9835817419655333\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 61, train_loss = 8.76039419323206, train_acc = 0.9839310666045645\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 62, train_loss = 8.620787465944886, train_acc = 0.984163949697252\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 63, train_loss = 8.484601940959692, train_acc = 0.9842803912435957\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 64, train_loss = 8.351858610287309, train_acc = 0.9845132743362832\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 65, train_loss = 8.222441906109452, train_acc = 0.9848625989753144\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 66, train_loss = 8.096184199675918, train_acc = 0.9848625989753144\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 67, train_loss = 7.973105728626251, train_acc = 0.9848625989753144\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 68, train_loss = 7.852772269397974, train_acc = 0.9850954820680019\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 69, train_loss = 7.7351957112550735, train_acc = 0.9850954820680019\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 70, train_loss = 7.620199529454112, train_acc = 0.985444806707033\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 71, train_loss = 7.507703702896833, train_acc = 0.9856776897997206\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 72, train_loss = 7.3977424595505, train_acc = 0.9856776897997206\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 73, train_loss = 7.290121929720044, train_acc = 0.9857941313460643\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 74, train_loss = 7.184899622574449, train_acc = 0.985910572892408\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 75, train_loss = 7.081692274659872, train_acc = 0.9864927806241267\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 76, train_loss = 6.980818180367351, train_acc = 0.9867256637168141\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 77, train_loss = 6.882025117054582, train_acc = 0.9868421052631579\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 78, train_loss = 6.785267915576696, train_acc = 0.9869585468095017\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 79, train_loss = 6.690527159720659, train_acc = 0.9869585468095017\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 80, train_loss = 6.597542790696025, train_acc = 0.9871914299021891\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 81, train_loss = 6.506561057642102, train_acc = 0.9876571960875641\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 82, train_loss = 6.417139321565628, train_acc = 0.9878900791802515\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 83, train_loss = 6.329484166577458, train_acc = 0.9880065207265952\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 84, train_loss = 6.2436016369611025, train_acc = 0.9883558453656265\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 85, train_loss = 6.159192143008113, train_acc = 0.9883558453656265\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 86, train_loss = 6.076511742547154, train_acc = 0.9887051700046576\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 87, train_loss = 5.995350707322359, train_acc = 0.9890544946436889\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 88, train_loss = 5.9157451428473, train_acc = 0.9892873777363763\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 89, train_loss = 5.837579531595111, train_acc = 0.9896367023754076\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 90, train_loss = 5.760871992446482, train_acc = 0.9897531439217513\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 91, train_loss = 5.685601525940001, train_acc = 0.9899860270144387\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 92, train_loss = 5.611626673489809, train_acc = 0.9901024685607824\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 93, train_loss = 5.539074313826859, train_acc = 0.9902189101071263\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 94, train_loss = 5.467802808620036, train_acc = 0.99033535165347\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 95, train_loss = 5.397734425030649, train_acc = 0.9906846762925011\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 96, train_loss = 5.328918105922639, train_acc = 0.9905682347461574\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 97, train_loss = 5.261486803181469, train_acc = 0.9906846762925011\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 98, train_loss = 5.1951187225058675, train_acc = 0.9906846762925011\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 99, train_loss = 5.1298698624596, train_acc = 0.990801117838845\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 100, train_loss = 5.06601067725569, train_acc = 0.990801117838845\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 101, train_loss = 5.003089677542448, train_acc = 0.9909175593851887\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 102, train_loss = 4.941093919798732, train_acc = 0.9910340009315324\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 103, train_loss = 4.880507533438504, train_acc = 0.9911504424778761\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 104, train_loss = 4.820795954205096, train_acc = 0.9912668840242198\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 105, train_loss = 4.762213482521474, train_acc = 0.9912668840242198\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 106, train_loss = 4.704638653434813, train_acc = 0.9916162086632511\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 107, train_loss = 4.648224710486829, train_acc = 0.9917326502095948\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 108, train_loss = 4.592686139978468, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "26th- epoch: 109, train_loss = 4.538245097734034, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "26th- epoch: 110, train_loss = 4.484612883999944, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "26th- epoch: 111, train_loss = 4.432122920639813, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 112, train_loss = 4.3803742518648505, train_acc = 0.992081974848626\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 113, train_loss = 4.329694236628711, train_acc = 0.992081974848626\n",
      "test Acc 0.9818435754189944:\n",
      "26th- epoch: 114, train_loss = 4.279919697903097, train_acc = 0.9921984163949698\n",
      "test Acc 0.9818435754189944:\n",
      "26th- epoch: 115, train_loss = 4.231097294948995, train_acc = 0.9924312994876572\n",
      "test Acc 0.9818435754189944:\n",
      "26th- epoch: 116, train_loss = 4.183007880114019, train_acc = 0.9925477410340009\n",
      "test Acc 0.9818435754189944:\n",
      "26th- epoch: 117, train_loss = 4.135847714729607, train_acc = 0.9926641825803446\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 118, train_loss = 4.089431218802929, train_acc = 0.9926641825803446\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 119, train_loss = 4.043864757753909, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 120, train_loss = 3.9990684362128377, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 121, train_loss = 3.955299607478082, train_acc = 0.9930135072193759\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 122, train_loss = 3.912024376913905, train_acc = 0.9931299487657196\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 123, train_loss = 3.869722525589168, train_acc = 0.9931299487657196\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 124, train_loss = 3.828134624287486, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 125, train_loss = 3.7872820189222693, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 126, train_loss = 3.747138848528266, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 127, train_loss = 3.7077988274395466, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 128, train_loss = 3.6689551305025816, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 129, train_loss = 3.631091073155403, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 130, train_loss = 3.593614261597395, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 131, train_loss = 3.5570363737642765, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 132, train_loss = 3.520874029956758, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 133, train_loss = 3.485470856539905, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 134, train_loss = 3.450545737054199, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 135, train_loss = 3.4161517173051834, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 136, train_loss = 3.3825079891830683, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 137, train_loss = 3.3492841911502182, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 138, train_loss = 3.316820724401623, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 139, train_loss = 3.2845701831392944, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 140, train_loss = 3.253170659765601, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 141, train_loss = 3.2222236837260425, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 142, train_loss = 3.191856857854873, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 143, train_loss = 3.161796727683395, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 144, train_loss = 3.132631042506546, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 145, train_loss = 3.1035072249360383, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 146, train_loss = 3.075303554069251, train_acc = 0.9952258965999069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 147, train_loss = 3.0471932203508914, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 148, train_loss = 3.0198247004300356, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 149, train_loss = 2.992708877194673, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 150, train_loss = 2.9661845485679805, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 151, train_loss = 2.9399898587726057, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 152, train_loss = 2.9142781998962164, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 153, train_loss = 2.888918276876211, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 154, train_loss = 2.864081705454737, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 155, train_loss = 2.8395511470735073, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 156, train_loss = 2.8154634279198945, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 157, train_loss = 2.7916989945806563, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 158, train_loss = 2.7683641486801207, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 159, train_loss = 2.745444899890572, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 160, train_loss = 2.722884173039347, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 161, train_loss = 2.7006165483035147, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 162, train_loss = 2.6788472631014884, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 163, train_loss = 2.6573291420936584, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 164, train_loss = 2.6361599885858595, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 165, train_loss = 2.615298042073846, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 166, train_loss = 2.5947018954902887, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 167, train_loss = 2.574547926429659, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 168, train_loss = 2.5545964408665895, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 169, train_loss = 2.535093668382615, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 170, train_loss = 2.515766752883792, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 171, train_loss = 2.496904782485217, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 172, train_loss = 2.4781205262988806, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 173, train_loss = 2.4597014375030994, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 174, train_loss = 2.4414819735102355, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 175, train_loss = 2.4236351954750717, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 176, train_loss = 2.4059221860952675, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 177, train_loss = 2.3884576936252415, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 178, train_loss = 2.371307934168726, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 179, train_loss = 2.3544066729955375, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 180, train_loss = 2.337786002550274, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 181, train_loss = 2.321412780787796, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 182, train_loss = 2.3052816302515566, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 183, train_loss = 2.2894133497029543, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 184, train_loss = 2.273771658539772, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 185, train_loss = 2.2582603748887777, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 186, train_loss = 2.2431820314377546, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 187, train_loss = 2.228184349834919, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 188, train_loss = 2.2133948858827353, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 189, train_loss = 2.1988371137995273, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 190, train_loss = 2.184437232092023, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 191, train_loss = 2.1702306114602834, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 192, train_loss = 2.1563733729999512, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 193, train_loss = 2.142535099061206, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 194, train_loss = 2.128911628620699, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 195, train_loss = 2.1155663176905364, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 196, train_loss = 2.102317205397412, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 197, train_loss = 2.0892966836690903, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 198, train_loss = 2.0765378053765744, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 199, train_loss = 2.063826075522229, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 200, train_loss = 2.051276649115607, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 201, train_loss = 2.039020153461024, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 202, train_loss = 2.0269251689314842, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 203, train_loss = 2.0149306517560035, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 204, train_loss = 2.0030252437572926, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 205, train_loss = 1.9915318328421563, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 206, train_loss = 1.9799141138792038, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 207, train_loss = 1.968513323692605, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 208, train_loss = 1.9574634011369199, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 209, train_loss = 1.9462634071242064, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 210, train_loss = 1.9353590346872807, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 211, train_loss = 1.9246465265750885, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 212, train_loss = 1.9138955473899841, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 213, train_loss = 1.9034556336700916, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 214, train_loss = 1.8930869463365525, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 215, train_loss = 1.8827635708730668, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 216, train_loss = 1.872758026001975, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 217, train_loss = 1.8626686695497483, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 218, train_loss = 1.8528124131262302, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 219, train_loss = 1.8431700095534325, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 220, train_loss = 1.833504156442359, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 221, train_loss = 1.823974299011752, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 222, train_loss = 1.8146825842559338, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 223, train_loss = 1.805460948497057, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 224, train_loss = 1.7963334370870143, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 225, train_loss = 1.7874129239935428, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 226, train_loss = 1.7785206835251302, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 227, train_loss = 1.7698212775867432, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 228, train_loss = 1.7611568521242589, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 229, train_loss = 1.7528063282370567, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 230, train_loss = 1.744273864896968, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 231, train_loss = 1.7359909762162715, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 232, train_loss = 1.7278881159145385, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 233, train_loss = 1.7198117475491017, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 234, train_loss = 1.7118483409285545, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 235, train_loss = 1.704055142821744, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 236, train_loss = 1.6961712781339884, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 237, train_loss = 1.68859451264143, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 238, train_loss = 1.6810186442453414, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 239, train_loss = 1.6735872389981523, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 240, train_loss = 1.666217315942049, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 241, train_loss = 1.658913865685463, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 242, train_loss = 1.651771298260428, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 243, train_loss = 1.6446906980127096, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 244, train_loss = 1.6377249726792797, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 245, train_loss = 1.6307664742926136, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 246, train_loss = 1.623981557204388, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 247, train_loss = 1.6173006811877713, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 248, train_loss = 1.6105374532053247, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 249, train_loss = 1.604096818715334, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 250, train_loss = 1.597592749982141, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 251, train_loss = 1.5912276854505762, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 252, train_loss = 1.5848891660571098, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 253, train_loss = 1.5787116078427061, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 254, train_loss = 1.5724530132720247, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 255, train_loss = 1.5664784634718671, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 256, train_loss = 1.560448837815784, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 257, train_loss = 1.5544933913042769, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 258, train_loss = 1.548692217678763, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 259, train_loss = 1.5427696282276884, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 260, train_loss = 1.5371646831044927, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 261, train_loss = 1.531418158323504, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 262, train_loss = 1.525884515256621, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 263, train_loss = 1.5202927315840498, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 264, train_loss = 1.514868271886371, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 265, train_loss = 1.5094781903317198, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 266, train_loss = 1.5040945522487164, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 267, train_loss = 1.4989070469746366, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 268, train_loss = 1.493525356054306, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 269, train_loss = 1.4885470172157511, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 270, train_loss = 1.4832699286052957, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 271, train_loss = 1.478381602675654, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 272, train_loss = 1.4732500910758972, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 273, train_loss = 1.4684211587300524, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 274, train_loss = 1.463430063216947, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 275, train_loss = 1.4587092647561803, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 276, train_loss = 1.4538179077208042, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 277, train_loss = 1.4491833025822416, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 278, train_loss = 1.4443891433766112, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 279, train_loss = 1.4398475252091885, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 280, train_loss = 1.435200985521078, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 281, train_loss = 1.4307509759673849, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 282, train_loss = 1.4262201065430418, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 283, train_loss = 1.4217255674302578, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 284, train_loss = 1.4174128621816635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 285, train_loss = 1.4130715964129195, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 286, train_loss = 1.40878778451588, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 287, train_loss = 1.4044871343066916, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 288, train_loss = 1.4003214103868231, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 289, train_loss = 1.396088489680551, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 290, train_loss = 1.3920386210083961, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 291, train_loss = 1.3878705389797688, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 292, train_loss = 1.383871910511516, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 293, train_loss = 1.3798252319684252, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 294, train_loss = 1.375904317945242, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 295, train_loss = 1.3718887517461553, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 296, train_loss = 1.3680373281240463, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 297, train_loss = 1.364156490773894, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 298, train_loss = 1.3603739166865125, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 299, train_loss = 1.3565620543668047, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 300, train_loss = 1.3528511548647657, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 301, train_loss = 1.3490786962211132, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 302, train_loss = 1.3454486764967442, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 303, train_loss = 1.3417449319968, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 304, train_loss = 1.3381584361195564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 305, train_loss = 1.3345302765956149, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 306, train_loss = 1.331034722388722, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 307, train_loss = 1.3274514687946066, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 308, train_loss = 1.3240408723358996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 309, train_loss = 1.320492185652256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 310, train_loss = 1.3171448062057607, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 311, train_loss = 1.3137235678732395, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 312, train_loss = 1.310382938652765, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 313, train_loss = 1.3070359056000598, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 314, train_loss = 1.3037808599765413, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 315, train_loss = 1.3004387741093524, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 316, train_loss = 1.297237228602171, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 317, train_loss = 1.2940010105376132, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 318, train_loss = 1.2908325642347336, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 319, train_loss = 1.287695071368944, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 320, train_loss = 1.2845490910112858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 321, train_loss = 1.2813457027077675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 322, train_loss = 1.2783377679879777, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 323, train_loss = 1.2752983669633977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 324, train_loss = 1.2722860872745514, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 325, train_loss = 1.2692348659038544, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 326, train_loss = 1.2662776559591293, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 327, train_loss = 1.2632463313639164, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 328, train_loss = 1.2603799079661258, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 329, train_loss = 1.2573558054864407, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 330, train_loss = 1.2544985922868364, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 331, train_loss = 1.251653881103266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 332, train_loss = 1.2487797091598623, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 333, train_loss = 1.246024516702164, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 334, train_loss = 1.2431389068369754, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 335, train_loss = 1.24046128988266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 336, train_loss = 1.2377119449083693, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 337, train_loss = 1.2348695695400238, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 338, train_loss = 1.2322866059839725, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 339, train_loss = 1.2294956247205846, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 340, train_loss = 1.2269192188978195, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 341, train_loss = 1.2242061284487136, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 342, train_loss = 1.221639213443268, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 343, train_loss = 1.219010899483692, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 344, train_loss = 1.216419554024469, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 345, train_loss = 1.2138765566051006, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 346, train_loss = 1.2113183314795606, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 347, train_loss = 1.2088014744222164, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 348, train_loss = 1.2063648154144175, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 349, train_loss = 1.203776303678751, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 350, train_loss = 1.2014567976002581, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 351, train_loss = 1.1989334362442605, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 352, train_loss = 1.1965272960369475, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 353, train_loss = 1.1941471683676355, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 354, train_loss = 1.1917125706677325, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 355, train_loss = 1.189440242946148, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 356, train_loss = 1.1870057818596251, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 357, train_loss = 1.1846597827970982, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 358, train_loss = 1.1824177292292006, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 359, train_loss = 1.180040477483999, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 360, train_loss = 1.1778940198128112, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 361, train_loss = 1.1755863353610039, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 362, train_loss = 1.1733986784820445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 363, train_loss = 1.1710852272808552, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 364, train_loss = 1.1689773127436638, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 365, train_loss = 1.1667074002325535, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 366, train_loss = 1.1645399046246894, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 367, train_loss = 1.1623102736775763, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 368, train_loss = 1.1602488185162656, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 369, train_loss = 1.1580263140494935, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 370, train_loss = 1.1559820758993737, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 371, train_loss = 1.1538011580705643, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 372, train_loss = 1.151778710365761, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 373, train_loss = 1.1496498547494411, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 374, train_loss = 1.1476495514507405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 375, train_loss = 1.1455604955554008, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 376, train_loss = 1.1435649233753793, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 377, train_loss = 1.1414742693305016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 378, train_loss = 1.13956805691123, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 379, train_loss = 1.137442262202967, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 380, train_loss = 1.135556474328041, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 381, train_loss = 1.1334824785590172, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 382, train_loss = 1.1316498890519142, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 383, train_loss = 1.1296727880835533, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 384, train_loss = 1.127763585478533, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 385, train_loss = 1.1258418075740337, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 386, train_loss = 1.1239417257602327, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 387, train_loss = 1.122029433667194, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 388, train_loss = 1.1202847274835221, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 389, train_loss = 1.1182699762284756, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 390, train_loss = 1.116518014401663, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 391, train_loss = 1.1145807703142054, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 392, train_loss = 1.1127929650247097, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 393, train_loss = 1.1110015933518298, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 394, train_loss = 1.1093144242768176, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 395, train_loss = 1.107396391511429, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 396, train_loss = 1.1056419859523885, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 397, train_loss = 1.1038329787552357, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 398, train_loss = 1.1020773624186404, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 399, train_loss = 1.1004004130954854, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 400, train_loss = 1.0986143251066096, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 401, train_loss = 1.096920508891344, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 402, train_loss = 1.095156194001902, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 403, train_loss = 1.0935211752657779, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 404, train_loss = 1.0917589242453687, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 405, train_loss = 1.0901394697721116, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 406, train_loss = 1.08841546747135, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 407, train_loss = 1.0868637772800867, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 408, train_loss = 1.08511677509523, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 409, train_loss = 1.083539026469225, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 410, train_loss = 1.081879511475563, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 411, train_loss = 1.080205978214508, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 412, train_loss = 1.0785706800816115, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 413, train_loss = 1.0770393870770931, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 414, train_loss = 1.075405329465866, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 415, train_loss = 1.0738949216902256, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 416, train_loss = 1.0722804429533426, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 417, train_loss = 1.0706944055855274, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 418, train_loss = 1.0690822986362036, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 419, train_loss = 1.0676484766008798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 420, train_loss = 1.0660749413073063, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 421, train_loss = 1.0645854373869952, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 422, train_loss = 1.0630427300930023, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 423, train_loss = 1.0614439199271146, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 424, train_loss = 1.0599452046153601, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 425, train_loss = 1.0584996653196868, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 426, train_loss = 1.0570365501043852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 427, train_loss = 1.0554682277143002, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 428, train_loss = 1.0540963473322336, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 429, train_loss = 1.052600409835577, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 430, train_loss = 1.0511990611848887, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 431, train_loss = 1.049692776054144, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 432, train_loss = 1.0482334146799985, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 433, train_loss = 1.0469533105788287, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 434, train_loss = 1.0453203494253103, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 435, train_loss = 1.0441341884434223, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 436, train_loss = 1.0425850836036261, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 437, train_loss = 1.0412804000079632, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 438, train_loss = 1.0397997250256594, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 439, train_loss = 1.0385331436991692, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 440, train_loss = 1.0370898669061717, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 441, train_loss = 1.0358562891779002, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 442, train_loss = 1.0343437604606152, train_acc = 0.9979040521658128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 443, train_loss = 1.0331486128270626, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 444, train_loss = 1.0317143636348192, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 445, train_loss = 1.0304208559391554, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 446, train_loss = 1.0290628112852573, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 447, train_loss = 1.0278031291963998, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 448, train_loss = 1.0264810360968113, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 449, train_loss = 1.0251728159782942, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 450, train_loss = 1.0238118879497051, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 451, train_loss = 1.022597006201977, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 452, train_loss = 1.0213200946745928, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 453, train_loss = 1.0201131825742777, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 454, train_loss = 1.0187383741140366, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 455, train_loss = 1.0174734095635358, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 456, train_loss = 1.016222028672928, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 457, train_loss = 1.015052419155836, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 458, train_loss = 1.0137693335709628, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 459, train_loss = 1.012548290193081, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 460, train_loss = 1.0112610509095248, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 461, train_loss = 1.0100909223256167, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 462, train_loss = 1.0088452672061976, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 463, train_loss = 1.0077470180985983, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 464, train_loss = 1.0064770951867104, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 465, train_loss = 1.005332058906788, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 466, train_loss = 1.0040779250266496, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 467, train_loss = 1.002942937106127, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 468, train_loss = 1.0016672077181283, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 469, train_loss = 1.0006615979073104, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 470, train_loss = 0.9993280606868211, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 471, train_loss = 0.9982503292558249, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 472, train_loss = 0.9970970253052656, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 473, train_loss = 0.9959757464530412, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 474, train_loss = 0.9947810309531633, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 475, train_loss = 0.9937931820750237, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 476, train_loss = 0.9925059477391187, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 477, train_loss = 0.9915158823132515, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 478, train_loss = 0.9902984897198621, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 479, train_loss = 0.9893110456469003, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 480, train_loss = 0.988053490727907, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 481, train_loss = 0.9870578845439013, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 482, train_loss = 0.9859227612614632, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 483, train_loss = 0.9849067417380866, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 484, train_loss = 0.9837060458958149, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 485, train_loss = 0.9827416812477168, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 486, train_loss = 0.9816489927470684, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 487, train_loss = 0.9806104140880052, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 488, train_loss = 0.9794830083847046, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 489, train_loss = 0.9784224902687129, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 490, train_loss = 0.9773815659282263, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 491, train_loss = 0.9763587763009127, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 492, train_loss = 0.9753111563622952, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 493, train_loss = 0.9743079332110938, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 494, train_loss = 0.9732650965452194, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 495, train_loss = 0.9722585591080133, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 496, train_loss = 0.9711411831376608, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 497, train_loss = 0.9701743399200495, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 498, train_loss = 0.9690846676530782, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 499, train_loss = 0.9682298017141875, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|██████████████████████████████████████████████████████████████▍         | 26/30 [2:57:55<27:27, 411.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "27th- epoch: 0, train_loss = 273.9934756755829, train_acc = 0.4231485794131346\n",
      "test Acc 0.5405027932960894:\n",
      "27th- epoch: 1, train_loss = 213.84843969345093, train_acc = 0.5407545412203074\n",
      "test Acc 0.5642458100558659:\n",
      "27th- epoch: 2, train_loss = 166.44849628210068, train_acc = 0.5730088495575221\n",
      "test Acc 0.5879888268156425:\n",
      "27th- epoch: 3, train_loss = 138.69827526807785, train_acc = 0.6441546343735445\n",
      "test Acc 0.7136871508379888:\n",
      "27th- epoch: 4, train_loss = 118.5055639743805, train_acc = 0.745575221238938\n",
      "test Acc 0.777001862197393:\n",
      "27th- epoch: 5, train_loss = 102.40687447786331, train_acc = 0.7711923614345598\n",
      "test Acc 0.7853817504655494:\n",
      "27th- epoch: 6, train_loss = 89.2821823656559, train_acc = 0.7853982300884956\n",
      "test Acc 0.8147113594040968:\n",
      "27th- epoch: 7, train_loss = 78.58857214450836, train_acc = 0.8245225896599907\n",
      "test Acc 0.8552141527001862:\n",
      "27th- epoch: 8, train_loss = 69.6372158229351, train_acc = 0.8651606893339544\n",
      "test Acc 0.8794227188081937:\n",
      "27th- epoch: 9, train_loss = 61.929829835891724, train_acc = 0.8910107126222636\n",
      "test Acc 0.9003724394785847:\n",
      "27th- epoch: 10, train_loss = 55.26162724196911, train_acc = 0.9052165812761993\n",
      "test Acc 0.914804469273743:\n",
      "27th- epoch: 11, train_loss = 49.56546075642109, train_acc = 0.9144154634373545\n",
      "test Acc 0.9222532588454376:\n",
      "27th- epoch: 12, train_loss = 44.73826804757118, train_acc = 0.9250116441546343\n",
      "test Acc 0.9329608938547486:\n",
      "27th- epoch: 13, train_loss = 40.64856143295765, train_acc = 0.9388681881695389\n",
      "test Acc 0.9408752327746741:\n",
      "27th- epoch: 14, train_loss = 37.17294329404831, train_acc = 0.9466697717745691\n",
      "test Acc 0.9422718808193669:\n",
      "27th- epoch: 15, train_loss = 34.20823336392641, train_acc = 0.9492314857941313\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 16, train_loss = 31.674013137817383, train_acc = 0.9514438751746623\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 17, train_loss = 29.50030328333378, train_acc = 0.9544713553795995\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 18, train_loss = 27.63145510107279, train_acc = 0.9581974848625989\n",
      "test Acc 0.9511173184357542:\n",
      "27th- epoch: 19, train_loss = 26.017175897955894, train_acc = 0.9601769911504425\n",
      "test Acc 0.9543761638733705:\n",
      "27th- epoch: 20, train_loss = 24.612052261829376, train_acc = 0.9633209129017233\n",
      "test Acc 0.9590316573556797:\n",
      "27th- epoch: 21, train_loss = 23.380067195743322, train_acc = 0.965649743828598\n",
      "test Acc 0.9594972067039106:\n",
      "27th- epoch: 22, train_loss = 22.29189831018448, train_acc = 0.9670470423847228\n",
      "test Acc 0.9599627560521415:\n",
      "27th- epoch: 23, train_loss = 21.322703897953033, train_acc = 0.9678621332091291\n",
      "test Acc 0.9604283054003724:\n",
      "27th- epoch: 24, train_loss = 20.453620590269566, train_acc = 0.9683278993945039\n",
      "test Acc 0.9608938547486033:\n",
      "27th- epoch: 25, train_loss = 19.668350405991077, train_acc = 0.9690265486725663\n",
      "test Acc 0.9613594040968343:\n",
      "27th- epoch: 26, train_loss = 18.954556111246347, train_acc = 0.9697251979506288\n",
      "test Acc 0.962756052141527:\n",
      "27th- epoch: 27, train_loss = 18.302036944776773, train_acc = 0.9704238472286912\n",
      "test Acc 0.9641527001862198:\n",
      "27th- epoch: 28, train_loss = 17.70161011442542, train_acc = 0.9707731718677224\n",
      "test Acc 0.9641527001862198:\n",
      "27th- epoch: 29, train_loss = 17.14593706279993, train_acc = 0.9712389380530974\n",
      "test Acc 0.9650837988826816:\n",
      "27th- epoch: 30, train_loss = 16.62997544556856, train_acc = 0.9717047042384723\n",
      "test Acc 0.9655493482309124:\n",
      "27th- epoch: 31, train_loss = 16.149192605167627, train_acc = 0.9725197950628784\n",
      "test Acc 0.9655493482309124:\n",
      "27th- epoch: 32, train_loss = 15.70005876943469, train_acc = 0.9732184443409408\n",
      "test Acc 0.9660148975791434:\n",
      "27th- epoch: 33, train_loss = 15.278189577162266, train_acc = 0.9732184443409408\n",
      "test Acc 0.9664804469273743:\n",
      "27th- epoch: 34, train_loss = 14.88076452538371, train_acc = 0.9738006520726595\n",
      "test Acc 0.9669459962756052:\n",
      "27th- epoch: 35, train_loss = 14.505293440073729, train_acc = 0.9741499767116907\n",
      "test Acc 0.9674115456238361:\n",
      "27th- epoch: 36, train_loss = 14.149893179535866, train_acc = 0.9744993013507219\n",
      "test Acc 0.9674115456238361:\n",
      "27th- epoch: 37, train_loss = 13.812991425395012, train_acc = 0.9750815090824406\n",
      "test Acc 0.9678770949720671:\n",
      "27th- epoch: 38, train_loss = 13.492874994874, train_acc = 0.9756637168141593\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 39, train_loss = 13.188188306987286, train_acc = 0.975780158360503\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 40, train_loss = 12.897628638893366, train_acc = 0.9761294829995343\n",
      "test Acc 0.9688081936685289:\n",
      "27th- epoch: 41, train_loss = 12.620167773216963, train_acc = 0.9765952491849091\n",
      "test Acc 0.9688081936685289:\n",
      "27th- epoch: 42, train_loss = 12.354583818465471, train_acc = 0.9772938984629715\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 43, train_loss = 12.100131314247847, train_acc = 0.9778761061946902\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 44, train_loss = 11.855826165527105, train_acc = 0.9785747554727526\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 45, train_loss = 11.621181707829237, train_acc = 0.9789240801117839\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 46, train_loss = 11.39539135247469, train_acc = 0.9792734047508151\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 47, train_loss = 11.177891286090016, train_acc = 0.97973917093619\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 48, train_loss = 10.968286164104939, train_acc = 0.9800884955752213\n",
      "test Acc 0.9706703910614525:\n",
      "27th- epoch: 49, train_loss = 10.765654750168324, train_acc = 0.980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 50, train_loss = 10.569841919466853, train_acc = 0.9804378202142524\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 51, train_loss = 10.380172407254577, train_acc = 0.98067070330694\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 52, train_loss = 10.196378884837031, train_acc = 0.9810200279459711\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 53, train_loss = 10.018420604988933, train_acc = 0.9813693525850024\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 54, train_loss = 9.846086485311389, train_acc = 0.9814857941313461\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 55, train_loss = 9.67886921390891, train_acc = 0.9816022356776898\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 56, train_loss = 9.516375496983528, train_acc = 0.9817186772240335\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 57, train_loss = 9.35870262235403, train_acc = 0.9820680018630648\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 58, train_loss = 9.205362735316157, train_acc = 0.9823008849557522\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 59, train_loss = 9.055999645963311, train_acc = 0.9825337680484397\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 60, train_loss = 8.9108348749578, train_acc = 0.9827666511411272\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 61, train_loss = 8.76940830796957, train_acc = 0.9827666511411272\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 62, train_loss = 8.631793769076467, train_acc = 0.9831159757801584\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 63, train_loss = 8.497597264125943, train_acc = 0.9834653004191896\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 64, train_loss = 8.366714717820287, train_acc = 0.983698183511877\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 65, train_loss = 8.23902596719563, train_acc = 0.9839310666045645\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 66, train_loss = 8.114532202482224, train_acc = 0.9842803912435957\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 67, train_loss = 7.99298195913434, train_acc = 0.9843968327899395\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 68, train_loss = 7.8742532934993505, train_acc = 0.9845132743362832\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 69, train_loss = 7.758281152695417, train_acc = 0.9849790405216581\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 70, train_loss = 7.644847862422466, train_acc = 0.9852119236143456\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 71, train_loss = 7.533938646316528, train_acc = 0.9853283651606893\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 72, train_loss = 7.425453899428248, train_acc = 0.9855612482533768\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 73, train_loss = 7.319316456094384, train_acc = 0.9857941313460643\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 74, train_loss = 7.215590363368392, train_acc = 0.985910572892408\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 75, train_loss = 7.1139922067523, train_acc = 0.986376339077783\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 76, train_loss = 7.014667080715299, train_acc = 0.9866092221704704\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 77, train_loss = 6.917365416884422, train_acc = 0.9866092221704704\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 78, train_loss = 6.822108956053853, train_acc = 0.9867256637168141\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 79, train_loss = 6.72860374301672, train_acc = 0.9869585468095017\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 80, train_loss = 6.637011395767331, train_acc = 0.9869585468095017\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 81, train_loss = 6.54716176725924, train_acc = 0.9871914299021891\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 82, train_loss = 6.459173953160644, train_acc = 0.9877736376339078\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 83, train_loss = 6.372720479033887, train_acc = 0.9880065207265952\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 84, train_loss = 6.288102419115603, train_acc = 0.9882394038192828\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 85, train_loss = 6.204906585626304, train_acc = 0.9882394038192828\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 86, train_loss = 6.123379397206008, train_acc = 0.9883558453656265\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 87, train_loss = 6.043178595602512, train_acc = 0.9884722869119702\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 88, train_loss = 5.9645130187273026, train_acc = 0.9885887284583139\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 89, train_loss = 5.887232438661158, train_acc = 0.9889380530973452\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 90, train_loss = 5.811429551802576, train_acc = 0.9889380530973452\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 91, train_loss = 5.73686817009002, train_acc = 0.9891709361900326\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 92, train_loss = 5.663571757264435, train_acc = 0.989869585468095\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 93, train_loss = 5.591575024649501, train_acc = 0.9899860270144387\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 94, train_loss = 5.520674316212535, train_acc = 0.9901024685607824\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 95, train_loss = 5.451115785166621, train_acc = 0.9904517931998137\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 96, train_loss = 5.382658242247999, train_acc = 0.9904517931998137\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 97, train_loss = 5.31543402839452, train_acc = 0.99033535165347\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 98, train_loss = 5.249420112930238, train_acc = 0.99033535165347\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 99, train_loss = 5.184337061829865, train_acc = 0.9905682347461574\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 100, train_loss = 5.120473052375019, train_acc = 0.990801117838845\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 101, train_loss = 5.057651617564261, train_acc = 0.9909175593851887\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 102, train_loss = 4.995721215382218, train_acc = 0.9909175593851887\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 103, train_loss = 4.9348596362397075, train_acc = 0.9910340009315324\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 104, train_loss = 4.874977505765855, train_acc = 0.9909175593851887\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 105, train_loss = 4.816127384081483, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 106, train_loss = 4.7581456219777465, train_acc = 0.9910340009315324\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 107, train_loss = 4.70118423551321, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 108, train_loss = 4.645165469497442, train_acc = 0.9917326502095948\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 109, train_loss = 4.589954307302833, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "27th- epoch: 110, train_loss = 4.535679790191352, train_acc = 0.9919655333022822\n",
      "test Acc 0.9823091247672253:\n",
      "27th- epoch: 111, train_loss = 4.482219467870891, train_acc = 0.992081974848626\n",
      "test Acc 0.9823091247672253:\n",
      "27th- epoch: 112, train_loss = 4.429500144906342, train_acc = 0.9923148579413135\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 113, train_loss = 4.377962370403111, train_acc = 0.9923148579413135\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 114, train_loss = 4.326992742717266, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 115, train_loss = 4.277022757567465, train_acc = 0.9924312994876572\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 116, train_loss = 4.22780682425946, train_acc = 0.9924312994876572\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 117, train_loss = 4.179441384971142, train_acc = 0.9924312994876572\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 118, train_loss = 4.131866660900414, train_acc = 0.9924312994876572\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 119, train_loss = 4.085021209903061, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 120, train_loss = 4.039043001830578, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 121, train_loss = 3.9936563819646835, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 122, train_loss = 3.9491965156048536, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 123, train_loss = 3.905222410336137, train_acc = 0.9928970656730322\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 124, train_loss = 3.8620384531095624, train_acc = 0.9928970656730322\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 125, train_loss = 3.819595878943801, train_acc = 0.9928970656730322\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 126, train_loss = 3.777868735138327, train_acc = 0.9931299487657196\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 127, train_loss = 3.7368291853927076, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 128, train_loss = 3.6965222754515707, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 129, train_loss = 3.6569469957612455, train_acc = 0.9935957149510946\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 130, train_loss = 3.617988359183073, train_acc = 0.9935957149510946\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 131, train_loss = 3.579651945736259, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 132, train_loss = 3.542117188218981, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 133, train_loss = 3.505062425509095, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 134, train_loss = 3.468755084555596, train_acc = 0.9939450395901258\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 135, train_loss = 3.433024470228702, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 136, train_loss = 3.397922271396965, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 137, train_loss = 3.363369276281446, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 138, train_loss = 3.329499708954245, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 139, train_loss = 3.29621505131945, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 140, train_loss = 3.263448760379106, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 141, train_loss = 3.2313622194342315, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 142, train_loss = 3.1998062636703253, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 143, train_loss = 3.168836935888976, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 144, train_loss = 3.1383179570548236, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 145, train_loss = 3.108414391055703, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 146, train_loss = 3.079029105603695, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 147, train_loss = 3.050078293774277, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 148, train_loss = 3.0215430702082813, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 149, train_loss = 2.9936706200242043, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 150, train_loss = 2.966161385178566, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 151, train_loss = 2.9391607702709734, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 152, train_loss = 2.9125574938952923, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 153, train_loss = 2.886476261075586, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 154, train_loss = 2.8608256825245917, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 155, train_loss = 2.835538435727358, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 156, train_loss = 2.8107047523371875, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 157, train_loss = 2.7864232123829424, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 158, train_loss = 2.762364152353257, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 159, train_loss = 2.7388105341233313, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 160, train_loss = 2.7157006561756134, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 161, train_loss = 2.6929211276583374, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 162, train_loss = 2.6704392582178116, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 163, train_loss = 2.6485483995638788, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 164, train_loss = 2.626817440148443, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 165, train_loss = 2.6055550263263285, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 166, train_loss = 2.584575953427702, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 167, train_loss = 2.564054239075631, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 168, train_loss = 2.5437003672122955, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 169, train_loss = 2.523782856296748, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 170, train_loss = 2.504158405121416, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 171, train_loss = 2.4848523046821356, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 172, train_loss = 2.4658050257712603, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 173, train_loss = 2.447171038482338, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 174, train_loss = 2.4287497769109905, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 175, train_loss = 2.4106714737135917, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 176, train_loss = 2.3928400352597237, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 177, train_loss = 2.375335371820256, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 178, train_loss = 2.3580970142502338, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 179, train_loss = 2.341095793992281, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 180, train_loss = 2.324397637275979, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 181, train_loss = 2.308015711605549, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 182, train_loss = 2.291822885395959, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 183, train_loss = 2.275905587943271, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 184, train_loss = 2.260221293894574, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 185, train_loss = 2.2447477381210774, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 186, train_loss = 2.229581519961357, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 187, train_loss = 2.2146656799595803, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 188, train_loss = 2.199854725273326, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 189, train_loss = 2.185434017330408, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 190, train_loss = 2.1711993615608662, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 191, train_loss = 2.157122607110068, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 192, train_loss = 2.143306704936549, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 193, train_loss = 2.129721349803731, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 194, train_loss = 2.1163425657432526, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 195, train_loss = 2.1031342323403805, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 196, train_loss = 2.0901373885571957, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 197, train_loss = 2.0773368838708848, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 198, train_loss = 2.0646813474595547, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 199, train_loss = 2.0522557261865586, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 200, train_loss = 2.0400745335500687, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 201, train_loss = 2.027920040069148, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 202, train_loss = 2.01610416918993, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 203, train_loss = 2.004425172926858, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 204, train_loss = 1.9929105665069073, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 205, train_loss = 1.9815101746935397, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 206, train_loss = 1.9703188005369157, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 207, train_loss = 1.9592909887433052, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 208, train_loss = 1.9484270464163274, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 209, train_loss = 1.9377734262961894, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 210, train_loss = 1.9271059322636575, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 211, train_loss = 1.9168364231009036, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 212, train_loss = 1.9065354503691196, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 213, train_loss = 1.8963934157509357, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 214, train_loss = 1.886509935138747, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 215, train_loss = 1.8767204396426678, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 216, train_loss = 1.866959563223645, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 217, train_loss = 1.8574454002082348, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 218, train_loss = 1.8479456938803196, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 219, train_loss = 1.8387115336954594, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 220, train_loss = 1.829473126679659, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 221, train_loss = 1.8205002211034298, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 222, train_loss = 1.8115405675489455, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 223, train_loss = 1.802747030975297, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 224, train_loss = 1.7940299350302666, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 225, train_loss = 1.785458066733554, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 226, train_loss = 1.777048957766965, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 227, train_loss = 1.7687174703460187, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 228, train_loss = 1.7604056086856872, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 229, train_loss = 1.7523649979848415, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 230, train_loss = 1.7443148866295815, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 231, train_loss = 1.7363434992730618, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 232, train_loss = 1.728649610071443, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 233, train_loss = 1.7208669694373384, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 234, train_loss = 1.713233987451531, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 235, train_loss = 1.7057271711528301, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 236, train_loss = 1.6983098549535498, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 237, train_loss = 1.6909153586020693, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 238, train_loss = 1.6837609397480264, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 239, train_loss = 1.6765820471337065, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 240, train_loss = 1.669445322244428, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 241, train_loss = 1.6625600209226832, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 242, train_loss = 1.6556705323746428, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 243, train_loss = 1.648761777789332, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 244, train_loss = 1.6421192089328542, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 245, train_loss = 1.635450384230353, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 246, train_loss = 1.628869254142046, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 247, train_loss = 1.6223766194889322, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 248, train_loss = 1.6159606352448463, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 249, train_loss = 1.6096328074345365, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 250, train_loss = 1.6032962314784527, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 251, train_loss = 1.597136071533896, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 252, train_loss = 1.5910530848195776, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 253, train_loss = 1.584931805729866, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 254, train_loss = 1.578951751231216, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 255, train_loss = 1.5730526596307755, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 256, train_loss = 1.5671562366187572, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 257, train_loss = 1.5614157678792253, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 258, train_loss = 1.5557190043618903, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 259, train_loss = 1.549955883412622, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 260, train_loss = 1.5444192700088024, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 261, train_loss = 1.5389002213487402, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 262, train_loss = 1.5333600329468027, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 263, train_loss = 1.5280421102652326, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 264, train_loss = 1.522583627491258, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 265, train_loss = 1.5173144899308681, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 266, train_loss = 1.5120673974743113, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 267, train_loss = 1.5068677179515362, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 268, train_loss = 1.5017200348665938, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 269, train_loss = 1.4966442013392225, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 270, train_loss = 1.4916200526058674, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 271, train_loss = 1.4867151143262163, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 272, train_loss = 1.481708038598299, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 273, train_loss = 1.4768375841667876, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 274, train_loss = 1.4720123820006847, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 275, train_loss = 1.4672648111591116, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 276, train_loss = 1.4624635055661201, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 277, train_loss = 1.4578007198870182, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 278, train_loss = 1.4531049256911501, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 279, train_loss = 1.4486021200427786, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 280, train_loss = 1.4439732395112514, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 281, train_loss = 1.4394817588618025, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 282, train_loss = 1.4349861418595538, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 283, train_loss = 1.430639666854404, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 284, train_loss = 1.4262521030614153, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 285, train_loss = 1.4218755029141903, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 286, train_loss = 1.4176283652195707, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 287, train_loss = 1.4132907477905974, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 288, train_loss = 1.4091637916862965, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 289, train_loss = 1.4048927625408396, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 290, train_loss = 1.4008801454911008, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 291, train_loss = 1.396740679978393, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 292, train_loss = 1.3927067430922762, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 293, train_loss = 1.3887442536652088, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 294, train_loss = 1.3846512995660305, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 295, train_loss = 1.3808365078875795, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 296, train_loss = 1.3769357787678018, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 297, train_loss = 1.372980316518806, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 298, train_loss = 1.3692818308481947, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 299, train_loss = 1.3653975824126974, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 300, train_loss = 1.361752014607191, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 301, train_loss = 1.3579096434405074, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 302, train_loss = 1.3543028483400121, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 303, train_loss = 1.3506774207344279, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 304, train_loss = 1.3469917438924313, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 305, train_loss = 1.3434534519910812, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 306, train_loss = 1.3398934814031236, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 307, train_loss = 1.336390809447039, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 308, train_loss = 1.332922027737368, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 309, train_loss = 1.329382535070181, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 310, train_loss = 1.3259936298127286, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 311, train_loss = 1.3225843074615113, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 312, train_loss = 1.3192181649501435, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 313, train_loss = 1.3158697982435115, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 314, train_loss = 1.3125610587303527, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 315, train_loss = 1.3092698392574675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 316, train_loss = 1.3060514343087561, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 317, train_loss = 1.3028042328660376, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 318, train_loss = 1.2996258835191838, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 319, train_loss = 1.2963978499174118, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 320, train_loss = 1.2932944471831433, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 321, train_loss = 1.2902299624984153, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 322, train_loss = 1.2871144277160056, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 323, train_loss = 1.2840613697771914, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 324, train_loss = 1.2809381534461863, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 325, train_loss = 1.2780059650540352, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 326, train_loss = 1.2749951966106892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 327, train_loss = 1.2720495611429214, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 328, train_loss = 1.269142019271385, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 329, train_loss = 1.2661452877218835, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 330, train_loss = 1.2632801420986652, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 331, train_loss = 1.260411957919132, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 332, train_loss = 1.2576032516662963, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 333, train_loss = 1.2548174287076108, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 334, train_loss = 1.2519357564742677, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 335, train_loss = 1.2491677279467694, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 336, train_loss = 1.246413979679346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 337, train_loss = 1.2436890887911431, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 338, train_loss = 1.2409787625074387, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 339, train_loss = 1.2382406815886497, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 340, train_loss = 1.2356468737125397, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 341, train_loss = 1.2329678324167617, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 342, train_loss = 1.2302641433780082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 343, train_loss = 1.2278028006548993, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 344, train_loss = 1.2251017789239995, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 345, train_loss = 1.2225603734259494, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 346, train_loss = 1.2200293515925296, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 347, train_loss = 1.2174556044046767, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 348, train_loss = 1.2150181817705743, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 349, train_loss = 1.2124791207606904, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 350, train_loss = 1.2099236746435054, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 351, train_loss = 1.2075635641813278, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 352, train_loss = 1.2051303870975971, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 353, train_loss = 1.202685562253464, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 354, train_loss = 1.2002733958070166, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 355, train_loss = 1.1979302279651165, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 356, train_loss = 1.1955814684624784, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 357, train_loss = 1.1932399794459343, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 358, train_loss = 1.1907955184578896, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 359, train_loss = 1.188641792803537, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 360, train_loss = 1.1862042918801308, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 361, train_loss = 1.1839617912773974, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 362, train_loss = 1.1817364257876761, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 363, train_loss = 1.1794823234085925, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 364, train_loss = 1.1772154395584948, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 365, train_loss = 1.1750465271179564, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 366, train_loss = 1.1727723106741905, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 367, train_loss = 1.1706392131745815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 368, train_loss = 1.1684433321352117, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 369, train_loss = 1.1662911822204478, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 370, train_loss = 1.1641810350120068, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 371, train_loss = 1.1620586315984838, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 372, train_loss = 1.159911195456516, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 373, train_loss = 1.157826516777277, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 374, train_loss = 1.1557611972093582, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 375, train_loss = 1.1536271087825298, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 376, train_loss = 1.1516150459647179, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 377, train_loss = 1.1495314563508146, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 378, train_loss = 1.147552018344868, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 379, train_loss = 1.145583541423548, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 380, train_loss = 1.1434823796153069, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 381, train_loss = 1.1415539954905398, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 382, train_loss = 1.139588305086363, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 383, train_loss = 1.1375547448988073, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 384, train_loss = 1.1357034891843796, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 385, train_loss = 1.1337230416829698, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 386, train_loss = 1.1318475492298603, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 387, train_loss = 1.1299113941495307, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 388, train_loss = 1.1280225875671022, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 389, train_loss = 1.1260631754994392, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 390, train_loss = 1.1242941754753701, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 391, train_loss = 1.1224087961018085, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 392, train_loss = 1.1205267421901226, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 393, train_loss = 1.118734745949041, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 394, train_loss = 1.116928681731224, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 395, train_loss = 1.1150106117129326, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 396, train_loss = 1.1133049515192397, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 397, train_loss = 1.1115179235930555, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 398, train_loss = 1.109730574011337, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 399, train_loss = 1.107931402802933, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 400, train_loss = 1.1062209668452851, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 401, train_loss = 1.1044201875920407, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 402, train_loss = 1.1027923983638175, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 403, train_loss = 1.1009763504262082, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 404, train_loss = 1.0992606083746068, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 405, train_loss = 1.0976391360163689, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 406, train_loss = 1.0959654934704304, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 407, train_loss = 1.0942014058528002, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 408, train_loss = 1.092577694595093, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 409, train_loss = 1.0909232137200888, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 410, train_loss = 1.0892567833361682, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 411, train_loss = 1.0876153732242528, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 412, train_loss = 1.0860682229103986, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 413, train_loss = 1.0843136360344943, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 414, train_loss = 1.0828339718282223, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 415, train_loss = 1.0811782789824065, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 416, train_loss = 1.0796021757123526, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 417, train_loss = 1.0780056739749853, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 418, train_loss = 1.0764549933373928, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 419, train_loss = 1.0748700300755445, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 420, train_loss = 1.0733678005635738, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 421, train_loss = 1.0718161687254906, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 422, train_loss = 1.0702622259559575, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 423, train_loss = 1.0687275913951453, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 424, train_loss = 1.0672833745775279, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 425, train_loss = 1.065736106276745, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 426, train_loss = 1.0641981549561024, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 427, train_loss = 1.062795021891361, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 428, train_loss = 1.0613132739963476, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 429, train_loss = 1.0597212525608484, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 430, train_loss = 1.0584098684194032, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 431, train_loss = 1.0569061537680682, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 432, train_loss = 1.055431084096199, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 433, train_loss = 1.054028549551731, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 434, train_loss = 1.052651079982752, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 435, train_loss = 1.051182928174967, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 436, train_loss = 1.0497516381146852, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 437, train_loss = 1.0483782390656415, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 438, train_loss = 1.0469672419130802, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 439, train_loss = 1.0455486103892326, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 440, train_loss = 1.0442549909057561, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 441, train_loss = 1.0428045565786306, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 442, train_loss = 1.0414360252616461, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 443, train_loss = 1.0401954042317811, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 444, train_loss = 1.0387492030858994, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 445, train_loss = 1.0374312860367354, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 446, train_loss = 1.0360726167855319, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 447, train_loss = 1.0348107156751212, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 448, train_loss = 1.0334596087632235, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 449, train_loss = 1.0321300017239992, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 450, train_loss = 1.0308846322295722, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 451, train_loss = 1.029527772217989, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 452, train_loss = 1.0282372844812926, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 453, train_loss = 1.026974401116604, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 454, train_loss = 1.02573742219829, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 455, train_loss = 1.024434400111204, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 456, train_loss = 1.0231396978197154, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 457, train_loss = 1.0219488764705602, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 458, train_loss = 1.020730309188366, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 459, train_loss = 1.019401549041504, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 460, train_loss = 1.0182223158481065, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 461, train_loss = 1.0169559816422407, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 462, train_loss = 1.0157447519304696, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 463, train_loss = 1.0145111369492952, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 464, train_loss = 1.0133678106067237, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 465, train_loss = 1.0120974394085351, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 466, train_loss = 1.0109342895448208, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 467, train_loss = 1.0097315087914467, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 468, train_loss = 1.0085445828735828, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 469, train_loss = 1.0073569702508394, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 470, train_loss = 1.0062304250895977, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 471, train_loss = 1.0049997332098428, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 472, train_loss = 1.0039245697262231, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 473, train_loss = 1.0026464946568012, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 474, train_loss = 1.001608998834854, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 475, train_loss = 1.0004387224616949, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 476, train_loss = 0.9992788521049079, train_acc = 0.9980204937121565\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 477, train_loss = 0.9981286662223283, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 478, train_loss = 0.9970879902539309, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 479, train_loss = 0.995884188771015, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 480, train_loss = 0.9947980456054211, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 481, train_loss = 0.993638027459383, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 482, train_loss = 0.9926405226287898, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 483, train_loss = 0.991432643175358, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 484, train_loss = 0.9904358647763729, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 485, train_loss = 0.9892332864401396, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 486, train_loss = 0.9882288413646165, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 487, train_loss = 0.9871728172001895, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 488, train_loss = 0.9861097050306853, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 489, train_loss = 0.9849066647293512, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 490, train_loss = 0.9840139858424664, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 491, train_loss = 0.9829016973671969, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 492, train_loss = 0.9818633273243904, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 493, train_loss = 0.9807663758692797, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 494, train_loss = 0.9797223421337549, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 495, train_loss = 0.9787612073123455, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 496, train_loss = 0.9776924985053483, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 497, train_loss = 0.9766771048307419, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 498, train_loss = 0.9756470806896687, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 499, train_loss = 0.974631417542696, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████▊       | 27/30 [3:04:46<20:35, 411.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "28th- epoch: 0, train_loss = 275.7717123031616, train_acc = 0.39892873777363763\n",
      "test Acc 0.5377094972067039:\n",
      "28th- epoch: 1, train_loss = 212.20757913589478, train_acc = 0.5503027480204937\n",
      "test Acc 0.5661080074487895:\n",
      "28th- epoch: 2, train_loss = 164.8435606956482, train_acc = 0.5711457848160224\n",
      "test Acc 0.5842644320297952:\n",
      "28th- epoch: 3, train_loss = 136.1530892252922, train_acc = 0.6433395435491384\n",
      "test Acc 0.7318435754189944:\n",
      "28th- epoch: 4, train_loss = 115.92902541160583, train_acc = 0.7511644154634374\n",
      "test Acc 0.7742085661080075:\n",
      "28th- epoch: 5, train_loss = 100.40538296103477, train_acc = 0.7711923614345598\n",
      "test Acc 0.797486033519553:\n",
      "28th- epoch: 6, train_loss = 88.27957019209862, train_acc = 0.78959012575687\n",
      "test Acc 0.8170391061452514:\n",
      "28th- epoch: 7, train_loss = 78.71726977825165, train_acc = 0.8162552398695855\n",
      "test Acc 0.839851024208566:\n",
      "28th- epoch: 8, train_loss = 70.73645597696304, train_acc = 0.8473451327433629\n",
      "test Acc 0.8696461824953445:\n",
      "28th- epoch: 9, train_loss = 63.70561099052429, train_acc = 0.8791336748952026\n",
      "test Acc 0.8933891992551211:\n",
      "28th- epoch: 10, train_loss = 57.36906200647354, train_acc = 0.8998602701443875\n",
      "test Acc 0.9120111731843575:\n",
      "28th- epoch: 11, train_loss = 51.68372608721256, train_acc = 0.9202375407545412\n",
      "test Acc 0.9269087523277467:\n",
      "28th- epoch: 12, train_loss = 46.66968768835068, train_acc = 0.9353749417792269\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 13, train_loss = 42.31096097826958, train_acc = 0.9445738239403819\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 14, train_loss = 38.55811109393835, train_acc = 0.9472519795062878\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 15, train_loss = 35.34633083641529, train_acc = 0.9499301350721937\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 16, train_loss = 32.60580029338598, train_acc = 0.9529576152771309\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 17, train_loss = 30.26409938931465, train_acc = 0.9548206800186306\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 18, train_loss = 28.257914572954178, train_acc = 0.9566837447601304\n",
      "test Acc 0.9543761638733705:\n",
      "28th- epoch: 19, train_loss = 26.531718648970127, train_acc = 0.9598276665114113\n",
      "test Acc 0.9567039106145251:\n",
      "28th- epoch: 20, train_loss = 25.035655960440636, train_acc = 0.9633209129017233\n",
      "test Acc 0.9594972067039106:\n",
      "28th- epoch: 21, train_loss = 23.728576701134443, train_acc = 0.9653004191895669\n",
      "test Acc 0.9613594040968343:\n",
      "28th- epoch: 22, train_loss = 22.577795445919037, train_acc = 0.9672799254774104\n",
      "test Acc 0.9613594040968343:\n",
      "28th- epoch: 23, train_loss = 21.556753654032946, train_acc = 0.9677456916627852\n",
      "test Acc 0.9622905027932961:\n",
      "28th- epoch: 24, train_loss = 20.644061882048845, train_acc = 0.9693758733115976\n",
      "test Acc 0.9622905027932961:\n",
      "28th- epoch: 25, train_loss = 19.821049489080906, train_acc = 0.9697251979506288\n",
      "test Acc 0.9622905027932961:\n",
      "28th- epoch: 26, train_loss = 19.074446327984333, train_acc = 0.9704238472286912\n",
      "test Acc 0.9632216014897579:\n",
      "28th- epoch: 27, train_loss = 18.392322950065136, train_acc = 0.9713553795994411\n",
      "test Acc 0.9636871508379888:\n",
      "28th- epoch: 28, train_loss = 17.76580722257495, train_acc = 0.971821145784816\n",
      "test Acc 0.9636871508379888:\n",
      "28th- epoch: 29, train_loss = 17.187938772141933, train_acc = 0.9721704704238472\n",
      "test Acc 0.9636871508379888:\n",
      "28th- epoch: 30, train_loss = 16.652703769505024, train_acc = 0.9729855612482534\n",
      "test Acc 0.9636871508379888:\n",
      "28th- epoch: 31, train_loss = 16.154546577483416, train_acc = 0.9731020027945971\n",
      "test Acc 0.9641527001862198:\n",
      "28th- epoch: 32, train_loss = 15.689565490931273, train_acc = 0.9733348858872846\n",
      "test Acc 0.9641527001862198:\n",
      "28th- epoch: 33, train_loss = 15.253463082015514, train_acc = 0.9735677689799721\n",
      "test Acc 0.9655493482309124:\n",
      "28th- epoch: 34, train_loss = 14.843108020722866, train_acc = 0.9741499767116907\n",
      "test Acc 0.9664804469273743:\n",
      "28th- epoch: 35, train_loss = 14.455778867006302, train_acc = 0.9749650675360969\n",
      "test Acc 0.9674115456238361:\n",
      "28th- epoch: 36, train_loss = 14.089582297950983, train_acc = 0.9750815090824406\n",
      "test Acc 0.9674115456238361:\n",
      "28th- epoch: 37, train_loss = 13.742706693708897, train_acc = 0.9754308337214718\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 38, train_loss = 13.413357425481081, train_acc = 0.9754308337214718\n",
      "test Acc 0.9683426443202979:\n",
      "28th- epoch: 39, train_loss = 13.100122410804033, train_acc = 0.976245924545878\n",
      "test Acc 0.9683426443202979:\n",
      "28th- epoch: 40, train_loss = 12.801700845360756, train_acc = 0.9764788076385654\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 41, train_loss = 12.51681037247181, train_acc = 0.9767116907312529\n",
      "test Acc 0.9702048417132216:\n",
      "28th- epoch: 42, train_loss = 12.24432884901762, train_acc = 0.9769445738239404\n",
      "test Acc 0.9702048417132216:\n",
      "28th- epoch: 43, train_loss = 11.983694233000278, train_acc = 0.9772938984629715\n",
      "test Acc 0.9706703910614525:\n",
      "28th- epoch: 44, train_loss = 11.734120305627584, train_acc = 0.9777596646483465\n",
      "test Acc 0.9706703910614525:\n",
      "28th- epoch: 45, train_loss = 11.494859121739864, train_acc = 0.9784583139264089\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 46, train_loss = 11.265028828755021, train_acc = 0.9785747554727526\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 47, train_loss = 11.043918069452047, train_acc = 0.9793898462971589\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 48, train_loss = 10.830597767606378, train_acc = 0.9803213786679087\n",
      "test Acc 0.9725325884543762:\n",
      "28th- epoch: 49, train_loss = 10.624886592850089, train_acc = 0.9807871448532837\n",
      "test Acc 0.9725325884543762:\n",
      "28th- epoch: 50, train_loss = 10.426317797973752, train_acc = 0.9809035863996274\n",
      "test Acc 0.9725325884543762:\n",
      "28th- epoch: 51, train_loss = 10.234424153342843, train_acc = 0.9813693525850024\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 52, train_loss = 10.049147823825479, train_acc = 0.9818351187703773\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 53, train_loss = 9.869686843827367, train_acc = 0.9821844434094085\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 54, train_loss = 9.695903945714235, train_acc = 0.9825337680484397\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 55, train_loss = 9.527589222416282, train_acc = 0.9829995342338146\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 56, train_loss = 9.364480834454298, train_acc = 0.9831159757801584\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 57, train_loss = 9.206517148762941, train_acc = 0.9833488588728458\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 58, train_loss = 9.053190115839243, train_acc = 0.9834653004191896\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 59, train_loss = 8.904072862118483, train_acc = 0.9835817419655333\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 60, train_loss = 8.759209588170052, train_acc = 0.9835817419655333\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 61, train_loss = 8.618444131687284, train_acc = 0.983698183511877\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 62, train_loss = 8.481655601412058, train_acc = 0.9838146250582208\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 63, train_loss = 8.34859892912209, train_acc = 0.9840475081509082\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 64, train_loss = 8.219101160764694, train_acc = 0.984163949697252\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 65, train_loss = 8.093134574592113, train_acc = 0.984163949697252\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 66, train_loss = 7.970288410782814, train_acc = 0.9843968327899395\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 67, train_loss = 7.850505828857422, train_acc = 0.9847461574289706\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 68, train_loss = 7.733613014221191, train_acc = 0.9848625989753144\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 69, train_loss = 7.619550723582506, train_acc = 0.9850954820680019\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 70, train_loss = 7.508202727884054, train_acc = 0.9855612482533768\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 71, train_loss = 7.39935477077961, train_acc = 0.9857941313460643\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 72, train_loss = 7.2929141744971275, train_acc = 0.9861434559850955\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 73, train_loss = 7.188860448077321, train_acc = 0.986376339077783\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 74, train_loss = 7.087147448211908, train_acc = 0.9864927806241267\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 75, train_loss = 6.987698448821902, train_acc = 0.9866092221704704\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 76, train_loss = 6.890286133624613, train_acc = 0.9871914299021891\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 77, train_loss = 6.795048211701214, train_acc = 0.9871914299021891\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 78, train_loss = 6.701725819148123, train_acc = 0.9871914299021891\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 79, train_loss = 6.610520307905972, train_acc = 0.9873078714485328\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 80, train_loss = 6.520943907089531, train_acc = 0.9873078714485328\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 81, train_loss = 6.433275585062802, train_acc = 0.9873078714485328\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 82, train_loss = 6.347291977144778, train_acc = 0.9876571960875641\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 83, train_loss = 6.263027689419687, train_acc = 0.9877736376339078\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 84, train_loss = 6.180231164209545, train_acc = 0.9880065207265952\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 85, train_loss = 6.099040477536619, train_acc = 0.9882394038192828\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 86, train_loss = 6.019250298850238, train_acc = 0.9884722869119702\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 87, train_loss = 5.941204492934048, train_acc = 0.9884722869119702\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 88, train_loss = 5.864297972992063, train_acc = 0.9885887284583139\n",
      "test Acc 0.9799813780260708:\n",
      "28th- epoch: 89, train_loss = 5.788898065686226, train_acc = 0.9887051700046576\n",
      "test Acc 0.9799813780260708:\n",
      "28th- epoch: 90, train_loss = 5.714741196483374, train_acc = 0.9888216115510013\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 91, train_loss = 5.641920791007578, train_acc = 0.9889380530973452\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 92, train_loss = 5.5703664710745215, train_acc = 0.9891709361900326\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 93, train_loss = 5.499860065057874, train_acc = 0.9892873777363763\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 94, train_loss = 5.4307325864210725, train_acc = 0.98940381928272\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 95, train_loss = 5.36263163946569, train_acc = 0.9896367023754076\n",
      "test Acc 0.9818435754189944:\n",
      "28th- epoch: 96, train_loss = 5.295728395693004, train_acc = 0.9897531439217513\n",
      "test Acc 0.9818435754189944:\n",
      "28th- epoch: 97, train_loss = 5.230009424500167, train_acc = 0.99033535165347\n",
      "test Acc 0.9823091247672253:\n",
      "28th- epoch: 98, train_loss = 5.1653959937393665, train_acc = 0.9904517931998137\n",
      "test Acc 0.9823091247672253:\n",
      "28th- epoch: 99, train_loss = 5.10179887060076, train_acc = 0.9905682347461574\n",
      "test Acc 0.9823091247672253:\n",
      "28th- epoch: 100, train_loss = 5.039170659147203, train_acc = 0.9906846762925011\n",
      "test Acc 0.9827746741154563:\n",
      "28th- epoch: 101, train_loss = 4.977521249093115, train_acc = 0.990801117838845\n",
      "test Acc 0.9827746741154563:\n",
      "28th- epoch: 102, train_loss = 4.916970930993557, train_acc = 0.9909175593851887\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 103, train_loss = 4.857218473218381, train_acc = 0.9913833255705635\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 104, train_loss = 4.7986978106200695, train_acc = 0.9913833255705635\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 105, train_loss = 4.7408578572794795, train_acc = 0.9913833255705635\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 106, train_loss = 4.684033918194473, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 107, train_loss = 4.6282161716371775, train_acc = 0.9914997671169073\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 108, train_loss = 4.57316973246634, train_acc = 0.9917326502095948\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 109, train_loss = 4.519241690635681, train_acc = 0.9919655333022822\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 110, train_loss = 4.466011223383248, train_acc = 0.9921984163949698\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 111, train_loss = 4.413678601384163, train_acc = 0.9921984163949698\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 112, train_loss = 4.36237127892673, train_acc = 0.9921984163949698\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 113, train_loss = 4.311781981028616, train_acc = 0.9923148579413135\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 114, train_loss = 4.261937403585762, train_acc = 0.9923148579413135\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 115, train_loss = 4.213121157605201, train_acc = 0.9926641825803446\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 116, train_loss = 4.164916045963764, train_acc = 0.9926641825803446\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 117, train_loss = 4.117642582859844, train_acc = 0.9926641825803446\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 118, train_loss = 4.071323113981634, train_acc = 0.9928970656730322\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 119, train_loss = 4.0254339929670095, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 120, train_loss = 3.9805949232541025, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 121, train_loss = 3.936504427343607, train_acc = 0.9928970656730322\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 122, train_loss = 3.893132738303393, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 123, train_loss = 3.850543858949095, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 124, train_loss = 3.808679098729044, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 125, train_loss = 3.767525041010231, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 126, train_loss = 3.7270337441004813, train_acc = 0.9934792734047508\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 127, train_loss = 3.68713034177199, train_acc = 0.9934792734047508\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 128, train_loss = 3.647979358676821, train_acc = 0.9934792734047508\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 129, train_loss = 3.6093518142588437, train_acc = 0.9937121564974383\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 130, train_loss = 3.571456810925156, train_acc = 0.993828598043782\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 131, train_loss = 3.5340762939304113, train_acc = 0.9939450395901258\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 132, train_loss = 3.49745343439281, train_acc = 0.9941779226828132\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 133, train_loss = 3.4613632415421307, train_acc = 0.9941779226828132\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 134, train_loss = 3.4259611223824322, train_acc = 0.9941779226828132\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 135, train_loss = 3.39100113324821, train_acc = 0.9945272473218444\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 136, train_loss = 3.3567258385010064, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 137, train_loss = 3.3229662380181253, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 138, train_loss = 3.2899124417454004, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 139, train_loss = 3.2571282549761236, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 140, train_loss = 3.225140294060111, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 141, train_loss = 3.1935212411917746, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 142, train_loss = 3.1625527539290488, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 143, train_loss = 3.131934924516827, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 144, train_loss = 3.101964403409511, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 145, train_loss = 3.072254835162312, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 146, train_loss = 3.0434141107834876, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 147, train_loss = 3.0148814599961042, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 148, train_loss = 2.98665294284001, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 149, train_loss = 2.9590310477651656, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 150, train_loss = 2.931808104738593, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 151, train_loss = 2.9050672464072704, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 152, train_loss = 2.878783494234085, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 153, train_loss = 2.8530947328545153, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 154, train_loss = 2.827524257823825, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 155, train_loss = 2.8024793677031994, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 156, train_loss = 2.7779581150971353, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 157, train_loss = 2.7537303627468646, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 158, train_loss = 2.730065956711769, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 159, train_loss = 2.706724387826398, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 160, train_loss = 2.68359811976552, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 161, train_loss = 2.6610020250082016, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 162, train_loss = 2.638826336711645, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 163, train_loss = 2.6168893426656723, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 164, train_loss = 2.595315594226122, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 165, train_loss = 2.5740449007134885, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 166, train_loss = 2.553202108712867, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 167, train_loss = 2.5325272742193192, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 168, train_loss = 2.5122999909799546, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 169, train_loss = 2.4923533983528614, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 170, train_loss = 2.472700074315071, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 171, train_loss = 2.4534874942619354, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 172, train_loss = 2.4344819139223546, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 173, train_loss = 2.4158347335178405, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 174, train_loss = 2.397432503523305, train_acc = 0.9962738705170004\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 175, train_loss = 2.3793623943347484, train_acc = 0.9962738705170004\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 176, train_loss = 2.3617119528353214, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 177, train_loss = 2.34421897190623, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 178, train_loss = 2.3270054671447724, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 179, train_loss = 2.3101365368347615, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 180, train_loss = 2.293428547680378, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 181, train_loss = 2.277067930670455, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 182, train_loss = 2.2609705440700054, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 183, train_loss = 2.2450751562137157, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 184, train_loss = 2.2295968506950885, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 185, train_loss = 2.214185970602557, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 186, train_loss = 2.199081228347495, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 187, train_loss = 2.1843291223049164, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 188, train_loss = 2.1696948744356632, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 189, train_loss = 2.155213739722967, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 190, train_loss = 2.1411196552217007, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 191, train_loss = 2.127174836816266, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 192, train_loss = 2.1134694267529994, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 193, train_loss = 2.1000160749536008, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 194, train_loss = 2.0866929951589555, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 195, train_loss = 2.0736375215929, train_acc = 0.9966231951560317\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 196, train_loss = 2.0607364128809422, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 197, train_loss = 2.0479799944441766, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 198, train_loss = 2.0354783858638257, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 199, train_loss = 2.023278222652152, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 200, train_loss = 2.0111033965367824, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 201, train_loss = 1.9991939079482108, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 202, train_loss = 1.9875529061537236, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 203, train_loss = 1.976024427684024, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 204, train_loss = 1.964567057788372, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 205, train_loss = 1.9534320074599236, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 206, train_loss = 1.9424581229686737, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 207, train_loss = 1.9315864120144397, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 208, train_loss = 1.920861404389143, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 209, train_loss = 1.9104003669926897, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 210, train_loss = 1.899875602335669, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 211, train_loss = 1.8897323062410578, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 212, train_loss = 1.8795835500350222, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 213, train_loss = 1.8697532141814008, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 214, train_loss = 1.859877901733853, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 215, train_loss = 1.8501877138623968, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 216, train_loss = 1.840691470890306, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 217, train_loss = 1.8312746696174145, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 218, train_loss = 1.821959694265388, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 219, train_loss = 1.8129198563983664, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 220, train_loss = 1.8038589222123846, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 221, train_loss = 1.7949049124727026, train_acc = 0.9972054028877504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 222, train_loss = 1.7861084677278996, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 223, train_loss = 1.7775205770740286, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 224, train_loss = 1.76882156485226, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 225, train_loss = 1.760542567819357, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 226, train_loss = 1.752094985335134, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 227, train_loss = 1.7438737973570824, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 228, train_loss = 1.7357524546096101, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 229, train_loss = 1.7277213794877753, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 230, train_loss = 1.719888543128036, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 231, train_loss = 1.712120128213428, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 232, train_loss = 1.704292289330624, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 233, train_loss = 1.696854621754028, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 234, train_loss = 1.689270500675775, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 235, train_loss = 1.6818482000380754, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 236, train_loss = 1.6746227642288432, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 237, train_loss = 1.6672953857341781, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 238, train_loss = 1.6602106528589502, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 239, train_loss = 1.6530244468012825, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 240, train_loss = 1.646143956691958, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 241, train_loss = 1.6392204525182024, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 242, train_loss = 1.6324635496130213, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 243, train_loss = 1.625636869459413, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 244, train_loss = 1.6189530888805166, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 245, train_loss = 1.6124778600642458, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 246, train_loss = 1.605878205387853, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 247, train_loss = 1.5995204411447048, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 248, train_loss = 1.5932303853332996, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 249, train_loss = 1.5868530882289633, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 250, train_loss = 1.5807955464115366, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 251, train_loss = 1.5746020985534415, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 252, train_loss = 1.5685224942862988, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 253, train_loss = 1.5625563425710425, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 254, train_loss = 1.5566994138062, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 255, train_loss = 1.5507671112427488, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 256, train_loss = 1.5449851043522358, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 257, train_loss = 1.5392170188715681, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 258, train_loss = 1.5335799952736124, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 259, train_loss = 1.5279526686063036, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 260, train_loss = 1.5223887165775523, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 261, train_loss = 1.5168760530650616, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 262, train_loss = 1.5114301592111588, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 263, train_loss = 1.506034909398295, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 264, train_loss = 1.500641262740828, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 265, train_loss = 1.495329993427731, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 266, train_loss = 1.4899791540810838, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 267, train_loss = 1.4847429245710373, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 268, train_loss = 1.479565430432558, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 269, train_loss = 1.4746344052255154, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 270, train_loss = 1.4695236720144749, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 271, train_loss = 1.4646558103850111, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 272, train_loss = 1.4597939476370811, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 273, train_loss = 1.454949252307415, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 274, train_loss = 1.4502112244372256, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 275, train_loss = 1.4454147132928483, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 276, train_loss = 1.4407787409727462, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 277, train_loss = 1.4361035439069383, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 278, train_loss = 1.431452023505699, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 279, train_loss = 1.4270032842759974, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 280, train_loss = 1.422460914880503, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 281, train_loss = 1.4180207724566571, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 282, train_loss = 1.4135392867028713, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 283, train_loss = 1.4092825439875014, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 284, train_loss = 1.4049569480121136, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 285, train_loss = 1.4005518381600268, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 286, train_loss = 1.396510299295187, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 287, train_loss = 1.3921485071186908, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 288, train_loss = 1.388051625341177, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 289, train_loss = 1.3838998638093472, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 290, train_loss = 1.379808746278286, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 291, train_loss = 1.375720473646652, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 292, train_loss = 1.3717616287176497, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 293, train_loss = 1.3678029365837574, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 294, train_loss = 1.3638422054355033, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 295, train_loss = 1.359928162128199, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 296, train_loss = 1.3560673954780214, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 297, train_loss = 1.3522603971068747, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 298, train_loss = 1.3484930979902856, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 299, train_loss = 1.3446772508323193, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 300, train_loss = 1.3409581680898555, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 301, train_loss = 1.337328840047121, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 302, train_loss = 1.3336147640948184, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 303, train_loss = 1.33000734570669, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 304, train_loss = 1.3264327111537568, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 305, train_loss = 1.3228462872211821, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 306, train_loss = 1.3193409542436711, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 307, train_loss = 1.3158473906223662, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 308, train_loss = 1.3123392388224602, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 309, train_loss = 1.3089864303474315, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 310, train_loss = 1.3054823614656925, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 311, train_loss = 1.302166483073961, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 312, train_loss = 1.2989178423886187, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 313, train_loss = 1.295460782945156, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 314, train_loss = 1.292240136594046, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 315, train_loss = 1.2888975863461383, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 316, train_loss = 1.2857260778546333, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 317, train_loss = 1.2825508539681323, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 318, train_loss = 1.2793037382070906, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 319, train_loss = 1.276148982346058, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 320, train_loss = 1.2730878355796449, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 321, train_loss = 1.2699179264600389, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 322, train_loss = 1.26691835623933, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 323, train_loss = 1.2637864400749095, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 324, train_loss = 1.260923641442787, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 325, train_loss = 1.2577686819131486, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 326, train_loss = 1.2549001661245711, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 327, train_loss = 1.2518665355746634, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 328, train_loss = 1.2489700727164745, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 329, train_loss = 1.2460627729888074, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 330, train_loss = 1.2431961844558828, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 331, train_loss = 1.240281842648983, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 332, train_loss = 1.2375816752319224, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 333, train_loss = 1.234647236764431, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 334, train_loss = 1.2319991141557693, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 335, train_loss = 1.2291140618617646, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 336, train_loss = 1.2263968102633953, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 337, train_loss = 1.223627109080553, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 338, train_loss = 1.220955352007877, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 339, train_loss = 1.2182511116261594, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 340, train_loss = 1.2156860952381976, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 341, train_loss = 1.212977806746494, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 342, train_loss = 1.210384068370331, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 343, train_loss = 1.2077568744425662, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 344, train_loss = 1.2051507669384591, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 345, train_loss = 1.2025801874697208, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 346, train_loss = 1.2000436547095887, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 347, train_loss = 1.1975464460556395, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 348, train_loss = 1.1950530844624154, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 349, train_loss = 1.1926074835355394, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 350, train_loss = 1.1901319709722884, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 351, train_loss = 1.1876764719490893, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 352, train_loss = 1.1852216646075249, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 353, train_loss = 1.1828398455982096, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 354, train_loss = 1.1804922595620155, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 355, train_loss = 1.1780685943667777, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 356, train_loss = 1.1757051721215248, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 357, train_loss = 1.1734158135950565, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 358, train_loss = 1.1710761462454684, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 359, train_loss = 1.168767975002993, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 360, train_loss = 1.1664668296580203, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 361, train_loss = 1.1642722263932228, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 362, train_loss = 1.1619634914095514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 363, train_loss = 1.1597188909654506, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 364, train_loss = 1.1576103729312308, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 365, train_loss = 1.1552959270775318, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 366, train_loss = 1.1531456907687243, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 367, train_loss = 1.1509874363837298, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 368, train_loss = 1.1488501727581024, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 369, train_loss = 1.146736045688158, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 370, train_loss = 1.144603372871643, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 371, train_loss = 1.1424155347049236, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 372, train_loss = 1.1403416357934475, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 373, train_loss = 1.1382600329816341, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 374, train_loss = 1.1361862147750799, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 375, train_loss = 1.1341297080216464, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 376, train_loss = 1.1321596056222916, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 377, train_loss = 1.1301243951020297, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 378, train_loss = 1.128054896980757, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 379, train_loss = 1.1260642508568708, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 380, train_loss = 1.124108262360096, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 381, train_loss = 1.1221230464580003, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 382, train_loss = 1.12016105526709, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 383, train_loss = 1.1182406904699747, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 384, train_loss = 1.1163978638651315, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 385, train_loss = 1.1143612079322338, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 386, train_loss = 1.1125038924219552, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 387, train_loss = 1.110604635119671, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 388, train_loss = 1.1087903628649656, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 389, train_loss = 1.1067802856268827, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 390, train_loss = 1.1050064799783286, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 391, train_loss = 1.1031103866698686, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 392, train_loss = 1.1013397636415903, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 393, train_loss = 1.0995340272784233, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 394, train_loss = 1.0976426005363464, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 395, train_loss = 1.0958697597088758, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 396, train_loss = 1.0941198281943798, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 397, train_loss = 1.0923248454928398, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 398, train_loss = 1.0905595558288042, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 399, train_loss = 1.0887310840189457, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 400, train_loss = 1.0870612586440984, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 401, train_loss = 1.0853278773429338, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 402, train_loss = 1.0835850400326308, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 403, train_loss = 1.0818977033195551, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 404, train_loss = 1.080134142190218, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 405, train_loss = 1.0785113833844662, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 406, train_loss = 1.0768563759920653, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 407, train_loss = 1.0752077276411, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 408, train_loss = 1.0734803502855357, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 409, train_loss = 1.0718917275371496, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 410, train_loss = 1.0702168941497803, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 411, train_loss = 1.0685964226722717, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 412, train_loss = 1.067056655883789, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 413, train_loss = 1.065399907529354, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 414, train_loss = 1.0638037236931268, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 415, train_loss = 1.0622874423861504, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 416, train_loss = 1.060707613825798, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 417, train_loss = 1.0591483538446482, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 418, train_loss = 1.057547693460947, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 419, train_loss = 1.055993065237999, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 420, train_loss = 1.0545253033342306, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 421, train_loss = 1.052976763487095, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 422, train_loss = 1.0514747264387552, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 423, train_loss = 1.0499572282133158, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 424, train_loss = 1.0483527990581933, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 425, train_loss = 1.0469810081121977, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 426, train_loss = 1.0454047235252801, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 427, train_loss = 1.0440819846990053, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 428, train_loss = 1.042548784374958, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 429, train_loss = 1.0410282388329506, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 430, train_loss = 1.0396356073615607, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 431, train_loss = 1.0381862074136734, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 432, train_loss = 1.0368372611701488, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 433, train_loss = 1.0353721579012927, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 434, train_loss = 1.0339852136967238, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 435, train_loss = 1.0325555391609669, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 436, train_loss = 1.0311783701181412, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 437, train_loss = 1.029772911220789, train_acc = 0.9981369352585002\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 438, train_loss = 1.028338356554741, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 439, train_loss = 1.027001886308426, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 440, train_loss = 1.0256631026568357, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 441, train_loss = 1.0243103951215744, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 442, train_loss = 1.0229047648608685, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 443, train_loss = 1.0215544812381268, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 444, train_loss = 1.020310444146162, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 445, train_loss = 1.0189420903625432, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 446, train_loss = 1.0176270678639412, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 447, train_loss = 1.0162036480905954, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 448, train_loss = 1.0150433704257011, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 449, train_loss = 1.0136732483806554, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 450, train_loss = 1.0124308144149836, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 451, train_loss = 1.0111005057988223, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 452, train_loss = 1.009748786687851, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 453, train_loss = 1.008607820927864, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 454, train_loss = 1.007343706995016, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 455, train_loss = 1.0059853605926037, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 456, train_loss = 1.004851445555687, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 457, train_loss = 1.0035530043242034, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 458, train_loss = 1.0022412165999413, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 459, train_loss = 1.0011884793639183, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 460, train_loss = 0.9998681942524854, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 461, train_loss = 0.998595596611267, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 462, train_loss = 0.9974770285189152, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 463, train_loss = 0.9963023327291012, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 464, train_loss = 0.995048680662876, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 465, train_loss = 0.9938697727920953, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 466, train_loss = 0.9927387982606888, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 467, train_loss = 0.991480641067028, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 468, train_loss = 0.9904245622456074, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 469, train_loss = 0.9892269012925681, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 470, train_loss = 0.98805502554751, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 471, train_loss = 0.9868522584438324, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 472, train_loss = 0.9857224138977472, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 473, train_loss = 0.9846189854142722, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 474, train_loss = 0.9835955562593881, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 475, train_loss = 0.9822818761167582, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 476, train_loss = 0.9812019368109759, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 477, train_loss = 0.980162331223255, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 478, train_loss = 0.979049313813448, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 479, train_loss = 0.9777864130737726, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 480, train_loss = 0.9768650817277376, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 481, train_loss = 0.97571455562138, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 482, train_loss = 0.974632420897251, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 483, train_loss = 0.9735256793501321, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 484, train_loss = 0.9723877260985319, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 485, train_loss = 0.9714088241162244, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 486, train_loss = 0.9702855994401034, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 487, train_loss = 0.9692176592943724, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 488, train_loss = 0.9681430881319102, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 489, train_loss = 0.9671417263743933, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 490, train_loss = 0.9661774548294488, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 491, train_loss = 0.9651835958065931, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 492, train_loss = 0.9640515533683356, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 493, train_loss = 0.9629529540834483, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 494, train_loss = 0.9621074683964252, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 495, train_loss = 0.9609533101320267, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 496, train_loss = 0.9601441957056522, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 497, train_loss = 0.9588977806270123, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 498, train_loss = 0.9580808964965399, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 499, train_loss = 0.9568991872074548, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████▏    | 28/30 [3:11:37<13:42, 411.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "29th- epoch: 0, train_loss = 269.3943465948105, train_acc = 0.49510945505356313\n",
      "test Acc 0.5889199255121043:\n",
      "29th- epoch: 1, train_loss = 201.19385850429535, train_acc = 0.5730088495575221\n",
      "test Acc 0.5754189944134078:\n",
      "29th- epoch: 2, train_loss = 156.34893596172333, train_acc = 0.5889613414066138\n",
      "test Acc 0.6247672253258846:\n",
      "29th- epoch: 3, train_loss = 131.9208208322525, train_acc = 0.6656963204471356\n",
      "test Acc 0.722998137802607:\n",
      "29th- epoch: 4, train_loss = 114.85826426744461, train_acc = 0.7431299487657196\n",
      "test Acc 0.7756052141527002:\n",
      "29th- epoch: 5, train_loss = 101.28797399997711, train_acc = 0.7729389846297159\n",
      "test Acc 0.7998137802607076:\n",
      "29th- epoch: 6, train_loss = 89.96764132380486, train_acc = 0.7893572426641826\n",
      "test Acc 0.8114525139664804:\n",
      "29th- epoch: 7, train_loss = 80.46773874759674, train_acc = 0.8054261760596181\n",
      "test Acc 0.8310055865921788:\n",
      "29th- epoch: 8, train_loss = 72.36550912261009, train_acc = 0.8311597578015836\n",
      "test Acc 0.8505586592178771:\n",
      "29th- epoch: 9, train_loss = 65.24372097849846, train_acc = 0.8601537028411738\n",
      "test Acc 0.8715083798882681:\n",
      "29th- epoch: 10, train_loss = 58.88270881772041, train_acc = 0.8853050768514206\n",
      "test Acc 0.8919925512104283:\n",
      "29th- epoch: 11, train_loss = 53.21963618695736, train_acc = 0.9005589194224499\n",
      "test Acc 0.9106145251396648:\n",
      "29th- epoch: 12, train_loss = 48.22121934592724, train_acc = 0.9148812296227294\n",
      "test Acc 0.9213221601489758:\n",
      "29th- epoch: 13, train_loss = 43.83935984969139, train_acc = 0.9293199813693526\n",
      "test Acc 0.9301675977653632:\n",
      "29th- epoch: 14, train_loss = 40.02478550374508, train_acc = 0.9404983698183512\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 15, train_loss = 36.71696199476719, train_acc = 0.9471355379599441\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 16, train_loss = 33.86501798778772, train_acc = 0.9509781089892874\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 17, train_loss = 31.41137706488371, train_acc = 0.9531904983698184\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 18, train_loss = 29.29587184637785, train_acc = 0.9547042384722869\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 19, train_loss = 27.468848809599876, train_acc = 0.9562179785747554\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 20, train_loss = 25.882455229759216, train_acc = 0.9579646017699115\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 21, train_loss = 24.495574317872524, train_acc = 0.9601769911504425\n",
      "test Acc 0.9548417132216015:\n",
      "29th- epoch: 22, train_loss = 23.275689225643873, train_acc = 0.9627387051700047\n",
      "test Acc 0.9585661080074488:\n",
      "29th- epoch: 23, train_loss = 22.195722337812185, train_acc = 0.9662319515603167\n",
      "test Acc 0.9608938547486033:\n",
      "29th- epoch: 24, train_loss = 21.233047105371952, train_acc = 0.9684443409408477\n",
      "test Acc 0.9636871508379888:\n",
      "29th- epoch: 25, train_loss = 20.369232311844826, train_acc = 0.9698416394969726\n",
      "test Acc 0.9636871508379888:\n",
      "29th- epoch: 26, train_loss = 19.588616713881493, train_acc = 0.970540288775035\n",
      "test Acc 0.9636871508379888:\n",
      "29th- epoch: 27, train_loss = 18.877873592078686, train_acc = 0.9708896134140661\n",
      "test Acc 0.9646182495344506:\n",
      "29th- epoch: 28, train_loss = 18.228359024971724, train_acc = 0.9712389380530974\n",
      "test Acc 0.9650837988826816:\n",
      "29th- epoch: 29, train_loss = 17.631377011537552, train_acc = 0.9714718211457848\n",
      "test Acc 0.9646182495344506:\n",
      "29th- epoch: 30, train_loss = 17.080163296312094, train_acc = 0.971821145784816\n",
      "test Acc 0.9664804469273743:\n",
      "29th- epoch: 31, train_loss = 16.568352941423655, train_acc = 0.9721704704238472\n",
      "test Acc 0.9664804469273743:\n",
      "29th- epoch: 32, train_loss = 16.091449692845345, train_acc = 0.9729855612482534\n",
      "test Acc 0.9669459962756052:\n",
      "29th- epoch: 33, train_loss = 15.645248431712389, train_acc = 0.9732184443409408\n",
      "test Acc 0.9669459962756052:\n",
      "29th- epoch: 34, train_loss = 15.226383801549673, train_acc = 0.9738006520726595\n",
      "test Acc 0.9674115456238361:\n",
      "29th- epoch: 35, train_loss = 14.832060597836971, train_acc = 0.9743828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 36, train_loss = 14.459416467696428, train_acc = 0.9748486259897532\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 37, train_loss = 14.106455754488707, train_acc = 0.9750815090824406\n",
      "test Acc 0.9688081936685289:\n",
      "29th- epoch: 38, train_loss = 13.771222542971373, train_acc = 0.9754308337214718\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 39, train_loss = 13.45244013890624, train_acc = 0.9756637168141593\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 40, train_loss = 13.149098165333271, train_acc = 0.976245924545878\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 41, train_loss = 12.85939011350274, train_acc = 0.9765952491849091\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 42, train_loss = 12.582262814044952, train_acc = 0.9770610153702841\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 43, train_loss = 12.316458847373724, train_acc = 0.9777596646483465\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 44, train_loss = 12.061343144625425, train_acc = 0.9781089892873778\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 45, train_loss = 11.816473811864853, train_acc = 0.9785747554727526\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 46, train_loss = 11.58123441413045, train_acc = 0.9792734047508151\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 47, train_loss = 11.35470488294959, train_acc = 0.9796227293898463\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 48, train_loss = 11.136397536844015, train_acc = 0.9798556124825337\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 49, train_loss = 10.925798833370209, train_acc = 0.9799720540288775\n",
      "test Acc 0.9720670391061452:\n",
      "29th- epoch: 50, train_loss = 10.722466226667166, train_acc = 0.9804378202142524\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 51, train_loss = 10.525807287544012, train_acc = 0.9809035863996274\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 52, train_loss = 10.33547099865973, train_acc = 0.9811364694923148\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 53, train_loss = 10.151138899847865, train_acc = 0.9813693525850024\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 54, train_loss = 9.972478911280632, train_acc = 0.9817186772240335\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 55, train_loss = 9.799329500645399, train_acc = 0.9817186772240335\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 56, train_loss = 9.631363738328218, train_acc = 0.9821844434094085\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 57, train_loss = 9.468295542523265, train_acc = 0.9825337680484397\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 58, train_loss = 9.3098060246557, train_acc = 0.9826502095947834\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 59, train_loss = 9.155803205445409, train_acc = 0.9829995342338146\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 60, train_loss = 9.006155379116535, train_acc = 0.9831159757801584\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 61, train_loss = 8.860588600859046, train_acc = 0.9831159757801584\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 62, train_loss = 8.718688512220979, train_acc = 0.9834653004191896\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 63, train_loss = 8.580574879422784, train_acc = 0.983698183511877\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 64, train_loss = 8.44597838819027, train_acc = 0.984163949697252\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 65, train_loss = 8.314670704305172, train_acc = 0.9842803912435957\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 66, train_loss = 8.186724064871669, train_acc = 0.984163949697252\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 67, train_loss = 8.062022326514125, train_acc = 0.9846297158826269\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 68, train_loss = 7.940409777686, train_acc = 0.9850954820680019\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 69, train_loss = 7.821726460009813, train_acc = 0.985444806707033\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 70, train_loss = 7.705846678465605, train_acc = 0.9856776897997206\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 71, train_loss = 7.592677673324943, train_acc = 0.9857941313460643\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 72, train_loss = 7.482231544330716, train_acc = 0.985910572892408\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 73, train_loss = 7.374272458255291, train_acc = 0.9862598975314392\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 74, train_loss = 7.268610563129187, train_acc = 0.9866092221704704\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 75, train_loss = 7.165305448696017, train_acc = 0.9866092221704704\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 76, train_loss = 7.064237924292684, train_acc = 0.9867256637168141\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 77, train_loss = 6.965089503675699, train_acc = 0.9867256637168141\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 78, train_loss = 6.86821173876524, train_acc = 0.9871914299021891\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 79, train_loss = 6.77347812242806, train_acc = 0.9874243129948765\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 80, train_loss = 6.680622847750783, train_acc = 0.9876571960875641\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 81, train_loss = 6.589940270408988, train_acc = 0.9877736376339078\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 82, train_loss = 6.500967947766185, train_acc = 0.9880065207265952\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 83, train_loss = 6.413809597492218, train_acc = 0.9880065207265952\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 84, train_loss = 6.3284535221755505, train_acc = 0.9881229622729389\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 85, train_loss = 6.244902636855841, train_acc = 0.9881229622729389\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 86, train_loss = 6.162882065400481, train_acc = 0.9884722869119702\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 87, train_loss = 6.082600144669414, train_acc = 0.9890544946436889\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 88, train_loss = 6.003881482407451, train_acc = 0.9892873777363763\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 89, train_loss = 5.926574306562543, train_acc = 0.9895202608290639\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 90, train_loss = 5.850760011002421, train_acc = 0.9896367023754076\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 91, train_loss = 5.776294203475118, train_acc = 0.9897531439217513\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 92, train_loss = 5.703039398416877, train_acc = 0.9899860270144387\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 93, train_loss = 5.6310551492497325, train_acc = 0.9899860270144387\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 94, train_loss = 5.560446816496551, train_acc = 0.9899860270144387\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 95, train_loss = 5.491146964021027, train_acc = 0.9904517931998137\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 96, train_loss = 5.4229425843805075, train_acc = 0.9906846762925011\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 97, train_loss = 5.355915860272944, train_acc = 0.9906846762925011\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 98, train_loss = 5.290017834864557, train_acc = 0.990801117838845\n",
      "test Acc 0.9809124767225326:\n",
      "29th- epoch: 99, train_loss = 5.22528276219964, train_acc = 0.9910340009315324\n",
      "test Acc 0.9813780260707635:\n",
      "29th- epoch: 100, train_loss = 5.161633586511016, train_acc = 0.9910340009315324\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 101, train_loss = 5.098999516107142, train_acc = 0.9911504424778761\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 102, train_loss = 5.037504554726183, train_acc = 0.9913833255705635\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 103, train_loss = 4.976786851882935, train_acc = 0.9914997671169073\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 104, train_loss = 4.917400452308357, train_acc = 0.9918490917559385\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 105, train_loss = 4.85878671426326, train_acc = 0.9918490917559385\n",
      "test Acc 0.9837057728119181:\n",
      "29th- epoch: 106, train_loss = 4.801115044392645, train_acc = 0.992081974848626\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 107, train_loss = 4.744487634859979, train_acc = 0.9921984163949698\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 108, train_loss = 4.688550051301718, train_acc = 0.9921984163949698\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 109, train_loss = 4.633549529127777, train_acc = 0.9921984163949698\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 110, train_loss = 4.5792730478569865, train_acc = 0.9923148579413135\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 111, train_loss = 4.526020283810794, train_acc = 0.9924312994876572\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 112, train_loss = 4.473484444431961, train_acc = 0.9924312994876572\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 113, train_loss = 4.421834837645292, train_acc = 0.9925477410340009\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 114, train_loss = 4.371069240383804, train_acc = 0.9924312994876572\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 115, train_loss = 4.321072592400014, train_acc = 0.9924312994876572\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 116, train_loss = 4.271779633127153, train_acc = 0.9924312994876572\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 117, train_loss = 4.2233647014945745, train_acc = 0.9923148579413135\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 118, train_loss = 4.1756172040477395, train_acc = 0.9923148579413135\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 119, train_loss = 4.12885728571564, train_acc = 0.9925477410340009\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 120, train_loss = 4.08259851206094, train_acc = 0.9927806241266884\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 121, train_loss = 4.03711858484894, train_acc = 0.9930135072193759\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 122, train_loss = 3.9924366269260645, train_acc = 0.9930135072193759\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 123, train_loss = 3.9481806764379144, train_acc = 0.9931299487657196\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 124, train_loss = 3.9050133107230067, train_acc = 0.9931299487657196\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 125, train_loss = 3.8621756406500936, train_acc = 0.9932463903120633\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 126, train_loss = 3.820270341821015, train_acc = 0.9933628318584071\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 127, train_loss = 3.7789413845166564, train_acc = 0.9933628318584071\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 128, train_loss = 3.738226498477161, train_acc = 0.9934792734047508\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 129, train_loss = 3.6983560137450695, train_acc = 0.9934792734047508\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 130, train_loss = 3.6590246530249715, train_acc = 0.9935957149510946\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 131, train_loss = 3.6203009439632297, train_acc = 0.9937121564974383\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 132, train_loss = 3.5822599353268743, train_acc = 0.9939450395901258\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 133, train_loss = 3.5448501240462065, train_acc = 0.9939450395901258\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 134, train_loss = 3.50798299908638, train_acc = 0.9940614811364695\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 135, train_loss = 3.4717100001871586, train_acc = 0.9940614811364695\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 136, train_loss = 3.4360622302629054, train_acc = 0.9941779226828132\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 137, train_loss = 3.4011001088656485, train_acc = 0.9941779226828132\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 138, train_loss = 3.366526680532843, train_acc = 0.9941779226828132\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 139, train_loss = 3.3326202128082514, train_acc = 0.9941779226828132\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 140, train_loss = 3.299338510725647, train_acc = 0.994294364229157\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 141, train_loss = 3.2665201094932854, train_acc = 0.9945272473218444\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 142, train_loss = 3.234239144716412, train_acc = 0.9946436888681882\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 143, train_loss = 3.2026230464689434, train_acc = 0.9946436888681882\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 144, train_loss = 3.1714186989702284, train_acc = 0.9946436888681882\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 145, train_loss = 3.1407716809771955, train_acc = 0.9947601304145319\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 146, train_loss = 3.11072156438604, train_acc = 0.9948765719608756\n",
      "test Acc 0.9851024208566108:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 147, train_loss = 3.081155426800251, train_acc = 0.9948765719608756\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 148, train_loss = 3.052047746721655, train_acc = 0.9949930135072194\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 149, train_loss = 3.023498518858105, train_acc = 0.9949930135072194\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 150, train_loss = 2.9953449331223965, train_acc = 0.9953423381462506\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 151, train_loss = 2.9676340855658054, train_acc = 0.9954587796925943\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 152, train_loss = 2.9404268637299538, train_acc = 0.9954587796925943\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 153, train_loss = 2.913617144804448, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 154, train_loss = 2.887286762241274, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 155, train_loss = 2.8614622820168734, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 156, train_loss = 2.8360662958584726, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 157, train_loss = 2.810978866647929, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 158, train_loss = 2.786438826005906, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 159, train_loss = 2.7622548355720937, train_acc = 0.9956916627852818\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 160, train_loss = 2.738452378194779, train_acc = 0.9956916627852818\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 161, train_loss = 2.715007569640875, train_acc = 0.9958081043316255\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 162, train_loss = 2.6920146732591093, train_acc = 0.9958081043316255\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 163, train_loss = 2.6693245861679316, train_acc = 0.9958081043316255\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 164, train_loss = 2.6469699791632593, train_acc = 0.9959245458779693\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 165, train_loss = 2.6250835307873785, train_acc = 0.9959245458779693\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 166, train_loss = 2.6034577321261168, train_acc = 0.9959245458779693\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 167, train_loss = 2.582333482336253, train_acc = 0.996040987424313\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 168, train_loss = 2.5613912302069366, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 169, train_loss = 2.5407689814455807, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 170, train_loss = 2.520536767318845, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 171, train_loss = 2.5007000328041613, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 172, train_loss = 2.4811162180267274, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 173, train_loss = 2.4619098301045597, train_acc = 0.9962738705170004\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 174, train_loss = 2.443005084991455, train_acc = 0.9962738705170004\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 175, train_loss = 2.4243616736494005, train_acc = 0.9963903120633442\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 176, train_loss = 2.4060910549014807, train_acc = 0.9962738705170004\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 177, train_loss = 2.3879386470653117, train_acc = 0.9962738705170004\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 178, train_loss = 2.370204704347998, train_acc = 0.9962738705170004\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 179, train_loss = 2.3526811846531928, train_acc = 0.9962738705170004\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 180, train_loss = 2.335580655839294, train_acc = 0.9963903120633442\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 181, train_loss = 2.318659693002701, train_acc = 0.9963903120633442\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 182, train_loss = 2.301997721195221, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 183, train_loss = 2.285538083408028, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 184, train_loss = 2.269460889045149, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 185, train_loss = 2.2535412558354437, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 186, train_loss = 2.2378909538965672, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 187, train_loss = 2.222552268533036, train_acc = 0.996506753609688\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 188, train_loss = 2.2073567274492234, train_acc = 0.996506753609688\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 189, train_loss = 2.192460438935086, train_acc = 0.9966231951560317\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 190, train_loss = 2.177821649936959, train_acc = 0.9966231951560317\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 191, train_loss = 2.163328408030793, train_acc = 0.9966231951560317\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 192, train_loss = 2.149123263778165, train_acc = 0.9967396367023754\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 193, train_loss = 2.1351357139647007, train_acc = 0.9967396367023754\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 194, train_loss = 2.121333076385781, train_acc = 0.9967396367023754\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 195, train_loss = 2.10780418664217, train_acc = 0.9967396367023754\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 196, train_loss = 2.094513372750953, train_acc = 0.9968560782487191\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 197, train_loss = 2.081238151760772, train_acc = 0.9968560782487191\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 198, train_loss = 2.0683803644496948, train_acc = 0.9968560782487191\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 199, train_loss = 2.055631570518017, train_acc = 0.9968560782487191\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 200, train_loss = 2.0430318724829704, train_acc = 0.9968560782487191\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 201, train_loss = 2.030683071585372, train_acc = 0.9968560782487191\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 202, train_loss = 2.0185190450865775, train_acc = 0.9968560782487191\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 203, train_loss = 2.0064951467793435, train_acc = 0.9968560782487191\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 204, train_loss = 1.9946317363064736, train_acc = 0.9968560782487191\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 205, train_loss = 1.9830396932084113, train_acc = 0.9968560782487191\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 206, train_loss = 1.9716196756344289, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 207, train_loss = 1.9603136021178216, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 208, train_loss = 1.9492295049130917, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 209, train_loss = 1.9381555009167641, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 210, train_loss = 1.927511579124257, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 211, train_loss = 1.9168159887194633, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 212, train_loss = 1.9063522194046527, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 213, train_loss = 1.896050413371995, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 214, train_loss = 1.8858696420211345, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 215, train_loss = 1.8758503396529704, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 216, train_loss = 1.8660170175135136, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 217, train_loss = 1.8562630366068333, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 218, train_loss = 1.8466800041496754, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 219, train_loss = 1.8371178980451077, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 220, train_loss = 1.827823057770729, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 221, train_loss = 1.8185460530221462, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 222, train_loss = 1.8095308914780617, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 223, train_loss = 1.8004859264474362, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 224, train_loss = 1.7917186275590211, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 225, train_loss = 1.782932511297986, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 226, train_loss = 1.774353853194043, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 227, train_loss = 1.7658493618946522, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 228, train_loss = 1.757512602256611, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 229, train_loss = 1.7492248427588493, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 230, train_loss = 1.7410692397970706, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 231, train_loss = 1.733008962124586, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 232, train_loss = 1.7251265074592084, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 233, train_loss = 1.717239300487563, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 234, train_loss = 1.7095748807769269, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 235, train_loss = 1.7019061918836087, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 236, train_loss = 1.6944298024754971, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 237, train_loss = 1.6869929246604443, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 238, train_loss = 1.6796381112653762, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 239, train_loss = 1.6724279585760087, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 240, train_loss = 1.6652701410930604, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 241, train_loss = 1.6581793066579849, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 242, train_loss = 1.6512131268391386, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 243, train_loss = 1.6442885994911194, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 244, train_loss = 1.6375362476101145, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 245, train_loss = 1.6307490380713716, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 246, train_loss = 1.6240565789630637, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 247, train_loss = 1.6175741838524118, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 248, train_loss = 1.6110384091734886, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 249, train_loss = 1.6046943267574534, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 250, train_loss = 1.5982875488698483, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 251, train_loss = 1.5921299457550049, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 252, train_loss = 1.5859168755123392, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 253, train_loss = 1.5797707425663248, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 254, train_loss = 1.5737633556127548, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 255, train_loss = 1.5677714186022058, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 256, train_loss = 1.5619179209461436, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 257, train_loss = 1.5560294762253761, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 258, train_loss = 1.5502267194679007, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 259, train_loss = 1.5446009747684002, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 260, train_loss = 1.5388956492533907, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 261, train_loss = 1.5333461252739653, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 262, train_loss = 1.5277991319308057, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 263, train_loss = 1.5223639532923698, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 264, train_loss = 1.516971973120235, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 265, train_loss = 1.5116253545274958, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 266, train_loss = 1.5063018016517162, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 267, train_loss = 1.501148651004769, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 268, train_loss = 1.4959170756628737, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 269, train_loss = 1.4908685497939587, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 270, train_loss = 1.4858090145280585, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 271, train_loss = 1.480712492018938, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 272, train_loss = 1.4758780499687418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 273, train_loss = 1.4709415497491136, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 274, train_loss = 1.4660387275507674, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 275, train_loss = 1.4613253498682752, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 276, train_loss = 1.4564938520779833, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 277, train_loss = 1.4518603459000587, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 278, train_loss = 1.4472162252059206, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 279, train_loss = 1.4425376603612676, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 280, train_loss = 1.438062166213058, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 281, train_loss = 1.4334679743042216, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 282, train_loss = 1.4290059370687231, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 283, train_loss = 1.4246656708419323, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 284, train_loss = 1.4202164908638224, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 285, train_loss = 1.4158502506325021, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 286, train_loss = 1.4115965055534616, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 287, train_loss = 1.4073015177855268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 288, train_loss = 1.4032083613565192, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 289, train_loss = 1.3989469235530123, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 290, train_loss = 1.3948605234036222, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 291, train_loss = 1.3907565561821684, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 292, train_loss = 1.3867025300860405, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 293, train_loss = 1.3826877573737875, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 294, train_loss = 1.3787669204175472, train_acc = 0.9973218444340941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 295, train_loss = 1.3747379767009988, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 296, train_loss = 1.370939745218493, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 297, train_loss = 1.3670033117523417, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 298, train_loss = 1.363190325559117, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 299, train_loss = 1.3594493257114664, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 300, train_loss = 1.355693700374104, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 301, train_loss = 1.3519760929048061, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 302, train_loss = 1.3482259263982996, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 303, train_loss = 1.344616531045176, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 304, train_loss = 1.3409897275269032, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 305, train_loss = 1.3373851738870144, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 306, train_loss = 1.3338595479726791, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 307, train_loss = 1.3303336128592491, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 308, train_loss = 1.3267941338708624, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 309, train_loss = 1.3233611062169075, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 310, train_loss = 1.3198942132294178, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 311, train_loss = 1.3165577203035355, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 312, train_loss = 1.3131367502501234, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 313, train_loss = 1.309758223593235, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 314, train_loss = 1.3064833171665668, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 315, train_loss = 1.30314189940691, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 316, train_loss = 1.2999578391900286, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 317, train_loss = 1.2967132379999384, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 318, train_loss = 1.2934668672969565, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 319, train_loss = 1.2903560387785546, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 320, train_loss = 1.2871101411874406, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 321, train_loss = 1.284040109545458, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 322, train_loss = 1.2808978545363061, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 323, train_loss = 1.277900209010113, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 324, train_loss = 1.274803298234474, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 325, train_loss = 1.2717965245246887, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 326, train_loss = 1.2688661813735962, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 327, train_loss = 1.2658207938075066, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 328, train_loss = 1.262883781164419, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 329, train_loss = 1.2599372044205666, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 330, train_loss = 1.2570758138899691, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 331, train_loss = 1.254180196672678, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 332, train_loss = 1.2513524778187275, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 333, train_loss = 1.2485368537600152, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 334, train_loss = 1.2457098389859311, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 335, train_loss = 1.2428736351430416, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 336, train_loss = 1.2401685528457165, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 337, train_loss = 1.2374960258603096, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 338, train_loss = 1.2347444978659041, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 339, train_loss = 1.231995664536953, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 340, train_loss = 1.229324498504866, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 341, train_loss = 1.226706410467159, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 342, train_loss = 1.2239668617839925, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 343, train_loss = 1.2214245460927486, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 344, train_loss = 1.2188512521679513, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 345, train_loss = 1.216204045980703, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 346, train_loss = 1.2137141997809522, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 347, train_loss = 1.2111704883282073, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 348, train_loss = 1.2086529657244682, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 349, train_loss = 1.2060918894712813, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 350, train_loss = 1.2036444780533202, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 351, train_loss = 1.2012293239240535, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 352, train_loss = 1.1987679761950858, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 353, train_loss = 1.1963580449228175, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 354, train_loss = 1.1939871373469941, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 355, train_loss = 1.1915419499273412, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 356, train_loss = 1.1891887485980988, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 357, train_loss = 1.1868691593408585, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 358, train_loss = 1.1845230981707573, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 359, train_loss = 1.1821748378570192, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 360, train_loss = 1.1798918533022515, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 361, train_loss = 1.1776019160752185, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 362, train_loss = 1.1752804331481457, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 363, train_loss = 1.173105277121067, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 364, train_loss = 1.1707832950050943, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 365, train_loss = 1.168654431879986, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 366, train_loss = 1.1664977979962714, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 367, train_loss = 1.164230588823557, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 368, train_loss = 1.162081851332914, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 369, train_loss = 1.1598531517083757, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 370, train_loss = 1.1577777328784578, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 371, train_loss = 1.1556152154807933, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 372, train_loss = 1.153589230030775, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 373, train_loss = 1.151377463073004, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 374, train_loss = 1.1494106451864354, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 375, train_loss = 1.147295467555523, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 376, train_loss = 1.1452585223014466, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 377, train_loss = 1.1432234061066993, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 378, train_loss = 1.1411698870360851, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 379, train_loss = 1.1391788758337498, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 380, train_loss = 1.1370756675605662, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 381, train_loss = 1.1351903465692885, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 382, train_loss = 1.1331725493073463, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 383, train_loss = 1.1312918029725552, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 384, train_loss = 1.1293183018569835, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 385, train_loss = 1.1273752351407893, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 386, train_loss = 1.1254743126337416, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 387, train_loss = 1.123518345237244, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 388, train_loss = 1.121669930696953, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 389, train_loss = 1.1197388296131976, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 390, train_loss = 1.1179220552439801, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 391, train_loss = 1.1160376121406443, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 392, train_loss = 1.114286508411169, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 393, train_loss = 1.1123434019391425, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 394, train_loss = 1.110594242811203, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 395, train_loss = 1.108743769407738, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 396, train_loss = 1.1069305303390138, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 397, train_loss = 1.1051932300324552, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 398, train_loss = 1.10334311920451, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 399, train_loss = 1.101692562282551, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 400, train_loss = 1.0998720998759381, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 401, train_loss = 1.0981569439172745, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 402, train_loss = 1.0963602773845196, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 403, train_loss = 1.0947192460298538, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 404, train_loss = 1.0929714553058147, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 405, train_loss = 1.0912505574524403, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 406, train_loss = 1.0896406285464764, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 407, train_loss = 1.0879351024632342, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 408, train_loss = 1.0863207653164864, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 409, train_loss = 1.0845717315678485, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 410, train_loss = 1.0830004066228867, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 411, train_loss = 1.0813653419609182, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 412, train_loss = 1.0797312706708908, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 413, train_loss = 1.0780417968635447, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 414, train_loss = 1.0764695815742016, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 415, train_loss = 1.0748177890782245, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 416, train_loss = 1.073237869888544, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 417, train_loss = 1.0716763685340993, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 418, train_loss = 1.0701248335535638, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 419, train_loss = 1.0685432329773903, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 420, train_loss = 1.0670272161369212, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 421, train_loss = 1.065406220674049, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 422, train_loss = 1.0639154526288621, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 423, train_loss = 1.0622742499108426, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 424, train_loss = 1.060886810242664, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 425, train_loss = 1.0592521503567696, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 426, train_loss = 1.057901223481167, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 427, train_loss = 1.0563385374844074, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 428, train_loss = 1.0548834924702533, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 429, train_loss = 1.0533879312279169, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 430, train_loss = 1.0519251823425293, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 431, train_loss = 1.0504061182437, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 432, train_loss = 1.049028371780878, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 433, train_loss = 1.0475739637913648, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 434, train_loss = 1.0460991114377975, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 435, train_loss = 1.044711814582115, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 436, train_loss = 1.0433317398128565, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 437, train_loss = 1.0418647999467794, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 438, train_loss = 1.0405682474374771, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 439, train_loss = 1.0390631941554602, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 440, train_loss = 1.0377932588162366, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 441, train_loss = 1.0364391915500164, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 442, train_loss = 1.0350749219360296, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 443, train_loss = 1.0336631486716215, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 444, train_loss = 1.032372821122408, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 445, train_loss = 1.0309086044726428, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 446, train_loss = 1.0296882589755114, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 447, train_loss = 1.0283670400676783, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 448, train_loss = 1.026944956422085, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 449, train_loss = 1.0256713007984217, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 450, train_loss = 1.0243682824075222, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 451, train_loss = 1.0230211603047792, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 452, train_loss = 1.021781362593174, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 453, train_loss = 1.0205027423799038, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 454, train_loss = 1.0191006337699946, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 455, train_loss = 1.0179054935870226, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 456, train_loss = 1.0166038659808692, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 457, train_loss = 1.0153741836547852, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 458, train_loss = 1.0141292363405228, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 459, train_loss = 1.0128532014787197, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 460, train_loss = 1.0116163603961468, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 461, train_loss = 1.0103974069061223, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 462, train_loss = 1.0091546798648778, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 463, train_loss = 1.0079776930215303, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 464, train_loss = 1.0067435850796755, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 465, train_loss = 1.0055781391856726, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 466, train_loss = 1.0043098168971483, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 467, train_loss = 1.0031722846033517, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 468, train_loss = 1.0019768600759562, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 469, train_loss = 1.00082328915596, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 470, train_loss = 0.9996957195398863, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 471, train_loss = 0.9985055463912431, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 472, train_loss = 0.9973065927624702, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 473, train_loss = 0.9961962116358336, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 474, train_loss = 0.9950638338923454, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 475, train_loss = 0.9938764025864657, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 476, train_loss = 0.9927079851331655, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 477, train_loss = 0.9916243702173233, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 478, train_loss = 0.9904288426041603, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 479, train_loss = 0.9894039630889893, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 480, train_loss = 0.9882494620978832, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 481, train_loss = 0.9871139129099902, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 482, train_loss = 0.9859691163001116, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 483, train_loss = 0.984952157974476, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 484, train_loss = 0.9839003048837185, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 485, train_loss = 0.9827692285180092, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 486, train_loss = 0.9816804900765419, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 487, train_loss = 0.9805825749936048, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 488, train_loss = 0.9795579475758132, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 489, train_loss = 0.9784714418055955, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 490, train_loss = 0.9775105031731073, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 491, train_loss = 0.9763577058911324, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 492, train_loss = 0.9753282405436039, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 493, train_loss = 0.9743461236357689, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 494, train_loss = 0.9733208740653936, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 495, train_loss = 0.9722018117608968, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 496, train_loss = 0.971216189354891, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 497, train_loss = 0.9702180375752505, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 498, train_loss = 0.9691608349385206, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 499, train_loss = 0.968098579585785, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████▌  | 29/30 [3:18:28<06:51, 411.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "30th- epoch: 0, train_loss = 275.8364187479019, train_acc = 0.42745691662785285\n",
      "test Acc 0.5279329608938548:\n",
      "30th- epoch: 1, train_loss = 214.5491360425949, train_acc = 0.553679552864462\n",
      "test Acc 0.5702979515828678:\n",
      "30th- epoch: 2, train_loss = 166.85157072544098, train_acc = 0.5723102002794597\n",
      "test Acc 0.590782122905028:\n",
      "30th- epoch: 3, train_loss = 137.99618256092072, train_acc = 0.6462505822077317\n",
      "test Acc 0.7313780260707635:\n",
      "30th- epoch: 4, train_loss = 117.44333189725876, train_acc = 0.7531439217512809\n",
      "test Acc 0.7816573556797021:\n",
      "30th- epoch: 5, train_loss = 101.02734237909317, train_acc = 0.7850489054494644\n",
      "test Acc 0.8040037243947858:\n",
      "30th- epoch: 6, train_loss = 87.73495781421661, train_acc = 0.8025151374010246\n",
      "test Acc 0.824487895716946:\n",
      "30th- epoch: 7, train_loss = 77.02870404720306, train_acc = 0.8303446669771775\n",
      "test Acc 0.8542830540037244:\n",
      "30th- epoch: 8, train_loss = 68.19792050123215, train_acc = 0.8641127154168607\n",
      "test Acc 0.8766294227188082:\n",
      "30th- epoch: 9, train_loss = 60.759939432144165, train_acc = 0.8843735444806707\n",
      "test Acc 0.8971135940409684:\n",
      "30th- epoch: 10, train_loss = 54.45276668667793, train_acc = 0.9002095947834188\n",
      "test Acc 0.909683426443203:\n",
      "30th- epoch: 11, train_loss = 49.07216823101044, train_acc = 0.9131346064275734\n",
      "test Acc 0.9203910614525139:\n",
      "30th- epoch: 12, train_loss = 44.46166841685772, train_acc = 0.9251280857009782\n",
      "test Acc 0.9320297951582868:\n",
      "30th- epoch: 13, train_loss = 40.50028416514397, train_acc = 0.9372380065207266\n",
      "test Acc 0.9376163873370578:\n",
      "30th- epoch: 14, train_loss = 37.09079560637474, train_acc = 0.9456217978574756\n",
      "test Acc 0.9422718808193669:\n",
      "30th- epoch: 15, train_loss = 34.1593598946929, train_acc = 0.9494643688868188\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 16, train_loss = 31.648281194269657, train_acc = 0.9513274336283186\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 17, train_loss = 29.495365031063557, train_acc = 0.9528411737307871\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 18, train_loss = 27.641942970454693, train_acc = 0.955519329296693\n",
      "test Acc 0.9511173184357542:\n",
      "30th- epoch: 19, train_loss = 26.0381640791893, train_acc = 0.9598276665114113\n",
      "test Acc 0.9534450651769087:\n",
      "30th- epoch: 20, train_loss = 24.641274370253086, train_acc = 0.961690731252911\n",
      "test Acc 0.9548417132216015:\n",
      "30th- epoch: 21, train_loss = 23.41529244184494, train_acc = 0.9634373544480671\n",
      "test Acc 0.957635009310987:\n",
      "30th- epoch: 22, train_loss = 22.330640520900488, train_acc = 0.9659990684676293\n",
      "test Acc 0.9594972067039106:\n",
      "30th- epoch: 23, train_loss = 21.36421251296997, train_acc = 0.9677456916627852\n",
      "test Acc 0.9608938547486033:\n",
      "30th- epoch: 24, train_loss = 20.497341379523277, train_acc = 0.9692594317652539\n",
      "test Acc 0.9608938547486033:\n",
      "30th- epoch: 25, train_loss = 19.713981565088034, train_acc = 0.9704238472286912\n",
      "test Acc 0.9608938547486033:\n",
      "30th- epoch: 26, train_loss = 19.001001078635454, train_acc = 0.9710060549604099\n",
      "test Acc 0.9613594040968343:\n",
      "30th- epoch: 27, train_loss = 18.348307475447655, train_acc = 0.9720540288775035\n",
      "test Acc 0.962756052141527:\n",
      "30th- epoch: 28, train_loss = 17.747413355857134, train_acc = 0.972286911970191\n",
      "test Acc 0.9636871508379888:\n",
      "30th- epoch: 29, train_loss = 17.191457215696573, train_acc = 0.9729855612482534\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 30, train_loss = 16.674079529941082, train_acc = 0.9733348858872846\n",
      "test Acc 0.9646182495344506:\n",
      "30th- epoch: 31, train_loss = 16.190705839544535, train_acc = 0.9742664182580345\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 32, train_loss = 15.738267928361893, train_acc = 0.9743828598043782\n",
      "test Acc 0.9655493482309124:\n",
      "30th- epoch: 33, train_loss = 15.313466377556324, train_acc = 0.9744993013507219\n",
      "test Acc 0.9655493482309124:\n",
      "30th- epoch: 34, train_loss = 14.913156680762768, train_acc = 0.9747321844434094\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 35, train_loss = 14.535071179270744, train_acc = 0.9748486259897532\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 36, train_loss = 14.17691333964467, train_acc = 0.9750815090824406\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 37, train_loss = 13.836970247328281, train_acc = 0.9756637168141593\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 38, train_loss = 13.513543985784054, train_acc = 0.975780158360503\n",
      "test Acc 0.9664804469273743:\n",
      "30th- epoch: 39, train_loss = 13.205313608050346, train_acc = 0.976245924545878\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 40, train_loss = 12.91100288927555, train_acc = 0.9764788076385654\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 41, train_loss = 12.629412524402142, train_acc = 0.9770610153702841\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 42, train_loss = 12.359475445002317, train_acc = 0.9775267815556591\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 43, train_loss = 12.100653655827045, train_acc = 0.977992547741034\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 44, train_loss = 11.852195259183645, train_acc = 0.977992547741034\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 45, train_loss = 11.612992886453867, train_acc = 0.9782254308337215\n",
      "test Acc 0.9706703910614525:\n",
      "30th- epoch: 46, train_loss = 11.382588677108288, train_acc = 0.9790405216581276\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 47, train_loss = 11.160197015851736, train_acc = 0.9795062878435026\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 48, train_loss = 10.945662651211023, train_acc = 0.9799720540288775\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 49, train_loss = 10.738267678767443, train_acc = 0.9805542617605962\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 50, train_loss = 10.537659361958504, train_acc = 0.9811364694923148\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 51, train_loss = 10.343579020351171, train_acc = 0.9812529110386586\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 52, train_loss = 10.155553791671991, train_acc = 0.9812529110386586\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 53, train_loss = 9.973416339606047, train_acc = 0.9818351187703773\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 54, train_loss = 9.796747406944633, train_acc = 0.9820680018630648\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 55, train_loss = 9.625278756022453, train_acc = 0.9820680018630648\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 56, train_loss = 9.458851402625442, train_acc = 0.9820680018630648\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 57, train_loss = 9.29695799946785, train_acc = 0.9826502095947834\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 58, train_loss = 9.139590764418244, train_acc = 0.9827666511411272\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 59, train_loss = 8.986471300944686, train_acc = 0.9831159757801584\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 60, train_loss = 8.837537819519639, train_acc = 0.9829995342338146\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 61, train_loss = 8.692524010315537, train_acc = 0.9832324173265021\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 62, train_loss = 8.55125674791634, train_acc = 0.9835817419655333\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 63, train_loss = 8.413541557267308, train_acc = 0.9839310666045645\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 64, train_loss = 8.279355151578784, train_acc = 0.9843968327899395\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 65, train_loss = 8.148510443046689, train_acc = 0.9843968327899395\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 66, train_loss = 8.02094461582601, train_acc = 0.9847461574289706\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 67, train_loss = 7.896270813420415, train_acc = 0.9848625989753144\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 68, train_loss = 7.774653792381287, train_acc = 0.9853283651606893\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 69, train_loss = 7.655841138213873, train_acc = 0.9856776897997206\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 70, train_loss = 7.539804395288229, train_acc = 0.9857941313460643\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 71, train_loss = 7.426348006352782, train_acc = 0.9862598975314392\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 72, train_loss = 7.3153590597212315, train_acc = 0.9864927806241267\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 73, train_loss = 7.206793544813991, train_acc = 0.9867256637168141\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 74, train_loss = 7.100596260279417, train_acc = 0.9866092221704704\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 75, train_loss = 6.996475078165531, train_acc = 0.9866092221704704\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 76, train_loss = 6.894700847566128, train_acc = 0.9867256637168141\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 77, train_loss = 6.795108150690794, train_acc = 0.9868421052631579\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 78, train_loss = 6.697553807869554, train_acc = 0.9868421052631579\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 79, train_loss = 6.60213360004127, train_acc = 0.9869585468095017\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 80, train_loss = 6.508613279089332, train_acc = 0.9870749883558454\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 81, train_loss = 6.417068837210536, train_acc = 0.9876571960875641\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 82, train_loss = 6.327295802533627, train_acc = 0.9878900791802515\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 83, train_loss = 6.239390525966883, train_acc = 0.9878900791802515\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 84, train_loss = 6.153244391083717, train_acc = 0.9880065207265952\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 85, train_loss = 6.068893453106284, train_acc = 0.9883558453656265\n",
      "test Acc 0.9795158286778398:\n",
      "30th- epoch: 86, train_loss = 5.986170012503862, train_acc = 0.9885887284583139\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 87, train_loss = 5.905075980350375, train_acc = 0.9888216115510013\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 88, train_loss = 5.825485620647669, train_acc = 0.9891709361900326\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 89, train_loss = 5.747434636577964, train_acc = 0.9891709361900326\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 90, train_loss = 5.670959526672959, train_acc = 0.98940381928272\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 91, train_loss = 5.595737924799323, train_acc = 0.989869585468095\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 92, train_loss = 5.5218710247427225, train_acc = 0.9899860270144387\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 93, train_loss = 5.449339824728668, train_acc = 0.99033535165347\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 94, train_loss = 5.378096376545727, train_acc = 0.9904517931998137\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 95, train_loss = 5.308109904639423, train_acc = 0.9906846762925011\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 96, train_loss = 5.239447182975709, train_acc = 0.9910340009315324\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 97, train_loss = 5.172086741775274, train_acc = 0.9912668840242198\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 98, train_loss = 5.105915142223239, train_acc = 0.9914997671169073\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 99, train_loss = 5.041015264578164, train_acc = 0.9914997671169073\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 100, train_loss = 4.977252941578627, train_acc = 0.9914997671169073\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 101, train_loss = 4.914589900523424, train_acc = 0.9914997671169073\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 102, train_loss = 4.853101479820907, train_acc = 0.9916162086632511\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 103, train_loss = 4.792784499004483, train_acc = 0.9914997671169073\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 104, train_loss = 4.73349229991436, train_acc = 0.9916162086632511\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 105, train_loss = 4.675348005257547, train_acc = 0.9917326502095948\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 106, train_loss = 4.618130053393543, train_acc = 0.9918490917559385\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 107, train_loss = 4.562101783230901, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 108, train_loss = 4.506992883048952, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 109, train_loss = 4.4531321339309216, train_acc = 0.9926641825803446\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 110, train_loss = 4.400143411941826, train_acc = 0.9926641825803446\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 111, train_loss = 4.348178210668266, train_acc = 0.9927806241266884\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 112, train_loss = 4.2971616284921765, train_acc = 0.9928970656730322\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 113, train_loss = 4.247079805471003, train_acc = 0.9928970656730322\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 114, train_loss = 4.197923831641674, train_acc = 0.9928970656730322\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 115, train_loss = 4.149641131050885, train_acc = 0.9928970656730322\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 116, train_loss = 4.102336025796831, train_acc = 0.9928970656730322\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 117, train_loss = 4.055720051750541, train_acc = 0.9928970656730322\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 118, train_loss = 4.010120370425284, train_acc = 0.9930135072193759\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 119, train_loss = 3.965316453948617, train_acc = 0.9928970656730322\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 120, train_loss = 3.9212369360029697, train_acc = 0.9931299487657196\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 121, train_loss = 3.8780547631904483, train_acc = 0.9932463903120633\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 122, train_loss = 3.835521270520985, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 123, train_loss = 3.793792978860438, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 124, train_loss = 3.7528879530727863, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 125, train_loss = 3.712421474047005, train_acc = 0.9937121564974383\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 126, train_loss = 3.67290061712265, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 127, train_loss = 3.6339668948203325, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 128, train_loss = 3.5957481004297733, train_acc = 0.9939450395901258\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 129, train_loss = 3.558096152730286, train_acc = 0.9939450395901258\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 130, train_loss = 3.520825925283134, train_acc = 0.9939450395901258\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 131, train_loss = 3.4844020307064056, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 132, train_loss = 3.4487036149948835, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 133, train_loss = 3.413742769509554, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 134, train_loss = 3.3791358079761267, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 135, train_loss = 3.3453377978876233, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 136, train_loss = 3.3119820607826114, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 137, train_loss = 3.279292168561369, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 138, train_loss = 3.2470513652078807, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 139, train_loss = 3.2153947837650776, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 140, train_loss = 3.1843000375665724, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 141, train_loss = 3.1537508629262447, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 142, train_loss = 3.123652505222708, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 143, train_loss = 3.0941723021678627, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 144, train_loss = 3.0650983708910644, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 145, train_loss = 3.0365685280412436, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 146, train_loss = 3.0083550345152617, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 147, train_loss = 2.980721613857895, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 148, train_loss = 2.9535454125143588, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 149, train_loss = 2.926816464867443, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 150, train_loss = 2.9005568251013756, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 151, train_loss = 2.874590086285025, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 152, train_loss = 2.8489639554172754, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 153, train_loss = 2.8238600180484354, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 154, train_loss = 2.7991330232471228, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 155, train_loss = 2.77491507306695, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 156, train_loss = 2.750873643439263, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 157, train_loss = 2.727423134725541, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 158, train_loss = 2.7041431847028434, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 159, train_loss = 2.6814798642881215, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 160, train_loss = 2.6589205279015005, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 161, train_loss = 2.636768165975809, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 162, train_loss = 2.6150237363763154, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 163, train_loss = 2.593540778849274, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 164, train_loss = 2.5726170260459185, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 165, train_loss = 2.551839256193489, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 166, train_loss = 2.531361737754196, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 167, train_loss = 2.5113243074156344, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 168, train_loss = 2.4914182648062706, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 169, train_loss = 2.4720907346345484, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 170, train_loss = 2.452888501342386, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 171, train_loss = 2.433982497546822, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 172, train_loss = 2.415431336965412, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 173, train_loss = 2.3971444577910006, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 174, train_loss = 2.3791647949256003, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 175, train_loss = 2.361502097453922, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 176, train_loss = 2.3439086019061506, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 177, train_loss = 2.3268057727254927, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 178, train_loss = 2.3098197667859495, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 179, train_loss = 2.293150082230568, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 180, train_loss = 2.276799260172993, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 181, train_loss = 2.26066722208634, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 182, train_loss = 2.2448272332549095, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 183, train_loss = 2.2290937029756606, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 184, train_loss = 2.2137981676496565, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 185, train_loss = 2.1987473270855844, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 186, train_loss = 2.1837008136790246, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 187, train_loss = 2.1690957993268967, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 188, train_loss = 2.1547835853416473, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 189, train_loss = 2.1404606737196445, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 190, train_loss = 2.1265609201509506, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 191, train_loss = 2.1127569389063865, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 192, train_loss = 2.099254307569936, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 193, train_loss = 2.085913208546117, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 194, train_loss = 2.0727672427892685, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 195, train_loss = 2.0599361148197204, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 196, train_loss = 2.0472564175724983, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 197, train_loss = 2.0346114970743656, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 198, train_loss = 2.022437335224822, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 199, train_loss = 2.0102349806111306, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 200, train_loss = 1.9982385362964123, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 201, train_loss = 1.9864580396097153, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 202, train_loss = 1.9748898558318615, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 203, train_loss = 1.963422107277438, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 204, train_loss = 1.952169045805931, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 205, train_loss = 1.9411162075120956, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 206, train_loss = 1.9301706824917346, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 207, train_loss = 1.9194607126992196, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 208, train_loss = 1.908925849944353, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 209, train_loss = 1.898439984768629, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 210, train_loss = 1.8882340069394559, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 211, train_loss = 1.8781145922839642, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 212, train_loss = 1.8681754854042083, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 213, train_loss = 1.858251228928566, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 214, train_loss = 1.848625847371295, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 215, train_loss = 1.8390084903221577, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 216, train_loss = 1.8297037333250046, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 217, train_loss = 1.8204122472088784, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 218, train_loss = 1.8112832456827164, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 219, train_loss = 1.8022397335153073, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 220, train_loss = 1.7933949828147888, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 221, train_loss = 1.784591306000948, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 222, train_loss = 1.7759504553396255, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 223, train_loss = 1.7674356736242771, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 224, train_loss = 1.759069224121049, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 225, train_loss = 1.7507654651999474, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 226, train_loss = 1.7425821460783482, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 227, train_loss = 1.7344673920888454, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 228, train_loss = 1.7265955072361976, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 229, train_loss = 1.7186963346321136, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 230, train_loss = 1.710937215713784, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 231, train_loss = 1.7032809157390147, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 232, train_loss = 1.6957118052523583, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 233, train_loss = 1.6882127486169338, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 234, train_loss = 1.6807897363323718, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 235, train_loss = 1.6735437426250428, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 236, train_loss = 1.6663623552303761, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 237, train_loss = 1.659292149124667, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 238, train_loss = 1.652226074365899, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 239, train_loss = 1.6453344982583076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 240, train_loss = 1.6385076891165227, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 241, train_loss = 1.6317294463515282, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 242, train_loss = 1.6250075349817052, train_acc = 0.9973218444340941\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 243, train_loss = 1.6184997422387823, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 244, train_loss = 1.6119693195214495, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 245, train_loss = 1.605555204092525, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 246, train_loss = 1.5991908287396654, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 247, train_loss = 1.5928477048873901, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 248, train_loss = 1.5867186872055754, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 249, train_loss = 1.5804627910256386, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 250, train_loss = 1.5744969384977594, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 251, train_loss = 1.5684257174143568, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 252, train_loss = 1.5625567138195038, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 253, train_loss = 1.5566521001746878, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 254, train_loss = 1.5508664374938235, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 255, train_loss = 1.5451453836867586, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 256, train_loss = 1.5395113552222028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 257, train_loss = 1.5339452549815178, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 258, train_loss = 1.5283708808710799, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 259, train_loss = 1.5228750730166212, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 260, train_loss = 1.5174580328166485, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 261, train_loss = 1.5121139598777518, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 262, train_loss = 1.5068448595702648, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 263, train_loss = 1.5015789294848219, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 264, train_loss = 1.4963722241809592, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 265, train_loss = 1.4912733720848337, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 266, train_loss = 1.4861726438393816, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 267, train_loss = 1.4811126241693273, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 268, train_loss = 1.476178719312884, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 269, train_loss = 1.471248166053556, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 270, train_loss = 1.4663864908507094, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 271, train_loss = 1.4616290045669302, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 272, train_loss = 1.4567970348289236, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 273, train_loss = 1.452076276182197, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 274, train_loss = 1.4473982168128714, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 275, train_loss = 1.4427641989896074, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 276, train_loss = 1.4381584773072973, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 277, train_loss = 1.4336706002941355, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 278, train_loss = 1.429210023372434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 279, train_loss = 1.4247133223107085, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 280, train_loss = 1.4203177243471146, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 281, train_loss = 1.415933339507319, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 282, train_loss = 1.4116348685929552, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 283, train_loss = 1.4074420953402296, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 284, train_loss = 1.4031891537597403, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 285, train_loss = 1.3989732190966606, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 286, train_loss = 1.3948532119393349, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 287, train_loss = 1.3907894702861086, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 288, train_loss = 1.3866606131196022, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 289, train_loss = 1.382648648112081, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 290, train_loss = 1.3786241809139028, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 291, train_loss = 1.374665517359972, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 292, train_loss = 1.370823678909801, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 293, train_loss = 1.3669316694140434, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 294, train_loss = 1.3631532788276672, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 295, train_loss = 1.3593451032647863, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 296, train_loss = 1.355564402998425, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 297, train_loss = 1.3517579039325938, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 298, train_loss = 1.3481252355268225, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 299, train_loss = 1.3444322583964095, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 300, train_loss = 1.3407788090407848, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 301, train_loss = 1.3372444262495264, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 302, train_loss = 1.3336664898088202, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 303, train_loss = 1.3300906084477901, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 304, train_loss = 1.3265523401787505, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 305, train_loss = 1.3231501864502206, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 306, train_loss = 1.3196825025370345, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 307, train_loss = 1.3162798335542902, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 308, train_loss = 1.3129566758871078, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 309, train_loss = 1.3095987836131826, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 310, train_loss = 1.306214182288386, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 311, train_loss = 1.3029665934154764, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 312, train_loss = 1.2996746512362733, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 313, train_loss = 1.296496618539095, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 314, train_loss = 1.293234987766482, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 315, train_loss = 1.2901499482104555, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 316, train_loss = 1.2869649616768584, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 317, train_loss = 1.2838436390156858, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 318, train_loss = 1.2806839744444005, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 319, train_loss = 1.277700763195753, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 320, train_loss = 1.274719179898966, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 321, train_loss = 1.2716275255079381, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 322, train_loss = 1.2686546829645522, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 323, train_loss = 1.2656877934932709, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 324, train_loss = 1.2627772937412374, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 325, train_loss = 1.2598413576488383, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 326, train_loss = 1.2569122103159316, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 327, train_loss = 1.2540775363449939, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 328, train_loss = 1.2512744751875289, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 329, train_loss = 1.2483397088944912, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 330, train_loss = 1.2456493129138835, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 331, train_loss = 1.2428313108976, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 332, train_loss = 1.24013503146125, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 333, train_loss = 1.2373789834673516, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 334, train_loss = 1.234572617977392, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 335, train_loss = 1.2320288482005708, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 336, train_loss = 1.2293067040736787, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 337, train_loss = 1.2267088678781874, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 338, train_loss = 1.2240638732910156, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 339, train_loss = 1.2213821199839003, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 340, train_loss = 1.2189534132485278, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 341, train_loss = 1.216297930746805, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 342, train_loss = 1.2137128760223277, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 343, train_loss = 1.2112392013077624, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 344, train_loss = 1.2087285506422631, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 345, train_loss = 1.2062450249795802, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 346, train_loss = 1.2037762912805192, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 347, train_loss = 1.2012876247172244, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 348, train_loss = 1.1989123784005642, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 349, train_loss = 1.1964485335047357, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 350, train_loss = 1.1940581016242504, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 351, train_loss = 1.1917624535853975, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 352, train_loss = 1.1893538522417657, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 353, train_loss = 1.1870392722194083, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 354, train_loss = 1.1847124981577508, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 355, train_loss = 1.1824313253164291, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 356, train_loss = 1.1800807379186153, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 357, train_loss = 1.177891731262207, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 358, train_loss = 1.175585416436661, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 359, train_loss = 1.1733279463951476, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 360, train_loss = 1.1711493234033696, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 361, train_loss = 1.1689537167549133, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 362, train_loss = 1.1667674382333644, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 363, train_loss = 1.1645515747368336, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 364, train_loss = 1.1624478536541574, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 365, train_loss = 1.160221119702328, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 366, train_loss = 1.1582145926658995, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 367, train_loss = 1.156071248173248, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 368, train_loss = 1.153948150575161, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 369, train_loss = 1.1519048735499382, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 370, train_loss = 1.149837500124704, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 371, train_loss = 1.1477122828364372, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 372, train_loss = 1.1457907247240655, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 373, train_loss = 1.143712745339144, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 374, train_loss = 1.1417149652843364, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 375, train_loss = 1.1396869172458537, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 376, train_loss = 1.1377178480033763, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 377, train_loss = 1.135811282962095, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 378, train_loss = 1.1338150364463218, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 379, train_loss = 1.131893755227793, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 380, train_loss = 1.1299220062792301, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 381, train_loss = 1.1279930286109447, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 382, train_loss = 1.126102524518501, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 383, train_loss = 1.1241632923483849, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 384, train_loss = 1.1223325940663926, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 385, train_loss = 1.1203998290002346, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 386, train_loss = 1.118472934991587, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 387, train_loss = 1.116720703721512, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 388, train_loss = 1.1148443718557246, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 389, train_loss = 1.113104936957825, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 390, train_loss = 1.1112321863765828, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 391, train_loss = 1.1094558934564702, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 392, train_loss = 1.1076440922915936, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 393, train_loss = 1.1059084944427013, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 394, train_loss = 1.1041216664016247, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 395, train_loss = 1.1024358049035072, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 396, train_loss = 1.1006319299340248, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 397, train_loss = 1.0989530409569852, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 398, train_loss = 1.0972148242290132, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 399, train_loss = 1.095553431659937, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 400, train_loss = 1.0937960458104499, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 401, train_loss = 1.092176737904083, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 402, train_loss = 1.0904769847984426, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 403, train_loss = 1.0888535591657273, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 404, train_loss = 1.0871946848928928, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 405, train_loss = 1.085564820736181, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 406, train_loss = 1.0839030742645264, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 407, train_loss = 1.0823956156964414, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 408, train_loss = 1.0806977711617947, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 409, train_loss = 1.07911417883588, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 410, train_loss = 1.0775517039000988, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 411, train_loss = 1.075994807004463, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 412, train_loss = 1.0743831023573875, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 413, train_loss = 1.0728487844462506, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 414, train_loss = 1.0712886254186742, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 415, train_loss = 1.0697906290297396, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 416, train_loss = 1.068195540457964, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 417, train_loss = 1.066686261445284, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 418, train_loss = 1.0652530416846275, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 419, train_loss = 1.0637046334450133, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 420, train_loss = 1.062158444256056, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 421, train_loss = 1.0607053053681739, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 422, train_loss = 1.0592459850013256, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 423, train_loss = 1.0577177914674394, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 424, train_loss = 1.056326974183321, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 425, train_loss = 1.054831379384268, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 426, train_loss = 1.0533975772559643, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 427, train_loss = 1.051969448744785, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 428, train_loss = 1.0505874206428416, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 429, train_loss = 1.0490744349663146, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 430, train_loss = 1.047710561484564, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 431, train_loss = 1.0462678571639117, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 432, train_loss = 1.044943551212782, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 433, train_loss = 1.043480730295414, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 434, train_loss = 1.0421613665821496, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 435, train_loss = 1.0407803319394588, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 436, train_loss = 1.0394096660020296, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 437, train_loss = 1.0380524632928427, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 438, train_loss = 1.0366868264973164, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 439, train_loss = 1.0353586971759796, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 440, train_loss = 1.0340057325956877, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 441, train_loss = 1.0327343195676804, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 442, train_loss = 1.0314310913381632, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 443, train_loss = 1.0300627164542675, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 444, train_loss = 1.0287431491015013, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 445, train_loss = 1.027501971781021, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 446, train_loss = 1.0262135565280914, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 447, train_loss = 1.024908222258091, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 448, train_loss = 1.0236580483615398, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 449, train_loss = 1.0223937444388866, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 450, train_loss = 1.0211545502243098, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 451, train_loss = 1.0198260570468847, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 452, train_loss = 1.0186593681573868, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 453, train_loss = 1.0174019634723663, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 454, train_loss = 1.0161845771071967, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 455, train_loss = 1.01494332155562, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 456, train_loss = 1.013759142399067, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 457, train_loss = 1.0125046943721827, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 458, train_loss = 1.011345705628628, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 459, train_loss = 1.0100924273428973, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 460, train_loss = 1.0089408780040685, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 461, train_loss = 1.0077626841666643, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 462, train_loss = 1.0065874569118023, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 463, train_loss = 1.0053924942913, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 464, train_loss = 1.004227144032484, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 465, train_loss = 1.0030507370829582, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 466, train_loss = 1.0018675712344702, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 467, train_loss = 1.0008233735861722, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 468, train_loss = 0.9996430687606335, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 469, train_loss = 0.9984486363828182, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 470, train_loss = 0.9973696333763655, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 471, train_loss = 0.9962168633937836, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 472, train_loss = 0.9951488611695822, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 473, train_loss = 0.9939992701110896, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 474, train_loss = 0.9928841429355089, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 475, train_loss = 0.9918246095476206, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 476, train_loss = 0.9906732974050101, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 477, train_loss = 0.9895828155276831, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 478, train_loss = 0.9885440369544085, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 479, train_loss = 0.9874942277965602, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 480, train_loss = 0.9863216678204481, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 481, train_loss = 0.985342094063526, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 482, train_loss = 0.984227138251299, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 483, train_loss = 0.9831742942333221, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 484, train_loss = 0.9822137430310249, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 485, train_loss = 0.9810579419136047, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 486, train_loss = 0.9799919997749384, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 487, train_loss = 0.9789848886430264, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 488, train_loss = 0.9779605728981551, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 489, train_loss = 0.9769382091762964, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 490, train_loss = 0.9759322168829385, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 491, train_loss = 0.9748801862297114, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 492, train_loss = 0.9738869456050452, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 493, train_loss = 0.9728752349910792, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 494, train_loss = 0.9718975871801376, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 495, train_loss = 0.9708410961029585, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 496, train_loss = 0.9698522562684957, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 497, train_loss = 0.9688930660486221, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 498, train_loss = 0.9679152344760951, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "30th- epoch: 499, train_loss = 0.9669605033996049, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 30/30 [3:24:38<00:00, 399.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3h 24min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    img_path = 'D:virus/image/4gram_512_pca/image_arr.npy'\n",
    "    label_path = 'D:virus/image/4gram_512_pca/label_arr.npy'\n",
    "    \n",
    "    data_a, label_a = np.load(img_path), np.load(label_path)\n",
    "    \n",
    "    idx = np.argsort(label_a)\n",
    "    \n",
    "    sorted_data = data_a[idx]\n",
    "    sorted_label = sorted(label_a)\n",
    "        \n",
    "    BATCH_SIZE = 64\n",
    "    TOTAL = 30\n",
    "    EPOCH = 500\n",
    "    NUM_CLASS = 9\n",
    "    LR = 0.005\n",
    "    SEED = [s for s in range(TOTAL)]\n",
    "    INPUT_NODES = 512                   \n",
    "    \n",
    "    CUDA_N = 'cuda:1'\n",
    "    \n",
    "    # creating data indices for spliting\n",
    "    full_dataset = CustomDataset(sorted_data, sorted_label)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # spliting\n",
    "    torch.manual_seed(10)\n",
    "    train_dataset, test_dataset = data.random_split(full_dataset, [train_size, test_size])\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    loss_total = []\n",
    "    acc_total = []\n",
    "    pred_total = []\n",
    "    true_total = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(TOTAL)):\n",
    "        \n",
    "        device = torch.device(CUDA_N if torch.cuda.is_available() else 'cpu')\n",
    "        torch.manual_seed(SEED[i])\n",
    "        net = Algorithm1(INPUT_NODES, NUM_CLASS)           \n",
    "        net.to(device)\n",
    "        print(net)\n",
    "        \n",
    "        softmax = nn.Softmax()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=LR, momentum = 0.1)\n",
    "        \n",
    "        loss_list = []\n",
    "        train_acc_list = []\n",
    "        test_acc_list = []\n",
    "        \n",
    "        pred_temp = []\n",
    "        true_temp = []\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            net.train()\n",
    "            running_loss = 0\n",
    "            total = train_size\n",
    "            correct = 0 \n",
    "            \n",
    "            for step, image_and_label in enumerate(train_loader):\n",
    "                inputs, labels = image_and_label            \n",
    "                inputs, labels = inputs.type(torch.FloatTensor).to(device), labels.type(torch.LongTensor).to(device)\n",
    "                \n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, pred = torch.max(outputs, dim=1)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            train_acc = correct/total\n",
    "            loss_list.append(running_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "            print('{}th- epoch: {}, train_loss = {}, train_acc = {}'.format(i+1, epoch, running_loss, train_acc))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                correct = 0\n",
    "                total = test_size\n",
    "                pt, tt = [], []\n",
    "                \n",
    "                for step_t, image_and_label_t in enumerate(test_loader):\n",
    "                    inputs_t, labels_t = image_and_label_t            \n",
    "                    inputs_t, labels_t = inputs_t.type(torch.FloatTensor).to(device), labels_t.type(torch.LongTensor).to(device)\n",
    "                    \n",
    "                    outputs_t = net(inputs_t)\n",
    "                    outputs_t = softmax(outputs_t)\n",
    "                    \n",
    "                    # test accuracy\n",
    "                    _, pred_t = torch.max(outputs_t, dim = 1)\n",
    "                    \n",
    "                    pt.append(pred_t)\n",
    "                    tt.append(labels_t)\n",
    "                    \n",
    "                    correct += (pred_t == labels_t).sum().item()\n",
    "                    \n",
    "                pred_temp.append(torch.cat(pt))\n",
    "                true_temp.append(torch.cat(tt))\n",
    "                \n",
    "                test_acc = correct/total\n",
    "                test_acc_list.append(test_acc)\n",
    "                \n",
    "                print('test Acc {}:'.format(test_acc))\n",
    "                \n",
    "        best_result_index = np.argmax(np.array(test_acc_list))\n",
    "        loss_total.append(loss_list[best_result_index])\n",
    "        acc_total.append(test_acc_list[best_result_index])\n",
    "        pred_total.append(pred_temp[best_result_index].tolist())\n",
    "        true_total.append(true_temp[best_result_index].tolist())\n",
    "        \n",
    "    file_name = 'res/Algorithm1_4gram'\n",
    "    torch.save(net.state_dict(), file_name +'.pth')\n",
    "    \n",
    "    loss_DF = pd.DataFrame(loss_total)\n",
    "    loss_DF.to_csv(file_name+\" loss.csv\")\n",
    "    \n",
    "    acc_DF = pd.DataFrame(acc_total)\n",
    "    acc_DF.to_csv(file_name +\" acc.csv\")\n",
    "    \n",
    "    pred_DF = pd.DataFrame(pred_total)\n",
    "    pred_DF.to_csv(file_name +\" pred.csv\")\n",
    "    \n",
    "    true_DF = pd.DataFrame(true_total)\n",
    "    true_DF.to_csv(file_name +\" true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
