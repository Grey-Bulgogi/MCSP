{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import utility.Data_loader as D\n",
    "from utility.Model import Base\n",
    "from utility.Custom import CustomDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 3gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                       | 0/10736 [00:00<?, ?it/s]\n",
      "  4%|██▊                                                                        | 394/10736 [00:00<00:02, 3904.05it/s]\n",
      "  7%|█████▍                                                                     | 784/10736 [00:00<00:02, 3894.29it/s]\n",
      " 10%|███████▍                                                                  | 1077/10736 [00:00<00:02, 3544.00it/s]\n",
      " 13%|█████████▉                                                                | 1436/10736 [00:00<00:02, 3556.33it/s]\n",
      " 17%|████████████▌                                                             | 1828/10736 [00:00<00:02, 3650.67it/s]\n",
      " 21%|███████████████▍                                                          | 2240/10736 [00:00<00:02, 3772.27it/s]\n",
      " 25%|██████████████████▍                                                       | 2677/10736 [00:00<00:02, 3853.45it/s]\n",
      " 28%|████████████████████▉                                                     | 3035/10736 [00:00<00:02, 3760.50it/s]\n",
      " 32%|███████████████████████▋                                                  | 3433/10736 [00:00<00:01, 3815.24it/s]\n",
      " 35%|██████████████████████████▏                                               | 3801/10736 [00:01<00:01, 3675.68it/s]\n",
      " 40%|█████████████████████████████▎                                            | 4245/10736 [00:01<00:01, 3875.68it/s]\n",
      " 43%|████████████████████████████████                                          | 4653/10736 [00:01<00:01, 3931.23it/s]\n",
      " 47%|██████████████████████████████████▉                                       | 5061/10736 [00:01<00:01, 3846.55it/s]\n",
      " 51%|█████████████████████████████████████▌                                    | 5445/10736 [00:01<00:01, 3765.53it/s]\n",
      " 55%|████████████████████████████████████████▍                                 | 5866/10736 [00:01<00:01, 3880.84it/s]\n",
      " 59%|███████████████████████████████████████████▎                              | 6292/10736 [00:01<00:01, 3979.14it/s]\n",
      " 62%|██████████████████████████████████████████████▏                           | 6692/10736 [00:01<00:01, 3976.69it/s]\n",
      " 66%|█████████████████████████████████████████████████▏                        | 7130/10736 [00:01<00:00, 4081.31it/s]\n",
      " 70%|███████████████████████████████████████████████████▉                      | 7540/10736 [00:01<00:00, 4077.99it/s]\n",
      " 74%|██████████████████████████████████████████████████████▊                   | 7949/10736 [00:02<00:00, 4060.58it/s]\n",
      " 78%|█████████████████████████████████████████████████████████▊                | 8379/10736 [00:02<00:00, 4120.88it/s]\n",
      " 82%|████████████████████████████████████████████████████████████▌             | 8792/10736 [00:02<00:00, 4054.19it/s]\n",
      " 86%|███████████████████████████████████████████████████████████████▍          | 9199/10736 [00:02<00:00, 4026.10it/s]\n",
      " 89%|██████████████████████████████████████████████████████████████████▏       | 9603/10736 [00:02<00:00, 3997.64it/s]\n",
      " 93%|████████████████████████████████████████████████████████████████████     | 10004/10736 [00:02<00:00, 3957.25it/s]\n",
      " 97%|██████████████████████████████████████████████████████████████████████▋  | 10401/10736 [00:02<00:00, 3793.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 10736/10736 [00:02<00:00, 3858.36it/s]\n",
      "  0%|                                                                                          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "1th- epoch: 0, train_loss = 344.64714738726616, train_acc = 0.8168374476013042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DTools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:98: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.819366852886406:\n",
      "1th- epoch: 1, train_loss = 78.81836052238941, train_acc = 0.9232650209594784\n",
      "test Acc 0.8701117318435754:\n",
      "1th- epoch: 2, train_loss = 47.488535647513345, train_acc = 0.9473684210526315\n",
      "test Acc 0.9366852886405959:\n",
      "1th- epoch: 3, train_loss = 33.86319765076041, train_acc = 0.9607591988821611\n",
      "test Acc 0.9422718808193669:\n",
      "1th- epoch: 4, train_loss = 25.99679752951488, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 5, train_loss = 20.426737138535827, train_acc = 0.9713553795994411\n",
      "test Acc 0.9506517690875232:\n",
      "1th- epoch: 6, train_loss = 16.435394727857783, train_acc = 0.976245924545878\n",
      "test Acc 0.9506517690875232:\n",
      "1th- epoch: 7, train_loss = 13.675160652725026, train_acc = 0.9796227293898463\n",
      "test Acc 0.952513966480447:\n",
      "1th- epoch: 8, train_loss = 11.462242004694417, train_acc = 0.9826502095947834\n",
      "test Acc 0.9515828677839852:\n",
      "1th- epoch: 9, train_loss = 9.876525263069198, train_acc = 0.9838146250582208\n",
      "test Acc 0.9529795158286778:\n",
      "1th- epoch: 10, train_loss = 8.531131305964664, train_acc = 0.9860270144387517\n",
      "test Acc 0.9539106145251397:\n",
      "1th- epoch: 11, train_loss = 7.501749958842993, train_acc = 0.9874243129948765\n",
      "test Acc 0.9534450651769087:\n",
      "1th- epoch: 12, train_loss = 6.668862217338756, train_acc = 0.9889380530973452\n",
      "test Acc 0.9539106145251397:\n",
      "1th- epoch: 13, train_loss = 6.006641412852332, train_acc = 0.9899860270144387\n",
      "test Acc 0.9543761638733705:\n",
      "1th- epoch: 14, train_loss = 5.417121258797124, train_acc = 0.9902189101071263\n",
      "test Acc 0.9548417132216015:\n",
      "1th- epoch: 15, train_loss = 4.899404253810644, train_acc = 0.9916162086632511\n",
      "test Acc 0.9553072625698324:\n",
      "1th- epoch: 16, train_loss = 4.474313738523051, train_acc = 0.9923148579413135\n",
      "test Acc 0.9562383612662942:\n",
      "1th- epoch: 17, train_loss = 4.118751508416608, train_acc = 0.9924312994876572\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 18, train_loss = 3.82900333032012, train_acc = 0.9933628318584071\n",
      "test Acc 0.957635009310987:\n",
      "1th- epoch: 19, train_loss = 3.5760692779440433, train_acc = 0.9937121564974383\n",
      "test Acc 0.957635009310987:\n",
      "1th- epoch: 20, train_loss = 3.3575969983357936, train_acc = 0.9934792734047508\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 21, train_loss = 3.1631326091010123, train_acc = 0.993828598043782\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 22, train_loss = 2.9740801975131035, train_acc = 0.9941779226828132\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 23, train_loss = 2.8168627843260765, train_acc = 0.9944108057755007\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 24, train_loss = 2.662899761227891, train_acc = 0.994294364229157\n",
      "test Acc 0.9594972067039106:\n",
      "1th- epoch: 25, train_loss = 2.5221644788980484, train_acc = 0.9949930135072194\n",
      "test Acc 0.9594972067039106:\n",
      "1th- epoch: 26, train_loss = 2.408643255708739, train_acc = 0.9949930135072194\n",
      "test Acc 0.9599627560521415:\n",
      "1th- epoch: 27, train_loss = 2.3073076244909316, train_acc = 0.9954587796925943\n",
      "test Acc 0.9594972067039106:\n",
      "1th- epoch: 28, train_loss = 2.2184400409460068, train_acc = 0.9953423381462506\n",
      "test Acc 0.9599627560521415:\n",
      "1th- epoch: 29, train_loss = 2.1353625021874905, train_acc = 0.995575221238938\n",
      "test Acc 0.9599627560521415:\n",
      "1th- epoch: 30, train_loss = 2.057349555194378, train_acc = 0.9956916627852818\n",
      "test Acc 0.9604283054003724:\n",
      "1th- epoch: 31, train_loss = 1.9968974005896598, train_acc = 0.9956916627852818\n",
      "test Acc 0.9604283054003724:\n",
      "1th- epoch: 32, train_loss = 1.931557334959507, train_acc = 0.9958081043316255\n",
      "test Acc 0.9599627560521415:\n",
      "1th- epoch: 33, train_loss = 1.8797851067502052, train_acc = 0.9958081043316255\n",
      "test Acc 0.9608938547486033:\n",
      "1th- epoch: 34, train_loss = 1.827787590562366, train_acc = 0.996040987424313\n",
      "test Acc 0.9618249534450651:\n",
      "1th- epoch: 35, train_loss = 1.790618677972816, train_acc = 0.9961574289706567\n",
      "test Acc 0.9618249534450651:\n",
      "1th- epoch: 36, train_loss = 1.746984951198101, train_acc = 0.9961574289706567\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 37, train_loss = 1.720041412860155, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 38, train_loss = 1.685609109699726, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 39, train_loss = 1.6547710783779621, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 40, train_loss = 1.622277095913887, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 41, train_loss = 1.6014139441540465, train_acc = 0.996506753609688\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 42, train_loss = 1.57755648100283, train_acc = 0.996506753609688\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 43, train_loss = 1.540897642611526, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 44, train_loss = 1.5271611599018797, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 45, train_loss = 1.5058939506998286, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 46, train_loss = 1.4900600090622902, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 47, train_loss = 1.469034944952, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "1th- epoch: 48, train_loss = 1.4450868479907513, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 49, train_loss = 1.4333380907773972, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "1th- epoch: 50, train_loss = 1.4259117605979554, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 51, train_loss = 1.4054637241060846, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "1th- epoch: 52, train_loss = 1.3932985837454908, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 53, train_loss = 1.3775229752063751, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 54, train_loss = 1.3656733284587972, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 55, train_loss = 1.3609711949829943, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 56, train_loss = 1.3489803460543044, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "1th- epoch: 57, train_loss = 1.3396938554942608, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 58, train_loss = 1.3198420442640781, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 59, train_loss = 1.3155107510392554, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 60, train_loss = 1.3069859854876995, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 61, train_loss = 1.2963279920513742, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "1th- epoch: 62, train_loss = 1.290331207215786, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 63, train_loss = 1.2775340626831166, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 64, train_loss = 1.2711473032832146, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 65, train_loss = 1.2643435348873027, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 66, train_loss = 1.257778191298712, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 67, train_loss = 1.247663511603605, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 68, train_loss = 1.2446881905198097, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 69, train_loss = 1.2358934581279755, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 70, train_loss = 1.229966587095987, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 71, train_loss = 1.224681736290222, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 72, train_loss = 1.2185749063792173, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 73, train_loss = 1.2096724274160806, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 74, train_loss = 1.2058687383832876, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 75, train_loss = 1.198187880218029, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 76, train_loss = 1.194939167558914, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 77, train_loss = 1.1883467435836792, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 78, train_loss = 1.1844388519821223, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 79, train_loss = 1.1785677783191204, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 80, train_loss = 1.1761300216021482, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 81, train_loss = 1.170057120412821, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 82, train_loss = 1.1632687275705393, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 83, train_loss = 1.16213364774012, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 84, train_loss = 1.1572709629836027, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 85, train_loss = 1.152089955896372, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 86, train_loss = 1.1485476829111576, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 87, train_loss = 1.1439030654728413, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 88, train_loss = 1.139386953174835, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 89, train_loss = 1.137075641512638, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 90, train_loss = 1.1330896081926767, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 91, train_loss = 1.128410673380131, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 92, train_loss = 1.1254231023194734, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 93, train_loss = 1.1206729809346143, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 94, train_loss = 1.1188248246908188, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 95, train_loss = 1.1157735946180765, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 96, train_loss = 1.1112813030777033, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 97, train_loss = 1.1097682354447898, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 98, train_loss = 1.105116669088602, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 99, train_loss = 1.1029095935227815, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 100, train_loss = 1.100710067898035, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 101, train_loss = 1.0975737571716309, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 102, train_loss = 1.0945543261768762, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 103, train_loss = 1.0917027282121126, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 104, train_loss = 1.0883480533957481, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 105, train_loss = 1.084027854114538, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 106, train_loss = 1.0839165598154068, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 107, train_loss = 1.0812382462027017, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 108, train_loss = 1.0776203063724097, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 109, train_loss = 1.0749972599151079, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 110, train_loss = 1.0726766126754228, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 111, train_loss = 1.0713113720121328, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 112, train_loss = 1.068844985216856, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 113, train_loss = 1.0659684191195993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 114, train_loss = 1.0638281553983688, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 115, train_loss = 1.0619286211876897, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 116, train_loss = 1.0585672805609647, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 117, train_loss = 1.0583375791757135, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 118, train_loss = 1.0540657726378413, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 119, train_loss = 1.0534326073975535, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 120, train_loss = 1.049863715961692, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 121, train_loss = 1.0495762340724468, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 122, train_loss = 1.0463025867938995, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 123, train_loss = 1.0470031052827835, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 124, train_loss = 1.042764483645442, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 125, train_loss = 1.0425868220627308, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 126, train_loss = 1.0390860624611378, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 127, train_loss = 1.0383875494153472, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 128, train_loss = 1.036511655896902, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 129, train_loss = 1.0344597523362609, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 130, train_loss = 1.032197780907154, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 131, train_loss = 1.0316817673592595, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 132, train_loss = 1.0302158072590828, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 133, train_loss = 1.026831816881895, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 134, train_loss = 1.0258594217448262, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 135, train_loss = 1.0234403970389394, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 136, train_loss = 1.0236376735119848, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 137, train_loss = 1.0223285257816315, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 138, train_loss = 1.0190100160689326, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 139, train_loss = 1.018771926566842, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 140, train_loss = 1.0154789971857099, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 141, train_loss = 1.0161564461886883, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 142, train_loss = 1.013239021107438, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 143, train_loss = 1.0117285860033007, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 144, train_loss = 1.0113431004137965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 145, train_loss = 1.0082415801734896, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 146, train_loss = 1.0086427604110213, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 147, train_loss = 1.0055192932486534, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 148, train_loss = 1.0051335655152798, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 149, train_loss = 1.004368947193143, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 150, train_loss = 1.0025373672397109, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 151, train_loss = 1.001338520392892, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 152, train_loss = 0.999592783555272, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 153, train_loss = 0.9982248457818059, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 154, train_loss = 0.9973397627472878, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 155, train_loss = 0.996891996517661, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 156, train_loss = 0.9966211331338855, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 157, train_loss = 0.9948897796421079, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 158, train_loss = 0.9939611591398716, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 159, train_loss = 0.9924451795668574, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 160, train_loss = 0.9904826109559508, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 161, train_loss = 0.9891640891582938, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 162, train_loss = 0.9883909896016121, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 163, train_loss = 0.986701217785594, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 164, train_loss = 0.9863697749824496, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 165, train_loss = 0.9843142554163933, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 166, train_loss = 0.9840208453388186, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 167, train_loss = 0.9824937147350283, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 168, train_loss = 0.9810966650693445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 169, train_loss = 0.9790248634963064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 170, train_loss = 0.9784443502576323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 171, train_loss = 0.9781767154781846, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 172, train_loss = 0.9764836554677458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 173, train_loss = 0.9761900417506695, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 174, train_loss = 0.973570932939765, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 175, train_loss = 0.9730881874711486, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 176, train_loss = 0.9722529028804274, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 177, train_loss = 0.9718696437776089, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 178, train_loss = 0.970102326318738, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 179, train_loss = 0.9686794603912858, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 180, train_loss = 0.9688234465866117, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 181, train_loss = 0.9680226296186447, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 182, train_loss = 0.96675265704107, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 183, train_loss = 0.9660406572074862, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 184, train_loss = 0.9648375858814688, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 185, train_loss = 0.9629698557109805, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 186, train_loss = 0.9631431649177102, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 187, train_loss = 0.9620998452155618, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 188, train_loss = 0.9607471972703934, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 189, train_loss = 0.9607087386102648, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 190, train_loss = 0.9595971604139777, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 191, train_loss = 0.9588874243199825, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 192, train_loss = 0.9567050747573376, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 193, train_loss = 0.9582239923329325, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 194, train_loss = 0.9554306454956532, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 195, train_loss = 0.9543051223008661, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 196, train_loss = 0.9543326608836651, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 197, train_loss = 0.9526477580293431, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 198, train_loss = 0.9529680808409466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 199, train_loss = 0.9522396673783078, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 200, train_loss = 0.950618735201715, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 201, train_loss = 0.9508068809882388, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 202, train_loss = 0.9480270954445587, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 203, train_loss = 0.949819798268436, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 204, train_loss = 0.9474297923370614, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 205, train_loss = 0.9472858086228371, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 206, train_loss = 0.9453463479876518, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 207, train_loss = 0.9462848119437695, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 208, train_loss = 0.9446943824514165, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 209, train_loss = 0.944272985063435, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 210, train_loss = 0.9443495248779072, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 211, train_loss = 0.9427217046395526, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 212, train_loss = 0.9427794416769757, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 213, train_loss = 0.9409480678514228, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 214, train_loss = 0.9406623877584934, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 215, train_loss = 0.9407436549663544, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 216, train_loss = 0.9381009700373397, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 217, train_loss = 0.9389306120574474, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 218, train_loss = 0.9379419051110744, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 219, train_loss = 0.9373844762667431, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 220, train_loss = 0.9366345455273404, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 221, train_loss = 0.9359345659613609, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 222, train_loss = 0.9352580370978103, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 223, train_loss = 0.9353669223710313, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 224, train_loss = 0.9337041477338062, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 225, train_loss = 0.9335626028478146, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 226, train_loss = 0.9328817824498401, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 227, train_loss = 0.9320727400481701, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 228, train_loss = 0.931878478579165, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 229, train_loss = 0.9318866146131768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 230, train_loss = 0.9282203800976276, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 231, train_loss = 0.927708121635078, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 232, train_loss = 0.9259940894917236, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 233, train_loss = 0.9263196811079979, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 234, train_loss = 0.9250894635915756, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 235, train_loss = 0.9251627859994187, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 236, train_loss = 0.9246214230879559, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 237, train_loss = 0.9232480488717556, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 238, train_loss = 0.922911370791553, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 239, train_loss = 0.922473531216383, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 240, train_loss = 0.922395370900631, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 241, train_loss = 0.9211928111835732, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 242, train_loss = 0.9210491913036094, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 243, train_loss = 0.9206643216311932, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 244, train_loss = 0.9200945558623062, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 245, train_loss = 0.9191331838592305, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 246, train_loss = 0.9194470879956498, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 247, train_loss = 0.9178645250722184, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 248, train_loss = 0.9179262779653072, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 249, train_loss = 0.9170369083658443, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 250, train_loss = 0.9167277502492652, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 251, train_loss = 0.9175822337492718, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 252, train_loss = 0.9153887368738651, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 253, train_loss = 0.9166396359578357, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 254, train_loss = 0.9153112260028138, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 255, train_loss = 0.9149150239900337, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 256, train_loss = 0.9138871431350708, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 257, train_loss = 0.9137964732944965, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 258, train_loss = 0.9137836856170907, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 259, train_loss = 0.9126094058156013, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 260, train_loss = 0.9138302865103469, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 261, train_loss = 0.9115494228899479, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 262, train_loss = 0.9117251398638473, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 263, train_loss = 0.9115246894434677, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 264, train_loss = 0.9106911482886062, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 265, train_loss = 0.9100391988977208, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 266, train_loss = 0.9107815995812416, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 267, train_loss = 0.9102270963267074, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 268, train_loss = 0.9104568796828971, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 269, train_loss = 0.9091498665511608, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 270, train_loss = 0.9076704159379005, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 271, train_loss = 0.9084406619294896, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 272, train_loss = 0.9082362217232003, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 273, train_loss = 0.9075303673744202, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 274, train_loss = 0.9068296067416668, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 275, train_loss = 0.9064750311299576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 276, train_loss = 0.9071092791855335, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 277, train_loss = 0.905467227101326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 278, train_loss = 0.9047595784068108, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 279, train_loss = 0.905675645917654, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 280, train_loss = 0.9044747600928531, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 281, train_loss = 0.9037040658295155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 282, train_loss = 0.9039870016276836, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 283, train_loss = 0.9056422039866447, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 284, train_loss = 0.9023843904360547, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 285, train_loss = 0.9032780987545266, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 286, train_loss = 0.9026233976110234, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 287, train_loss = 0.9025863396600471, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 288, train_loss = 0.9012988160029636, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 289, train_loss = 0.9022485390305519, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 290, train_loss = 0.9010924672111287, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 291, train_loss = 0.9010810491963639, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 292, train_loss = 0.9006928143426194, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 293, train_loss = 0.9011925583108678, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 294, train_loss = 0.9003101959824562, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 295, train_loss = 0.9023209313527332, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 296, train_loss = 0.8992457526401267, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 297, train_loss = 0.9008204080164433, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 298, train_loss = 0.8982045178636326, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 299, train_loss = 0.8990137701257481, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 300, train_loss = 0.8973787489012466, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 301, train_loss = 0.8998417605980649, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 302, train_loss = 0.8972081902102218, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 303, train_loss = 0.8979011798874126, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 304, train_loss = 0.896698072552681, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 305, train_loss = 0.8965740551575436, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 306, train_loss = 0.897838873170258, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 307, train_loss = 0.8969666548073292, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 308, train_loss = 0.8955043653622852, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 309, train_loss = 0.8969001931473031, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 310, train_loss = 0.8952524103224277, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 311, train_loss = 0.8948747354224906, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 312, train_loss = 0.8939251688643708, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 313, train_loss = 0.8951518622561707, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 314, train_loss = 0.8941061645746231, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 315, train_loss = 0.8950754056349979, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 316, train_loss = 0.8941101618111134, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 317, train_loss = 0.8930862459019409, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 318, train_loss = 0.8939501419663429, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 319, train_loss = 0.8934466789141879, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 320, train_loss = 0.8921313310638652, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 321, train_loss = 0.8939504797235713, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 322, train_loss = 0.8932051174342632, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 323, train_loss = 0.8921068844720139, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 324, train_loss = 0.8927337254062877, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 325, train_loss = 0.8919927850365639, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 326, train_loss = 0.893741966538073, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 327, train_loss = 0.8925031212493195, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 328, train_loss = 0.8919811199084506, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 329, train_loss = 0.8911207256242051, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 330, train_loss = 0.8930322018786683, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 331, train_loss = 0.8916850263849483, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 332, train_loss = 0.8906886714175926, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 333, train_loss = 0.8903058990836143, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 334, train_loss = 0.8906137930825935, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 335, train_loss = 0.8918590086177574, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 336, train_loss = 0.8904800564050674, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 337, train_loss = 0.8893536950126872, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 338, train_loss = 0.8891935758292675, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 339, train_loss = 0.8907765125259175, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 340, train_loss = 0.8886471167206764, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 341, train_loss = 0.891438306622149, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 342, train_loss = 0.888756667576672, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 343, train_loss = 0.8882517218589783, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 344, train_loss = 0.8884583724066033, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 345, train_loss = 0.8885074183344841, train_acc = 0.9981369352585002\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 346, train_loss = 0.8886608481407166, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 347, train_loss = 0.8875407738014474, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 348, train_loss = 0.8882592196241603, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 349, train_loss = 0.886629693210125, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 350, train_loss = 0.8892427062019124, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 351, train_loss = 0.8875051587820053, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 352, train_loss = 0.8889505304396152, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 353, train_loss = 0.8869665712118149, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 354, train_loss = 0.8883991229013191, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 355, train_loss = 0.8863076368943439, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 356, train_loss = 0.8863993175327778, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 357, train_loss = 0.8857033513486385, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 358, train_loss = 0.8889452504590736, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 359, train_loss = 0.8856793132945313, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 360, train_loss = 0.8874805333689437, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 361, train_loss = 0.8862515042201267, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 362, train_loss = 0.8866532631218433, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 363, train_loss = 0.8861378083602176, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 364, train_loss = 0.8868676970378147, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 365, train_loss = 0.8862659384831204, train_acc = 0.9980204937121565\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 366, train_loss = 0.8859010549858795, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 367, train_loss = 0.8860131241381168, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 368, train_loss = 0.8838661996051087, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 369, train_loss = 0.885136545944988, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 370, train_loss = 0.8866167217493057, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 371, train_loss = 0.8848900832235813, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 372, train_loss = 0.8841544948518276, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 373, train_loss = 0.885290652513504, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 374, train_loss = 0.8860548709817522, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 375, train_loss = 0.8842447698116302, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 376, train_loss = 0.8856236202009313, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 377, train_loss = 0.8861873522400856, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 378, train_loss = 0.8841661078222387, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 379, train_loss = 0.885945030797302, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 380, train_loss = 0.8835693721957796, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 381, train_loss = 0.8834333258382685, train_acc = 0.9980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 382, train_loss = 0.8856909275054932, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 383, train_loss = 0.8824301237873442, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 384, train_loss = 0.8845028852410906, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 385, train_loss = 0.885186929255724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 386, train_loss = 0.8833600940815813, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 387, train_loss = 0.8844813307114237, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 388, train_loss = 0.8829264168925874, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 389, train_loss = 0.8825024093202956, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 390, train_loss = 0.8819226026535034, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 391, train_loss = 0.8844288947693713, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 392, train_loss = 0.8824180054180033, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 393, train_loss = 0.8837389325090044, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 394, train_loss = 0.8845535119362467, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 395, train_loss = 0.8828248853496916, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 396, train_loss = 0.8835179445632093, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 397, train_loss = 0.8824705295264721, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 398, train_loss = 0.8815681810192473, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 399, train_loss = 0.8832310140132904, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 400, train_loss = 0.8835021344311826, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 401, train_loss = 0.8822745879479044, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 402, train_loss = 0.8817120268940926, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 403, train_loss = 0.8832049133889086, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 404, train_loss = 0.8820206448435783, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 405, train_loss = 0.8811795227229595, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 406, train_loss = 0.8828836803622835, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 407, train_loss = 0.8825177103281021, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 408, train_loss = 0.8818851113319397, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 409, train_loss = 0.8807180188596249, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 410, train_loss = 0.8808658371381171, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 411, train_loss = 0.8804289760701067, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 412, train_loss = 0.8828032575547695, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 413, train_loss = 0.8814095395318873, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 414, train_loss = 0.8803862767927058, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 415, train_loss = 0.8804901490620978, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 416, train_loss = 0.8823066403456323, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 417, train_loss = 0.8812595792114735, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 418, train_loss = 0.8817712006457441, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 419, train_loss = 0.8805606787391298, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 420, train_loss = 0.8801436511166685, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 421, train_loss = 0.8818395497910387, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 422, train_loss = 0.8800957227758772, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 423, train_loss = 0.880316690851032, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 424, train_loss = 0.8812882403544791, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 425, train_loss = 0.8802385243288882, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 426, train_loss = 0.8797750808298588, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 427, train_loss = 0.8816899955272675, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 428, train_loss = 0.8806553383656137, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 429, train_loss = 0.8801224355884187, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 430, train_loss = 0.8803487370423682, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 431, train_loss = 0.8794601236768358, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 432, train_loss = 0.8810118176043034, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 433, train_loss = 0.8788959719240665, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 434, train_loss = 0.8794200693555467, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 435, train_loss = 0.8793740955479734, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 436, train_loss = 0.8801784825809591, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 437, train_loss = 0.8805777120105631, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 438, train_loss = 0.8784302001186006, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 439, train_loss = 0.8812253375836008, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 440, train_loss = 0.8794288374483585, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 441, train_loss = 0.8790608917661302, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 442, train_loss = 0.8783517840020068, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 443, train_loss = 0.8792734779417515, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 444, train_loss = 0.8791028633713722, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 445, train_loss = 0.8784021511673927, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 446, train_loss = 0.8780922889709473, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 447, train_loss = 0.8803781643509865, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 448, train_loss = 0.8792978165038221, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 449, train_loss = 0.8780166606120474, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 450, train_loss = 0.8777440587691672, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 451, train_loss = 0.8790926523506641, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 452, train_loss = 0.8789514054842584, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 453, train_loss = 0.8798805835358507, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 454, train_loss = 0.8782921458296187, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 455, train_loss = 0.877612059313833, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 456, train_loss = 0.8785748134068854, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 457, train_loss = 0.878997473668278, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 458, train_loss = 0.8780675940215588, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 459, train_loss = 0.878681002806843, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 460, train_loss = 0.8789082181938284, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 461, train_loss = 0.8780899743251211, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 462, train_loss = 0.8775767957158678, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 463, train_loss = 0.8795966530851729, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 464, train_loss = 0.8779444980136759, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 465, train_loss = 0.8779231831431389, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 466, train_loss = 0.876978550106287, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 467, train_loss = 0.879354041069746, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 468, train_loss = 0.8785185428969271, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 469, train_loss = 0.8769142242781527, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 470, train_loss = 0.8788806311786175, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 471, train_loss = 0.8791051333137148, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 472, train_loss = 0.8779962969310873, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 473, train_loss = 0.8771445440761454, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 474, train_loss = 0.8781359444074042, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 475, train_loss = 0.8773870269469626, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 476, train_loss = 0.877911202609539, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 477, train_loss = 0.8774493535347574, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 478, train_loss = 0.8780432529747486, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 479, train_loss = 0.876728584367811, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 480, train_loss = 0.8791508239992254, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 481, train_loss = 0.8785234590359323, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 482, train_loss = 0.8791262644044764, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 483, train_loss = 0.8764239152260416, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 484, train_loss = 0.8774850852787495, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 485, train_loss = 0.8785692118108273, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 486, train_loss = 0.8772776983678341, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 487, train_loss = 0.87637209643799, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 488, train_loss = 0.8772403399161703, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 489, train_loss = 0.8783278812952631, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 490, train_loss = 0.8777336639650457, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 491, train_loss = 0.877435177564621, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 492, train_loss = 0.8773542419075966, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 493, train_loss = 0.8760819894559972, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 494, train_loss = 0.8769195998720534, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 495, train_loss = 0.8782242263368971, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 496, train_loss = 0.8777249207087152, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 497, train_loss = 0.8768105780072801, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 498, train_loss = 0.8761871444694407, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 499, train_loss = 0.8769790530204773, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|██▋                                                                            | 1/30 [09:02<4:21:58, 542.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "2th- epoch: 0, train_loss = 324.3734242618084, train_acc = 0.8126455519329296\n",
      "test Acc 0.8361266294227188:\n",
      "2th- epoch: 1, train_loss = 75.90388177288696, train_acc = 0.9259431765253843\n",
      "test Acc 0.931098696461825:\n",
      "2th- epoch: 2, train_loss = 44.327163737267256, train_acc = 0.94981369352585\n",
      "test Acc 0.9371508379888268:\n",
      "2th- epoch: 3, train_loss = 31.135896533727646, train_acc = 0.9611085235211924\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 4, train_loss = 23.110902555286884, train_acc = 0.9683278993945039\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 5, train_loss = 17.555766593664885, train_acc = 0.9739170936190032\n",
      "test Acc 0.9445996275605214:\n",
      "2th- epoch: 6, train_loss = 14.050495679490268, train_acc = 0.9782254308337215\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 7, train_loss = 11.336269672960043, train_acc = 0.9814857941313461\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 8, train_loss = 9.273001559078693, train_acc = 0.984163949697252\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 9, train_loss = 7.735241579590365, train_acc = 0.9862598975314392\n",
      "test Acc 0.952048417132216:\n",
      "2th- epoch: 10, train_loss = 6.506103105843067, train_acc = 0.9883558453656265\n",
      "test Acc 0.952048417132216:\n",
      "2th- epoch: 11, train_loss = 5.533408987044822, train_acc = 0.9896367023754076\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 12, train_loss = 4.7776843421161175, train_acc = 0.9909175593851887\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 13, train_loss = 4.20806079544127, train_acc = 0.9917326502095948\n",
      "test Acc 0.9539106145251397:\n",
      "2th- epoch: 14, train_loss = 3.7604444604367018, train_acc = 0.9925477410340009\n",
      "test Acc 0.9553072625698324:\n",
      "2th- epoch: 15, train_loss = 3.3840716369450092, train_acc = 0.9933628318584071\n",
      "test Acc 0.9553072625698324:\n",
      "2th- epoch: 16, train_loss = 3.0843966640532017, train_acc = 0.9939450395901258\n",
      "test Acc 0.9557728119180633:\n",
      "2th- epoch: 17, train_loss = 2.822388883039821, train_acc = 0.994294364229157\n",
      "test Acc 0.9557728119180633:\n",
      "2th- epoch: 18, train_loss = 2.608242119953502, train_acc = 0.9947601304145319\n",
      "test Acc 0.9562383612662942:\n",
      "2th- epoch: 19, train_loss = 2.4269042306696065, train_acc = 0.9949930135072194\n",
      "test Acc 0.9562383612662942:\n",
      "2th- epoch: 20, train_loss = 2.2866280029411428, train_acc = 0.9953423381462506\n",
      "test Acc 0.9562383612662942:\n",
      "2th- epoch: 21, train_loss = 2.161595866084099, train_acc = 0.9954587796925943\n",
      "test Acc 0.9567039106145251:\n",
      "2th- epoch: 22, train_loss = 2.068884906650055, train_acc = 0.9959245458779693\n",
      "test Acc 0.957635009310987:\n",
      "2th- epoch: 23, train_loss = 1.9904371090233326, train_acc = 0.996040987424313\n",
      "test Acc 0.9585661080074488:\n",
      "2th- epoch: 24, train_loss = 1.9216928885434754, train_acc = 0.996040987424313\n",
      "test Acc 0.9581005586592178:\n",
      "2th- epoch: 25, train_loss = 1.8651242889463902, train_acc = 0.9962738705170004\n",
      "test Acc 0.9581005586592178:\n",
      "2th- epoch: 26, train_loss = 1.8171232311869971, train_acc = 0.9963903120633442\n",
      "test Acc 0.9581005586592178:\n",
      "2th- epoch: 27, train_loss = 1.7687652092427015, train_acc = 0.9962738705170004\n",
      "test Acc 0.9581005586592178:\n",
      "2th- epoch: 28, train_loss = 1.7351771760731936, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "2th- epoch: 29, train_loss = 1.7008683755993843, train_acc = 0.996506753609688\n",
      "test Acc 0.9594972067039106:\n",
      "2th- epoch: 30, train_loss = 1.6737818326801062, train_acc = 0.996506753609688\n",
      "test Acc 0.9594972067039106:\n",
      "2th- epoch: 31, train_loss = 1.641941257432336, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "2th- epoch: 32, train_loss = 1.6161934938281775, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "2th- epoch: 33, train_loss = 1.5965917967259884, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "2th- epoch: 34, train_loss = 1.5712032988667488, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "2th- epoch: 35, train_loss = 1.5523806288838387, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "2th- epoch: 36, train_loss = 1.5313712122442666, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "2th- epoch: 37, train_loss = 1.5159530105593149, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "2th- epoch: 38, train_loss = 1.4984438499959651, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 39, train_loss = 1.4801870354858693, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 40, train_loss = 1.46646986095584, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 41, train_loss = 1.45293484753347, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 42, train_loss = 1.4418923078774242, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 43, train_loss = 1.4283052807149943, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 44, train_loss = 1.4158495130541269, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 45, train_loss = 1.4021526624710532, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 46, train_loss = 1.3913086193206254, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 47, train_loss = 1.3791245054453611, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 48, train_loss = 1.368159516408923, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 49, train_loss = 1.355331335842493, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 50, train_loss = 1.3475315130053787, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 51, train_loss = 1.3351568871439667, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 52, train_loss = 1.3263788825570373, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 53, train_loss = 1.3190969166607829, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 54, train_loss = 1.3059599734842777, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 55, train_loss = 1.300525363534689, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 56, train_loss = 1.2902509830892086, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 57, train_loss = 1.2847219283430604, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 58, train_loss = 1.2773234670312377, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 59, train_loss = 1.2748325032443972, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 60, train_loss = 1.2587058208882809, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 61, train_loss = 1.2540455323905917, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 62, train_loss = 1.2454859266726999, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 63, train_loss = 1.2404784920363454, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 64, train_loss = 1.2318377730698558, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 65, train_loss = 1.2261908389627934, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 66, train_loss = 1.2194204653351335, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 67, train_loss = 1.2120211410074262, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 68, train_loss = 1.209529018655303, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 69, train_loss = 1.2008075167686911, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 70, train_loss = 1.1949712869973155, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 71, train_loss = 1.1905754034669371, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 72, train_loss = 1.186453826725483, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 73, train_loss = 1.178533689424512, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 74, train_loss = 1.179736661419156, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 75, train_loss = 1.1696329228579998, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 76, train_loss = 1.1637705477623967, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 77, train_loss = 1.165134007736924, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 78, train_loss = 1.1546172139496775, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 79, train_loss = 1.1525281704962254, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 80, train_loss = 1.1481970685272245, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 81, train_loss = 1.1459353268146515, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 82, train_loss = 1.1447726587502984, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 83, train_loss = 1.1363518883736106, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 84, train_loss = 1.1359043580741854, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 85, train_loss = 1.1347975519747706, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 86, train_loss = 1.131768078848836, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 87, train_loss = 1.1241018560976954, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 88, train_loss = 1.1233080513775349, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 89, train_loss = 1.116889392331359, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 90, train_loss = 1.1128479937688098, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 91, train_loss = 1.1110234819352627, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 92, train_loss = 1.1125984738246188, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 93, train_loss = 1.1030032758935704, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 94, train_loss = 1.106723772980331, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 95, train_loss = 1.1004911834970699, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 96, train_loss = 1.0978310890495777, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 97, train_loss = 1.0934410070403828, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 98, train_loss = 1.0968590304255486, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 99, train_loss = 1.0899247787892818, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 100, train_loss = 1.0906527899205685, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 101, train_loss = 1.086238268762827, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 102, train_loss = 1.0866046262308373, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 103, train_loss = 1.0823630690574646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 104, train_loss = 1.0816480318680988, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 105, train_loss = 1.075218549616693, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 106, train_loss = 1.075246449559927, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 107, train_loss = 1.0711281597614288, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 108, train_loss = 1.0740044005215168, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 109, train_loss = 1.0677037499845028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 110, train_loss = 1.0681518390774727, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 111, train_loss = 1.0627201298848377, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 112, train_loss = 1.0607052432969795, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 113, train_loss = 1.0572390469387756, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 114, train_loss = 1.0615295395255089, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 115, train_loss = 1.055157928414701, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 116, train_loss = 1.0547753957434907, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 117, train_loss = 1.0499193196519627, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 118, train_loss = 1.0475944293066277, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 119, train_loss = 1.046279862523079, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 120, train_loss = 1.0434878133237362, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 121, train_loss = 1.042059302330017, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 122, train_loss = 1.044026547424437, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 123, train_loss = 1.0396423898637295, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 124, train_loss = 1.039244686566235, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 125, train_loss = 1.0361110419034958, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 126, train_loss = 1.0353923365473747, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 127, train_loss = 1.0296591309233918, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 128, train_loss = 1.0295713593586697, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 129, train_loss = 1.0296222642064095, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 130, train_loss = 1.02503103017807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 131, train_loss = 1.0242175658568158, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 132, train_loss = 1.019725501537323, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 133, train_loss = 1.023144468665123, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 134, train_loss = 1.019681575395225, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 135, train_loss = 1.016080873705505, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 136, train_loss = 1.0166776341720833, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 137, train_loss = 1.0163837273939862, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 138, train_loss = 1.0147568099200726, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 139, train_loss = 1.0109759382903576, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 140, train_loss = 1.0097461069599376, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 141, train_loss = 1.0100364138706937, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 142, train_loss = 1.0102049323395477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 143, train_loss = 1.0055346811786876, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 144, train_loss = 1.0069692892357125, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 145, train_loss = 1.0038164195939316, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 146, train_loss = 1.001849131040217, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 147, train_loss = 1.0026622414588928, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 148, train_loss = 1.0023074472919689, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 149, train_loss = 0.9996407715007081, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 150, train_loss = 0.9960994919165387, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 151, train_loss = 0.9986085792406811, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 152, train_loss = 0.9994660094380379, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 153, train_loss = 0.9948315558358445, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 154, train_loss = 0.994264309607388, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 155, train_loss = 0.9923927734271274, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 156, train_loss = 0.9922164169474854, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 157, train_loss = 0.9926400644108071, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 158, train_loss = 0.9877259482964291, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 159, train_loss = 0.9908386953175068, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 160, train_loss = 0.9859192781150341, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 161, train_loss = 0.9876757847741828, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 162, train_loss = 0.9869808132461912, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 163, train_loss = 0.9842765157409303, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 164, train_loss = 0.9829048439860344, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 165, train_loss = 0.9842887769154913, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 166, train_loss = 0.981809239834547, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 167, train_loss = 0.9803958398588293, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 168, train_loss = 0.9782590568065643, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 169, train_loss = 0.9796766526997089, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 170, train_loss = 0.9759727964810736, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 171, train_loss = 0.9791261504105933, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 172, train_loss = 0.9763750371821516, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 173, train_loss = 0.9734216866381757, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 174, train_loss = 0.9726923878006346, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 175, train_loss = 0.973898071795702, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 176, train_loss = 0.971482499193371, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 177, train_loss = 0.9712189671881788, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 178, train_loss = 0.9711694022007578, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 179, train_loss = 0.9705427835397131, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 180, train_loss = 0.9691813314966566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 181, train_loss = 0.9691641641147726, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 182, train_loss = 0.9654033705592155, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 183, train_loss = 0.9666302328296297, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 184, train_loss = 0.9661972684152715, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 185, train_loss = 0.9665123124905222, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 186, train_loss = 0.9648087384812243, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 187, train_loss = 0.9631141076497443, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 188, train_loss = 0.9634699647613161, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 189, train_loss = 0.9618084604553587, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 190, train_loss = 0.959369728963793, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 191, train_loss = 0.9612713481001265, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 192, train_loss = 0.9605301519222849, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 193, train_loss = 0.9571116318293207, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 194, train_loss = 0.9569789941124327, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 195, train_loss = 0.9576854482293129, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 196, train_loss = 0.9552896954119205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 197, train_loss = 0.9544421496502764, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 198, train_loss = 0.9546982385218143, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 199, train_loss = 0.9525181390345097, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 200, train_loss = 0.95310115193206, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 201, train_loss = 0.9503075865395658, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 202, train_loss = 0.9509812742471695, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 203, train_loss = 0.9510406615845568, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 204, train_loss = 0.9505688771605492, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 205, train_loss = 0.9495510483793623, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 206, train_loss = 0.9495022768787749, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 207, train_loss = 0.9481912876181013, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 208, train_loss = 0.9468848817050457, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 209, train_loss = 0.9452985525131226, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 210, train_loss = 0.944661180179537, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 211, train_loss = 0.94462476298213, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 212, train_loss = 0.9441625624895096, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 213, train_loss = 0.9435317926108837, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 214, train_loss = 0.9436016033105261, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 215, train_loss = 0.9426609886177175, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 216, train_loss = 0.9390411240347021, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 217, train_loss = 0.9375702552497387, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 218, train_loss = 0.9406477237753279, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 219, train_loss = 0.9398210048675537, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 220, train_loss = 0.941403117030859, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 221, train_loss = 0.9394679317883856, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 222, train_loss = 0.9366248349360831, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 223, train_loss = 0.9364539347589016, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 224, train_loss = 0.9375892815478437, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 225, train_loss = 0.9347173683345318, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 226, train_loss = 0.9339782049246423, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 227, train_loss = 0.9339092684276693, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 228, train_loss = 0.9335692338645458, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 229, train_loss = 0.9339703495315916, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 230, train_loss = 0.9318087883293629, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 231, train_loss = 0.9321997774131887, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 232, train_loss = 0.933708688866318, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 233, train_loss = 0.9321405092887289, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 234, train_loss = 0.9289460368454456, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 235, train_loss = 0.9290907246358984, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 236, train_loss = 0.9260896022133238, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 237, train_loss = 0.9277128614485264, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 238, train_loss = 0.9269291746131785, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 239, train_loss = 0.925567377358675, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 240, train_loss = 0.9284945962317579, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 241, train_loss = 0.9243989748247259, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 242, train_loss = 0.9260118243582838, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 243, train_loss = 0.9250618206970103, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 244, train_loss = 0.9273613480218046, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 245, train_loss = 0.9236590142063505, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 246, train_loss = 0.923372628789366, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 247, train_loss = 0.9213492708913691, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 248, train_loss = 0.9229704091958411, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 249, train_loss = 0.9224480018019676, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 250, train_loss = 0.9212518446147442, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 251, train_loss = 0.9220163362733729, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 252, train_loss = 0.9204649478197098, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 253, train_loss = 0.9228533431887627, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 254, train_loss = 0.9192881397902966, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 255, train_loss = 0.9198598526418209, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 256, train_loss = 0.9190913674719923, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 257, train_loss = 0.9171022648624785, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 258, train_loss = 0.9190867431461811, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 259, train_loss = 0.9178873201199167, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 260, train_loss = 0.9170912491790659, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 261, train_loss = 0.9162185726054304, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 262, train_loss = 0.9134262291081541, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 263, train_loss = 0.9148475925139792, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 264, train_loss = 0.913974229246378, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 265, train_loss = 0.914270531386137, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 266, train_loss = 0.912889864295721, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 267, train_loss = 0.9123159535229206, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 268, train_loss = 0.9116244266442664, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 269, train_loss = 0.910412301618635, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 270, train_loss = 0.9113671407103539, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 271, train_loss = 0.9107085590549104, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 272, train_loss = 0.9124510722867853, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 273, train_loss = 0.9105331040918827, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 274, train_loss = 0.9107543453574181, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 275, train_loss = 0.9107207047454722, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 276, train_loss = 0.9099582893140905, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 277, train_loss = 0.9110133312642574, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 278, train_loss = 0.9070376244671934, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 279, train_loss = 0.9074169596024149, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 280, train_loss = 0.9077660155780904, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 281, train_loss = 0.9081262474246614, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 282, train_loss = 0.9098287013657682, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 283, train_loss = 0.9068558216094971, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 284, train_loss = 0.9069943564645655, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 285, train_loss = 0.9059851902238734, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 286, train_loss = 0.9051649992652528, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 287, train_loss = 0.9058164370544546, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 288, train_loss = 0.9053809655197256, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 289, train_loss = 0.9043511897325516, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 290, train_loss = 0.9045428770295985, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 291, train_loss = 0.9035568237304688, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 292, train_loss = 0.9007239652164571, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 293, train_loss = 0.9025607369840145, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 294, train_loss = 0.9016945486255281, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 295, train_loss = 0.9025160819292068, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 296, train_loss = 0.9020781318358786, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 297, train_loss = 0.8990000064186461, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 298, train_loss = 0.9003357825167768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 299, train_loss = 0.8999867551028728, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 300, train_loss = 0.9011233958117373, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 301, train_loss = 0.9031671968587034, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 302, train_loss = 0.8997727508358366, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 303, train_loss = 0.9007352851331234, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 304, train_loss = 0.9025658729187853, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 305, train_loss = 0.8982575833797455, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 306, train_loss = 0.8976563426367647, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 307, train_loss = 0.898086221266567, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 308, train_loss = 0.8966300512365706, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 309, train_loss = 0.8964061426631815, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 310, train_loss = 0.8983673863112926, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 311, train_loss = 0.8968727861829393, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 312, train_loss = 0.896879643201828, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 313, train_loss = 0.896266753476084, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 314, train_loss = 0.8969731852412224, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 315, train_loss = 0.898962272953213, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 316, train_loss = 0.898730956017971, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 317, train_loss = 0.8948744125664234, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 318, train_loss = 0.8982965101786249, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 319, train_loss = 0.8964564402886026, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 320, train_loss = 0.8971071777232282, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 321, train_loss = 0.8951516846827872, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 322, train_loss = 0.8948683254420757, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 323, train_loss = 0.8961142338812351, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 324, train_loss = 0.8942953149489767, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 325, train_loss = 0.8955687209963799, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 326, train_loss = 0.8939823570362933, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 327, train_loss = 0.893821311492502, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 328, train_loss = 0.8932836391031742, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 329, train_loss = 0.8929502206556208, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 330, train_loss = 0.8960571959614754, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 331, train_loss = 0.8916238161436922, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 332, train_loss = 0.8933814813681238, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 333, train_loss = 0.8923075906932354, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 334, train_loss = 0.8909214896448248, train_acc = 0.9980204937121565\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 335, train_loss = 0.8907668354622729, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 336, train_loss = 0.8891534221656912, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 337, train_loss = 0.8916736928113096, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 338, train_loss = 0.8894768779464357, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 339, train_loss = 0.8900539452843077, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 340, train_loss = 0.8888611632100947, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 341, train_loss = 0.8873007508627779, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 342, train_loss = 0.8864057448990934, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 343, train_loss = 0.8874657203741663, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 344, train_loss = 0.884525286655844, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 345, train_loss = 0.8851993816606409, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 346, train_loss = 0.8872068077325821, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 347, train_loss = 0.8826947112866037, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 348, train_loss = 0.8879064718894369, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 349, train_loss = 0.8862141830213659, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 350, train_loss = 0.8875529058277607, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 351, train_loss = 0.8885783354453451, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 352, train_loss = 0.8872829414904118, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 353, train_loss = 0.8855752224735625, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 354, train_loss = 0.8853047303855419, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 355, train_loss = 0.8852461340538866, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 356, train_loss = 0.8858526684343815, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 357, train_loss = 0.8863859549164772, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 358, train_loss = 0.8857725026718981, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 359, train_loss = 0.885060132790386, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 360, train_loss = 0.885248086106003, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 361, train_loss = 0.8821611292660236, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 362, train_loss = 0.8846334877107438, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 363, train_loss = 0.8836185000836849, train_acc = 0.9980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 364, train_loss = 0.8826323747634888, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 365, train_loss = 0.8851888092849549, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 366, train_loss = 0.8817789740860462, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 367, train_loss = 0.8834856574721925, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 368, train_loss = 0.8831370659172535, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 369, train_loss = 0.882132908951462, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 370, train_loss = 0.8844864604379836, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 371, train_loss = 0.8824868810679618, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 372, train_loss = 0.879629751047105, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 373, train_loss = 0.8810692677889165, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 374, train_loss = 0.8815895256902877, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 375, train_loss = 0.8822931572794914, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 376, train_loss = 0.8802009634673595, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 377, train_loss = 0.8820440868530568, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 378, train_loss = 0.8786513383183774, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 379, train_loss = 0.8789890731386549, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 380, train_loss = 0.88084601983428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 381, train_loss = 0.8789912561569508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 382, train_loss = 0.878229446709156, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 383, train_loss = 0.8785529894139472, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 384, train_loss = 0.8786624073982239, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 385, train_loss = 0.8774630104489916, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 386, train_loss = 0.8782203942537308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 387, train_loss = 0.8779377825558186, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 388, train_loss = 0.8783765087518987, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 389, train_loss = 0.8780543580651283, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 390, train_loss = 0.8782209046185017, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 391, train_loss = 0.877293294915944, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 392, train_loss = 0.8773488228525821, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 393, train_loss = 0.8763570934534073, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 394, train_loss = 0.8785237520933151, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 395, train_loss = 0.8794684993717965, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 396, train_loss = 0.8771913883592788, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 397, train_loss = 0.877429665377349, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 398, train_loss = 0.8753618635237217, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 399, train_loss = 0.877406407147646, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 400, train_loss = 0.8745160636808578, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 401, train_loss = 0.8790959070120152, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 402, train_loss = 0.8766523152589798, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 403, train_loss = 0.8745424126591388, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 404, train_loss = 0.8754809896145161, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 405, train_loss = 0.8756215088069439, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 406, train_loss = 0.8761242727432546, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 407, train_loss = 0.8751056579258147, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 408, train_loss = 0.8757142511512939, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 409, train_loss = 0.8762812328841392, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 410, train_loss = 0.8718343190848827, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 411, train_loss = 0.8757785496618453, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 412, train_loss = 0.8722028632964793, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 413, train_loss = 0.8729177912082378, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 414, train_loss = 0.874579152712613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 415, train_loss = 0.8726415298879147, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 416, train_loss = 0.8725928701460361, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 417, train_loss = 0.8748797004427615, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 418, train_loss = 0.8724671415984631, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 419, train_loss = 0.872514742115527, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 420, train_loss = 0.8737616712842282, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 421, train_loss = 0.872797567397356, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 422, train_loss = 0.872626526901513, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 423, train_loss = 0.8716493037845794, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 424, train_loss = 0.8712886994089786, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 425, train_loss = 0.8731649753954116, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 426, train_loss = 0.872164557376891, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 427, train_loss = 0.8745207153260708, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 428, train_loss = 0.8754988871514797, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 429, train_loss = 0.8715238620843593, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 430, train_loss = 0.8715775596592721, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 431, train_loss = 0.8724128020312492, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 432, train_loss = 0.8695839531719685, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 433, train_loss = 0.8703022475037869, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 434, train_loss = 0.8710114918649197, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 435, train_loss = 0.8703633310888108, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 436, train_loss = 0.8682399777080718, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 437, train_loss = 0.8714839244876202, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 438, train_loss = 0.8692150873448554, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 439, train_loss = 0.8681239833440486, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 440, train_loss = 0.8692908932771388, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 441, train_loss = 0.8684555056188401, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 442, train_loss = 0.8669486045837402, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 443, train_loss = 0.871813947955161, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 444, train_loss = 0.8663962061200436, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 445, train_loss = 0.869258871922284, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 446, train_loss = 0.8706397004425526, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 447, train_loss = 0.8663584887981415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 448, train_loss = 0.8654246665537357, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 449, train_loss = 0.867457968493909, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 450, train_loss = 0.8689614050090313, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 451, train_loss = 0.8667342315111455, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 452, train_loss = 0.8660579957067966, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 453, train_loss = 0.8685886710882187, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 454, train_loss = 0.8663186207413673, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 455, train_loss = 0.8676427019145194, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 456, train_loss = 0.8680032826960087, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 457, train_loss = 0.8662615319099132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 458, train_loss = 0.8679482924435433, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 459, train_loss = 0.8667359997834865, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 460, train_loss = 0.8688238449394703, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 461, train_loss = 0.8647386481370631, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 462, train_loss = 0.8675499881301221, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 463, train_loss = 0.8653168181572255, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 464, train_loss = 0.8651392397787276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 465, train_loss = 0.8637580213453475, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 466, train_loss = 0.8640003266427811, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 467, train_loss = 0.8642939751352969, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 468, train_loss = 0.8628667605426017, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 469, train_loss = 0.8646822012960911, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 470, train_loss = 0.8617879301309586, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 471, train_loss = 0.8620374190304574, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 472, train_loss = 0.8659843727946281, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 473, train_loss = 0.8644606433808804, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 474, train_loss = 0.862751108905286, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 475, train_loss = 0.865478478372097, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 476, train_loss = 0.8630195409059525, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 477, train_loss = 0.8620666687693301, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 478, train_loss = 0.8618113237116631, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 479, train_loss = 0.8634796241913136, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 480, train_loss = 0.8616783867273625, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 481, train_loss = 0.8619225521888438, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 482, train_loss = 0.8640702851116657, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 483, train_loss = 0.8613696371521655, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 484, train_loss = 0.8643782759700116, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 485, train_loss = 0.8616316840052605, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 486, train_loss = 0.8617531384024915, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 487, train_loss = 0.8627885542809963, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 488, train_loss = 0.8609542946014699, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 489, train_loss = 0.8629488460719585, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 490, train_loss = 0.8641709933672246, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 491, train_loss = 0.8631165747847263, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 492, train_loss = 0.8610558174550533, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 493, train_loss = 0.8595871354136762, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 494, train_loss = 0.8596360286082927, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 495, train_loss = 0.8584161450471584, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 496, train_loss = 0.8621366247534752, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 497, train_loss = 0.8594557009637356, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 498, train_loss = 0.8587579453978833, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 499, train_loss = 0.8586782949660119, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|█████▎                                                                         | 2/30 [18:03<4:12:51, 541.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "3th- epoch: 0, train_loss = 368.0054593831301, train_acc = 0.8178854215183977\n",
      "test Acc 0.8170391061452514:\n",
      "3th- epoch: 1, train_loss = 83.67944613593863, train_acc = 0.9290870982766651\n",
      "test Acc 0.9348230912476723:\n",
      "3th- epoch: 2, train_loss = 51.385812908411026, train_acc = 0.951560316721006\n",
      "test Acc 0.9338919925512105:\n",
      "3th- epoch: 3, train_loss = 36.532220791094005, train_acc = 0.9613414066138798\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 4, train_loss = 27.265800332650542, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 5, train_loss = 20.27149103814736, train_acc = 0.9733348858872846\n",
      "test Acc 0.9534450651769087:\n",
      "3th- epoch: 6, train_loss = 16.19092639302835, train_acc = 0.9784583139264089\n",
      "test Acc 0.9567039106145251:\n",
      "3th- epoch: 7, train_loss = 13.04632984357886, train_acc = 0.9811364694923148\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 8, train_loss = 10.634168894495815, train_acc = 0.9835817419655333\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 9, train_loss = 8.63022301485762, train_acc = 0.9860270144387517\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 10, train_loss = 7.209229157771915, train_acc = 0.9882394038192828\n",
      "test Acc 0.9622905027932961:\n",
      "3th- epoch: 11, train_loss = 6.1178540624678135, train_acc = 0.9895202608290639\n",
      "test Acc 0.9622905027932961:\n",
      "3th- epoch: 12, train_loss = 5.323881884338334, train_acc = 0.9904517931998137\n",
      "test Acc 0.9646182495344506:\n",
      "3th- epoch: 13, train_loss = 4.719150997698307, train_acc = 0.9912668840242198\n",
      "test Acc 0.9646182495344506:\n",
      "3th- epoch: 14, train_loss = 4.244805278838612, train_acc = 0.9919655333022822\n",
      "test Acc 0.9641527001862198:\n",
      "3th- epoch: 15, train_loss = 3.888251772732474, train_acc = 0.9925477410340009\n",
      "test Acc 0.9636871508379888:\n",
      "3th- epoch: 16, train_loss = 3.585320151061751, train_acc = 0.993828598043782\n",
      "test Acc 0.9646182495344506:\n",
      "3th- epoch: 17, train_loss = 3.333276681602001, train_acc = 0.9941779226828132\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 18, train_loss = 3.1013854891061783, train_acc = 0.9944108057755007\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 19, train_loss = 2.9154182163183577, train_acc = 0.9947601304145319\n",
      "test Acc 0.9664804469273743:\n",
      "3th- epoch: 20, train_loss = 2.761325176805258, train_acc = 0.9948765719608756\n",
      "test Acc 0.9674115456238361:\n",
      "3th- epoch: 21, train_loss = 2.6220037403400056, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 22, train_loss = 2.520947727083694, train_acc = 0.9952258965999069\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 23, train_loss = 2.412833336740732, train_acc = 0.9953423381462506\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 24, train_loss = 2.3273392766714096, train_acc = 0.9953423381462506\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 25, train_loss = 2.2379343782668, train_acc = 0.995575221238938\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 26, train_loss = 2.1680112679605372, train_acc = 0.9958081043316255\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 27, train_loss = 2.1043569346365985, train_acc = 0.9958081043316255\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 28, train_loss = 2.042031981050968, train_acc = 0.9959245458779693\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 29, train_loss = 1.9834532899258193, train_acc = 0.9959245458779693\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 30, train_loss = 1.9303525003197137, train_acc = 0.9959245458779693\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 31, train_loss = 1.8868156062962953, train_acc = 0.9959245458779693\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 32, train_loss = 1.8402837005851325, train_acc = 0.9959245458779693\n",
      "test Acc 0.9702048417132216:\n",
      "3th- epoch: 33, train_loss = 1.8115451695921365, train_acc = 0.9961574289706567\n",
      "test Acc 0.9702048417132216:\n",
      "3th- epoch: 34, train_loss = 1.7717186100780964, train_acc = 0.9962738705170004\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 35, train_loss = 1.755399371177191, train_acc = 0.9962738705170004\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 36, train_loss = 1.719577394425869, train_acc = 0.9961574289706567\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 37, train_loss = 1.7038917119207326, train_acc = 0.9962738705170004\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 38, train_loss = 1.6853425987064838, train_acc = 0.9962738705170004\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 39, train_loss = 1.6705212742090225, train_acc = 0.9963903120633442\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 40, train_loss = 1.654422509163851, train_acc = 0.9963903120633442\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 41, train_loss = 1.6439595644769724, train_acc = 0.9963903120633442\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 42, train_loss = 1.6215277003648225, train_acc = 0.9962738705170004\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 43, train_loss = 1.6110765722987708, train_acc = 0.9962738705170004\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 44, train_loss = 1.5925625028612558, train_acc = 0.9962738705170004\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 45, train_loss = 1.5852153884770814, train_acc = 0.9962738705170004\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 46, train_loss = 1.5717857827694388, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 47, train_loss = 1.5583106875419617, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 48, train_loss = 1.5487029142677784, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 49, train_loss = 1.534853022545576, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 50, train_loss = 1.5231751116662053, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 51, train_loss = 1.5102493936865358, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 52, train_loss = 1.5027560591697693, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 53, train_loss = 1.487961944192648, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 54, train_loss = 1.4776895406394033, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 55, train_loss = 1.4725011115224333, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 56, train_loss = 1.4625971168279648, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 57, train_loss = 1.4536580319254426, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 58, train_loss = 1.4412149700074224, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 59, train_loss = 1.4358209880738286, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 60, train_loss = 1.4260443188250065, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 61, train_loss = 1.4196278937160969, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 62, train_loss = 1.4114721131772967, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 63, train_loss = 1.4045456647872925, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 64, train_loss = 1.4009021769015817, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 65, train_loss = 1.3925299371330766, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 66, train_loss = 1.3846717812120914, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 67, train_loss = 1.3735918092279462, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 68, train_loss = 1.3727373195142718, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 69, train_loss = 1.3605803214013577, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 70, train_loss = 1.359517827630043, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 71, train_loss = 1.3513725089505897, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 72, train_loss = 1.3474763544872985, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 73, train_loss = 1.3382357036098256, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 74, train_loss = 1.332681830972433, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 75, train_loss = 1.32772394890344, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 76, train_loss = 1.3223060381933465, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 77, train_loss = 1.318800130240561, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 78, train_loss = 1.3097197102979408, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 79, train_loss = 1.305142247430922, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 80, train_loss = 1.2978522454723134, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 81, train_loss = 1.2937313467264175, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 82, train_loss = 1.2886132846251712, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 83, train_loss = 1.2826167903840542, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 84, train_loss = 1.2823141651824699, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 85, train_loss = 1.2736652468665852, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 86, train_loss = 1.2719926933423267, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 87, train_loss = 1.2660719491541386, train_acc = 0.9966231951560317\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 88, train_loss = 1.2626102156937122, train_acc = 0.9966231951560317\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 89, train_loss = 1.2583228709772811, train_acc = 0.9966231951560317\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 90, train_loss = 1.2499399669468403, train_acc = 0.9966231951560317\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 91, train_loss = 1.2481108345091343, train_acc = 0.9966231951560317\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 92, train_loss = 1.2409181470648036, train_acc = 0.9966231951560317\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 93, train_loss = 1.2390113895162358, train_acc = 0.9966231951560317\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 94, train_loss = 1.236095655709505, train_acc = 0.9966231951560317\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 95, train_loss = 1.231992223612906, train_acc = 0.9966231951560317\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 96, train_loss = 1.2306335046887398, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 97, train_loss = 1.224376194179058, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 98, train_loss = 1.2217033728957176, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 99, train_loss = 1.2155862053259625, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 100, train_loss = 1.2132213115692139, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 101, train_loss = 1.210152698062302, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 102, train_loss = 1.2041433254889853, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 103, train_loss = 1.2079345497004397, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 104, train_loss = 1.203409397352516, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 105, train_loss = 1.1954211182892323, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 106, train_loss = 1.1928918523080938, train_acc = 0.9967396367023754\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 107, train_loss = 1.191323899973213, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 108, train_loss = 1.1933162175118923, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 109, train_loss = 1.1854511573910713, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 110, train_loss = 1.1838035099208355, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 111, train_loss = 1.1811447354666598, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 112, train_loss = 1.1769772594161623, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 113, train_loss = 1.1798974499106407, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 114, train_loss = 1.1730564683675766, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 115, train_loss = 1.1675292924046516, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 116, train_loss = 1.166752321023523, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 117, train_loss = 1.1697739027440548, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 118, train_loss = 1.1606713036708243, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 119, train_loss = 1.1600276703647978, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 120, train_loss = 1.1610718692354567, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 121, train_loss = 1.153587769716978, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 122, train_loss = 1.1520133651793003, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 123, train_loss = 1.1499959900975227, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 124, train_loss = 1.1545946833975904, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 125, train_loss = 1.143901160608948, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 126, train_loss = 1.1424705907702446, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 127, train_loss = 1.146972401689709, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 128, train_loss = 1.1399570405483246, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 129, train_loss = 1.1350435577332973, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 130, train_loss = 1.1390721872448921, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 131, train_loss = 1.1358803647271998, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 132, train_loss = 1.1318684878460772, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 133, train_loss = 1.1287533715367317, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 134, train_loss = 1.1312831938266754, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 135, train_loss = 1.1283397724218958, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 136, train_loss = 1.123711911339342, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 137, train_loss = 1.1277436266354925, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 138, train_loss = 1.1192103090397723, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 139, train_loss = 1.1190939409025304, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 140, train_loss = 1.1205203868448734, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 141, train_loss = 1.1156195228286379, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 142, train_loss = 1.1114900472275622, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 143, train_loss = 1.1169663344808214, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 144, train_loss = 1.1100819247476466, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 145, train_loss = 1.1065598651766777, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 146, train_loss = 1.11149324973303, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 147, train_loss = 1.1043203522749536, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 148, train_loss = 1.1006695553660393, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 149, train_loss = 1.1062785970680125, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 150, train_loss = 1.1000277896710031, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 151, train_loss = 1.0971233968921297, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 152, train_loss = 1.1013924231119745, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 153, train_loss = 1.0936024424918287, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 154, train_loss = 1.0939117235429876, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 155, train_loss = 1.095951651532232, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 156, train_loss = 1.0909335017204285, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 157, train_loss = 1.087589920807659, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 158, train_loss = 1.0902878195047379, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 159, train_loss = 1.0857527082152956, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 160, train_loss = 1.082517396658659, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 161, train_loss = 1.085646029561758, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 162, train_loss = 1.0798470651097887, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 163, train_loss = 1.0790472676344507, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 164, train_loss = 1.077956295262993, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 165, train_loss = 1.0779673966280825, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 166, train_loss = 1.0806470910720236, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 167, train_loss = 1.0752839470915205, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 168, train_loss = 1.0706692971289158, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 169, train_loss = 1.076786915462435, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 170, train_loss = 1.0692609759680636, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 171, train_loss = 1.073965327192127, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 172, train_loss = 1.0669076566882723, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 173, train_loss = 1.0655553489923477, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 174, train_loss = 1.068410852301895, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 175, train_loss = 1.0644626108296507, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 176, train_loss = 1.0643938245884783, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 177, train_loss = 1.059656220179022, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 178, train_loss = 1.055829979479313, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 179, train_loss = 1.0608235026411421, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 180, train_loss = 1.0532463006675243, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 181, train_loss = 1.0594967020042532, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 182, train_loss = 1.0519584591202147, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 183, train_loss = 1.0505543189756281, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 184, train_loss = 1.0511594998351939, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 185, train_loss = 1.0487089628986723, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 186, train_loss = 1.0499577646442049, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 187, train_loss = 1.0460747219622135, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 188, train_loss = 1.0425792261958122, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 189, train_loss = 1.044570043683052, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 190, train_loss = 1.0398880081884272, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 191, train_loss = 1.045022906113445, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 192, train_loss = 1.0377483877055056, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 193, train_loss = 1.035154975950718, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 194, train_loss = 1.0361897833645344, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 195, train_loss = 1.0332762400321371, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 196, train_loss = 1.036368870485603, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 197, train_loss = 1.0324696426578157, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 198, train_loss = 1.0307359956204891, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 199, train_loss = 1.0349275010339625, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 200, train_loss = 1.029509728152334, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 201, train_loss = 1.0341986864805222, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 202, train_loss = 1.0263317339122295, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 203, train_loss = 1.0259609284512408, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 204, train_loss = 1.0294081891588576, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 205, train_loss = 1.0225187515206926, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 206, train_loss = 1.021383338917076, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 207, train_loss = 1.0242519515268214, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 208, train_loss = 1.019185865920008, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 209, train_loss = 1.0247771094254858, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 210, train_loss = 1.0189626539759047, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 211, train_loss = 1.017900920163811, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 212, train_loss = 1.017978241045057, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 213, train_loss = 1.016259549807728, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 214, train_loss = 1.0181794563941367, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 215, train_loss = 1.0142925406507857, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 216, train_loss = 1.0101628353186243, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 217, train_loss = 1.0117045193910599, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 218, train_loss = 1.0109008674808138, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 219, train_loss = 1.0140377208590508, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 220, train_loss = 1.0096075845249288, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 221, train_loss = 1.00552299618721, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 222, train_loss = 1.0068382819481485, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 223, train_loss = 1.0051036129407294, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 224, train_loss = 1.0052790381014347, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 225, train_loss = 1.0029460601508617, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 226, train_loss = 1.0082011297345161, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 227, train_loss = 1.001208659261465, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 228, train_loss = 0.9989899843931198, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 229, train_loss = 1.0015591221563227, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 230, train_loss = 0.9972305409610271, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 231, train_loss = 0.9991107918322086, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 232, train_loss = 0.9977239121981256, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 233, train_loss = 1.0006031468510628, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 234, train_loss = 0.99720610429722, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 235, train_loss = 0.9953892305493355, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 236, train_loss = 0.993722523253382, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 237, train_loss = 0.9937562445811636, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 238, train_loss = 0.9922016796954267, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 239, train_loss = 0.9906665794551373, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 240, train_loss = 0.9933258332312107, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 241, train_loss = 0.9882334719113715, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 242, train_loss = 0.993463816743315, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 243, train_loss = 0.9906333175786131, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 244, train_loss = 0.9880263159684546, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 245, train_loss = 0.9879256847016222, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 246, train_loss = 0.9856159550436132, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 247, train_loss = 0.9857846101112955, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 248, train_loss = 0.9849667400121689, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 249, train_loss = 0.9848003213592165, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 250, train_loss = 0.9835666355975263, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 251, train_loss = 0.9861413153521426, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 252, train_loss = 0.9811154492199421, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 253, train_loss = 0.9809242971241474, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 254, train_loss = 0.9796807368584268, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 255, train_loss = 0.9765615959950082, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 256, train_loss = 0.9810736365616322, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 257, train_loss = 0.9774662243835337, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 258, train_loss = 0.9771285516508215, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 259, train_loss = 0.9728333465754986, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 260, train_loss = 0.9753393791615963, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 261, train_loss = 0.9742238384969824, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 262, train_loss = 0.9747713257856958, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 263, train_loss = 0.9723685781173117, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 264, train_loss = 0.9725874178111553, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 265, train_loss = 0.97177990650016, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 266, train_loss = 0.9734818624965556, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 267, train_loss = 0.9695934007577307, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 268, train_loss = 0.9734787680208683, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 269, train_loss = 0.9703493366650946, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 270, train_loss = 0.9678005675486929, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 271, train_loss = 0.966667402535677, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 272, train_loss = 0.9677658739201433, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 273, train_loss = 0.9661647714674473, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 274, train_loss = 0.9667541819326289, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 275, train_loss = 0.9652612643949396, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 276, train_loss = 0.9656282191463106, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 277, train_loss = 0.965604979544878, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 278, train_loss = 0.9623261876404285, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 279, train_loss = 0.9624051650353067, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 280, train_loss = 0.9637084752321243, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 281, train_loss = 0.9616833689324267, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 282, train_loss = 0.9649134054780006, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 283, train_loss = 0.960488806169451, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 284, train_loss = 0.9570108416191943, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 285, train_loss = 0.9613663504533179, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 286, train_loss = 0.9589427188038826, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 287, train_loss = 0.9596877271906123, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 288, train_loss = 0.956597817439615, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 289, train_loss = 0.9562238305807114, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 290, train_loss = 0.9531741502396471, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 291, train_loss = 0.955725833773613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 292, train_loss = 0.9548553985878243, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 293, train_loss = 0.9525343415662064, train_acc = 0.9975547275267815\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 294, train_loss = 0.9512998374775634, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 295, train_loss = 0.9527971607967629, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 296, train_loss = 0.9520265695973649, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 297, train_loss = 0.9511913719252334, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 298, train_loss = 0.9518205597996712, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 299, train_loss = 0.9524800529106869, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 300, train_loss = 0.9509860786274658, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 301, train_loss = 0.9515087120234966, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 302, train_loss = 0.9483092625960126, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 303, train_loss = 0.9497311227023602, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 304, train_loss = 0.9452634130939259, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 305, train_loss = 0.9458893053233624, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 306, train_loss = 0.946465906999947, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 307, train_loss = 0.9465178959071636, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 308, train_loss = 0.9474314550534473, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 309, train_loss = 0.9456045193001046, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 310, train_loss = 0.944313640393375, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 311, train_loss = 0.9448767614885583, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 312, train_loss = 0.9428951032459736, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 313, train_loss = 0.9443687349557877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 314, train_loss = 0.9440095412210212, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 315, train_loss = 0.9416483268141747, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 316, train_loss = 0.942978693790792, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 317, train_loss = 0.9411794940606342, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 318, train_loss = 0.9433248763307347, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 319, train_loss = 0.9397295067683444, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 320, train_loss = 0.943005733191967, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 321, train_loss = 0.937001666672586, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 322, train_loss = 0.9387054865583195, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 323, train_loss = 0.9388361449018703, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 324, train_loss = 0.9391489289700985, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 325, train_loss = 0.9404686354100704, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 326, train_loss = 0.9368246359154, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 327, train_loss = 0.9385968310161843, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 328, train_loss = 0.9360936544835567, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 329, train_loss = 0.9336786419153214, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 330, train_loss = 0.9384012122973218, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 331, train_loss = 0.9340798904522671, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 332, train_loss = 0.9369038355871453, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 333, train_loss = 0.936335006110312, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 334, train_loss = 0.9347276439293637, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 335, train_loss = 0.9342981937006698, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 336, train_loss = 0.9335778330787434, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 337, train_loss = 0.9359713258818374, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 338, train_loss = 0.9329504892230034, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 339, train_loss = 0.9342376676722779, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 340, train_loss = 0.9315800579861389, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 341, train_loss = 0.9317223628386273, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 342, train_loss = 0.9345613705590949, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 343, train_loss = 0.9305598363280296, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 344, train_loss = 0.9333401272670017, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 345, train_loss = 0.930900577455759, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 346, train_loss = 0.9314067736268044, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 347, train_loss = 0.9294864721596241, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 348, train_loss = 0.9314772424622788, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 349, train_loss = 0.9307446703314781, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 350, train_loss = 0.9288099482655525, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 351, train_loss = 0.930981340505241, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 352, train_loss = 0.9306336641311646, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 353, train_loss = 0.9270569905638695, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 354, train_loss = 0.9297613588496461, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 355, train_loss = 0.9278560827151523, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 356, train_loss = 0.9286448918282986, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 357, train_loss = 0.9271281647161231, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 358, train_loss = 0.9266489619985805, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 359, train_loss = 0.9264202738777385, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 360, train_loss = 0.9263592188581242, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 361, train_loss = 0.9265410552397952, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 362, train_loss = 0.92672987034166, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 363, train_loss = 0.9232442528009415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 364, train_loss = 0.9280796758830547, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 365, train_loss = 0.9249453122392879, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 366, train_loss = 0.9246246529146447, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 367, train_loss = 0.9254273946062312, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 368, train_loss = 0.9242676844223752, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 369, train_loss = 0.9230440482497215, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 370, train_loss = 0.9258577426298871, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 371, train_loss = 0.9207440999671235, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 372, train_loss = 0.9220000257118954, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 373, train_loss = 0.9242171545847668, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 374, train_loss = 0.9230024131611572, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 375, train_loss = 0.9220849399789586, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 376, train_loss = 0.9194333553314209, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 377, train_loss = 0.9233421807512059, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 378, train_loss = 0.9210516028106213, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 379, train_loss = 0.9211058790460811, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 380, train_loss = 0.9220738311632886, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 381, train_loss = 0.9220472549422993, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 382, train_loss = 0.9205564844087348, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 383, train_loss = 0.9221488547846093, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 384, train_loss = 0.9172282293438911, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 385, train_loss = 0.9180207426325069, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 386, train_loss = 0.9212233213111176, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 387, train_loss = 0.9212749923244701, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 388, train_loss = 0.9158952720463276, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 389, train_loss = 0.9157271993681206, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 390, train_loss = 0.912682635091187, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 391, train_loss = 0.9128934182226658, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 392, train_loss = 0.9125409349799156, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 393, train_loss = 0.9197193036452518, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 394, train_loss = 0.9178957281037583, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 395, train_loss = 0.9177849106490612, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 396, train_loss = 0.91501632953441, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 397, train_loss = 0.91006552552426, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 398, train_loss = 0.914060041308403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 399, train_loss = 0.9178448853417649, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 400, train_loss = 0.9181642880066647, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 401, train_loss = 0.9179744857028709, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 402, train_loss = 0.9147755006924854, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 403, train_loss = 0.9092318527400494, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 404, train_loss = 0.909161850810051, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 405, train_loss = 0.9100253656506538, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 406, train_loss = 0.9087736917063012, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 407, train_loss = 0.9126101695001125, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 408, train_loss = 0.9104196603075252, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 409, train_loss = 0.9114507834092365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 410, train_loss = 0.9136756832376705, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 411, train_loss = 0.9147714103237377, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 412, train_loss = 0.9128390898331418, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 413, train_loss = 0.9137472423390136, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 414, train_loss = 0.911411851644516, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 415, train_loss = 0.9126564102843986, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 416, train_loss = 0.9116670762523427, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 417, train_loss = 0.9113772213459015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 418, train_loss = 0.9144710948094144, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 419, train_loss = 0.9122746288776398, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 420, train_loss = 0.9119398010298028, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 421, train_loss = 0.9094996588901267, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 422, train_loss = 0.9144153272136464, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 423, train_loss = 0.9126478644684539, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 424, train_loss = 0.9113508462905884, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 425, train_loss = 0.9105443172156811, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 426, train_loss = 0.9056805570944562, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 427, train_loss = 0.9054311402142048, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 428, train_loss = 0.9076842802242027, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 429, train_loss = 0.9080283219591365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 430, train_loss = 0.9106430535539403, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 431, train_loss = 0.9068696796894073, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 432, train_loss = 0.9132337073460803, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 433, train_loss = 0.9094845987856388, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 434, train_loss = 0.9086834813133464, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 435, train_loss = 0.912430534757732, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 436, train_loss = 0.9094432517886162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 437, train_loss = 0.9116917413994088, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 438, train_loss = 0.9099952802062035, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 439, train_loss = 0.9076743001714931, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 440, train_loss = 0.9073247139676823, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 441, train_loss = 0.907846828304173, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 442, train_loss = 0.9082611563280807, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 443, train_loss = 0.9091266157702194, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 444, train_loss = 0.9085902596489177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 445, train_loss = 0.9063220918178558, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 446, train_loss = 0.9123296799734817, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 447, train_loss = 0.9061148365362897, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 448, train_loss = 0.9091190472245216, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 449, train_loss = 0.9104225027040229, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 450, train_loss = 0.9063453028575168, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 451, train_loss = 0.9076619868501439, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 452, train_loss = 0.9074549774304614, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 453, train_loss = 0.9091468304395676, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 454, train_loss = 0.9072369113564491, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 455, train_loss = 0.9026732482016087, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 456, train_loss = 0.8997678756713867, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 457, train_loss = 0.9010078124701977, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 458, train_loss = 0.9048253856599331, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 459, train_loss = 0.9079109616577625, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 460, train_loss = 0.9035944230854511, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 461, train_loss = 0.9086083372458233, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 462, train_loss = 0.9040200884119258, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 463, train_loss = 0.9077539630234241, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 464, train_loss = 0.9074937105178833, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 465, train_loss = 0.9049001547173248, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 466, train_loss = 0.9070960792378173, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 467, train_loss = 0.9028880906626, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 468, train_loss = 0.908749170601368, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 469, train_loss = 0.905553538352251, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 470, train_loss = 0.9058823970481171, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 471, train_loss = 0.9043970480561256, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 472, train_loss = 0.9062953678294434, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 473, train_loss = 0.906352624297142, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 474, train_loss = 0.9041675080879941, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 475, train_loss = 0.9037805323823704, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 476, train_loss = 0.9060875698924065, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 477, train_loss = 0.9024568150416599, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 478, train_loss = 0.9032461568713188, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 479, train_loss = 0.902041378118156, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 480, train_loss = 0.9066477976739407, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 481, train_loss = 0.9011454097926617, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 482, train_loss = 0.9023335091769695, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 483, train_loss = 0.8956737679764046, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 484, train_loss = 0.897331103682518, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 485, train_loss = 0.8960884436964989, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 486, train_loss = 0.8963912576436996, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 487, train_loss = 0.8952502446845756, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 488, train_loss = 0.8960436967536225, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 489, train_loss = 0.8928036677316413, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 490, train_loss = 0.8984987909570918, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 491, train_loss = 0.8952475475743995, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 492, train_loss = 0.8955655085519538, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 493, train_loss = 0.8944696908220067, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 494, train_loss = 0.8981090734378085, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 495, train_loss = 0.8952024442478432, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 496, train_loss = 0.8971483881250606, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 497, train_loss = 0.898191283144115, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 498, train_loss = 0.8966140237971558, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 499, train_loss = 0.8966452293097973, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|███████▉                                                                       | 3/30 [27:03<4:03:35, 541.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "4th- epoch: 0, train_loss = 349.424253359437, train_acc = 0.8169538891476479\n",
      "test Acc 0.8766294227188082:\n",
      "4th- epoch: 1, train_loss = 83.84362636005972, train_acc = 0.9241965533302282\n",
      "test Acc 0.9264432029795159:\n",
      "4th- epoch: 2, train_loss = 51.58511023723986, train_acc = 0.945854680950163\n",
      "test Acc 0.9324953445065177:\n",
      "4th- epoch: 3, train_loss = 36.289122951508034, train_acc = 0.9568001863064741\n",
      "test Acc 0.9399441340782123:\n",
      "4th- epoch: 4, train_loss = 26.86881260073278, train_acc = 0.9646017699115044\n",
      "test Acc 0.9432029795158287:\n",
      "4th- epoch: 5, train_loss = 20.821475418866612, train_acc = 0.9703074056823474\n",
      "test Acc 0.9450651769087524:\n",
      "4th- epoch: 6, train_loss = 16.494844786822796, train_acc = 0.9748486259897532\n",
      "test Acc 0.9534450651769087:\n",
      "4th- epoch: 7, train_loss = 13.511177204549313, train_acc = 0.9782254308337215\n",
      "test Acc 0.9548417132216015:\n",
      "4th- epoch: 8, train_loss = 11.13854539510794, train_acc = 0.9824173265020959\n",
      "test Acc 0.9562383612662942:\n",
      "4th- epoch: 9, train_loss = 9.472597502171993, train_acc = 0.984163949697252\n",
      "test Acc 0.957635009310987:\n",
      "4th- epoch: 10, train_loss = 8.20120048278477, train_acc = 0.9862598975314392\n",
      "test Acc 0.9581005586592178:\n",
      "4th- epoch: 11, train_loss = 7.142496254295111, train_acc = 0.9873078714485328\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 12, train_loss = 6.229617168486584, train_acc = 0.9880065207265952\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 13, train_loss = 5.485844526439905, train_acc = 0.9891709361900326\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 14, train_loss = 4.895193540782202, train_acc = 0.989869585468095\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 15, train_loss = 4.41582952812314, train_acc = 0.9911504424778761\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 16, train_loss = 3.992749693483347, train_acc = 0.9918490917559385\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 17, train_loss = 3.670490377902752, train_acc = 0.9928970656730322\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 18, train_loss = 3.381227344274521, train_acc = 0.9931299487657196\n",
      "test Acc 0.962756052141527:\n",
      "4th- epoch: 19, train_loss = 3.126781707018381, train_acc = 0.9937121564974383\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 20, train_loss = 2.9278106751444284, train_acc = 0.9946436888681882\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 21, train_loss = 2.741948143899208, train_acc = 0.9948765719608756\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 22, train_loss = 2.5912186577916145, train_acc = 0.9954587796925943\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 23, train_loss = 2.4474471546709538, train_acc = 0.995575221238938\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 24, train_loss = 2.33153934776783, train_acc = 0.9956916627852818\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 25, train_loss = 2.2386766634881496, train_acc = 0.996040987424313\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 26, train_loss = 2.152679894119501, train_acc = 0.996040987424313\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 27, train_loss = 2.07449858635664, train_acc = 0.9962738705170004\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 28, train_loss = 2.012218592062709, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 29, train_loss = 1.9500952226371737, train_acc = 0.996506753609688\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 30, train_loss = 1.8975305333733559, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 31, train_loss = 1.8504871216864558, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 32, train_loss = 1.8079199567437172, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 33, train_loss = 1.766861682132003, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 34, train_loss = 1.7296450759022264, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 35, train_loss = 1.7003752030432224, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 36, train_loss = 1.6684494080691366, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 37, train_loss = 1.639294323817012, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 38, train_loss = 1.6138504395930795, train_acc = 0.9969725197950629\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 39, train_loss = 1.5914186400623294, train_acc = 0.9969725197950629\n",
      "test Acc 0.962756052141527:\n",
      "4th- epoch: 40, train_loss = 1.5669831496925326, train_acc = 0.9969725197950629\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 41, train_loss = 1.5474292623548536, train_acc = 0.9969725197950629\n",
      "test Acc 0.962756052141527:\n",
      "4th- epoch: 42, train_loss = 1.5268517484219046, train_acc = 0.9969725197950629\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 43, train_loss = 1.5071896774024935, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 44, train_loss = 1.4924105989484815, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 45, train_loss = 1.4796709629372344, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 46, train_loss = 1.4671812119559036, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 47, train_loss = 1.450054731220007, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 48, train_loss = 1.4383303883150802, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 49, train_loss = 1.4265109511688934, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 50, train_loss = 1.4149101885632263, train_acc = 0.9972054028877504\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 51, train_loss = 1.4044527523219585, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 52, train_loss = 1.3945057528690086, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 53, train_loss = 1.3844239562749863, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 54, train_loss = 1.3738682270050049, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 55, train_loss = 1.3662483555599465, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 56, train_loss = 1.3570340797305107, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 57, train_loss = 1.3475106333717122, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 58, train_loss = 1.341153031833528, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 59, train_loss = 1.330320077635406, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 60, train_loss = 1.3248706236481667, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 61, train_loss = 1.3179203495383263, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 62, train_loss = 1.3082940032109036, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 63, train_loss = 1.3041080199182034, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 64, train_loss = 1.2990461997687817, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 65, train_loss = 1.2903457693755627, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 66, train_loss = 1.2830897544845357, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 67, train_loss = 1.2778066359460354, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 68, train_loss = 1.2734143137931824, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 69, train_loss = 1.266218040138483, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 70, train_loss = 1.2611633042470203, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 71, train_loss = 1.254870434604527, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 72, train_loss = 1.2496545811518445, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 73, train_loss = 1.2443574592471123, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 74, train_loss = 1.237715153642057, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 75, train_loss = 1.2336916526182904, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 76, train_loss = 1.2292101817802177, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 77, train_loss = 1.2225808314979076, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 78, train_loss = 1.2188473207279458, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 79, train_loss = 1.212355842195393, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 80, train_loss = 1.2091463704928174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 81, train_loss = 1.2046341933310032, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 82, train_loss = 1.2001582408920513, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 83, train_loss = 1.1974572017788887, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 84, train_loss = 1.1903828655704274, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 85, train_loss = 1.1869855970144272, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 86, train_loss = 1.182725589722395, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 87, train_loss = 1.1797014859839692, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 88, train_loss = 1.1756331461147056, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 89, train_loss = 1.1709570052735216, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 90, train_loss = 1.1670872593931563, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 91, train_loss = 1.163032708067476, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 92, train_loss = 1.1615055327602022, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 93, train_loss = 1.1542440901212103, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 94, train_loss = 1.1532376656941778, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 95, train_loss = 1.1485587457827933, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 96, train_loss = 1.1465525118001096, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 97, train_loss = 1.1411500237882137, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 98, train_loss = 1.1391286787875288, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 99, train_loss = 1.1332855857908726, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 100, train_loss = 1.1302586073688872, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 101, train_loss = 1.1275071874260902, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 102, train_loss = 1.1266171919814951, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 103, train_loss = 1.1207698583602905, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 104, train_loss = 1.1197931331880682, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 105, train_loss = 1.1162035427987576, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 106, train_loss = 1.1112438887357712, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 107, train_loss = 1.1099203030280478, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 108, train_loss = 1.1065886939577467, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 109, train_loss = 1.1030718249567144, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 110, train_loss = 1.1017266064882278, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 111, train_loss = 1.0957493136338599, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 112, train_loss = 1.0964676439762115, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 113, train_loss = 1.0917202432938211, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 114, train_loss = 1.0895820781588554, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 115, train_loss = 1.0880862300582521, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 116, train_loss = 1.0842735283076763, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 117, train_loss = 1.0809977315366268, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 118, train_loss = 1.0806897766888142, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 119, train_loss = 1.0768945068120956, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 120, train_loss = 1.0746071239300363, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 121, train_loss = 1.073485525947035, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 122, train_loss = 1.0695107827596075, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 123, train_loss = 1.0688616683073633, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 124, train_loss = 1.0645418502390385, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 125, train_loss = 1.0638769529759884, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 126, train_loss = 1.061200133215607, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 127, train_loss = 1.05953510602194, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 128, train_loss = 1.0564869654663198, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 129, train_loss = 1.054376599688112, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 130, train_loss = 1.053827320534765, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 131, train_loss = 1.0494481821842783, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 132, train_loss = 1.049861675750435, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 133, train_loss = 1.0471401860304468, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 134, train_loss = 1.0451751587279432, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 135, train_loss = 1.0423899218440056, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 136, train_loss = 1.041645693283499, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 137, train_loss = 1.0399297761432535, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 138, train_loss = 1.0359047328420274, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 139, train_loss = 1.0359351498373144, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 140, train_loss = 1.0328597066290968, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 141, train_loss = 1.0320739982016676, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 142, train_loss = 1.0281819688789255, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 143, train_loss = 1.0276919628195174, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 144, train_loss = 1.0266968756914139, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 145, train_loss = 1.0241199508309364, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 146, train_loss = 1.0208212099969387, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 147, train_loss = 1.0194406248629093, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 148, train_loss = 1.0203221390656836, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 149, train_loss = 1.0181688355914957, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 150, train_loss = 1.0164579624943144, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 151, train_loss = 1.014219640444935, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 152, train_loss = 1.0126184436194308, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 153, train_loss = 1.0128801514692896, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 154, train_loss = 1.0102138469628699, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 155, train_loss = 1.0093956788368814, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 156, train_loss = 1.007141262292862, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 157, train_loss = 1.0067126477752026, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 158, train_loss = 1.004291641214877, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 159, train_loss = 1.0030889014415152, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 160, train_loss = 1.002008855342865, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 161, train_loss = 0.9999134801328182, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 162, train_loss = 0.9999285365138348, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 163, train_loss = 0.9980164617300034, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 164, train_loss = 0.9958960923049744, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 165, train_loss = 0.9963573180139065, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 166, train_loss = 0.9936786318812665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 167, train_loss = 0.9913763105869293, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 168, train_loss = 0.9903576448559761, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 169, train_loss = 0.9919822414722148, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 170, train_loss = 0.9876366394255456, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 171, train_loss = 0.9867638709638413, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 172, train_loss = 0.9865107884015742, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 173, train_loss = 0.9830934430156049, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 174, train_loss = 0.9852199964225292, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 175, train_loss = 0.9817117738220986, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 176, train_loss = 0.9819313995540142, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 177, train_loss = 0.9791260212659836, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 178, train_loss = 0.9796499485764798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 179, train_loss = 0.9769711705539521, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 180, train_loss = 0.9761188998818398, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 181, train_loss = 0.9751970159504708, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 182, train_loss = 0.9726298948135081, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 183, train_loss = 0.9743449923898879, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 184, train_loss = 0.97126280143857, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 185, train_loss = 0.9710977599024773, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 186, train_loss = 0.9698458202183247, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 187, train_loss = 0.9691340463850793, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 188, train_loss = 0.9675404503941536, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 189, train_loss = 0.9658620953559875, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 190, train_loss = 0.9666634959485236, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 191, train_loss = 0.9640189955625829, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 192, train_loss = 0.9652495458722115, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 193, train_loss = 0.9609263290967647, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 194, train_loss = 0.9606046179924306, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 195, train_loss = 0.9616996794939041, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 196, train_loss = 0.9612905134763423, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 197, train_loss = 0.9591141603887081, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 198, train_loss = 0.9594118520617485, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 199, train_loss = 0.9604473697636422, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 200, train_loss = 0.9568983974550065, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 201, train_loss = 0.9573866551127139, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 202, train_loss = 0.9539942455794517, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 203, train_loss = 0.9540299127493199, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 204, train_loss = 0.9551960465814773, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 205, train_loss = 0.9512882803883258, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 206, train_loss = 0.9496838090326492, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 207, train_loss = 0.9522893577814102, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 208, train_loss = 0.948806643486023, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 209, train_loss = 0.9478353771064576, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 210, train_loss = 0.9500174584482011, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 211, train_loss = 0.9457551464438438, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 212, train_loss = 0.9463393564019498, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 213, train_loss = 0.9461207787189778, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 214, train_loss = 0.9436250366270542, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 215, train_loss = 0.9429829269647598, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 216, train_loss = 0.9443503605816659, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 217, train_loss = 0.94142996023038, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 218, train_loss = 0.9406620922181901, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 219, train_loss = 0.941651713103056, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 220, train_loss = 0.939375925809145, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 221, train_loss = 0.9389745270218555, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 222, train_loss = 0.9391121913995448, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 223, train_loss = 0.9348833970725536, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 224, train_loss = 0.9377052796389762, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 225, train_loss = 0.9342985041439533, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 226, train_loss = 0.9334027717504796, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 227, train_loss = 0.9363290729615983, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 228, train_loss = 0.9333060731496516, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 229, train_loss = 0.931129727512598, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 230, train_loss = 0.9344502550866309, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 231, train_loss = 0.9294758277628716, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 232, train_loss = 0.9294980987906456, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 233, train_loss = 0.9305383774135407, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 234, train_loss = 0.9282570940758887, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 235, train_loss = 0.926338733484954, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 236, train_loss = 0.9280512655768689, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 237, train_loss = 0.9256896215174493, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 238, train_loss = 0.9252335466444492, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 239, train_loss = 0.926093207051963, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 240, train_loss = 0.9240678163860139, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 241, train_loss = 0.9233609773218632, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 242, train_loss = 0.9229915924370289, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 243, train_loss = 0.9249075291063491, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 244, train_loss = 0.9217248186469078, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 245, train_loss = 0.9211498411987122, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 246, train_loss = 0.9233483324442204, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 247, train_loss = 0.9187611602246761, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 248, train_loss = 0.9189705165717896, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 249, train_loss = 0.9212399224434193, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 250, train_loss = 0.9181065546963509, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 251, train_loss = 0.9180117708947364, train_acc = 0.9981369352585002\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 252, train_loss = 0.9190555301811401, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 253, train_loss = 0.916672716537505, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 254, train_loss = 0.9167889207601547, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 255, train_loss = 0.9146912346277531, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 256, train_loss = 0.9163654893636703, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 257, train_loss = 0.9157014191150665, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 258, train_loss = 0.9128671586513519, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 259, train_loss = 0.9135031402111053, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 260, train_loss = 0.9136294089257717, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 261, train_loss = 0.9114743409063522, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 262, train_loss = 0.9116109001133736, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 263, train_loss = 0.9130640191342536, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 264, train_loss = 0.9095262537393864, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 265, train_loss = 0.9108373212311562, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 266, train_loss = 0.9086454982552823, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 267, train_loss = 0.9108314948771294, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 268, train_loss = 0.9078789502382278, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 269, train_loss = 0.9082188693191711, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 270, train_loss = 0.9058100841939449, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 271, train_loss = 0.9085043681170646, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 272, train_loss = 0.9055504066254798, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 273, train_loss = 0.9053937171902362, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 274, train_loss = 0.9054786625001725, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 275, train_loss = 0.9072526494655904, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 276, train_loss = 0.9045040893051919, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 277, train_loss = 0.9038256344701949, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 278, train_loss = 0.903539527207613, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 279, train_loss = 0.9061997160315514, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 280, train_loss = 0.9013651621844474, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 281, train_loss = 0.901845575621337, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 282, train_loss = 0.9038567232582864, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 283, train_loss = 0.9016401010248956, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 284, train_loss = 0.8994581066071987, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 285, train_loss = 0.9027204029262066, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 286, train_loss = 0.8996935362620206, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 287, train_loss = 0.8999941038591714, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 288, train_loss = 0.9003995545208454, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 289, train_loss = 0.9010921468334345, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 290, train_loss = 0.8995083197951317, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 291, train_loss = 0.8988318406045437, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 292, train_loss = 0.8974131383001804, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 293, train_loss = 0.899870865046978, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 294, train_loss = 0.8960540009038596, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 295, train_loss = 0.8963690573964413, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 296, train_loss = 0.8987338667111544, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 297, train_loss = 0.8959517876310201, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 298, train_loss = 0.8947859890758991, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 299, train_loss = 0.8981072107953878, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 300, train_loss = 0.8934582906467767, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 301, train_loss = 0.8948968375725599, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 302, train_loss = 0.893164164076552, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 303, train_loss = 0.8951221778988838, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 304, train_loss = 0.8926768576102404, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 305, train_loss = 0.8926621824502945, train_acc = 0.9981369352585002\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 306, train_loss = 0.8961729804677816, train_acc = 0.9981369352585002\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 307, train_loss = 0.8917437580721526, train_acc = 0.9981369352585002\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 308, train_loss = 0.8914498152835222, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 309, train_loss = 0.8908709970610289, train_acc = 0.9981369352585002\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 310, train_loss = 0.8913530943291335, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 311, train_loss = 0.8923232716815619, train_acc = 0.9981369352585002\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 312, train_loss = 0.8898721610503344, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 313, train_loss = 0.8896511582033781, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 314, train_loss = 0.8888479148345141, train_acc = 0.9981369352585002\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 315, train_loss = 0.888589970767498, train_acc = 0.9981369352585002\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 316, train_loss = 0.8912291787564754, train_acc = 0.9981369352585002\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 317, train_loss = 0.8887660180525927, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 318, train_loss = 0.8886492463452669, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 319, train_loss = 0.8882446574671121, train_acc = 0.9981369352585002\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 320, train_loss = 0.8903447004659029, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 321, train_loss = 0.8876748904585838, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 322, train_loss = 0.887836404144764, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 323, train_loss = 0.8867440198855547, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 324, train_loss = 0.8893177409963755, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 325, train_loss = 0.8872763800127359, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 326, train_loss = 0.8858232498168945, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 327, train_loss = 0.8857232766849847, train_acc = 0.9981369352585002\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 328, train_loss = 0.8868557090563627, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 329, train_loss = 0.8851105111343713, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 330, train_loss = 0.8839616229133753, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 331, train_loss = 0.8840108402073383, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 332, train_loss = 0.8864056020975113, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 333, train_loss = 0.8834840667741446, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 334, train_loss = 0.8833079114556313, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 335, train_loss = 0.8832168926792292, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 336, train_loss = 0.8847745259599833, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 337, train_loss = 0.8827588371932507, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 338, train_loss = 0.8813599112136217, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 339, train_loss = 0.8819077375037523, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 340, train_loss = 0.8824438589317651, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 341, train_loss = 0.8810758541030737, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 342, train_loss = 0.8798371044294981, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 343, train_loss = 0.8804655397934766, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 344, train_loss = 0.8804562911391258, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 345, train_loss = 0.8795592586202474, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 346, train_loss = 0.8813201052444128, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 347, train_loss = 0.8782377156121584, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 348, train_loss = 0.8788888851804586, train_acc = 0.9981369352585002\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 349, train_loss = 0.8807976705329565, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 350, train_loss = 0.8821780147654863, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 351, train_loss = 0.8784826037781386, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 352, train_loss = 0.8784996035201402, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 353, train_loss = 0.8774606846272945, train_acc = 0.9980204937121565\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 354, train_loss = 0.8791615429026933, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 355, train_loss = 0.8773247860372066, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 356, train_loss = 0.8758749564485697, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 357, train_loss = 0.8760910369455814, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 358, train_loss = 0.8792044259607792, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 359, train_loss = 0.8769058945281358, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 360, train_loss = 0.8767157855136247, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 361, train_loss = 0.8750076132519098, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 362, train_loss = 0.8745791750652643, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 363, train_loss = 0.87735166400671, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 364, train_loss = 0.8741975550847201, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 365, train_loss = 0.8754097608225493, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 366, train_loss = 0.8773333765566349, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 367, train_loss = 0.8743695616722107, train_acc = 0.9980204937121565\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 368, train_loss = 0.8744777974980025, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 369, train_loss = 0.8742440119385719, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 370, train_loss = 0.8733798613147883, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 371, train_loss = 0.8767517743008284, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 372, train_loss = 0.8729915233952852, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 373, train_loss = 0.8728536839289518, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 374, train_loss = 0.8711228035390377, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 375, train_loss = 0.8728606700897217, train_acc = 0.9980204937121565\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 376, train_loss = 0.8743753793341966, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 377, train_loss = 0.872178817789063, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 378, train_loss = 0.8725732055800108, train_acc = 0.9980204937121565\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 379, train_loss = 0.8713523633778095, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 380, train_loss = 0.873096262414947, train_acc = 0.9980204937121565\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 381, train_loss = 0.873555889974341, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 382, train_loss = 0.8705740074319692, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 383, train_loss = 0.871001233656898, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 384, train_loss = 0.8718432163195757, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 385, train_loss = 0.8731444031000137, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 386, train_loss = 0.8702369046704916, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 387, train_loss = 0.8714942273991255, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 388, train_loss = 0.869860113908544, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 389, train_loss = 0.8739673035843225, train_acc = 0.9980204937121565\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 390, train_loss = 0.8706487789750099, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 391, train_loss = 0.8707460997002272, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 392, train_loss = 0.8695403312640337, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 393, train_loss = 0.8720374753074793, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 394, train_loss = 0.8697785561280398, train_acc = 0.9980204937121565\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 395, train_loss = 0.867631295074716, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 396, train_loss = 0.8690068547921328, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 397, train_loss = 0.8688610369963499, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 398, train_loss = 0.8693135529756546, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 399, train_loss = 0.8680889060096888, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 400, train_loss = 0.8687095604836941, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 401, train_loss = 0.8679321557283401, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 402, train_loss = 0.867475648720756, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 403, train_loss = 0.870302000393167, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 404, train_loss = 0.8664657026529312, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 405, train_loss = 0.8685947743551878, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 406, train_loss = 0.868273104230866, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 407, train_loss = 0.8665547408163548, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 408, train_loss = 0.8693941173451094, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 409, train_loss = 0.8643630755441336, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 410, train_loss = 0.867172971367836, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 411, train_loss = 0.865880721558824, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 412, train_loss = 0.8676403636736723, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 413, train_loss = 0.8654114964110704, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 414, train_loss = 0.8651910213129668, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 415, train_loss = 0.8661360815167427, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 416, train_loss = 0.8666758847730307, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 417, train_loss = 0.8647726463777872, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 418, train_loss = 0.8640903520090433, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 419, train_loss = 0.8642860129475594, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 420, train_loss = 0.8637055692570357, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 421, train_loss = 0.8648694405956121, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 422, train_loss = 0.8696213625371456, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 423, train_loss = 0.8639490505056528, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 424, train_loss = 0.8651314141852708, train_acc = 0.9980204937121565\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 425, train_loss = 0.863600070278153, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 426, train_loss = 0.865003974487081, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 427, train_loss = 0.86263008415699, train_acc = 0.9981369352585002\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 428, train_loss = 0.8635100051760674, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 429, train_loss = 0.862600464373827, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 430, train_loss = 0.860616399596438, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 431, train_loss = 0.8645008305711599, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 432, train_loss = 0.8625526155037733, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 433, train_loss = 0.8667708051698355, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 434, train_loss = 0.8622754539055677, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 435, train_loss = 0.8599308431148529, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 436, train_loss = 0.8623764688773008, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 437, train_loss = 0.8642498031258583, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 438, train_loss = 0.8598055019974709, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 439, train_loss = 0.861653306831613, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 440, train_loss = 0.8614981236560197, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 441, train_loss = 0.8600826760130076, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 442, train_loss = 0.8623734662933202, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 443, train_loss = 0.861238167931333, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 444, train_loss = 0.8604381866753101, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 445, train_loss = 0.8601867196457533, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 446, train_loss = 0.8617280063526778, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 447, train_loss = 0.8601608425378799, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 448, train_loss = 0.861777203778729, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 449, train_loss = 0.8597723580896854, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 450, train_loss = 0.86049435287714, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 451, train_loss = 0.8581747586531492, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 452, train_loss = 0.862003430724144, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 453, train_loss = 0.8599617977934031, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 454, train_loss = 0.8586149948341699, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 455, train_loss = 0.8572098836302757, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 456, train_loss = 0.8582495450973511, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 457, train_loss = 0.8603010425968023, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 458, train_loss = 0.8589513127999453, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 459, train_loss = 0.8578786887228489, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 460, train_loss = 0.8575266723828463, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 461, train_loss = 0.8578990312917085, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 462, train_loss = 0.8602942936122417, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 463, train_loss = 0.8574606490628867, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 464, train_loss = 0.8578206586344095, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 465, train_loss = 0.8585024227695612, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 466, train_loss = 0.8561635091900826, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 467, train_loss = 0.8584456803901048, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 468, train_loss = 0.8577480812864451, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 469, train_loss = 0.8564532982809396, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 470, train_loss = 0.85517967740725, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 471, train_loss = 0.8558068387210369, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 472, train_loss = 0.8602646440267563, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 473, train_loss = 0.8564529108507486, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 474, train_loss = 0.8544238768517971, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 475, train_loss = 0.8572607065243574, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 476, train_loss = 0.8546668402850628, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 477, train_loss = 0.8555324785411358, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 478, train_loss = 0.8588421506183295, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 479, train_loss = 0.8555702877538351, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 480, train_loss = 0.8539580206079336, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 481, train_loss = 0.8531106896698475, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 482, train_loss = 0.855129674077034, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 483, train_loss = 0.8540074129896311, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 484, train_loss = 0.857093368967071, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 485, train_loss = 0.8542439093189387, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 486, train_loss = 0.8528313860297203, train_acc = 0.9981369352585002\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 487, train_loss = 0.8553161521749644, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 488, train_loss = 0.8537007855875345, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 489, train_loss = 0.8528301579253821, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 490, train_loss = 0.8555958109600397, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 491, train_loss = 0.8550315176444201, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 492, train_loss = 0.8526367793483587, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 493, train_loss = 0.8528139106929302, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 494, train_loss = 0.8542161261038927, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 495, train_loss = 0.8556204835576864, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 496, train_loss = 0.8526637963950634, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 497, train_loss = 0.8522657702369543, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 498, train_loss = 0.8522375014917998, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 499, train_loss = 0.8542143404483795, train_acc = 0.9980204937121565\n",
      "test Acc 0.9678770949720671:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|██████████▌                                                                    | 4/30 [36:03<3:54:20, 540.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "5th- epoch: 0, train_loss = 333.30812707543373, train_acc = 0.8196320447135538\n",
      "test Acc 0.9180633147113594:\n",
      "5th- epoch: 1, train_loss = 83.07292818150017, train_acc = 0.9248952026082906\n",
      "test Acc 0.936219739292365:\n",
      "5th- epoch: 2, train_loss = 50.21817409712821, train_acc = 0.9474848625989754\n",
      "test Acc 0.9413407821229051:\n",
      "5th- epoch: 3, train_loss = 34.28682007081807, train_acc = 0.9587796925943176\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 4, train_loss = 25.17487696511671, train_acc = 0.9676292501164415\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 5, train_loss = 18.912317644339055, train_acc = 0.9729855612482534\n",
      "test Acc 0.9511173184357542:\n",
      "5th- epoch: 6, train_loss = 14.700070754159242, train_acc = 0.9782254308337215\n",
      "test Acc 0.9506517690875232:\n",
      "5th- epoch: 7, train_loss = 11.915396164171398, train_acc = 0.9821844434094085\n",
      "test Acc 0.952513966480447:\n",
      "5th- epoch: 8, train_loss = 9.846447251271456, train_acc = 0.9845132743362832\n",
      "test Acc 0.952513966480447:\n",
      "5th- epoch: 9, train_loss = 8.288784808013588, train_acc = 0.9862598975314392\n",
      "test Acc 0.952048417132216:\n",
      "5th- epoch: 10, train_loss = 7.086458098143339, train_acc = 0.9887051700046576\n",
      "test Acc 0.9534450651769087:\n",
      "5th- epoch: 11, train_loss = 6.221715643303469, train_acc = 0.9902189101071263\n",
      "test Acc 0.9543761638733705:\n",
      "5th- epoch: 12, train_loss = 5.582267408492044, train_acc = 0.9904517931998137\n",
      "test Acc 0.9557728119180633:\n",
      "5th- epoch: 13, train_loss = 5.026132678613067, train_acc = 0.9917326502095948\n",
      "test Acc 0.9562383612662942:\n",
      "5th- epoch: 14, train_loss = 4.5889535987516865, train_acc = 0.9925477410340009\n",
      "test Acc 0.9562383612662942:\n",
      "5th- epoch: 15, train_loss = 4.249088119715452, train_acc = 0.9930135072193759\n",
      "test Acc 0.9562383612662942:\n",
      "5th- epoch: 16, train_loss = 3.939077528193593, train_acc = 0.9932463903120633\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 17, train_loss = 3.6910815400769934, train_acc = 0.9935957149510946\n",
      "test Acc 0.9562383612662942:\n",
      "5th- epoch: 18, train_loss = 3.4387611132115126, train_acc = 0.9937121564974383\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 19, train_loss = 3.2431417977204546, train_acc = 0.9940614811364695\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 20, train_loss = 3.0484758894890547, train_acc = 0.9945272473218444\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 21, train_loss = 2.884066523401998, train_acc = 0.9949930135072194\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 22, train_loss = 2.754263941780664, train_acc = 0.9949930135072194\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 23, train_loss = 2.633589974255301, train_acc = 0.9951094550535631\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 24, train_loss = 2.525294658378698, train_acc = 0.9951094550535631\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 25, train_loss = 2.4394021263578907, train_acc = 0.995575221238938\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 26, train_loss = 2.3642539182910696, train_acc = 0.995575221238938\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 27, train_loss = 2.2977782391244546, train_acc = 0.9956916627852818\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 28, train_loss = 2.237223517149687, train_acc = 0.9956916627852818\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 29, train_loss = 2.179607550613582, train_acc = 0.9958081043316255\n",
      "test Acc 0.9618249534450651:\n",
      "5th- epoch: 30, train_loss = 2.120806751481723, train_acc = 0.9958081043316255\n",
      "test Acc 0.962756052141527:\n",
      "5th- epoch: 31, train_loss = 2.0661040910636075, train_acc = 0.9958081043316255\n",
      "test Acc 0.9622905027932961:\n",
      "5th- epoch: 32, train_loss = 2.022408560558688, train_acc = 0.9958081043316255\n",
      "test Acc 0.962756052141527:\n",
      "5th- epoch: 33, train_loss = 1.9590355663676746, train_acc = 0.9959245458779693\n",
      "test Acc 0.9622905027932961:\n",
      "5th- epoch: 34, train_loss = 1.9128728788346052, train_acc = 0.9959245458779693\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 35, train_loss = 1.8707693628966808, train_acc = 0.9959245458779693\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 36, train_loss = 1.8225514777004719, train_acc = 0.9959245458779693\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 37, train_loss = 1.7866480611264706, train_acc = 0.9959245458779693\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 38, train_loss = 1.7444565606419928, train_acc = 0.9959245458779693\n",
      "test Acc 0.962756052141527:\n",
      "5th- epoch: 39, train_loss = 1.7073569583590142, train_acc = 0.996040987424313\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 40, train_loss = 1.6749022230505943, train_acc = 0.996040987424313\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 41, train_loss = 1.6394569513504393, train_acc = 0.996040987424313\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 42, train_loss = 1.6140203271061182, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 43, train_loss = 1.58524532179581, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 44, train_loss = 1.5537226622109301, train_acc = 0.9962738705170004\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 45, train_loss = 1.5246690983767621, train_acc = 0.9962738705170004\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 46, train_loss = 1.5038054821197875, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 47, train_loss = 1.4904297962784767, train_acc = 0.996506753609688\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 48, train_loss = 1.4735605039750226, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 49, train_loss = 1.461144729226362, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 50, train_loss = 1.4469206382636912, train_acc = 0.9962738705170004\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 51, train_loss = 1.4335981023905333, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 52, train_loss = 1.4266614032385405, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 53, train_loss = 1.4126797684875783, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 54, train_loss = 1.4073896954359952, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 55, train_loss = 1.3934556537715252, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 56, train_loss = 1.389288075879449, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 57, train_loss = 1.3775375336408615, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 58, train_loss = 1.3707059311273042, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 59, train_loss = 1.3608665888605174, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 60, train_loss = 1.354211008787388, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 61, train_loss = 1.3492984759213869, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 62, train_loss = 1.3408894278109074, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 63, train_loss = 1.3350880704820156, train_acc = 0.9963903120633442\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 64, train_loss = 1.3255990991892759, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 65, train_loss = 1.3212385326623917, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 66, train_loss = 1.314572629838949, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 67, train_loss = 1.309980550169712, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 68, train_loss = 1.3047252967953682, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 69, train_loss = 1.2975913149712142, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 70, train_loss = 1.2924076368362876, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 71, train_loss = 1.2873724860401126, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 72, train_loss = 1.280966362610343, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 73, train_loss = 1.2756966091692448, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 74, train_loss = 1.269928690046072, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 75, train_loss = 1.2664340784103842, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 76, train_loss = 1.2616164696664782, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 77, train_loss = 1.2555632392613916, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 78, train_loss = 1.2513555300683947, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 79, train_loss = 1.2473525330424309, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 80, train_loss = 1.2410785729734926, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 81, train_loss = 1.2375055650918512, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 82, train_loss = 1.2324353704898385, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 83, train_loss = 1.2267420254647732, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 84, train_loss = 1.2242717022745637, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 85, train_loss = 1.2197476128785638, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 86, train_loss = 1.215155032768962, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 87, train_loss = 1.210800910994294, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 88, train_loss = 1.208092870816472, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 89, train_loss = 1.2032423851342173, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 90, train_loss = 1.199868651732686, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 91, train_loss = 1.1965955992491217, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 92, train_loss = 1.1959162180573912, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 93, train_loss = 1.1912359831185313, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 94, train_loss = 1.186902642250061, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 95, train_loss = 1.184439634278533, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 96, train_loss = 1.1792551365942927, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 97, train_loss = 1.17484566073108, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 98, train_loss = 1.1722358403058024, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 99, train_loss = 1.1695678432733985, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 100, train_loss = 1.1665162667632103, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 101, train_loss = 1.1639638344495324, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 102, train_loss = 1.1609875087888213, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 103, train_loss = 1.1569527027459117, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 104, train_loss = 1.156964340552804, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 105, train_loss = 1.1524545537977247, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 106, train_loss = 1.1499860783369513, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 107, train_loss = 1.1478707138448954, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 108, train_loss = 1.1450878654941334, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 109, train_loss = 1.1431080208494677, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 110, train_loss = 1.1403342553749098, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 111, train_loss = 1.1378019421026693, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 112, train_loss = 1.1341057835743413, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 113, train_loss = 1.132726655654551, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 114, train_loss = 1.1322552623823867, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 115, train_loss = 1.129407910630107, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 116, train_loss = 1.1263892414644943, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 117, train_loss = 1.1254037792459712, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 118, train_loss = 1.1215292786582722, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 119, train_loss = 1.1205067137852893, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 120, train_loss = 1.12027805919206, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 121, train_loss = 1.1154457169250236, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 122, train_loss = 1.1139776588752284, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 123, train_loss = 1.1142729086204781, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 124, train_loss = 1.1093703123406158, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 125, train_loss = 1.110085320971848, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 126, train_loss = 1.1050802214667783, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 127, train_loss = 1.107857837654592, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 128, train_loss = 1.1015288239941583, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 129, train_loss = 1.1022908141239895, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 130, train_loss = 1.0993689366951003, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 131, train_loss = 1.0987677754237666, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 132, train_loss = 1.0952145848423243, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 133, train_loss = 1.095954662807344, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 134, train_loss = 1.0923177978620515, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 135, train_loss = 1.0917224418371916, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 136, train_loss = 1.0885939983054413, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 137, train_loss = 1.0886227445080294, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 138, train_loss = 1.085638727992773, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 139, train_loss = 1.0840165882036672, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 140, train_loss = 1.0829454716295004, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 141, train_loss = 1.083187890551926, train_acc = 0.9969725197950629\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 142, train_loss = 1.0799255749807344, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 143, train_loss = 1.079150899000524, train_acc = 0.9969725197950629\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 144, train_loss = 1.0782504392191186, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 145, train_loss = 1.075577748939395, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 146, train_loss = 1.0736350336446776, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 147, train_loss = 1.0725345940663829, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 148, train_loss = 1.0724344098343863, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 149, train_loss = 1.0688385081812157, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 150, train_loss = 1.0672613351271139, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 151, train_loss = 1.066793874524592, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 152, train_loss = 1.0619547770693316, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 153, train_loss = 1.0601605270057917, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 154, train_loss = 1.0615577933713212, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 155, train_loss = 1.0618560090661049, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 156, train_loss = 1.0580778811126947, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 157, train_loss = 1.0572538822889328, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 158, train_loss = 1.056921795629023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 159, train_loss = 1.05462182933843, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 160, train_loss = 1.0546245922669186, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 161, train_loss = 1.0530288287773146, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 162, train_loss = 1.0524179271087633, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 163, train_loss = 1.0507308288142667, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 164, train_loss = 1.0482803763225093, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 165, train_loss = 1.0449864578768029, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 166, train_loss = 1.0481970608234406, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 167, train_loss = 1.0479115154594183, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 168, train_loss = 1.0428421000615344, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 169, train_loss = 1.0445915485397563, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 170, train_loss = 1.045290943235159, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 171, train_loss = 1.042008792363049, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 172, train_loss = 1.0398772867993102, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 173, train_loss = 1.0372988519593491, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 174, train_loss = 1.0373654936774983, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 175, train_loss = 1.038609412185906, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 176, train_loss = 1.0372564382851124, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 177, train_loss = 1.035446164511086, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 178, train_loss = 1.0326863937079906, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 179, train_loss = 1.032926071435213, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 180, train_loss = 1.034909645713924, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 181, train_loss = 1.032877175755857, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 182, train_loss = 1.0307973908857093, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 183, train_loss = 1.0292850701735006, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 184, train_loss = 1.0253621327356086, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 185, train_loss = 1.0278812696560635, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 186, train_loss = 1.0257647248581634, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 187, train_loss = 1.0262612830847502, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 188, train_loss = 1.0247671442702995, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 189, train_loss = 1.0227737290188088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 190, train_loss = 1.0221250746399164, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 191, train_loss = 1.0225257643833174, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 192, train_loss = 1.020730442054628, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 193, train_loss = 1.017737690359354, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 194, train_loss = 1.0171399526298046, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 195, train_loss = 1.017384123057127, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 196, train_loss = 1.0169475879520178, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 197, train_loss = 1.0168708066121326, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 198, train_loss = 1.013109448053001, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 199, train_loss = 1.013612342379929, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 200, train_loss = 1.0137557132766233, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 201, train_loss = 1.0113794927819981, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 202, train_loss = 1.0107222863807692, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 203, train_loss = 1.0106435026973486, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 204, train_loss = 1.0081021878868341, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 205, train_loss = 1.0082190191969858, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 206, train_loss = 1.0069326553493738, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 207, train_loss = 1.0065245876685367, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 208, train_loss = 1.004958209268807, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 209, train_loss = 1.0039225990549312, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 210, train_loss = 1.003107366464974, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 211, train_loss = 1.0025325305759907, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 212, train_loss = 1.0023576642051921, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 213, train_loss = 1.001863776393293, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 214, train_loss = 0.999514989554882, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 215, train_loss = 0.99923648188269, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 216, train_loss = 0.9993269629776478, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 217, train_loss = 0.9968030365780578, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 218, train_loss = 0.9965797991826548, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 219, train_loss = 0.9954145513474941, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 220, train_loss = 0.9947230275720358, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 221, train_loss = 0.9936404588297592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 222, train_loss = 0.9927262937053456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 223, train_loss = 0.9932445387021289, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 224, train_loss = 0.9920210453346954, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 225, train_loss = 0.9910821306184516, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 226, train_loss = 0.9897448594347225, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 227, train_loss = 0.9889657323583378, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 228, train_loss = 0.9889679377301945, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 229, train_loss = 0.9878503127620206, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 230, train_loss = 0.9875519958659424, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 231, train_loss = 0.9855844949706807, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 232, train_loss = 0.9856237483545556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 233, train_loss = 0.9858141125514521, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 234, train_loss = 0.9830983666106476, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 235, train_loss = 0.9830695260316133, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 236, train_loss = 0.9831702448427677, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 237, train_loss = 0.9775504171848297, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 238, train_loss = 0.9806368543431745, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 239, train_loss = 0.981146328151226, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 240, train_loss = 0.9794837484732852, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 241, train_loss = 0.9801348354667425, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 242, train_loss = 0.9760323210284696, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 243, train_loss = 0.9770839673765295, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 244, train_loss = 0.9760388154536486, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 245, train_loss = 0.9761293313131318, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 246, train_loss = 0.9747637708969705, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 247, train_loss = 0.9744571167975664, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 248, train_loss = 0.9738025227561593, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 249, train_loss = 0.9732336519882665, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 250, train_loss = 0.9720646369569295, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 251, train_loss = 0.9704483825080388, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 252, train_loss = 0.9715330045037263, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 253, train_loss = 0.9697930375114083, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 254, train_loss = 0.9689391416795843, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 255, train_loss = 0.9689154143743508, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 256, train_loss = 0.969538116518379, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 257, train_loss = 0.9662803610153787, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 258, train_loss = 0.9676606422290206, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 259, train_loss = 0.9656875577456958, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 260, train_loss = 0.965456633206486, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 261, train_loss = 0.96460828371346, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 262, train_loss = 0.9649368772916205, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 263, train_loss = 0.9621696748472459, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 264, train_loss = 0.9601103958375461, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 265, train_loss = 0.9647306725382805, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 266, train_loss = 0.9610023020468361, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 267, train_loss = 0.9613577627278573, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 268, train_loss = 0.9615286228545301, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 269, train_loss = 0.9599736506752379, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 270, train_loss = 0.9603392326571338, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 271, train_loss = 0.958998177509784, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 272, train_loss = 0.9567788479216688, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 273, train_loss = 0.9546148379631632, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 274, train_loss = 0.953601966612041, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 275, train_loss = 0.956087258644402, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 276, train_loss = 0.9522486831992865, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 277, train_loss = 0.9542551059275866, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 278, train_loss = 0.955952207557857, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 279, train_loss = 0.9551914976909757, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 280, train_loss = 0.9528598769866221, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 281, train_loss = 0.9528553352392919, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 282, train_loss = 0.9519145078957081, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 283, train_loss = 0.9527669195085764, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 284, train_loss = 0.9521847286559932, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 285, train_loss = 0.949371051043272, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 286, train_loss = 0.9472142001613975, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 287, train_loss = 0.9485045128203637, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 288, train_loss = 0.9495480954647064, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 289, train_loss = 0.9481525719165802, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 290, train_loss = 0.9491872067264921, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 291, train_loss = 0.946454859647929, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 292, train_loss = 0.9474137493707531, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 293, train_loss = 0.9468917387239344, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 294, train_loss = 0.9456886133812077, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 295, train_loss = 0.9451050882526033, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 296, train_loss = 0.9450801564380527, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 297, train_loss = 0.9440138737372763, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 298, train_loss = 0.9445286697409756, train_acc = 0.9979040521658128\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 299, train_loss = 0.9437465481460094, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 300, train_loss = 0.9407891404516704, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 301, train_loss = 0.9393324687443965, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 302, train_loss = 0.9404316463806026, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 303, train_loss = 0.9375153590626724, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 304, train_loss = 0.9379723872989416, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 305, train_loss = 0.9371400196105242, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 306, train_loss = 0.9371259659528732, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 307, train_loss = 0.9345050879455812, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 308, train_loss = 0.9381711365022056, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 309, train_loss = 0.9384198583029502, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 310, train_loss = 0.9357576705515385, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 311, train_loss = 0.9330394901335239, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 312, train_loss = 0.9362816515676968, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 313, train_loss = 0.9344710508994467, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 314, train_loss = 0.9323057973124378, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 315, train_loss = 0.9328701763115532, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 316, train_loss = 0.9350028894841671, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 317, train_loss = 0.9325785087421536, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 318, train_loss = 0.9324565250426531, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 319, train_loss = 0.932683880750119, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 320, train_loss = 0.9295713783540123, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 321, train_loss = 0.931389625184238, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 322, train_loss = 0.9322409170381434, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 323, train_loss = 0.9298636522144079, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 324, train_loss = 0.9290269482880831, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 325, train_loss = 0.9284878674261563, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 326, train_loss = 0.9273599603511684, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 327, train_loss = 0.9297966168560379, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 328, train_loss = 0.9286476025990851, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 329, train_loss = 0.9277195402719371, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 330, train_loss = 0.9284623290113814, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 331, train_loss = 0.9272625825069554, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 332, train_loss = 0.9233620023987896, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 333, train_loss = 0.927026114117325, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 334, train_loss = 0.9253507256507874, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 335, train_loss = 0.9263396393507719, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 336, train_loss = 0.924220041371882, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 337, train_loss = 0.9241014153994911, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 338, train_loss = 0.926219664823293, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 339, train_loss = 0.9236714864782698, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 340, train_loss = 0.923335427109123, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 341, train_loss = 0.9227223523594148, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 342, train_loss = 0.9218810393176682, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 343, train_loss = 0.922046275500179, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 344, train_loss = 0.9220589504875534, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 345, train_loss = 0.9232449289411306, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 346, train_loss = 0.9199879355728626, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 347, train_loss = 0.9144561737775803, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 348, train_loss = 0.9208490277342207, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 349, train_loss = 0.9188221165277355, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 350, train_loss = 0.9195917450524576, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 351, train_loss = 0.9186647798233025, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 352, train_loss = 0.9132564663887024, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 353, train_loss = 0.9176036765165918, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 354, train_loss = 0.9177534263581038, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 355, train_loss = 0.9166072982661717, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 356, train_loss = 0.915844323735655, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 357, train_loss = 0.9162992397323251, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 358, train_loss = 0.9166180106512911, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 359, train_loss = 0.9156165697313554, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 360, train_loss = 0.9141361806541681, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 361, train_loss = 0.9143590113781102, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 362, train_loss = 0.9142665984109044, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 363, train_loss = 0.91505775321275, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 364, train_loss = 0.9088507822416432, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 365, train_loss = 0.9101320492736704, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 366, train_loss = 0.9109062273055315, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 367, train_loss = 0.9122707660608285, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 368, train_loss = 0.9062006690837734, train_acc = 0.9981369352585002\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 369, train_loss = 0.9121561544016004, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 370, train_loss = 0.9129783405624039, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 371, train_loss = 0.9110953453928232, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 372, train_loss = 0.9081176829822653, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 373, train_loss = 0.9088235907256603, train_acc = 0.9981369352585002\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 374, train_loss = 0.9082534713670611, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 375, train_loss = 0.9076038962230086, train_acc = 0.9981369352585002\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 376, train_loss = 0.9041741043329239, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 377, train_loss = 0.9088783115148544, train_acc = 0.9981369352585002\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 378, train_loss = 0.9046943324319727, train_acc = 0.9981369352585002\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 379, train_loss = 0.9091582919172652, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 380, train_loss = 0.9065966559574008, train_acc = 0.9981369352585002\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 381, train_loss = 0.9062684029340744, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 382, train_loss = 0.9064268457404978, train_acc = 0.9981369352585002\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 383, train_loss = 0.9075876617171161, train_acc = 0.9980204937121565\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 384, train_loss = 0.9056408833712339, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 385, train_loss = 0.9010558426380157, train_acc = 0.9981369352585002\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 386, train_loss = 0.9029869673140638, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 387, train_loss = 0.9017189188562043, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 388, train_loss = 0.9045531790070527, train_acc = 0.9981369352585002\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 389, train_loss = 0.902671945590555, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 390, train_loss = 0.9068099288269877, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 391, train_loss = 0.9011536302677996, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 392, train_loss = 0.9031078085936315, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 393, train_loss = 0.9012120499573939, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 394, train_loss = 0.8960981027521484, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 395, train_loss = 0.9034741514660709, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 396, train_loss = 0.9012019541114569, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 397, train_loss = 0.906474660459935, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 398, train_loss = 0.8999850116670132, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 399, train_loss = 0.8983036894351244, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 400, train_loss = 0.902032588608563, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 401, train_loss = 0.9032890116795897, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 402, train_loss = 0.8975459936373227, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 403, train_loss = 0.9029163724444516, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 404, train_loss = 0.8969100825488567, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 405, train_loss = 0.9004602624736435, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 406, train_loss = 0.901971918221534, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 407, train_loss = 0.8981044773645408, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 408, train_loss = 0.8990965128577955, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 409, train_loss = 0.8966035333760374, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 410, train_loss = 0.897285773728072, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 411, train_loss = 0.9003478254489892, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 412, train_loss = 0.8946882939599163, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 413, train_loss = 0.8964407071471214, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 414, train_loss = 0.8964006643145694, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 415, train_loss = 0.8949190163984895, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 416, train_loss = 0.8952738490552292, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 417, train_loss = 0.9023576031140692, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 418, train_loss = 0.8989050233103626, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 419, train_loss = 0.8935113294683106, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 420, train_loss = 0.899436199106276, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 421, train_loss = 0.8988612374923832, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 422, train_loss = 0.8978660603388562, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 423, train_loss = 0.8916750301941647, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 424, train_loss = 0.8961895356587775, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 425, train_loss = 0.8897892466411577, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 426, train_loss = 0.8883691821247339, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 427, train_loss = 0.8975624352060549, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 428, train_loss = 0.8976263199001551, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 429, train_loss = 0.899695934727788, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 430, train_loss = 0.8970397763587243, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 431, train_loss = 0.8949592042081349, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 432, train_loss = 0.8924530955664522, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 433, train_loss = 0.8961432874202728, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 434, train_loss = 0.8988980408757925, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 435, train_loss = 0.8962547977753275, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 436, train_loss = 0.8934806600846059, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 437, train_loss = 0.8958824221044779, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 438, train_loss = 0.8943542713932402, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 439, train_loss = 0.8904784213154926, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 440, train_loss = 0.8924059408418543, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 441, train_loss = 0.8924457853026979, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 442, train_loss = 0.8924391797445423, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 443, train_loss = 0.8963569576553709, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 444, train_loss = 0.8964282246306539, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 445, train_loss = 0.8913436466827989, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 446, train_loss = 0.89513394826281, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 447, train_loss = 0.8946583275683224, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 448, train_loss = 0.8952794823162549, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 449, train_loss = 0.8946844621859782, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 450, train_loss = 0.8924878790676303, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 451, train_loss = 0.8899034494534135, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 452, train_loss = 0.8854307200163021, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 453, train_loss = 0.8886623273901932, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 454, train_loss = 0.8892699778079987, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 455, train_loss = 0.8883014411367185, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 456, train_loss = 0.8897412413098209, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 457, train_loss = 0.8828468996398442, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 458, train_loss = 0.8915895534046285, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 459, train_loss = 0.8923619600645907, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 460, train_loss = 0.8884676620364189, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 461, train_loss = 0.890080144006788, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 462, train_loss = 0.8834172319620848, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 463, train_loss = 0.8851819060109847, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 464, train_loss = 0.8819116846025281, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 465, train_loss = 0.8864552529230423, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 466, train_loss = 0.8857658077031374, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 467, train_loss = 0.8862438052892685, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 468, train_loss = 0.8812169202901714, train_acc = 0.9983698183511877\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 469, train_loss = 0.8854703474789858, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 470, train_loss = 0.880702135462343, train_acc = 0.9983698183511877\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 471, train_loss = 0.8846737093590491, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 472, train_loss = 0.8800704671702988, train_acc = 0.9983698183511877\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 473, train_loss = 0.8838999125473492, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 474, train_loss = 0.8795024718456261, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 475, train_loss = 0.8847901693843596, train_acc = 0.9983698183511877\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 476, train_loss = 0.880829737521708, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 477, train_loss = 0.8802928337827325, train_acc = 0.9983698183511877\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 478, train_loss = 0.8832558657340996, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 479, train_loss = 0.8788238866254687, train_acc = 0.9983698183511877\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 480, train_loss = 0.881284546416282, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 481, train_loss = 0.8832598843910091, train_acc = 0.9983698183511877\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 482, train_loss = 0.8846057895570993, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 483, train_loss = 0.8819725279063277, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 484, train_loss = 0.8823758413382166, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 485, train_loss = 0.8823422455861873, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 486, train_loss = 0.8786496985703707, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 487, train_loss = 0.8812486032657034, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 488, train_loss = 0.8805053898431652, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 489, train_loss = 0.8776975193359249, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 490, train_loss = 0.8797584027051926, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 491, train_loss = 0.8814585233740218, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 492, train_loss = 0.8802527386396832, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 493, train_loss = 0.8811411044262059, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 494, train_loss = 0.8792102541774511, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 495, train_loss = 0.8784323674626648, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 496, train_loss = 0.8758274395950139, train_acc = 0.9983698183511877\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 497, train_loss = 0.880013231497287, train_acc = 0.9982533768048439\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 498, train_loss = 0.8786263040565245, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 499, train_loss = 0.8781012479848869, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█████████████▏                                                                 | 5/30 [45:03<3:45:15, 540.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "6th- epoch: 0, train_loss = 343.8085923194885, train_acc = 0.8131113181183046\n",
      "test Acc 0.9017690875232774:\n",
      "6th- epoch: 1, train_loss = 79.5186332364101, train_acc = 0.9248952026082906\n",
      "test Acc 0.9399441340782123:\n",
      "6th- epoch: 2, train_loss = 48.9902276720386, train_acc = 0.9460875640428504\n",
      "test Acc 0.9455307262569832:\n",
      "6th- epoch: 3, train_loss = 34.59926050296053, train_acc = 0.9595947834187238\n",
      "test Acc 0.9487895716945997:\n",
      "6th- epoch: 4, train_loss = 26.104463177500293, train_acc = 0.9675128085700978\n",
      "test Acc 0.952048417132216:\n",
      "6th- epoch: 5, train_loss = 20.383338940679096, train_acc = 0.9729855612482534\n",
      "test Acc 0.9557728119180633:\n",
      "6th- epoch: 6, train_loss = 16.270562102436088, train_acc = 0.9770610153702841\n",
      "test Acc 0.9567039106145251:\n",
      "6th- epoch: 7, train_loss = 13.377219013869762, train_acc = 0.9803213786679087\n",
      "test Acc 0.9567039106145251:\n",
      "6th- epoch: 8, train_loss = 11.244586785673164, train_acc = 0.9835817419655333\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 9, train_loss = 9.566708872676827, train_acc = 0.9856776897997206\n",
      "test Acc 0.9604283054003724:\n",
      "6th- epoch: 10, train_loss = 8.274690564721823, train_acc = 0.9864927806241267\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 11, train_loss = 7.295877434313297, train_acc = 0.9876571960875641\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 12, train_loss = 6.490795524150599, train_acc = 0.9885887284583139\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 13, train_loss = 5.887829436629545, train_acc = 0.989869585468095\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 14, train_loss = 5.425722349435091, train_acc = 0.9905682347461574\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 15, train_loss = 5.0103056455845945, train_acc = 0.9911504424778761\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 16, train_loss = 4.667872389138211, train_acc = 0.9914997671169073\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 17, train_loss = 4.35820111510111, train_acc = 0.992081974848626\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 18, train_loss = 4.086301984905731, train_acc = 0.9925477410340009\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 19, train_loss = 3.8375163177843206, train_acc = 0.9926641825803446\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 20, train_loss = 3.622699463099707, train_acc = 0.9930135072193759\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 21, train_loss = 3.430960046767723, train_acc = 0.9934792734047508\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 22, train_loss = 3.264182223647367, train_acc = 0.993828598043782\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 23, train_loss = 3.112032563716639, train_acc = 0.9940614811364695\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 24, train_loss = 2.991157741576899, train_acc = 0.994294364229157\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 25, train_loss = 2.8840939067304134, train_acc = 0.9947601304145319\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 26, train_loss = 2.7887802571058273, train_acc = 0.9949930135072194\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 27, train_loss = 2.6940854216809385, train_acc = 0.9949930135072194\n",
      "test Acc 0.9646182495344506:\n",
      "6th- epoch: 28, train_loss = 2.6071996713872068, train_acc = 0.9951094550535631\n",
      "test Acc 0.9646182495344506:\n",
      "6th- epoch: 29, train_loss = 2.5172119649942033, train_acc = 0.9956916627852818\n",
      "test Acc 0.9646182495344506:\n",
      "6th- epoch: 30, train_loss = 2.4473409106140025, train_acc = 0.9958081043316255\n",
      "test Acc 0.9646182495344506:\n",
      "6th- epoch: 31, train_loss = 2.37516112747835, train_acc = 0.9956916627852818\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 32, train_loss = 2.3037486101384275, train_acc = 0.9956916627852818\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 33, train_loss = 2.249927680939436, train_acc = 0.9958081043316255\n",
      "test Acc 0.9650837988826816:\n",
      "6th- epoch: 34, train_loss = 2.187274917960167, train_acc = 0.9958081043316255\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 35, train_loss = 2.145576498180162, train_acc = 0.9958081043316255\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 36, train_loss = 2.0925043473835103, train_acc = 0.9958081043316255\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 37, train_loss = 2.042555050284136, train_acc = 0.9958081043316255\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 38, train_loss = 1.9991220335359685, train_acc = 0.9958081043316255\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 39, train_loss = 1.9547237741644494, train_acc = 0.9958081043316255\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 40, train_loss = 1.9146139460499398, train_acc = 0.9959245458779693\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 41, train_loss = 1.8776889381115325, train_acc = 0.9959245458779693\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 42, train_loss = 1.827745359390974, train_acc = 0.9959245458779693\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 43, train_loss = 1.7942679400439374, train_acc = 0.9959245458779693\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 44, train_loss = 1.7619697687332518, train_acc = 0.9959245458779693\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 45, train_loss = 1.726683869957924, train_acc = 0.996040987424313\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 46, train_loss = 1.688621689885622, train_acc = 0.996040987424313\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 47, train_loss = 1.6509008519351482, train_acc = 0.9959245458779693\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 48, train_loss = 1.619219704210991, train_acc = 0.996040987424313\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 49, train_loss = 1.5944327811303083, train_acc = 0.996040987424313\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 50, train_loss = 1.5663457239570562, train_acc = 0.9962738705170004\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 51, train_loss = 1.543488451599842, train_acc = 0.9962738705170004\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 52, train_loss = 1.51929771900177, train_acc = 0.9963903120633442\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 53, train_loss = 1.5102109449508134, train_acc = 0.9963903120633442\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 54, train_loss = 1.4873870337905828, train_acc = 0.996506753609688\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 55, train_loss = 1.469221394509077, train_acc = 0.996506753609688\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 56, train_loss = 1.4586699356732424, train_acc = 0.9966231951560317\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 57, train_loss = 1.4404349041578826, train_acc = 0.9967396367023754\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 58, train_loss = 1.430104629456764, train_acc = 0.9967396367023754\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 59, train_loss = 1.4168075025081635, train_acc = 0.9967396367023754\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 60, train_loss = 1.4093564463255461, train_acc = 0.9967396367023754\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 61, train_loss = 1.39229092374444, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 62, train_loss = 1.385911082237726, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 63, train_loss = 1.3761994205415249, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 64, train_loss = 1.3692938362655696, train_acc = 0.9967396367023754\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 65, train_loss = 1.3550654202699661, train_acc = 0.9967396367023754\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 66, train_loss = 1.3513291366398335, train_acc = 0.9967396367023754\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 67, train_loss = 1.3417154774069786, train_acc = 0.9967396367023754\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 68, train_loss = 1.3321356462838594, train_acc = 0.9967396367023754\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 69, train_loss = 1.32336569702602, train_acc = 0.9967396367023754\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 70, train_loss = 1.3177460258302744, train_acc = 0.9967396367023754\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 71, train_loss = 1.3111607109603938, train_acc = 0.9967396367023754\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 72, train_loss = 1.3040500158967916, train_acc = 0.9967396367023754\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 73, train_loss = 1.2949142369034234, train_acc = 0.9967396367023754\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 74, train_loss = 1.2915706535277423, train_acc = 0.9967396367023754\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 75, train_loss = 1.2813916566374246, train_acc = 0.9967396367023754\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 76, train_loss = 1.280249302595621, train_acc = 0.9967396367023754\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 77, train_loss = 1.2697897578182165, train_acc = 0.9968560782487191\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 78, train_loss = 1.2648242811410455, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 79, train_loss = 1.2626876247522887, train_acc = 0.9967396367023754\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 80, train_loss = 1.2564497292041779, train_acc = 0.9968560782487191\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 81, train_loss = 1.2468172684311867, train_acc = 0.9968560782487191\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 82, train_loss = 1.2465449410228757, train_acc = 0.9968560782487191\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 83, train_loss = 1.238093189895153, train_acc = 0.9968560782487191\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 84, train_loss = 1.2331745934934588, train_acc = 0.9968560782487191\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 85, train_loss = 1.2263087518513203, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 86, train_loss = 1.2211904649884673, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 87, train_loss = 1.2171686440706253, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 88, train_loss = 1.2152199931442738, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 89, train_loss = 1.2113176733255386, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 90, train_loss = 1.2063740827143192, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 91, train_loss = 1.1999483021645574, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 92, train_loss = 1.1941117184906034, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 93, train_loss = 1.1901747633964987, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 94, train_loss = 1.18858702480793, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 95, train_loss = 1.1826710229070159, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 96, train_loss = 1.178451885774848, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 97, train_loss = 1.1740144553332357, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 98, train_loss = 1.1716390997171402, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 99, train_loss = 1.1670389572827844, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 100, train_loss = 1.1638241174368886, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 101, train_loss = 1.1602496281266212, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 102, train_loss = 1.1566959296615096, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 103, train_loss = 1.152734758958104, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 104, train_loss = 1.14709089200187, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 105, train_loss = 1.1447250892670127, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 106, train_loss = 1.1422183985559968, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 107, train_loss = 1.1374519479722949, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 108, train_loss = 1.134193878620863, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 109, train_loss = 1.1314565228967695, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 110, train_loss = 1.127519715577364, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 111, train_loss = 1.1255644957273034, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 112, train_loss = 1.1214066632092, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 113, train_loss = 1.1205772906541824, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 114, train_loss = 1.1153281442821026, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 115, train_loss = 1.1135684922337532, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 116, train_loss = 1.1103165062813787, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 117, train_loss = 1.1048147392721148, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 118, train_loss = 1.1043303745536832, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 119, train_loss = 1.100007654473302, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 120, train_loss = 1.0984424389898777, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 121, train_loss = 1.09651231020689, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 122, train_loss = 1.091830961406231, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 123, train_loss = 1.0889915352017852, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 124, train_loss = 1.0866574185638456, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 125, train_loss = 1.0853973242192296, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 126, train_loss = 1.0809372079820605, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 127, train_loss = 1.0776253715157509, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 128, train_loss = 1.0794511983767734, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 129, train_loss = 1.0761299915611744, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 130, train_loss = 1.0725147190241842, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 131, train_loss = 1.0713938276021508, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 132, train_loss = 1.0663186224774108, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 133, train_loss = 1.0643836868330254, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 134, train_loss = 1.0616656852289452, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 135, train_loss = 1.0631968801244511, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 136, train_loss = 1.0601970056668506, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 137, train_loss = 1.056216310709715, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 138, train_loss = 1.0555149180217995, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 139, train_loss = 1.0551151906474843, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 140, train_loss = 1.049057466290833, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 141, train_loss = 1.0459882331415429, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 142, train_loss = 1.0433570556342602, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 143, train_loss = 1.04088592404878, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 144, train_loss = 1.0382825533524738, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 145, train_loss = 1.0369928069412708, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 146, train_loss = 1.0353255098088994, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 147, train_loss = 1.0343339753671899, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 148, train_loss = 1.0315685458481312, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 149, train_loss = 1.0307981769219623, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 150, train_loss = 1.030801619090198, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 151, train_loss = 1.0292945615947247, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 152, train_loss = 1.0258636760190711, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 153, train_loss = 1.0256755227819667, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 154, train_loss = 1.0235648999587283, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 155, train_loss = 1.0212245720103965, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 156, train_loss = 1.0216667006388889, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 157, train_loss = 1.0193869893773808, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 158, train_loss = 1.0175558502451167, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 159, train_loss = 1.0165959907099023, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 160, train_loss = 1.0132853351533413, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 161, train_loss = 1.0124063019975438, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 162, train_loss = 1.0106758835390792, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 163, train_loss = 1.0117794734760537, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 164, train_loss = 1.0080844201147556, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 165, train_loss = 1.0097370818257332, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 166, train_loss = 1.0057459461168037, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 167, train_loss = 1.003984538219811, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 168, train_loss = 1.0034569712952361, train_acc = 0.9973218444340941\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 169, train_loss = 1.0022374441250577, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 170, train_loss = 1.0034869437440648, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 171, train_loss = 0.9994913451373577, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 172, train_loss = 0.9979458985253586, train_acc = 0.9973218444340941\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 173, train_loss = 0.9963086967691197, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 174, train_loss = 0.9993845547214733, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 175, train_loss = 0.9943658635020256, train_acc = 0.9973218444340941\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 176, train_loss = 0.9921896060332074, train_acc = 0.9973218444340941\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 177, train_loss = 0.9932950971051469, train_acc = 0.9973218444340941\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 178, train_loss = 0.9903692925945506, train_acc = 0.9973218444340941\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 179, train_loss = 0.9925452818497433, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 180, train_loss = 0.9877462213262334, train_acc = 0.9973218444340941\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 181, train_loss = 0.9856322991327033, train_acc = 0.9973218444340941\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 182, train_loss = 0.986641356103064, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 183, train_loss = 0.9870126532987342, train_acc = 0.9973218444340941\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 184, train_loss = 0.984568040817976, train_acc = 0.9973218444340941\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 185, train_loss = 0.9835793226957321, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 186, train_loss = 0.9827257581055164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 187, train_loss = 0.9813298421577201, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 188, train_loss = 0.9807566739618778, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 189, train_loss = 0.9789835102856159, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 190, train_loss = 0.9776450830177055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 191, train_loss = 0.9782589537426247, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 192, train_loss = 0.9741064893678413, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 193, train_loss = 0.9778937734663486, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 194, train_loss = 0.975028607994318, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 195, train_loss = 0.9714536691681133, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 196, train_loss = 0.9736990717574372, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 197, train_loss = 0.9727811776101589, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 198, train_loss = 0.9718628711998463, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 199, train_loss = 0.9697782533839927, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 200, train_loss = 0.9691214983686223, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 201, train_loss = 0.9689663934186683, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 202, train_loss = 0.9634208269417286, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 203, train_loss = 0.9630039533003583, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 204, train_loss = 0.9643334349020733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 205, train_loss = 0.9635302138849511, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 206, train_loss = 0.9595315704755194, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 207, train_loss = 0.9623457131310715, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 208, train_loss = 0.9620707854628563, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 209, train_loss = 0.9597714617848396, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 210, train_loss = 0.9564056483395689, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 211, train_loss = 0.9560997908301943, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 212, train_loss = 0.9575235036500089, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 213, train_loss = 0.9555327755697363, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 214, train_loss = 0.9547923716418154, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 215, train_loss = 0.9544869363307953, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 216, train_loss = 0.9528598263859749, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 217, train_loss = 0.9551262942441099, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 218, train_loss = 0.9501399186738126, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 219, train_loss = 0.9533502260856039, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 220, train_loss = 0.9529701347164519, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 221, train_loss = 0.9523347318172455, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 222, train_loss = 0.9479419067502022, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 223, train_loss = 0.9518586844205856, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 224, train_loss = 0.9476837255060673, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 225, train_loss = 0.9483073788396723, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 226, train_loss = 0.9486022479832172, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 227, train_loss = 0.9477365724742413, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 228, train_loss = 0.9451219936199777, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 229, train_loss = 0.946318294852972, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 230, train_loss = 0.942568801343441, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 231, train_loss = 0.9444823637604713, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 232, train_loss = 0.9444804141930945, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 233, train_loss = 0.9417754734568007, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 234, train_loss = 0.9430291329808824, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 235, train_loss = 0.9407151639461517, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 236, train_loss = 0.9398777311034792, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 237, train_loss = 0.9389633685350418, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 238, train_loss = 0.9360462240874767, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 239, train_loss = 0.942773524671793, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 240, train_loss = 0.9368857430927164, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 241, train_loss = 0.9373077414929867, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 242, train_loss = 0.9360397979617119, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 243, train_loss = 0.9375989139080048, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 244, train_loss = 0.9356901546307199, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 245, train_loss = 0.9343206820376508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 246, train_loss = 0.9346221859268553, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 247, train_loss = 0.9318137541413307, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 248, train_loss = 0.9347333262376196, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 249, train_loss = 0.93250709151107, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 250, train_loss = 0.9353042443581217, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 251, train_loss = 0.9301700343676202, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 252, train_loss = 0.9310666595883959, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 253, train_loss = 0.9321950264275074, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 254, train_loss = 0.9296766047664278, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 255, train_loss = 0.9322872757911682, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 256, train_loss = 0.9267198207489855, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 257, train_loss = 0.9284773121289618, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 258, train_loss = 0.9277650974690914, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 259, train_loss = 0.9301402320452326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 260, train_loss = 0.9241080867759592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 261, train_loss = 0.921831801533699, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 262, train_loss = 0.9263019599020481, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 263, train_loss = 0.9245498515665531, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 264, train_loss = 0.9256732799112797, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 265, train_loss = 0.9258701006583578, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 266, train_loss = 0.9262853848449595, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 267, train_loss = 0.9214218072593212, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 268, train_loss = 0.9232732293494337, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 269, train_loss = 0.9260612453035719, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 270, train_loss = 0.9188111374787695, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 271, train_loss = 0.9220803653188341, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 272, train_loss = 0.9237311631441116, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 273, train_loss = 0.9252963550388813, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 274, train_loss = 0.9182818358131044, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 275, train_loss = 0.9159911572933197, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 276, train_loss = 0.9210339474193461, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 277, train_loss = 0.9221810574345, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 278, train_loss = 0.9182367101311684, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 279, train_loss = 0.9186539116017229, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 280, train_loss = 0.917670259874285, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 281, train_loss = 0.9154684667773836, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 282, train_loss = 0.9174382574856281, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 283, train_loss = 0.9133173488080502, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 284, train_loss = 0.9154139906167984, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 285, train_loss = 0.9117684066295624, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 286, train_loss = 0.9151632500179403, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 287, train_loss = 0.9141403138637543, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 288, train_loss = 0.9114248529076576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 289, train_loss = 0.9079344583042257, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 290, train_loss = 0.9113170715681917, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 291, train_loss = 0.9110282883048058, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 292, train_loss = 0.9109138237945444, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 293, train_loss = 0.9108216005079157, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 294, train_loss = 0.906793899834156, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 295, train_loss = 0.9086810996122949, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 296, train_loss = 0.909797956544935, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 297, train_loss = 0.9117353595793247, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 298, train_loss = 0.9102530181407928, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 299, train_loss = 0.9101403305940039, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 300, train_loss = 0.9118610533587344, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 301, train_loss = 0.9103522896766663, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 302, train_loss = 0.9061055493839376, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 303, train_loss = 0.906864371150732, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 304, train_loss = 0.911802127957344, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 305, train_loss = 0.9059234199412458, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 306, train_loss = 0.9057307913899422, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 307, train_loss = 0.9062406271696091, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 308, train_loss = 0.906747271616041, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 309, train_loss = 0.904773872345686, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 310, train_loss = 0.9040388849862211, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 311, train_loss = 0.9035507043190592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 312, train_loss = 0.905503203470289, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 313, train_loss = 0.9047903244681947, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 314, train_loss = 0.9073295369744301, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 315, train_loss = 0.9035743425301916, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 316, train_loss = 0.9055307942144282, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 317, train_loss = 0.9053046790249937, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 318, train_loss = 0.902744684368372, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 319, train_loss = 0.899765362340986, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 320, train_loss = 0.896901107083977, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 321, train_loss = 0.897172732900799, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 322, train_loss = 0.9004657417535782, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 323, train_loss = 0.9016911722719669, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 324, train_loss = 0.9003219020851247, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 325, train_loss = 0.9000506388656504, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 326, train_loss = 0.8979726433753967, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 327, train_loss = 0.9017144565768831, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 328, train_loss = 0.8994590540714853, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 329, train_loss = 0.8982901945710182, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 330, train_loss = 0.895664860803663, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 331, train_loss = 0.8954761972017877, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 332, train_loss = 0.8927414640784264, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 333, train_loss = 0.8975030494220846, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 334, train_loss = 0.8937137449793227, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 335, train_loss = 0.8920657299458981, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 336, train_loss = 0.8917211542539007, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 337, train_loss = 0.8947468474507332, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 338, train_loss = 0.8946685356386297, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 339, train_loss = 0.8965176343917847, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 340, train_loss = 0.8947943523526192, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 341, train_loss = 0.8958457186818123, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 342, train_loss = 0.894880685955286, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 343, train_loss = 0.8961528738327615, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 344, train_loss = 0.8926327166445844, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 345, train_loss = 0.8934362630061514, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 346, train_loss = 0.8927683296315081, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 347, train_loss = 0.8943107277154922, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 348, train_loss = 0.892043257754267, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 349, train_loss = 0.8935180331282027, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 350, train_loss = 0.8918701782822609, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 351, train_loss = 0.8937033029906161, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 352, train_loss = 0.8910104210190184, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 353, train_loss = 0.8912782023362524, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 354, train_loss = 0.8902819727845781, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 355, train_loss = 0.8871318909041292, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 356, train_loss = 0.8861012856177695, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 357, train_loss = 0.8909100741147995, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 358, train_loss = 0.8883179351687431, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 359, train_loss = 0.8907584063708782, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 360, train_loss = 0.8886937747411139, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 361, train_loss = 0.8901279742531187, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 362, train_loss = 0.8855468692891009, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 363, train_loss = 0.8894573077559471, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 364, train_loss = 0.8858483893163793, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 365, train_loss = 0.8898291649929888, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 366, train_loss = 0.8871827771254175, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 367, train_loss = 0.8856757332869165, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 368, train_loss = 0.8870423597581976, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 369, train_loss = 0.8860287951938517, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 370, train_loss = 0.886244089651882, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 371, train_loss = 0.8833088117353327, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 372, train_loss = 0.8853576903529756, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 373, train_loss = 0.886179671932041, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 374, train_loss = 0.883821826428175, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 375, train_loss = 0.8857361450791359, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 376, train_loss = 0.8875800594687462, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 377, train_loss = 0.8844883553683758, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 378, train_loss = 0.882327181596338, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 379, train_loss = 0.8848167558498972, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 380, train_loss = 0.8830132931470871, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 381, train_loss = 0.884706873446703, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 382, train_loss = 0.8842124491930008, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 383, train_loss = 0.884994875639677, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 384, train_loss = 0.8840030431747437, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 385, train_loss = 0.8819418214261532, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 386, train_loss = 0.8824971243739128, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 387, train_loss = 0.882020307082712, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 388, train_loss = 0.8848377230278857, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 389, train_loss = 0.8819572565444105, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 390, train_loss = 0.8833635623268492, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 391, train_loss = 0.8809928546361334, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 392, train_loss = 0.8798841312527657, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 393, train_loss = 0.8810028483458154, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 394, train_loss = 0.8803753294050694, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 395, train_loss = 0.8802101537585258, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 396, train_loss = 0.8790554317347414, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 397, train_loss = 0.8790405802428722, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 398, train_loss = 0.8800248553343408, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 399, train_loss = 0.8784359047822363, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 400, train_loss = 0.8790932285301096, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 401, train_loss = 0.8804253923408396, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 402, train_loss = 0.8786222711205482, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 403, train_loss = 0.8785195673517592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 404, train_loss = 0.8778231404721737, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 405, train_loss = 0.8782183018811338, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 406, train_loss = 0.8800134348384745, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 407, train_loss = 0.8758177223317034, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 408, train_loss = 0.8763987943530083, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 409, train_loss = 0.8748369303830259, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 410, train_loss = 0.8760721112303145, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 411, train_loss = 0.8771193188913458, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 412, train_loss = 0.8739113646261103, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 413, train_loss = 0.8760423262901895, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 414, train_loss = 0.87568049877882, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 415, train_loss = 0.875589902203501, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 416, train_loss = 0.8734653095416434, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 417, train_loss = 0.8739320859313011, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 418, train_loss = 0.8751242992766493, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 419, train_loss = 0.8778049945831299, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 420, train_loss = 0.8702519424259663, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 421, train_loss = 0.8734990420452959, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 422, train_loss = 0.8745754944793589, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 423, train_loss = 0.8733444375284307, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 424, train_loss = 0.8742113336920738, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 425, train_loss = 0.8722084363289468, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 426, train_loss = 0.8759472506753809, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 427, train_loss = 0.8729046620428562, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 428, train_loss = 0.8733022858687036, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 429, train_loss = 0.8782696301750548, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 430, train_loss = 0.8735519225410826, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 431, train_loss = 0.8719812954477675, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 432, train_loss = 0.8750177485235326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 433, train_loss = 0.8695593476295471, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 434, train_loss = 0.8722048575691588, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 435, train_loss = 0.8702237717807293, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 436, train_loss = 0.8711102493107319, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 437, train_loss = 0.8726008248831931, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 438, train_loss = 0.8740971299521334, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 439, train_loss = 0.8716284272577468, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 440, train_loss = 0.8720611905064288, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 441, train_loss = 0.8706788904964924, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 442, train_loss = 0.8735890189800557, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 443, train_loss = 0.8704502607379254, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 444, train_loss = 0.8678726193811599, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 445, train_loss = 0.8705909786112898, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 446, train_loss = 0.8723848611116409, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 447, train_loss = 0.8724413998425007, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 448, train_loss = 0.869951801996649, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 449, train_loss = 0.8717111994828883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 450, train_loss = 0.8649033134188358, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 451, train_loss = 0.8614567220211029, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 452, train_loss = 0.8668369576334953, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 453, train_loss = 0.8722446622941789, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 454, train_loss = 0.8679083858933154, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 455, train_loss = 0.8696601813044254, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 456, train_loss = 0.8671787182483968, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 457, train_loss = 0.8650031027700607, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 458, train_loss = 0.8675738970432576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 459, train_loss = 0.8701806589961052, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 460, train_loss = 0.86381384482047, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 461, train_loss = 0.8621542416512966, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 462, train_loss = 0.8701980747282505, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 463, train_loss = 0.8679241525624093, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 464, train_loss = 0.8690741645787057, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 465, train_loss = 0.8704561566319171, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 466, train_loss = 0.8661282534394559, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 467, train_loss = 0.8675155490636826, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 468, train_loss = 0.8676444378997985, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 469, train_loss = 0.8664119839668274, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 470, train_loss = 0.866814040889949, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 471, train_loss = 0.8678735209014121, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 472, train_loss = 0.8644891381263733, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 473, train_loss = 0.8636706893648807, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 474, train_loss = 0.8631909775231179, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 475, train_loss = 0.8641981817781925, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 476, train_loss = 0.8665474864337739, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 477, train_loss = 0.8664410176370438, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 478, train_loss = 0.8684631983433064, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 479, train_loss = 0.864706984410077, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 480, train_loss = 0.8665351644158363, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 481, train_loss = 0.8629478377606574, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 482, train_loss = 0.8643178902566433, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 483, train_loss = 0.8654099168870744, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 484, train_loss = 0.8670661983396712, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 485, train_loss = 0.8657896667718887, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 486, train_loss = 0.866532697031289, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 487, train_loss = 0.8624994407091435, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 488, train_loss = 0.8649056081976596, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 489, train_loss = 0.862304055443019, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 490, train_loss = 0.8621116019785404, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 491, train_loss = 0.864549001058549, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 492, train_loss = 0.8642556158210937, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 493, train_loss = 0.8620823596920673, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 494, train_loss = 0.8654677594695386, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 495, train_loss = 0.8645276303086575, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 496, train_loss = 0.8633731566369534, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 497, train_loss = 0.8671627094354335, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 498, train_loss = 0.8641237566862401, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 499, train_loss = 0.8629207909107208, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|███████████████▊                                                               | 6/30 [54:04<3:36:17, 540.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "7th- epoch: 0, train_loss = 322.52209386229515, train_acc = 0.8187005123428039\n",
      "test Acc 0.9106145251396648:\n",
      "7th- epoch: 1, train_loss = 77.69618588499725, train_acc = 0.9271075919888216\n",
      "test Acc 0.9376163873370578:\n",
      "7th- epoch: 2, train_loss = 48.4510141313076, train_acc = 0.9487657196087564\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 3, train_loss = 34.3898832174018, train_acc = 0.9587796925943176\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 4, train_loss = 25.26498518139124, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "7th- epoch: 5, train_loss = 19.721506101079285, train_acc = 0.971821145784816\n",
      "test Acc 0.9548417132216015:\n",
      "7th- epoch: 6, train_loss = 15.752939885482192, train_acc = 0.976245924545878\n",
      "test Acc 0.957169459962756:\n",
      "7th- epoch: 7, train_loss = 12.799455061554909, train_acc = 0.97973917093619\n",
      "test Acc 0.9581005586592178:\n",
      "7th- epoch: 8, train_loss = 10.559674985706806, train_acc = 0.9814857941313461\n",
      "test Acc 0.9594972067039106:\n",
      "7th- epoch: 9, train_loss = 8.818997356109321, train_acc = 0.9846297158826269\n",
      "test Acc 0.9594972067039106:\n",
      "7th- epoch: 10, train_loss = 7.543743862770498, train_acc = 0.9871914299021891\n",
      "test Acc 0.9613594040968343:\n",
      "7th- epoch: 11, train_loss = 6.553464411292225, train_acc = 0.9884722869119702\n",
      "test Acc 0.9613594040968343:\n",
      "7th- epoch: 12, train_loss = 5.802203910425305, train_acc = 0.9899860270144387\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 13, train_loss = 5.200603207107633, train_acc = 0.9910340009315324\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 14, train_loss = 4.730477244127542, train_acc = 0.9914997671169073\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 15, train_loss = 4.332533597014844, train_acc = 0.9919655333022822\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 16, train_loss = 3.9917298769578338, train_acc = 0.9926641825803446\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 17, train_loss = 3.681702532339841, train_acc = 0.9931299487657196\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 18, train_loss = 3.427981457673013, train_acc = 0.9934792734047508\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 19, train_loss = 3.216617017518729, train_acc = 0.993828598043782\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 20, train_loss = 3.002057950012386, train_acc = 0.994294364229157\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 21, train_loss = 2.838480473263189, train_acc = 0.9945272473218444\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 22, train_loss = 2.670238309772685, train_acc = 0.9946436888681882\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 23, train_loss = 2.522503375541419, train_acc = 0.9947601304145319\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 24, train_loss = 2.400598839856684, train_acc = 0.9953423381462506\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 25, train_loss = 2.3261542641557753, train_acc = 0.9954587796925943\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 26, train_loss = 2.2402726800646633, train_acc = 0.9954587796925943\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 27, train_loss = 2.159837179700844, train_acc = 0.9954587796925943\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 28, train_loss = 2.0908645518356934, train_acc = 0.995575221238938\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 29, train_loss = 2.044603167218156, train_acc = 0.995575221238938\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 30, train_loss = 1.9929432376520708, train_acc = 0.9958081043316255\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 31, train_loss = 1.9336953575257212, train_acc = 0.9958081043316255\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 32, train_loss = 1.8931685709394515, train_acc = 0.9958081043316255\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 33, train_loss = 1.8409131512744352, train_acc = 0.9958081043316255\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 34, train_loss = 1.8086198813980445, train_acc = 0.9958081043316255\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 35, train_loss = 1.7716550905024633, train_acc = 0.9959245458779693\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 36, train_loss = 1.7445121213095263, train_acc = 0.9962738705170004\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 37, train_loss = 1.7119523454457521, train_acc = 0.9962738705170004\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 38, train_loss = 1.6883909276220948, train_acc = 0.9962738705170004\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 39, train_loss = 1.6709743711398914, train_acc = 0.9962738705170004\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 40, train_loss = 1.6425549117848277, train_acc = 0.9963903120633442\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 41, train_loss = 1.6222303784452379, train_acc = 0.9962738705170004\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 42, train_loss = 1.6112736075883731, train_acc = 0.9962738705170004\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 43, train_loss = 1.5870201172074303, train_acc = 0.9962738705170004\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 44, train_loss = 1.57343569281511, train_acc = 0.9963903120633442\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 45, train_loss = 1.5538564398884773, train_acc = 0.9966231951560317\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 46, train_loss = 1.5464079087250866, train_acc = 0.9963903120633442\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 47, train_loss = 1.528044391889125, train_acc = 0.996506753609688\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 48, train_loss = 1.5177322721574455, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 49, train_loss = 1.4971206132904626, train_acc = 0.9966231951560317\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 50, train_loss = 1.4893401586450636, train_acc = 0.996506753609688\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 51, train_loss = 1.4738363358774222, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 52, train_loss = 1.4624353774706833, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 53, train_loss = 1.4486214785720222, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 54, train_loss = 1.4315505643025972, train_acc = 0.9967396367023754\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 55, train_loss = 1.4268049558158964, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 56, train_loss = 1.4180421195924282, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 57, train_loss = 1.406220892968122, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 58, train_loss = 1.3987734786351211, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 59, train_loss = 1.3847380503430031, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 60, train_loss = 1.374884322809521, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 61, train_loss = 1.3659422166529112, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 62, train_loss = 1.3579650601022877, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 63, train_loss = 1.347964602697175, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 64, train_loss = 1.3436225790064782, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 65, train_loss = 1.337455867382232, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 66, train_loss = 1.3270551930763759, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 67, train_loss = 1.320278990024235, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 68, train_loss = 1.3141480219201185, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 69, train_loss = 1.3133135871612467, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 70, train_loss = 1.297677396738436, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 71, train_loss = 1.295782487199176, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 72, train_loss = 1.290349249728024, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 73, train_loss = 1.2873377811629325, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 74, train_loss = 1.2741549736820161, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 75, train_loss = 1.2746611916809343, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 76, train_loss = 1.2720897535327822, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 77, train_loss = 1.2599568192381412, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 78, train_loss = 1.2603700440959074, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 79, train_loss = 1.2592832560185343, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 80, train_loss = 1.2468358394689858, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 81, train_loss = 1.2472752645553555, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 82, train_loss = 1.2450984126480762, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 83, train_loss = 1.2349866871954873, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 84, train_loss = 1.234349054604536, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 85, train_loss = 1.2361047443409916, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 86, train_loss = 1.2230354752100538, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 87, train_loss = 1.2212641365767922, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 88, train_loss = 1.2171495782095008, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 89, train_loss = 1.2168162503221538, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 90, train_loss = 1.2154141998616979, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 91, train_loss = 1.209314300416736, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 92, train_loss = 1.2079842427920084, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 93, train_loss = 1.2093057296297047, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 94, train_loss = 1.1970825921744108, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 95, train_loss = 1.1955599604407325, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 96, train_loss = 1.1917798969370779, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 97, train_loss = 1.1973258223442826, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 98, train_loss = 1.1874025214929134, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 99, train_loss = 1.1827087154670153, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 100, train_loss = 1.1814125069358852, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 101, train_loss = 1.1811507497623097, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 102, train_loss = 1.178152758278884, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 103, train_loss = 1.1756379634898622, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 104, train_loss = 1.1730323410301935, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 105, train_loss = 1.1784041811188217, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 106, train_loss = 1.1684755256574135, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 107, train_loss = 1.165974712726893, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 108, train_loss = 1.171032362501137, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 109, train_loss = 1.1599871015932877, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 110, train_loss = 1.1598551057104487, train_acc = 0.9972054028877504\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 111, train_loss = 1.158286058693193, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 112, train_loss = 1.1612761352444068, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 113, train_loss = 1.1548996421333868, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 114, train_loss = 1.15100130616338, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 115, train_loss = 1.1493077928025741, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 116, train_loss = 1.1543966875469778, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 117, train_loss = 1.1464512781531084, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 118, train_loss = 1.1437151753343642, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 119, train_loss = 1.1424847628513817, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 120, train_loss = 1.1467405951116234, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 121, train_loss = 1.1398714863753412, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 122, train_loss = 1.1356073889473919, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 123, train_loss = 1.1358813148981426, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 124, train_loss = 1.131414638570277, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 125, train_loss = 1.1321470668481197, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 126, train_loss = 1.1284988501283806, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 127, train_loss = 1.1280521960870828, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 128, train_loss = 1.1261172063823324, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 129, train_loss = 1.1244621768419165, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 130, train_loss = 1.1232993558514863, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 131, train_loss = 1.1213096841966035, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 132, train_loss = 1.120913970094989, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 133, train_loss = 1.1177350475190906, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 134, train_loss = 1.1170358191011474, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 135, train_loss = 1.115141834525275, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 136, train_loss = 1.1139251471759053, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 137, train_loss = 1.1119050305132987, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 138, train_loss = 1.1114786905236542, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 139, train_loss = 1.1097993544972269, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 140, train_loss = 1.107040200920892, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 141, train_loss = 1.107429516967386, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 142, train_loss = 1.1047785920090973, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 143, train_loss = 1.1042270961479517, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 144, train_loss = 1.1016315368469805, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 145, train_loss = 1.0997873343731044, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 146, train_loss = 1.0989971743692877, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 147, train_loss = 1.097682975771022, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 148, train_loss = 1.0978278701659292, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 149, train_loss = 1.0956422119197669, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 150, train_loss = 1.0956277617515298, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 151, train_loss = 1.0933560452685924, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 152, train_loss = 1.0917531355516985, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 153, train_loss = 1.089451887877658, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 154, train_loss = 1.087976461436483, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 155, train_loss = 1.0873211537254974, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 156, train_loss = 1.0864377079997212, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 157, train_loss = 1.0841085548745468, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 158, train_loss = 1.0848777240607888, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 159, train_loss = 1.0828879546170356, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 160, train_loss = 1.082130980095826, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 161, train_loss = 1.0808036633534357, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 162, train_loss = 1.078899248270318, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 163, train_loss = 1.0783880542730913, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 164, train_loss = 1.0761390799161745, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 165, train_loss = 1.075180413085036, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 166, train_loss = 1.0738444196758792, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 167, train_loss = 1.0732223184313625, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 168, train_loss = 1.0719748539850116, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 169, train_loss = 1.0706348571256967, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 170, train_loss = 1.0699550433346303, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 171, train_loss = 1.0693536717881216, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 172, train_loss = 1.0671325096627697, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 173, train_loss = 1.0666641230491223, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 174, train_loss = 1.0649088268837659, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 175, train_loss = 1.064240754887578, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 176, train_loss = 1.0646283805399435, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 177, train_loss = 1.0633625963964732, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 178, train_loss = 1.0613508099195315, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 179, train_loss = 1.0600753029139014, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 180, train_loss = 1.060233074313146, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 181, train_loss = 1.0589674763614312, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 182, train_loss = 1.0570249709999189, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 183, train_loss = 1.0559343703789636, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 184, train_loss = 1.0555101247009588, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 185, train_loss = 1.0538412684836658, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 186, train_loss = 1.0530995222070487, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 187, train_loss = 1.0521268682350637, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 188, train_loss = 1.0512678236700594, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 189, train_loss = 1.051339216181077, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 190, train_loss = 1.0499473353411304, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 191, train_loss = 1.047911384186591, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 192, train_loss = 1.047040437508258, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 193, train_loss = 1.046684143904713, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 194, train_loss = 1.0457338866544887, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 195, train_loss = 1.0446030542516382, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 196, train_loss = 1.0433793523552595, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 197, train_loss = 1.0426803258742439, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 198, train_loss = 1.0420817902049748, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 199, train_loss = 1.0404290065780515, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 200, train_loss = 1.0404020264395513, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 201, train_loss = 1.0389827415929176, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 202, train_loss = 1.037409732954984, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 203, train_loss = 1.0374458290971234, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 204, train_loss = 1.0363384269512608, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 205, train_loss = 1.0353118887069286, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 206, train_loss = 1.034381743207632, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 207, train_loss = 1.0344763203975162, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 208, train_loss = 1.0327170210657641, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 209, train_loss = 1.0315917758271098, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 210, train_loss = 1.0310330491047353, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 211, train_loss = 1.0296604313189164, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 212, train_loss = 1.029395858407952, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 213, train_loss = 1.028342172583507, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 214, train_loss = 1.0276655280395062, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 215, train_loss = 1.0259641819866374, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 216, train_loss = 1.026409106249048, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 217, train_loss = 1.0256397594348527, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 218, train_loss = 1.0240335423513898, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 219, train_loss = 1.0233613254167722, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 220, train_loss = 1.021667089604307, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 221, train_loss = 1.0224610083023435, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 222, train_loss = 1.0205044571775943, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 223, train_loss = 1.0200456611564732, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 224, train_loss = 1.0193825923706754, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 225, train_loss = 1.0181656439090148, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 226, train_loss = 1.017882415362692, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 227, train_loss = 1.0177877496826113, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 228, train_loss = 1.0156582355630235, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 229, train_loss = 1.0155915507712052, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 230, train_loss = 1.0146672204937204, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 231, train_loss = 1.0141890126178623, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 232, train_loss = 1.0134772673482075, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 233, train_loss = 1.0121245754053234, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 234, train_loss = 1.0118228181599989, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 235, train_loss = 1.0108027661553933, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 236, train_loss = 1.0094182935208664, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 237, train_loss = 1.0096223346190527, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 238, train_loss = 1.0084359570973902, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 239, train_loss = 1.008032045327127, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 240, train_loss = 1.007405820848362, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 241, train_loss = 1.006621694425121, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 242, train_loss = 1.0057640317827463, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 243, train_loss = 1.0054688513409928, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 244, train_loss = 1.004347718473582, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 245, train_loss = 1.0035034196116612, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 246, train_loss = 1.0027669622431858, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 247, train_loss = 1.00177281039214, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 248, train_loss = 1.0023428821805282, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 249, train_loss = 1.000552579840587, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 250, train_loss = 0.9993273618165404, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 251, train_loss = 1.0000297445003525, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 252, train_loss = 0.9993804516270757, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 253, train_loss = 0.9979542633518577, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 254, train_loss = 0.9984848864842206, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 255, train_loss = 0.9969533996190876, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 256, train_loss = 0.9957972836346016, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 257, train_loss = 0.9960160658229142, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 258, train_loss = 0.9936306615491048, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 259, train_loss = 0.9949482729789452, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 260, train_loss = 0.9936877576037659, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 261, train_loss = 0.9928416630718857, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 262, train_loss = 0.9918598793447018, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 263, train_loss = 0.9919748400934623, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 264, train_loss = 0.9915722012519836, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 265, train_loss = 0.9907284507862641, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 266, train_loss = 0.9900947904679924, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 267, train_loss = 0.9896220945156529, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 268, train_loss = 0.9880866610910743, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 269, train_loss = 0.9890417977367179, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 270, train_loss = 0.9879185378886177, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 271, train_loss = 0.9868023806120618, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 272, train_loss = 0.9870241169483052, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 273, train_loss = 0.983997281640768, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 274, train_loss = 0.9849482026547776, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 275, train_loss = 0.984694100683555, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 276, train_loss = 0.9841996640898287, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 277, train_loss = 0.9839081102982163, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 278, train_loss = 0.9824295868966146, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 279, train_loss = 0.9826568512580707, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 280, train_loss = 0.9812475289218128, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 281, train_loss = 0.9823500909842551, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 282, train_loss = 0.9807748142629862, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 283, train_loss = 0.9791951899751439, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 284, train_loss = 0.9796080707237707, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 285, train_loss = 0.9789676647633314, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 286, train_loss = 0.9784323045387282, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 287, train_loss = 0.977164998803346, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 288, train_loss = 0.9779938283973024, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 289, train_loss = 0.9758438941425993, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 290, train_loss = 0.9763525457456126, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 291, train_loss = 0.9761544774883077, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 292, train_loss = 0.9753759281375096, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 293, train_loss = 0.9727368725762062, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 294, train_loss = 0.973286081723927, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 295, train_loss = 0.9733435378111608, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 296, train_loss = 0.9724403644613631, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 297, train_loss = 0.9725954926907434, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 298, train_loss = 0.9710384743921168, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 299, train_loss = 0.970569837216317, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 300, train_loss = 0.9706477659456141, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 301, train_loss = 0.9708834236189432, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 302, train_loss = 0.9682389583140321, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 303, train_loss = 0.9685096430293925, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 304, train_loss = 0.9678674299902923, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 305, train_loss = 0.9683531878217764, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 306, train_loss = 0.9658481287769973, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 307, train_loss = 0.9687073101922579, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 308, train_loss = 0.9660352816172235, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 309, train_loss = 0.9660370710007555, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 310, train_loss = 0.9659188395999081, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 311, train_loss = 0.9659622255712748, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 312, train_loss = 0.964291634503752, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 313, train_loss = 0.9644532015845471, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 314, train_loss = 0.9639624082483351, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 315, train_loss = 0.9639895589389198, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 316, train_loss = 0.9634830878749199, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 317, train_loss = 0.9622312703468197, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 318, train_loss = 0.960524435620755, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 319, train_loss = 0.9617398547306948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 320, train_loss = 0.9608555788472586, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 321, train_loss = 0.9609566389881365, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 322, train_loss = 0.9599616459272511, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 323, train_loss = 0.9599923508540087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 324, train_loss = 0.9580212882719934, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 325, train_loss = 0.9573416158855252, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 326, train_loss = 0.9573506726883352, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 327, train_loss = 0.9576048217713833, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 328, train_loss = 0.9564091488718987, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 329, train_loss = 0.9567403413057036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 330, train_loss = 0.9552192382216163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 331, train_loss = 0.9566551178395457, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 332, train_loss = 0.9550082435198419, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 333, train_loss = 0.9545506423637562, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 334, train_loss = 0.9545935300811834, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 335, train_loss = 0.9544765438586182, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 336, train_loss = 0.9561782145574398, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 337, train_loss = 0.9537040006071038, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 338, train_loss = 0.953768540173769, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 339, train_loss = 0.9526713504455984, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 340, train_loss = 0.9523379406891763, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 341, train_loss = 0.9523166677281552, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 342, train_loss = 0.9502773357853584, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 343, train_loss = 0.9510438034012623, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 344, train_loss = 0.9507554202973552, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 345, train_loss = 0.9491621178276546, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 346, train_loss = 0.9488735067025118, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 347, train_loss = 0.9494161456823349, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 348, train_loss = 0.9484868369363539, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 349, train_loss = 0.9479008833877742, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 350, train_loss = 0.9478295735716529, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 351, train_loss = 0.9487564953342371, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 352, train_loss = 0.9482181710191071, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 353, train_loss = 0.9460648808926635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 354, train_loss = 0.9475400052033365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 355, train_loss = 0.9461217972748273, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 356, train_loss = 0.94704245403409, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 357, train_loss = 0.9465588109269447, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 358, train_loss = 0.9460243441462808, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 359, train_loss = 0.9455353595949418, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 360, train_loss = 0.9458622767888301, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 361, train_loss = 0.9444831272885494, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 362, train_loss = 0.9446147211529023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 363, train_loss = 0.9440525382124179, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 364, train_loss = 0.9444433652497537, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 365, train_loss = 0.944076968356967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 366, train_loss = 0.9435402027629607, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 367, train_loss = 0.9435489916540973, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 368, train_loss = 0.9424887501336343, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 369, train_loss = 0.9423847133293748, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 370, train_loss = 0.9428716904185421, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 371, train_loss = 0.9417851930484176, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 372, train_loss = 0.9415576094761491, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 373, train_loss = 0.9415717453994148, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 374, train_loss = 0.9417211075015075, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 375, train_loss = 0.9405813260636933, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 376, train_loss = 0.9406108874827623, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 377, train_loss = 0.9400571941696398, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 378, train_loss = 0.9397279083095782, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 379, train_loss = 0.9392211403064721, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 380, train_loss = 0.9403852609284513, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 381, train_loss = 0.9389261401556723, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 382, train_loss = 0.938753590296983, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 383, train_loss = 0.9375039848200686, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 384, train_loss = 0.9361855275928974, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 385, train_loss = 0.9391020803413994, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 386, train_loss = 0.9373944190629118, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 387, train_loss = 0.9388511603065126, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 388, train_loss = 0.9369488755874045, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 389, train_loss = 0.9352718209847808, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 390, train_loss = 0.938108625512541, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 391, train_loss = 0.9364365627989173, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 392, train_loss = 0.9355419479943521, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 393, train_loss = 0.9330140395722992, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 394, train_loss = 0.9346535891927488, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 395, train_loss = 0.9329818918668025, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 396, train_loss = 0.9323255040981167, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 397, train_loss = 0.9357697584964626, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 398, train_loss = 0.9348421267532103, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 399, train_loss = 0.93284077352655, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 400, train_loss = 0.9317785343155265, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 401, train_loss = 0.9340177228041284, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 402, train_loss = 0.9339412515982985, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 403, train_loss = 0.9349568380675919, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 404, train_loss = 0.9334972770884633, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 405, train_loss = 0.9309193324297667, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 406, train_loss = 0.9332814815752499, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 407, train_loss = 0.9304435107223981, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 408, train_loss = 0.9323197559751861, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 409, train_loss = 0.9317655448503501, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 410, train_loss = 0.9315383617467887, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 411, train_loss = 0.9289489965885878, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 412, train_loss = 0.9286682357378595, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 413, train_loss = 0.9317361349239945, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 414, train_loss = 0.9297125500925176, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 415, train_loss = 0.9296882068738341, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 416, train_loss = 0.9292040336877108, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 417, train_loss = 0.9261787667237513, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 418, train_loss = 0.9287617883346684, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 419, train_loss = 0.9258078758903139, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 420, train_loss = 0.9271023490764492, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 421, train_loss = 0.9270503148436546, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 422, train_loss = 0.9259245839602954, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 423, train_loss = 0.9237308530136943, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 424, train_loss = 0.9256652801595919, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 425, train_loss = 0.9237160963621136, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 426, train_loss = 0.9277218482457101, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 427, train_loss = 0.9245431230719987, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 428, train_loss = 0.9236474277768139, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 429, train_loss = 0.9239200206156966, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 430, train_loss = 0.922624749597162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 431, train_loss = 0.924991408828646, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 432, train_loss = 0.924446941819042, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 433, train_loss = 0.9213350020963844, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 434, train_loss = 0.9263651501387358, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 435, train_loss = 0.9230977216120664, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 436, train_loss = 0.9218308239560429, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 437, train_loss = 0.9228060920722783, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 438, train_loss = 0.9200990353710949, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 439, train_loss = 0.9244237140137557, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 440, train_loss = 0.922721407841891, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 441, train_loss = 0.9228159002959728, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 442, train_loss = 0.9189124652184546, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 443, train_loss = 0.9218357003610436, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 444, train_loss = 0.9205107620600756, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 445, train_loss = 0.917461766706765, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 446, train_loss = 0.9214212469141785, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 447, train_loss = 0.9172546486370265, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 448, train_loss = 0.91751763317734, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 449, train_loss = 0.9186258812751475, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 450, train_loss = 0.9178127797003981, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 451, train_loss = 0.9166664451677207, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 452, train_loss = 0.9200310703981813, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 453, train_loss = 0.9156806099545065, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 454, train_loss = 0.9141133697703481, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 455, train_loss = 0.9195449482649565, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 456, train_loss = 0.9196009812876582, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 457, train_loss = 0.9162035601530079, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 458, train_loss = 0.9159573543201986, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 459, train_loss = 0.9182231125105318, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 460, train_loss = 0.9144287649542093, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 461, train_loss = 0.9143599043600261, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 462, train_loss = 0.9178437776863575, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 463, train_loss = 0.9158150015082356, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 464, train_loss = 0.9126169574446976, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 465, train_loss = 0.9127323793563846, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 466, train_loss = 0.9173455904237926, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 467, train_loss = 0.9169104131869972, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 468, train_loss = 0.9141493425704539, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 469, train_loss = 0.9123649353477958, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 470, train_loss = 0.9157816578317579, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 471, train_loss = 0.916640582960099, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 472, train_loss = 0.9121327892262343, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 473, train_loss = 0.9109093498755101, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 474, train_loss = 0.9149525306802389, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 475, train_loss = 0.9154685378689464, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 476, train_loss = 0.9118971309308108, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 477, train_loss = 0.9103896422311664, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 478, train_loss = 0.9154065659586195, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 479, train_loss = 0.9129494037479162, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 480, train_loss = 0.9111077700126771, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 481, train_loss = 0.9095542932245735, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 482, train_loss = 0.9121668889802095, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 483, train_loss = 0.9111541377696994, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 484, train_loss = 0.9087571501731873, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 485, train_loss = 0.9080139085035626, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 486, train_loss = 0.910683690881342, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 487, train_loss = 0.9119850162733201, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 488, train_loss = 0.908942908359677, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 489, train_loss = 0.9079042803496122, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 490, train_loss = 0.9093524290565256, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 491, train_loss = 0.9073127253595885, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 492, train_loss = 0.910515178771675, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 493, train_loss = 0.9079238131325837, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 494, train_loss = 0.9130504244621989, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 495, train_loss = 0.9106494500301778, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 496, train_loss = 0.9089754326269031, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 497, train_loss = 0.9058740992713865, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 498, train_loss = 0.9078762481603917, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 499, train_loss = 0.906587001247317, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|█████████████████▉                                                           | 7/30 [1:03:04<3:27:10, 540.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "8th- epoch: 0, train_loss = 285.4503229558468, train_acc = 0.8292966930600838\n",
      "test Acc 0.8608007448789572:\n",
      "8th- epoch: 1, train_loss = 72.91705649590585, train_acc = 0.9350256171401956\n",
      "test Acc 0.9320297951582868:\n",
      "8th- epoch: 2, train_loss = 45.85442457476165, train_acc = 0.950279459711225\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 3, train_loss = 32.55248344561551, train_acc = 0.96040987424313\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 4, train_loss = 24.487824605079368, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 5, train_loss = 18.61258662864566, train_acc = 0.9725197950628784\n",
      "test Acc 0.9548417132216015:\n",
      "8th- epoch: 6, train_loss = 14.85076537844725, train_acc = 0.9775267815556591\n",
      "test Acc 0.9553072625698324:\n",
      "8th- epoch: 7, train_loss = 12.157081694342196, train_acc = 0.980204937121565\n",
      "test Acc 0.957169459962756:\n",
      "8th- epoch: 8, train_loss = 10.031150585738942, train_acc = 0.9833488588728458\n",
      "test Acc 0.9585661080074488:\n",
      "8th- epoch: 9, train_loss = 8.477703883079812, train_acc = 0.9861434559850955\n",
      "test Acc 0.9590316573556797:\n",
      "8th- epoch: 10, train_loss = 7.279047356219962, train_acc = 0.986376339077783\n",
      "test Acc 0.9599627560521415:\n",
      "8th- epoch: 11, train_loss = 6.209952652454376, train_acc = 0.9885887284583139\n",
      "test Acc 0.9604283054003724:\n",
      "8th- epoch: 12, train_loss = 5.399370964616537, train_acc = 0.9902189101071263\n",
      "test Acc 0.9604283054003724:\n",
      "8th- epoch: 13, train_loss = 4.78333139163442, train_acc = 0.9912668840242198\n",
      "test Acc 0.9613594040968343:\n",
      "8th- epoch: 14, train_loss = 4.29408712068107, train_acc = 0.9921984163949698\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 15, train_loss = 3.9189604012062773, train_acc = 0.9921984163949698\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 16, train_loss = 3.626005324185826, train_acc = 0.9924312994876572\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 17, train_loss = 3.387994913966395, train_acc = 0.9937121564974383\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 18, train_loss = 3.1910549215972424, train_acc = 0.9939450395901258\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 19, train_loss = 3.0139720427105203, train_acc = 0.9944108057755007\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 20, train_loss = 2.869585059583187, train_acc = 0.9946436888681882\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 21, train_loss = 2.742847108631395, train_acc = 0.9947601304145319\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 22, train_loss = 2.632003653794527, train_acc = 0.9948765719608756\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 23, train_loss = 2.5259820260107517, train_acc = 0.9948765719608756\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 24, train_loss = 2.432907583832275, train_acc = 0.9949930135072194\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 25, train_loss = 2.3458145770127885, train_acc = 0.9948765719608756\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 26, train_loss = 2.263190953701269, train_acc = 0.9951094550535631\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 27, train_loss = 2.188360195606947, train_acc = 0.9952258965999069\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 28, train_loss = 2.1247201301157475, train_acc = 0.9953423381462506\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 29, train_loss = 2.0639137625694275, train_acc = 0.9954587796925943\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 30, train_loss = 2.011972603679169, train_acc = 0.995575221238938\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 31, train_loss = 1.9645118725602515, train_acc = 0.9954587796925943\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 32, train_loss = 1.9229380625183694, train_acc = 0.9958081043316255\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 33, train_loss = 1.886553555727005, train_acc = 0.996040987424313\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 34, train_loss = 1.8535614162683487, train_acc = 0.9959245458779693\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 35, train_loss = 1.8189036399126053, train_acc = 0.9961574289706567\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 36, train_loss = 1.7855129254166968, train_acc = 0.9962738705170004\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 37, train_loss = 1.7602765883202665, train_acc = 0.9962738705170004\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 38, train_loss = 1.7278728659148328, train_acc = 0.9962738705170004\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 39, train_loss = 1.703072624921333, train_acc = 0.9963903120633442\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 40, train_loss = 1.6830460379715078, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 41, train_loss = 1.6619615356321447, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 42, train_loss = 1.644773107022047, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 43, train_loss = 1.6274168938398361, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 44, train_loss = 1.6082786582410336, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 45, train_loss = 1.5948211960494518, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 46, train_loss = 1.5779887661337852, train_acc = 0.996506753609688\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 47, train_loss = 1.563024076342117, train_acc = 0.996506753609688\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 48, train_loss = 1.5512390931253321, train_acc = 0.996506753609688\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 49, train_loss = 1.5351556899549905, train_acc = 0.996506753609688\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 50, train_loss = 1.523116579890484, train_acc = 0.996506753609688\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 51, train_loss = 1.510658902436262, train_acc = 0.996506753609688\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 52, train_loss = 1.4978589502570685, train_acc = 0.996506753609688\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 53, train_loss = 1.4868383780121803, train_acc = 0.996506753609688\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 54, train_loss = 1.4745681062340736, train_acc = 0.996506753609688\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 55, train_loss = 1.4627189425227698, train_acc = 0.996506753609688\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 56, train_loss = 1.4539571168425027, train_acc = 0.996506753609688\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 57, train_loss = 1.4424384571611881, train_acc = 0.996506753609688\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 58, train_loss = 1.4333462243375834, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 59, train_loss = 1.4239165422914084, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 60, train_loss = 1.4140484854578972, train_acc = 0.9966231951560317\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 61, train_loss = 1.4064049621520098, train_acc = 0.9966231951560317\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 62, train_loss = 1.3971769697964191, train_acc = 0.9966231951560317\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 63, train_loss = 1.3885854246618692, train_acc = 0.9967396367023754\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 64, train_loss = 1.3815409876406193, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 65, train_loss = 1.374460220336914, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 66, train_loss = 1.3666632721724454, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 67, train_loss = 1.3594950226543006, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 68, train_loss = 1.3517398610711098, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 69, train_loss = 1.3453387854096945, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 70, train_loss = 1.3391091550292913, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 71, train_loss = 1.332677190512186, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 72, train_loss = 1.326511582970852, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 73, train_loss = 1.3209137246012688, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 74, train_loss = 1.3151645275356714, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 75, train_loss = 1.308890338987112, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 76, train_loss = 1.3031184872088488, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 77, train_loss = 1.2984167846443597, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 78, train_loss = 1.2934390492737293, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 79, train_loss = 1.2886264584958553, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 80, train_loss = 1.2826472409069538, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 81, train_loss = 1.2781449668109417, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 82, train_loss = 1.273248872399563, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 83, train_loss = 1.2691496138868388, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 84, train_loss = 1.2645742533204611, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 85, train_loss = 1.2609202489256859, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 86, train_loss = 1.255819421261549, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 87, train_loss = 1.2510225785226794, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 88, train_loss = 1.2462806652038125, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 89, train_loss = 1.2444275679590646, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 90, train_loss = 1.2383375143108424, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 91, train_loss = 1.235891915857792, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 92, train_loss = 1.231521158173564, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 93, train_loss = 1.227442151561263, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 94, train_loss = 1.223702885210514, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 95, train_loss = 1.2199385936110048, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 96, train_loss = 1.217690556004527, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 97, train_loss = 1.2127305381000042, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 98, train_loss = 1.2096350019128295, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 99, train_loss = 1.2071387097239494, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 100, train_loss = 1.2042971849441528, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 101, train_loss = 1.2003588676452637, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 102, train_loss = 1.1971009224653244, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 103, train_loss = 1.1935381914227037, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 104, train_loss = 1.1904843101947336, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 105, train_loss = 1.1876252156944247, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 106, train_loss = 1.184243364885333, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 107, train_loss = 1.182084475949523, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 108, train_loss = 1.1783836632966995, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 109, train_loss = 1.176030249640462, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 110, train_loss = 1.174239398285863, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 111, train_loss = 1.1703243951051263, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 112, train_loss = 1.1675597851426573, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 113, train_loss = 1.1666032200009795, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 114, train_loss = 1.1629087428300409, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 115, train_loss = 1.1600843730120687, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 116, train_loss = 1.1588567520229844, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 117, train_loss = 1.1553041264414787, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 118, train_loss = 1.1526843793690205, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 119, train_loss = 1.1519779153168201, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 120, train_loss = 1.1480983557848958, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 121, train_loss = 1.1469994224607944, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 122, train_loss = 1.144243045404437, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 123, train_loss = 1.1414086781442165, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 124, train_loss = 1.1402629564254312, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 125, train_loss = 1.1379347071051598, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 126, train_loss = 1.1352538404316874, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 127, train_loss = 1.1335410736501217, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 128, train_loss = 1.1315214335918427, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 129, train_loss = 1.1295149363577366, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 130, train_loss = 1.12775952865195, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 131, train_loss = 1.1258870425372152, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 132, train_loss = 1.1241763035504846, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 133, train_loss = 1.1221563120634528, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 134, train_loss = 1.1206585143954726, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 135, train_loss = 1.1180454082787037, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 136, train_loss = 1.116786768034217, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 137, train_loss = 1.1172941861004801, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 138, train_loss = 1.1146099393517943, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 139, train_loss = 1.1136104352772236, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 140, train_loss = 1.1118791687040357, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 141, train_loss = 1.1096466022281675, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 142, train_loss = 1.1084965740592452, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 143, train_loss = 1.106500305235386, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 144, train_loss = 1.1052400047628907, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 145, train_loss = 1.102415557950735, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 146, train_loss = 1.1025067803711863, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 147, train_loss = 1.0992488153278828, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 148, train_loss = 1.0990144945681095, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 149, train_loss = 1.0965232327580452, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 150, train_loss = 1.09505791713309, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 151, train_loss = 1.0944913203566102, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 152, train_loss = 1.0925068333745003, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 153, train_loss = 1.091430351138115, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 154, train_loss = 1.0896558749227552, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 155, train_loss = 1.088734661534545, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 156, train_loss = 1.0863811460585566, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 157, train_loss = 1.0857312033622293, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 158, train_loss = 1.0834000359027414, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 159, train_loss = 1.0828227698802948, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 160, train_loss = 1.080851525068283, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 161, train_loss = 1.0795610596687766, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 162, train_loss = 1.078403980776784, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 163, train_loss = 1.076602689921856, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 164, train_loss = 1.0767765541822882, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 165, train_loss = 1.0743130246846704, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 166, train_loss = 1.0735495003609685, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 167, train_loss = 1.0716613667755155, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 168, train_loss = 1.0716901781706838, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 169, train_loss = 1.0686976313591003, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 170, train_loss = 1.068971345826867, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 171, train_loss = 1.067175121352193, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 172, train_loss = 1.0657708694488974, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 173, train_loss = 1.0654434015305014, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 174, train_loss = 1.0634934715926647, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 175, train_loss = 1.062776209160802, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 176, train_loss = 1.0609778314828873, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 177, train_loss = 1.060564032450202, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 178, train_loss = 1.0592838215379743, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 179, train_loss = 1.0583449105470208, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 180, train_loss = 1.0567843044846086, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 181, train_loss = 1.0564767184405355, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 182, train_loss = 1.0541092716157436, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 183, train_loss = 1.054172837481019, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 184, train_loss = 1.052517311021802, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 185, train_loss = 1.0517540859727887, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 186, train_loss = 1.0499398286192445, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 187, train_loss = 1.0500492726714583, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 188, train_loss = 1.0479153494088678, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 189, train_loss = 1.0478717349469662, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 190, train_loss = 1.0465969257056713, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 191, train_loss = 1.0457567597477464, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 192, train_loss = 1.0439865079970332, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 193, train_loss = 1.0436232363135787, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 194, train_loss = 1.041711051017046, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 195, train_loss = 1.0414356949477224, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 196, train_loss = 1.039751420423272, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 197, train_loss = 1.0399210453033447, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 198, train_loss = 1.038271953657386, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 199, train_loss = 1.0375385470688343, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 200, train_loss = 1.0360344250948401, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 201, train_loss = 1.0358829696924658, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 202, train_loss = 1.0346917522401782, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 203, train_loss = 1.0328478962182999, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 204, train_loss = 1.0333411532192258, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 205, train_loss = 1.0311439832003089, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 206, train_loss = 1.0316215828061104, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 207, train_loss = 1.0299110623745946, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 208, train_loss = 1.0298292239458533, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 209, train_loss = 1.028455318257329, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 210, train_loss = 1.027457834527013, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 211, train_loss = 1.0271048992872238, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 212, train_loss = 1.0254900132567855, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 213, train_loss = 1.0250862526445417, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 214, train_loss = 1.0237421207129955, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 215, train_loss = 1.0234684335737256, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 216, train_loss = 1.0230023389012786, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 217, train_loss = 1.0212681579141645, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 218, train_loss = 1.0214238415210275, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 219, train_loss = 1.01950532074261, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 220, train_loss = 1.019791841506958, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 221, train_loss = 1.018024031072855, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 222, train_loss = 1.018187027424574, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 223, train_loss = 1.0175373939127894, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 224, train_loss = 1.0157004396169214, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 225, train_loss = 1.0157252786011668, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 226, train_loss = 1.0144816786050797, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 227, train_loss = 1.0143283742218046, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 228, train_loss = 1.013756652668235, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 229, train_loss = 1.0121836066246033, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 230, train_loss = 1.0127589168696431, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 231, train_loss = 1.0108032611460658, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 232, train_loss = 1.0108364596962929, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 233, train_loss = 1.0106176882982254, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 234, train_loss = 1.0086612912564306, train_acc = 0.9969725197950629\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 235, train_loss = 1.0087384755461244, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 236, train_loss = 1.008031651377678, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 237, train_loss = 1.0063654594123363, train_acc = 0.9969725197950629\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 238, train_loss = 1.0064456214458914, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 239, train_loss = 1.005726716175559, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 240, train_loss = 1.0042659838945838, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 241, train_loss = 1.004347966358182, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 242, train_loss = 1.0042220453469781, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 243, train_loss = 1.0023525791912107, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 244, train_loss = 1.0027171348483535, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 245, train_loss = 1.0013825657515554, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 246, train_loss = 1.001519963145256, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 247, train_loss = 1.000220812857151, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 248, train_loss = 0.9992813554854365, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 249, train_loss = 0.9992996826767921, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 250, train_loss = 0.998861089348793, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 251, train_loss = 0.9972170231194468, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 252, train_loss = 0.9976107440888882, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 253, train_loss = 0.9970718386321096, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 254, train_loss = 0.9956326335668564, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 255, train_loss = 0.9959621590824099, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 256, train_loss = 0.9957127620727988, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 257, train_loss = 0.9944505443127127, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 258, train_loss = 0.9939995060412912, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 259, train_loss = 0.9939017842261819, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 260, train_loss = 0.991841696202755, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 261, train_loss = 0.9923861746938201, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 262, train_loss = 0.9916038413794013, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 263, train_loss = 0.9902505812497111, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 264, train_loss = 0.9905080323369475, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 265, train_loss = 0.9898815515189199, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 266, train_loss = 0.9882549109606771, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 267, train_loss = 0.9886582096369239, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 268, train_loss = 0.9882598742842674, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 269, train_loss = 0.9869657543749781, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 270, train_loss = 0.9871781058609486, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 271, train_loss = 0.9862117320299149, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 272, train_loss = 0.9851837443857221, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 273, train_loss = 0.9851607009768486, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 274, train_loss = 0.9848290321679087, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 275, train_loss = 0.9833749247045489, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 276, train_loss = 0.9838526397943497, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 277, train_loss = 0.9829863011837006, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 278, train_loss = 0.9820564674882917, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 279, train_loss = 0.9818949202744989, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 280, train_loss = 0.9813180689961882, train_acc = 0.9972054028877504\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 281, train_loss = 0.9801929456443759, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 282, train_loss = 0.9810416201798944, train_acc = 0.9973218444340941\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 283, train_loss = 0.9797939794807462, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 284, train_loss = 0.9794996740965871, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 285, train_loss = 0.9780295044183731, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 286, train_loss = 0.9786255334838643, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 287, train_loss = 0.9778633154928684, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 288, train_loss = 0.9776827171444893, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 289, train_loss = 0.9756935872137547, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 290, train_loss = 0.976385448127985, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 291, train_loss = 0.9755766702219262, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 292, train_loss = 0.9753367429002537, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 293, train_loss = 0.9743114076554775, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 294, train_loss = 0.9733984433114529, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 295, train_loss = 0.9735240948721184, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 296, train_loss = 0.9732138440012932, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 297, train_loss = 0.9727040765210404, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 298, train_loss = 0.9719357353969826, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 299, train_loss = 0.971664277218224, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 300, train_loss = 0.9710636188610806, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 301, train_loss = 0.9712167928591953, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 302, train_loss = 0.9705450907349586, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 303, train_loss = 0.9699581166132702, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 304, train_loss = 0.9689472479076358, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 305, train_loss = 0.9689196857361821, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 306, train_loss = 0.9683259129524231, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 307, train_loss = 0.9679164712651982, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 308, train_loss = 0.9677783288061619, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 309, train_loss = 0.9672240825966583, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 310, train_loss = 0.9667942027226673, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 311, train_loss = 0.9660839376374497, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 312, train_loss = 0.9658071361482143, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 313, train_loss = 0.9645932416096912, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 314, train_loss = 0.9652692166491761, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 315, train_loss = 0.9647357786670909, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 316, train_loss = 0.964441567659378, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 317, train_loss = 0.9638313514515175, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 318, train_loss = 0.9636560467406525, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 319, train_loss = 0.9629997946321964, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 320, train_loss = 0.9630446583032608, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 321, train_loss = 0.9622914766296162, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 322, train_loss = 0.9614287925287499, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 323, train_loss = 0.9616779858915834, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 324, train_loss = 0.9601164124906063, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 325, train_loss = 0.9605018931106315, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 326, train_loss = 0.9601114889010205, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 327, train_loss = 0.9597632922232151, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 328, train_loss = 0.9593811109662056, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 329, train_loss = 0.9588523805141449, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 330, train_loss = 0.9586464626117959, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 331, train_loss = 0.958277835197805, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 332, train_loss = 0.9574753468259587, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 333, train_loss = 0.9576574054881348, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 334, train_loss = 0.9569178037345409, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 335, train_loss = 0.9566426599994884, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 336, train_loss = 0.9564418109803228, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 337, train_loss = 0.9561499319970608, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 338, train_loss = 0.9550340672358288, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 339, train_loss = 0.9551569074392319, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 340, train_loss = 0.9545469445511117, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 341, train_loss = 0.954313879214169, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 342, train_loss = 0.9537906236946583, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 343, train_loss = 0.9536051601171494, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 344, train_loss = 0.9529752433300018, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 345, train_loss = 0.9528528389855637, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 346, train_loss = 0.9524694991632714, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 347, train_loss = 0.9518351753577008, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 348, train_loss = 0.9516487680375576, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 349, train_loss = 0.9519732197077246, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 350, train_loss = 0.9509736684412928, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 351, train_loss = 0.950537659227848, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 352, train_loss = 0.9509345218539238, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 353, train_loss = 0.9503643972202553, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 354, train_loss = 0.9492209615782485, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 355, train_loss = 0.9496756978332996, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 356, train_loss = 0.948902985699533, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 357, train_loss = 0.9483118156567798, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 358, train_loss = 0.94822410618508, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 359, train_loss = 0.947768429912685, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 360, train_loss = 0.9474902090951218, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 361, train_loss = 0.9470796026289463, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 362, train_loss = 0.947091950722097, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 363, train_loss = 0.9464022293686867, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 364, train_loss = 0.9464980947450385, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 365, train_loss = 0.9460502925066976, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 366, train_loss = 0.9457156931312056, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 367, train_loss = 0.9450523679406615, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 368, train_loss = 0.9451410224064603, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 369, train_loss = 0.9441887227148982, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 370, train_loss = 0.9443573566750274, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 371, train_loss = 0.9437701416536584, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 372, train_loss = 0.9438373235389008, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 373, train_loss = 0.9431330151855946, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 374, train_loss = 0.9427551403641701, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 375, train_loss = 0.9425024837255478, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 376, train_loss = 0.9424598651603446, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 377, train_loss = 0.9419462506994023, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 378, train_loss = 0.9417126849293709, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 379, train_loss = 0.9412333642467274, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 380, train_loss = 0.9409121746793971, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 381, train_loss = 0.9405427947640419, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 382, train_loss = 0.9404891356825829, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 383, train_loss = 0.9400970463975682, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 384, train_loss = 0.9398411052898155, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 385, train_loss = 0.9397287418469205, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 386, train_loss = 0.9391083133741631, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 387, train_loss = 0.9388065375387669, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 388, train_loss = 0.9384243289605365, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 389, train_loss = 0.9384290389716625, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 390, train_loss = 0.9382789966912242, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 391, train_loss = 0.9377382770180702, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 392, train_loss = 0.9371201992034912, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 393, train_loss = 0.9369391401633038, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 394, train_loss = 0.9365741622968926, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 395, train_loss = 0.9363684418276534, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 396, train_loss = 0.9355890676379204, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 397, train_loss = 0.9357580828145728, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 398, train_loss = 0.9348196710125194, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 399, train_loss = 0.934538334608078, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 400, train_loss = 0.9343952064737095, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 401, train_loss = 0.934576158724667, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 402, train_loss = 0.9337731016203179, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 403, train_loss = 0.9337172694504261, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 404, train_loss = 0.9330684679225669, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 405, train_loss = 0.932776269815804, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 406, train_loss = 0.9324100166559219, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 407, train_loss = 0.9323200012222514, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 408, train_loss = 0.9316321797668934, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 409, train_loss = 0.9313634609134169, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 410, train_loss = 0.9311809564678697, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 411, train_loss = 0.930634309843299, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 412, train_loss = 0.9303063750267029, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 413, train_loss = 0.9299925764353247, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 414, train_loss = 0.9296410133392783, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 415, train_loss = 0.9291501802654238, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 416, train_loss = 0.9290089321584674, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 417, train_loss = 0.9287513643503189, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 418, train_loss = 0.928091091409442, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 419, train_loss = 0.9281992527394323, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 420, train_loss = 0.9281547330319881, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 421, train_loss = 0.9273576997220516, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 422, train_loss = 0.9275890998542309, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 423, train_loss = 0.9271080705075292, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 424, train_loss = 0.9268786038010148, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 425, train_loss = 0.9268080356268911, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 426, train_loss = 0.9263930817396613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 427, train_loss = 0.9264837453811197, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 428, train_loss = 0.9258365568966838, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 429, train_loss = 0.9256798711867305, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 430, train_loss = 0.925607081502676, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 431, train_loss = 0.9251503857522039, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 432, train_loss = 0.9254568219184875, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 433, train_loss = 0.9251635298132896, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 434, train_loss = 0.9244560661463765, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 435, train_loss = 0.9242949299514294, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 436, train_loss = 0.9240348835737677, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 437, train_loss = 0.9239874891936779, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 438, train_loss = 0.9236383462994127, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 439, train_loss = 0.9231722764670849, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 440, train_loss = 0.9232740104198456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 441, train_loss = 0.9230311810970306, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 442, train_loss = 0.9226457551121712, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 443, train_loss = 0.9223608573229285, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 444, train_loss = 0.9223586780281039, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 445, train_loss = 0.9219275203795405, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 446, train_loss = 0.9216824062168598, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 447, train_loss = 0.9215313283057185, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 448, train_loss = 0.9212699420750141, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 449, train_loss = 0.9211558438837528, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 450, train_loss = 0.9209267223923234, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 451, train_loss = 0.9209471717476845, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 452, train_loss = 0.9204953995795222, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 453, train_loss = 0.9204237672238378, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 454, train_loss = 0.9202382527291775, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 455, train_loss = 0.9195591782481642, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 456, train_loss = 0.9197710702865152, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 457, train_loss = 0.9193685874342918, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 458, train_loss = 0.9190967443064437, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 459, train_loss = 0.9188439982608543, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 460, train_loss = 0.919183033212903, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 461, train_loss = 0.9184185154736042, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 462, train_loss = 0.9182369895279408, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 463, train_loss = 0.91819017380476, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 464, train_loss = 0.91794703155756, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 465, train_loss = 0.9176255650818348, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 466, train_loss = 0.917423872895597, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 467, train_loss = 0.917308031268476, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 468, train_loss = 0.9172287310138927, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 469, train_loss = 0.9169600481764064, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 470, train_loss = 0.9165948331356049, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 471, train_loss = 0.916379430644156, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 472, train_loss = 0.9163233377039433, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 473, train_loss = 0.9160220548510551, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 474, train_loss = 0.9158688647075905, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 475, train_loss = 0.9156619509085431, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 476, train_loss = 0.9153860546648502, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 477, train_loss = 0.9151587213054881, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 478, train_loss = 0.9151701169685111, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 479, train_loss = 0.9148708557113423, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 480, train_loss = 0.9146799606605782, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 481, train_loss = 0.9146464504301548, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 482, train_loss = 0.9146449044346809, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 483, train_loss = 0.9139854609966278, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 484, train_loss = 0.9140760401860462, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 485, train_loss = 0.9136533116325154, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 486, train_loss = 0.9131849470213638, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 487, train_loss = 0.9129349452778115, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 488, train_loss = 0.9123979732394218, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 489, train_loss = 0.9121140167117119, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 490, train_loss = 0.9121123738586903, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 491, train_loss = 0.911781912051083, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 492, train_loss = 0.9115991691724048, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 493, train_loss = 0.9114289693534374, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 494, train_loss = 0.9110216870903969, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 495, train_loss = 0.9109201480969205, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 496, train_loss = 0.9108467449768796, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 497, train_loss = 0.9104561607018695, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 498, train_loss = 0.9103692757562385, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 499, train_loss = 0.9103993984535919, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|████████████████████▌                                                        | 8/30 [1:12:10<3:18:51, 542.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "9th- epoch: 0, train_loss = 359.77194795478135, train_acc = 0.8115975780158361\n",
      "test Acc 0.9050279329608939:\n",
      "9th- epoch: 1, train_loss = 83.94783857604489, train_acc = 0.9267582673497904\n",
      "test Acc 0.9320297951582868:\n",
      "9th- epoch: 2, train_loss = 50.365046934224665, train_acc = 0.9488821611551002\n",
      "test Acc 0.9436685288640596:\n",
      "9th- epoch: 3, train_loss = 35.10147136091837, train_acc = 0.96040987424313\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 4, train_loss = 25.857876591559034, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 5, train_loss = 19.96460161730647, train_acc = 0.974033535165347\n",
      "test Acc 0.9562383612662942:\n",
      "9th- epoch: 6, train_loss = 15.782895082607865, train_acc = 0.9775267815556591\n",
      "test Acc 0.9581005586592178:\n",
      "9th- epoch: 7, train_loss = 12.669752684654668, train_acc = 0.9818351187703773\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 8, train_loss = 10.439165213145316, train_acc = 0.984163949697252\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 9, train_loss = 8.798474078532308, train_acc = 0.9868421052631579\n",
      "test Acc 0.9594972067039106:\n",
      "9th- epoch: 10, train_loss = 7.414586692117155, train_acc = 0.9881229622729389\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 11, train_loss = 6.325040477560833, train_acc = 0.9901024685607824\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 12, train_loss = 5.4520576413488016, train_acc = 0.9906846762925011\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 13, train_loss = 4.741152916802093, train_acc = 0.9916162086632511\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 14, train_loss = 4.194233061862178, train_acc = 0.9926641825803446\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 15, train_loss = 3.7566455716150813, train_acc = 0.993828598043782\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 16, train_loss = 3.4253837197320536, train_acc = 0.9941779226828132\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 17, train_loss = 3.1522542112506926, train_acc = 0.9947601304145319\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 18, train_loss = 2.9219535392476246, train_acc = 0.9952258965999069\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 19, train_loss = 2.72837011620868, train_acc = 0.9954587796925943\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 20, train_loss = 2.5537800029851496, train_acc = 0.9954587796925943\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 21, train_loss = 2.403455476742238, train_acc = 0.9954587796925943\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 22, train_loss = 2.2627930277958512, train_acc = 0.995575221238938\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 23, train_loss = 2.1438911977456883, train_acc = 0.9956916627852818\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 24, train_loss = 2.0345004012342542, train_acc = 0.9958081043316255\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 25, train_loss = 1.9453182825236581, train_acc = 0.9958081043316255\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 26, train_loss = 1.8640692930785008, train_acc = 0.9959245458779693\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 27, train_loss = 1.8071375964791514, train_acc = 0.9961574289706567\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 28, train_loss = 1.7578665670589544, train_acc = 0.9961574289706567\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 29, train_loss = 1.718804435862694, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 30, train_loss = 1.6810732441954315, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 31, train_loss = 1.654727878922131, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 32, train_loss = 1.6226807020721026, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 33, train_loss = 1.600762938556727, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 34, train_loss = 1.576323970570229, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 35, train_loss = 1.559321936510969, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 36, train_loss = 1.5371474724961445, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 37, train_loss = 1.5157272050855681, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 38, train_loss = 1.501330926315859, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 39, train_loss = 1.484614747343585, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 40, train_loss = 1.4669166046660393, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 41, train_loss = 1.452627042250242, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 42, train_loss = 1.439140341739403, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 43, train_loss = 1.4236975536041427, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 44, train_loss = 1.4126516675169114, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 45, train_loss = 1.3998358533135615, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 46, train_loss = 1.3892202839779202, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 47, train_loss = 1.3793159025372006, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 48, train_loss = 1.368548843311146, train_acc = 0.9967396367023754\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 49, train_loss = 1.3601871639257297, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 50, train_loss = 1.3490656215290073, train_acc = 0.9967396367023754\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 51, train_loss = 1.3420363031036686, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 52, train_loss = 1.328821090864949, train_acc = 0.9967396367023754\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 53, train_loss = 1.3248439300514292, train_acc = 0.9967396367023754\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 54, train_loss = 1.312360373995034, train_acc = 0.9967396367023754\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 55, train_loss = 1.3048648404947016, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 56, train_loss = 1.3001040712115355, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 57, train_loss = 1.2894732248096261, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 58, train_loss = 1.280718365102075, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 59, train_loss = 1.2759595012757927, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 60, train_loss = 1.2679406400711741, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 61, train_loss = 1.2616722212696914, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 62, train_loss = 1.2536814009363297, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 63, train_loss = 1.2526939238596242, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 64, train_loss = 1.2428861192602199, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 65, train_loss = 1.2387320225534495, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 66, train_loss = 1.2316608189139515, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 67, train_loss = 1.2269444666744675, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 68, train_loss = 1.2186360745545244, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 69, train_loss = 1.2183021836099215, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 70, train_loss = 1.2095292471931316, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 71, train_loss = 1.2069046699762112, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 72, train_loss = 1.1991201909113443, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 73, train_loss = 1.1943292972136987, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 74, train_loss = 1.1913387646927731, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 75, train_loss = 1.1859874058282003, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 76, train_loss = 1.1801701435324503, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 77, train_loss = 1.1779698280151933, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 78, train_loss = 1.1709842227428453, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 79, train_loss = 1.1679054771229858, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 80, train_loss = 1.1626691354467766, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 81, train_loss = 1.158495682058856, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 82, train_loss = 1.1542997097130865, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 83, train_loss = 1.151662371121347, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 84, train_loss = 1.1484518692159327, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 85, train_loss = 1.1441628922475502, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 86, train_loss = 1.140160174923949, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 87, train_loss = 1.1371022270031972, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 88, train_loss = 1.1327017322182655, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 89, train_loss = 1.129938140627928, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 90, train_loss = 1.1258723765349714, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 91, train_loss = 1.1222145062492928, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 92, train_loss = 1.1204276229254901, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 93, train_loss = 1.1161528868833557, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 94, train_loss = 1.112984601102653, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 95, train_loss = 1.1107210269983625, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 96, train_loss = 1.1069661763758631, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 97, train_loss = 1.1042832810926484, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 98, train_loss = 1.100974346336443, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 99, train_loss = 1.0978170582966413, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 100, train_loss = 1.0935355102701578, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 101, train_loss = 1.0943750585283851, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 102, train_loss = 1.090745582288946, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 103, train_loss = 1.088687155279331, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 104, train_loss = 1.083541765823611, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 105, train_loss = 1.082574697356904, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 106, train_loss = 1.0789774311851943, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 107, train_loss = 1.0756819425878348, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 108, train_loss = 1.0752794469153741, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 109, train_loss = 1.0727020710910438, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 110, train_loss = 1.069861746582319, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 111, train_loss = 1.0687959105271148, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 112, train_loss = 1.0654260261944728, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 113, train_loss = 1.0619587053079158, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 114, train_loss = 1.0630409492878243, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 115, train_loss = 1.0588566872756928, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 116, train_loss = 1.0576467807550216, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 117, train_loss = 1.0561973217336345, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 118, train_loss = 1.0525582651025616, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 119, train_loss = 1.0507427493212163, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 120, train_loss = 1.0479438902111724, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 121, train_loss = 1.0471954558524885, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 122, train_loss = 1.0421779242460616, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 123, train_loss = 1.0436437789394404, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 124, train_loss = 1.0413768340004026, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 125, train_loss = 1.03820094056573, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 126, train_loss = 1.037709243966674, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 127, train_loss = 1.0347259267000481, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 128, train_loss = 1.034680284152273, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 129, train_loss = 1.0299844562759972, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 130, train_loss = 1.0320975163776893, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 131, train_loss = 1.026616163631843, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 132, train_loss = 1.0266544143669307, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 133, train_loss = 1.0242139201363898, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 134, train_loss = 1.0223682026335155, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 135, train_loss = 1.022938535315916, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 136, train_loss = 1.0201614531470113, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 137, train_loss = 1.0196123787682154, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 138, train_loss = 1.0169052344572265, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 139, train_loss = 1.016622909286525, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 140, train_loss = 1.0147451650336734, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 141, train_loss = 1.0130708714495995, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 142, train_loss = 1.0123618743746192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 143, train_loss = 1.0109725871006958, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 144, train_loss = 1.0081021040459746, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 145, train_loss = 1.008464246231597, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 146, train_loss = 1.0083743311406579, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 147, train_loss = 1.0050420893530827, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 148, train_loss = 1.0040329780822503, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 149, train_loss = 1.001183222331747, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 150, train_loss = 1.0005082522329758, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 151, train_loss = 0.999295837857062, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 152, train_loss = 0.9985811400183593, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 153, train_loss = 0.9977551898409729, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 154, train_loss = 0.9965153022785671, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 155, train_loss = 0.9930464823191869, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 156, train_loss = 0.9943699170471518, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 157, train_loss = 0.990725480405672, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 158, train_loss = 0.99066819017753, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 159, train_loss = 0.9904456408476108, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 160, train_loss = 0.9886474359082058, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 161, train_loss = 0.9861297032111906, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 162, train_loss = 0.9878036514855921, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 163, train_loss = 0.9831301091835485, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 164, train_loss = 0.9849372170647257, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 165, train_loss = 0.9824886525166221, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 166, train_loss = 0.9814014638905064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 167, train_loss = 0.9816427364130504, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 168, train_loss = 0.9783864420824102, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 169, train_loss = 0.9805744212135323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 170, train_loss = 0.9789042233023793, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 171, train_loss = 0.9763824762194417, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 172, train_loss = 0.9784389248816296, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 173, train_loss = 0.975594708485005, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 174, train_loss = 0.973259428399615, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 175, train_loss = 0.9720159910284565, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 176, train_loss = 0.9725423734416836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 177, train_loss = 0.9705555888576782, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 178, train_loss = 0.9694837235510931, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 179, train_loss = 0.9709263992481283, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 180, train_loss = 0.9688501576674753, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 181, train_loss = 0.9666068441365496, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 182, train_loss = 0.966597881866619, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 183, train_loss = 0.9641215803349041, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 184, train_loss = 0.9650869161341689, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 185, train_loss = 0.9624293526867405, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 186, train_loss = 0.962814589496702, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 187, train_loss = 0.9607791679736692, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 188, train_loss = 0.9605958369211294, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 189, train_loss = 0.9596681736875325, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 190, train_loss = 0.9581692256324459, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 191, train_loss = 0.9575373173574917, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 192, train_loss = 0.9560194235309609, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 193, train_loss = 0.9564891562404227, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 194, train_loss = 0.95469032676192, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 195, train_loss = 0.9533500489887956, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 196, train_loss = 0.9532986551057547, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 197, train_loss = 0.9511209513402719, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 198, train_loss = 0.9527468859923829, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 199, train_loss = 0.9502249897814181, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 200, train_loss = 0.949769103066501, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 201, train_loss = 0.9496937941003125, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 202, train_loss = 0.9491558909649029, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 203, train_loss = 0.9481934085961257, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 204, train_loss = 0.9452518424259324, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 205, train_loss = 0.9469787200796418, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 206, train_loss = 0.9446183361396834, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 207, train_loss = 0.9438759939512238, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 208, train_loss = 0.943645387149445, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 209, train_loss = 0.9434748649073299, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 210, train_loss = 0.9421891037782189, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 211, train_loss = 0.940549042483326, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 212, train_loss = 0.9415453780675307, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 213, train_loss = 0.9390535034181084, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 214, train_loss = 0.9400991049660661, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 215, train_loss = 0.9387659430685744, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 216, train_loss = 0.9377100085839629, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 217, train_loss = 0.9369149199810636, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 218, train_loss = 0.9371472438615456, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 219, train_loss = 0.9340620091134042, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 220, train_loss = 0.9345221977564506, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 221, train_loss = 0.9329145963602059, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 222, train_loss = 0.9351381600245077, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 223, train_loss = 0.9335321186044894, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 224, train_loss = 0.9323093972234346, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 225, train_loss = 0.9326192603912205, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 226, train_loss = 0.9309360688312154, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 227, train_loss = 0.931133222009521, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 228, train_loss = 0.9294983670115471, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 229, train_loss = 0.9300867103556811, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 230, train_loss = 0.9283776845368266, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 231, train_loss = 0.9287732200282335, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 232, train_loss = 0.9271274989187077, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 233, train_loss = 0.927433722983551, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 234, train_loss = 0.9258373380289413, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 235, train_loss = 0.9259939179755747, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 236, train_loss = 0.9247276385831356, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 237, train_loss = 0.9257586941421323, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 238, train_loss = 0.9248621948063374, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 239, train_loss = 0.923741883783805, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 240, train_loss = 0.9254812777217012, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 241, train_loss = 0.9270204437962093, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 242, train_loss = 0.9276814984223165, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 243, train_loss = 0.9263203435875766, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 244, train_loss = 0.9249851128552109, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 245, train_loss = 0.9254218937712722, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 246, train_loss = 0.9243247287413396, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 247, train_loss = 0.9224468215252273, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 248, train_loss = 0.9228965994734608, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 249, train_loss = 0.9211954209604301, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 250, train_loss = 0.9221693881736428, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 251, train_loss = 0.921069937019638, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 252, train_loss = 0.920446466847352, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 253, train_loss = 0.9196398648200557, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 254, train_loss = 0.917028494139231, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 255, train_loss = 0.9189766333438456, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 256, train_loss = 0.917098561378225, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 257, train_loss = 0.9175809660227969, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 258, train_loss = 0.9157651085006364, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 259, train_loss = 0.9159025272638246, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 260, train_loss = 0.9148128398046538, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 261, train_loss = 0.9155918943179131, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 262, train_loss = 0.913331578271027, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 263, train_loss = 0.9129257637941919, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 264, train_loss = 0.913202671934414, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 265, train_loss = 0.9119572860254266, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 266, train_loss = 0.9124911185535893, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 267, train_loss = 0.9113989153411239, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 268, train_loss = 0.9116346520022489, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 269, train_loss = 0.9100273024523631, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 270, train_loss = 0.9112506171622954, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 271, train_loss = 0.9101686131725728, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 272, train_loss = 0.9085509566939436, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 273, train_loss = 0.9091627901470929, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 274, train_loss = 0.9081998815927363, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 275, train_loss = 0.9084133023679897, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 276, train_loss = 0.9066313175135292, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 277, train_loss = 0.9071352795181156, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 278, train_loss = 0.9071973154968873, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 279, train_loss = 0.9061787003483914, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 280, train_loss = 0.9072262715017132, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 281, train_loss = 0.9051771123195067, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 282, train_loss = 0.906041752488818, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 283, train_loss = 0.9039434459991753, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 284, train_loss = 0.9051539969332225, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 285, train_loss = 0.9042028856529214, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 286, train_loss = 0.9042370559182018, train_acc = 0.9979040521658128\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 287, train_loss = 0.9028143322393589, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 288, train_loss = 0.9033590499129787, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 289, train_loss = 0.9022418231070333, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 290, train_loss = 0.903059370466508, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 291, train_loss = 0.901589521788992, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 292, train_loss = 0.9015327113447711, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 293, train_loss = 0.9003916884539649, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 294, train_loss = 0.9015797825013578, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 295, train_loss = 0.8987365913926624, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 296, train_loss = 0.9000748259131797, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 297, train_loss = 0.8999840695942112, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 298, train_loss = 0.900115506741713, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 299, train_loss = 0.8989605860733718, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 300, train_loss = 0.8990219498336955, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 301, train_loss = 0.8980236888564832, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 302, train_loss = 0.8990948291611858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 303, train_loss = 0.897663630934403, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 304, train_loss = 0.8979708601946186, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 305, train_loss = 0.896595022873953, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 306, train_loss = 0.8971547306573484, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 307, train_loss = 0.8973368551705789, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 308, train_loss = 0.8954749637232453, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 309, train_loss = 0.8970205511323002, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 310, train_loss = 0.8950972030397679, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 311, train_loss = 0.895712964120321, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 312, train_loss = 0.8947478929767385, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 313, train_loss = 0.894406019255257, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 314, train_loss = 0.8942217471376352, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 315, train_loss = 0.8939660164178349, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 316, train_loss = 0.8942645339593582, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 317, train_loss = 0.8928374809729576, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 318, train_loss = 0.8945551418983086, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 319, train_loss = 0.8917721840152808, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 320, train_loss = 0.8940630515753583, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 321, train_loss = 0.8923164606494538, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 322, train_loss = 0.8913196102184884, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 323, train_loss = 0.8929110452299938, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 324, train_loss = 0.8914932245970704, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 325, train_loss = 0.8904681308194995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 326, train_loss = 0.8910888551035896, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 327, train_loss = 0.8909391639353998, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 328, train_loss = 0.8888192239683121, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 329, train_loss = 0.8879563330374367, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 330, train_loss = 0.8906703933607787, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 331, train_loss = 0.8896477253474586, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 332, train_loss = 0.8900791799351282, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 333, train_loss = 0.8877118777418218, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 334, train_loss = 0.8897204955192137, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 335, train_loss = 0.8879320603628003, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 336, train_loss = 0.8889001506995555, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 337, train_loss = 0.88836387180163, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 338, train_loss = 0.8875085777071945, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 339, train_loss = 0.8864455514121801, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 340, train_loss = 0.8876507345521532, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 341, train_loss = 0.8876209815498441, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 342, train_loss = 0.8858207167759247, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 343, train_loss = 0.8858317407630238, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 344, train_loss = 0.8869952158220258, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 345, train_loss = 0.8861096989912767, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 346, train_loss = 0.8858159967930987, train_acc = 0.9979040521658128\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 347, train_loss = 0.8844879805110395, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 348, train_loss = 0.8858155513098609, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 349, train_loss = 0.8855727236168605, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 350, train_loss = 0.8839533374793973, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 351, train_loss = 0.8844784854827594, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 352, train_loss = 0.884839771897532, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 353, train_loss = 0.8823724607154873, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 354, train_loss = 0.8829719765726622, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 355, train_loss = 0.8832560168029886, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 356, train_loss = 0.8822602413511049, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 357, train_loss = 0.8825112937101949, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 358, train_loss = 0.8835736206965521, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 359, train_loss = 0.8831910608769249, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 360, train_loss = 0.8824217618875991, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 361, train_loss = 0.8828264109524753, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 362, train_loss = 0.8797424255953956, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 363, train_loss = 0.8819141487092566, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 364, train_loss = 0.8803702036002505, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 365, train_loss = 0.8824950625421479, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 366, train_loss = 0.8812938229530118, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 367, train_loss = 0.881459165850174, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 368, train_loss = 0.8807948296307586, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 369, train_loss = 0.8810826504486613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 370, train_loss = 0.8813457509768341, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 371, train_loss = 0.8790984673833009, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 372, train_loss = 0.8810009465469193, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 373, train_loss = 0.8787147110069782, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 374, train_loss = 0.8796144730004016, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 375, train_loss = 0.8795234251683723, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 376, train_loss = 0.877927242545411, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 377, train_loss = 0.8790430335411656, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 378, train_loss = 0.8803012023799965, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 379, train_loss = 0.880003263378967, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 380, train_loss = 0.87580439933663, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 381, train_loss = 0.8778043017955497, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 382, train_loss = 0.8786036958354089, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 383, train_loss = 0.8769977971478511, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 384, train_loss = 0.8774419193123322, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 385, train_loss = 0.8783298763246421, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 386, train_loss = 0.877777506606435, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 387, train_loss = 0.877051159448456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 388, train_loss = 0.877078732542941, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 389, train_loss = 0.877183900845921, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 390, train_loss = 0.873723690127008, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 391, train_loss = 0.8752839115240931, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 392, train_loss = 0.8749400626784336, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 393, train_loss = 0.8770235463362042, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 394, train_loss = 0.8760278873869538, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 395, train_loss = 0.8745656872633845, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 396, train_loss = 0.8758037450606935, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 397, train_loss = 0.8759263004958484, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 398, train_loss = 0.8754913419252262, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 399, train_loss = 0.8750787087483332, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 400, train_loss = 0.8751656746808294, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 401, train_loss = 0.8744204118647758, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 402, train_loss = 0.875346369246472, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 403, train_loss = 0.8744296424556524, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 404, train_loss = 0.8747050501206104, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 405, train_loss = 0.8747505769515556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 406, train_loss = 0.8744132584542967, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 407, train_loss = 0.8748143366919976, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 408, train_loss = 0.8734681057194393, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 409, train_loss = 0.8737054693428945, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 410, train_loss = 0.8735155618433055, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 411, train_loss = 0.8737019648342539, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 412, train_loss = 0.8738048880677525, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 413, train_loss = 0.8724408160978783, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 414, train_loss = 0.8733323617689166, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 415, train_loss = 0.8717841443922225, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 416, train_loss = 0.8719955948963616, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 417, train_loss = 0.8730466704782884, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 418, train_loss = 0.8719002333618846, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 419, train_loss = 0.8723557949615497, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 420, train_loss = 0.8713633056413528, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 421, train_loss = 0.8720349693412572, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 422, train_loss = 0.8711762840193842, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 423, train_loss = 0.8713966542181879, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 424, train_loss = 0.871109633028027, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 425, train_loss = 0.8698856816336047, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 426, train_loss = 0.8692846665853722, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 427, train_loss = 0.8704159081189573, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 428, train_loss = 0.8708546018551715, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 429, train_loss = 0.8708982500302227, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 430, train_loss = 0.870458716284702, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 431, train_loss = 0.8701479529208882, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 432, train_loss = 0.8707020165547874, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 433, train_loss = 0.8688403066280443, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 434, train_loss = 0.8692598801335407, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 435, train_loss = 0.8703118996400008, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 436, train_loss = 0.8693856587105984, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 437, train_loss = 0.8699799399819312, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 438, train_loss = 0.8683054625580553, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 439, train_loss = 0.8696182287822012, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 440, train_loss = 0.8687110407554428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 441, train_loss = 0.8689548062484391, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 442, train_loss = 0.8689055496124638, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 443, train_loss = 0.8685043477598811, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 444, train_loss = 0.8683796041786991, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 445, train_loss = 0.8683639862429118, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 446, train_loss = 0.8679199495963985, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 447, train_loss = 0.8678172976360656, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 448, train_loss = 0.8677366090032592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 449, train_loss = 0.8677596363704652, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 450, train_loss = 0.8656062818772625, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 451, train_loss = 0.8675676615876, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 452, train_loss = 0.8680685958443064, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 453, train_loss = 0.8677064439107198, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 454, train_loss = 0.8675585692399181, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 455, train_loss = 0.8672401495859958, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 456, train_loss = 0.8664772582324076, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 457, train_loss = 0.8673739598598331, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 458, train_loss = 0.8668763672958448, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 459, train_loss = 0.8663707864088792, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 460, train_loss = 0.8673821445936483, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 461, train_loss = 0.86594853119459, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 462, train_loss = 0.8665190622559749, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 463, train_loss = 0.8662039345654193, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 464, train_loss = 0.8662142401444726, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 465, train_loss = 0.8660354295188881, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 466, train_loss = 0.8659450483482942, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 467, train_loss = 0.8654575609343738, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 468, train_loss = 0.8660588454513345, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 469, train_loss = 0.8656697359492682, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 470, train_loss = 0.8646003174653742, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 471, train_loss = 0.8657069360197056, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 472, train_loss = 0.86541534175376, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 473, train_loss = 0.8651326791059546, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 474, train_loss = 0.8624919996273093, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 475, train_loss = 0.8653721917944495, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 476, train_loss = 0.864264054238447, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 477, train_loss = 0.8644015303871129, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 478, train_loss = 0.8613410988964461, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 479, train_loss = 0.8645014289359096, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 480, train_loss = 0.8630504970042239, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 481, train_loss = 0.8633513167642377, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 482, train_loss = 0.86440329348261, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 483, train_loss = 0.863685162830734, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 484, train_loss = 0.8637251471864147, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 485, train_loss = 0.863375224000265, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 486, train_loss = 0.8613101250393811, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 487, train_loss = 0.8636079218849773, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 488, train_loss = 0.8633842966355587, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 489, train_loss = 0.8626811706362787, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 490, train_loss = 0.8633702849638212, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 491, train_loss = 0.8624647282431397, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 492, train_loss = 0.8619625690062094, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 493, train_loss = 0.8613792831984028, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 494, train_loss = 0.8600506024031347, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 495, train_loss = 0.8618194219325233, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 496, train_loss = 0.8624685060694901, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 497, train_loss = 0.8615117497029132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 498, train_loss = 0.861285396726089, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 499, train_loss = 0.8618666565653257, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███████████████████████                                                      | 9/30 [1:21:53<3:14:00, 554.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "10th- epoch: 0, train_loss = 336.292869836092, train_acc = 0.8197484862598975\n",
      "test Acc 0.914804469273743:\n",
      "10th- epoch: 1, train_loss = 77.73789403028786, train_acc = 0.9294364229156963\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 2, train_loss = 49.01110279932618, train_acc = 0.9481835118770378\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 3, train_loss = 34.83499105647206, train_acc = 0.9579646017699115\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 4, train_loss = 25.739614602178335, train_acc = 0.9640195621797858\n",
      "test Acc 0.9557728119180633:\n",
      "10th- epoch: 5, train_loss = 19.29650940746069, train_acc = 0.970540288775035\n",
      "test Acc 0.9581005586592178:\n",
      "10th- epoch: 6, train_loss = 14.946425948292017, train_acc = 0.9749650675360969\n",
      "test Acc 0.9581005586592178:\n",
      "10th- epoch: 7, train_loss = 11.927838755771518, train_acc = 0.9786911970190965\n",
      "test Acc 0.9608938547486033:\n",
      "10th- epoch: 8, train_loss = 9.685540564358234, train_acc = 0.9820680018630648\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 9, train_loss = 8.034875470213592, train_acc = 0.985910572892408\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 10, train_loss = 6.822116416878998, train_acc = 0.9883558453656265\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 11, train_loss = 5.963692720979452, train_acc = 0.9896367023754076\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 12, train_loss = 5.342513972893357, train_acc = 0.9904517931998137\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 13, train_loss = 4.845524352509528, train_acc = 0.9913833255705635\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 14, train_loss = 4.449303545057774, train_acc = 0.9919655333022822\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 15, train_loss = 4.106189315672964, train_acc = 0.9923148579413135\n",
      "test Acc 0.9664804469273743:\n",
      "10th- epoch: 16, train_loss = 3.809853652957827, train_acc = 0.9925477410340009\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 17, train_loss = 3.5660807341337204, train_acc = 0.993828598043782\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 18, train_loss = 3.3702044575475156, train_acc = 0.9941779226828132\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 19, train_loss = 3.1935798302292824, train_acc = 0.9944108057755007\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 20, train_loss = 3.062940113246441, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 21, train_loss = 2.9196697524748743, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 22, train_loss = 2.809710097964853, train_acc = 0.9945272473218444\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 23, train_loss = 2.695618810597807, train_acc = 0.9946436888681882\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 24, train_loss = 2.6001483760774136, train_acc = 0.9946436888681882\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 25, train_loss = 2.4967814669944346, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 26, train_loss = 2.403832733631134, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 27, train_loss = 2.3096188590861857, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 28, train_loss = 2.247590953949839, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 29, train_loss = 2.1684354380704463, train_acc = 0.9949930135072194\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 30, train_loss = 2.1217041737399995, train_acc = 0.9949930135072194\n",
      "test Acc 0.9664804469273743:\n",
      "10th- epoch: 31, train_loss = 2.057244742754847, train_acc = 0.9949930135072194\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 32, train_loss = 2.018235459923744, train_acc = 0.9951094550535631\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 33, train_loss = 1.9735172800719738, train_acc = 0.9951094550535631\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 34, train_loss = 1.9432419363874942, train_acc = 0.9952258965999069\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 35, train_loss = 1.9098499044775963, train_acc = 0.9952258965999069\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 36, train_loss = 1.8743390317540616, train_acc = 0.9952258965999069\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 37, train_loss = 1.853411829797551, train_acc = 0.9959245458779693\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 38, train_loss = 1.8273371893446892, train_acc = 0.9959245458779693\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 39, train_loss = 1.8039103858172894, train_acc = 0.9959245458779693\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 40, train_loss = 1.783113858429715, train_acc = 0.9959245458779693\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 41, train_loss = 1.7596490979194641, train_acc = 0.996040987424313\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 42, train_loss = 1.7390265353024006, train_acc = 0.996040987424313\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 43, train_loss = 1.719577339827083, train_acc = 0.996040987424313\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 44, train_loss = 1.696373164653778, train_acc = 0.996040987424313\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 45, train_loss = 1.6788497157394886, train_acc = 0.996040987424313\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 46, train_loss = 1.6597759500145912, train_acc = 0.996040987424313\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 47, train_loss = 1.6393289590487257, train_acc = 0.9961574289706567\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 48, train_loss = 1.6254480158677325, train_acc = 0.9961574289706567\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 49, train_loss = 1.6128436885774136, train_acc = 0.9962738705170004\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 50, train_loss = 1.5971675490727648, train_acc = 0.9962738705170004\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 51, train_loss = 1.5789569666376337, train_acc = 0.9962738705170004\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 52, train_loss = 1.5625506900250912, train_acc = 0.9962738705170004\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 53, train_loss = 1.5526408975711092, train_acc = 0.9963903120633442\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 54, train_loss = 1.5355862999567762, train_acc = 0.9963903120633442\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 55, train_loss = 1.5212691376218572, train_acc = 0.9963903120633442\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 56, train_loss = 1.509606538922526, train_acc = 0.9963903120633442\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 57, train_loss = 1.4957967003574595, train_acc = 0.9963903120633442\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 58, train_loss = 1.4836906070122495, train_acc = 0.9963903120633442\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 59, train_loss = 1.4706089732935652, train_acc = 0.9963903120633442\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 60, train_loss = 1.4581947376136668, train_acc = 0.9963903120633442\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 61, train_loss = 1.4510058127343655, train_acc = 0.9963903120633442\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 62, train_loss = 1.4370619766414165, train_acc = 0.9963903120633442\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 63, train_loss = 1.4256800872390158, train_acc = 0.9963903120633442\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 64, train_loss = 1.4155127691919915, train_acc = 0.9963903120633442\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 65, train_loss = 1.408049888908863, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 66, train_loss = 1.393773275136482, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 67, train_loss = 1.3847816835041158, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 68, train_loss = 1.3740052593057044, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 69, train_loss = 1.3684066857094876, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 70, train_loss = 1.3580316479201429, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 71, train_loss = 1.3486753329634666, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 72, train_loss = 1.3396946129505523, train_acc = 0.9966231951560317\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 73, train_loss = 1.3324237652122974, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 74, train_loss = 1.3235553142731078, train_acc = 0.9966231951560317\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 75, train_loss = 1.3137671388685703, train_acc = 0.9966231951560317\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 76, train_loss = 1.3085281935636885, train_acc = 0.9966231951560317\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 77, train_loss = 1.3028885771636851, train_acc = 0.9966231951560317\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 78, train_loss = 1.291500274091959, train_acc = 0.9966231951560317\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 79, train_loss = 1.2886025868356228, train_acc = 0.9966231951560317\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 80, train_loss = 1.280271155119408, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 81, train_loss = 1.2743316727282945, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 82, train_loss = 1.2659466452896595, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 83, train_loss = 1.2584548580052797, train_acc = 0.9967396367023754\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 84, train_loss = 1.2545964382588863, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 85, train_loss = 1.2473655069770757, train_acc = 0.9967396367023754\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 86, train_loss = 1.2430300253035966, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 87, train_loss = 1.2366694981756154, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 88, train_loss = 1.2317279664275702, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 89, train_loss = 1.2241094186902046, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 90, train_loss = 1.2203079139289912, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 91, train_loss = 1.2143961613473948, train_acc = 0.9968560782487191\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 92, train_loss = 1.208496263861889, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 93, train_loss = 1.2039659321308136, train_acc = 0.9968560782487191\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 94, train_loss = 1.199788107216591, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 95, train_loss = 1.196076283842558, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 96, train_loss = 1.1899774695339147, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 97, train_loss = 1.1861903915705625, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 98, train_loss = 1.1807241390051786, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 99, train_loss = 1.17748636379838, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 100, train_loss = 1.1712614285352174, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 101, train_loss = 1.1683933970925864, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 102, train_loss = 1.1659968396124896, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 103, train_loss = 1.1609969474375248, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 104, train_loss = 1.1569079706969205, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 105, train_loss = 1.1524358776805457, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 106, train_loss = 1.1501631985011045, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 107, train_loss = 1.145111121237278, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 108, train_loss = 1.140969848871464, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 109, train_loss = 1.1400046261551324, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 110, train_loss = 1.1346193378267344, train_acc = 0.9972054028877504\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 111, train_loss = 1.131228480488062, train_acc = 0.9972054028877504\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 112, train_loss = 1.1278427379729692, train_acc = 0.9972054028877504\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 113, train_loss = 1.1253721366229001, train_acc = 0.9972054028877504\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 114, train_loss = 1.1207050147058908, train_acc = 0.9972054028877504\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 115, train_loss = 1.1195666169223841, train_acc = 0.9972054028877504\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 116, train_loss = 1.1149304596183356, train_acc = 0.9972054028877504\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 117, train_loss = 1.1127760460076388, train_acc = 0.9972054028877504\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 118, train_loss = 1.110582035034895, train_acc = 0.9972054028877504\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 119, train_loss = 1.1070109444262926, train_acc = 0.9972054028877504\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 120, train_loss = 1.1045050298271235, train_acc = 0.9972054028877504\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 121, train_loss = 1.1013606836495455, train_acc = 0.9972054028877504\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 122, train_loss = 1.0992266933026258, train_acc = 0.9972054028877504\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 123, train_loss = 1.095712518930668, train_acc = 0.9972054028877504\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 124, train_loss = 1.0925527922809124, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 125, train_loss = 1.092329528182745, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 126, train_loss = 1.0884837421181146, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 127, train_loss = 1.0870115458965302, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 128, train_loss = 1.08335754647851, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 129, train_loss = 1.0817961009743158, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 130, train_loss = 1.0786599492130335, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 131, train_loss = 1.0769416814146098, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 132, train_loss = 1.0753849844186334, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 133, train_loss = 1.0723208896815777, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 134, train_loss = 1.070037682846305, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 135, train_loss = 1.0678010160772828, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 136, train_loss = 1.0650886185467243, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 137, train_loss = 1.0649392915220233, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 138, train_loss = 1.0625588831753703, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 139, train_loss = 1.060275753334281, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 140, train_loss = 1.0582841125578852, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 141, train_loss = 1.0568550589232473, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 142, train_loss = 1.054328850164893, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 143, train_loss = 1.0526944224984618, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 144, train_loss = 1.0511003881692886, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 145, train_loss = 1.05023655295372, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 146, train_loss = 1.046516085669282, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 147, train_loss = 1.0461596300156089, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 148, train_loss = 1.0434832560567884, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 149, train_loss = 1.0420572273433208, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 150, train_loss = 1.0403505476861028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 151, train_loss = 1.0379221041948767, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 152, train_loss = 1.0364874675869942, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 153, train_loss = 1.0344073015003232, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 154, train_loss = 1.0345467974693747, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 155, train_loss = 1.031713955104351, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 156, train_loss = 1.0295634443609742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 157, train_loss = 1.030053755894187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 158, train_loss = 1.026934967681882, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 159, train_loss = 1.0263427272439003, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 160, train_loss = 1.0269205582590075, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 161, train_loss = 1.023097988218069, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 162, train_loss = 1.0224631788878469, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 163, train_loss = 1.0209890988917323, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 164, train_loss = 1.0180714788584737, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 165, train_loss = 1.017338274672511, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 166, train_loss = 1.015342349812272, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 167, train_loss = 1.0151493561716052, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 168, train_loss = 1.015336078897235, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 169, train_loss = 1.0126161389052868, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 170, train_loss = 1.011305554464343, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 171, train_loss = 1.0093799332826165, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 172, train_loss = 1.008889393255231, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 173, train_loss = 1.0085465262382058, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 174, train_loss = 1.0055994962604018, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 175, train_loss = 1.0063203523604898, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 176, train_loss = 1.004118258759263, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 177, train_loss = 1.0023203343153, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 178, train_loss = 1.0014576464891434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 179, train_loss = 1.0009793415665627, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 180, train_loss = 0.9988898746669292, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 181, train_loss = 0.9999286706297426, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 182, train_loss = 0.9958680209965678, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 183, train_loss = 0.9957678044884233, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 184, train_loss = 0.995197934404132, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 185, train_loss = 0.9933887757360935, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 186, train_loss = 0.9937962740659714, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 187, train_loss = 0.9914655995817157, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 188, train_loss = 0.9909890107810497, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 189, train_loss = 0.9884745838789968, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 190, train_loss = 0.9891771860420704, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 191, train_loss = 0.9871566668152809, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 192, train_loss = 0.9868581369519234, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 193, train_loss = 0.9850265147833852, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 194, train_loss = 0.9846785341651412, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 195, train_loss = 0.9830030774028273, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 196, train_loss = 0.984122230365756, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 197, train_loss = 0.9806474298238754, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 198, train_loss = 0.9800138821155997, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 199, train_loss = 0.9802385407238035, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 200, train_loss = 0.9781546294689178, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 201, train_loss = 0.9791326932609081, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 202, train_loss = 0.9785620893089799, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 203, train_loss = 0.975763005510089, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 204, train_loss = 0.9762480556964874, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 205, train_loss = 0.974050585180521, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 206, train_loss = 0.9725574093608884, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 207, train_loss = 0.9728658559470205, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 208, train_loss = 0.9708824182598619, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 209, train_loss = 0.9713926129043102, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 210, train_loss = 0.969499143466237, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 211, train_loss = 0.9708086562604876, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 212, train_loss = 0.9673305948526831, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 213, train_loss = 0.9674566475005122, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 214, train_loss = 0.9672903182654409, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 215, train_loss = 0.965180054306984, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 216, train_loss = 0.964693742498639, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 217, train_loss = 0.9648939656763105, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 218, train_loss = 0.9630618393421173, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 219, train_loss = 0.9624880974442931, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 220, train_loss = 0.962853416800499, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 221, train_loss = 0.9600754044950008, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 222, train_loss = 0.9598644413053989, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 223, train_loss = 0.9600828054099111, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 224, train_loss = 0.9577610443084268, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 225, train_loss = 0.9573719414620427, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 226, train_loss = 0.957770299166441, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 227, train_loss = 0.955732237547636, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 228, train_loss = 0.9551930626184912, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 229, train_loss = 0.9564354829490185, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 230, train_loss = 0.9536529083998175, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 231, train_loss = 0.9530951455235481, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 232, train_loss = 0.9534256619663211, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 233, train_loss = 0.9514291770756245, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 234, train_loss = 0.9504528393299552, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 235, train_loss = 0.9506575676350622, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 236, train_loss = 0.9495216086506844, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 237, train_loss = 0.948665106043336, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 238, train_loss = 0.949260763823986, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 239, train_loss = 0.9474377085716696, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 240, train_loss = 0.9464432907552691, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 241, train_loss = 0.9468320484011201, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 242, train_loss = 0.9446547627449036, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 243, train_loss = 0.9456148619501619, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 244, train_loss = 0.9434987294225721, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 245, train_loss = 0.943579396858695, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 246, train_loss = 0.9436265875847312, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 247, train_loss = 0.9420638953597518, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 248, train_loss = 0.9424923521728488, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 249, train_loss = 0.9410442337393761, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 250, train_loss = 0.941131554543972, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 251, train_loss = 0.9405691611318616, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 252, train_loss = 0.9395218044519424, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 253, train_loss = 0.9392929623572854, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 254, train_loss = 0.9388633668422699, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 255, train_loss = 0.9382201681582956, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 256, train_loss = 0.9371385164558887, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 257, train_loss = 0.9384868095366983, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 258, train_loss = 0.9358552545309067, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 259, train_loss = 0.9350863546133041, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 260, train_loss = 0.9346460538654355, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 261, train_loss = 0.9342210131435422, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 262, train_loss = 0.933236173048499, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 263, train_loss = 0.9333096953778295, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 264, train_loss = 0.9324426092207432, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 265, train_loss = 0.9319001709372969, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 266, train_loss = 0.9310933935194043, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 267, train_loss = 0.9313976280391216, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 268, train_loss = 0.9302175727934809, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 269, train_loss = 0.9296907546668081, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 270, train_loss = 0.929360477879527, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 271, train_loss = 0.9287628084421158, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 272, train_loss = 0.9285172286181478, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 273, train_loss = 0.9273840325622587, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 274, train_loss = 0.9275043519883184, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 275, train_loss = 0.9260386452078819, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 276, train_loss = 0.9260861712245969, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 277, train_loss = 0.925086010247469, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 278, train_loss = 0.9250801218004199, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 279, train_loss = 0.9247727319598198, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 280, train_loss = 0.9238330759108067, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 281, train_loss = 0.9238123806862859, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 282, train_loss = 0.9237506079225568, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 283, train_loss = 0.9225496637372999, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 284, train_loss = 0.9221731834113598, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 285, train_loss = 0.9213272209017305, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 286, train_loss = 0.9227868566958932, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 287, train_loss = 0.920964544013259, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 288, train_loss = 0.9206499109714059, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 289, train_loss = 0.9199923314154148, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 290, train_loss = 0.9195953359158011, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 291, train_loss = 0.9188793028442888, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 292, train_loss = 0.9188323480339022, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 293, train_loss = 0.9181752614676952, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 294, train_loss = 0.9176915213465691, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 295, train_loss = 0.9168835058808327, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 296, train_loss = 0.9172748463897733, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 297, train_loss = 0.9167911782860756, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 298, train_loss = 0.9161628236324759, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 299, train_loss = 0.9156427209527465, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 300, train_loss = 0.9157284398825141, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 301, train_loss = 0.9147134646773338, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 302, train_loss = 0.914410109326127, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 303, train_loss = 0.9135283244177117, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 304, train_loss = 0.9135152089074836, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 305, train_loss = 0.9132779464125633, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 306, train_loss = 0.9123917395918397, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 307, train_loss = 0.9119949117302895, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 308, train_loss = 0.9118381589651108, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 309, train_loss = 0.911175920315145, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 310, train_loss = 0.9108363762497902, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 311, train_loss = 0.9106450031176792, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 312, train_loss = 0.9102691536172642, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 313, train_loss = 0.9097608899101033, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 314, train_loss = 0.9091307781636715, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 315, train_loss = 0.9106761527582421, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 316, train_loss = 0.9085364639759064, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 317, train_loss = 0.908414247132896, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 318, train_loss = 0.9083654433488846, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 319, train_loss = 0.9077614645138965, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 320, train_loss = 0.9075113795697689, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 321, train_loss = 0.9070269390940666, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 322, train_loss = 0.9073586240410805, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 323, train_loss = 0.9069264394565835, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 324, train_loss = 0.906953252851963, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 325, train_loss = 0.9055664812549367, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 326, train_loss = 0.905869372189045, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 327, train_loss = 0.9059585680588498, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 328, train_loss = 0.9052475939170108, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 329, train_loss = 0.9048052790240035, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 330, train_loss = 0.9042044679299579, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 331, train_loss = 0.9047965543941245, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 332, train_loss = 0.9037924446165562, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 333, train_loss = 0.9031340281144367, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 334, train_loss = 0.9031266632155166, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 335, train_loss = 0.9028248613103642, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 336, train_loss = 0.9022507195695653, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 337, train_loss = 0.9021344085558667, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 338, train_loss = 0.9016264639794827, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 339, train_loss = 0.9021056021229015, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 340, train_loss = 0.9012881269081845, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 341, train_loss = 0.901200777538179, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 342, train_loss = 0.9007513585165725, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 343, train_loss = 0.9010320914312615, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 344, train_loss = 0.8995070022865548, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 345, train_loss = 0.901177603751421, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 346, train_loss = 0.8996699514464126, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 347, train_loss = 0.9001190451308503, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 348, train_loss = 0.8988707028329372, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 349, train_loss = 0.8985796757042408, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 350, train_loss = 0.8992455253974185, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 351, train_loss = 0.8981051978989854, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 352, train_loss = 0.897668066121696, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 353, train_loss = 0.897431667894125, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 354, train_loss = 0.8968415074050426, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 355, train_loss = 0.8973060958087444, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 356, train_loss = 0.8965616660789237, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 357, train_loss = 0.8963053598999977, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 358, train_loss = 0.8958724637850537, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 359, train_loss = 0.8957265304998145, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 360, train_loss = 0.8955797702074051, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 361, train_loss = 0.895381610840559, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 362, train_loss = 0.89457329610741, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 363, train_loss = 0.8946495292111649, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 364, train_loss = 0.894490297883749, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 365, train_loss = 0.8940160634592758, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 366, train_loss = 0.8938208694235072, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 367, train_loss = 0.893453390650393, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 368, train_loss = 0.8933236437515006, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 369, train_loss = 0.893313101179956, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 370, train_loss = 0.8927579075098038, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 371, train_loss = 0.893135247133614, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 372, train_loss = 0.8918839295729413, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 373, train_loss = 0.8921136346980347, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 374, train_loss = 0.8920973700805916, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 375, train_loss = 0.8914191089570522, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 376, train_loss = 0.891501826547028, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 377, train_loss = 0.8907693140208721, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 378, train_loss = 0.8910108233467326, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 379, train_loss = 0.8910956084728241, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 380, train_loss = 0.8903821843341575, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 381, train_loss = 0.891206124179007, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 382, train_loss = 0.8899471548720612, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 383, train_loss = 0.8900322789922939, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 384, train_loss = 0.8893337696790695, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 385, train_loss = 0.8892792140468373, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 386, train_loss = 0.888785836599709, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 387, train_loss = 0.8891979840918793, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 388, train_loss = 0.8883385745211854, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 389, train_loss = 0.888287370406033, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 390, train_loss = 0.8877507323995815, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 391, train_loss = 0.8882717800661339, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 392, train_loss = 0.8876569084823132, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 393, train_loss = 0.887345361210464, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 394, train_loss = 0.8874192722141743, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 395, train_loss = 0.8872450341805234, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 396, train_loss = 0.8865597657859325, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 397, train_loss = 0.8868232456370606, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 398, train_loss = 0.8861670618280186, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 399, train_loss = 0.8864354478791938, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 400, train_loss = 0.885725407548307, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 401, train_loss = 0.8859423920512199, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 402, train_loss = 0.8858655815347447, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 403, train_loss = 0.8853797403498902, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 404, train_loss = 0.8852858866230235, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 405, train_loss = 0.8846276303156628, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 406, train_loss = 0.884842436760664, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 407, train_loss = 0.884975233428122, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 408, train_loss = 0.8842877435163246, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 409, train_loss = 0.8840901950970874, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 410, train_loss = 0.8849631498233066, train_acc = 0.9982533768048439\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 411, train_loss = 0.8840760091916309, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 412, train_loss = 0.8840869876221404, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 413, train_loss = 0.8835161601527943, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 414, train_loss = 0.8839332784191356, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 415, train_loss = 0.8832826179786935, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 416, train_loss = 0.8828740641474724, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 417, train_loss = 0.8829362454489456, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 418, train_loss = 0.8823395570143475, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 419, train_loss = 0.8823644568547024, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 420, train_loss = 0.8825636158362613, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 421, train_loss = 0.8815495471135364, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 422, train_loss = 0.8835555538535118, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 423, train_loss = 0.8820951556190266, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 424, train_loss = 0.8818014065400348, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 425, train_loss = 0.8816251431926503, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 426, train_loss = 0.8810949487015023, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 427, train_loss = 0.8811049833893776, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 428, train_loss = 0.8806438284591422, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 429, train_loss = 0.8815868993624463, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 430, train_loss = 0.8807150237262249, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 431, train_loss = 0.8805207436307683, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 432, train_loss = 0.8799780383706093, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 433, train_loss = 0.8800120279192924, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 434, train_loss = 0.879883178822638, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 435, train_loss = 0.8809270324782119, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 436, train_loss = 0.8796843600794091, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 437, train_loss = 0.8794100930317654, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 438, train_loss = 0.8792032996789203, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 439, train_loss = 0.8788938770667301, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 440, train_loss = 0.8791797223166213, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 441, train_loss = 0.8786787539720535, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 442, train_loss = 0.8786908698602929, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 443, train_loss = 0.8785221526995883, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 444, train_loss = 0.8779591172933578, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 445, train_loss = 0.8785706659182324, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 446, train_loss = 0.8789946250617504, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 447, train_loss = 0.8777112228199258, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 448, train_loss = 0.8778346578255878, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 449, train_loss = 0.8775855600833893, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 450, train_loss = 0.8774349018931389, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 451, train_loss = 0.8771681897342205, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 452, train_loss = 0.8770866083577857, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 453, train_loss = 0.8767704268320813, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 454, train_loss = 0.8769222671762691, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 455, train_loss = 0.8766794291659608, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 456, train_loss = 0.8764772688373341, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 457, train_loss = 0.8762372769415379, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 458, train_loss = 0.8758651862517581, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 459, train_loss = 0.8757995453997864, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 460, train_loss = 0.8762457681223168, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 461, train_loss = 0.876863536737801, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 462, train_loss = 0.8756533550695167, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 463, train_loss = 0.8755741268396378, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 464, train_loss = 0.8754423148930073, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 465, train_loss = 0.8754932545125484, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 466, train_loss = 0.8751450491472497, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 467, train_loss = 0.8745247994884267, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 468, train_loss = 0.8761960814372287, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 469, train_loss = 0.8743999066427932, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 470, train_loss = 0.8743821221069084, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 471, train_loss = 0.8746581350787892, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 472, train_loss = 0.8739765783175244, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 473, train_loss = 0.8737031668424606, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 474, train_loss = 0.8742723750547157, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 475, train_loss = 0.8737248492761864, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 476, train_loss = 0.8733651575967087, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 477, train_loss = 0.8736263811588287, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 478, train_loss = 0.8731350724920048, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 479, train_loss = 0.8731654845178127, train_acc = 0.9983698183511877\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 480, train_loss = 0.8729717669411912, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 481, train_loss = 0.8731999086812721, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 482, train_loss = 0.8728966899216175, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 483, train_loss = 0.8728198570534005, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 484, train_loss = 0.8729111154898419, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 485, train_loss = 0.8723754199818359, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 486, train_loss = 0.8723268819376244, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 487, train_loss = 0.8723424052222981, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 488, train_loss = 0.8719691100195632, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 489, train_loss = 0.8721532908602967, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 490, train_loss = 0.8718673810362816, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 491, train_loss = 0.8716228579505696, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 492, train_loss = 0.8722298455759301, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 493, train_loss = 0.8711150934323086, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 494, train_loss = 0.8711601408795104, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 495, train_loss = 0.871207403637527, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 496, train_loss = 0.8711929023265839, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 497, train_loss = 0.8711485105231986, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 498, train_loss = 0.8709012952967896, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 499, train_loss = 0.8708757547065034, train_acc = 0.9983698183511877\n",
      "test Acc 0.9706703910614525:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|█████████████████████████▎                                                  | 10/30 [1:31:54<3:09:31, 568.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "11th- epoch: 0, train_loss = 324.17337876558304, train_acc = 0.8161387983232418\n",
      "test Acc 0.8347299813780261:\n",
      "11th- epoch: 1, train_loss = 79.9767304584384, train_acc = 0.927806241266884\n",
      "test Acc 0.9017690875232774:\n",
      "11th- epoch: 2, train_loss = 51.730346811935306, train_acc = 0.9459711224965067\n",
      "test Acc 0.9380819366852886:\n",
      "11th- epoch: 3, train_loss = 36.51316404528916, train_acc = 0.96040987424313\n",
      "test Acc 0.9427374301675978:\n",
      "11th- epoch: 4, train_loss = 27.48288258165121, train_acc = 0.9678621332091291\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 5, train_loss = 21.165826222626492, train_acc = 0.9739170936190032\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 6, train_loss = 16.755355628905818, train_acc = 0.9777596646483465\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 7, train_loss = 13.547526727081276, train_acc = 0.9814857941313461\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 8, train_loss = 11.22453272587154, train_acc = 0.9843968327899395\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 9, train_loss = 9.405018974095583, train_acc = 0.9855612482533768\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 10, train_loss = 8.033724612207152, train_acc = 0.9868421052631579\n",
      "test Acc 0.9548417132216015:\n",
      "11th- epoch: 11, train_loss = 6.924434632062912, train_acc = 0.9887051700046576\n",
      "test Acc 0.957169459962756:\n",
      "11th- epoch: 12, train_loss = 6.080240186303854, train_acc = 0.98940381928272\n",
      "test Acc 0.957635009310987:\n",
      "11th- epoch: 13, train_loss = 5.406618663400877, train_acc = 0.9905682347461574\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 14, train_loss = 4.936683516949415, train_acc = 0.9916162086632511\n",
      "test Acc 0.9604283054003724:\n",
      "11th- epoch: 15, train_loss = 4.507803200453054, train_acc = 0.9924312994876572\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 16, train_loss = 4.164186964451801, train_acc = 0.9930135072193759\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 17, train_loss = 3.8958330911700614, train_acc = 0.9934792734047508\n",
      "test Acc 0.9604283054003724:\n",
      "11th- epoch: 18, train_loss = 3.6722426203195937, train_acc = 0.9937121564974383\n",
      "test Acc 0.9608938547486033:\n",
      "11th- epoch: 19, train_loss = 3.4409246034920216, train_acc = 0.9937121564974383\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 20, train_loss = 3.2455210089683533, train_acc = 0.9939450395901258\n",
      "test Acc 0.9608938547486033:\n",
      "11th- epoch: 21, train_loss = 3.0524856373667717, train_acc = 0.9939450395901258\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 22, train_loss = 2.9115568809211254, train_acc = 0.9945272473218444\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 23, train_loss = 2.762749880552292, train_acc = 0.9946436888681882\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 24, train_loss = 2.637216663628351, train_acc = 0.9947601304145319\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 25, train_loss = 2.54023839533329, train_acc = 0.9948765719608756\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 26, train_loss = 2.437685531855095, train_acc = 0.9949930135072194\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 27, train_loss = 2.347260285168886, train_acc = 0.9949930135072194\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 28, train_loss = 2.2563265984063037, train_acc = 0.9949930135072194\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 29, train_loss = 2.192289230704773, train_acc = 0.9951094550535631\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 30, train_loss = 2.1043459748034365, train_acc = 0.9951094550535631\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 31, train_loss = 2.0546563963289373, train_acc = 0.9952258965999069\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 32, train_loss = 1.9781510879402049, train_acc = 0.9953423381462506\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 33, train_loss = 1.9214969351887703, train_acc = 0.9954587796925943\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 34, train_loss = 1.8694272103602998, train_acc = 0.995575221238938\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 35, train_loss = 1.8165917731821537, train_acc = 0.9956916627852818\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 36, train_loss = 1.7703635729849339, train_acc = 0.9956916627852818\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 37, train_loss = 1.73604142293334, train_acc = 0.9961574289706567\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 38, train_loss = 1.7040411879715975, train_acc = 0.9962738705170004\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 39, train_loss = 1.6711008436977863, train_acc = 0.9962738705170004\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 40, train_loss = 1.6444022481737193, train_acc = 0.9963903120633442\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 41, train_loss = 1.6223513955774251, train_acc = 0.996506753609688\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 42, train_loss = 1.5977178663015366, train_acc = 0.996506753609688\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 43, train_loss = 1.5786437131464481, train_acc = 0.996506753609688\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 44, train_loss = 1.5540352948009968, train_acc = 0.9966231951560317\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 45, train_loss = 1.542437126248842, train_acc = 0.9966231951560317\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 46, train_loss = 1.5237492384912912, train_acc = 0.9967396367023754\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 47, train_loss = 1.5075967547891196, train_acc = 0.9967396367023754\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 48, train_loss = 1.496033230170724, train_acc = 0.9967396367023754\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 49, train_loss = 1.4778717085719109, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 50, train_loss = 1.469740990549326, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 51, train_loss = 1.454372864216566, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 52, train_loss = 1.4411538019776344, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 53, train_loss = 1.4241562436072854, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 54, train_loss = 1.4179037387220887, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 55, train_loss = 1.398702409118414, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 56, train_loss = 1.391739148646593, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 57, train_loss = 1.3822064263076754, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 58, train_loss = 1.3677094715385465, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 59, train_loss = 1.3592408746480942, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 60, train_loss = 1.3551176215260057, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 61, train_loss = 1.3417098534555407, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 62, train_loss = 1.3333132155239582, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 63, train_loss = 1.3286045106724487, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 64, train_loss = 1.3166348723098054, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 65, train_loss = 1.31090771779418, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 66, train_loss = 1.303078925855516, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 67, train_loss = 1.295255788914801, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 68, train_loss = 1.2879157215356827, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 69, train_loss = 1.2797031365334988, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 70, train_loss = 1.2758546260520234, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 71, train_loss = 1.2691096998751163, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 72, train_loss = 1.262262220181583, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 73, train_loss = 1.2545368323699222, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 74, train_loss = 1.250343170017004, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 75, train_loss = 1.2440338010565029, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 76, train_loss = 1.2390072544440045, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 77, train_loss = 1.2327919776216731, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 78, train_loss = 1.2260454669594765, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 79, train_loss = 1.2203632183372974, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 80, train_loss = 1.2154627951458679, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 81, train_loss = 1.2107734071687446, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 82, train_loss = 1.204288899898529, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 83, train_loss = 1.1972333565354347, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 84, train_loss = 1.1941048415974365, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 85, train_loss = 1.191194899380207, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 86, train_loss = 1.1827417835593224, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 87, train_loss = 1.1787447805181728, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 88, train_loss = 1.1731995679438114, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 89, train_loss = 1.1694106298164115, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 90, train_loss = 1.1645787532143004, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 91, train_loss = 1.160362603764952, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 92, train_loss = 1.156840831041336, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 93, train_loss = 1.1525136555246718, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 94, train_loss = 1.1473959932736761, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 95, train_loss = 1.143392509471596, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 96, train_loss = 1.1401975825428963, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 97, train_loss = 1.1363958977162838, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 98, train_loss = 1.1328160539269447, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 99, train_loss = 1.128189089398802, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 100, train_loss = 1.1247212290763855, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 101, train_loss = 1.121281151969015, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 102, train_loss = 1.1175494939088821, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 103, train_loss = 1.1141767563931353, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 104, train_loss = 1.1111137395091646, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 105, train_loss = 1.107078147430002, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 106, train_loss = 1.1052647729702585, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 107, train_loss = 1.1027869830541022, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 108, train_loss = 1.099585282307089, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 109, train_loss = 1.094896907608927, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 110, train_loss = 1.090841850887955, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 111, train_loss = 1.0855373603590124, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 112, train_loss = 1.0813332150391943, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 113, train_loss = 1.0778847336769104, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 114, train_loss = 1.07871151963991, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 115, train_loss = 1.0753892200700648, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 116, train_loss = 1.071401707828045, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 117, train_loss = 1.070071280002594, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 118, train_loss = 1.0665374075360887, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 119, train_loss = 1.0636451058089733, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 120, train_loss = 1.0623680117241747, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 121, train_loss = 1.0591437344737642, train_acc = 0.9972054028877504\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 122, train_loss = 1.0565202993639105, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 123, train_loss = 1.0542626480273611, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 124, train_loss = 1.052904274314642, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 125, train_loss = 1.051321050774277, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 126, train_loss = 1.0492654293775558, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 127, train_loss = 1.0495682706423395, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 128, train_loss = 1.0452967385444936, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 129, train_loss = 1.0451275656614598, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 130, train_loss = 1.0416215360164642, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 131, train_loss = 1.0414679050445557, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 132, train_loss = 1.0387961864471436, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 133, train_loss = 1.0370463368799392, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 134, train_loss = 1.0342058303449448, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 135, train_loss = 1.0346232652664185, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 136, train_loss = 1.0318836756050587, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 137, train_loss = 1.0311879254877567, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 138, train_loss = 1.0282028975580033, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 139, train_loss = 1.0273795338962373, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 140, train_loss = 1.0265148604903516, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 141, train_loss = 1.023301734277993, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 142, train_loss = 1.0233082957565784, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 143, train_loss = 1.0199023758377734, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 144, train_loss = 1.0199058701600734, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 145, train_loss = 1.0174965833630267, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 146, train_loss = 1.0170305271949474, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 147, train_loss = 1.0151037598643597, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 148, train_loss = 1.0142091227080527, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 149, train_loss = 1.0119267304744426, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 150, train_loss = 1.010624216249198, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 151, train_loss = 1.0110823052618798, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 152, train_loss = 1.0069352264199551, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 153, train_loss = 1.0074269945416745, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 154, train_loss = 1.0050371202323731, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 155, train_loss = 1.0045673437416553, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 156, train_loss = 1.0022113360464573, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 157, train_loss = 1.0043005396928493, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 158, train_loss = 1.0001618154346943, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 159, train_loss = 0.9995663116369542, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 160, train_loss = 0.9983886952195462, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 161, train_loss = 0.9974471392724809, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 162, train_loss = 0.9948160288240615, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 163, train_loss = 0.9945300084855262, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 164, train_loss = 0.9935541773829755, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 165, train_loss = 0.9922303011026088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 166, train_loss = 0.9904824209716026, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 167, train_loss = 0.9894389845430851, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 168, train_loss = 0.9885780960321426, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 169, train_loss = 0.9870738474037353, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 170, train_loss = 0.9866034115348157, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 171, train_loss = 0.985425225147992, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 172, train_loss = 0.9854546636343002, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 173, train_loss = 0.983715242395192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 174, train_loss = 0.9825587210561935, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 175, train_loss = 0.9815803517903987, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 176, train_loss = 0.9799554012715816, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 177, train_loss = 0.9795017577707767, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 178, train_loss = 0.9792644865810871, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 179, train_loss = 0.9772320985794067, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 180, train_loss = 0.9760839951541129, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 181, train_loss = 0.9751287239287194, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 182, train_loss = 0.9742668482158479, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 183, train_loss = 0.9728424338009063, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 184, train_loss = 0.9733954245839413, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 185, train_loss = 0.9720135567094985, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 186, train_loss = 0.9711669931803044, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 187, train_loss = 0.969581143310279, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 188, train_loss = 0.9692713829372224, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 189, train_loss = 0.9683939802143868, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 190, train_loss = 0.9670806328449544, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 191, train_loss = 0.9665148817002773, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 192, train_loss = 0.9666595707330998, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 193, train_loss = 0.9648071229457855, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 194, train_loss = 0.9645997000243369, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 195, train_loss = 0.9640213859584037, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 196, train_loss = 0.961486200490981, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 197, train_loss = 0.9615923898909386, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 198, train_loss = 0.9610051947329339, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 199, train_loss = 0.9609683963153657, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 200, train_loss = 0.9597526465859119, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 201, train_loss = 0.9580479798223678, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 202, train_loss = 0.9575058408081532, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 203, train_loss = 0.9563777496423427, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 204, train_loss = 0.955501892914981, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 205, train_loss = 0.9553923631701764, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 206, train_loss = 0.9549722311403457, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 207, train_loss = 0.9532904165480431, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 208, train_loss = 0.9541705101728439, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 209, train_loss = 0.9515387130286399, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 210, train_loss = 0.9518220275640488, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 211, train_loss = 0.9508064302299317, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 212, train_loss = 0.9509394528959092, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 213, train_loss = 0.950771859535962, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 214, train_loss = 0.9493621525671188, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 215, train_loss = 0.9484337096409945, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 216, train_loss = 0.9475389569997787, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 217, train_loss = 0.9473265198366789, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 218, train_loss = 0.9464081910746245, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 219, train_loss = 0.9445508643984795, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 220, train_loss = 0.945034496486187, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 221, train_loss = 0.9445567155880781, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 222, train_loss = 0.9441249892115593, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 223, train_loss = 0.9434440582990646, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 224, train_loss = 0.9415845746798368, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 225, train_loss = 0.9434431145591589, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 226, train_loss = 0.941080680738196, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 227, train_loss = 0.9396551474928856, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 228, train_loss = 0.9387527219951153, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 229, train_loss = 0.9398049538331179, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 230, train_loss = 0.939096235980287, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 231, train_loss = 0.9385390914976597, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 232, train_loss = 0.9383267660932688, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 233, train_loss = 0.9368334859609604, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 234, train_loss = 0.9365243390202522, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 235, train_loss = 0.9358201523618845, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 236, train_loss = 0.9356976027293058, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 237, train_loss = 0.9350209422409534, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 238, train_loss = 0.9344023192925306, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 239, train_loss = 0.93249536926578, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 240, train_loss = 0.9347861595451832, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 241, train_loss = 0.9337897015111594, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 242, train_loss = 0.9334695090847163, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 243, train_loss = 0.9314894750714302, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 244, train_loss = 0.9319269570214601, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 245, train_loss = 0.9314110788209291, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 246, train_loss = 0.9307583086192608, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 247, train_loss = 0.9294795903069826, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 248, train_loss = 0.9299925193190575, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 249, train_loss = 0.9296153262257576, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 250, train_loss = 0.9287205673754215, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 251, train_loss = 0.9290499563021513, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 252, train_loss = 0.9269768819212914, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 253, train_loss = 0.9275627161068769, train_acc = 0.9976711690731253\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 254, train_loss = 0.9279053745167403, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 255, train_loss = 0.9257204458117485, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 256, train_loss = 0.9261808718247266, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 257, train_loss = 0.9262332320213318, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 258, train_loss = 0.9252179923159929, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 259, train_loss = 0.9249709832174631, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 260, train_loss = 0.9234687946736813, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 261, train_loss = 0.9229496133821158, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 262, train_loss = 0.9239872569842191, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 263, train_loss = 0.9232507559163423, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 264, train_loss = 0.9229965445892958, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 265, train_loss = 0.9225276373326778, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 266, train_loss = 0.9222321833176466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 267, train_loss = 0.9212798774242401, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 268, train_loss = 0.921476484586492, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 269, train_loss = 0.9200168425841184, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 270, train_loss = 0.9215091206133366, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 271, train_loss = 0.9193556793034077, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 272, train_loss = 0.9203074499964714, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 273, train_loss = 0.9193040691316128, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 274, train_loss = 0.9199488436179308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 275, train_loss = 0.917335756123066, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 276, train_loss = 0.920192802946076, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 277, train_loss = 0.9172626622021198, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 278, train_loss = 0.918399266898632, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 279, train_loss = 0.9170842543244362, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 280, train_loss = 0.9187902112798838, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 281, train_loss = 0.9164249027771803, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 282, train_loss = 0.9162730711204858, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 283, train_loss = 0.9157289986806063, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 284, train_loss = 0.9173895046114922, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 285, train_loss = 0.9145829578237681, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 286, train_loss = 0.9148749001324177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 287, train_loss = 0.9164156938595625, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 288, train_loss = 0.9152933868272157, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 289, train_loss = 0.9155173872904925, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 290, train_loss = 0.915408982585177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 291, train_loss = 0.9129404711229654, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 292, train_loss = 0.9124627560377121, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 293, train_loss = 0.9137942741317602, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 294, train_loss = 0.9135825770599695, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 295, train_loss = 0.9120431343717428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 296, train_loss = 0.9126093549029974, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 297, train_loss = 0.9119452784461828, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 298, train_loss = 0.9118136639399381, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 299, train_loss = 0.9136161915957928, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 300, train_loss = 0.9109820400672106, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 301, train_loss = 0.9110533632338047, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 302, train_loss = 0.9109651048975138, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 303, train_loss = 0.9095401912927628, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 304, train_loss = 0.9103219484286456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 305, train_loss = 0.909388990451589, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 306, train_loss = 0.9111650524037032, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 307, train_loss = 0.9088964735465197, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 308, train_loss = 0.9092026439802794, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 309, train_loss = 0.9095256924629211, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 310, train_loss = 0.9081873471541257, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 311, train_loss = 0.9087469143169074, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 312, train_loss = 0.9082359907524733, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 313, train_loss = 0.9077538835508676, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 314, train_loss = 0.9081706864135413, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 315, train_loss = 0.9071376907331796, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 316, train_loss = 0.9087379947304726, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 317, train_loss = 0.9077305371565672, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 318, train_loss = 0.9069507954018263, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 319, train_loss = 0.9079604484140873, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 320, train_loss = 0.9054418479399828, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 321, train_loss = 0.9059351508813052, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 322, train_loss = 0.9086433661477713, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 323, train_loss = 0.9073948437971922, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 324, train_loss = 0.9062939571840616, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 325, train_loss = 0.905658173064694, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 326, train_loss = 0.9057239418225436, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 327, train_loss = 0.9057814665138721, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 328, train_loss = 0.9053743854165077, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 329, train_loss = 0.9052063673734665, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 330, train_loss = 0.9056855688495489, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 331, train_loss = 0.9034428298473358, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 332, train_loss = 0.903303038328886, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 333, train_loss = 0.9040169107420297, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 334, train_loss = 0.9038815870881081, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 335, train_loss = 0.9046524427831173, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 336, train_loss = 0.9034951602416186, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 337, train_loss = 0.9038229187326579, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 338, train_loss = 0.904741533100605, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 339, train_loss = 0.9047872064011244, train_acc = 0.9979040521658128\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 340, train_loss = 0.9039358446998449, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 341, train_loss = 0.9038408423466535, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 342, train_loss = 0.9037039217846541, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 343, train_loss = 0.901008201141849, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 344, train_loss = 0.9024325447780939, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 345, train_loss = 0.9007451422512531, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 346, train_loss = 0.902602167178884, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 347, train_loss = 0.9030049666762352, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 348, train_loss = 0.90277399122715, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 349, train_loss = 0.9018211451666502, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 350, train_loss = 0.9022762663662434, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 351, train_loss = 0.9016340685384421, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 352, train_loss = 0.9029853418469429, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 353, train_loss = 0.9019955607755037, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 354, train_loss = 0.9023091085255146, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 355, train_loss = 0.9002294205129147, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 356, train_loss = 0.9010311961174011, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 357, train_loss = 0.8997633767621664, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 358, train_loss = 0.9008080686135145, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 359, train_loss = 0.8994656677050443, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 360, train_loss = 0.8999929067986159, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 361, train_loss = 0.8993569662170557, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 362, train_loss = 0.8985205541057439, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 363, train_loss = 0.9005357461674066, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 364, train_loss = 0.8997600873308329, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 365, train_loss = 0.8987065677838473, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 366, train_loss = 0.9018432584898619, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 367, train_loss = 0.8992059069378229, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 368, train_loss = 0.8981440750258116, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 369, train_loss = 0.8973992777364401, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 370, train_loss = 0.8980087873833327, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 371, train_loss = 0.8981731186313482, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 372, train_loss = 0.8975886876387449, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 373, train_loss = 0.898553726573482, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 374, train_loss = 0.8975910519557146, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 375, train_loss = 0.8988144832355829, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 376, train_loss = 0.8968966094153075, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 377, train_loss = 0.8985723343985228, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 378, train_loss = 0.8963508258266302, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 379, train_loss = 0.8966352343559265, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 380, train_loss = 0.896629836410284, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 381, train_loss = 0.8962169823544173, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 382, train_loss = 0.8971819827957006, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 383, train_loss = 0.8953335533542486, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 384, train_loss = 0.8971220018966051, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 385, train_loss = 0.8955743089318275, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 386, train_loss = 0.8962982073426247, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 387, train_loss = 0.8953530639410019, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 388, train_loss = 0.8951449058949947, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 389, train_loss = 0.8960146407289358, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 390, train_loss = 0.8975301223499628, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 391, train_loss = 0.8938580565154552, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 392, train_loss = 0.894374841202989, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 393, train_loss = 0.8964151317877622, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 394, train_loss = 0.8938096252577452, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 395, train_loss = 0.8947389113409372, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 396, train_loss = 0.8942792788147926, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 397, train_loss = 0.8930051637189536, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 398, train_loss = 0.8960012830793858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 399, train_loss = 0.8937321814401002, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 400, train_loss = 0.892756098260179, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 401, train_loss = 0.8950192617876382, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 402, train_loss = 0.8914831466972828, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 403, train_loss = 0.8934768326580524, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 404, train_loss = 0.8923617204027323, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 405, train_loss = 0.8946422698600145, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 406, train_loss = 0.8931328766047955, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 407, train_loss = 0.8916971944272518, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 408, train_loss = 0.8910148267941622, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 409, train_loss = 0.8931967231137605, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 410, train_loss = 0.8906161747872829, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 411, train_loss = 0.8931171533959059, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 412, train_loss = 0.8933605924248695, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 413, train_loss = 0.8915349182980208, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 414, train_loss = 0.8913882598280907, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 415, train_loss = 0.8918063007295132, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 416, train_loss = 0.8919075578451157, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 417, train_loss = 0.891344164808288, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 418, train_loss = 0.8897094155354353, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 419, train_loss = 0.8920884144799857, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 420, train_loss = 0.8909949387116285, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 421, train_loss = 0.8898251950740814, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 422, train_loss = 0.8916386775672436, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 423, train_loss = 0.8896934936446996, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 424, train_loss = 0.88686952988337, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 425, train_loss = 0.8898631259799004, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 426, train_loss = 0.8893655315041542, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 427, train_loss = 0.8901623350875525, train_acc = 0.9979040521658128\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 428, train_loss = 0.8899440939230772, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 429, train_loss = 0.8888306344551893, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 430, train_loss = 0.8908138250308184, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 431, train_loss = 0.8905670618014483, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 432, train_loss = 0.8890087629361005, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 433, train_loss = 0.8863593861460686, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 434, train_loss = 0.8895586244761944, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 435, train_loss = 0.8886190156144949, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 436, train_loss = 0.8896161479251532, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 437, train_loss = 0.8860899979872556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 438, train_loss = 0.8878500970704408, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 439, train_loss = 0.8901964649558067, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 440, train_loss = 0.8889680306119772, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 441, train_loss = 0.8879015619559141, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 442, train_loss = 0.8839001767337322, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 443, train_loss = 0.8875023797154427, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 444, train_loss = 0.8895476559800954, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 445, train_loss = 0.8887227699160576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 446, train_loss = 0.8874860554933548, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 447, train_loss = 0.8870532922446728, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 448, train_loss = 0.887811926503673, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 449, train_loss = 0.8890611914293913, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 450, train_loss = 0.8863994417088179, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 451, train_loss = 0.8891224712133408, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 452, train_loss = 0.8868729298310427, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 453, train_loss = 0.8845811672508717, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 454, train_loss = 0.8868496616678385, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 455, train_loss = 0.8879811229808183, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 456, train_loss = 0.8859570448594241, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 457, train_loss = 0.8866807570057063, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 458, train_loss = 0.8894476021332594, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 459, train_loss = 0.8840579030411391, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 460, train_loss = 0.8869342220323233, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 461, train_loss = 0.8878284605843874, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 462, train_loss = 0.8848253786563873, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 463, train_loss = 0.8857045186059622, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 464, train_loss = 0.8844379534320979, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 465, train_loss = 0.8845560128493162, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 466, train_loss = 0.8874210280673651, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 467, train_loss = 0.8868852506084295, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 468, train_loss = 0.8842649199068546, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 469, train_loss = 0.8859507242841573, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 470, train_loss = 0.8806403838098049, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 471, train_loss = 0.8848456330597401, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 472, train_loss = 0.8825931387646051, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 473, train_loss = 0.8846080514294954, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 474, train_loss = 0.8824436664581299, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 475, train_loss = 0.881314143538475, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 476, train_loss = 0.8854267324013563, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 477, train_loss = 0.8851289339363575, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 478, train_loss = 0.8850478753447533, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 479, train_loss = 0.8830385419232698, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 480, train_loss = 0.8818177618086338, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 481, train_loss = 0.8805795796215534, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 482, train_loss = 0.879412017762661, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 483, train_loss = 0.881643995642662, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 484, train_loss = 0.8847394722206445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 485, train_loss = 0.8844442963600159, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 486, train_loss = 0.8850916872424932, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 487, train_loss = 0.8833292586105017, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 488, train_loss = 0.8799082338809967, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 489, train_loss = 0.8842032949132772, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 490, train_loss = 0.8851184075074343, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 491, train_loss = 0.8821722542243151, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 492, train_loss = 0.8804263472557068, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 493, train_loss = 0.8849679753184319, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 494, train_loss = 0.8843373283743858, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 495, train_loss = 0.8845560488598494, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 496, train_loss = 0.8802248165011406, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 497, train_loss = 0.8813109608990999, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 498, train_loss = 0.8819993088645788, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 499, train_loss = 0.8846764775616975, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███████████████████████████▊                                                | 11/30 [1:42:12<3:04:40, 583.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "12th- epoch: 0, train_loss = 353.95555806159973, train_acc = 0.8295295761527713\n",
      "test Acc 0.9017690875232774:\n",
      "12th- epoch: 1, train_loss = 68.61716855072882, train_acc = 0.9315323707498836\n",
      "test Acc 0.9278398510242085:\n",
      "12th- epoch: 2, train_loss = 43.171240244060755, train_acc = 0.9514438751746623\n",
      "test Acc 0.936219739292365:\n",
      "12th- epoch: 3, train_loss = 30.994490640237927, train_acc = 0.9612249650675361\n",
      "test Acc 0.9432029795158287:\n",
      "12th- epoch: 4, train_loss = 23.680889220908284, train_acc = 0.9685607824871915\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 5, train_loss = 18.384136084467173, train_acc = 0.974033535165347\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 6, train_loss = 14.570686627645046, train_acc = 0.9782254308337215\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 7, train_loss = 11.778602657839656, train_acc = 0.9810200279459711\n",
      "test Acc 0.9534450651769087:\n",
      "12th- epoch: 8, train_loss = 9.649394561070949, train_acc = 0.9828830926874709\n",
      "test Acc 0.9548417132216015:\n",
      "12th- epoch: 9, train_loss = 8.050141604617238, train_acc = 0.9860270144387517\n",
      "test Acc 0.9534450651769087:\n",
      "12th- epoch: 10, train_loss = 6.807427640538663, train_acc = 0.9881229622729389\n",
      "test Acc 0.9553072625698324:\n",
      "12th- epoch: 11, train_loss = 5.936074103228748, train_acc = 0.9899860270144387\n",
      "test Acc 0.9548417132216015:\n",
      "12th- epoch: 12, train_loss = 5.241356830578297, train_acc = 0.990801117838845\n",
      "test Acc 0.9543761638733705:\n",
      "12th- epoch: 13, train_loss = 4.659619749523699, train_acc = 0.992081974848626\n",
      "test Acc 0.9548417132216015:\n",
      "12th- epoch: 14, train_loss = 4.218032145407051, train_acc = 0.9925477410340009\n",
      "test Acc 0.9557728119180633:\n",
      "12th- epoch: 15, train_loss = 3.8464724756777287, train_acc = 0.9930135072193759\n",
      "test Acc 0.9553072625698324:\n",
      "12th- epoch: 16, train_loss = 3.521170523017645, train_acc = 0.9935957149510946\n",
      "test Acc 0.9553072625698324:\n",
      "12th- epoch: 17, train_loss = 3.281068950193003, train_acc = 0.9939450395901258\n",
      "test Acc 0.9553072625698324:\n",
      "12th- epoch: 18, train_loss = 3.0495953359641135, train_acc = 0.994294364229157\n",
      "test Acc 0.9553072625698324:\n",
      "12th- epoch: 19, train_loss = 2.910543237347156, train_acc = 0.9944108057755007\n",
      "test Acc 0.9557728119180633:\n",
      "12th- epoch: 20, train_loss = 2.699507284210995, train_acc = 0.9946436888681882\n",
      "test Acc 0.9553072625698324:\n",
      "12th- epoch: 21, train_loss = 2.594154600868933, train_acc = 0.9945272473218444\n",
      "test Acc 0.9567039106145251:\n",
      "12th- epoch: 22, train_loss = 2.4422883809311315, train_acc = 0.9947601304145319\n",
      "test Acc 0.9567039106145251:\n",
      "12th- epoch: 23, train_loss = 2.3470390831353143, train_acc = 0.9948765719608756\n",
      "test Acc 0.957169459962756:\n",
      "12th- epoch: 24, train_loss = 2.230651498073712, train_acc = 0.9949930135072194\n",
      "test Acc 0.957169459962756:\n",
      "12th- epoch: 25, train_loss = 2.1839975989423692, train_acc = 0.9951094550535631\n",
      "test Acc 0.957169459962756:\n",
      "12th- epoch: 26, train_loss = 2.090529695735313, train_acc = 0.9954587796925943\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 27, train_loss = 2.023727278225124, train_acc = 0.995575221238938\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 28, train_loss = 1.9742914241505787, train_acc = 0.9956916627852818\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 29, train_loss = 1.9201813994441181, train_acc = 0.9959245458779693\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 30, train_loss = 1.8784588732523844, train_acc = 0.9959245458779693\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 31, train_loss = 1.8347076800419018, train_acc = 0.996040987424313\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 32, train_loss = 1.7890589091693982, train_acc = 0.9962738705170004\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 33, train_loss = 1.757147352444008, train_acc = 0.9962738705170004\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 34, train_loss = 1.7282007896574214, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 35, train_loss = 1.6940402992768213, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 36, train_loss = 1.6704298300901428, train_acc = 0.996506753609688\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 37, train_loss = 1.6419679700629786, train_acc = 0.996506753609688\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 38, train_loss = 1.6258023908594623, train_acc = 0.996506753609688\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 39, train_loss = 1.5969854554859921, train_acc = 0.996506753609688\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 40, train_loss = 1.5778405900346115, train_acc = 0.996506753609688\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 41, train_loss = 1.5596231778035872, train_acc = 0.996506753609688\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 42, train_loss = 1.547260669816751, train_acc = 0.9966231951560317\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 43, train_loss = 1.5239025467890315, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 44, train_loss = 1.5146056756493635, train_acc = 0.9967396367023754\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 45, train_loss = 1.4982529298285954, train_acc = 0.9967396367023754\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 46, train_loss = 1.4840205921791494, train_acc = 0.9967396367023754\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 47, train_loss = 1.470071870367974, train_acc = 0.9967396367023754\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 48, train_loss = 1.461039595946204, train_acc = 0.9967396367023754\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 49, train_loss = 1.4436730844900012, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 50, train_loss = 1.4296150876325555, train_acc = 0.9967396367023754\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 51, train_loss = 1.4314568199333735, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 52, train_loss = 1.408708768140059, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 53, train_loss = 1.4049048117885832, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 54, train_loss = 1.3883855511958245, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 55, train_loss = 1.3736084192059934, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 56, train_loss = 1.3689151257276535, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 57, train_loss = 1.3596306941471994, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 58, train_loss = 1.34388846764341, train_acc = 0.9968560782487191\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 59, train_loss = 1.3387439005600754, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 60, train_loss = 1.3274124293529894, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 61, train_loss = 1.320095277245855, train_acc = 0.9968560782487191\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 62, train_loss = 1.3106035394594073, train_acc = 0.9968560782487191\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 63, train_loss = 1.3103659305197652, train_acc = 0.9968560782487191\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 64, train_loss = 1.2962542905006558, train_acc = 0.9968560782487191\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 65, train_loss = 1.290245479758596, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 66, train_loss = 1.28623738171882, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 67, train_loss = 1.2755015643779188, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 68, train_loss = 1.2682736334681977, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 69, train_loss = 1.2682673131348565, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 70, train_loss = 1.2516010493272915, train_acc = 0.9969725197950629\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 71, train_loss = 1.2536531143123284, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 72, train_loss = 1.240316667186562, train_acc = 0.9969725197950629\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 73, train_loss = 1.2417332386539783, train_acc = 0.9969725197950629\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 74, train_loss = 1.2304406020848546, train_acc = 0.9969725197950629\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 75, train_loss = 1.2249835704860743, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 76, train_loss = 1.2156735930766445, train_acc = 0.9970889613414066\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 77, train_loss = 1.2207228477054741, train_acc = 0.9968560782487191\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 78, train_loss = 1.2051773534331005, train_acc = 0.9969725197950629\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 79, train_loss = 1.2012938576808665, train_acc = 0.9969725197950629\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 80, train_loss = 1.2005211743235122, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 81, train_loss = 1.1905991684907349, train_acc = 0.9969725197950629\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 82, train_loss = 1.188464796403423, train_acc = 0.9969725197950629\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 83, train_loss = 1.183029184656334, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 84, train_loss = 1.178882538806647, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 85, train_loss = 1.1718049421178875, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 86, train_loss = 1.169440021039918, train_acc = 0.9969725197950629\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 87, train_loss = 1.1639495812705718, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 88, train_loss = 1.1629329988063546, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 89, train_loss = 1.1561603362351889, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 90, train_loss = 1.152166244442924, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 91, train_loss = 1.1477247072325554, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 92, train_loss = 1.1429733227123506, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 93, train_loss = 1.1421953602257418, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 94, train_loss = 1.1361094418825815, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 95, train_loss = 1.1376196238416014, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 96, train_loss = 1.1292176580027444, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 97, train_loss = 1.1271570105600404, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 98, train_loss = 1.1236161383567378, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 99, train_loss = 1.119401432806626, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 100, train_loss = 1.1197856934159063, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 101, train_loss = 1.110911588461022, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 102, train_loss = 1.1146963108476484, train_acc = 0.9970889613414066\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 103, train_loss = 1.1086012434243457, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 104, train_loss = 1.1066856645484222, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 105, train_loss = 1.1002215785410954, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 106, train_loss = 1.0983716037590057, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 107, train_loss = 1.1011805201414973, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 108, train_loss = 1.0942615890671732, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 109, train_loss = 1.0951934653130593, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 110, train_loss = 1.0896994192589773, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 111, train_loss = 1.0866219817398814, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 112, train_loss = 1.0866493802313926, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 113, train_loss = 1.0793818621168612, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 114, train_loss = 1.0843529432750074, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 115, train_loss = 1.0794557599147083, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 116, train_loss = 1.0779318714048713, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 117, train_loss = 1.0735766833386151, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 118, train_loss = 1.0734984270093264, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 119, train_loss = 1.0688475311471848, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 120, train_loss = 1.0671944431232987, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 121, train_loss = 1.0682115342933685, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 122, train_loss = 1.0632300602010218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 123, train_loss = 1.0632295387331396, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 124, train_loss = 1.0600425088778138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 125, train_loss = 1.0606973410322098, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 126, train_loss = 1.0553563091234537, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 127, train_loss = 1.055058063546312, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 128, train_loss = 1.0543592884205282, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 129, train_loss = 1.0533713197073666, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 130, train_loss = 1.0479136261419626, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 131, train_loss = 1.0504002099187346, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 132, train_loss = 1.04625647670764, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 133, train_loss = 1.0473096085042926, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 134, train_loss = 1.0444981756154448, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 135, train_loss = 1.045589035449666, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 136, train_loss = 1.0396043835935416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 137, train_loss = 1.042858331464231, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 138, train_loss = 1.0358316007332178, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 139, train_loss = 1.038643899213639, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 140, train_loss = 1.0323790194670437, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 141, train_loss = 1.0354581027495442, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 142, train_loss = 1.032890452464926, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 143, train_loss = 1.033489093722892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 144, train_loss = 1.0293134249077411, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 145, train_loss = 1.0306893959641457, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 146, train_loss = 1.0285027383361012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 147, train_loss = 1.0259111644263612, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 148, train_loss = 1.0239361472631572, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 149, train_loss = 1.0242566637025448, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 150, train_loss = 1.0203400489408523, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 151, train_loss = 1.0251324245909927, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 152, train_loss = 1.0182936703058658, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 153, train_loss = 1.0213807062245905, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 154, train_loss = 1.0157937554031378, train_acc = 0.9975547275267815\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 155, train_loss = 1.0169131035363534, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 156, train_loss = 1.0130819649639307, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 157, train_loss = 1.0178627323693945, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 158, train_loss = 1.0121205729083158, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 159, train_loss = 1.0149446109644487, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 160, train_loss = 1.010763203179522, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 161, train_loss = 1.010963260931021, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 162, train_loss = 1.0090096536659985, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 163, train_loss = 1.009788880335691, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 164, train_loss = 1.006838003602752, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 165, train_loss = 1.0073080230140476, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 166, train_loss = 1.0046005096155568, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 167, train_loss = 1.0049869248177856, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 168, train_loss = 1.002853375430277, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 169, train_loss = 1.003207120775187, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 170, train_loss = 1.0016789998408058, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 171, train_loss = 1.0027847312521772, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 172, train_loss = 0.9995080552180298, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 173, train_loss = 0.9971701033646241, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 174, train_loss = 0.9973200752647244, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 175, train_loss = 0.997720328545256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 176, train_loss = 0.996371103603451, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 177, train_loss = 0.9947928939945996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 178, train_loss = 0.993638429325074, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 179, train_loss = 0.9930294597506872, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 180, train_loss = 0.9914572178386152, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 181, train_loss = 0.9913772092331783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 182, train_loss = 0.9892825226634159, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 183, train_loss = 0.9893613615204231, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 184, train_loss = 0.9873919145102263, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 185, train_loss = 0.9911745000645169, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 186, train_loss = 0.9862930061281077, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 187, train_loss = 0.9881131309448392, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 188, train_loss = 0.9845961136743426, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 189, train_loss = 0.9834343610782526, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 190, train_loss = 0.9845623545479611, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 191, train_loss = 0.9864440715391538, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 192, train_loss = 0.9802289636936621, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 193, train_loss = 0.9814981344388798, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 194, train_loss = 0.9807865267139277, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 195, train_loss = 0.9834713056916371, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 196, train_loss = 0.9785173789496184, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 197, train_loss = 0.9777126179542392, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 198, train_loss = 0.9774157409774489, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 199, train_loss = 0.9767534006969072, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 200, train_loss = 0.9785400088294409, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 201, train_loss = 0.9775547046810971, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 202, train_loss = 0.973837528435979, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 203, train_loss = 0.9773199273040518, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 204, train_loss = 0.9737319985288195, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 205, train_loss = 0.9719317037597648, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 206, train_loss = 0.9700795416720212, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 207, train_loss = 0.9716751830055728, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 208, train_loss = 0.9708588822177262, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 209, train_loss = 0.970134653885907, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 210, train_loss = 0.970807696437987, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 211, train_loss = 0.9708101830547093, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 212, train_loss = 0.9693869183538482, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 213, train_loss = 0.9671841474701068, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 214, train_loss = 0.96772403025534, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 215, train_loss = 0.9658320733578876, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 216, train_loss = 0.9661792003316805, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 217, train_loss = 0.9653977327980101, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 218, train_loss = 0.9644099453362287, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 219, train_loss = 0.9636833713157102, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 220, train_loss = 0.961931670026388, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 221, train_loss = 0.96404263520526, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 222, train_loss = 0.9600419318521745, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 223, train_loss = 0.9615610189503059, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 224, train_loss = 0.9606441874420852, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 225, train_loss = 0.9629950614544214, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 226, train_loss = 0.9603586664088652, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 227, train_loss = 0.958592360104376, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 228, train_loss = 0.9596056373775355, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 229, train_loss = 0.9603399643601733, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 230, train_loss = 0.9584704846492968, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 231, train_loss = 0.9583729398727883, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 232, train_loss = 0.9582258210066357, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 233, train_loss = 0.9577168831237941, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 234, train_loss = 0.9553339238409535, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 235, train_loss = 0.9532395870774053, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 236, train_loss = 0.952035030706611, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 237, train_loss = 0.9552480857018963, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 238, train_loss = 0.9548576207234873, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 239, train_loss = 0.951909809919016, train_acc = 0.9975547275267815\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 240, train_loss = 0.9507673042462557, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 241, train_loss = 0.949504564741801, train_acc = 0.9976711690731253\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 242, train_loss = 0.9502549620810896, train_acc = 0.9976711690731253\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 243, train_loss = 0.9534282731401618, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 244, train_loss = 0.9513028401051997, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 245, train_loss = 0.9499204458188615, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 246, train_loss = 0.9478780824210844, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 247, train_loss = 0.9464183644959121, train_acc = 0.9976711690731253\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 248, train_loss = 0.9495882881819853, train_acc = 0.9976711690731253\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 249, train_loss = 0.9495882474584505, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 250, train_loss = 0.9483771357336082, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 251, train_loss = 0.9456909048603848, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 252, train_loss = 0.9481269510943093, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 253, train_loss = 0.9485872175209806, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 254, train_loss = 0.9480308849233552, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 255, train_loss = 0.9444261522730812, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 256, train_loss = 0.9431157329599955, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 257, train_loss = 0.9425046239848598, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 258, train_loss = 0.9426391786328168, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 259, train_loss = 0.9446794463437982, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 260, train_loss = 0.9444810924833291, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 261, train_loss = 0.9435533176874742, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 262, train_loss = 0.9436913715107949, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 263, train_loss = 0.943426404359343, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 264, train_loss = 0.9427384847876965, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 265, train_loss = 0.9434963507010252, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 266, train_loss = 0.9428470131606446, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 267, train_loss = 0.940917808584345, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 268, train_loss = 0.9411682490972453, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 269, train_loss = 0.9408974320394918, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 270, train_loss = 0.941898004617542, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 271, train_loss = 0.9391297391048283, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 272, train_loss = 0.9392248680815101, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 273, train_loss = 0.9365812565665692, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 274, train_loss = 0.9377805903422995, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 275, train_loss = 0.9358333590207621, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 276, train_loss = 0.936101160805265, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 277, train_loss = 0.9373703724340885, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 278, train_loss = 0.9367896262774593, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 279, train_loss = 0.9317124490262358, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 280, train_loss = 0.9356025273082196, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 281, train_loss = 0.9361011164437514, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 282, train_loss = 0.9350892532165744, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 283, train_loss = 0.934443246187584, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 284, train_loss = 0.9327408050012309, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 285, train_loss = 0.9334431010356639, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 286, train_loss = 0.9316757792621502, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 287, train_loss = 0.9311165279286797, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 288, train_loss = 0.9325428883967106, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 289, train_loss = 0.9322615667551872, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 290, train_loss = 0.9327481378277298, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 291, train_loss = 0.9297334318762296, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 292, train_loss = 0.9301655040253536, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 293, train_loss = 0.929172020907572, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 294, train_loss = 0.9292533412808552, train_acc = 0.9976711690731253\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 295, train_loss = 0.9265993257868104, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 296, train_loss = 0.926770058227703, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 297, train_loss = 0.9268068595338264, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 298, train_loss = 0.9278215618905961, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 299, train_loss = 0.9282807131748996, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 300, train_loss = 0.9299662911798805, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 301, train_loss = 0.928947849861288, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 302, train_loss = 0.9251657167551457, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 303, train_loss = 0.9243887034244835, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 304, train_loss = 0.9253240004181862, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 305, train_loss = 0.9239859541412443, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 306, train_loss = 0.922768474323675, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 307, train_loss = 0.9268781650680467, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 308, train_loss = 0.9271003729299991, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 309, train_loss = 0.9227215351638733, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 310, train_loss = 0.923059763154015, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 311, train_loss = 0.9234576266389922, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 312, train_loss = 0.9245663156034425, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 313, train_loss = 0.9216732166241854, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 314, train_loss = 0.9243897536434815, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 315, train_loss = 0.920024949744402, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 316, train_loss = 0.9196215265765204, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 317, train_loss = 0.9231203036251827, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 318, train_loss = 0.9217825340238051, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 319, train_loss = 0.9201583924368606, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 320, train_loss = 0.9187638643998071, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 321, train_loss = 0.9188657687045634, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 322, train_loss = 0.9191040278747096, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 323, train_loss = 0.9177995852660388, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 324, train_loss = 0.9228743071798817, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 325, train_loss = 0.920484983442293, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 326, train_loss = 0.9174962609540671, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 327, train_loss = 0.9174521535169333, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 328, train_loss = 0.9171651431024657, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 329, train_loss = 0.9176978346295073, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 330, train_loss = 0.9199778664988116, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 331, train_loss = 0.9176630084402859, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 332, train_loss = 0.916868513369991, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 333, train_loss = 0.9196627642159001, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 334, train_loss = 0.9168315855786204, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 335, train_loss = 0.9145947850774974, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 336, train_loss = 0.91652943178633, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 337, train_loss = 0.9173736283555627, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 338, train_loss = 0.9144399128854275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 339, train_loss = 0.9154919977299869, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 340, train_loss = 0.9183787348811165, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 341, train_loss = 0.9152000714093447, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 342, train_loss = 0.9131706097759889, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 343, train_loss = 0.9172970413565054, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 344, train_loss = 0.9174506586641655, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 345, train_loss = 0.9159009815193713, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 346, train_loss = 0.913857199717313, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 347, train_loss = 0.9127409228458419, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 348, train_loss = 0.9146604601628496, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 349, train_loss = 0.9131093327887356, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 350, train_loss = 0.9121623313985765, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 351, train_loss = 0.9140737963243737, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 352, train_loss = 0.9115361201875203, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 353, train_loss = 0.915194994151534, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 354, train_loss = 0.9107536614574201, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 355, train_loss = 0.9110634207390831, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 356, train_loss = 0.9133320402652316, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 357, train_loss = 0.9111274069473438, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 358, train_loss = 0.909113504767447, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 359, train_loss = 0.9134347710460133, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 360, train_loss = 0.9101434340700507, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 361, train_loss = 0.9121423535980284, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 362, train_loss = 0.9098754891492717, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 363, train_loss = 0.9102985599711246, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 364, train_loss = 0.9085800956636376, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 365, train_loss = 0.9105979570485943, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 366, train_loss = 0.9095611842349172, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 367, train_loss = 0.907895127467782, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 368, train_loss = 0.9053556600883894, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 369, train_loss = 0.9081566534005105, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 370, train_loss = 0.9120954613499634, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 371, train_loss = 0.907805281382025, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 372, train_loss = 0.9112114662602835, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 373, train_loss = 0.9078265251591802, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 374, train_loss = 0.9065235105044849, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 375, train_loss = 0.9073720529377169, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 376, train_loss = 0.9100049897097051, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 377, train_loss = 0.9069664003327489, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 378, train_loss = 0.9051706053614907, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 379, train_loss = 0.9018991321026988, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 380, train_loss = 0.9071060003079765, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 381, train_loss = 0.9082073237113946, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 382, train_loss = 0.9059427073225379, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 383, train_loss = 0.9077239778525836, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 384, train_loss = 0.906390279687912, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 385, train_loss = 0.9054552619345486, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 386, train_loss = 0.9008535356260836, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 387, train_loss = 0.9056695811450481, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 388, train_loss = 0.9070212853439443, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 389, train_loss = 0.9001173685937829, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 390, train_loss = 0.9051730879582465, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 391, train_loss = 0.9050213000737131, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 392, train_loss = 0.8992515054233081, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 393, train_loss = 0.9047817937098444, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 394, train_loss = 0.9067568165883131, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 395, train_loss = 0.9004059814214997, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 396, train_loss = 0.9054996014274366, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 397, train_loss = 0.9044560648799234, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 398, train_loss = 0.8989726738072932, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 399, train_loss = 0.9037205811291642, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 400, train_loss = 0.9048685201742046, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 401, train_loss = 0.8998805941082537, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 402, train_loss = 0.90255259008336, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 403, train_loss = 0.9036574843339622, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 404, train_loss = 0.9033443507105403, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 405, train_loss = 0.8988035591319203, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 406, train_loss = 0.9036984681151807, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 407, train_loss = 0.9020613299981051, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 408, train_loss = 0.9034020408689685, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 409, train_loss = 0.8991135891228623, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 410, train_loss = 0.9042754118963785, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 411, train_loss = 0.9022949052341573, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 412, train_loss = 0.8960377553776198, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 413, train_loss = 0.9032057110853202, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 414, train_loss = 0.9026254617310769, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 415, train_loss = 0.901910049997241, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 416, train_loss = 0.8998465436343395, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 417, train_loss = 0.9016176283657842, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 418, train_loss = 0.8978258109018498, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 419, train_loss = 0.9019348182082467, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 420, train_loss = 0.9029685203749978, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 421, train_loss = 0.9020061612427526, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 422, train_loss = 0.8993242154829204, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 423, train_loss = 0.9022283847443759, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 424, train_loss = 0.9024191658645577, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 425, train_loss = 0.9017829274926044, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 426, train_loss = 0.9014145419932902, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 427, train_loss = 0.9022714125458151, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 428, train_loss = 0.9014770470857911, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 429, train_loss = 0.9005475867706991, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 430, train_loss = 0.9001363820862025, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 431, train_loss = 0.9024183233268559, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 432, train_loss = 0.9003534187395417, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 433, train_loss = 0.8991142070553906, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 434, train_loss = 0.8996099752839655, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 435, train_loss = 0.900249919777707, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 436, train_loss = 0.8964482991323166, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 437, train_loss = 0.9001299624032981, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 438, train_loss = 0.8970127503089316, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 439, train_loss = 0.8976871849336021, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 440, train_loss = 0.9011615642812103, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 441, train_loss = 0.8999901246279478, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 442, train_loss = 0.8979635442774452, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 443, train_loss = 0.8996339100413024, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 444, train_loss = 0.8990123729054176, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 445, train_loss = 0.8945827889256179, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 446, train_loss = 0.8977942292112857, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 447, train_loss = 0.8985466739795811, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 448, train_loss = 0.8978014643471397, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 449, train_loss = 0.8982844381425821, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 450, train_loss = 0.8992996227461845, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 451, train_loss = 0.8949312563054264, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 452, train_loss = 0.8984041195362806, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 453, train_loss = 0.8972525190729357, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 454, train_loss = 0.893580042913527, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 455, train_loss = 0.8991600732952065, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 456, train_loss = 0.8976768411230296, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 457, train_loss = 0.8964198369831138, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 458, train_loss = 0.8973324674880132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 459, train_loss = 0.8966351101007604, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 460, train_loss = 0.8975948795377917, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 461, train_loss = 0.8987573765516572, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 462, train_loss = 0.8971314689079009, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 463, train_loss = 0.8947407844643749, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 464, train_loss = 0.8998715008310683, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 465, train_loss = 0.8969691359670833, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 466, train_loss = 0.8951539913359738, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 467, train_loss = 0.8887368171708658, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 468, train_loss = 0.8904168203771405, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 469, train_loss = 0.8963866365374997, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 470, train_loss = 0.8962428978811658, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 471, train_loss = 0.8952383419564285, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 472, train_loss = 0.895976566203899, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 473, train_loss = 0.8964759321715974, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 474, train_loss = 0.895051175768458, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 475, train_loss = 0.8972476898161403, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 476, train_loss = 0.8948631365783513, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 477, train_loss = 0.8951523208525032, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 478, train_loss = 0.8957535666813783, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 479, train_loss = 0.8937544384971261, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 480, train_loss = 0.8872676501450769, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 481, train_loss = 0.8894872222626873, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 482, train_loss = 0.8919319091182842, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 483, train_loss = 0.8942545948084444, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 484, train_loss = 0.8933174434168905, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 485, train_loss = 0.8944098643078178, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 486, train_loss = 0.8934972085226036, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 487, train_loss = 0.8845857714950398, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 488, train_loss = 0.8887046920535795, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 489, train_loss = 0.8904651392367668, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 490, train_loss = 0.8925063872993633, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 491, train_loss = 0.8940960407053353, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 492, train_loss = 0.8919928399664059, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 493, train_loss = 0.8924463943112642, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 494, train_loss = 0.8956147284479812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 495, train_loss = 0.8921182000667613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 496, train_loss = 0.8924471651553176, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 497, train_loss = 0.8925426276800863, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 498, train_loss = 0.89300497764998, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 499, train_loss = 0.8927568418621377, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|██████████████████████████████▍                                             | 12/30 [1:52:32<2:58:19, 594.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "13th- epoch: 0, train_loss = 338.6809697523713, train_acc = 0.8110153702841174\n",
      "test Acc 0.8747672253258846:\n",
      "13th- epoch: 1, train_loss = 75.48274311423302, train_acc = 0.9269911504424779\n",
      "test Acc 0.9329608938547486:\n",
      "13th- epoch: 2, train_loss = 47.572497820016, train_acc = 0.9487657196087564\n",
      "test Acc 0.9418063314711359:\n",
      "13th- epoch: 3, train_loss = 33.48366406885907, train_acc = 0.9597112249650676\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 4, train_loss = 24.525709379464388, train_acc = 0.9682114578481602\n",
      "test Acc 0.9548417132216015:\n",
      "13th- epoch: 5, train_loss = 18.884783007204533, train_acc = 0.9724033535165347\n",
      "test Acc 0.9567039106145251:\n",
      "13th- epoch: 6, train_loss = 15.070343543135095, train_acc = 0.9777596646483465\n",
      "test Acc 0.9581005586592178:\n",
      "13th- epoch: 7, train_loss = 12.257821347855497, train_acc = 0.98067070330694\n",
      "test Acc 0.9599627560521415:\n",
      "13th- epoch: 8, train_loss = 10.22965352499159, train_acc = 0.9842803912435957\n",
      "test Acc 0.9622905027932961:\n",
      "13th- epoch: 9, train_loss = 8.77610127456137, train_acc = 0.985910572892408\n",
      "test Acc 0.9622905027932961:\n",
      "13th- epoch: 10, train_loss = 7.605208428751212, train_acc = 0.9871914299021891\n",
      "test Acc 0.9622905027932961:\n",
      "13th- epoch: 11, train_loss = 6.692665645852685, train_acc = 0.9887051700046576\n",
      "test Acc 0.9618249534450651:\n",
      "13th- epoch: 12, train_loss = 5.992006083193701, train_acc = 0.9892873777363763\n",
      "test Acc 0.9622905027932961:\n",
      "13th- epoch: 13, train_loss = 5.413989569758996, train_acc = 0.9902189101071263\n",
      "test Acc 0.9613594040968343:\n",
      "13th- epoch: 14, train_loss = 4.910732242802624, train_acc = 0.9916162086632511\n",
      "test Acc 0.9613594040968343:\n",
      "13th- epoch: 15, train_loss = 4.520232971699443, train_acc = 0.9919655333022822\n",
      "test Acc 0.9622905027932961:\n",
      "13th- epoch: 16, train_loss = 4.188598571170587, train_acc = 0.9927806241266884\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 17, train_loss = 3.906595795939211, train_acc = 0.9932463903120633\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 18, train_loss = 3.6924607774126343, train_acc = 0.9932463903120633\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 19, train_loss = 3.471549656242132, train_acc = 0.994294364229157\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 20, train_loss = 3.2936342744505964, train_acc = 0.9945272473218444\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 21, train_loss = 3.1348411822109483, train_acc = 0.9947601304145319\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 22, train_loss = 2.9782610555994324, train_acc = 0.9948765719608756\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 23, train_loss = 2.8389567086996976, train_acc = 0.9949930135072194\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 24, train_loss = 2.7124436433950905, train_acc = 0.9954587796925943\n",
      "test Acc 0.9641527001862198:\n",
      "13th- epoch: 25, train_loss = 2.61194256413728, train_acc = 0.9953423381462506\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 26, train_loss = 2.5061006577161606, train_acc = 0.9953423381462506\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 27, train_loss = 2.4052352546714246, train_acc = 0.9954587796925943\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 28, train_loss = 2.3190461421909276, train_acc = 0.9954587796925943\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 29, train_loss = 2.2269367994740605, train_acc = 0.9954587796925943\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 30, train_loss = 2.151450147066498, train_acc = 0.9954587796925943\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 31, train_loss = 2.0727198575623333, train_acc = 0.995575221238938\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 32, train_loss = 2.0067933687678305, train_acc = 0.9956916627852818\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 33, train_loss = 1.9486838880256983, train_acc = 0.9956916627852818\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 34, train_loss = 1.901114913940546, train_acc = 0.9956916627852818\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 35, train_loss = 1.8612136521114735, train_acc = 0.9958081043316255\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 36, train_loss = 1.8251646617427468, train_acc = 0.9958081043316255\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 37, train_loss = 1.793367854625103, train_acc = 0.9961574289706567\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 38, train_loss = 1.756963665902731, train_acc = 0.9961574289706567\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 39, train_loss = 1.7349492721259594, train_acc = 0.9961574289706567\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 40, train_loss = 1.709475111521897, train_acc = 0.9962738705170004\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 41, train_loss = 1.6832634772435995, train_acc = 0.9962738705170004\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 42, train_loss = 1.6629009672178654, train_acc = 0.9963903120633442\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 43, train_loss = 1.6374185712338658, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 44, train_loss = 1.6212409593426855, train_acc = 0.996506753609688\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 45, train_loss = 1.6026550605893135, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 46, train_loss = 1.584024451978621, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 47, train_loss = 1.5682930938637583, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 48, train_loss = 1.5531997253856389, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 49, train_loss = 1.5380896907299757, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 50, train_loss = 1.5224826584308175, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 51, train_loss = 1.509056960538146, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 52, train_loss = 1.4986206792964367, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 53, train_loss = 1.4823394613340497, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 54, train_loss = 1.475277442485094, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 55, train_loss = 1.4616235457360744, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 56, train_loss = 1.4482161138876108, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 57, train_loss = 1.4410957253276138, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 58, train_loss = 1.4321276259870501, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 59, train_loss = 1.4187954679800896, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 60, train_loss = 1.407407160542789, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 61, train_loss = 1.4028385185374646, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 62, train_loss = 1.3910790511145024, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 63, train_loss = 1.3822449293656973, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 64, train_loss = 1.3732202199025778, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 65, train_loss = 1.3670749139710097, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 66, train_loss = 1.3568909177556634, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 67, train_loss = 1.3484283983707428, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 68, train_loss = 1.3399501768872142, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 69, train_loss = 1.3308958634734154, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 70, train_loss = 1.3233975609764457, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 71, train_loss = 1.3148932543917908, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 72, train_loss = 1.3080226695165038, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 73, train_loss = 1.3001254570335732, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 74, train_loss = 1.295132507882954, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 75, train_loss = 1.2880957564339042, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 76, train_loss = 1.2794329561293125, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 77, train_loss = 1.2725165734664188, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 78, train_loss = 1.2668134321793332, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 79, train_loss = 1.2583168564960943, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 80, train_loss = 1.2520731333643198, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 81, train_loss = 1.2454651979132905, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 82, train_loss = 1.2408395425081835, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 83, train_loss = 1.2340497064069496, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 84, train_loss = 1.2281918370499625, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 85, train_loss = 1.2231355172916665, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 86, train_loss = 1.2177374633029103, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 87, train_loss = 1.2119404651821242, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 88, train_loss = 1.2081961523144855, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 89, train_loss = 1.2011818252503872, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 90, train_loss = 1.1998196324930177, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 91, train_loss = 1.1931365321725025, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 92, train_loss = 1.1883949202820077, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 93, train_loss = 1.1840530705303536, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 94, train_loss = 1.1797622755766497, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 95, train_loss = 1.1747936382889748, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 96, train_loss = 1.171398579455854, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 97, train_loss = 1.1668574291616096, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 98, train_loss = 1.163347882531525, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 99, train_loss = 1.16041469884658, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 100, train_loss = 1.1547959925010218, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 101, train_loss = 1.1522362850009813, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 102, train_loss = 1.149086074285151, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 103, train_loss = 1.1455694713295088, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 104, train_loss = 1.1424261524007306, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 105, train_loss = 1.1396783767268062, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 106, train_loss = 1.135172731243074, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 107, train_loss = 1.1322886543348432, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 108, train_loss = 1.1280317967757583, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 109, train_loss = 1.126241899713932, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 110, train_loss = 1.123971786662878, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 111, train_loss = 1.120928490847291, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 112, train_loss = 1.1156447560861125, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 113, train_loss = 1.113853750131966, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 114, train_loss = 1.1125481330454932, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 115, train_loss = 1.1081835068762302, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 116, train_loss = 1.1062495841979398, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 117, train_loss = 1.1044070165007724, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 118, train_loss = 1.1006119903177023, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 119, train_loss = 1.1003532220274792, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 120, train_loss = 1.0958219108506455, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 121, train_loss = 1.0936678064390435, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 122, train_loss = 1.0924331465139403, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 123, train_loss = 1.0883635701611638, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 124, train_loss = 1.086470226138772, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 125, train_loss = 1.0859459821731434, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 126, train_loss = 1.0811397178695188, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 127, train_loss = 1.0825127527714358, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 128, train_loss = 1.078349015362619, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 129, train_loss = 1.077728504933475, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 130, train_loss = 1.0722166566774831, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 131, train_loss = 1.071646519623755, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 132, train_loss = 1.0686441526413546, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 133, train_loss = 1.0674707060679793, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 134, train_loss = 1.0638706063255086, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 135, train_loss = 1.064138816051127, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 136, train_loss = 1.0611129198223352, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 137, train_loss = 1.0608075174168334, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 138, train_loss = 1.0557111759335385, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 139, train_loss = 1.056278841882886, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 140, train_loss = 1.055707072839141, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 141, train_loss = 1.0517389679662301, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 142, train_loss = 1.0503247484230087, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 143, train_loss = 1.049107381455542, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 144, train_loss = 1.0484487636349513, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 145, train_loss = 1.044548910263984, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 146, train_loss = 1.0429870444349945, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 147, train_loss = 1.042766832280904, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 148, train_loss = 1.0383453203030513, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 149, train_loss = 1.036605984903872, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 150, train_loss = 1.0346664556636824, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 151, train_loss = 1.0343715543858707, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 152, train_loss = 1.0303027837871923, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 153, train_loss = 1.0320120241158293, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 154, train_loss = 1.0311305178329349, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 155, train_loss = 1.0271477719434188, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 156, train_loss = 1.026539668753685, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 157, train_loss = 1.0249231389389024, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 158, train_loss = 1.0241817218848155, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 159, train_loss = 1.0215293754226877, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 160, train_loss = 1.0210422234013095, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 161, train_loss = 1.0180628284215345, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 162, train_loss = 1.0191921798177646, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 163, train_loss = 1.0162751137613668, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 164, train_loss = 1.0151143249458983, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 165, train_loss = 1.0160536246039555, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 166, train_loss = 1.0127751588224783, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 167, train_loss = 1.0116221184507594, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 168, train_loss = 1.0102380245589302, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 169, train_loss = 1.0094490897245123, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 170, train_loss = 1.0077063934877515, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 171, train_loss = 1.007811187300831, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 172, train_loss = 1.0065781765952124, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 173, train_loss = 1.0036844896749244, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 174, train_loss = 1.0024509178474545, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 175, train_loss = 1.0025039765387191, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 176, train_loss = 1.00048539632553, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 177, train_loss = 0.9992898278869689, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 178, train_loss = 0.9989142566118971, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 179, train_loss = 0.9984603827688261, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 180, train_loss = 0.9962433391847298, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 181, train_loss = 0.996082785539329, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 182, train_loss = 0.9941218800377101, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 183, train_loss = 0.9928297568112612, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 184, train_loss = 0.9915743540041149, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 185, train_loss = 0.9909904440064565, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 186, train_loss = 0.9904661186374142, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 187, train_loss = 0.9919410988222808, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 188, train_loss = 0.988597070252581, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 189, train_loss = 0.987240536371246, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 190, train_loss = 0.9864540752023458, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 191, train_loss = 0.9879613314624294, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 192, train_loss = 0.9855717344544246, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 193, train_loss = 0.9834003436044441, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 194, train_loss = 0.9834273916203529, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 195, train_loss = 0.9819545863792882, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 196, train_loss = 0.9813538435846567, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 197, train_loss = 0.9789883980192826, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 198, train_loss = 0.9790694925104617, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 199, train_loss = 0.9792081154882908, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 200, train_loss = 0.976627694988565, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 201, train_loss = 0.9766974111189484, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 202, train_loss = 0.974654617253691, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 203, train_loss = 0.976076776314585, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 204, train_loss = 0.972482258650416, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 205, train_loss = 0.9729356301613734, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 206, train_loss = 0.9705543095842586, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 207, train_loss = 0.972765568876639, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 208, train_loss = 0.9698541244360968, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 209, train_loss = 0.9690153249175637, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 210, train_loss = 0.969619029237947, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 211, train_loss = 0.9668112779036164, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 212, train_loss = 0.967195461736992, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 213, train_loss = 0.9656275340821594, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 214, train_loss = 0.9660595863460912, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 215, train_loss = 0.9641519692959264, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 216, train_loss = 0.9635585531723336, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 217, train_loss = 0.9623415439054952, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 218, train_loss = 0.961819823634869, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 219, train_loss = 0.9608835133622051, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 220, train_loss = 0.9606645883395686, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 221, train_loss = 0.9600192427169532, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 222, train_loss = 0.9606687683844939, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 223, train_loss = 0.9608650778536685, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 224, train_loss = 0.9565094489735202, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 225, train_loss = 0.956135251057276, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 226, train_loss = 0.955973252923286, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 227, train_loss = 0.9554887134945602, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 228, train_loss = 0.9547991225626902, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 229, train_loss = 0.9550550685962662, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 230, train_loss = 0.9535527480984456, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 231, train_loss = 0.9529939521089545, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 232, train_loss = 0.9525387368048541, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 233, train_loss = 0.9523288654527278, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 234, train_loss = 0.9503372365725227, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 235, train_loss = 0.9518339164424106, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 236, train_loss = 0.9503575095659471, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 237, train_loss = 0.9495031173355528, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 238, train_loss = 0.9493048669173731, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 239, train_loss = 0.9486359508191526, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 240, train_loss = 0.9482784598367289, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 241, train_loss = 0.9470133075374179, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 242, train_loss = 0.9465827899985015, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 243, train_loss = 0.9459157898272679, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 244, train_loss = 0.945728952607169, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 245, train_loss = 0.9442531001986936, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 246, train_loss = 0.9435720586516254, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 247, train_loss = 0.9431707233088673, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 248, train_loss = 0.9430323065025732, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 249, train_loss = 0.9429152205702849, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 250, train_loss = 0.9424901648490049, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 251, train_loss = 0.9419385879300535, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 252, train_loss = 0.9411078878147237, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 253, train_loss = 0.9409994878042198, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 254, train_loss = 0.9401619302807376, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 255, train_loss = 0.9392085786676034, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 256, train_loss = 0.9415474594170519, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 257, train_loss = 0.9400721458187036, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 258, train_loss = 0.9389074275568419, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 259, train_loss = 0.9373725228542753, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 260, train_loss = 0.9352358928481408, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 261, train_loss = 0.9354051080699719, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 262, train_loss = 0.9362266456409998, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 263, train_loss = 0.9362758819479495, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 264, train_loss = 0.9336942359805107, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 265, train_loss = 0.9354576054793142, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 266, train_loss = 0.9348284573461569, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 267, train_loss = 0.9345281296409667, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 268, train_loss = 0.9332890570331074, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 269, train_loss = 0.9317246087994135, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 270, train_loss = 0.9323563785292208, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 271, train_loss = 0.9328842086251825, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 272, train_loss = 0.931648964760825, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 273, train_loss = 0.9328691496048123, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 274, train_loss = 0.9306870982982218, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 275, train_loss = 0.9296709323134564, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 276, train_loss = 0.9308770860079676, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 277, train_loss = 0.93339377067241, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 278, train_loss = 0.9282777618318505, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 279, train_loss = 0.9282658798620105, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 280, train_loss = 0.9278426439668692, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 281, train_loss = 0.9292414194605954, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 282, train_loss = 0.9266691876873665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 283, train_loss = 0.9265618518293195, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 284, train_loss = 0.9263585099652119, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 285, train_loss = 0.9274113664105244, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 286, train_loss = 0.9263730596285313, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 287, train_loss = 0.9259396460838616, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 288, train_loss = 0.924912365309865, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 289, train_loss = 0.926004699740588, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 290, train_loss = 0.9241004207469814, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 291, train_loss = 0.9236477606464177, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 292, train_loss = 0.9245359851047397, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 293, train_loss = 0.9254772847052664, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 294, train_loss = 0.9220038989260502, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 295, train_loss = 0.9257127398159355, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 296, train_loss = 0.9227946088649333, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 297, train_loss = 0.9217913785651035, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 298, train_loss = 0.9221704990304715, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 299, train_loss = 0.9234911316707439, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 300, train_loss = 0.9220738308504224, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 301, train_loss = 0.9237243993375159, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 302, train_loss = 0.9208978681526787, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 303, train_loss = 0.9201258898247033, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 304, train_loss = 0.920968213584274, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 305, train_loss = 0.9206058643758297, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 306, train_loss = 0.9189543115608103, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 307, train_loss = 0.9215732256416231, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 308, train_loss = 0.9187927561179094, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 309, train_loss = 0.9193650680426799, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 310, train_loss = 0.9204340101387061, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 311, train_loss = 0.919018046464771, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 312, train_loss = 0.9182115159928799, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 313, train_loss = 0.9194030538201332, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 314, train_loss = 0.917500576004386, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 315, train_loss = 0.9168850336391188, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 316, train_loss = 0.9188755152281374, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 317, train_loss = 0.9163392141163058, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 318, train_loss = 0.9170828131791495, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 319, train_loss = 0.9152596186213486, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 320, train_loss = 0.9182310923933983, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 321, train_loss = 0.9184836091772013, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 322, train_loss = 0.9153590160422027, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 323, train_loss = 0.9156203269958496, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 324, train_loss = 0.9171624979171611, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 325, train_loss = 0.9152931363023527, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 326, train_loss = 0.9149140201807313, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 327, train_loss = 0.9150834200736426, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 328, train_loss = 0.9174734624102712, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 329, train_loss = 0.9147063296586566, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 330, train_loss = 0.9147976987696893, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 331, train_loss = 0.9142945022322237, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 332, train_loss = 0.9134310656227171, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 333, train_loss = 0.9147273419257544, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 334, train_loss = 0.9128975630737841, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 335, train_loss = 0.9117367931939953, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 336, train_loss = 0.9110961368605786, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 337, train_loss = 0.9117510326504998, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 338, train_loss = 0.9107321631163359, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 339, train_loss = 0.9116121043152816, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 340, train_loss = 0.9092857933137566, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 341, train_loss = 0.9108470000028319, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 342, train_loss = 0.9115633424371481, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 343, train_loss = 0.9103752615228586, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 344, train_loss = 0.9092875504102267, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 345, train_loss = 0.9145755557510711, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 346, train_loss = 0.9112547447439283, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 347, train_loss = 0.9096206012945913, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 348, train_loss = 0.908837389510154, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 349, train_loss = 0.9100820836611092, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 350, train_loss = 0.9115248053967662, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 351, train_loss = 0.90853269336003, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 352, train_loss = 0.9074062434956431, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 353, train_loss = 0.9104729991704517, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 354, train_loss = 0.9064157887660258, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 355, train_loss = 0.9089668078049726, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 356, train_loss = 0.9081700860988349, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 357, train_loss = 0.9075802750885487, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 358, train_loss = 0.907815785612911, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 359, train_loss = 0.9099564403295517, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 360, train_loss = 0.9052570388485037, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 361, train_loss = 0.9072265118993528, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 362, train_loss = 0.9066126317084127, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 363, train_loss = 0.9083144150972657, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 364, train_loss = 0.9093073370568163, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 365, train_loss = 0.9095715070907318, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 366, train_loss = 0.9061785593330569, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 367, train_loss = 0.9075731779448688, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 368, train_loss = 0.9043490203730471, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 369, train_loss = 0.9057329916395247, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 370, train_loss = 0.9073920592963987, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 371, train_loss = 0.9043855958916538, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 372, train_loss = 0.9078767794817395, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 373, train_loss = 0.9040785278193653, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 374, train_loss = 0.9036902178377204, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 375, train_loss = 0.9060544540807314, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 376, train_loss = 0.9053907870948024, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 377, train_loss = 0.9061703463084996, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 378, train_loss = 0.9049393145833164, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 379, train_loss = 0.9044582041278773, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 380, train_loss = 0.903497725881607, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 381, train_loss = 0.9055934643074579, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 382, train_loss = 0.902087688602478, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 383, train_loss = 0.9028629938438826, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 384, train_loss = 0.9017748557962477, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 385, train_loss = 0.9062534139193303, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 386, train_loss = 0.9033525407612615, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 387, train_loss = 0.9032098768111609, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 388, train_loss = 0.902960028808593, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 389, train_loss = 0.9035735301840759, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 390, train_loss = 0.9033502382990264, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 391, train_loss = 0.904644232319697, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 392, train_loss = 0.9020798843521334, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 393, train_loss = 0.9028022474776662, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 394, train_loss = 0.9031267491336621, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 395, train_loss = 0.9023097434546798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 396, train_loss = 0.9019678948279761, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 397, train_loss = 0.9050641032699787, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 398, train_loss = 0.9003983595575846, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 399, train_loss = 0.9016406702976383, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 400, train_loss = 0.9025525664146699, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 401, train_loss = 0.9009309400971688, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 402, train_loss = 0.9021002134140872, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 403, train_loss = 0.9021822817157954, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 404, train_loss = 0.900770520867809, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 405, train_loss = 0.9029676401223696, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 406, train_loss = 0.9021951574068225, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 407, train_loss = 0.9034825615417503, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 408, train_loss = 0.9000776391476393, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 409, train_loss = 0.8986018853029236, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 410, train_loss = 0.9010261875409924, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 411, train_loss = 0.9023975635645911, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 412, train_loss = 0.8998966543404094, train_acc = 0.9979040521658128\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 413, train_loss = 0.900537054403685, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 414, train_loss = 0.8999910146631009, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 415, train_loss = 0.8982165257511951, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 416, train_loss = 0.9040946411369077, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 417, train_loss = 0.9005785201043182, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 418, train_loss = 0.9011333532398567, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 419, train_loss = 0.8993826694786549, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 420, train_loss = 0.9004435784481757, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 421, train_loss = 0.9030387136153877, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 422, train_loss = 0.8993421002924151, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 423, train_loss = 0.8993087703311176, train_acc = 0.9979040521658128\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 424, train_loss = 0.8994734270781919, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 425, train_loss = 0.8984233162664168, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 426, train_loss = 0.9013389025167271, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 427, train_loss = 0.8998973882989958, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 428, train_loss = 0.8991116936267645, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 429, train_loss = 0.8994452595361508, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 430, train_loss = 0.9010147319459065, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 431, train_loss = 0.900553609826602, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 432, train_loss = 0.8998459318245295, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 433, train_loss = 0.8971339148993138, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 434, train_loss = 0.8973537263700564, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 435, train_loss = 0.8991389402071945, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 436, train_loss = 0.9004690384208516, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 437, train_loss = 0.8991001159483858, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 438, train_loss = 0.9004064156906679, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 439, train_loss = 0.8992944327073928, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 440, train_loss = 0.897530485799507, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 441, train_loss = 0.8984247468288231, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 442, train_loss = 0.8977296589582693, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 443, train_loss = 0.8987619801591791, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 444, train_loss = 0.8980496163021598, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 445, train_loss = 0.8969652554951608, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 446, train_loss = 0.8976213986061339, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 447, train_loss = 0.8976017740606039, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 448, train_loss = 0.9023804236785509, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 449, train_loss = 0.8978582091331191, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 450, train_loss = 0.8969723808877461, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 451, train_loss = 0.8996457806606486, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 452, train_loss = 0.8953645191104442, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 453, train_loss = 0.8953730335924774, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 454, train_loss = 0.8986269389279187, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 455, train_loss = 0.8985284344926185, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 456, train_loss = 0.9000024564047635, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 457, train_loss = 0.8973271775757894, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 458, train_loss = 0.8984436383288994, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 459, train_loss = 0.89837998180883, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 460, train_loss = 0.8977814436839253, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 461, train_loss = 0.8975786906266876, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 462, train_loss = 0.8964464171258442, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 463, train_loss = 0.8950183099368587, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 464, train_loss = 0.895289141957619, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 465, train_loss = 0.8955601555062458, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 466, train_loss = 0.894814496354229, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 467, train_loss = 0.8943613527408161, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 468, train_loss = 0.8965115470746241, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 469, train_loss = 0.8954735632687516, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 470, train_loss = 0.8967063646996394, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 471, train_loss = 0.8989036109596782, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 472, train_loss = 0.8978791399858892, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 473, train_loss = 0.8985871607037552, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 474, train_loss = 0.8966970380097337, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 475, train_loss = 0.8967069461941719, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 476, train_loss = 0.8977117271460884, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 477, train_loss = 0.8970846976153553, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 478, train_loss = 0.8976468158252828, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 479, train_loss = 0.893422840279527, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 480, train_loss = 0.8949390266388946, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 481, train_loss = 0.8936234173997946, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 482, train_loss = 0.8956814899975143, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 483, train_loss = 0.896789240941871, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 484, train_loss = 0.895318599010352, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 485, train_loss = 0.8945749623235315, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 486, train_loss = 0.8919110678652942, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 487, train_loss = 0.8914603611519851, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 488, train_loss = 0.89242697681766, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 489, train_loss = 0.8980478395060345, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 490, train_loss = 0.8950720051252574, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 491, train_loss = 0.8930234471336007, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 492, train_loss = 0.893841204331693, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 493, train_loss = 0.8943846204019792, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 494, train_loss = 0.8921999085687276, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 495, train_loss = 0.893668285523745, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 496, train_loss = 0.8937863216269761, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 497, train_loss = 0.8921250671373855, train_acc = 0.9980204937121565\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 498, train_loss = 0.8928281908338249, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 499, train_loss = 0.8945588764145214, train_acc = 0.9980204937121565\n",
      "test Acc 0.9669459962756052:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████████████████████████████████▉                                           | 13/30 [2:02:53<2:50:38, 602.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "14th- epoch: 0, train_loss = 378.92400792241096, train_acc = 0.8211457848160224\n",
      "test Acc 0.8687150837988827:\n",
      "14th- epoch: 1, train_loss = 78.29214557399973, train_acc = 0.9264089427107592\n",
      "test Acc 0.9334264432029795:\n",
      "14th- epoch: 2, train_loss = 47.68995712604374, train_acc = 0.9476013041453191\n",
      "test Acc 0.9418063314711359:\n",
      "14th- epoch: 3, train_loss = 33.77963364031166, train_acc = 0.9597112249650676\n",
      "test Acc 0.9539106145251397:\n",
      "14th- epoch: 4, train_loss = 25.913388905115426, train_acc = 0.9687936655798789\n",
      "test Acc 0.9557728119180633:\n",
      "14th- epoch: 5, train_loss = 20.654514071531594, train_acc = 0.9732184443409408\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 6, train_loss = 16.733812370337546, train_acc = 0.9770610153702841\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 7, train_loss = 13.748429778032005, train_acc = 0.9799720540288775\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 8, train_loss = 11.50707710813731, train_acc = 0.9832324173265021\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 9, train_loss = 9.825670253485441, train_acc = 0.9857941313460643\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 10, train_loss = 8.47742346022278, train_acc = 0.9875407545412203\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 11, train_loss = 7.38787062978372, train_acc = 0.9885887284583139\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 12, train_loss = 6.490535639692098, train_acc = 0.9909175593851887\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 13, train_loss = 5.744234173092991, train_acc = 0.9914997671169073\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 14, train_loss = 5.129572172183543, train_acc = 0.9925477410340009\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 15, train_loss = 4.618131826631725, train_acc = 0.9933628318584071\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 16, train_loss = 4.158539967145771, train_acc = 0.9939450395901258\n",
      "test Acc 0.9641527001862198:\n",
      "14th- epoch: 17, train_loss = 3.7965044933371246, train_acc = 0.9945272473218444\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 18, train_loss = 3.4909872305579484, train_acc = 0.9949930135072194\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 19, train_loss = 3.2221293221227825, train_acc = 0.9956916627852818\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 20, train_loss = 2.9994310601614416, train_acc = 0.995575221238938\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 21, train_loss = 2.8029684755019844, train_acc = 0.9956916627852818\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 22, train_loss = 2.6311881565488875, train_acc = 0.9958081043316255\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 23, train_loss = 2.5003743236884475, train_acc = 0.9959245458779693\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 24, train_loss = 2.3864543880335987, train_acc = 0.996040987424313\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 25, train_loss = 2.291887274943292, train_acc = 0.9962738705170004\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 26, train_loss = 2.2048292635008693, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 27, train_loss = 2.120984508190304, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 28, train_loss = 2.0524321966804564, train_acc = 0.996506753609688\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 29, train_loss = 1.982807966414839, train_acc = 0.996506753609688\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 30, train_loss = 1.9185098386369646, train_acc = 0.996506753609688\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 31, train_loss = 1.8643423425965011, train_acc = 0.9967396367023754\n",
      "test Acc 0.9664804469273743:\n",
      "14th- epoch: 32, train_loss = 1.8122222200036049, train_acc = 0.9967396367023754\n",
      "test Acc 0.9664804469273743:\n",
      "14th- epoch: 33, train_loss = 1.7752905054949224, train_acc = 0.9966231951560317\n",
      "test Acc 0.9664804469273743:\n",
      "14th- epoch: 34, train_loss = 1.7403586704749614, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "14th- epoch: 35, train_loss = 1.7166908180806786, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "14th- epoch: 36, train_loss = 1.6877552012447268, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "14th- epoch: 37, train_loss = 1.6661393363028765, train_acc = 0.9970889613414066\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 38, train_loss = 1.6475217933766544, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "14th- epoch: 39, train_loss = 1.629528052173555, train_acc = 0.9970889613414066\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 40, train_loss = 1.611761832376942, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 41, train_loss = 1.5974584084469825, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 42, train_loss = 1.5810278826393187, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 43, train_loss = 1.5666715307161212, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 44, train_loss = 1.5539982242044061, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 45, train_loss = 1.5416361442767084, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 46, train_loss = 1.5291981267509982, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 47, train_loss = 1.5149830320151523, train_acc = 0.9972054028877504\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 48, train_loss = 1.5065947727998719, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 49, train_loss = 1.4961999845691025, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 50, train_loss = 1.4851440448546782, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 51, train_loss = 1.4753396440064535, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 52, train_loss = 1.4648557836189866, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 53, train_loss = 1.456230807933025, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 54, train_loss = 1.4466906798770651, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 55, train_loss = 1.4394124392420053, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 56, train_loss = 1.4276785491965711, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 57, train_loss = 1.4203490099171177, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 58, train_loss = 1.4112311995122582, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 59, train_loss = 1.404906485346146, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 60, train_loss = 1.3961748806759715, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 61, train_loss = 1.3897140013286844, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 62, train_loss = 1.3786575515987352, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 63, train_loss = 1.3745818763272837, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 64, train_loss = 1.3674811479868367, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 65, train_loss = 1.3601123420521617, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 66, train_loss = 1.353841106290929, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 67, train_loss = 1.344815157004632, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 68, train_loss = 1.3393504161504097, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 69, train_loss = 1.3333725374541245, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 70, train_loss = 1.3283356096944772, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 71, train_loss = 1.3212993399356492, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 72, train_loss = 1.3125934625859372, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 73, train_loss = 1.3102078984375112, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 74, train_loss = 1.3034209280158393, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 75, train_loss = 1.2976193060167134, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 76, train_loss = 1.291717250365764, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 77, train_loss = 1.2865687849116512, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 78, train_loss = 1.2812750909361057, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 79, train_loss = 1.2769321356900036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 80, train_loss = 1.26989518199116, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 81, train_loss = 1.2665917944977991, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 82, train_loss = 1.2622836123337038, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 83, train_loss = 1.2544885709066875, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 84, train_loss = 1.252809845842421, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 85, train_loss = 1.2476528662373312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 86, train_loss = 1.2405009772628546, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 87, train_loss = 1.2404253923450597, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 88, train_loss = 1.2346488914336078, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 89, train_loss = 1.2286184218828566, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 90, train_loss = 1.2254939147387631, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 91, train_loss = 1.2213620599359274, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 92, train_loss = 1.2174912678892724, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 93, train_loss = 1.213576392561663, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 94, train_loss = 1.2078497229958884, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 95, train_loss = 1.20315207663225, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 96, train_loss = 1.201033799618017, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 97, train_loss = 1.1972397795761935, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 98, train_loss = 1.1922992343897931, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 99, train_loss = 1.1896535207924899, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 100, train_loss = 1.1846475433558226, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 101, train_loss = 1.179959516361123, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 102, train_loss = 1.1798764324339572, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 103, train_loss = 1.1740187474933919, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 104, train_loss = 1.1728025286865886, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 105, train_loss = 1.1699775547313038, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 106, train_loss = 1.1623877439124044, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 107, train_loss = 1.1627418892458081, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 108, train_loss = 1.1589568285271525, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 109, train_loss = 1.1546039659006055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 110, train_loss = 1.1515508725715335, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 111, train_loss = 1.148901547305286, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 112, train_loss = 1.1451231529936194, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 113, train_loss = 1.1412523010221776, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 114, train_loss = 1.1388975605368614, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 115, train_loss = 1.1382381437870208, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 116, train_loss = 1.1334202159196138, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 117, train_loss = 1.1306436030718032, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 118, train_loss = 1.1295832923206035, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 119, train_loss = 1.1236662349256221, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 120, train_loss = 1.1223104117962066, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 121, train_loss = 1.1175014066102449, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 122, train_loss = 1.11890260130167, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 123, train_loss = 1.1145989683864173, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 124, train_loss = 1.1104985475540161, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 125, train_loss = 1.108601429819828, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 126, train_loss = 1.106776083499426, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 127, train_loss = 1.1045516760495957, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 128, train_loss = 1.1009284059109632, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 129, train_loss = 1.099323347210884, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 130, train_loss = 1.0956982262432575, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 131, train_loss = 1.0958711660059635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 132, train_loss = 1.0914548771979753, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 133, train_loss = 1.0911013887671288, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 134, train_loss = 1.0883093258889858, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 135, train_loss = 1.0871488712728024, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 136, train_loss = 1.08330394452787, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 137, train_loss = 1.083663072437048, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 138, train_loss = 1.0770615457149688, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 139, train_loss = 1.079797808706644, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 140, train_loss = 1.075834833085537, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 141, train_loss = 1.0755130064935656, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 142, train_loss = 1.0719669740647078, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 143, train_loss = 1.0716841922403546, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 144, train_loss = 1.0679822738020448, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 145, train_loss = 1.0679340319038602, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 146, train_loss = 1.0651701514871093, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 147, train_loss = 1.06367012206465, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 148, train_loss = 1.05959093508136, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 149, train_loss = 1.0624060717673274, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 150, train_loss = 1.0579636388720246, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 151, train_loss = 1.0567480083554983, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 152, train_loss = 1.053670554421842, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 153, train_loss = 1.0554671380668879, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 154, train_loss = 1.051928300410509, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 155, train_loss = 1.0501301369367866, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 156, train_loss = 1.0481702337710885, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 157, train_loss = 1.0481333378702402, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 158, train_loss = 1.0458426689729095, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 159, train_loss = 1.0449761403724551, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 160, train_loss = 1.04167184450489, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 161, train_loss = 1.0420499605388613, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 162, train_loss = 1.0384218699036865, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 163, train_loss = 1.0393328222708078, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 164, train_loss = 1.036285252936068, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 165, train_loss = 1.0361866407765774, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 166, train_loss = 1.0331813444645377, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 167, train_loss = 1.0340251053421525, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 168, train_loss = 1.0301974403409986, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 169, train_loss = 1.03069157495338, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 170, train_loss = 1.0278467740863562, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 171, train_loss = 1.0280940610246034, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 172, train_loss = 1.025693384304759, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 173, train_loss = 1.025554718755302, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 174, train_loss = 1.0248425758181838, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 175, train_loss = 1.0215091786085395, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 176, train_loss = 1.0229928391054273, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 177, train_loss = 1.0200780552549986, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 178, train_loss = 1.019712836787221, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 179, train_loss = 1.0181011650711298, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 180, train_loss = 1.0174204505310627, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 181, train_loss = 1.014914280429366, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 182, train_loss = 1.0154277173132868, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 183, train_loss = 1.0148978459910722, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 184, train_loss = 1.0121498415246606, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 185, train_loss = 1.012188719585538, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 186, train_loss = 1.0114034097641706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 187, train_loss = 1.0087014970631571, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 188, train_loss = 1.0078251895756694, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 189, train_loss = 1.006559561312315, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 190, train_loss = 1.0054325715900632, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 191, train_loss = 1.0036668131797342, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 192, train_loss = 1.0021591105760308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 193, train_loss = 1.0017888257279992, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 194, train_loss = 1.0004959674552083, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 195, train_loss = 1.0004868293181062, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 196, train_loss = 0.9977257813588949, train_acc = 0.9977876106194691\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 197, train_loss = 0.9993959376588464, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 198, train_loss = 0.9959704556240467, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 199, train_loss = 0.9963121796026826, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 200, train_loss = 0.994765020594059, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 201, train_loss = 0.995265577606915, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 202, train_loss = 0.9931760958061204, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 203, train_loss = 0.991884518727602, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 204, train_loss = 0.99141855227208, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 205, train_loss = 0.9916823015882983, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 206, train_loss = 0.9888357228264795, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 207, train_loss = 0.9901314036324038, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 208, train_loss = 0.9874567445367575, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 209, train_loss = 0.9867503022178425, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 210, train_loss = 0.9871355683208094, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 211, train_loss = 0.9855413381010294, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 212, train_loss = 0.9845897456034436, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 213, train_loss = 0.9847107681780471, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 214, train_loss = 0.9825324015691876, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 215, train_loss = 0.9835193107501254, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 216, train_loss = 0.9812855112031684, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 217, train_loss = 0.9806197077632532, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 218, train_loss = 0.9795112743377103, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 219, train_loss = 0.9792267583907233, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 220, train_loss = 0.9776744541377411, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 221, train_loss = 0.9775384975000634, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 222, train_loss = 0.9764204643070116, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 223, train_loss = 0.9779544823468314, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 224, train_loss = 0.975108727812767, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 225, train_loss = 0.9763117609545588, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 226, train_loss = 0.9741674680262804, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 227, train_loss = 0.9744019766003476, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 228, train_loss = 0.9725559642538428, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 229, train_loss = 0.9712708589286194, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 230, train_loss = 0.9703973984942422, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 231, train_loss = 0.9693167265504599, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 232, train_loss = 0.9701352429910912, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 233, train_loss = 0.9707837008536444, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 234, train_loss = 0.9679320929571986, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 235, train_loss = 0.9696022337302566, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 236, train_loss = 0.9659344072788372, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 237, train_loss = 0.9680954699069844, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 238, train_loss = 0.9650857765227556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 239, train_loss = 0.9668310194610967, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 240, train_loss = 0.9644680131823407, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 241, train_loss = 0.9645816244519665, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 242, train_loss = 0.9634843356907368, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 243, train_loss = 0.9642592035233974, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 244, train_loss = 0.962086101375462, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 245, train_loss = 0.9632054615431116, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 246, train_loss = 0.9602342074140324, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 247, train_loss = 0.9620721264145686, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 248, train_loss = 0.9584724269807339, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 249, train_loss = 0.9605020224116743, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 250, train_loss = 0.9578687536195503, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 251, train_loss = 0.9576165283433511, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 252, train_loss = 0.9567300396374776, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 253, train_loss = 0.9561717524193227, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 254, train_loss = 0.9553539454936981, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 255, train_loss = 0.9560294977054582, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 256, train_loss = 0.9542898099534796, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 257, train_loss = 0.953074903380184, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 258, train_loss = 0.9546837620437145, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 259, train_loss = 0.952806629393308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 260, train_loss = 0.9513473642655299, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 261, train_loss = 0.9538708679974661, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 262, train_loss = 0.951097538229078, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 263, train_loss = 0.9530610291621997, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 264, train_loss = 0.951012304831238, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 265, train_loss = 0.9511670164429233, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 266, train_loss = 0.9484957483000471, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 267, train_loss = 0.9483816333449795, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 268, train_loss = 0.9489138961434946, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 269, train_loss = 0.9478925565854297, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 270, train_loss = 0.947365362662822, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 271, train_loss = 0.9474341296590865, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 272, train_loss = 0.9463449004106224, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 273, train_loss = 0.9450844271705137, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 274, train_loss = 0.9449382664970472, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 275, train_loss = 0.9445862293578102, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 276, train_loss = 0.9441592472940101, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 277, train_loss = 0.9444583174772561, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 278, train_loss = 0.9428138574585319, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 279, train_loss = 0.9431146723218262, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 280, train_loss = 0.9410682443194673, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 281, train_loss = 0.9413546845316887, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 282, train_loss = 0.9408575599081814, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 283, train_loss = 0.9404736473225057, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 284, train_loss = 0.94069988202682, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 285, train_loss = 0.9398258249275386, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 286, train_loss = 0.9392144652083516, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 287, train_loss = 0.9375727244987502, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 288, train_loss = 0.9380348130725906, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 289, train_loss = 0.9381054644472897, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 290, train_loss = 0.9378292892761237, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 291, train_loss = 0.9373659285083704, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 292, train_loss = 0.9363357909023762, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 293, train_loss = 0.93673448683694, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 294, train_loss = 0.9347866581119888, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 295, train_loss = 0.9339130387343175, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 296, train_loss = 0.9349959132559889, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 297, train_loss = 0.9343156681097753, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 298, train_loss = 0.9343205471523106, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 299, train_loss = 0.9353141792416864, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 300, train_loss = 0.9325814562216692, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 301, train_loss = 0.9315577850975387, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 302, train_loss = 0.9322109776549041, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 303, train_loss = 0.9321109660268121, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 304, train_loss = 0.9313861612863548, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 305, train_loss = 0.931286592502147, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 306, train_loss = 0.9307355924211151, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 307, train_loss = 0.9300733891614072, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 308, train_loss = 0.9297456077001698, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 309, train_loss = 0.9297228128016286, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 310, train_loss = 0.9288462521508336, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 311, train_loss = 0.9285650018136948, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 312, train_loss = 0.9277239558286965, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 313, train_loss = 0.9275613979734771, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 314, train_loss = 0.927792420687183, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 315, train_loss = 0.9268539263102866, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 316, train_loss = 0.9268706967122853, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 317, train_loss = 0.9263684942852706, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 318, train_loss = 0.9255643954966217, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 319, train_loss = 0.9258789063133008, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 320, train_loss = 0.9250115695576824, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 321, train_loss = 0.9240426507312804, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 322, train_loss = 0.9242914485912479, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 323, train_loss = 0.9234540310390003, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 324, train_loss = 0.923624109087541, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 325, train_loss = 0.9223915866277821, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 326, train_loss = 0.9222132377326488, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 327, train_loss = 0.9223653198387183, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 328, train_loss = 0.9221688814759545, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 329, train_loss = 0.921006389969989, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 330, train_loss = 0.9214363941755437, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 331, train_loss = 0.9203990390524268, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 332, train_loss = 0.9219091577288054, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 333, train_loss = 0.9204119053501927, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 334, train_loss = 0.9198097652588331, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 335, train_loss = 0.9193896347023838, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 336, train_loss = 0.9192321385089599, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 337, train_loss = 0.9188034136313945, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 338, train_loss = 0.9179993964098685, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 339, train_loss = 0.9182547957170755, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 340, train_loss = 0.9178547194060229, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 341, train_loss = 0.9170375604480796, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 342, train_loss = 0.9159962631129019, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 343, train_loss = 0.9167373970449262, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 344, train_loss = 0.9164383212737448, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 345, train_loss = 0.9155039108190977, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 346, train_loss = 0.9145841393619776, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 347, train_loss = 0.9146225627810054, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 348, train_loss = 0.9135856777429581, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 349, train_loss = 0.9141715255864256, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 350, train_loss = 0.9146315163634426, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 351, train_loss = 0.9139310205755464, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 352, train_loss = 0.9127649136753462, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 353, train_loss = 0.9135446677282744, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 354, train_loss = 0.9128059150352783, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 355, train_loss = 0.9125365936597518, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 356, train_loss = 0.9117164448434778, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 357, train_loss = 0.9119840721068613, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 358, train_loss = 0.9114648695103824, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 359, train_loss = 0.910565853893786, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 360, train_loss = 0.910649208817631, train_acc = 0.9981369352585002\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 361, train_loss = 0.909517141757533, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 362, train_loss = 0.9102252753618814, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 363, train_loss = 0.9101603633789637, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 364, train_loss = 0.908971744862356, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 365, train_loss = 0.909426764195814, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 366, train_loss = 0.9096112710358284, train_acc = 0.9980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 367, train_loss = 0.9078908355040767, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 368, train_loss = 0.9069423319706402, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 369, train_loss = 0.9074526592157781, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 370, train_loss = 0.9064372584871307, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 371, train_loss = 0.9065630825534754, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 372, train_loss = 0.9059475285648659, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 373, train_loss = 0.9063181835808791, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 374, train_loss = 0.905963806395448, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 375, train_loss = 0.9053409232110425, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 376, train_loss = 0.9047870993963443, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 377, train_loss = 0.9046436116914265, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 378, train_loss = 0.9057492626780004, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 379, train_loss = 0.9060169824915647, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 380, train_loss = 0.9042363367625512, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 381, train_loss = 0.9036875644633255, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 382, train_loss = 0.9034382715180982, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 383, train_loss = 0.9036158421076834, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 384, train_loss = 0.9026467875919479, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 385, train_loss = 0.9025899551161274, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 386, train_loss = 0.9019064313288254, train_acc = 0.9980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 387, train_loss = 0.9025353108409035, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 388, train_loss = 0.902335310845956, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 389, train_loss = 0.901977717425325, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 390, train_loss = 0.902290252266539, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 391, train_loss = 0.9011563150997972, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 392, train_loss = 0.9008688932408404, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 393, train_loss = 0.9028004074170894, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 394, train_loss = 0.9011619641860307, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 395, train_loss = 0.9015083190461155, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 396, train_loss = 0.9009458368527703, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 397, train_loss = 0.9004144876089413, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 398, train_loss = 0.900522600102704, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 399, train_loss = 0.8982768242713064, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 400, train_loss = 0.8992015142393939, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 401, train_loss = 0.897767190792365, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 402, train_loss = 0.8993673444310843, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 403, train_loss = 0.8999202867853455, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 404, train_loss = 0.8980072451122396, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 405, train_loss = 0.89799470390426, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 406, train_loss = 0.8981342982551723, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 407, train_loss = 0.8971557884360664, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 408, train_loss = 0.8978105527148728, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 409, train_loss = 0.895816488773562, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 410, train_loss = 0.8969190169973444, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 411, train_loss = 0.8950634268112481, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 412, train_loss = 0.8966915514702123, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 413, train_loss = 0.8962358830412995, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 414, train_loss = 0.8948665905827511, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 415, train_loss = 0.8956973169697449, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 416, train_loss = 0.8942479013549018, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 417, train_loss = 0.8956387261478085, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 418, train_loss = 0.895686045909315, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 419, train_loss = 0.895533851464279, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 420, train_loss = 0.8939456675434485, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 421, train_loss = 0.8943102071843896, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 422, train_loss = 0.8937800026415061, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 423, train_loss = 0.8938317452175397, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 424, train_loss = 0.8939782323232066, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 425, train_loss = 0.893526817089878, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 426, train_loss = 0.893617663959958, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 427, train_loss = 0.8935258707879257, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 428, train_loss = 0.8925594827942405, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 429, train_loss = 0.894077270058915, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 430, train_loss = 0.8925844190325734, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 431, train_loss = 0.8934599823551252, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 432, train_loss = 0.8927324768155813, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 433, train_loss = 0.8908705126177665, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 434, train_loss = 0.8916706340387464, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 435, train_loss = 0.8916206466965377, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 436, train_loss = 0.8907669575419277, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 437, train_loss = 0.8909481819719076, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 438, train_loss = 0.8901649479139451, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 439, train_loss = 0.8902937817238126, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 440, train_loss = 0.8898932930696901, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 441, train_loss = 0.8907760997917649, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 442, train_loss = 0.8911025770157721, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 443, train_loss = 0.8894865910988301, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 444, train_loss = 0.8890300154071156, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 445, train_loss = 0.8890950356144458, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 446, train_loss = 0.8906132441479713, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 447, train_loss = 0.887401558304191, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 448, train_loss = 0.8902852735482156, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 449, train_loss = 0.8870225769933313, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 450, train_loss = 0.8879793084543053, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 451, train_loss = 0.8876131173838075, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 452, train_loss = 0.8875187812373042, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 453, train_loss = 0.8890271716900315, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 454, train_loss = 0.8862034938447323, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 455, train_loss = 0.8867558805122826, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 456, train_loss = 0.8862478957362327, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 457, train_loss = 0.8865136894546595, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 458, train_loss = 0.8862150945551548, train_acc = 0.9981369352585002\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 459, train_loss = 0.8871544543653727, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 460, train_loss = 0.8844276741929207, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 461, train_loss = 0.8861332493052032, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 462, train_loss = 0.8864025385119021, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 463, train_loss = 0.8855598184745759, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 464, train_loss = 0.8847320859003958, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 465, train_loss = 0.8857851956654486, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 466, train_loss = 0.8842212823219597, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 467, train_loss = 0.8845699779540155, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 468, train_loss = 0.8840571994278434, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 469, train_loss = 0.8854477395452705, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 470, train_loss = 0.8844146390911192, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 471, train_loss = 0.8842092380709801, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 472, train_loss = 0.8867307539712783, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 473, train_loss = 0.88354376796633, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 474, train_loss = 0.8860941303428262, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 475, train_loss = 0.8830981233622879, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 476, train_loss = 0.883693965151906, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 477, train_loss = 0.8827133811228123, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 478, train_loss = 0.8835808103904128, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 479, train_loss = 0.8838807047195587, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 480, train_loss = 0.8822947357930389, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 481, train_loss = 0.8846625932492316, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 482, train_loss = 0.8825713954865932, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 483, train_loss = 0.8821034183110896, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 484, train_loss = 0.8825500592738535, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 485, train_loss = 0.8813030447345227, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 486, train_loss = 0.8817720026709139, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 487, train_loss = 0.8816912739221152, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 488, train_loss = 0.8812149678506103, train_acc = 0.9982533768048439\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 489, train_loss = 0.8834025379419472, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 490, train_loss = 0.880674801146597, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 491, train_loss = 0.8821992011125985, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 492, train_loss = 0.8816166215892736, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 493, train_loss = 0.8796775796599832, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 494, train_loss = 0.8812909311764088, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 495, train_loss = 0.879450355656445, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 496, train_loss = 0.8824047789294127, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 497, train_loss = 0.879228161958963, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 498, train_loss = 0.881028714356944, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 499, train_loss = 0.880432693675175, train_acc = 0.9982533768048439\n",
      "test Acc 0.9711359404096834:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|███████████████████████████████████▍                                        | 14/30 [2:13:15<2:42:10, 608.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "15th- epoch: 0, train_loss = 355.539771551732, train_acc = 0.8057755006986492\n",
      "test Acc 0.9134078212290503:\n",
      "15th- epoch: 1, train_loss = 74.35702122375369, train_acc = 0.9253609687936656\n",
      "test Acc 0.931098696461825:\n",
      "15th- epoch: 2, train_loss = 47.07466543838382, train_acc = 0.9469026548672567\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 3, train_loss = 33.94904986396432, train_acc = 0.959944108057755\n",
      "test Acc 0.9450651769087524:\n",
      "15th- epoch: 4, train_loss = 25.915647049667314, train_acc = 0.966581276199348\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 5, train_loss = 20.370489979861304, train_acc = 0.9713553795994411\n",
      "test Acc 0.9515828677839852:\n",
      "15th- epoch: 6, train_loss = 16.401670244755223, train_acc = 0.9749650675360969\n",
      "test Acc 0.9506517690875232:\n",
      "15th- epoch: 7, train_loss = 13.540990218520164, train_acc = 0.9790405216581276\n",
      "test Acc 0.952048417132216:\n",
      "15th- epoch: 8, train_loss = 11.309579172404483, train_acc = 0.9821844434094085\n",
      "test Acc 0.9562383612662942:\n",
      "15th- epoch: 9, train_loss = 9.634617416886613, train_acc = 0.9838146250582208\n",
      "test Acc 0.957635009310987:\n",
      "15th- epoch: 10, train_loss = 8.290485338540748, train_acc = 0.9850954820680019\n",
      "test Acc 0.9594972067039106:\n",
      "15th- epoch: 11, train_loss = 7.31422608345747, train_acc = 0.9871914299021891\n",
      "test Acc 0.9604283054003724:\n",
      "15th- epoch: 12, train_loss = 6.514631281374022, train_acc = 0.9888216115510013\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 13, train_loss = 5.883524879813194, train_acc = 0.9896367023754076\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 14, train_loss = 5.3124879859387875, train_acc = 0.9902189101071263\n",
      "test Acc 0.9604283054003724:\n",
      "15th- epoch: 15, train_loss = 4.83625881629996, train_acc = 0.9911504424778761\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 16, train_loss = 4.432583908201195, train_acc = 0.9913833255705635\n",
      "test Acc 0.962756052141527:\n",
      "15th- epoch: 17, train_loss = 4.089703143923543, train_acc = 0.992081974848626\n",
      "test Acc 0.9622905027932961:\n",
      "15th- epoch: 18, train_loss = 3.804005268961191, train_acc = 0.9927806241266884\n",
      "test Acc 0.9622905027932961:\n",
      "15th- epoch: 19, train_loss = 3.5829410577425733, train_acc = 0.9933628318584071\n",
      "test Acc 0.9632216014897579:\n",
      "15th- epoch: 20, train_loss = 3.4018872355809435, train_acc = 0.9933628318584071\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 21, train_loss = 3.223446880816482, train_acc = 0.9939450395901258\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 22, train_loss = 3.088422710658051, train_acc = 0.9939450395901258\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 23, train_loss = 2.96719129383564, train_acc = 0.993828598043782\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 24, train_loss = 2.8462184058735147, train_acc = 0.9939450395901258\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 25, train_loss = 2.7570363134145737, train_acc = 0.9940614811364695\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 26, train_loss = 2.6552904794807546, train_acc = 0.9944108057755007\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 27, train_loss = 2.578068708360661, train_acc = 0.9944108057755007\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 28, train_loss = 2.4990251983399503, train_acc = 0.9945272473218444\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 29, train_loss = 2.4343174907262437, train_acc = 0.9945272473218444\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 30, train_loss = 2.3681177918915637, train_acc = 0.9946436888681882\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 31, train_loss = 2.3038736817543395, train_acc = 0.9946436888681882\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 32, train_loss = 2.2439336801762693, train_acc = 0.9945272473218444\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 33, train_loss = 2.1896020298008807, train_acc = 0.9945272473218444\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 34, train_loss = 2.1363944833283313, train_acc = 0.9947601304145319\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 35, train_loss = 2.0949895319645293, train_acc = 0.9951094550535631\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 36, train_loss = 2.052117448300123, train_acc = 0.9949930135072194\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 37, train_loss = 2.01153782257461, train_acc = 0.9951094550535631\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 38, train_loss = 1.9780684324505273, train_acc = 0.9951094550535631\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 39, train_loss = 1.9464177352492698, train_acc = 0.9953423381462506\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 40, train_loss = 1.9169754472968634, train_acc = 0.9953423381462506\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 41, train_loss = 1.8894832929072436, train_acc = 0.9954587796925943\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 42, train_loss = 1.8637368952331599, train_acc = 0.9956916627852818\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 43, train_loss = 1.8408451477589551, train_acc = 0.9958081043316255\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 44, train_loss = 1.8202740475535393, train_acc = 0.996040987424313\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 45, train_loss = 1.7954263811407145, train_acc = 0.9962738705170004\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 46, train_loss = 1.7794761421682779, train_acc = 0.9961574289706567\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 47, train_loss = 1.760210511594778, train_acc = 0.9963903120633442\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 48, train_loss = 1.7424966407415923, train_acc = 0.9963903120633442\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 49, train_loss = 1.7262074798345566, train_acc = 0.9962738705170004\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 50, train_loss = 1.7066136958601419, train_acc = 0.9963903120633442\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 51, train_loss = 1.6944652473030146, train_acc = 0.9962738705170004\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 52, train_loss = 1.678602291882271, train_acc = 0.9962738705170004\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 53, train_loss = 1.6685299724340439, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 54, train_loss = 1.6516569977102336, train_acc = 0.996506753609688\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 55, train_loss = 1.6405981866118964, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 56, train_loss = 1.6250023717584554, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 57, train_loss = 1.61311705908156, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 58, train_loss = 1.6018291364016477, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 59, train_loss = 1.5909729028644506, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 60, train_loss = 1.5793268842098769, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 61, train_loss = 1.5683435052633286, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 62, train_loss = 1.5559900303633185, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 63, train_loss = 1.5473946829733904, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 64, train_loss = 1.5361321183590917, train_acc = 0.996506753609688\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 65, train_loss = 1.5273011773824692, train_acc = 0.996506753609688\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 66, train_loss = 1.5159947288484545, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 67, train_loss = 1.5079615376889706, train_acc = 0.9966231951560317\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 68, train_loss = 1.4999051950871944, train_acc = 0.9966231951560317\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 69, train_loss = 1.4903100468218327, train_acc = 0.9967396367023754\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 70, train_loss = 1.480861787989852, train_acc = 0.9967396367023754\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 71, train_loss = 1.4728956868202658, train_acc = 0.9967396367023754\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 72, train_loss = 1.4650376439094543, train_acc = 0.9967396367023754\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 73, train_loss = 1.4577683582901955, train_acc = 0.9967396367023754\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 74, train_loss = 1.4489652179181576, train_acc = 0.9967396367023754\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 75, train_loss = 1.4377597433776828, train_acc = 0.9967396367023754\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 76, train_loss = 1.4289004753081826, train_acc = 0.9967396367023754\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 77, train_loss = 1.4205342469067546, train_acc = 0.9967396367023754\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 78, train_loss = 1.4130581195204286, train_acc = 0.9967396367023754\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 79, train_loss = 1.4061558495013742, train_acc = 0.9968560782487191\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 80, train_loss = 1.3973627177329035, train_acc = 0.9967396367023754\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 81, train_loss = 1.3930398796946974, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 82, train_loss = 1.3859777140169172, train_acc = 0.9966231951560317\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 83, train_loss = 1.3770696260035038, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 84, train_loss = 1.3700940335838823, train_acc = 0.9967396367023754\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 85, train_loss = 1.3625907003879547, train_acc = 0.9967396367023754\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 86, train_loss = 1.3603480880410643, train_acc = 0.9967396367023754\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 87, train_loss = 1.3505042480974225, train_acc = 0.9967396367023754\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 88, train_loss = 1.3466303509922, train_acc = 0.9967396367023754\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 89, train_loss = 1.3403290112764807, train_acc = 0.9967396367023754\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 90, train_loss = 1.333007822438958, train_acc = 0.9967396367023754\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 91, train_loss = 1.3265291129500838, train_acc = 0.9967396367023754\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 92, train_loss = 1.320806213960168, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 93, train_loss = 1.3160774980933638, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 94, train_loss = 1.3079893949179677, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 95, train_loss = 1.3070384872407885, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 96, train_loss = 1.299463105693576, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 97, train_loss = 1.2952222811727552, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 98, train_loss = 1.2887620143592358, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 99, train_loss = 1.285462057843688, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 100, train_loss = 1.280068167798163, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 101, train_loss = 1.2742569620459108, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 102, train_loss = 1.2697709028871031, train_acc = 0.9968560782487191\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 103, train_loss = 1.2669665167777566, train_acc = 0.9968560782487191\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 104, train_loss = 1.2592804419546155, train_acc = 0.9968560782487191\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 105, train_loss = 1.2580982968211174, train_acc = 0.9968560782487191\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 106, train_loss = 1.2510081231594086, train_acc = 0.9968560782487191\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 107, train_loss = 1.2482177875936031, train_acc = 0.9968560782487191\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 108, train_loss = 1.245391994714737, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 109, train_loss = 1.2405607749969931, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 110, train_loss = 1.236057588204858, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 111, train_loss = 1.2328593917191029, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 112, train_loss = 1.2265865082517848, train_acc = 0.9968560782487191\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 113, train_loss = 1.2233636900782585, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 114, train_loss = 1.2182582256646128, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 115, train_loss = 1.2112093555479078, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 116, train_loss = 1.2087365003972081, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 117, train_loss = 1.2060779916719184, train_acc = 0.9968560782487191\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 118, train_loss = 1.2007669185622944, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 119, train_loss = 1.1994698233902454, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 120, train_loss = 1.1941173275336041, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 121, train_loss = 1.192070808261633, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 122, train_loss = 1.187275910131575, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 123, train_loss = 1.1870733126997948, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 124, train_loss = 1.1808788937851205, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 125, train_loss = 1.180647107459663, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 126, train_loss = 1.1761924090460525, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 127, train_loss = 1.1743551157414913, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 128, train_loss = 1.1704536428078427, train_acc = 0.9968560782487191\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 129, train_loss = 1.1676831667646184, train_acc = 0.9968560782487191\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 130, train_loss = 1.1659652168527828, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 131, train_loss = 1.161703443773149, train_acc = 0.9969725197950629\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 132, train_loss = 1.160515642412065, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 133, train_loss = 1.1576264637187705, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 134, train_loss = 1.1557742469012737, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 135, train_loss = 1.1528431748374715, train_acc = 0.9969725197950629\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 136, train_loss = 1.1487485840916634, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 137, train_loss = 1.1480356380343437, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 138, train_loss = 1.1465055483058677, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 139, train_loss = 1.1440679195002303, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 140, train_loss = 1.1407994292676449, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 141, train_loss = 1.1377078083678498, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 142, train_loss = 1.136899863682629, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 143, train_loss = 1.1344326511025429, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 144, train_loss = 1.1329854217692628, train_acc = 0.9969725197950629\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 145, train_loss = 1.130149096250534, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 146, train_loss = 1.127476283661963, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 147, train_loss = 1.1254645201042877, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 148, train_loss = 1.1229328736662865, train_acc = 0.9969725197950629\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 149, train_loss = 1.1226913295686245, train_acc = 0.9969725197950629\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 150, train_loss = 1.1204552501440048, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 151, train_loss = 1.1179890645071282, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 152, train_loss = 1.1155897776261554, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 153, train_loss = 1.1140490559264435, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 154, train_loss = 1.113072024039866, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 155, train_loss = 1.1102642826735973, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 156, train_loss = 1.108481372393726, train_acc = 0.9970889613414066\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 157, train_loss = 1.1056426999493851, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 158, train_loss = 1.1058059558272362, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 159, train_loss = 1.1028811956421123, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 160, train_loss = 1.1025176979601383, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 161, train_loss = 1.0981751320287003, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 162, train_loss = 1.0971786379814148, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 163, train_loss = 1.0961888184174313, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 164, train_loss = 1.0950487715526833, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 165, train_loss = 1.093005566544889, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 166, train_loss = 1.090396761894226, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 167, train_loss = 1.0882798867896781, train_acc = 0.9969725197950629\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 168, train_loss = 1.0881170369684696, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 169, train_loss = 1.0861050213352428, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 170, train_loss = 1.0848438628017902, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 171, train_loss = 1.0827885580583825, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 172, train_loss = 1.0809552992359386, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 173, train_loss = 1.0793351853862987, train_acc = 0.9969725197950629\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 174, train_loss = 1.0781686802729382, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 175, train_loss = 1.0783485248684883, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 176, train_loss = 1.074910597257258, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 177, train_loss = 1.0731451349929557, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 178, train_loss = 1.0713049409314408, train_acc = 0.9969725197950629\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 179, train_loss = 1.071849891297461, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 180, train_loss = 1.0700748612507596, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 181, train_loss = 1.068318014346005, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 182, train_loss = 1.066631481051445, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 183, train_loss = 1.0651060069576488, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 184, train_loss = 1.0638438425958157, train_acc = 0.9969725197950629\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 185, train_loss = 1.0614501548334374, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 186, train_loss = 1.061835919819714, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 187, train_loss = 1.0598028488457203, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 188, train_loss = 1.0572495075539337, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 189, train_loss = 1.0570880149825825, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 190, train_loss = 1.0565183920189156, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 191, train_loss = 1.0543562422171817, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 192, train_loss = 1.0533539652824402, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 193, train_loss = 1.0517146537677036, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 194, train_loss = 1.0504574701189995, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 195, train_loss = 1.0483742716387496, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 196, train_loss = 1.0475570994094596, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 197, train_loss = 1.0462284162640572, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 198, train_loss = 1.0467182770371437, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 199, train_loss = 1.0444312232211814, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 200, train_loss = 1.0427720149382367, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 201, train_loss = 1.041339465729834, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 202, train_loss = 1.0407378797754063, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 203, train_loss = 1.039154010511993, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 204, train_loss = 1.0396307011469617, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 205, train_loss = 1.0372840290292515, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 206, train_loss = 1.0360402104779496, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 207, train_loss = 1.0350483879446983, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 208, train_loss = 1.0332194877191796, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 209, train_loss = 1.031737835459353, train_acc = 0.9970889613414066\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 210, train_loss = 1.03115187833464, train_acc = 0.9972054028877504\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 211, train_loss = 1.0320419979616418, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 212, train_loss = 1.029081934444548, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 213, train_loss = 1.0292842661365285, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 214, train_loss = 1.0278795920312405, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 215, train_loss = 1.0263542644679546, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 216, train_loss = 1.0247913748025894, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 217, train_loss = 1.0238236015065922, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 218, train_loss = 1.0227442607283592, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 219, train_loss = 1.0229218142703758, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 220, train_loss = 1.0218954756855965, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 221, train_loss = 1.0198951599522843, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 222, train_loss = 1.0190097702070489, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 223, train_loss = 1.0175404002293362, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 224, train_loss = 1.0177606654688134, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 225, train_loss = 1.0166471116244793, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 226, train_loss = 1.0155613012611866, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 227, train_loss = 1.0134459845721722, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 228, train_loss = 1.0129286112860427, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 229, train_loss = 1.012629004813789, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 230, train_loss = 1.0108505648895516, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 231, train_loss = 1.0111927526668296, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 232, train_loss = 1.0095102091654553, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 233, train_loss = 1.0076499618589878, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 234, train_loss = 1.0070232873185887, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 235, train_loss = 1.0056081227958202, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 236, train_loss = 1.0061902118250146, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 237, train_loss = 1.004828754812479, train_acc = 0.9972054028877504\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 238, train_loss = 1.0041992825790658, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 239, train_loss = 1.002367106579186, train_acc = 0.9973218444340941\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 240, train_loss = 1.0024411839767708, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 241, train_loss = 0.9995462149381638, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 242, train_loss = 0.9992423318326473, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 243, train_loss = 0.9987550526857376, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 244, train_loss = 0.9987366398199811, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 245, train_loss = 0.9953191516324296, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 246, train_loss = 0.9968234126790776, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 247, train_loss = 0.9935494872406707, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 248, train_loss = 0.9950490854680538, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 249, train_loss = 0.9920394035652862, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 250, train_loss = 0.9926006346940994, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 251, train_loss = 0.9905477190986858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 252, train_loss = 0.9900788714512601, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 253, train_loss = 0.9896321085616364, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 254, train_loss = 0.989148922264576, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 255, train_loss = 0.9865121766924858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 256, train_loss = 0.9868775183931575, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 257, train_loss = 0.9867155862375512, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 258, train_loss = 0.9865210478528752, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 259, train_loss = 0.9837128656581626, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 260, train_loss = 0.9827178890482173, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 261, train_loss = 0.9832148564382805, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 262, train_loss = 0.98325962448871, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 263, train_loss = 0.9817550542429672, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 264, train_loss = 0.9814429009929881, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 265, train_loss = 0.9788582064211369, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 266, train_loss = 0.9784399631098495, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 267, train_loss = 0.978595782071352, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 268, train_loss = 0.9781002899035229, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 269, train_loss = 0.976991689451097, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 270, train_loss = 0.9766750956550823, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 271, train_loss = 0.9762108897193684, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 272, train_loss = 0.9752532318234444, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 273, train_loss = 0.9742943917735829, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 274, train_loss = 0.9740787831469788, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 275, train_loss = 0.9720924347639084, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 276, train_loss = 0.9721430192366824, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 277, train_loss = 0.9702553662136779, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 278, train_loss = 0.9705112216397538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 279, train_loss = 0.9687509325667634, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 280, train_loss = 0.9687770679593086, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 281, train_loss = 0.9679322578012943, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 282, train_loss = 0.9672558630481944, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 283, train_loss = 0.9665659293532372, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 284, train_loss = 0.9664332730098977, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 285, train_loss = 0.9653459365144954, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 286, train_loss = 0.9647426269948483, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 287, train_loss = 0.9642931955531822, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 288, train_loss = 0.9636231785043492, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 289, train_loss = 0.9638016795142903, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 290, train_loss = 0.9617206466718926, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 291, train_loss = 0.9619913659989834, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 292, train_loss = 0.9609874250963912, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 293, train_loss = 0.9597226604819298, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 294, train_loss = 0.9602903760969639, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 295, train_loss = 0.9586726998313679, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 296, train_loss = 0.9587464531286969, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 297, train_loss = 0.9581345083788619, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 298, train_loss = 0.9582207674757228, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 299, train_loss = 0.957113467156887, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 300, train_loss = 0.956252316631435, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 301, train_loss = 0.9557142443954945, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 302, train_loss = 0.9546714524403797, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 303, train_loss = 0.9545009682551608, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 304, train_loss = 0.9539795021191821, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 305, train_loss = 0.9530883108600392, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 306, train_loss = 0.9524981478825794, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 307, train_loss = 0.9522719172164216, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 308, train_loss = 0.9517440857962356, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 309, train_loss = 0.9511104648336186, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 310, train_loss = 0.9504239882007823, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 311, train_loss = 0.9500753792599426, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 312, train_loss = 0.9495737714096322, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 313, train_loss = 0.9491474653259502, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 314, train_loss = 0.9478708108290448, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 315, train_loss = 0.9487970632835641, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 316, train_loss = 0.9470721247271285, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 317, train_loss = 0.9461750748232589, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 318, train_loss = 0.9466051173731103, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 319, train_loss = 0.9456516069694771, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 320, train_loss = 0.9458229107185616, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 321, train_loss = 0.944757475204824, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 322, train_loss = 0.9445639165714965, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 323, train_loss = 0.944096756480576, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 324, train_loss = 0.9432837131098495, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 325, train_loss = 0.9429236650466919, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 326, train_loss = 0.941765695810318, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 327, train_loss = 0.9420667228623643, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 328, train_loss = 0.9413785040378571, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 329, train_loss = 0.940837583191751, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 330, train_loss = 0.9403210766613483, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 331, train_loss = 0.9402464181184769, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 332, train_loss = 0.9390712268650532, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 333, train_loss = 0.9388799207881675, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 334, train_loss = 0.9387756561263814, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 335, train_loss = 0.9371705005542026, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 336, train_loss = 0.9379537229760899, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 337, train_loss = 0.9370445559397922, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 338, train_loss = 0.9365722338334308, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 339, train_loss = 0.936579030007124, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 340, train_loss = 0.9356802726761089, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 341, train_loss = 0.935017562158464, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 342, train_loss = 0.9344762551263557, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 343, train_loss = 0.9337143525481224, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 344, train_loss = 0.9341248137279763, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 345, train_loss = 0.9336795347408042, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 346, train_loss = 0.9328622979446664, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 347, train_loss = 0.932154347501637, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 348, train_loss = 0.9321948202923522, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 349, train_loss = 0.9314444648698554, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 350, train_loss = 0.9308860885575996, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 351, train_loss = 0.9309648498892784, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 352, train_loss = 0.930268757045269, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 353, train_loss = 0.9305061722770915, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 354, train_loss = 0.9293451470657601, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 355, train_loss = 0.9290388077497482, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 356, train_loss = 0.9287250352426781, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 357, train_loss = 0.9282931461930275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 358, train_loss = 0.9278533930555568, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 359, train_loss = 0.9273504093289375, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 360, train_loss = 0.9275188359097228, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 361, train_loss = 0.9267341805025353, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 362, train_loss = 0.9263067642823444, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 363, train_loss = 0.9254071315153851, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 364, train_loss = 0.9254651553928852, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 365, train_loss = 0.9250158742070198, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 366, train_loss = 0.9245149902999401, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 367, train_loss = 0.9244890064001083, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 368, train_loss = 0.9238142470494495, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 369, train_loss = 0.923572089523077, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 370, train_loss = 0.9231994661167846, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 371, train_loss = 0.9224313795566559, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 372, train_loss = 0.9224844661875977, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 373, train_loss = 0.9222139852718101, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 374, train_loss = 0.9213624733165489, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 375, train_loss = 0.9212298492566333, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 376, train_loss = 0.9214312843978405, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 377, train_loss = 0.9210721316412673, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 378, train_loss = 0.9201892676428542, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 379, train_loss = 0.9197500521913753, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 380, train_loss = 0.9196113583966508, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 381, train_loss = 0.9198844668790116, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 382, train_loss = 0.9187804907560349, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 383, train_loss = 0.9183451893404708, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 384, train_loss = 0.9181151203811169, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 385, train_loss = 0.9178398288786411, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 386, train_loss = 0.9172271514908061, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 387, train_loss = 0.9171645926908241, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 388, train_loss = 0.9165944134219899, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 389, train_loss = 0.9166301799341454, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 390, train_loss = 0.916245773434639, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 391, train_loss = 0.9158791837617173, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 392, train_loss = 0.9148892909288406, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 393, train_loss = 0.9146884903311729, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 394, train_loss = 0.9148670149370446, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 395, train_loss = 0.9150680142120109, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 396, train_loss = 0.9143200901671662, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 397, train_loss = 0.9138010106980801, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 398, train_loss = 0.9132480720654712, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 399, train_loss = 0.9132857037111535, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 400, train_loss = 0.9128550427631126, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 401, train_loss = 0.912019028015493, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 402, train_loss = 0.9127147967592464, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 403, train_loss = 0.9119265638291836, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 404, train_loss = 0.9109770655632019, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 405, train_loss = 0.9113261600359692, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 406, train_loss = 0.9110368850306259, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 407, train_loss = 0.9104114112778916, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 408, train_loss = 0.9101971723139286, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 409, train_loss = 0.9108262447043671, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 410, train_loss = 0.9094510910435929, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 411, train_loss = 0.9095438992007985, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 412, train_loss = 0.908734763659595, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 413, train_loss = 0.9085760551170097, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 414, train_loss = 0.9088356854990707, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 415, train_loss = 0.9089736975729465, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 416, train_loss = 0.9072928825989948, train_acc = 0.9980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 417, train_loss = 0.9079168774187565, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 418, train_loss = 0.9077586320563569, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 419, train_loss = 0.9069168008863926, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 420, train_loss = 0.9065841026604176, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 421, train_loss = 0.9063801181837334, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 422, train_loss = 0.906102366745472, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 423, train_loss = 0.9059252912775264, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 424, train_loss = 0.905358225107193, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 425, train_loss = 0.9055692665278912, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 426, train_loss = 0.9053037278354168, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 427, train_loss = 0.9056099479421391, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 428, train_loss = 0.9044371967538609, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 429, train_loss = 0.9044334205464111, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 430, train_loss = 0.9040623853579746, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 431, train_loss = 0.9036808721721172, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 432, train_loss = 0.9028208206073032, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 433, train_loss = 0.9035868085920811, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 434, train_loss = 0.9032104536890984, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 435, train_loss = 0.9027506200000062, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 436, train_loss = 0.9021314022465958, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 437, train_loss = 0.9022364864722476, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 438, train_loss = 0.9018994594589458, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 439, train_loss = 0.9011191998943104, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 440, train_loss = 0.9016731120646, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 441, train_loss = 0.9008531905710697, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 442, train_loss = 0.9009428819044842, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 443, train_loss = 0.9002348370850086, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 444, train_loss = 0.9006726654843078, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 445, train_loss = 0.9000871280804859, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 446, train_loss = 0.9003301039338112, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 447, train_loss = 0.8989707777873264, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 448, train_loss = 0.8993865263983025, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 449, train_loss = 0.9000575517638936, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 450, train_loss = 0.8993130040689721, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 451, train_loss = 0.8987893449739204, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 452, train_loss = 0.8984247619882808, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 453, train_loss = 0.8973787277936935, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 454, train_loss = 0.8985466510057449, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 455, train_loss = 0.8974047762676491, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 456, train_loss = 0.8970712174996152, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 457, train_loss = 0.8972219824790955, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 458, train_loss = 0.8965679556131363, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 459, train_loss = 0.8973061715587392, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 460, train_loss = 0.8964140539392247, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 461, train_loss = 0.8956051530913101, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 462, train_loss = 0.8960796867831959, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 463, train_loss = 0.895821171499847, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 464, train_loss = 0.8963963985443115, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 465, train_loss = 0.8949802629649639, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 466, train_loss = 0.895603130258678, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 467, train_loss = 0.8946956979707466, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 468, train_loss = 0.8944925082250847, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 469, train_loss = 0.8940342565401806, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 470, train_loss = 0.8956088088452816, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 471, train_loss = 0.8942534737288952, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 472, train_loss = 0.8934434813781991, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 473, train_loss = 0.8947971723973751, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 474, train_loss = 0.8931783636435284, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 475, train_loss = 0.8921422250568867, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 476, train_loss = 0.8947032441719784, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 477, train_loss = 0.8925789756103768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 478, train_loss = 0.8918536342680454, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 479, train_loss = 0.8920344921425567, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 480, train_loss = 0.8924008682370186, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 481, train_loss = 0.8923651066943421, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 482, train_loss = 0.8915427513420582, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 483, train_loss = 0.8902396808043704, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 484, train_loss = 0.8944770234302268, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 485, train_loss = 0.8915420820339932, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 486, train_loss = 0.8910517171025276, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 487, train_loss = 0.8907139388247742, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 488, train_loss = 0.8899364123717532, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 489, train_loss = 0.8919338869527564, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 490, train_loss = 0.8897562647835002, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 491, train_loss = 0.889296155422926, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 492, train_loss = 0.8899814238175168, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 493, train_loss = 0.888864162065147, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 494, train_loss = 0.8906995902434574, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 495, train_loss = 0.8888480017558322, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 496, train_loss = 0.888744996242167, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 497, train_loss = 0.8884826190769672, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 498, train_loss = 0.8870398042126908, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 499, train_loss = 0.8910412428303971, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████                                      | 15/30 [2:23:37<2:33:04, 612.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "16th- epoch: 0, train_loss = 368.1844882071018, train_acc = 0.7908709827666511\n",
      "test Acc 0.8738361266294227:\n",
      "16th- epoch: 1, train_loss = 85.36075408756733, train_acc = 0.9245458779692595\n",
      "test Acc 0.8943202979515829:\n",
      "16th- epoch: 2, train_loss = 53.91246785223484, train_acc = 0.9452724732184443\n",
      "test Acc 0.9292364990689013:\n",
      "16th- epoch: 3, train_loss = 37.36412639403716, train_acc = 0.9574988355845365\n",
      "test Acc 0.9385474860335196:\n",
      "16th- epoch: 4, train_loss = 27.57476266962476, train_acc = 0.963903120633442\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 5, train_loss = 21.23786960914731, train_acc = 0.9710060549604099\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 6, train_loss = 16.749711964279413, train_acc = 0.9744993013507219\n",
      "test Acc 0.9473929236499069:\n",
      "16th- epoch: 7, train_loss = 13.42998729518149, train_acc = 0.9784583139264089\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 8, train_loss = 11.08923160401173, train_acc = 0.9814857941313461\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 9, train_loss = 9.326670352369547, train_acc = 0.9828830926874709\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 10, train_loss = 7.970718688098714, train_acc = 0.9856776897997206\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 11, train_loss = 6.879575767787173, train_acc = 0.9869585468095017\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 12, train_loss = 6.005622347118333, train_acc = 0.9882394038192828\n",
      "test Acc 0.9529795158286778:\n",
      "16th- epoch: 13, train_loss = 5.284143518656492, train_acc = 0.9895202608290639\n",
      "test Acc 0.9543761638733705:\n",
      "16th- epoch: 14, train_loss = 4.708071229280904, train_acc = 0.9906846762925011\n",
      "test Acc 0.9557728119180633:\n",
      "16th- epoch: 15, train_loss = 4.2229803539812565, train_acc = 0.9917326502095948\n",
      "test Acc 0.9567039106145251:\n",
      "16th- epoch: 16, train_loss = 3.8288430359680206, train_acc = 0.9924312994876572\n",
      "test Acc 0.957635009310987:\n",
      "16th- epoch: 17, train_loss = 3.502514616935514, train_acc = 0.9931299487657196\n",
      "test Acc 0.957169459962756:\n",
      "16th- epoch: 18, train_loss = 3.2368523267796263, train_acc = 0.9935957149510946\n",
      "test Acc 0.957169459962756:\n",
      "16th- epoch: 19, train_loss = 3.022266987711191, train_acc = 0.9937121564974383\n",
      "test Acc 0.9581005586592178:\n",
      "16th- epoch: 20, train_loss = 2.836466538370587, train_acc = 0.9947601304145319\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 21, train_loss = 2.6853144777705893, train_acc = 0.9951094550535631\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 22, train_loss = 2.5676197285065427, train_acc = 0.9952258965999069\n",
      "test Acc 0.9594972067039106:\n",
      "16th- epoch: 23, train_loss = 2.4528162827482447, train_acc = 0.995575221238938\n",
      "test Acc 0.9594972067039106:\n",
      "16th- epoch: 24, train_loss = 2.358121879398823, train_acc = 0.9954587796925943\n",
      "test Acc 0.9594972067039106:\n",
      "16th- epoch: 25, train_loss = 2.278095348388888, train_acc = 0.995575221238938\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 26, train_loss = 2.206031526089646, train_acc = 0.995575221238938\n",
      "test Acc 0.9594972067039106:\n",
      "16th- epoch: 27, train_loss = 2.1428880505263805, train_acc = 0.9958081043316255\n",
      "test Acc 0.9594972067039106:\n",
      "16th- epoch: 28, train_loss = 2.078859381377697, train_acc = 0.996040987424313\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 29, train_loss = 2.030587360262871, train_acc = 0.9958081043316255\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 30, train_loss = 1.9807948222151026, train_acc = 0.9958081043316255\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 31, train_loss = 1.9368342322995886, train_acc = 0.996040987424313\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 32, train_loss = 1.8914864473044872, train_acc = 0.9961574289706567\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 33, train_loss = 1.8584398491075262, train_acc = 0.9961574289706567\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 34, train_loss = 1.8246203971793875, train_acc = 0.9961574289706567\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 35, train_loss = 1.7973494144389406, train_acc = 0.9962738705170004\n",
      "test Acc 0.9608938547486033:\n",
      "16th- epoch: 36, train_loss = 1.7695114873349667, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 37, train_loss = 1.7439525139634497, train_acc = 0.9962738705170004\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 38, train_loss = 1.723168219148647, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "16th- epoch: 39, train_loss = 1.6963730727438815, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 40, train_loss = 1.6739035211503506, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 41, train_loss = 1.6523588672280312, train_acc = 0.996506753609688\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 42, train_loss = 1.631226812780369, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 43, train_loss = 1.6136805688147433, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 44, train_loss = 1.601484550803434, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 45, train_loss = 1.5841708816587925, train_acc = 0.996506753609688\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 46, train_loss = 1.5714842726592906, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 47, train_loss = 1.557945600419771, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 48, train_loss = 1.5466322017018683, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 49, train_loss = 1.5342342903022654, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 50, train_loss = 1.523995976895094, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 51, train_loss = 1.5121306354703847, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 52, train_loss = 1.5028703635034617, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 53, train_loss = 1.4900120869278908, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 54, train_loss = 1.4838918236491736, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 55, train_loss = 1.4740641613898333, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 56, train_loss = 1.4656499177217484, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 57, train_loss = 1.455616306513548, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 58, train_loss = 1.4458252067270223, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 59, train_loss = 1.4400394981203135, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 60, train_loss = 1.4330738981661852, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 61, train_loss = 1.4243688099086285, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 62, train_loss = 1.4183207427558955, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 63, train_loss = 1.4093201445939485, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 64, train_loss = 1.398065478861099, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 65, train_loss = 1.3969311515393201, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 66, train_loss = 1.3890528492629528, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 67, train_loss = 1.3809294650855009, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 68, train_loss = 1.3775356635451317, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 69, train_loss = 1.3712578142731218, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 70, train_loss = 1.3652355472295312, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 71, train_loss = 1.3558017077593831, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 72, train_loss = 1.3537497855722904, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 73, train_loss = 1.3480139163584681, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 74, train_loss = 1.3409076742827892, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 75, train_loss = 1.3343513384461403, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 76, train_loss = 1.3292400687932968, train_acc = 0.9970889613414066\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 77, train_loss = 1.3246976335794898, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 78, train_loss = 1.3189194475562545, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 79, train_loss = 1.312236726284027, train_acc = 0.9970889613414066\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 80, train_loss = 1.3116637443454238, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 81, train_loss = 1.3028094694018364, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 82, train_loss = 1.2986011393368244, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 83, train_loss = 1.2940561026334763, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 84, train_loss = 1.2894081945269136, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 85, train_loss = 1.2829130043537589, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 86, train_loss = 1.2800034185202094, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 87, train_loss = 1.273209220424178, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 88, train_loss = 1.2703267907054396, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 89, train_loss = 1.2673138392419787, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 90, train_loss = 1.2624658606946468, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 91, train_loss = 1.2586731649935246, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 92, train_loss = 1.255395578846219, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 93, train_loss = 1.250474204614875, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 94, train_loss = 1.247128666684148, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 95, train_loss = 1.241741869598627, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 96, train_loss = 1.237172012522933, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 97, train_loss = 1.2342630997300148, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 98, train_loss = 1.228809787586215, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 99, train_loss = 1.2284393993468257, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 100, train_loss = 1.2229232527315617, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 101, train_loss = 1.2192697413265705, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 102, train_loss = 1.2141097212879686, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 103, train_loss = 1.2125004989356967, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 104, train_loss = 1.2086272252054187, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 105, train_loss = 1.2047493966965703, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 106, train_loss = 1.1999446464105858, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 107, train_loss = 1.198089838027954, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 108, train_loss = 1.195312616728188, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 109, train_loss = 1.192367927484156, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 110, train_loss = 1.1887838219627156, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 111, train_loss = 1.1845977803095593, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 112, train_loss = 1.1819677452222095, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 113, train_loss = 1.177968225129007, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 114, train_loss = 1.173528354614973, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 115, train_loss = 1.1737146824598312, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 116, train_loss = 1.1684754552916274, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 117, train_loss = 1.167244644217135, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 118, train_loss = 1.1627878285944462, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 119, train_loss = 1.1589120750650181, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 120, train_loss = 1.1554060777052655, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 121, train_loss = 1.1542498419657932, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 122, train_loss = 1.1512070608659997, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 123, train_loss = 1.1451632107273326, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 124, train_loss = 1.145469361297728, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 125, train_loss = 1.1414345006123767, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 126, train_loss = 1.1390143372118473, train_acc = 0.9972054028877504\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 127, train_loss = 1.1339304260909557, train_acc = 0.9972054028877504\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 128, train_loss = 1.1352592085822835, train_acc = 0.9972054028877504\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 129, train_loss = 1.129982128739357, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 130, train_loss = 1.1290649250149727, train_acc = 0.9972054028877504\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 131, train_loss = 1.1263601444661617, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 132, train_loss = 1.120552026979567, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 133, train_loss = 1.1188858412206173, train_acc = 0.9972054028877504\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 134, train_loss = 1.1158854104578495, train_acc = 0.9972054028877504\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 135, train_loss = 1.1131080600098358, train_acc = 0.9972054028877504\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 136, train_loss = 1.1105383175090537, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 137, train_loss = 1.1068202555179596, train_acc = 0.9972054028877504\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 138, train_loss = 1.103687164686562, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 139, train_loss = 1.1017865563408122, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 140, train_loss = 1.0991967916488647, train_acc = 0.9972054028877504\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 141, train_loss = 1.0951690562069416, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 142, train_loss = 1.0936960689723492, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 143, train_loss = 1.091568659991026, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 144, train_loss = 1.0876352700070129, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 145, train_loss = 1.083297561854124, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 146, train_loss = 1.082810439169407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 147, train_loss = 1.0805936890319572, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 148, train_loss = 1.0778308870867477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 149, train_loss = 1.0738031628206954, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 150, train_loss = 1.070994916059135, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 151, train_loss = 1.071241058409214, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 152, train_loss = 1.0665473217741237, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 153, train_loss = 1.06541383638978, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 154, train_loss = 1.06402611235535, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 155, train_loss = 1.0613108364268555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 156, train_loss = 1.0601891155019985, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 157, train_loss = 1.0580727929846034, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 158, train_loss = 1.0539762613698258, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 159, train_loss = 1.053278274834156, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 160, train_loss = 1.0506527349352837, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 161, train_loss = 1.0482487926856265, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 162, train_loss = 1.0444638046101318, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 163, train_loss = 1.0422139577567577, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 164, train_loss = 1.0421498852447257, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 165, train_loss = 1.0413499064743519, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 166, train_loss = 1.037569539003016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 167, train_loss = 1.0362356938421726, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 168, train_loss = 1.030485977731587, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 169, train_loss = 1.0304459047838463, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 170, train_loss = 1.0270001006647362, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 171, train_loss = 1.028096493333578, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 172, train_loss = 1.0224237479269505, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 173, train_loss = 1.0253538427277817, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 174, train_loss = 1.0228334702551365, train_acc = 0.9973218444340941\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 175, train_loss = 1.0198291204869747, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 176, train_loss = 1.018535899616836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 177, train_loss = 1.0168603658676147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 178, train_loss = 1.0126341953873634, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 179, train_loss = 1.0124541781842709, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 180, train_loss = 1.0116039589047432, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 181, train_loss = 1.0089521979316487, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 182, train_loss = 1.0098814753218903, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 183, train_loss = 1.0083347881845839, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 184, train_loss = 1.0047475981227763, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 185, train_loss = 1.0017086478583224, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 186, train_loss = 1.0027600427456491, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 187, train_loss = 1.0021838719658263, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 188, train_loss = 0.9998397330455191, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 189, train_loss = 0.9969645962119102, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 190, train_loss = 0.9962740031369322, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 191, train_loss = 0.9955500736832619, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 192, train_loss = 0.9918023360260122, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 193, train_loss = 0.990555343527376, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 194, train_loss = 0.9915461912751198, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 195, train_loss = 0.9879557055719488, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 196, train_loss = 0.986099777121126, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 197, train_loss = 0.9843397984914191, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 198, train_loss = 0.9861872593573935, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 199, train_loss = 0.9836817495524883, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 200, train_loss = 0.9813197863586538, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 201, train_loss = 0.9799000546336174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 202, train_loss = 0.9791694283485413, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 203, train_loss = 0.9778423098214262, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 204, train_loss = 0.975774385035038, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 205, train_loss = 0.9755053694061644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 206, train_loss = 0.9746046389154799, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 207, train_loss = 0.972460129607498, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 208, train_loss = 0.9729665654413111, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 209, train_loss = 0.9704431369900703, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 210, train_loss = 0.9675219766795635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 211, train_loss = 0.9671159808822267, train_acc = 0.9974382859804378\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 212, train_loss = 0.9665384491272562, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 213, train_loss = 0.9670417668930895, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 214, train_loss = 0.96472728748995, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 215, train_loss = 0.961983768891514, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 216, train_loss = 0.9614573145918257, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 217, train_loss = 0.961804651964485, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 218, train_loss = 0.960468702018261, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 219, train_loss = 0.960877617199003, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 220, train_loss = 0.9581448671706312, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 221, train_loss = 0.9549889229238033, train_acc = 0.9974382859804378\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 222, train_loss = 0.956041173387348, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 223, train_loss = 0.9549959376454353, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 224, train_loss = 0.9557791526131041, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 225, train_loss = 0.954030209530174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 226, train_loss = 0.9513375821225054, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 227, train_loss = 0.9512119131795771, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 228, train_loss = 0.9503047044090636, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 229, train_loss = 0.9482749042399519, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 230, train_loss = 0.9483785554766655, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 231, train_loss = 0.948060600709141, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 232, train_loss = 0.9461783915758133, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 233, train_loss = 0.9452908212952025, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 234, train_loss = 0.9448643711693876, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 235, train_loss = 0.9436189122498035, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 236, train_loss = 0.9435873267539137, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 237, train_loss = 0.9447831610850699, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 238, train_loss = 0.9434002811722166, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 239, train_loss = 0.9389743767678738, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 240, train_loss = 0.9391350994519598, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 241, train_loss = 0.9403371959924698, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 242, train_loss = 0.9385069670788653, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 243, train_loss = 0.9379010001830466, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 244, train_loss = 0.9374776110053062, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 245, train_loss = 0.9355034455657005, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 246, train_loss = 0.935374220211088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 247, train_loss = 0.9339830987155437, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 248, train_loss = 0.9351190080233209, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 249, train_loss = 0.9350077410526865, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 250, train_loss = 0.933047832299053, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 251, train_loss = 0.9332868568599224, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 252, train_loss = 0.9301279224455357, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 253, train_loss = 0.9299259347208135, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 254, train_loss = 0.9299989007413387, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 255, train_loss = 0.9307744142897718, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 256, train_loss = 0.9292146960906393, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 257, train_loss = 0.9270516497381323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 258, train_loss = 0.9276041649281979, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 259, train_loss = 0.926413739722193, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 260, train_loss = 0.9258393521122343, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 261, train_loss = 0.9270655686668761, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 262, train_loss = 0.9247747051231272, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 263, train_loss = 0.9236703266687982, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 264, train_loss = 0.9242705777287483, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 265, train_loss = 0.9236153922975063, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 266, train_loss = 0.9215108354874246, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 267, train_loss = 0.9233829726763361, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 268, train_loss = 0.9207961857318878, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 269, train_loss = 0.9205624486021406, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 270, train_loss = 0.9192402139306068, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 271, train_loss = 0.9193634440489404, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 272, train_loss = 0.9170683274678595, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 273, train_loss = 0.9164792113006115, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 274, train_loss = 0.9176727719604969, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 275, train_loss = 0.9176910445094109, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 276, train_loss = 0.9170878206678026, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 277, train_loss = 0.9163808388002508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 278, train_loss = 0.9153358402363665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 279, train_loss = 0.9144313956312544, train_acc = 0.9975547275267815\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 280, train_loss = 0.9152274218686216, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 281, train_loss = 0.9120995538942225, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 282, train_loss = 0.9137701354920864, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 283, train_loss = 0.9128769983835809, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 284, train_loss = 0.9122927424796217, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 285, train_loss = 0.9114737982563383, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 286, train_loss = 0.9118482582271099, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 287, train_loss = 0.9101248110346205, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 288, train_loss = 0.9101548319049471, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 289, train_loss = 0.909164426226198, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 290, train_loss = 0.9096880331635475, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 291, train_loss = 0.9078403289131529, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 292, train_loss = 0.9085319687910669, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 293, train_loss = 0.9070236732550256, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 294, train_loss = 0.9078484140336514, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 295, train_loss = 0.9065918649248488, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 296, train_loss = 0.9061252810060978, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 297, train_loss = 0.9045052876062982, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 298, train_loss = 0.9052617897577875, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 299, train_loss = 0.905494038015604, train_acc = 0.9975547275267815\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 300, train_loss = 0.9034266906492121, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 301, train_loss = 0.9043037953488238, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 302, train_loss = 0.904247644048155, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 303, train_loss = 0.9026924123354547, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 304, train_loss = 0.9018971050791151, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 305, train_loss = 0.9027786652259238, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 306, train_loss = 0.9029525232799642, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 307, train_loss = 0.9017318226397038, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 308, train_loss = 0.9006720706820488, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 309, train_loss = 0.9009934812784195, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 310, train_loss = 0.8992549677677744, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 311, train_loss = 0.8999406720213301, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 312, train_loss = 0.8994665083773725, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 313, train_loss = 0.8991192082576163, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 314, train_loss = 0.8978993892669678, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 315, train_loss = 0.8979240742810362, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 316, train_loss = 0.8981808808930509, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 317, train_loss = 0.8980883161239035, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 318, train_loss = 0.8975102429576509, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 319, train_loss = 0.8951586037874222, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 320, train_loss = 0.8957720783837431, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 321, train_loss = 0.8956490146629221, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 322, train_loss = 0.8964173334352381, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 323, train_loss = 0.8946993028112047, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 324, train_loss = 0.8939827966187295, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 325, train_loss = 0.8938989266753197, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 326, train_loss = 0.895287849009037, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 327, train_loss = 0.8927536259107001, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 328, train_loss = 0.8928324530515965, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 329, train_loss = 0.8933245403077308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 330, train_loss = 0.8925727494060993, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 331, train_loss = 0.89169792085886, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 332, train_loss = 0.8924329007659253, train_acc = 0.9976711690731253\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 333, train_loss = 0.8899600344393548, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 334, train_loss = 0.8903739725556079, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 335, train_loss = 0.8898688343670074, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 336, train_loss = 0.8908857901897136, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 337, train_loss = 0.8906402972843352, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 338, train_loss = 0.8903450841698941, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 339, train_loss = 0.8889458477497101, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 340, train_loss = 0.88921844089964, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 341, train_loss = 0.8890794105827808, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 342, train_loss = 0.8881663071606454, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 343, train_loss = 0.8863791041076183, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 344, train_loss = 0.8872147810961906, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 345, train_loss = 0.8875863042976562, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 346, train_loss = 0.8882861770689487, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 347, train_loss = 0.8866728519406024, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 348, train_loss = 0.885847015926629, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 349, train_loss = 0.8857237473130226, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 350, train_loss = 0.8854591275248822, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 351, train_loss = 0.8848307989537716, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 352, train_loss = 0.8851941699776944, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 353, train_loss = 0.8857039548456669, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 354, train_loss = 0.8856450455878075, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 355, train_loss = 0.8843494256343547, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 356, train_loss = 0.883929500976592, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 357, train_loss = 0.8824445667360123, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 358, train_loss = 0.8827779851853848, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 359, train_loss = 0.8837049081921577, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 360, train_loss = 0.883442971855402, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 361, train_loss = 0.8820457334313687, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 362, train_loss = 0.8814988459143933, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 363, train_loss = 0.8807545552645024, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 364, train_loss = 0.8813269808888435, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 365, train_loss = 0.881868127733469, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 366, train_loss = 0.8812921891603764, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 367, train_loss = 0.8806231543421745, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 368, train_loss = 0.8798003047704697, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 369, train_loss = 0.880407335856944, train_acc = 0.9979040521658128\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 370, train_loss = 0.8799275681376457, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 371, train_loss = 0.8815672869477567, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 372, train_loss = 0.8803252664711181, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 373, train_loss = 0.8791032495591935, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 374, train_loss = 0.8781221571061906, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 375, train_loss = 0.8795701128747169, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 376, train_loss = 0.8791408340130147, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 377, train_loss = 0.8778597824275494, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 378, train_loss = 0.8772749366853532, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 379, train_loss = 0.8774634140227136, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 380, train_loss = 0.8791561437155906, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 381, train_loss = 0.8777638835217658, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 382, train_loss = 0.8760477999840077, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 383, train_loss = 0.8766270540654659, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 384, train_loss = 0.8764708998296555, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 385, train_loss = 0.8771049703154858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 386, train_loss = 0.8754621421303455, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 387, train_loss = 0.8743416133020219, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 388, train_loss = 0.8759263741467294, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 389, train_loss = 0.8771240239348117, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 390, train_loss = 0.8744413492586318, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 391, train_loss = 0.8733283976707753, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 392, train_loss = 0.8747523116562661, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 393, train_loss = 0.8753532196078595, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 394, train_loss = 0.8744245171546936, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 395, train_loss = 0.8717345943059627, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 396, train_loss = 0.8729753270745277, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 397, train_loss = 0.8740391246974468, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 398, train_loss = 0.8745682736243907, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 399, train_loss = 0.8717801036927995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 400, train_loss = 0.8716362230479717, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 401, train_loss = 0.8739182353019714, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 402, train_loss = 0.8726110036168393, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 403, train_loss = 0.8717179968953133, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 404, train_loss = 0.8711936175823212, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 405, train_loss = 0.8729375377297401, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 406, train_loss = 0.8708956303689774, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 407, train_loss = 0.8710406447444257, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 408, train_loss = 0.8706416711211205, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 409, train_loss = 0.8711920529603958, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 410, train_loss = 0.8708532303571701, train_acc = 0.9979040521658128\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 411, train_loss = 0.8699439118299779, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 412, train_loss = 0.8691948552932445, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 413, train_loss = 0.8716554045677185, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 414, train_loss = 0.8702486542370025, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 415, train_loss = 0.8699179502818879, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 416, train_loss = 0.8690980101619061, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 417, train_loss = 0.8699774953220185, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 418, train_loss = 0.8700399622321129, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 419, train_loss = 0.8680672720074654, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 420, train_loss = 0.869044962028056, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 421, train_loss = 0.8696817718446255, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 422, train_loss = 0.8697162667904195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 423, train_loss = 0.8672302899267379, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 424, train_loss = 0.8683121018111706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 425, train_loss = 0.8703200990948972, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 426, train_loss = 0.8685050383210182, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 427, train_loss = 0.8668747544288635, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 428, train_loss = 0.8679042855892476, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 429, train_loss = 0.8685755779351894, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 430, train_loss = 0.867571542659789, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 431, train_loss = 0.8669794412944611, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 432, train_loss = 0.866900256523877, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 433, train_loss = 0.8681565336883068, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 434, train_loss = 0.8670519453789893, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 435, train_loss = 0.8661658577620983, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 436, train_loss = 0.8661041781306267, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 437, train_loss = 0.8671872106697265, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 438, train_loss = 0.865328922867775, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 439, train_loss = 0.86574287215808, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 440, train_loss = 0.86354410896638, train_acc = 0.9979040521658128\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 441, train_loss = 0.8664407307896909, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 442, train_loss = 0.8658446595072746, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 443, train_loss = 0.8653113444652263, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 444, train_loss = 0.8645159254465398, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 445, train_loss = 0.8654477124418918, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 446, train_loss = 0.8630024219546613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 447, train_loss = 0.8634194955229759, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 448, train_loss = 0.863380045941085, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 449, train_loss = 0.8635024627055827, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 450, train_loss = 0.8624465999509994, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 451, train_loss = 0.8620637369658652, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 452, train_loss = 0.8652527555823326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 453, train_loss = 0.8620937267933186, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 454, train_loss = 0.8623780508842174, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 455, train_loss = 0.8625944393370446, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 456, train_loss = 0.8636879461500939, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 457, train_loss = 0.8612095341086388, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 458, train_loss = 0.8617308971788589, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 459, train_loss = 0.8610617009308044, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 460, train_loss = 0.8622458862755593, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 461, train_loss = 0.8624404904749099, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 462, train_loss = 0.8596168073509034, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 463, train_loss = 0.8600944640729722, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 464, train_loss = 0.8625572385881242, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 465, train_loss = 0.8603346658255759, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 466, train_loss = 0.8601758504901227, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 467, train_loss = 0.8598840211834613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 468, train_loss = 0.8612597038354579, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 469, train_loss = 0.8582972312960919, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 470, train_loss = 0.8594079613685608, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 471, train_loss = 0.8598294643070403, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 472, train_loss = 0.8595883324742317, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 473, train_loss = 0.858551540723056, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 474, train_loss = 0.858802350858241, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 475, train_loss = 0.8592171035706997, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 476, train_loss = 0.8598085443172749, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 477, train_loss = 0.858933570483714, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 478, train_loss = 0.8589177901540097, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 479, train_loss = 0.8580821144078072, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 480, train_loss = 0.8570459100101289, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 481, train_loss = 0.8574072358514968, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 482, train_loss = 0.8594700358808041, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 483, train_loss = 0.8576914692912396, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 484, train_loss = 0.8578521944582462, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 485, train_loss = 0.858725639680415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 486, train_loss = 0.8569284453988075, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 487, train_loss = 0.8560697386656102, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 488, train_loss = 0.8590758691225346, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 489, train_loss = 0.8579324161019031, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 490, train_loss = 0.8562879549954232, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 491, train_loss = 0.856716051697731, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 492, train_loss = 0.8592407467458543, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 493, train_loss = 0.8572619979586307, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 494, train_loss = 0.8557437931503955, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 495, train_loss = 0.8558854535222054, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 496, train_loss = 0.8586962074041367, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 497, train_loss = 0.8570428440962132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 498, train_loss = 0.8554045992586907, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 499, train_loss = 0.8552225716412067, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|████████████████████████████████████████▌                                   | 16/30 [2:34:06<2:24:02, 617.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "17th- epoch: 0, train_loss = 353.12507288903, train_acc = 0.8143921751280857\n",
      "test Acc 0.9082867783985102:\n",
      "17th- epoch: 1, train_loss = 73.63246032595634, train_acc = 0.926525384257103\n",
      "test Acc 0.930633147113594:\n",
      "17th- epoch: 2, train_loss = 44.769031601026654, train_acc = 0.94981369352585\n",
      "test Acc 0.9413407821229051:\n",
      "17th- epoch: 3, train_loss = 31.49257619958371, train_acc = 0.9611085235211924\n",
      "test Acc 0.9427374301675978:\n",
      "17th- epoch: 4, train_loss = 23.81458329129964, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 5, train_loss = 18.857039969414473, train_acc = 0.975314392175128\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 6, train_loss = 15.483075147029012, train_acc = 0.9788076385654402\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 7, train_loss = 13.013964908197522, train_acc = 0.9816022356776898\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 8, train_loss = 11.17279367800802, train_acc = 0.9832324173265021\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 9, train_loss = 9.692743355408311, train_acc = 0.9846297158826269\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 10, train_loss = 8.414653852116317, train_acc = 0.985910572892408\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 11, train_loss = 7.349818960996345, train_acc = 0.9871914299021891\n",
      "test Acc 0.9501862197392924:\n",
      "17th- epoch: 12, train_loss = 6.433085563359782, train_acc = 0.9890544946436889\n",
      "test Acc 0.952513966480447:\n",
      "17th- epoch: 13, train_loss = 5.701262570917606, train_acc = 0.99033535165347\n",
      "test Acc 0.9548417132216015:\n",
      "17th- epoch: 14, train_loss = 5.086137909442186, train_acc = 0.9910340009315324\n",
      "test Acc 0.9562383612662942:\n",
      "17th- epoch: 15, train_loss = 4.559983289567754, train_acc = 0.9921984163949698\n",
      "test Acc 0.957169459962756:\n",
      "17th- epoch: 16, train_loss = 4.1369999933522195, train_acc = 0.9927806241266884\n",
      "test Acc 0.957169459962756:\n",
      "17th- epoch: 17, train_loss = 3.796272360952571, train_acc = 0.9935957149510946\n",
      "test Acc 0.957635009310987:\n",
      "17th- epoch: 18, train_loss = 3.52340051275678, train_acc = 0.994294364229157\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 19, train_loss = 3.283501538215205, train_acc = 0.9945272473218444\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 20, train_loss = 3.0668866385240108, train_acc = 0.9945272473218444\n",
      "test Acc 0.957635009310987:\n",
      "17th- epoch: 21, train_loss = 2.881752899615094, train_acc = 0.9945272473218444\n",
      "test Acc 0.957169459962756:\n",
      "17th- epoch: 22, train_loss = 2.695011065574363, train_acc = 0.9946436888681882\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 23, train_loss = 2.548316042870283, train_acc = 0.9948765719608756\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 24, train_loss = 2.4163450822234154, train_acc = 0.9951094550535631\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 25, train_loss = 2.302570055006072, train_acc = 0.9952258965999069\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 26, train_loss = 2.196737719234079, train_acc = 0.995575221238938\n",
      "test Acc 0.9590316573556797:\n",
      "17th- epoch: 27, train_loss = 2.0969303369056433, train_acc = 0.9956916627852818\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 28, train_loss = 2.0166023045312613, train_acc = 0.9958081043316255\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 29, train_loss = 1.9345579470973462, train_acc = 0.9958081043316255\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 30, train_loss = 1.8673658557236195, train_acc = 0.996040987424313\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 31, train_loss = 1.8129294093232602, train_acc = 0.996040987424313\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 32, train_loss = 1.7611308961641043, train_acc = 0.9963903120633442\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 33, train_loss = 1.7156387716531754, train_acc = 0.9966231951560317\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 34, train_loss = 1.6845419581513852, train_acc = 0.9966231951560317\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 35, train_loss = 1.6482413744088262, train_acc = 0.9966231951560317\n",
      "test Acc 0.9594972067039106:\n",
      "17th- epoch: 36, train_loss = 1.6157828122377396, train_acc = 0.9968560782487191\n",
      "test Acc 0.9590316573556797:\n",
      "17th- epoch: 37, train_loss = 1.5912189790979028, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 38, train_loss = 1.5652424090076238, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 39, train_loss = 1.5420107969548553, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 40, train_loss = 1.5213721810141578, train_acc = 0.9969725197950629\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 41, train_loss = 1.5009212034055963, train_acc = 0.9969725197950629\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 42, train_loss = 1.4810220807557926, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 43, train_loss = 1.4574692798778415, train_acc = 0.9970889613414066\n",
      "test Acc 0.9604283054003724:\n",
      "17th- epoch: 44, train_loss = 1.4371202712645754, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 45, train_loss = 1.4228689139708877, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 46, train_loss = 1.4089016324141994, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 47, train_loss = 1.395297523937188, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 48, train_loss = 1.3818681603297591, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 49, train_loss = 1.367590461857617, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 50, train_loss = 1.3540280513698235, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 51, train_loss = 1.3410974502330646, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 52, train_loss = 1.3232424911111593, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 53, train_loss = 1.3114129438763484, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 54, train_loss = 1.3007901225355454, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 55, train_loss = 1.2934321276843548, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 56, train_loss = 1.2816501666675322, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 57, train_loss = 1.2780225272290409, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 58, train_loss = 1.2701942531275563, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 59, train_loss = 1.263119618583005, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 60, train_loss = 1.2563855220214464, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 61, train_loss = 1.2464607674628496, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 62, train_loss = 1.2398762202938087, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 63, train_loss = 1.2345666364417411, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 64, train_loss = 1.2280033722054213, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 65, train_loss = 1.220690063200891, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 66, train_loss = 1.2189161349087954, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 67, train_loss = 1.2125070847687311, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 68, train_loss = 1.210022958519403, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 69, train_loss = 1.201312636199873, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 70, train_loss = 1.1992882463964634, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 71, train_loss = 1.1924101898330264, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 72, train_loss = 1.1877017722581513, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 73, train_loss = 1.1831539256963879, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 74, train_loss = 1.1776019934914075, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 75, train_loss = 1.1723630741180386, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 76, train_loss = 1.1696175474207848, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 77, train_loss = 1.1666384072450455, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 78, train_loss = 1.1622649267374072, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 79, train_loss = 1.1602271530719008, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 80, train_loss = 1.1487843093054835, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 81, train_loss = 1.1464903446321841, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 82, train_loss = 1.1451857427600771, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 83, train_loss = 1.1392652632202953, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 84, train_loss = 1.1351622778456658, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 85, train_loss = 1.1335217045561876, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 86, train_loss = 1.1283297458139714, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 87, train_loss = 1.1255726552044507, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 88, train_loss = 1.124789517809404, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 89, train_loss = 1.120316712796921, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 90, train_loss = 1.1160886633733753, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 91, train_loss = 1.1122901861963328, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 92, train_loss = 1.1102613997645676, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 93, train_loss = 1.1088121795037296, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 94, train_loss = 1.1066482542955782, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 95, train_loss = 1.102175258944044, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 96, train_loss = 1.1003140959364828, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 97, train_loss = 1.0968274163024034, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 98, train_loss = 1.0964583581371699, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 99, train_loss = 1.0909138395509217, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 100, train_loss = 1.0890096945222467, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 101, train_loss = 1.0868261221330613, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 102, train_loss = 1.084375584643567, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 103, train_loss = 1.0836506214400288, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 104, train_loss = 1.0812234398035798, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 105, train_loss = 1.0805011332558934, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 106, train_loss = 1.0754951010458171, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 107, train_loss = 1.0735625927336514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 108, train_loss = 1.070286637172103, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 109, train_loss = 1.070748287398601, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 110, train_loss = 1.067338874883717, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 111, train_loss = 1.0646048669295851, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 112, train_loss = 1.066047771833837, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 113, train_loss = 1.062168536707759, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 114, train_loss = 1.0596815748140216, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 115, train_loss = 1.0575369969010353, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 116, train_loss = 1.0559923740511294, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 117, train_loss = 1.0528012313880026, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 118, train_loss = 1.0515560051426291, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 119, train_loss = 1.0506422227772418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 120, train_loss = 1.0490300076489802, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 121, train_loss = 1.0451190881431103, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 122, train_loss = 1.046874763298547, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 123, train_loss = 1.0426272099430207, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 124, train_loss = 1.0437725308875088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 125, train_loss = 1.0403074878267944, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 126, train_loss = 1.0380465192720294, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 127, train_loss = 1.0365048966777977, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 128, train_loss = 1.0366598543187138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 129, train_loss = 1.0348944830184337, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 130, train_loss = 1.032099086936796, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 131, train_loss = 1.0320326428336557, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 132, train_loss = 1.0292287942429539, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 133, train_loss = 1.0275033096258994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 134, train_loss = 1.0275820257666055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 135, train_loss = 1.0254754973575473, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 136, train_loss = 1.0242415725660976, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 137, train_loss = 1.0221503187494818, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 138, train_loss = 1.021779054615763, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 139, train_loss = 1.020765289053088, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 140, train_loss = 1.017247021824005, train_acc = 0.9975547275267815\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 141, train_loss = 1.017014007709804, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 142, train_loss = 1.015033410556498, train_acc = 0.9975547275267815\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 143, train_loss = 1.0143300807103515, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 144, train_loss = 1.011800502121332, train_acc = 0.9975547275267815\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 145, train_loss = 1.0119871832430363, train_acc = 0.9975547275267815\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 146, train_loss = 1.0104116437287303, train_acc = 0.9975547275267815\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 147, train_loss = 1.0091778769419761, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 148, train_loss = 1.0081787363887997, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 149, train_loss = 1.006724175371346, train_acc = 0.9975547275267815\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 150, train_loss = 1.0066905145795317, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 151, train_loss = 1.0046187285333872, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 152, train_loss = 1.0037961838097544, train_acc = 0.9975547275267815\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 153, train_loss = 1.0026945273129968, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 154, train_loss = 1.0024711930454941, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 155, train_loss = 0.9996198589651613, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 156, train_loss = 0.9995056204497814, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 157, train_loss = 0.9982243459671736, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 158, train_loss = 0.9972392519266577, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 159, train_loss = 0.9956870910973521, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 160, train_loss = 0.995290135659161, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 161, train_loss = 0.9926574298442574, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 162, train_loss = 0.9922357111499878, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 163, train_loss = 0.9916935339570045, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 164, train_loss = 0.9899846073240042, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 165, train_loss = 0.9904685343353776, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 166, train_loss = 0.9881578025670024, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 167, train_loss = 0.9870585377066163, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 168, train_loss = 0.9880861692799954, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 169, train_loss = 0.9856638374476461, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 170, train_loss = 0.9843361337407259, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 171, train_loss = 0.9845300366432639, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 172, train_loss = 0.9829205060377717, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 173, train_loss = 0.9808972999453545, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 174, train_loss = 0.9804938562883763, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 175, train_loss = 0.979085009850678, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 176, train_loss = 0.9785718709899811, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 177, train_loss = 0.9778569958434673, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 178, train_loss = 0.9791455240920186, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 179, train_loss = 0.9748490278871031, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 180, train_loss = 0.9771622304542689, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 181, train_loss = 0.9744500986562343, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 182, train_loss = 0.9728546049445868, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 183, train_loss = 0.9731853290722938, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 184, train_loss = 0.9721196961327223, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 185, train_loss = 0.9714219328016043, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 186, train_loss = 0.9722810278908582, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 187, train_loss = 0.9714418466464849, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 188, train_loss = 0.9690980445593596, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 189, train_loss = 0.9676135076879291, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 190, train_loss = 0.9683546066953568, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 191, train_loss = 0.9675621424539713, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 192, train_loss = 0.9666787404567003, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 193, train_loss = 0.9670221842825413, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 194, train_loss = 0.9636749693454476, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 195, train_loss = 0.9645424329937669, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 196, train_loss = 0.9642455664725276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 197, train_loss = 0.9615597886295291, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 198, train_loss = 0.9619076612143544, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 199, train_loss = 0.9605714303179411, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 200, train_loss = 0.9593440927565098, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 201, train_loss = 0.9604915110394359, train_acc = 0.9976711690731253\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 202, train_loss = 0.9590646444557933, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 203, train_loss = 0.9592990909441141, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 204, train_loss = 0.9578336306585697, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 205, train_loss = 0.9578175985516282, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 206, train_loss = 0.95450403013092, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 207, train_loss = 0.9562626627011923, train_acc = 0.9975547275267815\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 208, train_loss = 0.9554948642180534, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 209, train_loss = 0.9536394573078724, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 210, train_loss = 0.9528278590441914, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 211, train_loss = 0.9512492381036282, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 212, train_loss = 0.9525968944653869, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 213, train_loss = 0.9511411683633924, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 214, train_loss = 0.9490621332079172, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 215, train_loss = 0.950091730497661, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 216, train_loss = 0.9507012556568952, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 217, train_loss = 0.9492092337459326, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 218, train_loss = 0.9480217692180304, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 219, train_loss = 0.9481340199708939, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 220, train_loss = 0.9463083446025848, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 221, train_loss = 0.9468301686720224, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 222, train_loss = 0.9455472404806642, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 223, train_loss = 0.9444365470408229, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 224, train_loss = 0.9444703593180748, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 225, train_loss = 0.9426308677793713, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 226, train_loss = 0.9417411793692736, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 227, train_loss = 0.9436767883598804, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 228, train_loss = 0.9426515605300665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 229, train_loss = 0.940609570898232, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 230, train_loss = 0.9417418620287208, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 231, train_loss = 0.938784503377974, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 232, train_loss = 0.9373668314219685, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 233, train_loss = 0.9403550727292895, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 234, train_loss = 0.9372666515409946, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 235, train_loss = 0.9360244780109497, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 236, train_loss = 0.939614150673151, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 237, train_loss = 0.9367985380813479, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 238, train_loss = 0.9355230489745736, train_acc = 0.9977876106194691\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 239, train_loss = 0.9350433591753244, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 240, train_loss = 0.9350361737160711, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 241, train_loss = 0.9341887924820185, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 242, train_loss = 0.9319051836355356, train_acc = 0.9977876106194691\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 243, train_loss = 0.9345571988524171, train_acc = 0.9977876106194691\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 244, train_loss = 0.9317878916190239, train_acc = 0.9977876106194691\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 245, train_loss = 0.9332183624355821, train_acc = 0.9976711690731253\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 246, train_loss = 0.931214772790554, train_acc = 0.9977876106194691\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 247, train_loss = 0.9288680696190568, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 248, train_loss = 0.9319130356161622, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 249, train_loss = 0.9306257528514834, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 250, train_loss = 0.9293800878076581, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 251, train_loss = 0.9288340124039678, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 252, train_loss = 0.9265278298407793, train_acc = 0.9977876106194691\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 253, train_loss = 0.9291758189647226, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 254, train_loss = 0.9266422341315774, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 255, train_loss = 0.9262743492872687, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 256, train_loss = 0.9274725709110498, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 257, train_loss = 0.9249391940684291, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 258, train_loss = 0.9259371602238389, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 259, train_loss = 0.9229234109370736, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 260, train_loss = 0.9243188314139843, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 261, train_loss = 0.9241733563394519, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 262, train_loss = 0.92340746584523, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 263, train_loss = 0.922784107431653, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 264, train_loss = 0.9217791681439849, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 265, train_loss = 0.9222483318299055, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 266, train_loss = 0.9209484842867823, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 267, train_loss = 0.921430729329586, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 268, train_loss = 0.9209736101329327, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 269, train_loss = 0.9208133195788832, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 270, train_loss = 0.9187270719558001, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 271, train_loss = 0.9222586434334517, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 272, train_loss = 0.9183265144674806, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 273, train_loss = 0.9168109657912282, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 274, train_loss = 0.91926381427038, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 275, train_loss = 0.916816441967967, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 276, train_loss = 0.9173943481146125, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 277, train_loss = 0.9163561661989661, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 278, train_loss = 0.9145653049199609, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 279, train_loss = 0.9166205053479644, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 280, train_loss = 0.9151904353202553, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 281, train_loss = 0.9129208922386169, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 282, train_loss = 0.9155839066952467, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 283, train_loss = 0.9133355400263099, train_acc = 0.9979040521658128\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 284, train_loss = 0.9116402386425762, train_acc = 0.9979040521658128\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 285, train_loss = 0.916344407320139, train_acc = 0.9979040521658128\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 286, train_loss = 0.9120021114795236, train_acc = 0.9979040521658128\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 287, train_loss = 0.910845935344696, train_acc = 0.9979040521658128\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 288, train_loss = 0.9117770747543545, train_acc = 0.9979040521658128\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 289, train_loss = 0.9125760129390983, train_acc = 0.9979040521658128\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 290, train_loss = 0.9107199714781018, train_acc = 0.9979040521658128\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 291, train_loss = 0.9109063291252824, train_acc = 0.9979040521658128\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 292, train_loss = 0.9085875184537144, train_acc = 0.9979040521658128\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 293, train_loss = 0.909190408885479, train_acc = 0.9979040521658128\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 294, train_loss = 0.9097188611776801, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 295, train_loss = 0.9071638795285253, train_acc = 0.9979040521658128\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 296, train_loss = 0.909284186855075, train_acc = 0.9979040521658128\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 297, train_loss = 0.9075338840484619, train_acc = 0.9979040521658128\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 298, train_loss = 0.9079586863517761, train_acc = 0.9979040521658128\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 299, train_loss = 0.9072754792869091, train_acc = 0.9979040521658128\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 300, train_loss = 0.9095728260726901, train_acc = 0.9979040521658128\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 301, train_loss = 0.9051396648137597, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 302, train_loss = 0.9061101128609153, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 303, train_loss = 0.9068326925189467, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 304, train_loss = 0.9057929751725169, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 305, train_loss = 0.9073200902639655, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 306, train_loss = 0.9048032518476248, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 307, train_loss = 0.9048961754888296, train_acc = 0.9979040521658128\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 308, train_loss = 0.9036319398583146, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 309, train_loss = 0.9041764115245314, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 310, train_loss = 0.9027352233679267, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 311, train_loss = 0.9022636891604634, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 312, train_loss = 0.9044284826813964, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 313, train_loss = 0.9018781371414661, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 314, train_loss = 0.9023309082986088, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 315, train_loss = 0.8999364313931437, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 316, train_loss = 0.9017693642526865, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 317, train_loss = 0.8996415206493111, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 318, train_loss = 0.902450197681901, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 319, train_loss = 0.8999863062053919, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 320, train_loss = 0.9007257949560881, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 321, train_loss = 0.8983493596315384, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 322, train_loss = 0.8993467154650716, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 323, train_loss = 0.899749872580287, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 324, train_loss = 0.8988458557723789, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 325, train_loss = 0.8977726784796687, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 326, train_loss = 0.897087865814683, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 327, train_loss = 0.8979886720626382, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 328, train_loss = 0.8988898750394583, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 329, train_loss = 0.8967656722961692, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 330, train_loss = 0.8955207404942485, train_acc = 0.9979040521658128\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 331, train_loss = 0.8955199023112073, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 332, train_loss = 0.8960929376335116, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 333, train_loss = 0.8962162714451551, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 334, train_loss = 0.8941247444599867, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 335, train_loss = 0.8959110683426843, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 336, train_loss = 0.8934996295720339, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 337, train_loss = 0.8949523903429508, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 338, train_loss = 0.8938440090641961, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 339, train_loss = 0.89452895832801, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 340, train_loss = 0.8924548706636415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 341, train_loss = 0.8952975682914257, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 342, train_loss = 0.8925393987447023, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 343, train_loss = 0.891526784747839, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 344, train_loss = 0.8913443169221864, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 345, train_loss = 0.8911261800676584, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 346, train_loss = 0.8922839177175774, train_acc = 0.9976711690731253\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 347, train_loss = 0.8913424170241342, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 348, train_loss = 0.8921304369941936, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 349, train_loss = 0.8906349626704468, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 350, train_loss = 0.8894801108763204, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 351, train_loss = 0.8897040331139578, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 352, train_loss = 0.8924408132807002, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 353, train_loss = 0.8882169475182309, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 354, train_loss = 0.8896252326667309, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 355, train_loss = 0.8887604835108505, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 356, train_loss = 0.888661581404449, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 357, train_loss = 0.8897982574999332, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 358, train_loss = 0.8877385258674622, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 359, train_loss = 0.8881823023184552, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 360, train_loss = 0.8863336822614656, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 361, train_loss = 0.8869301540180459, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 362, train_loss = 0.8854263840839849, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 363, train_loss = 0.8884568133726134, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 364, train_loss = 0.8878090586513281, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 365, train_loss = 0.8858657870441675, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 366, train_loss = 0.8861394841223955, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 367, train_loss = 0.8857596144080162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 368, train_loss = 0.8846948624923243, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 369, train_loss = 0.8855819211676135, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 370, train_loss = 0.883470173306705, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 371, train_loss = 0.8844437841325998, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 372, train_loss = 0.8834398481994867, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 373, train_loss = 0.8838125610127463, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 374, train_loss = 0.8849526637568488, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 375, train_loss = 0.8831197476611123, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 376, train_loss = 0.8819780237972736, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 377, train_loss = 0.8848331483677612, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 378, train_loss = 0.8817536029964685, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 379, train_loss = 0.8815491031855345, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 380, train_loss = 0.8820160037503229, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 381, train_loss = 0.8812859368845238, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 382, train_loss = 0.8810488960371003, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 383, train_loss = 0.883407345660089, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 384, train_loss = 0.8803577541038976, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 385, train_loss = 0.8801267190501676, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 386, train_loss = 0.8820991236716509, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 387, train_loss = 0.8808686261399998, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 388, train_loss = 0.879419411845447, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 389, train_loss = 0.8828143173232093, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 390, train_loss = 0.8793217384591117, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 391, train_loss = 0.8792485191152082, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 392, train_loss = 0.8792631396427169, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 393, train_loss = 0.8791839020923362, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 394, train_loss = 0.8797493403180852, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 395, train_loss = 0.8779011387377977, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 396, train_loss = 0.8799712608233676, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 397, train_loss = 0.8774239880367531, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 398, train_loss = 0.878291310124041, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 399, train_loss = 0.8775905376896844, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 400, train_loss = 0.8788620314226137, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 401, train_loss = 0.8775546718388796, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 402, train_loss = 0.8765969723463058, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 403, train_loss = 0.877150867752789, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 404, train_loss = 0.8776238095015287, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 405, train_loss = 0.8758494804278598, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 406, train_loss = 0.8764679587111459, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 407, train_loss = 0.8772710965349688, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 408, train_loss = 0.8744942204430117, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 409, train_loss = 0.8761908579617739, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 410, train_loss = 0.8756637281403528, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 411, train_loss = 0.8751531740053906, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 412, train_loss = 0.8739923989996896, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 413, train_loss = 0.8772846143692732, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 414, train_loss = 0.8744948276653304, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 415, train_loss = 0.874095905572176, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 416, train_loss = 0.8731442640200839, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 417, train_loss = 0.874448166541697, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 418, train_loss = 0.8740055399612174, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 419, train_loss = 0.8730907744393335, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 420, train_loss = 0.8740436813459382, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 421, train_loss = 0.8731021719650016, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 422, train_loss = 0.8725967736318125, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 423, train_loss = 0.8731374523267732, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 424, train_loss = 0.8730637760236277, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 425, train_loss = 0.8723246101289988, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 426, train_loss = 0.8712941557168961, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 427, train_loss = 0.8737809285521507, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 428, train_loss = 0.8717322647571564, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 429, train_loss = 0.8719490760340705, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 430, train_loss = 0.8706024537459598, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 431, train_loss = 0.8705132224931731, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 432, train_loss = 0.8721287262960686, train_acc = 0.9976711690731253\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 433, train_loss = 0.8724680741652264, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 434, train_loss = 0.8704794937148108, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 435, train_loss = 0.8699798354282393, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 436, train_loss = 0.8703724009319558, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 437, train_loss = 0.8702911784275784, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 438, train_loss = 0.8701170869171619, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 439, train_loss = 0.869190468765737, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 440, train_loss = 0.8693417888134718, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 441, train_loss = 0.8710774114952073, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 442, train_loss = 0.8694746624678373, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 443, train_loss = 0.8687602896243334, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 444, train_loss = 0.8677410321906791, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 445, train_loss = 0.8700561417863355, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 446, train_loss = 0.86801623491192, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 447, train_loss = 0.8682876992970705, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 448, train_loss = 0.86762261018157, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 449, train_loss = 0.8663846061899676, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 450, train_loss = 0.8659436771049513, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 451, train_loss = 0.8668354184701457, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 452, train_loss = 0.8658807768151746, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 453, train_loss = 0.8670823865904822, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 454, train_loss = 0.8663452124819742, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 455, train_loss = 0.8655436293556704, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 456, train_loss = 0.8651766870170832, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 457, train_loss = 0.8659500814974308, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 458, train_loss = 0.8649042254910455, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 459, train_loss = 0.8644392999485717, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 460, train_loss = 0.8650285272524343, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 461, train_loss = 0.8645519713536487, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 462, train_loss = 0.8637342099100351, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 463, train_loss = 0.864114424213767, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 464, train_loss = 0.863142962254642, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 465, train_loss = 0.8633994137271657, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 466, train_loss = 0.8637795920149074, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 467, train_loss = 0.8629355517550721, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 468, train_loss = 0.862489157669188, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 469, train_loss = 0.8630467827097164, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 470, train_loss = 0.8631935485973372, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 471, train_loss = 0.8630734464750276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 472, train_loss = 0.8624676739200368, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 473, train_loss = 0.861175282545446, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 474, train_loss = 0.8622744847089052, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 475, train_loss = 0.8615516504869447, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 476, train_loss = 0.8612177626564517, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 477, train_loss = 0.8614262100309134, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 478, train_loss = 0.8619759678840637, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 479, train_loss = 0.8604090418666601, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 480, train_loss = 0.8608074933290482, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 481, train_loss = 0.8597882358953939, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 482, train_loss = 0.860965187974216, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 483, train_loss = 0.8602489735931158, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 484, train_loss = 0.8601191658526659, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 485, train_loss = 0.8602512280122028, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 486, train_loss = 0.8593022966160788, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 487, train_loss = 0.8604672979563475, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 488, train_loss = 0.859742317967175, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 489, train_loss = 0.8598532589749084, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 490, train_loss = 0.8586985400543199, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 491, train_loss = 0.8590359799563885, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 492, train_loss = 0.8585209871307597, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 493, train_loss = 0.8579394935295568, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 494, train_loss = 0.8602064494043589, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 495, train_loss = 0.8576838715598569, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 496, train_loss = 0.858662573620677, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 497, train_loss = 0.8575302014724002, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 498, train_loss = 0.8582433300689445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 499, train_loss = 0.8578972965478897, train_acc = 0.9977876106194691\n",
      "test Acc 0.9669459962756052:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|███████████████████████████████████████████                                 | 17/30 [2:44:30<2:14:12, 619.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "18th- epoch: 0, train_loss = 326.57691603899, train_acc = 0.8136935258500233\n",
      "test Acc 0.8379888268156425:\n",
      "18th- epoch: 1, train_loss = 80.14014901220798, train_acc = 0.9222170470423847\n",
      "test Acc 0.8752327746741154:\n",
      "18th- epoch: 2, train_loss = 47.18844624608755, train_acc = 0.945388914764788\n",
      "test Acc 0.9334264432029795:\n",
      "18th- epoch: 3, train_loss = 32.41749233007431, train_acc = 0.9580810433162552\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 4, train_loss = 23.657416771166027, train_acc = 0.9677456916627852\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 5, train_loss = 17.810007931198925, train_acc = 0.9729855612482534\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 6, train_loss = 13.706240388099104, train_acc = 0.9782254308337215\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 7, train_loss = 10.999072901904583, train_acc = 0.9823008849557522\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 8, train_loss = 9.174434722401202, train_acc = 0.9846297158826269\n",
      "test Acc 0.952048417132216:\n",
      "18th- epoch: 9, train_loss = 7.801611444912851, train_acc = 0.9860270144387517\n",
      "test Acc 0.952048417132216:\n",
      "18th- epoch: 10, train_loss = 6.730264811776578, train_acc = 0.9876571960875641\n",
      "test Acc 0.9529795158286778:\n",
      "18th- epoch: 11, train_loss = 5.880935157183558, train_acc = 0.9897531439217513\n",
      "test Acc 0.9534450651769087:\n",
      "18th- epoch: 12, train_loss = 5.26383608719334, train_acc = 0.9904517931998137\n",
      "test Acc 0.9543761638733705:\n",
      "18th- epoch: 13, train_loss = 4.768304786179215, train_acc = 0.990801117838845\n",
      "test Acc 0.9548417132216015:\n",
      "18th- epoch: 14, train_loss = 4.377433636458591, train_acc = 0.9917326502095948\n",
      "test Acc 0.9553072625698324:\n",
      "18th- epoch: 15, train_loss = 4.035880109993741, train_acc = 0.992081974848626\n",
      "test Acc 0.9562383612662942:\n",
      "18th- epoch: 16, train_loss = 3.7593424767255783, train_acc = 0.9928970656730322\n",
      "test Acc 0.9567039106145251:\n",
      "18th- epoch: 17, train_loss = 3.52343159657903, train_acc = 0.9935957149510946\n",
      "test Acc 0.9567039106145251:\n",
      "18th- epoch: 18, train_loss = 3.332416333258152, train_acc = 0.9937121564974383\n",
      "test Acc 0.9567039106145251:\n",
      "18th- epoch: 19, train_loss = 3.148371148854494, train_acc = 0.9940614811364695\n",
      "test Acc 0.9562383612662942:\n",
      "18th- epoch: 20, train_loss = 3.00135564932134, train_acc = 0.994294364229157\n",
      "test Acc 0.957169459962756:\n",
      "18th- epoch: 21, train_loss = 2.867449752986431, train_acc = 0.994294364229157\n",
      "test Acc 0.957169459962756:\n",
      "18th- epoch: 22, train_loss = 2.74648779258132, train_acc = 0.9940614811364695\n",
      "test Acc 0.957169459962756:\n",
      "18th- epoch: 23, train_loss = 2.6368187541957013, train_acc = 0.9941779226828132\n",
      "test Acc 0.9567039106145251:\n",
      "18th- epoch: 24, train_loss = 2.542626228183508, train_acc = 0.994294364229157\n",
      "test Acc 0.9590316573556797:\n",
      "18th- epoch: 25, train_loss = 2.4585954497451894, train_acc = 0.9944108057755007\n",
      "test Acc 0.9590316573556797:\n",
      "18th- epoch: 26, train_loss = 2.3721895937924273, train_acc = 0.9944108057755007\n",
      "test Acc 0.9590316573556797:\n",
      "18th- epoch: 27, train_loss = 2.3112859812681563, train_acc = 0.9944108057755007\n",
      "test Acc 0.9585661080074488:\n",
      "18th- epoch: 28, train_loss = 2.245210933178896, train_acc = 0.9947601304145319\n",
      "test Acc 0.9590316573556797:\n",
      "18th- epoch: 29, train_loss = 2.19062215462327, train_acc = 0.9947601304145319\n",
      "test Acc 0.9594972067039106:\n",
      "18th- epoch: 30, train_loss = 2.1412189081311226, train_acc = 0.9948765719608756\n",
      "test Acc 0.9594972067039106:\n",
      "18th- epoch: 31, train_loss = 2.099861120193964, train_acc = 0.9948765719608756\n",
      "test Acc 0.9599627560521415:\n",
      "18th- epoch: 32, train_loss = 2.059463250130648, train_acc = 0.9949930135072194\n",
      "test Acc 0.9599627560521415:\n",
      "18th- epoch: 33, train_loss = 2.0213575536909048, train_acc = 0.9953423381462506\n",
      "test Acc 0.9599627560521415:\n",
      "18th- epoch: 34, train_loss = 1.990816354751587, train_acc = 0.9954587796925943\n",
      "test Acc 0.9599627560521415:\n",
      "18th- epoch: 35, train_loss = 1.9616179851291236, train_acc = 0.9954587796925943\n",
      "test Acc 0.9594972067039106:\n",
      "18th- epoch: 36, train_loss = 1.9367550474999007, train_acc = 0.995575221238938\n",
      "test Acc 0.9599627560521415:\n",
      "18th- epoch: 37, train_loss = 1.9135146563348826, train_acc = 0.995575221238938\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 38, train_loss = 1.8881041966378689, train_acc = 0.995575221238938\n",
      "test Acc 0.9599627560521415:\n",
      "18th- epoch: 39, train_loss = 1.8688255796732847, train_acc = 0.995575221238938\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 40, train_loss = 1.8501777251658496, train_acc = 0.995575221238938\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 41, train_loss = 1.831116604298586, train_acc = 0.9956916627852818\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 42, train_loss = 1.8121247328817844, train_acc = 0.9956916627852818\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 43, train_loss = 1.7928751284925966, train_acc = 0.9958081043316255\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 44, train_loss = 1.7796420430095168, train_acc = 0.9959245458779693\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 45, train_loss = 1.7632847540080547, train_acc = 0.9959245458779693\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 46, train_loss = 1.7485749994666548, train_acc = 0.996040987424313\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 47, train_loss = 1.7332937146275071, train_acc = 0.996040987424313\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 48, train_loss = 1.7186632417142391, train_acc = 0.996040987424313\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 49, train_loss = 1.7046941444277763, train_acc = 0.996040987424313\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 50, train_loss = 1.691529440387967, train_acc = 0.996040987424313\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 51, train_loss = 1.68023703371, train_acc = 0.996040987424313\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 52, train_loss = 1.6671296457498102, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 53, train_loss = 1.6543961092829704, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 54, train_loss = 1.6444549039006233, train_acc = 0.9961574289706567\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 55, train_loss = 1.6325105167925358, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 56, train_loss = 1.6227825917303562, train_acc = 0.9961574289706567\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 57, train_loss = 1.6106329783797264, train_acc = 0.9961574289706567\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 58, train_loss = 1.6007158694119425, train_acc = 0.9961574289706567\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 59, train_loss = 1.5898944313375978, train_acc = 0.9961574289706567\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 60, train_loss = 1.5826739656477002, train_acc = 0.9961574289706567\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 61, train_loss = 1.572268184274435, train_acc = 0.9961574289706567\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 62, train_loss = 1.5608229525387287, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 63, train_loss = 1.5533577017486095, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 64, train_loss = 1.5445753584353952, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 65, train_loss = 1.5341580932290526, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 66, train_loss = 1.5252546767442254, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 67, train_loss = 1.5181362628936768, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 68, train_loss = 1.508982103317976, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 69, train_loss = 1.5022528767585754, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 70, train_loss = 1.4902292427941575, train_acc = 0.9961574289706567\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 71, train_loss = 1.4872403405606747, train_acc = 0.9962738705170004\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 72, train_loss = 1.477227742470859, train_acc = 0.9962738705170004\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 73, train_loss = 1.470958899706602, train_acc = 0.9962738705170004\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 74, train_loss = 1.4605891915634857, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 75, train_loss = 1.4578095388933434, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 76, train_loss = 1.4481815857216134, train_acc = 0.996506753609688\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 77, train_loss = 1.4405115234330879, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 78, train_loss = 1.4358838150874362, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 79, train_loss = 1.4277951419353485, train_acc = 0.996506753609688\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 80, train_loss = 1.4198432266712189, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 81, train_loss = 1.4144796393811703, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 82, train_loss = 1.4109642282128334, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 83, train_loss = 1.4015371675268398, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 84, train_loss = 1.3962526991963387, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 85, train_loss = 1.3901502738372074, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 86, train_loss = 1.383841070033668, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 87, train_loss = 1.3775556025429978, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 88, train_loss = 1.3741362057626247, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 89, train_loss = 1.3659614635034814, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 90, train_loss = 1.361172924436687, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 91, train_loss = 1.3562250547111034, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 92, train_loss = 1.349739150457026, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 93, train_loss = 1.344782164938806, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 94, train_loss = 1.3386498975232826, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 95, train_loss = 1.334406847752689, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 96, train_loss = 1.3278494949117885, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 97, train_loss = 1.3253774344921112, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 98, train_loss = 1.320775813110231, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 99, train_loss = 1.3170537961050286, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 100, train_loss = 1.3102865504697547, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 101, train_loss = 1.3065811805427074, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 102, train_loss = 1.3012846832498326, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 103, train_loss = 1.297390390187502, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 104, train_loss = 1.2943502043708577, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 105, train_loss = 1.2887537752612843, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 106, train_loss = 1.2847267501056194, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 107, train_loss = 1.280550087489246, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 108, train_loss = 1.276574570685625, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 109, train_loss = 1.2726287518962636, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 110, train_loss = 1.2693934788330807, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 111, train_loss = 1.2653371579945087, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 112, train_loss = 1.2611765402034507, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 113, train_loss = 1.259126375116466, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 114, train_loss = 1.2552304665223346, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 115, train_loss = 1.250448933489679, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 116, train_loss = 1.2478115235753648, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 117, train_loss = 1.2439184648283117, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 118, train_loss = 1.2411437605805986, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 119, train_loss = 1.2372564698271162, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 120, train_loss = 1.2348510921001434, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 121, train_loss = 1.231377559404791, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 122, train_loss = 1.2283974140882492, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 123, train_loss = 1.2268088621385687, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 124, train_loss = 1.2224605282135599, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 125, train_loss = 1.2212525022514455, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 126, train_loss = 1.2160916129760153, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 127, train_loss = 1.2131557365246408, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 128, train_loss = 1.2106150413565047, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 129, train_loss = 1.2079160325229168, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 130, train_loss = 1.2049824185669422, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 131, train_loss = 1.2037777391560667, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 132, train_loss = 1.1992686788253195, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 133, train_loss = 1.199403348069609, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 134, train_loss = 1.195939244080364, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 135, train_loss = 1.1910196095705032, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 136, train_loss = 1.19260773062706, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 137, train_loss = 1.1887925093360536, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 138, train_loss = 1.1865908789150126, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 139, train_loss = 1.182983839262306, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 140, train_loss = 1.1828266779593832, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 141, train_loss = 1.1792730217166536, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 142, train_loss = 1.1763892037160986, train_acc = 0.9972054028877504\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 143, train_loss = 1.1750403754413128, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 144, train_loss = 1.1730949990451336, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 145, train_loss = 1.1691681556403637, train_acc = 0.9972054028877504\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 146, train_loss = 1.1673270277678967, train_acc = 0.9972054028877504\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 147, train_loss = 1.1653427282981283, train_acc = 0.9972054028877504\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 148, train_loss = 1.162537417065323, train_acc = 0.9972054028877504\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 149, train_loss = 1.1633315322287672, train_acc = 0.9972054028877504\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 150, train_loss = 1.159005954861641, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 151, train_loss = 1.157033421099186, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 152, train_loss = 1.15456023812294, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 153, train_loss = 1.1514088002331846, train_acc = 0.9972054028877504\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 154, train_loss = 1.1526778625957377, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 155, train_loss = 1.1488064577170007, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 156, train_loss = 1.1473564157895453, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 157, train_loss = 1.14438260222596, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 158, train_loss = 1.1425106947608583, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 159, train_loss = 1.1421243635304563, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 160, train_loss = 1.1389549747109413, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 161, train_loss = 1.1371312948576815, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 162, train_loss = 1.1351688280701637, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 163, train_loss = 1.1330499984323978, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 164, train_loss = 1.1336737349629402, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 165, train_loss = 1.1295116320252419, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 166, train_loss = 1.1278935285918124, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 167, train_loss = 1.1261797919869423, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 168, train_loss = 1.1242514761797793, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 169, train_loss = 1.1231761798262596, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 170, train_loss = 1.1211120424159162, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 171, train_loss = 1.1193720599003427, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 172, train_loss = 1.118120518822252, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 173, train_loss = 1.1161752517036803, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 174, train_loss = 1.1149987963326566, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 175, train_loss = 1.1135989427566528, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 176, train_loss = 1.1112520446367853, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 177, train_loss = 1.109766657154978, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 178, train_loss = 1.1086284071207047, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 179, train_loss = 1.1061357309408777, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 180, train_loss = 1.1051462863870256, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 181, train_loss = 1.1048364850394137, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 182, train_loss = 1.1038566331080801, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 183, train_loss = 1.1027283817529678, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 184, train_loss = 1.1017191944010847, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 185, train_loss = 1.0979558415710926, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 186, train_loss = 1.0971269893161661, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 187, train_loss = 1.0973508097231388, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 188, train_loss = 1.095871734123648, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 189, train_loss = 1.0941233399025805, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 190, train_loss = 1.0926785332449072, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 191, train_loss = 1.0919366988055117, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 192, train_loss = 1.0901954782493704, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 193, train_loss = 1.0885664212219126, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 194, train_loss = 1.0878692952283018, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 195, train_loss = 1.0859756606332667, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 196, train_loss = 1.0849994607269764, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 197, train_loss = 1.0830242435149557, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 198, train_loss = 1.0813041975088709, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 199, train_loss = 1.0798187417276495, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 200, train_loss = 1.079297974705696, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 201, train_loss = 1.0776741442568891, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 202, train_loss = 1.0777674938253767, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 203, train_loss = 1.0767124220728874, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 204, train_loss = 1.0742581002414227, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 205, train_loss = 1.073819977540552, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 206, train_loss = 1.0710314226635091, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 207, train_loss = 1.071043153602659, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 208, train_loss = 1.0706788127608888, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 209, train_loss = 1.0685495436191559, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 210, train_loss = 1.0678420724980242, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 211, train_loss = 1.0650452611334913, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 212, train_loss = 1.0660371469966776, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 213, train_loss = 1.0642131430395239, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 214, train_loss = 1.0633432194590569, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 215, train_loss = 1.0618288653604395, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 216, train_loss = 1.060754969716072, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 217, train_loss = 1.0599945411086082, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 218, train_loss = 1.057205706834793, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 219, train_loss = 1.0570776176937215, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 220, train_loss = 1.0569463719912164, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 221, train_loss = 1.053440007071913, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 222, train_loss = 1.05614559476453, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 223, train_loss = 1.0536344560496218, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 224, train_loss = 1.0524453905709379, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 225, train_loss = 1.05220453068614, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 226, train_loss = 1.0496928195170767, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 227, train_loss = 1.049368047464668, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 228, train_loss = 1.047294179599703, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 229, train_loss = 1.0468023543544405, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 230, train_loss = 1.0478801677636511, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 231, train_loss = 1.0452466843016737, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 232, train_loss = 1.0447865625210397, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 233, train_loss = 1.0419369253031618, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 234, train_loss = 1.0443154883869283, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 235, train_loss = 1.0403968170285225, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 236, train_loss = 1.0422031991183758, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 237, train_loss = 1.0395692375786894, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 238, train_loss = 1.0404844035692804, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 239, train_loss = 1.0356092167385214, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 240, train_loss = 1.038021743297577, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 241, train_loss = 1.0358210876584053, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 242, train_loss = 1.0332621286324866, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 243, train_loss = 1.033532503992319, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 244, train_loss = 1.0329803215972788, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 245, train_loss = 1.0319690381475084, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 246, train_loss = 1.0309526448436372, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 247, train_loss = 1.0299314868934744, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 248, train_loss = 1.028582317132532, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 249, train_loss = 1.0277972879521258, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 250, train_loss = 1.0269645837433927, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 251, train_loss = 1.0264700638763316, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 252, train_loss = 1.0251601624004252, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 253, train_loss = 1.0245968202762015, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 254, train_loss = 1.0233780555427074, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 255, train_loss = 1.0226867534220219, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 256, train_loss = 1.0215286811180704, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 257, train_loss = 1.0212639508135908, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 258, train_loss = 1.020643699914217, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 259, train_loss = 1.0195172168314457, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 260, train_loss = 1.0197344683110714, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 261, train_loss = 1.0180086381733418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 262, train_loss = 1.0178296479098208, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 263, train_loss = 1.0164316818118095, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 264, train_loss = 1.0157439311333292, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 265, train_loss = 1.0146795188375108, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 266, train_loss = 1.015066284686327, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 267, train_loss = 1.0130268844477541, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 268, train_loss = 1.0124698864929087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 269, train_loss = 1.0111177004873753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 270, train_loss = 1.0110382537059195, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 271, train_loss = 1.0102281955369108, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 272, train_loss = 1.0099515852816694, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 273, train_loss = 1.0084045554212935, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 274, train_loss = 1.007998955745279, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 275, train_loss = 1.0064283000938303, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 276, train_loss = 1.006645525496424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 277, train_loss = 1.0058669398240454, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 278, train_loss = 1.005215027678787, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 279, train_loss = 1.003909420222044, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 280, train_loss = 1.0018141120672226, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 281, train_loss = 1.0019329239912622, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 282, train_loss = 1.0012185350060463, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 283, train_loss = 1.0005148996897333, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 284, train_loss = 1.0009910240769386, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 285, train_loss = 0.9995579371861822, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 286, train_loss = 0.9987835536412604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 287, train_loss = 0.9982788190245628, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 288, train_loss = 0.9975296358279593, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 289, train_loss = 0.9972153355683986, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 290, train_loss = 0.9960067942738533, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 291, train_loss = 0.9953938089311123, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 292, train_loss = 0.9947370116915408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 293, train_loss = 0.9938686390723888, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 294, train_loss = 0.9939090895150002, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 295, train_loss = 0.9929129096362885, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 296, train_loss = 0.9923151259627048, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 297, train_loss = 0.9914061787221726, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 298, train_loss = 0.990764033049345, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 299, train_loss = 0.9901582983638946, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 300, train_loss = 0.9896248529348668, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 301, train_loss = 0.9891358253862563, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 302, train_loss = 0.9885816549267474, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 303, train_loss = 0.9878460690379143, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 304, train_loss = 0.9868028896544274, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 305, train_loss = 0.9867977015674114, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 306, train_loss = 0.9853294976055622, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 307, train_loss = 0.985195475319415, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 308, train_loss = 0.9848440550267696, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 309, train_loss = 0.9839496612548828, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 310, train_loss = 0.9831741427387897, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 311, train_loss = 0.9825645051896572, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 312, train_loss = 0.9823477976024151, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 313, train_loss = 0.9817279403414432, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 314, train_loss = 0.9808392574395839, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 315, train_loss = 0.9800299840662774, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 316, train_loss = 0.9792021537814435, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 317, train_loss = 0.9790090397000313, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 318, train_loss = 0.9784369307253655, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 319, train_loss = 0.9759861739967164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 320, train_loss = 0.9771557835247222, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 321, train_loss = 0.9761991774048511, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 322, train_loss = 0.9764372582230862, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 323, train_loss = 0.9763443507254124, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 324, train_loss = 0.9726787954568863, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 325, train_loss = 0.973676972091198, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 326, train_loss = 0.9737428364660445, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 327, train_loss = 0.9737974603976909, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 328, train_loss = 0.9728888049721718, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 329, train_loss = 0.9707137892637547, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 330, train_loss = 0.9717787553872768, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 331, train_loss = 0.9708969232942763, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 332, train_loss = 0.9703325095269975, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 333, train_loss = 0.9685328056420985, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 334, train_loss = 0.9679945868756477, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 335, train_loss = 0.9675956629216671, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 336, train_loss = 0.9658172366525832, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 337, train_loss = 0.9678136954698857, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 338, train_loss = 0.9683281977977458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 339, train_loss = 0.9673779681324959, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 340, train_loss = 0.9671790463235084, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 341, train_loss = 0.9636840634047985, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 342, train_loss = 0.9643563044573966, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 343, train_loss = 0.9629608268533048, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 344, train_loss = 0.9624001371357735, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 345, train_loss = 0.9637172905113403, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 346, train_loss = 0.9635472210738953, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 347, train_loss = 0.9649974641706649, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 348, train_loss = 0.9628609716892242, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 349, train_loss = 0.9605689967665967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 350, train_loss = 0.9609282426536083, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 351, train_loss = 0.9583573093023006, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 352, train_loss = 0.9580227248370647, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 353, train_loss = 0.9596983268857002, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 354, train_loss = 0.9604907954726514, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 355, train_loss = 0.9573612858857814, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 356, train_loss = 0.9566328711807728, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 357, train_loss = 0.9583439032230672, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 358, train_loss = 0.9554274243619147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 359, train_loss = 0.9543906760718528, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 360, train_loss = 0.9552663527429104, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 361, train_loss = 0.9564809824023541, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 362, train_loss = 0.9564389002825919, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 363, train_loss = 0.9539711090419587, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 364, train_loss = 0.9530668134484586, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 365, train_loss = 0.9524988569319248, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 366, train_loss = 0.9524274331834022, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 367, train_loss = 0.9538078531622887, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 368, train_loss = 0.953575732806712, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 369, train_loss = 0.9503547226395312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 370, train_loss = 0.9512010080125037, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 371, train_loss = 0.9495833416785899, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 372, train_loss = 0.9485761225223541, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 373, train_loss = 0.9494383546207246, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 374, train_loss = 0.9486309215426445, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 375, train_loss = 0.948208903273553, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 376, train_loss = 0.9498395683858689, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 377, train_loss = 0.947668115297347, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 378, train_loss = 0.9469163951780502, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 379, train_loss = 0.9467127447333041, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 380, train_loss = 0.9458536927904788, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 381, train_loss = 0.946488289782792, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 382, train_loss = 0.9452152748908702, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 383, train_loss = 0.9446980990469456, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 384, train_loss = 0.9439405960347358, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 385, train_loss = 0.9444478427376453, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 386, train_loss = 0.9435658367965516, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 387, train_loss = 0.9430203450228873, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 388, train_loss = 0.9431557543575764, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 389, train_loss = 0.9414169527590275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 390, train_loss = 0.9417159693930444, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 391, train_loss = 0.9387392662465572, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 392, train_loss = 0.9412655184660252, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 393, train_loss = 0.9392213436458405, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 394, train_loss = 0.9393793431427184, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 395, train_loss = 0.937415711581707, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 396, train_loss = 0.9374514197315875, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 397, train_loss = 0.9398737375940982, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 398, train_loss = 0.9370555765926838, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 399, train_loss = 0.9358964848015603, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 400, train_loss = 0.9359251633286476, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 401, train_loss = 0.9381458126008511, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 402, train_loss = 0.9373530807588395, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 403, train_loss = 0.934535530706853, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 404, train_loss = 0.9371522727105912, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 405, train_loss = 0.9337510714922246, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 406, train_loss = 0.9346582206580933, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 407, train_loss = 0.9329117933903035, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 408, train_loss = 0.9325241856276989, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 409, train_loss = 0.9352046065032482, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 410, train_loss = 0.9319249279797077, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 411, train_loss = 0.9312254252527055, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 412, train_loss = 0.9337954185903072, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 413, train_loss = 0.9307832928989228, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 414, train_loss = 0.9330112126972381, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 415, train_loss = 0.9300676112379733, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 416, train_loss = 0.9301670913901035, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 417, train_loss = 0.9300040751695633, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 418, train_loss = 0.9260940067470074, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 419, train_loss = 0.926171250641346, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 420, train_loss = 0.9257887589428719, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 421, train_loss = 0.9253671132028103, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 422, train_loss = 0.9248483913634118, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 423, train_loss = 0.924782379219323, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 424, train_loss = 0.9241444667186443, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 425, train_loss = 0.9238276369869709, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 426, train_loss = 0.9233790710568428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 427, train_loss = 0.9249164077136811, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 428, train_loss = 0.9226904958486557, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 429, train_loss = 0.9222204238176346, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 430, train_loss = 0.9220447937641438, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 431, train_loss = 0.9215402156114578, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 432, train_loss = 0.9212394977603253, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 433, train_loss = 0.9209798822794255, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 434, train_loss = 0.9207056748364266, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 435, train_loss = 0.9205416726563271, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 436, train_loss = 0.9197895700726804, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 437, train_loss = 0.9197270311415195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 438, train_loss = 0.9193247656021413, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 439, train_loss = 0.9190250895917416, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 440, train_loss = 0.9188246006760892, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 441, train_loss = 0.9179761782288551, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 442, train_loss = 0.9183225718643371, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 443, train_loss = 0.9172468272354308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 444, train_loss = 0.9167542594168481, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 445, train_loss = 0.91577959805727, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 446, train_loss = 0.914524740228444, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 447, train_loss = 0.913068105777711, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 448, train_loss = 0.9140554095301923, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 449, train_loss = 0.9138562480602559, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 450, train_loss = 0.9128363033141795, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 451, train_loss = 0.9126368040833768, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 452, train_loss = 0.9121431410312653, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 453, train_loss = 0.9115498401224613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 454, train_loss = 0.912952205786496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 455, train_loss = 0.9110756504032906, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 456, train_loss = 0.9111753925681114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 457, train_loss = 0.9106162190437317, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 458, train_loss = 0.9104943759739399, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 459, train_loss = 0.9128342395033542, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 460, train_loss = 0.9101927106585208, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 461, train_loss = 0.9095617110524472, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 462, train_loss = 0.9094939728583995, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 463, train_loss = 0.9112886476013955, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 464, train_loss = 0.909636755784959, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 465, train_loss = 0.9088072913382348, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 466, train_loss = 0.9083481604848203, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 467, train_loss = 0.9079881409797963, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 468, train_loss = 0.9077400664482411, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 469, train_loss = 0.9096742148194608, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 470, train_loss = 0.9073183933887776, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 471, train_loss = 0.9067281049992744, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 472, train_loss = 0.9094483467433747, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 473, train_loss = 0.9069143757224083, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 474, train_loss = 0.9092205998804275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 475, train_loss = 0.9069190596546832, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 476, train_loss = 0.9066733742747601, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 477, train_loss = 0.9060539503898326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 478, train_loss = 0.9051769487559795, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 479, train_loss = 0.9048368918392953, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 480, train_loss = 0.9050611642505828, train_acc = 0.9977876106194691\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 481, train_loss = 0.9061589973662194, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 482, train_loss = 0.9045126475393772, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 483, train_loss = 0.9044502340257168, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 484, train_loss = 0.9039879254996777, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 485, train_loss = 0.9030361697077751, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 486, train_loss = 0.9027238239850703, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 487, train_loss = 0.9056899820770923, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 488, train_loss = 0.9029608269538585, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 489, train_loss = 0.9026301453504857, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 490, train_loss = 0.902597592523307, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 491, train_loss = 0.90503740558961, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 492, train_loss = 0.9047054474558536, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 493, train_loss = 0.9041085503995419, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 494, train_loss = 0.9040441649649438, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 495, train_loss = 0.9039112590253353, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 496, train_loss = 0.9027577117085457, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 497, train_loss = 0.900769458463401, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 498, train_loss = 0.9003747726474103, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 499, train_loss = 0.898400620868415, train_acc = 0.9979040521658128\n",
      "test Acc 0.9674115456238361:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████▌                              | 18/30 [2:54:58<2:04:21, 621.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "19th- epoch: 0, train_loss = 363.3332947306335, train_acc = 0.8093851886353051\n",
      "test Acc 0.910148975791434:\n",
      "19th- epoch: 1, train_loss = 75.4872776940465, train_acc = 0.9245458779692595\n",
      "test Acc 0.9324953445065177:\n",
      "19th- epoch: 2, train_loss = 45.66243320214562, train_acc = 0.9488821611551002\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 3, train_loss = 32.09034991776571, train_acc = 0.9612249650675361\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 4, train_loss = 24.669426957145333, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "19th- epoch: 5, train_loss = 19.789334919303656, train_acc = 0.9744993013507219\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 6, train_loss = 16.18131787283346, train_acc = 0.9782254308337215\n",
      "test Acc 0.9543761638733705:\n",
      "19th- epoch: 7, train_loss = 13.517876403406262, train_acc = 0.9803213786679087\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 8, train_loss = 11.400652443990111, train_acc = 0.9820680018630648\n",
      "test Acc 0.9585661080074488:\n",
      "19th- epoch: 9, train_loss = 9.767625228036195, train_acc = 0.985910572892408\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 10, train_loss = 8.497474225237966, train_acc = 0.9874243129948765\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 11, train_loss = 7.454013640526682, train_acc = 0.9889380530973452\n",
      "test Acc 0.9622905027932961:\n",
      "19th- epoch: 12, train_loss = 6.605223372578621, train_acc = 0.9902189101071263\n",
      "test Acc 0.9636871508379888:\n",
      "19th- epoch: 13, train_loss = 5.891306166537106, train_acc = 0.9911504424778761\n",
      "test Acc 0.9650837988826816:\n",
      "19th- epoch: 14, train_loss = 5.289538050536066, train_acc = 0.9916162086632511\n",
      "test Acc 0.9655493482309124:\n",
      "19th- epoch: 15, train_loss = 4.757955418899655, train_acc = 0.992081974848626\n",
      "test Acc 0.9660148975791434:\n",
      "19th- epoch: 16, train_loss = 4.2857293747365475, train_acc = 0.9924312994876572\n",
      "test Acc 0.9655493482309124:\n",
      "19th- epoch: 17, train_loss = 3.858817657455802, train_acc = 0.9930135072193759\n",
      "test Acc 0.9660148975791434:\n",
      "19th- epoch: 18, train_loss = 3.5366152697242796, train_acc = 0.9934792734047508\n",
      "test Acc 0.9655493482309124:\n",
      "19th- epoch: 19, train_loss = 3.259873689385131, train_acc = 0.9940614811364695\n",
      "test Acc 0.9660148975791434:\n",
      "19th- epoch: 20, train_loss = 3.0280010558199137, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 21, train_loss = 2.82613827730529, train_acc = 0.9946436888681882\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 22, train_loss = 2.6569096266757697, train_acc = 0.9948765719608756\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 23, train_loss = 2.4904701951891184, train_acc = 0.9953423381462506\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 24, train_loss = 2.36180797428824, train_acc = 0.9954587796925943\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 25, train_loss = 2.2420454174280167, train_acc = 0.995575221238938\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 26, train_loss = 2.124881743453443, train_acc = 0.9959245458779693\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 27, train_loss = 2.037739575258456, train_acc = 0.996040987424313\n",
      "test Acc 0.9660148975791434:\n",
      "19th- epoch: 28, train_loss = 1.946045704302378, train_acc = 0.9963903120633442\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 29, train_loss = 1.8718553110957146, train_acc = 0.9963903120633442\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 30, train_loss = 1.8109088274650276, train_acc = 0.9961574289706567\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 31, train_loss = 1.7555959777673706, train_acc = 0.9963903120633442\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 32, train_loss = 1.7152947159484029, train_acc = 0.9966231951560317\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 33, train_loss = 1.6768738366663456, train_acc = 0.996506753609688\n",
      "test Acc 0.9669459962756052:\n",
      "19th- epoch: 34, train_loss = 1.6423508847947232, train_acc = 0.9966231951560317\n",
      "test Acc 0.9669459962756052:\n",
      "19th- epoch: 35, train_loss = 1.61793495278107, train_acc = 0.9966231951560317\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 36, train_loss = 1.5957244665478356, train_acc = 0.9966231951560317\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 37, train_loss = 1.5704459833796136, train_acc = 0.9966231951560317\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 38, train_loss = 1.5520104166935198, train_acc = 0.9966231951560317\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 39, train_loss = 1.5336502490681596, train_acc = 0.9966231951560317\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 40, train_loss = 1.5166180062224157, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 41, train_loss = 1.5023691039532423, train_acc = 0.9967396367023754\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 42, train_loss = 1.485126118932385, train_acc = 0.9967396367023754\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 43, train_loss = 1.4687001386773773, train_acc = 0.9967396367023754\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 44, train_loss = 1.4556468023802154, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 45, train_loss = 1.4478721127961762, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 46, train_loss = 1.4345533601008356, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 47, train_loss = 1.4193851274321787, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 48, train_loss = 1.412906797893811, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 49, train_loss = 1.4007689265417866, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 50, train_loss = 1.3935761071334127, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 51, train_loss = 1.3770644143223763, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 52, train_loss = 1.3743799046205822, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 53, train_loss = 1.3637066697701812, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 54, train_loss = 1.3560441598820034, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 55, train_loss = 1.3488687556236982, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 56, train_loss = 1.3430606645124499, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 57, train_loss = 1.3312141584756318, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 58, train_loss = 1.3309410481306259, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 59, train_loss = 1.3189363814890385, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 60, train_loss = 1.3137338940578047, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 61, train_loss = 1.309496014699107, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 62, train_loss = 1.3039069796504918, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 63, train_loss = 1.3015355647949036, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 64, train_loss = 1.291768735885853, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 65, train_loss = 1.2873618295416236, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 66, train_loss = 1.2801650256442372, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 67, train_loss = 1.2792391991242766, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 68, train_loss = 1.2688044682145119, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 69, train_loss = 1.269384521059692, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 70, train_loss = 1.2618778192845639, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 71, train_loss = 1.2585147808713373, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 72, train_loss = 1.2513413469714578, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 73, train_loss = 1.2504327952337917, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 74, train_loss = 1.2462069233879447, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 75, train_loss = 1.2413439176452812, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 76, train_loss = 1.2374424366280437, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 77, train_loss = 1.2345375191944186, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 78, train_loss = 1.2283979368803557, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 79, train_loss = 1.2289465895446483, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 80, train_loss = 1.2220188391802367, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 81, train_loss = 1.2178108195366804, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 82, train_loss = 1.2178528023359831, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 83, train_loss = 1.209890436992282, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 84, train_loss = 1.2092776596546173, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 85, train_loss = 1.2075731810182333, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 86, train_loss = 1.202473054319853, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 87, train_loss = 1.201259795576334, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 88, train_loss = 1.1953652972879354, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 89, train_loss = 1.193048156797886, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 90, train_loss = 1.1936711973248748, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 91, train_loss = 1.1869359780102968, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 92, train_loss = 1.1832358483225107, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 93, train_loss = 1.1852093475608854, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 94, train_loss = 1.1770369857549667, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 95, train_loss = 1.1803484335541725, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 96, train_loss = 1.1733186555356951, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 97, train_loss = 1.172550777599099, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 98, train_loss = 1.1702440225781174, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 99, train_loss = 1.165849730372429, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 100, train_loss = 1.16210871686053, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 101, train_loss = 1.1642287758440943, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 102, train_loss = 1.1579964670090703, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 103, train_loss = 1.1555363989173202, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 104, train_loss = 1.1561219673603773, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 105, train_loss = 1.1510683347732993, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 106, train_loss = 1.1478923776448937, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 107, train_loss = 1.148725751787424, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 108, train_loss = 1.1441842249332694, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 109, train_loss = 1.1424808992742328, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 110, train_loss = 1.1389943628309993, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 111, train_loss = 1.1359690384269925, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 112, train_loss = 1.137955101832631, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 113, train_loss = 1.133514643952367, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 114, train_loss = 1.129051748663187, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 115, train_loss = 1.1294817880989285, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 116, train_loss = 1.1267461230308982, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 117, train_loss = 1.1267948113381863, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 118, train_loss = 1.1225370758475037, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 119, train_loss = 1.1228532859386178, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 120, train_loss = 1.1191330893634586, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 121, train_loss = 1.1178962414414855, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 122, train_loss = 1.1171011701226234, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 123, train_loss = 1.1134181463421555, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 124, train_loss = 1.1122505286039086, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 125, train_loss = 1.1098578895180253, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 126, train_loss = 1.1078244571835967, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 127, train_loss = 1.106613676995039, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 128, train_loss = 1.1048027041106252, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 129, train_loss = 1.1025279313325882, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 130, train_loss = 1.1004454027861357, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 131, train_loss = 1.0981084108352661, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 132, train_loss = 1.09686407011759, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 133, train_loss = 1.096580998346326, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 134, train_loss = 1.0942133273929358, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 135, train_loss = 1.092969661578536, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 136, train_loss = 1.0907520105392905, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 137, train_loss = 1.089237763240817, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 138, train_loss = 1.0868048326374264, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 139, train_loss = 1.0863660437316867, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 140, train_loss = 1.0836487182677956, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 141, train_loss = 1.0829223400651244, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 142, train_loss = 1.078484653189662, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 143, train_loss = 1.0789414880127879, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 144, train_loss = 1.0769268268049927, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 145, train_loss = 1.0760357237159042, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 146, train_loss = 1.0740929301828146, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 147, train_loss = 1.0723775147198467, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 148, train_loss = 1.0699695932416944, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 149, train_loss = 1.0697168937622337, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 150, train_loss = 1.0678169025777606, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 151, train_loss = 1.0678861656488152, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 152, train_loss = 1.0660445926041575, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 153, train_loss = 1.0630314660520526, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 154, train_loss = 1.0623377282172441, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 155, train_loss = 1.059344946712372, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 156, train_loss = 1.0600052730442258, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 157, train_loss = 1.0582086096255807, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 158, train_loss = 1.0574795206339331, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 159, train_loss = 1.0577486927359132, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 160, train_loss = 1.0548826468439074, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 161, train_loss = 1.0514028867037268, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 162, train_loss = 1.0523903239518404, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 163, train_loss = 1.0527774660586147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 164, train_loss = 1.0510034871549578, train_acc = 0.9975547275267815\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 165, train_loss = 1.0489615450351266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 166, train_loss = 1.0463629358710023, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 167, train_loss = 1.0451463405042887, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 168, train_loss = 1.0424580772669287, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 169, train_loss = 1.0456704472453566, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 170, train_loss = 1.0433317075221566, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 171, train_loss = 1.042567961543682, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 172, train_loss = 1.0394093350769253, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 173, train_loss = 1.0378721306769876, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 174, train_loss = 1.0361689633427886, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 175, train_loss = 1.037411427751067, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 176, train_loss = 1.0358159107418032, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 177, train_loss = 1.0346239234058885, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 178, train_loss = 1.033320222675684, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 179, train_loss = 1.0313479832111625, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 180, train_loss = 1.0321065690368414, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 181, train_loss = 1.0292130870147957, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 182, train_loss = 1.0276380709037767, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 183, train_loss = 1.0284127406775951, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 184, train_loss = 1.0236425381153822, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 185, train_loss = 1.0249943186790915, train_acc = 0.9975547275267815\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 186, train_loss = 1.0232348727658973, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 187, train_loss = 1.0237533027902828, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 188, train_loss = 1.019014187157154, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 189, train_loss = 1.0178502512499108, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 190, train_loss = 1.0221401154994965, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 191, train_loss = 1.0179812038913951, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 192, train_loss = 1.0175441286191926, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 193, train_loss = 1.0171229268089519, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 194, train_loss = 1.0161249463781132, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 195, train_loss = 1.0145695904866443, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 196, train_loss = 1.0144212612285628, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 197, train_loss = 1.0136542078107595, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 198, train_loss = 1.010203535981418, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 199, train_loss = 1.0111386993303313, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 200, train_loss = 1.008636867009045, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 201, train_loss = 1.0106983458026662, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 202, train_loss = 1.0077566802501678, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 203, train_loss = 1.0057729271575226, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 204, train_loss = 1.0059660325423465, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 205, train_loss = 1.0042077737525688, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 206, train_loss = 1.0052189348862157, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 207, train_loss = 1.0004220151677146, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 208, train_loss = 1.0019579610452638, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 209, train_loss = 1.0015730025843368, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 210, train_loss = 1.002304562680365, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 211, train_loss = 0.9987177215516567, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 212, train_loss = 0.9974035210907459, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 213, train_loss = 0.9978144702836289, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 214, train_loss = 0.9959938911124482, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 215, train_loss = 0.9930337524638162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 216, train_loss = 0.9956935501322732, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 217, train_loss = 0.9950707958414569, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 218, train_loss = 0.9914007013067021, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 219, train_loss = 0.9885101740583195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 220, train_loss = 0.9890977224931703, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 221, train_loss = 0.9899208166971221, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 222, train_loss = 0.9870805547907366, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 223, train_loss = 0.987167023740767, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 224, train_loss = 0.9852431056424393, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 225, train_loss = 0.9858097930773511, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 226, train_loss = 0.9867285291329608, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 227, train_loss = 0.9837742845193134, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 228, train_loss = 0.9834486314430251, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 229, train_loss = 0.9823708981275558, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 230, train_loss = 0.9833197928965092, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 231, train_loss = 0.9819405563175678, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 232, train_loss = 0.9803048223257065, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 233, train_loss = 0.9804464764893055, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 234, train_loss = 0.9797222502529621, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 235, train_loss = 0.9772396869957447, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 236, train_loss = 0.9793497311547981, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 237, train_loss = 0.9766872636973858, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 238, train_loss = 0.977315371237637, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 239, train_loss = 0.9771411592737422, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 240, train_loss = 0.9746706796213402, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 241, train_loss = 0.9744421889408841, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 242, train_loss = 0.973665310688375, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 243, train_loss = 0.9735381801947369, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 244, train_loss = 0.9714749616905465, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 245, train_loss = 0.9719713491722359, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 246, train_loss = 0.9716692753136158, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 247, train_loss = 0.9701710256413207, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 248, train_loss = 0.9676434161738143, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 249, train_loss = 0.969065817691444, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 250, train_loss = 0.9679582677781582, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 251, train_loss = 0.9679434361532913, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 252, train_loss = 0.9662790733054862, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 253, train_loss = 0.9664521800950752, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 254, train_loss = 0.964086359985231, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 255, train_loss = 0.9662415596321807, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 256, train_loss = 0.9656321580187068, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 257, train_loss = 0.9607297045513405, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 258, train_loss = 0.9622874098495231, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 259, train_loss = 0.9629081835373654, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 260, train_loss = 0.9613369802609668, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 261, train_loss = 0.9609750881791115, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 262, train_loss = 0.961064970739244, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 263, train_loss = 0.9587731187566533, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 264, train_loss = 0.9596077315509319, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 265, train_loss = 0.9596957291141734, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 266, train_loss = 0.9607419222593307, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 267, train_loss = 0.9584840523675666, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 268, train_loss = 0.9563118194564595, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 269, train_loss = 0.957807278879045, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 270, train_loss = 0.9548272105530486, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 271, train_loss = 0.9551711504682316, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 272, train_loss = 0.9539491484538303, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 273, train_loss = 0.9557682598606334, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 274, train_loss = 0.9539770421906724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 275, train_loss = 0.9542615773752914, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 276, train_loss = 0.9526833730415092, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 277, train_loss = 0.9517066354528652, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 278, train_loss = 0.9520484184249653, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 279, train_loss = 0.9517188059762702, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 280, train_loss = 0.9517716815098538, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 281, train_loss = 0.9504265251234756, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 282, train_loss = 0.9501375543550239, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 283, train_loss = 0.9486834406852722, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 284, train_loss = 0.9493448312059627, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 285, train_loss = 0.9475520253181458, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 286, train_loss = 0.9461103950961842, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 287, train_loss = 0.948005635291338, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 288, train_loss = 0.9464626051485538, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 289, train_loss = 0.9475635724738822, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 290, train_loss = 0.9459533654153347, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 291, train_loss = 0.9459037544802413, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 292, train_loss = 0.9440255413428531, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 293, train_loss = 0.9452623973265872, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 294, train_loss = 0.9447749095634208, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 295, train_loss = 0.9444715765639558, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 296, train_loss = 0.9434685496016755, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 297, train_loss = 0.9432170180007233, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 298, train_loss = 0.942845918238163, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 299, train_loss = 0.9424111470580101, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 300, train_loss = 0.9415790811181068, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 301, train_loss = 0.9411548599600792, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 302, train_loss = 0.9408799695447669, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 303, train_loss = 0.9408576885834918, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 304, train_loss = 0.9398857442065491, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 305, train_loss = 0.9389502654448734, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 306, train_loss = 0.9394395798444748, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 307, train_loss = 0.9376217685639858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 308, train_loss = 0.9387264512479305, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 309, train_loss = 0.9399897369221435, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 310, train_loss = 0.9371251339689479, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 311, train_loss = 0.9369153355582966, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 312, train_loss = 0.9370918820277438, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 313, train_loss = 0.9366625299080624, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 314, train_loss = 0.9355769256726489, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 315, train_loss = 0.9373570618554368, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 316, train_loss = 0.9348741484209313, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 317, train_loss = 0.9348916125818505, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 318, train_loss = 0.9349862312301411, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 319, train_loss = 0.9334189345463528, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 320, train_loss = 0.9337416291236877, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 321, train_loss = 0.9332377041355358, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 322, train_loss = 0.9323167453185306, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 323, train_loss = 0.9319755807518959, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 324, train_loss = 0.9327383128329529, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 325, train_loss = 0.9311880233362899, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 326, train_loss = 0.9324279253705754, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 327, train_loss = 0.9310689345002174, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 328, train_loss = 0.9301280317231431, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 329, train_loss = 0.9303239248692989, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 330, train_loss = 0.9307802369221463, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 331, train_loss = 0.9292769270614372, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 332, train_loss = 0.9284737184643745, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 333, train_loss = 0.9290113945826306, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 334, train_loss = 0.9294519225732074, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 335, train_loss = 0.9287453877404914, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 336, train_loss = 0.9278486780822277, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 337, train_loss = 0.928801778703928, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 338, train_loss = 0.9264941141009331, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 339, train_loss = 0.9263685631231056, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 340, train_loss = 0.9268356959000812, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 341, train_loss = 0.9254772290587425, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 342, train_loss = 0.9250811760648503, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 343, train_loss = 0.9262673904522671, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 344, train_loss = 0.9254782497882843, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 345, train_loss = 0.9243892480953946, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 346, train_loss = 0.9237659772261395, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 347, train_loss = 0.9246844823137508, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 348, train_loss = 0.9230915320440545, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 349, train_loss = 0.9226154834032059, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 350, train_loss = 0.9237395003437996, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 351, train_loss = 0.9235932752490044, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 352, train_loss = 0.9226736091077328, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 353, train_loss = 0.9220868075863109, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 354, train_loss = 0.9227705200537457, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 355, train_loss = 0.9230254366993904, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 356, train_loss = 0.920900221914053, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 357, train_loss = 0.9221264173611416, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 358, train_loss = 0.9207821972668171, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 359, train_loss = 0.920806847512722, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 360, train_loss = 0.9191946859136806, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 361, train_loss = 0.9208711435421719, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 362, train_loss = 0.9196965756491409, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 363, train_loss = 0.9200623172000633, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 364, train_loss = 0.9185685068368912, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 365, train_loss = 0.9187687622979865, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 366, train_loss = 0.9193943118079915, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 367, train_loss = 0.9186939969658852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 368, train_loss = 0.9172316640615463, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 369, train_loss = 0.9182287218645797, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 370, train_loss = 0.9183544019833789, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 371, train_loss = 0.9168684482574463, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 372, train_loss = 0.9163390112444176, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 373, train_loss = 0.9175516118630185, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 374, train_loss = 0.9170502573251724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 375, train_loss = 0.9157992750406265, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 376, train_loss = 0.9153547349051223, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 377, train_loss = 0.9163879491388798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 378, train_loss = 0.9149176043792977, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 379, train_loss = 0.9145679213106632, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 380, train_loss = 0.9148094157353626, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 381, train_loss = 0.914229653775692, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 382, train_loss = 0.9136688659564243, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 383, train_loss = 0.913975944124104, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 384, train_loss = 0.9146856839433894, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 385, train_loss = 0.9126348719000816, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 386, train_loss = 0.9125012035146938, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 387, train_loss = 0.9127598479390144, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 388, train_loss = 0.9129346013069153, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 389, train_loss = 0.9117292190567241, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 390, train_loss = 0.9115826599299908, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 391, train_loss = 0.9108556297942414, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 392, train_loss = 0.9117085337638855, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 393, train_loss = 0.9106093148366199, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 394, train_loss = 0.9112745660022483, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 395, train_loss = 0.9099553674459457, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 396, train_loss = 0.9104137569665909, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 397, train_loss = 0.9097787427381263, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 398, train_loss = 0.9090687769130454, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 399, train_loss = 0.9099183989092126, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 400, train_loss = 0.9099167635067715, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 401, train_loss = 0.908670866243483, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 402, train_loss = 0.9082213478759513, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 403, train_loss = 0.9085842793210759, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 404, train_loss = 0.908199338860868, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 405, train_loss = 0.9070098089650855, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 406, train_loss = 0.9081690162420273, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 407, train_loss = 0.9071811102330685, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 408, train_loss = 0.9086277460082783, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 409, train_loss = 0.9064633473753929, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 410, train_loss = 0.9070745781064034, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 411, train_loss = 0.9059139639139175, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 412, train_loss = 0.9061775157824741, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 413, train_loss = 0.9057336511687026, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 414, train_loss = 0.9057563915848732, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 415, train_loss = 0.9048454749063239, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 416, train_loss = 0.9067391169592156, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 417, train_loss = 0.9043507464230061, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 418, train_loss = 0.9048879382535233, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 419, train_loss = 0.9043326725586667, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 420, train_loss = 0.9042778474613442, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 421, train_loss = 0.9034871732219472, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 422, train_loss = 0.904441944010614, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 423, train_loss = 0.9032402237280621, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 424, train_loss = 0.9049964720979915, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 425, train_loss = 0.9035396787003265, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 426, train_loss = 0.9034126102924347, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 427, train_loss = 0.9031716076060547, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 428, train_loss = 0.9023166274055257, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 429, train_loss = 0.9014153070747852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 430, train_loss = 0.9039441309869289, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 431, train_loss = 0.9018576753660454, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 432, train_loss = 0.9026548738256679, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 433, train_loss = 0.901774058736919, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 434, train_loss = 0.9021711461246014, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 435, train_loss = 0.9005089079364552, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 436, train_loss = 0.9022138963118778, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 437, train_loss = 0.9008618593215942, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 438, train_loss = 0.9005024321377277, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 439, train_loss = 0.9002434462308884, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 440, train_loss = 0.8997976543978439, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 441, train_loss = 0.8993484651073231, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 442, train_loss = 0.9000753127038479, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 443, train_loss = 0.8971070448533283, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 444, train_loss = 0.8978783997372375, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 445, train_loss = 0.8978742410763516, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 446, train_loss = 0.896365363150835, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 447, train_loss = 0.898252323269844, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 448, train_loss = 0.8940668491050019, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 449, train_loss = 0.8921953365206718, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 450, train_loss = 0.8927487085238681, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 451, train_loss = 0.8969066714234941, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 452, train_loss = 0.8981772623956203, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 453, train_loss = 0.8974077266939275, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 454, train_loss = 0.8985866531729698, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 455, train_loss = 0.8970699186138518, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 456, train_loss = 0.89472185323757, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 457, train_loss = 0.8887993134558201, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 458, train_loss = 0.891144468139828, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 459, train_loss = 0.8954733498394489, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 460, train_loss = 0.8917900510132313, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 461, train_loss = 0.8915427476167679, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 462, train_loss = 0.8901256918907166, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 463, train_loss = 0.8955020693429105, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 464, train_loss = 0.8891988769173622, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 465, train_loss = 0.889097889263212, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 466, train_loss = 0.8942154198884964, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 467, train_loss = 0.8961489746980078, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 468, train_loss = 0.8947026692330837, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 469, train_loss = 0.8938421631864912, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 470, train_loss = 0.8948809715620882, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 471, train_loss = 0.8932770974934101, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 472, train_loss = 0.8936707948632829, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 473, train_loss = 0.8949170534797304, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 474, train_loss = 0.8925772048532963, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 475, train_loss = 0.8877329354472749, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 476, train_loss = 0.8911413960158825, train_acc = 0.9979040521658128\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 477, train_loss = 0.8932744736484892, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 478, train_loss = 0.8921657229475386, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 479, train_loss = 0.8862672559916973, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 480, train_loss = 0.8863902228586085, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 481, train_loss = 0.8898309258111112, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 482, train_loss = 0.8909969168416865, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 483, train_loss = 0.8895910431929224, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 484, train_loss = 0.8838475135453336, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 485, train_loss = 0.8858835461251147, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 486, train_loss = 0.8904154573865526, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 487, train_loss = 0.8867469852157228, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 488, train_loss = 0.8917542708404653, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 489, train_loss = 0.8847296386957169, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 490, train_loss = 0.8850459295026667, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 491, train_loss = 0.8916008758060343, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 492, train_loss = 0.8903981273360841, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 493, train_loss = 0.8903017689772241, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 494, train_loss = 0.8910146914422512, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 495, train_loss = 0.8830609979740984, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 496, train_loss = 0.8884834299497015, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 497, train_loss = 0.8873026880137331, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 498, train_loss = 0.8881515488028526, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 499, train_loss = 0.8868835953362577, train_acc = 0.9979040521658128\n",
      "test Acc 0.9767225325884544:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|████████████████████████████████████████████████▏                           | 19/30 [3:05:21<1:54:06, 622.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "20th- epoch: 0, train_loss = 407.4422921668738, train_acc = 0.7987890079180252\n",
      "test Acc 0.8975791433891993:\n",
      "20th- epoch: 1, train_loss = 85.33225200825837, train_acc = 0.9224499301350721\n",
      "test Acc 0.9227188081936686:\n",
      "20th- epoch: 2, train_loss = 51.077318109571934, train_acc = 0.9429436422915697\n",
      "test Acc 0.9269087523277467:\n",
      "20th- epoch: 3, train_loss = 34.55851466518652, train_acc = 0.9585468095016302\n",
      "test Acc 0.9343575418994413:\n",
      "20th- epoch: 4, train_loss = 25.56621980915952, train_acc = 0.9651839776432231\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 5, train_loss = 19.594347203761572, train_acc = 0.9706567303213787\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 6, train_loss = 15.465696746483445, train_acc = 0.9768281322775967\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 7, train_loss = 12.808437361032702, train_acc = 0.9811364694923148\n",
      "test Acc 0.952048417132216:\n",
      "20th- epoch: 8, train_loss = 10.88739125430584, train_acc = 0.9832324173265021\n",
      "test Acc 0.9515828677839852:\n",
      "20th- epoch: 9, train_loss = 9.389873301028274, train_acc = 0.9852119236143456\n",
      "test Acc 0.952513966480447:\n",
      "20th- epoch: 10, train_loss = 8.108123790472746, train_acc = 0.9862598975314392\n",
      "test Acc 0.9539106145251397:\n",
      "20th- epoch: 11, train_loss = 7.052691704942845, train_acc = 0.9877736376339078\n",
      "test Acc 0.9543761638733705:\n",
      "20th- epoch: 12, train_loss = 6.203369652852416, train_acc = 0.9896367023754076\n",
      "test Acc 0.9543761638733705:\n",
      "20th- epoch: 13, train_loss = 5.54307203181088, train_acc = 0.9904517931998137\n",
      "test Acc 0.9543761638733705:\n",
      "20th- epoch: 14, train_loss = 4.995721218525432, train_acc = 0.9910340009315324\n",
      "test Acc 0.9548417132216015:\n",
      "20th- epoch: 15, train_loss = 4.545370234758593, train_acc = 0.9916162086632511\n",
      "test Acc 0.9557728119180633:\n",
      "20th- epoch: 16, train_loss = 4.1937844470958225, train_acc = 0.9921984163949698\n",
      "test Acc 0.957635009310987:\n",
      "20th- epoch: 17, train_loss = 3.8559178048744798, train_acc = 0.9925477410340009\n",
      "test Acc 0.9581005586592178:\n",
      "20th- epoch: 18, train_loss = 3.560856905474793, train_acc = 0.9927806241266884\n",
      "test Acc 0.9585661080074488:\n",
      "20th- epoch: 19, train_loss = 3.30197980691446, train_acc = 0.9932463903120633\n",
      "test Acc 0.9585661080074488:\n",
      "20th- epoch: 20, train_loss = 3.0733781158924103, train_acc = 0.9935957149510946\n",
      "test Acc 0.9590316573556797:\n",
      "20th- epoch: 21, train_loss = 2.8617676359717734, train_acc = 0.994294364229157\n",
      "test Acc 0.9590316573556797:\n",
      "20th- epoch: 22, train_loss = 2.6941220350563526, train_acc = 0.9946436888681882\n",
      "test Acc 0.9590316573556797:\n",
      "20th- epoch: 23, train_loss = 2.568772043392528, train_acc = 0.9948765719608756\n",
      "test Acc 0.9594972067039106:\n",
      "20th- epoch: 24, train_loss = 2.4510570255224593, train_acc = 0.9952258965999069\n",
      "test Acc 0.9599627560521415:\n",
      "20th- epoch: 25, train_loss = 2.356932138383854, train_acc = 0.9956916627852818\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 26, train_loss = 2.2824514198000543, train_acc = 0.9956916627852818\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 27, train_loss = 2.2023368943482637, train_acc = 0.9958081043316255\n",
      "test Acc 0.9604283054003724:\n",
      "20th- epoch: 28, train_loss = 2.1434307539020665, train_acc = 0.9959245458779693\n",
      "test Acc 0.9599627560521415:\n",
      "20th- epoch: 29, train_loss = 2.0881596694816835, train_acc = 0.9961574289706567\n",
      "test Acc 0.9599627560521415:\n",
      "20th- epoch: 30, train_loss = 2.038557714491617, train_acc = 0.9961574289706567\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 31, train_loss = 1.9968989957123995, train_acc = 0.9961574289706567\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 32, train_loss = 1.9568933906848542, train_acc = 0.9963903120633442\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 33, train_loss = 1.9226875237072818, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 34, train_loss = 1.886388340324629, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 35, train_loss = 1.8585736616514623, train_acc = 0.996506753609688\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 36, train_loss = 1.8307311238604598, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 37, train_loss = 1.8047701961477287, train_acc = 0.996506753609688\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 38, train_loss = 1.7806500508449972, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 39, train_loss = 1.7568388238432817, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 40, train_loss = 1.736674077808857, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 41, train_loss = 1.7155489339493215, train_acc = 0.996506753609688\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 42, train_loss = 1.695562143198913, train_acc = 0.996506753609688\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 43, train_loss = 1.6781500433571637, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 44, train_loss = 1.6587178415211383, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 45, train_loss = 1.6412584881763905, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 46, train_loss = 1.6267809794808272, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 47, train_loss = 1.6084735965414438, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 48, train_loss = 1.5936527767626103, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 49, train_loss = 1.5816798956657294, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 50, train_loss = 1.5679157361446414, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 51, train_loss = 1.5552813769318163, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 52, train_loss = 1.542241977615049, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 53, train_loss = 1.530346489744261, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 54, train_loss = 1.516625348944217, train_acc = 0.996506753609688\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 55, train_loss = 1.5041004201921169, train_acc = 0.996506753609688\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 56, train_loss = 1.493339283770183, train_acc = 0.996506753609688\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 57, train_loss = 1.4812583602033556, train_acc = 0.996506753609688\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 58, train_loss = 1.4697365432512015, train_acc = 0.996506753609688\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 59, train_loss = 1.4600540479586925, train_acc = 0.996506753609688\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 60, train_loss = 1.4503909299091902, train_acc = 0.996506753609688\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 61, train_loss = 1.438496904593194, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 62, train_loss = 1.4291510727198329, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 63, train_loss = 1.4192185152787715, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 64, train_loss = 1.4106165232806234, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 65, train_loss = 1.4029345877061132, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 66, train_loss = 1.391609468657407, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 67, train_loss = 1.3828163780272007, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 68, train_loss = 1.373892848539981, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 69, train_loss = 1.3660291200503707, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 70, train_loss = 1.358829077493283, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 71, train_loss = 1.350947508282843, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 72, train_loss = 1.343257483720663, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 73, train_loss = 1.3354444524011342, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 74, train_loss = 1.3280217197461752, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 75, train_loss = 1.3214082286431221, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 76, train_loss = 1.3123135423957137, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 77, train_loss = 1.3082451804802986, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 78, train_loss = 1.2992032368929358, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 79, train_loss = 1.2941188135446282, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 80, train_loss = 1.2872148674650816, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 81, train_loss = 1.2810893611313077, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 82, train_loss = 1.275988070294261, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 83, train_loss = 1.2717317181377439, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 84, train_loss = 1.2645466104149818, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 85, train_loss = 1.2617793122044532, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 86, train_loss = 1.256615910679102, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 87, train_loss = 1.2512242391967447, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 88, train_loss = 1.2449027984403074, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 89, train_loss = 1.2418245586304693, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 90, train_loss = 1.236147432893631, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 91, train_loss = 1.2292693501076428, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 92, train_loss = 1.2241847861296264, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 93, train_loss = 1.2212609105481533, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 94, train_loss = 1.2157417798152892, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 95, train_loss = 1.212611887138337, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 96, train_loss = 1.2091360286140116, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 97, train_loss = 1.2035249499604106, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 98, train_loss = 1.2009015802759677, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 99, train_loss = 1.1978984451125143, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 100, train_loss = 1.1925239753181813, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 101, train_loss = 1.191426132034394, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 102, train_loss = 1.1838236070034327, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 103, train_loss = 1.1800337890163064, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 104, train_loss = 1.1745058713277103, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 105, train_loss = 1.1718333150929539, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 106, train_loss = 1.1656323905772297, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 107, train_loss = 1.1629558138083667, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 108, train_loss = 1.1614778425282566, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 109, train_loss = 1.157308911511791, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 110, train_loss = 1.1551231297926279, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 111, train_loss = 1.153271269358811, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 112, train_loss = 1.1489807235338958, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 113, train_loss = 1.1468899890314788, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 114, train_loss = 1.1434735913499026, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 115, train_loss = 1.14190210790548, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 116, train_loss = 1.1384441258123843, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 117, train_loss = 1.1368768881075084, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 118, train_loss = 1.1330169794819085, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 119, train_loss = 1.131687762986985, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 120, train_loss = 1.1296647064591525, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 121, train_loss = 1.1259959358721972, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 122, train_loss = 1.1231040303828195, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 123, train_loss = 1.1219331373722525, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 124, train_loss = 1.1184433010639623, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 125, train_loss = 1.1164010150823742, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 126, train_loss = 1.1149817452896968, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 127, train_loss = 1.1119507733601495, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 128, train_loss = 1.1097835934124305, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 129, train_loss = 1.1079384440890863, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 130, train_loss = 1.1065309890545905, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 131, train_loss = 1.1040189937557443, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 132, train_loss = 1.1019251914694905, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 133, train_loss = 1.099091700045392, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 134, train_loss = 1.0979569352566614, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 135, train_loss = 1.0967278316020383, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 136, train_loss = 1.0934507992715226, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 137, train_loss = 1.091530900761427, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 138, train_loss = 1.0897993777543888, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 139, train_loss = 1.087591480150877, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 140, train_loss = 1.0870162748396979, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 141, train_loss = 1.085587049681635, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 142, train_loss = 1.0840434601195739, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 143, train_loss = 1.080793201457709, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 144, train_loss = 1.0800852050670073, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 145, train_loss = 1.0781463516541407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 146, train_loss = 1.0764368252494023, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 147, train_loss = 1.0758441855796264, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 148, train_loss = 1.0723838764242828, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 149, train_loss = 1.0711160688661039, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 150, train_loss = 1.0700844279490411, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 151, train_loss = 1.0675878333859146, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 152, train_loss = 1.0671099916435196, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 153, train_loss = 1.065152009949088, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 154, train_loss = 1.0645329419858172, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 155, train_loss = 1.062280107908009, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 156, train_loss = 1.0609718436971889, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 157, train_loss = 1.059728577885835, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 158, train_loss = 1.0568933679387555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 159, train_loss = 1.0567328110337257, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 160, train_loss = 1.0548123928383575, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 161, train_loss = 1.054335094988346, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 162, train_loss = 1.0521627409980283, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 163, train_loss = 1.050122583284974, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 164, train_loss = 1.050657785810472, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 165, train_loss = 1.048530399799347, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 166, train_loss = 1.0481784449293627, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 167, train_loss = 1.0446719732135534, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 168, train_loss = 1.0456389232203946, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 169, train_loss = 1.0433094675317989, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 170, train_loss = 1.0413604682908044, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 171, train_loss = 1.04046541700518, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 172, train_loss = 1.039691803358437, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 173, train_loss = 1.0375172874555574, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 174, train_loss = 1.037066649645567, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 175, train_loss = 1.036404773592949, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 176, train_loss = 1.0353960879147053, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 177, train_loss = 1.0323531733229174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 178, train_loss = 1.0324627341105952, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 179, train_loss = 1.0312009919434786, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 180, train_loss = 1.029039910681604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 181, train_loss = 1.0308479393497691, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 182, train_loss = 1.0265675745904446, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 183, train_loss = 1.0268824106678949, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 184, train_loss = 1.02535653704399, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 185, train_loss = 1.024094836167933, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 186, train_loss = 1.024680511407496, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 187, train_loss = 1.0233089554458275, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 188, train_loss = 1.02127067589754, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 189, train_loss = 1.0194107086063013, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 190, train_loss = 1.0194860817864537, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 191, train_loss = 1.019030924886465, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 192, train_loss = 1.0173118353486643, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 193, train_loss = 1.0160626759752631, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 194, train_loss = 1.0145718650892377, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 195, train_loss = 1.0161509752870188, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 196, train_loss = 1.0118495086207986, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 197, train_loss = 1.0125351445749402, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 198, train_loss = 1.0117088410406723, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 199, train_loss = 1.0100611175075755, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 200, train_loss = 1.0088422593325959, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 201, train_loss = 1.0080455979332328, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 202, train_loss = 1.0089460794479237, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 203, train_loss = 1.0057623464017524, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 204, train_loss = 1.0050077553241863, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 205, train_loss = 1.0051441394389258, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 206, train_loss = 1.0045428794473992, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 207, train_loss = 1.0018284131438122, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 208, train_loss = 1.002505243755877, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 209, train_loss = 1.0003657884299173, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 210, train_loss = 1.0010054207741632, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 211, train_loss = 1.0001113908365369, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 212, train_loss = 0.9981225980445743, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 213, train_loss = 0.9969985966235981, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 214, train_loss = 0.9971257774159312, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 215, train_loss = 0.9974700892344117, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 216, train_loss = 0.9952735636979924, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 217, train_loss = 0.9939069713800563, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 218, train_loss = 0.9922254554330721, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 219, train_loss = 0.9926785798743367, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 220, train_loss = 0.9918044373989687, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 221, train_loss = 0.9902774998918176, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 222, train_loss = 0.9913538126274943, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 223, train_loss = 0.9911286374554038, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 224, train_loss = 0.9898326996117248, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 225, train_loss = 0.9872727328911424, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 226, train_loss = 0.986581570468843, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 227, train_loss = 0.9852897484452114, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 228, train_loss = 0.9859392807484255, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 229, train_loss = 0.9863803184925928, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 230, train_loss = 0.9852345067411079, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 231, train_loss = 0.983711948931159, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 232, train_loss = 0.9829897740855813, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 233, train_loss = 0.9813158273100271, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 234, train_loss = 0.9823135041297064, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 235, train_loss = 0.979973364934267, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 236, train_loss = 0.9805325999259367, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 237, train_loss = 0.978379019536078, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 238, train_loss = 0.9781213567293889, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 239, train_loss = 0.9766454985365272, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 240, train_loss = 0.9766586463301792, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 241, train_loss = 0.9752621573097713, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 242, train_loss = 0.9745234316214919, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 243, train_loss = 0.9730195766314864, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 244, train_loss = 0.9734371829144948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 245, train_loss = 0.9729636780284636, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 246, train_loss = 0.9709362173452973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 247, train_loss = 0.9725254212171421, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 248, train_loss = 0.9714195619635575, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 249, train_loss = 0.9696042180694349, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 250, train_loss = 0.9692671972625249, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 251, train_loss = 0.9689803983383172, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 252, train_loss = 0.9677486596629024, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 253, train_loss = 0.9687128560617566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 254, train_loss = 0.9664590889587998, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 255, train_loss = 0.966711615834356, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 256, train_loss = 0.9659509171433456, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 257, train_loss = 0.9635458982847922, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 258, train_loss = 0.9636909523978829, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 259, train_loss = 0.9633554123975046, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 260, train_loss = 0.9628138445950754, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 261, train_loss = 0.963906664710521, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 262, train_loss = 0.9604704917110212, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 263, train_loss = 0.9591419476382725, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 264, train_loss = 0.9598070299252868, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 265, train_loss = 0.9602863164618611, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 266, train_loss = 0.9594922615215182, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 267, train_loss = 0.9568262686952949, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 268, train_loss = 0.9576436669267423, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 269, train_loss = 0.9567923008762591, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 270, train_loss = 0.9581933142617345, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 271, train_loss = 0.9565723075829737, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 272, train_loss = 0.9533454058691859, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 273, train_loss = 0.9538875684775121, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 274, train_loss = 0.9536715156100399, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 275, train_loss = 0.9532626845575578, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 276, train_loss = 0.9529953571036458, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 277, train_loss = 0.9520016272253997, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 278, train_loss = 0.9518164026849263, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 279, train_loss = 0.9508617697283626, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 280, train_loss = 0.9513680689669854, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 281, train_loss = 0.9490313632413745, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 282, train_loss = 0.9479679210744507, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 283, train_loss = 0.9491356136277318, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 284, train_loss = 0.9484027661383152, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 285, train_loss = 0.9456998252608173, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 286, train_loss = 0.9466525272764557, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 287, train_loss = 0.9474505779035098, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 288, train_loss = 0.9458371382206678, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 289, train_loss = 0.9448981583118439, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 290, train_loss = 0.9442191210873716, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 291, train_loss = 0.9450053721666336, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 292, train_loss = 0.9434574227780104, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 293, train_loss = 0.9440145821608894, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 294, train_loss = 0.940668199211359, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 295, train_loss = 0.941707809764921, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 296, train_loss = 0.9418512365482457, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 297, train_loss = 0.9425466445572965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 298, train_loss = 0.9391300429888361, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 299, train_loss = 0.9406765811145306, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 300, train_loss = 0.94025519490242, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 301, train_loss = 0.939839522663533, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 302, train_loss = 0.9364258113018877, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 303, train_loss = 0.9382236910350912, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 304, train_loss = 0.9376783091574907, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 305, train_loss = 0.9375501989088662, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 306, train_loss = 0.937947453930974, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 307, train_loss = 0.937632401164592, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 308, train_loss = 0.936536455526948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 309, train_loss = 0.9360024842135317, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 310, train_loss = 0.934813255444169, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 311, train_loss = 0.9354671910405159, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 312, train_loss = 0.9361555948853493, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 313, train_loss = 0.9342873717359907, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 314, train_loss = 0.9340895228087902, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 315, train_loss = 0.9328074759505398, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 316, train_loss = 0.9323432917408354, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 317, train_loss = 0.9323832572736137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 318, train_loss = 0.9311555661261082, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 319, train_loss = 0.9315693688877218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 320, train_loss = 0.9306486671157472, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 321, train_loss = 0.9315686790905602, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 322, train_loss = 0.9288408160209656, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 323, train_loss = 0.9285349224992387, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 324, train_loss = 0.9304402923844464, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 325, train_loss = 0.9287208250425465, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 326, train_loss = 0.927937733631552, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 327, train_loss = 0.9280680858828418, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 328, train_loss = 0.9270694206170447, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 329, train_loss = 0.927755052845896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 330, train_loss = 0.9258369250856049, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 331, train_loss = 0.9272875059396029, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 332, train_loss = 0.9238263337574608, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 333, train_loss = 0.9242181790359609, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 334, train_loss = 0.9260888037570112, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 335, train_loss = 0.924474282812298, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 336, train_loss = 0.92354359788078, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 337, train_loss = 0.9232940835245245, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 338, train_loss = 0.922621255118429, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 339, train_loss = 0.9214241827539809, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 340, train_loss = 0.9215505085885525, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 341, train_loss = 0.9199425932019949, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 342, train_loss = 0.9194499372206337, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 343, train_loss = 0.9215208186469681, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 344, train_loss = 0.9199643259235017, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 345, train_loss = 0.9203321294226043, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 346, train_loss = 0.9184082082174427, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 347, train_loss = 0.9192181204743974, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 348, train_loss = 0.9169645340480201, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 349, train_loss = 0.9173203352838755, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 350, train_loss = 0.918455329414428, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 351, train_loss = 0.9165353545286052, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 352, train_loss = 0.915980506066262, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 353, train_loss = 0.9184040116779215, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 354, train_loss = 0.9166251731403463, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 355, train_loss = 0.9163642420135147, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 356, train_loss = 0.9142935611307621, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 357, train_loss = 0.9138885699212551, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 358, train_loss = 0.9130825642496347, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 359, train_loss = 0.9137915261089802, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 360, train_loss = 0.9144482196606987, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 361, train_loss = 0.9141976429782517, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 362, train_loss = 0.9137324020266533, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 363, train_loss = 0.9126784975342161, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 364, train_loss = 0.9123380358032591, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 365, train_loss = 0.9098913048692339, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 366, train_loss = 0.9103505450002558, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 367, train_loss = 0.9119982098527544, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 368, train_loss = 0.9115221351385117, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 369, train_loss = 0.9098754574843042, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 370, train_loss = 0.9120809019841545, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 371, train_loss = 0.9112027467526786, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 372, train_loss = 0.9099580602087372, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 373, train_loss = 0.910127163555444, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 374, train_loss = 0.9085788143165701, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 375, train_loss = 0.9080448026470549, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 376, train_loss = 0.9055507425218821, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 377, train_loss = 0.9070630203932524, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 378, train_loss = 0.908493593957246, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 379, train_loss = 0.9081248541660898, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 380, train_loss = 0.9066358556337946, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 381, train_loss = 0.9089696146547794, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 382, train_loss = 0.9069947022944689, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 383, train_loss = 0.9060628625265963, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 384, train_loss = 0.9055479081980593, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 385, train_loss = 0.9063975767530792, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 386, train_loss = 0.9049407473466999, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 387, train_loss = 0.90471844188869, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 388, train_loss = 0.9037024645767815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 389, train_loss = 0.9056534754745371, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 390, train_loss = 0.9034991133958101, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 391, train_loss = 0.9032898228615522, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 392, train_loss = 0.9025265326090448, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 393, train_loss = 0.9039398624263413, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 394, train_loss = 0.9034871961921453, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 395, train_loss = 0.9017084632068872, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 396, train_loss = 0.9031026661396027, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 397, train_loss = 0.9013754092156887, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 398, train_loss = 0.9015441294759512, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 399, train_loss = 0.9003761615604162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 400, train_loss = 0.9020238698758476, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 401, train_loss = 0.9002631244547956, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 402, train_loss = 0.8998679127544165, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 403, train_loss = 0.897842221584142, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 404, train_loss = 0.8985111483671062, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 405, train_loss = 0.8981850910931826, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 406, train_loss = 0.8967804877720482, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 407, train_loss = 0.8973090847321146, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 408, train_loss = 0.9010171902664297, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 409, train_loss = 0.8984468045346148, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 410, train_loss = 0.8979277660437219, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 411, train_loss = 0.8964912680276029, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 412, train_loss = 0.8985902487002022, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 413, train_loss = 0.894900328170479, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 414, train_loss = 0.8947349606714852, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 415, train_loss = 0.8965051658451557, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 416, train_loss = 0.8955230719111569, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 417, train_loss = 0.8932581723965995, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 418, train_loss = 0.89536995254457, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 419, train_loss = 0.8939493124671571, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 420, train_loss = 0.8931106068193913, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 421, train_loss = 0.8946593875698454, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 422, train_loss = 0.8948610251136415, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 423, train_loss = 0.8925073581449396, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 424, train_loss = 0.8941308874636889, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 425, train_loss = 0.8925671937577135, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 426, train_loss = 0.8912368019409769, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 427, train_loss = 0.8922299065925472, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 428, train_loss = 0.8934145402163267, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 429, train_loss = 0.8924237334467762, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 430, train_loss = 0.8935156048573845, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 431, train_loss = 0.8922340994067781, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 432, train_loss = 0.892010161653161, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 433, train_loss = 0.8894848873205774, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 434, train_loss = 0.8906660297252529, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 435, train_loss = 0.8893983699381351, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 436, train_loss = 0.8897304118909233, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 437, train_loss = 0.8897983568422205, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 438, train_loss = 0.8902448806911707, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 439, train_loss = 0.8874612065665133, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 440, train_loss = 0.8874896646775596, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 441, train_loss = 0.8879267598204024, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 442, train_loss = 0.8873329789676063, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 443, train_loss = 0.8865257259458303, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 444, train_loss = 0.8890298170335882, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 445, train_loss = 0.8862872192003124, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 446, train_loss = 0.8865583104379766, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 447, train_loss = 0.8870610445737839, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 448, train_loss = 0.8902466222643852, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 449, train_loss = 0.8881470182277553, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 450, train_loss = 0.8866002218164795, train_acc = 0.9976711690731253\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 451, train_loss = 0.8872507431842678, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 452, train_loss = 0.884085601195693, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 453, train_loss = 0.8850561380386353, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 454, train_loss = 0.8852004172913439, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 455, train_loss = 0.8844159251711972, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 456, train_loss = 0.8845439646393061, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 457, train_loss = 0.8836935665458441, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 458, train_loss = 0.8873856688551314, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 459, train_loss = 0.8868065265305631, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 460, train_loss = 0.8850996978580952, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 461, train_loss = 0.88359285145998, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 462, train_loss = 0.8831344743557565, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 463, train_loss = 0.8828850612044334, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 464, train_loss = 0.8841130044311285, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 465, train_loss = 0.881372598309099, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 466, train_loss = 0.8820246414579742, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 467, train_loss = 0.8826020751148462, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 468, train_loss = 0.8839535179249651, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 469, train_loss = 0.8843228121586435, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 470, train_loss = 0.8821329958736897, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 471, train_loss = 0.8819782268255949, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 472, train_loss = 0.8796268155165308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 473, train_loss = 0.8808000671378977, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 474, train_loss = 0.8810535445809364, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 475, train_loss = 0.8788075465708971, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 476, train_loss = 0.8801881192885048, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 477, train_loss = 0.8801786831281788, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 478, train_loss = 0.881281382713496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 479, train_loss = 0.8793749560900324, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 480, train_loss = 0.879585599526763, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 481, train_loss = 0.8793934627137787, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 482, train_loss = 0.8816366692371957, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 483, train_loss = 0.8803730563558929, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 484, train_loss = 0.8808512942232483, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 485, train_loss = 0.8811259008944035, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 486, train_loss = 0.8799183908849955, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 487, train_loss = 0.8794881074391014, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 488, train_loss = 0.8803920528553135, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 489, train_loss = 0.8790300606451638, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 490, train_loss = 0.8775724451988935, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 491, train_loss = 0.8767387146763213, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 492, train_loss = 0.8802169455848343, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 493, train_loss = 0.8784390998371236, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 494, train_loss = 0.8779075108468533, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 495, train_loss = 0.8793414514511824, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 496, train_loss = 0.8779837271831639, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 497, train_loss = 0.8769341285042174, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 498, train_loss = 0.8787403982132673, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 499, train_loss = 0.8770495957396633, train_acc = 0.9977876106194691\n",
      "test Acc 0.9664804469273743:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████████████████████████████████████████████████▋                         | 20/30 [3:15:43<1:43:42, 622.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "21th- epoch: 0, train_loss = 389.62322855740786, train_acc = 0.8050768514205868\n",
      "test Acc 0.8635940409683427:\n",
      "21th- epoch: 1, train_loss = 84.39378953468986, train_acc = 0.9244294364229158\n",
      "test Acc 0.9385474860335196:\n",
      "21th- epoch: 2, train_loss = 52.03450193750905, train_acc = 0.9469026548672567\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 3, train_loss = 37.47450418025255, train_acc = 0.9562179785747554\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 4, train_loss = 28.086430037074024, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 5, train_loss = 21.947570732489112, train_acc = 0.9719375873311598\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 6, train_loss = 17.657824356429046, train_acc = 0.9755472752678156\n",
      "test Acc 0.9515828677839852:\n",
      "21th- epoch: 7, train_loss = 14.49029745781445, train_acc = 0.9791569632044713\n",
      "test Acc 0.952048417132216:\n",
      "21th- epoch: 8, train_loss = 12.097592604346573, train_acc = 0.9823008849557522\n",
      "test Acc 0.9529795158286778:\n",
      "21th- epoch: 9, train_loss = 10.243867594137555, train_acc = 0.984163949697252\n",
      "test Acc 0.9543761638733705:\n",
      "21th- epoch: 10, train_loss = 8.831749761477113, train_acc = 0.9862598975314392\n",
      "test Acc 0.9548417132216015:\n",
      "21th- epoch: 11, train_loss = 7.758456383540761, train_acc = 0.9884722869119702\n",
      "test Acc 0.9553072625698324:\n",
      "21th- epoch: 12, train_loss = 6.9192008869722486, train_acc = 0.989869585468095\n",
      "test Acc 0.9567039106145251:\n",
      "21th- epoch: 13, train_loss = 6.2253738371655345, train_acc = 0.9902189101071263\n",
      "test Acc 0.957635009310987:\n",
      "21th- epoch: 14, train_loss = 5.669939372339286, train_acc = 0.990801117838845\n",
      "test Acc 0.9581005586592178:\n",
      "21th- epoch: 15, train_loss = 5.16791456687497, train_acc = 0.9916162086632511\n",
      "test Acc 0.9585661080074488:\n",
      "21th- epoch: 16, train_loss = 4.759271090559196, train_acc = 0.992081974848626\n",
      "test Acc 0.957635009310987:\n",
      "21th- epoch: 17, train_loss = 4.389374938968103, train_acc = 0.9931299487657196\n",
      "test Acc 0.9581005586592178:\n",
      "21th- epoch: 18, train_loss = 4.053650521847885, train_acc = 0.9934792734047508\n",
      "test Acc 0.9581005586592178:\n",
      "21th- epoch: 19, train_loss = 3.768038426816929, train_acc = 0.9937121564974383\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 20, train_loss = 3.521099556062836, train_acc = 0.9940614811364695\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 21, train_loss = 3.297431313141715, train_acc = 0.9941779226828132\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 22, train_loss = 3.121520663262345, train_acc = 0.9944108057755007\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 23, train_loss = 2.972211269661784, train_acc = 0.9946436888681882\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 24, train_loss = 2.8421193032409064, train_acc = 0.9952258965999069\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 25, train_loss = 2.7378790105576627, train_acc = 0.9952258965999069\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 26, train_loss = 2.6531954538077116, train_acc = 0.9952258965999069\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 27, train_loss = 2.5747156093711965, train_acc = 0.9952258965999069\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 28, train_loss = 2.4989518650691025, train_acc = 0.9952258965999069\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 29, train_loss = 2.428138143091928, train_acc = 0.995575221238938\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 30, train_loss = 2.3545920907636173, train_acc = 0.9956916627852818\n",
      "test Acc 0.9608938547486033:\n",
      "21th- epoch: 31, train_loss = 2.2880411955120508, train_acc = 0.9958081043316255\n",
      "test Acc 0.9608938547486033:\n",
      "21th- epoch: 32, train_loss = 2.231325365282828, train_acc = 0.9961574289706567\n",
      "test Acc 0.9608938547486033:\n",
      "21th- epoch: 33, train_loss = 2.1751460222003516, train_acc = 0.9961574289706567\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 34, train_loss = 2.123134486057097, train_acc = 0.9962738705170004\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 35, train_loss = 2.077294047921896, train_acc = 0.996040987424313\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 36, train_loss = 2.0336578699352685, train_acc = 0.9961574289706567\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 37, train_loss = 1.9914859592390712, train_acc = 0.9962738705170004\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 38, train_loss = 1.9491885978204664, train_acc = 0.9962738705170004\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 39, train_loss = 1.9160112966783345, train_acc = 0.9963903120633442\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 40, train_loss = 1.8751727690396365, train_acc = 0.9962738705170004\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 41, train_loss = 1.8454178334213793, train_acc = 0.9962738705170004\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 42, train_loss = 1.8151511269097682, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 43, train_loss = 1.7966716087830719, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 44, train_loss = 1.7725630534405354, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 45, train_loss = 1.7562217684462667, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 46, train_loss = 1.7367909490130842, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 47, train_loss = 1.7227172530256212, train_acc = 0.996506753609688\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 48, train_loss = 1.7058870146574918, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 49, train_loss = 1.693588800728321, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 50, train_loss = 1.6823042786272708, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 51, train_loss = 1.6680710023792926, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 52, train_loss = 1.659324897453189, train_acc = 0.996506753609688\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 53, train_loss = 1.6460615160467569, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 54, train_loss = 1.6336980921623763, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 55, train_loss = 1.6189378959534224, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 56, train_loss = 1.6068705711513758, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 57, train_loss = 1.5953521796909627, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 58, train_loss = 1.5848261546343565, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 59, train_loss = 1.5782463513314724, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 60, train_loss = 1.5699866358190775, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 61, train_loss = 1.5625621868821327, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 62, train_loss = 1.5551940432342235, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 63, train_loss = 1.5470631377247628, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 64, train_loss = 1.5378310326486826, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 65, train_loss = 1.5331308574823197, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 66, train_loss = 1.5255739726126194, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 67, train_loss = 1.5191921312361956, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 68, train_loss = 1.51235918328166, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 69, train_loss = 1.503360809147125, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 70, train_loss = 1.4969694546016399, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 71, train_loss = 1.4911176338791847, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 72, train_loss = 1.4871734803018626, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 73, train_loss = 1.4839345241489355, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 74, train_loss = 1.4748560252191965, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 75, train_loss = 1.47089940434671, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 76, train_loss = 1.46267226463533, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 77, train_loss = 1.4581566533597652, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 78, train_loss = 1.454317161202198, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 79, train_loss = 1.4482045540062245, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 80, train_loss = 1.440561252326006, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 81, train_loss = 1.4341521660389844, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 82, train_loss = 1.4336678590625525, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 83, train_loss = 1.4271676428616047, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 84, train_loss = 1.4214323237538338, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 85, train_loss = 1.4168982977571432, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 86, train_loss = 1.4132054460642394, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 87, train_loss = 1.4068135047855321, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 88, train_loss = 1.4019588716328144, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 89, train_loss = 1.3961839204130229, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 90, train_loss = 1.3941922523081303, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 91, train_loss = 1.3876882189360913, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 92, train_loss = 1.3822548581811134, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 93, train_loss = 1.379827613622183, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 94, train_loss = 1.3718730323016644, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 95, train_loss = 1.3664241513761226, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 96, train_loss = 1.3661558224412147, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 97, train_loss = 1.3604470336285885, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 98, train_loss = 1.3519177430716809, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 99, train_loss = 1.3502827069314662, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 100, train_loss = 1.346480123072979, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 101, train_loss = 1.3435443484631833, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 102, train_loss = 1.338282003387576, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 103, train_loss = 1.3335401037184056, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 104, train_loss = 1.3297531735152006, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 105, train_loss = 1.3249031895247754, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 106, train_loss = 1.3219570368528366, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 107, train_loss = 1.3154536876827478, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 108, train_loss = 1.3125391826033592, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 109, train_loss = 1.3105605275777634, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 110, train_loss = 1.30546810105443, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 111, train_loss = 1.300851129606599, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 112, train_loss = 1.2964679480937775, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 113, train_loss = 1.2933088230493013, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 114, train_loss = 1.2896458798350068, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 115, train_loss = 1.2846305215207394, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 116, train_loss = 1.2799464662966784, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 117, train_loss = 1.2793390409497079, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 118, train_loss = 1.2724238689988852, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 119, train_loss = 1.2692220912576886, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 120, train_loss = 1.2647003307938576, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 121, train_loss = 1.2623042365012225, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 122, train_loss = 1.2581740102323238, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 123, train_loss = 1.2551956704555778, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 124, train_loss = 1.2482047379016876, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 125, train_loss = 1.2465556934475899, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 126, train_loss = 1.2421978767961264, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 127, train_loss = 1.2347663268446922, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 128, train_loss = 1.234471763804322, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 129, train_loss = 1.2311017246247502, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 130, train_loss = 1.226407506808755, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 131, train_loss = 1.2247213907539845, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 132, train_loss = 1.216264020651579, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 133, train_loss = 1.2156512060610112, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 134, train_loss = 1.2105187376291724, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 135, train_loss = 1.2101067515759496, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 136, train_loss = 1.2010960839688778, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 137, train_loss = 1.2018244241626235, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 138, train_loss = 1.1964320900442544, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 139, train_loss = 1.192473993942258, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 140, train_loss = 1.188394128024811, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 141, train_loss = 1.185356978327036, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 142, train_loss = 1.1811405296175508, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 143, train_loss = 1.1752469036728144, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 144, train_loss = 1.1761596662254306, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 145, train_loss = 1.1707580424845219, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 146, train_loss = 1.168186275914195, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 147, train_loss = 1.1619972226617392, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 148, train_loss = 1.1609849408268929, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 149, train_loss = 1.1566114549787017, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 150, train_loss = 1.1558595200331183, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 151, train_loss = 1.1486809353082208, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 152, train_loss = 1.1461596017034026, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 153, train_loss = 1.1445261823682813, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 154, train_loss = 1.1389176261873217, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 155, train_loss = 1.137832532331231, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 156, train_loss = 1.1351168366818456, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 157, train_loss = 1.130040716379881, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 158, train_loss = 1.1300236309616594, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 159, train_loss = 1.1256167478859425, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 160, train_loss = 1.1241067126393318, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 161, train_loss = 1.1191181130707264, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 162, train_loss = 1.1204689554870129, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 163, train_loss = 1.1162859151809243, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 164, train_loss = 1.1114949161856202, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 165, train_loss = 1.1098717388958903, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 166, train_loss = 1.1066771509795217, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 167, train_loss = 1.1035903083829908, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 168, train_loss = 1.1021178451628657, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 169, train_loss = 1.0970444716513157, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 170, train_loss = 1.0955068680195836, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 171, train_loss = 1.0931274332106113, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 172, train_loss = 1.0883387749345275, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 173, train_loss = 1.0870183644146891, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 174, train_loss = 1.089623335748911, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 175, train_loss = 1.082184846207383, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 176, train_loss = 1.0792270489037037, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 177, train_loss = 1.0814555759279756, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 178, train_loss = 1.0756277938635321, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 179, train_loss = 1.0726547166705132, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 180, train_loss = 1.0735112577676773, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 181, train_loss = 1.070668005690095, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 182, train_loss = 1.068120247378829, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 183, train_loss = 1.0660492070019245, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 184, train_loss = 1.0638692652137252, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 185, train_loss = 1.0608972224144964, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 186, train_loss = 1.0616119553596945, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 187, train_loss = 1.0578438006341457, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 188, train_loss = 1.0559335400612326, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 189, train_loss = 1.0552954537124606, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 190, train_loss = 1.0522369183599949, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 191, train_loss = 1.053359058991191, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 192, train_loss = 1.0494345488696126, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 193, train_loss = 1.0481563918292522, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 194, train_loss = 1.045571309819934, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 195, train_loss = 1.0454760069696931, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 196, train_loss = 1.0413662406353978, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 197, train_loss = 1.0425879930407973, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 198, train_loss = 1.038824832692626, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 199, train_loss = 1.0402195217757253, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 200, train_loss = 1.0380231787712546, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 201, train_loss = 1.0367290265858173, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 202, train_loss = 1.0336262732744217, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 203, train_loss = 1.0331712812185287, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 204, train_loss = 1.0308592356741428, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 205, train_loss = 1.032102861747262, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 206, train_loss = 1.0273952869029017, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 207, train_loss = 1.0257934592664242, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 208, train_loss = 1.0275563870818587, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 209, train_loss = 1.0245200395584106, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 210, train_loss = 1.0252098751516314, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 211, train_loss = 1.022458590567112, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 212, train_loss = 1.019627083092928, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 213, train_loss = 1.0208460030407878, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 214, train_loss = 1.0180439824907808, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 215, train_loss = 1.018434194222209, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 216, train_loss = 1.0155489668250084, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 217, train_loss = 1.0138405039906502, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 218, train_loss = 1.0148145171551732, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 219, train_loss = 1.011190759643796, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 220, train_loss = 1.012489378452301, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 221, train_loss = 1.008902025714633, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 222, train_loss = 1.0102706576435594, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 223, train_loss = 1.0085401087999344, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 224, train_loss = 1.0058355157525511, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 225, train_loss = 1.00729164108634, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 226, train_loss = 1.0076114709227113, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 227, train_loss = 1.0032042165548773, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 228, train_loss = 1.0017239240260096, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 229, train_loss = 1.001598622649908, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    read_path = 'D:virus/image/3gram_768/'\n",
    "    \n",
    "    temp = [[],[]]\n",
    "    \n",
    "    Loader = D.File_loader()\n",
    "    data_a, label_a = Loader.read_files(read_path, interp = False)\n",
    "    \n",
    "    idx = np.argsort(label_a)\n",
    "    \n",
    "    sorted_data = data_a[idx].reshape(10736, -1)\n",
    "    sorted_label = sorted(label_a)\n",
    "        \n",
    "    BATCH_SIZE = 64\n",
    "    TOTAL = 30\n",
    "    EPOCH = 500\n",
    "    NUM_CLASS = 9\n",
    "    LR = 0.0001\n",
    "    SEED = [s for s in range(TOTAL)]\n",
    "    INPUT_NODES = 768                   \n",
    "    \n",
    "    CUDA_N = 'cuda:1'\n",
    "    \n",
    "    # creating data indices for spliting\n",
    "    full_dataset = CustomDataset(sorted_data, sorted_label)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # spliting\n",
    "    torch.manual_seed(10)\n",
    "    train_dataset, test_dataset = data.random_split(full_dataset, [train_size, test_size])\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    loss_total = []\n",
    "    acc_total = []\n",
    "    pred_total = []\n",
    "    true_total = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(TOTAL)):\n",
    "        \n",
    "        device = torch.device(CUDA_N if torch.cuda.is_available() else 'cpu')\n",
    "        torch.manual_seed(SEED[i])\n",
    "        net = Net(INPUT_NODES, NUM_CLASS)           \n",
    "        net.to(device)\n",
    "        print(net)\n",
    "        \n",
    "        softmax = nn.Softmax()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=LR, momentum = 0.1)\n",
    "        \n",
    "        loss_list = []\n",
    "        train_acc_list = []\n",
    "        test_acc_list = []\n",
    "        \n",
    "        pred_temp = []\n",
    "        true_temp = []\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            net.train()\n",
    "            running_loss = 0\n",
    "            total = train_size\n",
    "            correct = 0 \n",
    "            \n",
    "            for step, image_and_label in enumerate(train_loader):\n",
    "                inputs, labels = image_and_label            \n",
    "                inputs, labels = inputs.type(torch.FloatTensor).to(device), labels.type(torch.LongTensor).to(device)\n",
    "                \n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, pred = torch.max(outputs, dim=1)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            train_acc = correct/total\n",
    "            loss_list.append(running_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "            print('{}th- epoch: {}, train_loss = {}, train_acc = {}'.format(i+1, epoch, running_loss, train_acc))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                correct = 0\n",
    "                total = test_size\n",
    "                pt, tt = [], []\n",
    "                \n",
    "                for step_t, image_and_label_t in enumerate(test_loader):\n",
    "                    inputs_t, labels_t = image_and_label_t            \n",
    "                    inputs_t, labels_t = inputs_t.type(torch.FloatTensor).to(device), labels_t.type(torch.LongTensor).to(device)\n",
    "                    \n",
    "                    outputs_t = net(inputs_t)\n",
    "                    outputs_t = softmax(outputs_t)\n",
    "                    \n",
    "                    # test accuracy\n",
    "                    _, pred_t = torch.max(outputs_t, dim = 1)\n",
    "                    \n",
    "                    pt.append(pred_t)\n",
    "                    tt.append(labels_t)\n",
    "                    \n",
    "                    correct += (pred_t == labels_t).sum().item()\n",
    "                    \n",
    "                pred_temp.append(torch.cat(pt))\n",
    "                true_temp.append(torch.cat(tt))\n",
    "                \n",
    "                test_acc = correct/total\n",
    "                test_acc_list.append(test_acc)\n",
    "                \n",
    "                print('test Acc {}:'.format(test_acc))\n",
    "                \n",
    "        best_result_index = np.argmax(np.array(test_acc_list))\n",
    "        loss_total.append(loss_list[best_result_index])\n",
    "        acc_total.append(test_acc_list[best_result_index])\n",
    "        pred_total.append(pred_temp[best_result_index].tolist())\n",
    "        true_total.append(true_temp[best_result_index].tolist())\n",
    "        \n",
    "    file_name = 'res/3gram_baseline'\n",
    "    torch.save(net.state_dict(), file_name +'.pth')\n",
    "    \n",
    "    loss_DF = pd.DataFrame(loss_total)\n",
    "    loss_DF.to_csv(file_name+\" loss.csv\")\n",
    "    \n",
    "    acc_DF = pd.DataFrame(acc_total)\n",
    "    acc_DF.to_csv(file_name +\" acc.csv\")\n",
    "    \n",
    "    pred_DF = pd.DataFrame(pred_total)\n",
    "    pred_DF.to_csv(file_name +\" pred.csv\")\n",
    "    \n",
    "    true_DF = pd.DataFrame(true_total)\n",
    "    true_DF.to_csv(file_name +\" true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
