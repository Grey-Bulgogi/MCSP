{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import utility.Data_loader as D\n",
    "from utility.Model import Base\n",
    "from utility.Custom import CustomDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 4gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                       | 0/10736 [00:00<?, ?it/s]\n",
      "  3%|██▍                                                                        | 347/10736 [00:00<00:03, 3444.89it/s]\n",
      "  7%|████▉                                                                      | 708/10736 [00:00<00:02, 3492.59it/s]\n",
      " 10%|███████▏                                                                  | 1045/10736 [00:00<00:02, 3445.12it/s]\n",
      " 13%|█████████▌                                                                | 1385/10736 [00:00<00:02, 3422.86it/s]\n",
      " 16%|███████████▌                                                              | 1678/10736 [00:00<00:02, 3252.61it/s]\n",
      " 19%|█████████████▊                                                            | 2007/10736 [00:00<00:02, 3254.67it/s]\n",
      " 21%|███████████████▊                                                          | 2294/10736 [00:00<00:02, 3068.03it/s]\n",
      " 25%|██████████████████▍                                                       | 2670/10736 [00:00<00:02, 3246.63it/s]\n",
      " 28%|████████████████████▉                                                     | 3040/10736 [00:00<00:02, 3268.43it/s]\n",
      " 32%|███████████████████████▍                                                  | 3408/10736 [00:01<00:02, 3373.04it/s]\n",
      " 35%|█████████████████████████▊                                                | 3739/10736 [00:01<00:02, 3334.41it/s]\n",
      " 38%|████████████████████████████                                              | 4069/10736 [00:01<00:02, 3323.69it/s]\n",
      " 41%|██████████████████████████████▎                                           | 4399/10736 [00:01<00:01, 3259.00it/s]\n",
      " 44%|████████████████████████████████▌                                         | 4724/10736 [00:01<00:01, 3167.31it/s]\n",
      " 47%|██████████████████████████████████▊                                       | 5057/10736 [00:01<00:01, 3207.64it/s]\n",
      " 50%|█████████████████████████████████████                                     | 5378/10736 [00:01<00:01, 3205.84it/s]\n",
      " 53%|███████████████████████████████████████▎                                  | 5699/10736 [00:01<00:01, 3186.54it/s]\n",
      " 56%|█████████████████████████████████████████▌                                | 6032/10736 [00:01<00:01, 3221.26it/s]\n",
      " 59%|███████████████████████████████████████████▊                              | 6355/10736 [00:01<00:01, 3214.25it/s]\n",
      " 62%|██████████████████████████████████████████████                            | 6677/10736 [00:02<00:01, 3180.51it/s]\n",
      " 65%|████████████████████████████████████████████████▏                         | 6996/10736 [00:02<00:01, 3124.28it/s]\n",
      " 69%|██████████████████████████████████████████████████▋                       | 7358/10736 [00:02<00:01, 3250.66it/s]\n",
      " 72%|█████████████████████████████████████████████████████▏                    | 7718/10736 [00:02<00:00, 3347.82it/s]\n",
      " 75%|███████████████████████████████████████████████████████▋                  | 8080/10736 [00:02<00:00, 3420.28it/s]\n",
      " 78%|██████████████████████████████████████████████████████████                | 8424/10736 [00:02<00:00, 3406.75it/s]\n",
      " 82%|████████████████████████████████████████████████████████████▍             | 8766/10736 [00:02<00:00, 3358.36it/s]\n",
      " 85%|██████████████████████████████████████████████████████████████▋           | 9103/10736 [00:02<00:00, 3353.23it/s]\n",
      " 88%|█████████████████████████████████████████████████████████████████         | 9445/10736 [00:02<00:00, 3365.70it/s]\n",
      " 91%|███████████████████████████████████████████████████████████████████▍      | 9786/10736 [00:02<00:00, 3369.36it/s]\n",
      " 94%|████████████████████████████████████████████████████████████████████▊    | 10124/10736 [00:03<00:00, 3322.83it/s]\n",
      " 97%|███████████████████████████████████████████████████████████████████████  | 10457/10736 [00:03<00:00, 3296.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 10736/10736 [00:03<00:00, 3281.91it/s]\n",
      "  0%|                                                                                          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "1th- epoch: 0, train_loss = 395.49940517544746, train_acc = 0.7999534233814625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DTools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:98: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.8161080074487895:\n",
      "1th- epoch: 1, train_loss = 100.7806388027966, train_acc = 0.9183744760130415\n",
      "test Acc 0.9250465549348231:\n",
      "1th- epoch: 2, train_loss = 61.89220432005823, train_acc = 0.9425943176525384\n",
      "test Acc 0.9329608938547486:\n",
      "1th- epoch: 3, train_loss = 43.40145802870393, train_acc = 0.9554028877503493\n",
      "test Acc 0.9418063314711359:\n",
      "1th- epoch: 4, train_loss = 32.34325800742954, train_acc = 0.9642524452724732\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 5, train_loss = 24.731218985281885, train_acc = 0.9703074056823474\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 6, train_loss = 19.387288666330278, train_acc = 0.9742664182580345\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 7, train_loss = 15.5129589792341, train_acc = 0.9783418723800652\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 8, train_loss = 12.522489679045975, train_acc = 0.9813693525850024\n",
      "test Acc 0.9515828677839852:\n",
      "1th- epoch: 9, train_loss = 10.179840727709234, train_acc = 0.9847461574289706\n",
      "test Acc 0.9511173184357542:\n",
      "1th- epoch: 10, train_loss = 8.528158027678728, train_acc = 0.9874243129948765\n",
      "test Acc 0.9539106145251397:\n",
      "1th- epoch: 11, train_loss = 7.216732673346996, train_acc = 0.9888216115510013\n",
      "test Acc 0.9529795158286778:\n",
      "1th- epoch: 12, train_loss = 6.230692010372877, train_acc = 0.990801117838845\n",
      "test Acc 0.9553072625698324:\n",
      "1th- epoch: 13, train_loss = 5.476725517772138, train_acc = 0.9917326502095948\n",
      "test Acc 0.9539106145251397:\n",
      "1th- epoch: 14, train_loss = 4.843554017599672, train_acc = 0.9925477410340009\n",
      "test Acc 0.9543761638733705:\n",
      "1th- epoch: 15, train_loss = 4.363101460039616, train_acc = 0.9925477410340009\n",
      "test Acc 0.9543761638733705:\n",
      "1th- epoch: 16, train_loss = 3.9164247438311577, train_acc = 0.9937121564974383\n",
      "test Acc 0.9557728119180633:\n",
      "1th- epoch: 17, train_loss = 3.5654040365479887, train_acc = 0.9941779226828132\n",
      "test Acc 0.9562383612662942:\n",
      "1th- epoch: 18, train_loss = 3.2434325516223907, train_acc = 0.9944108057755007\n",
      "test Acc 0.9557728119180633:\n",
      "1th- epoch: 19, train_loss = 2.9915998107753694, train_acc = 0.9947601304145319\n",
      "test Acc 0.9562383612662942:\n",
      "1th- epoch: 20, train_loss = 2.764820124953985, train_acc = 0.9951094550535631\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 21, train_loss = 2.5899718143045902, train_acc = 0.9952258965999069\n",
      "test Acc 0.957635009310987:\n",
      "1th- epoch: 22, train_loss = 2.428207316668704, train_acc = 0.9953423381462506\n",
      "test Acc 0.9581005586592178:\n",
      "1th- epoch: 23, train_loss = 2.2978296391665936, train_acc = 0.9956916627852818\n",
      "test Acc 0.957169459962756:\n",
      "1th- epoch: 24, train_loss = 2.1860533878207207, train_acc = 0.9959245458779693\n",
      "test Acc 0.9562383612662942:\n",
      "1th- epoch: 25, train_loss = 2.093840803951025, train_acc = 0.9959245458779693\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 26, train_loss = 2.0187367958715186, train_acc = 0.9961574289706567\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 27, train_loss = 1.9573373371968046, train_acc = 0.996040987424313\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 28, train_loss = 1.9061455950140953, train_acc = 0.996040987424313\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 29, train_loss = 1.8666582157602534, train_acc = 0.996040987424313\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 30, train_loss = 1.8304226770997047, train_acc = 0.9961574289706567\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 31, train_loss = 1.8010914115002379, train_acc = 0.9962738705170004\n",
      "test Acc 0.957169459962756:\n",
      "1th- epoch: 32, train_loss = 1.7769833778729662, train_acc = 0.9962738705170004\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 33, train_loss = 1.7520740950712934, train_acc = 0.9962738705170004\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 34, train_loss = 1.730883183539845, train_acc = 0.9962738705170004\n",
      "test Acc 0.9581005586592178:\n",
      "1th- epoch: 35, train_loss = 1.711728036403656, train_acc = 0.9962738705170004\n",
      "test Acc 0.957635009310987:\n",
      "1th- epoch: 36, train_loss = 1.6921320334076881, train_acc = 0.9962738705170004\n",
      "test Acc 0.9581005586592178:\n",
      "1th- epoch: 37, train_loss = 1.677704745263327, train_acc = 0.9962738705170004\n",
      "test Acc 0.9581005586592178:\n",
      "1th- epoch: 38, train_loss = 1.6576599106192589, train_acc = 0.9962738705170004\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 39, train_loss = 1.647044858604204, train_acc = 0.9962738705170004\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 40, train_loss = 1.6303680874407291, train_acc = 0.9962738705170004\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 41, train_loss = 1.6206986270844936, train_acc = 0.9962738705170004\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 42, train_loss = 1.60519215837121, train_acc = 0.9962738705170004\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 43, train_loss = 1.5938672323827632, train_acc = 0.9963903120633442\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 44, train_loss = 1.5809200803632848, train_acc = 0.9963903120633442\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 45, train_loss = 1.5701955904369242, train_acc = 0.9963903120633442\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 46, train_loss = 1.5573919887538068, train_acc = 0.9963903120633442\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 47, train_loss = 1.5462857273523696, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "1th- epoch: 48, train_loss = 1.5369888457353227, train_acc = 0.9963903120633442\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 49, train_loss = 1.5254513981635682, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "1th- epoch: 50, train_loss = 1.5168700118665583, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "1th- epoch: 51, train_loss = 1.5097403514082544, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "1th- epoch: 52, train_loss = 1.5006286327843554, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "1th- epoch: 53, train_loss = 1.4928206863696687, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "1th- epoch: 54, train_loss = 1.484146385162603, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "1th- epoch: 55, train_loss = 1.4751608148217201, train_acc = 0.9963903120633442\n",
      "test Acc 0.9608938547486033:\n",
      "1th- epoch: 56, train_loss = 1.4668267592787743, train_acc = 0.9963903120633442\n",
      "test Acc 0.9608938547486033:\n",
      "1th- epoch: 57, train_loss = 1.4609168295864947, train_acc = 0.9963903120633442\n",
      "test Acc 0.9613594040968343:\n",
      "1th- epoch: 58, train_loss = 1.452761062711943, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "1th- epoch: 59, train_loss = 1.444810437678825, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "1th- epoch: 60, train_loss = 1.439451324462425, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "1th- epoch: 61, train_loss = 1.4322397112846375, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "1th- epoch: 62, train_loss = 1.4278942893142812, train_acc = 0.996506753609688\n",
      "test Acc 0.9613594040968343:\n",
      "1th- epoch: 63, train_loss = 1.4209500352735631, train_acc = 0.996506753609688\n",
      "test Acc 0.9613594040968343:\n",
      "1th- epoch: 64, train_loss = 1.4158883281052113, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "1th- epoch: 65, train_loss = 1.4094874523580074, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "1th- epoch: 66, train_loss = 1.4033291637897491, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "1th- epoch: 67, train_loss = 1.3995797460374888, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "1th- epoch: 68, train_loss = 1.3932739483716432, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 69, train_loss = 1.3896625749766827, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "1th- epoch: 70, train_loss = 1.383514982968336, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 71, train_loss = 1.3792875334620476, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "1th- epoch: 72, train_loss = 1.373224521666998, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "1th- epoch: 73, train_loss = 1.3694902608694974, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "1th- epoch: 74, train_loss = 1.3641858100891113, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "1th- epoch: 75, train_loss = 1.3611901104450226, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 76, train_loss = 1.3558971422316972, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 77, train_loss = 1.3499765433371067, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 78, train_loss = 1.3484753208758775, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 79, train_loss = 1.3445228276250418, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 80, train_loss = 1.339118130505085, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 81, train_loss = 1.3350861681101378, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 82, train_loss = 1.3312532640993595, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 83, train_loss = 1.3298435074684676, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 84, train_loss = 1.3255635934474412, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 85, train_loss = 1.321427938848501, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "1th- epoch: 86, train_loss = 1.3172927958366927, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "1th- epoch: 87, train_loss = 1.31575863683247, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "1th- epoch: 88, train_loss = 1.3116882083413657, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "1th- epoch: 89, train_loss = 1.3094726651906967, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "1th- epoch: 90, train_loss = 1.306383983552223, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "1th- epoch: 91, train_loss = 1.3023794628679752, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "1th- epoch: 92, train_loss = 1.3011327398417052, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 93, train_loss = 1.2972283984126989, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "1th- epoch: 94, train_loss = 1.2955608616175596, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 95, train_loss = 1.2917616603372153, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 96, train_loss = 1.2890787050127983, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 97, train_loss = 1.2876394378545228, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 98, train_loss = 1.2838271036744118, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 99, train_loss = 1.281492176145548, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 100, train_loss = 1.2790088330802973, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 101, train_loss = 1.2769540771842003, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 102, train_loss = 1.2739146053791046, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 103, train_loss = 1.2723844138381537, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 104, train_loss = 1.2689963690936565, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 105, train_loss = 1.2702572879643412, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 106, train_loss = 1.2727666571736336, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 107, train_loss = 1.2706953808665276, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 108, train_loss = 1.2690590408892604, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 109, train_loss = 1.266491339847562, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 110, train_loss = 1.264040629073861, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 111, train_loss = 1.2623803851456614, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 112, train_loss = 1.2602572614996461, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 113, train_loss = 1.2580659339873819, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 114, train_loss = 1.2560982443392277, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 115, train_loss = 1.2544745082705049, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 116, train_loss = 1.2521460627467604, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 117, train_loss = 1.2505465559661388, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 118, train_loss = 1.2486136890947819, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 119, train_loss = 1.2465900791139575, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 120, train_loss = 1.2451630644500256, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 121, train_loss = 1.2432766507117776, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 122, train_loss = 1.241770210370305, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 123, train_loss = 1.2397574931383133, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 124, train_loss = 1.2383170550019713, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 125, train_loss = 1.2368748721928569, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 126, train_loss = 1.2350060778408078, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 127, train_loss = 1.2326924080698518, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 128, train_loss = 1.231784260526183, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 129, train_loss = 1.2302739496080903, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 130, train_loss = 1.228202823549509, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 131, train_loss = 1.2272724956274033, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 132, train_loss = 1.2249463548214408, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 133, train_loss = 1.224072760596755, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 134, train_loss = 1.222245963916066, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 135, train_loss = 1.2212225807161303, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 136, train_loss = 1.2198631800711155, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 137, train_loss = 1.217620940253255, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 138, train_loss = 1.216448272272828, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 139, train_loss = 1.2149012585432502, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 140, train_loss = 1.2133495584130287, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 141, train_loss = 1.211958301559207, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 142, train_loss = 1.2119450916798087, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 143, train_loss = 1.2096147648990154, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 144, train_loss = 1.207800392061472, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 145, train_loss = 1.2058771140873432, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 146, train_loss = 1.205167967826128, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 147, train_loss = 1.2033931997866603, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 148, train_loss = 1.2015787499694852, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 149, train_loss = 1.2007872449903516, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 150, train_loss = 1.199104522660491, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 151, train_loss = 1.1981646766216727, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 152, train_loss = 1.1970031013042899, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 153, train_loss = 1.1950860284268856, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 154, train_loss = 1.194489449262619, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 155, train_loss = 1.1933791252522497, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 156, train_loss = 1.192800659686327, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 157, train_loss = 1.1913233622908592, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 158, train_loss = 1.1902958638966084, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 159, train_loss = 1.1882851434202166, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 160, train_loss = 1.1872650682926178, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 161, train_loss = 1.1862898841500282, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 162, train_loss = 1.1853985202760668, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 163, train_loss = 1.1842166421265574, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 164, train_loss = 1.1830101944506168, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 165, train_loss = 1.1811199970543385, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 166, train_loss = 1.180257345236896, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 167, train_loss = 1.1784040232523694, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 168, train_loss = 1.1780082037075772, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 169, train_loss = 1.1771004659458413, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 170, train_loss = 1.1756614024416194, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 171, train_loss = 1.1741153299808502, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 172, train_loss = 1.172673358269094, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 173, train_loss = 1.1715958826243877, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 174, train_loss = 1.1715975503102527, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 175, train_loss = 1.1689802445471287, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 176, train_loss = 1.1677659725173726, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 177, train_loss = 1.166379223264812, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 178, train_loss = 1.166509964816214, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 179, train_loss = 1.164622224867344, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 180, train_loss = 1.1629124159589992, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 181, train_loss = 1.1609540519639268, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 182, train_loss = 1.1621635059491382, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 183, train_loss = 1.1595084766522632, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 184, train_loss = 1.1580109360293136, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 185, train_loss = 1.1587763751522289, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 186, train_loss = 1.1557771836742177, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 187, train_loss = 1.1553042866289616, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 188, train_loss = 1.154087144881487, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 189, train_loss = 1.1533518135547638, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 190, train_loss = 1.1520855041817413, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 191, train_loss = 1.1505646221339703, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 192, train_loss = 1.1488631702959538, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 193, train_loss = 1.1500039733946323, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 194, train_loss = 1.1469377167522907, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 195, train_loss = 1.1465971109792008, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 196, train_loss = 1.1463306123987422, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 197, train_loss = 1.1459906660020351, train_acc = 0.9970889613414066\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 198, train_loss = 1.143814954906702, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 199, train_loss = 1.1405010595917702, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 200, train_loss = 1.1414546221494675, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 201, train_loss = 1.1418504429384484, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 202, train_loss = 1.1408867773934617, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 203, train_loss = 1.1405242110267864, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 204, train_loss = 1.138548232614994, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 205, train_loss = 1.1381464550868259, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 206, train_loss = 1.1359727581366315, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 207, train_loss = 1.1350512926801457, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 208, train_loss = 1.1337279801591649, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 209, train_loss = 1.1333160834983573, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 210, train_loss = 1.1340467110276222, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 211, train_loss = 1.1329115169719444, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 212, train_loss = 1.1309832943006768, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 213, train_loss = 1.1311066038906574, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 214, train_loss = 1.1288584967478528, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 215, train_loss = 1.1276702756658779, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 216, train_loss = 1.1269373024479137, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 217, train_loss = 1.12626390656078, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 218, train_loss = 1.1263077085241093, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 219, train_loss = 1.1259293965995312, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 220, train_loss = 1.1242313931361423, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 221, train_loss = 1.1215299355462776, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 222, train_loss = 1.1217171599491849, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 223, train_loss = 1.1205668908878579, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 224, train_loss = 1.120350324861647, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 225, train_loss = 1.1200668662786484, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 226, train_loss = 1.1190837708636536, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 227, train_loss = 1.1173446339889779, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 228, train_loss = 1.1157927016392932, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 229, train_loss = 1.1153013134971843, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 230, train_loss = 1.1148677940145717, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 231, train_loss = 1.1139923011287465, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 232, train_loss = 1.1136796548962593, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 233, train_loss = 1.1132936092690215, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 234, train_loss = 1.1128865467981086, train_acc = 0.9972054028877504\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 235, train_loss = 1.1117226170972572, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 236, train_loss = 1.1098262791856541, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 237, train_loss = 1.108926693596004, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 238, train_loss = 1.108179233968258, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 239, train_loss = 1.107463549822569, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 240, train_loss = 1.1064850737675442, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 241, train_loss = 1.1078152010813938, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 242, train_loss = 1.1062099623159156, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 243, train_loss = 1.1051652704700246, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 244, train_loss = 1.103484332561493, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 245, train_loss = 1.1030259728431702, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 246, train_loss = 1.1018866871818318, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 247, train_loss = 1.101703697197081, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 248, train_loss = 1.1004196343346848, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 249, train_loss = 1.099741247795464, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 250, train_loss = 1.100046540297626, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 251, train_loss = 1.0997325691059814, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 252, train_loss = 1.0985682023092522, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 253, train_loss = 1.0977631732821465, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 254, train_loss = 1.0957957059144974, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 255, train_loss = 1.0956251906827674, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 256, train_loss = 1.094460309795977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 257, train_loss = 1.0934352800250053, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 258, train_loss = 1.0933127266689553, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 259, train_loss = 1.0932040525003686, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 260, train_loss = 1.0916802237406955, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 261, train_loss = 1.0914485206230893, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 262, train_loss = 1.089799601584673, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 263, train_loss = 1.089448545128107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 264, train_loss = 1.0891715014950023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 265, train_loss = 1.0895892716944218, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 266, train_loss = 1.089002799242735, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 267, train_loss = 1.0870000198483467, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 268, train_loss = 1.0871272012591362, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 269, train_loss = 1.0850135075525031, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 270, train_loss = 1.0846697812303319, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 271, train_loss = 1.0840803633109317, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 272, train_loss = 1.0843544813469634, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 273, train_loss = 1.0840341498478665, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 274, train_loss = 1.0834060721099377, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 275, train_loss = 1.083784860871674, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 276, train_loss = 1.0823150835931301, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 277, train_loss = 1.0806793632582412, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 278, train_loss = 1.0806813004091964, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 279, train_loss = 1.0790336951613426, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 280, train_loss = 1.0792675813063397, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 281, train_loss = 1.079143401235342, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 282, train_loss = 1.0772830918431282, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 283, train_loss = 1.0774059779942036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 284, train_loss = 1.077361678086163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 285, train_loss = 1.0758442891165032, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 286, train_loss = 1.07497838139534, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 287, train_loss = 1.0753758735954762, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 288, train_loss = 1.074075253061892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 289, train_loss = 1.0746975702568307, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 290, train_loss = 1.0748438090085983, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 291, train_loss = 1.0737499060705886, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 292, train_loss = 1.0717661852613674, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 293, train_loss = 1.0727511433287873, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 294, train_loss = 1.0709987456575618, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 295, train_loss = 1.069945630930306, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 296, train_loss = 1.0695689966305508, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 297, train_loss = 1.069392554461956, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 298, train_loss = 1.069236924253346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 299, train_loss = 1.0690651051700115, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 300, train_loss = 1.0676739104092121, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 301, train_loss = 1.0669869929552078, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 302, train_loss = 1.0666907615959644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 303, train_loss = 1.0657708669677959, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 304, train_loss = 1.0661161753014312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 305, train_loss = 1.0646252880469547, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 306, train_loss = 1.0647099614143372, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 307, train_loss = 1.063782338052988, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 308, train_loss = 1.0654100862666382, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 309, train_loss = 1.0640365829094662, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 310, train_loss = 1.0638817908838973, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 311, train_loss = 1.0632480718195438, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 312, train_loss = 1.0624054968357086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 313, train_loss = 1.0625630815848126, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 314, train_loss = 1.0620099268853664, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 315, train_loss = 1.0612354489639984, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 316, train_loss = 1.0607712753117085, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 317, train_loss = 1.059670860566257, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 318, train_loss = 1.0597932140008197, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 319, train_loss = 1.0587031207978725, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 320, train_loss = 1.0587783828377724, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 321, train_loss = 1.0582219511270523, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 322, train_loss = 1.0581748522818089, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 323, train_loss = 1.056453616671206, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 324, train_loss = 1.0556030732914223, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 325, train_loss = 1.0565877531989827, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 326, train_loss = 1.056093300379871, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 327, train_loss = 1.0559796529487357, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 328, train_loss = 1.0553427711129189, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 329, train_loss = 1.05441828941548, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 330, train_loss = 1.0539498664438725, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 331, train_loss = 1.0538343923763023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 332, train_loss = 1.053459888942598, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 333, train_loss = 1.0529280664995895, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 334, train_loss = 1.0529560546056018, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 335, train_loss = 1.0521937496960163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 336, train_loss = 1.0510764780119644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 337, train_loss = 1.050700195133686, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 338, train_loss = 1.0510501600801945, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 339, train_loss = 1.050007106117846, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 340, train_loss = 1.0498352696522488, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 341, train_loss = 1.0490353802815662, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 342, train_loss = 1.0489085453227744, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 343, train_loss = 1.0493367190138088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 344, train_loss = 1.0477561081424938, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 345, train_loss = 1.0480665688701265, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 346, train_loss = 1.0471119582653046, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 347, train_loss = 1.0467089526355267, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 348, train_loss = 1.0465718122832186, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 349, train_loss = 1.0461682615168684, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 350, train_loss = 1.0455772913992405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 351, train_loss = 1.045022933434666, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 352, train_loss = 1.0450322143733501, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 353, train_loss = 1.0441570567600138, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 354, train_loss = 1.0440009074918635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 355, train_loss = 1.043330813448847, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 356, train_loss = 1.0430930728725798, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 357, train_loss = 1.0428167867175944, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 358, train_loss = 1.0424650249369734, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 359, train_loss = 1.041636607300461, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 360, train_loss = 1.0404619748405821, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 361, train_loss = 1.0407412946224213, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 362, train_loss = 1.0401259412356012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 363, train_loss = 1.0398450046777725, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 364, train_loss = 1.0395550442226522, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 365, train_loss = 1.0386088192462921, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 366, train_loss = 1.0375527143478394, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 367, train_loss = 1.0386208755262487, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 368, train_loss = 1.0383665462322824, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 369, train_loss = 1.0379479192197323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 370, train_loss = 1.0378079998008616, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 371, train_loss = 1.0371172837913036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 372, train_loss = 1.0355753911026113, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 373, train_loss = 1.0361497178673744, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 374, train_loss = 1.035980001091957, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 375, train_loss = 1.0354905078820593, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 376, train_loss = 1.0350028301290877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 377, train_loss = 1.0343461632728577, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 378, train_loss = 1.0328761786222458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 379, train_loss = 1.0342352936677344, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 380, train_loss = 1.0326744963713281, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 381, train_loss = 1.0333715341985226, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 382, train_loss = 1.0327233051248186, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 383, train_loss = 1.032484179984749, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 384, train_loss = 1.0316662987061136, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 385, train_loss = 1.030832057196676, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 386, train_loss = 1.0315518925599463, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 387, train_loss = 1.0290875894315832, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 388, train_loss = 1.0300198992081278, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 389, train_loss = 1.0302706435322762, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 390, train_loss = 1.0285683547444933, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 391, train_loss = 1.0298020405061834, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 392, train_loss = 1.028954458732187, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 393, train_loss = 1.0274816788733006, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 394, train_loss = 1.0283589884638786, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 395, train_loss = 1.0265900529921055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 396, train_loss = 1.0273533128201962, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 397, train_loss = 1.0268894682340033, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 398, train_loss = 1.026053298264742, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 399, train_loss = 1.0260899476706982, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 400, train_loss = 1.0249775101729028, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 401, train_loss = 1.0255160381384485, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 402, train_loss = 1.025593967486202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 403, train_loss = 1.0236380298920267, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 404, train_loss = 1.0243134746961005, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 405, train_loss = 1.0240122539289587, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 406, train_loss = 1.0236794749907858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 407, train_loss = 1.0226062747351534, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 408, train_loss = 1.0220016265921004, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 409, train_loss = 1.0227930111177557, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 410, train_loss = 1.0223107996098406, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 411, train_loss = 1.022153918940603, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 412, train_loss = 1.0203883027024858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 413, train_loss = 1.0213794360570319, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 414, train_loss = 1.0209143832325935, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 415, train_loss = 1.0194860945157416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 416, train_loss = 1.019973248243332, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 417, train_loss = 1.0187715751417272, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 418, train_loss = 1.0184548807628744, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 419, train_loss = 1.0198591810949438, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 420, train_loss = 1.0173652544617653, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 421, train_loss = 1.0168736266605265, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 422, train_loss = 1.0178997442126274, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 423, train_loss = 1.017166422057926, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 424, train_loss = 1.017576340585947, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 425, train_loss = 1.017746951431036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 426, train_loss = 1.015766266733408, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 427, train_loss = 1.0166100524365902, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 428, train_loss = 1.0153047728053934, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 429, train_loss = 1.016311643023073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 430, train_loss = 1.015815990667761, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 431, train_loss = 1.0144257247447968, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 432, train_loss = 1.0152512192726135, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 433, train_loss = 1.0136516826860316, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 434, train_loss = 1.0149038483687036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 435, train_loss = 1.0142725072801113, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 436, train_loss = 1.012622658163309, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 437, train_loss = 1.0119493305683136, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 438, train_loss = 1.0128911597021215, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 439, train_loss = 1.0130937074609392, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 440, train_loss = 1.011942016582907, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 441, train_loss = 1.0109389958270185, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 442, train_loss = 1.0108673299364455, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 443, train_loss = 1.0113804141692526, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 444, train_loss = 1.009653590619564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 445, train_loss = 1.009786482900381, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 446, train_loss = 1.0095402213446505, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 447, train_loss = 1.0099401958286762, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 448, train_loss = 1.0087752516083128, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 449, train_loss = 1.0082664924375422, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 450, train_loss = 1.0082477020732767, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 451, train_loss = 1.0089908950030804, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 452, train_loss = 1.0073394626379013, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 453, train_loss = 1.0082710112146742, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 454, train_loss = 1.0072055645287037, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 455, train_loss = 1.0068475070111162, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 456, train_loss = 1.0074594542384148, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 457, train_loss = 1.0063276402652264, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 458, train_loss = 1.0069905606396787, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 459, train_loss = 1.005221941817581, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 460, train_loss = 1.0052610263228416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 461, train_loss = 1.0060907217375643, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 462, train_loss = 1.0061517457179434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 463, train_loss = 1.0042671784758568, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 464, train_loss = 1.0038569383323193, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 465, train_loss = 1.0046151230744726, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 466, train_loss = 1.0044348215051286, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 467, train_loss = 1.0030210291333788, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 468, train_loss = 1.0027484484016895, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 469, train_loss = 1.0035613241307146, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 470, train_loss = 1.002074707299471, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 471, train_loss = 1.0021752417087555, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 472, train_loss = 1.0014485133178823, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 473, train_loss = 1.0020150554664724, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 474, train_loss = 1.0008755984417803, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 475, train_loss = 1.0004729144275188, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 476, train_loss = 1.0019629846028693, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 477, train_loss = 1.001558185864269, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 478, train_loss = 0.9998175787441141, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 479, train_loss = 0.9995015561580658, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 480, train_loss = 1.0001231506466866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 481, train_loss = 0.9990377935282595, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 482, train_loss = 0.998686591785372, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 483, train_loss = 0.9995916448533535, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 484, train_loss = 0.9992513296492689, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 485, train_loss = 0.9978190573565371, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 486, train_loss = 0.9992857513316267, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 487, train_loss = 0.9974355424456007, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 488, train_loss = 0.997993237029732, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 489, train_loss = 0.9977031213529699, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 490, train_loss = 0.9960806121416681, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 491, train_loss = 0.9974292765073187, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 492, train_loss = 0.9957681757696264, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 493, train_loss = 0.9969787523150444, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 494, train_loss = 0.9966144561767578, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 495, train_loss = 0.9948899348564737, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 496, train_loss = 0.9956555292010307, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 497, train_loss = 0.9959022241346247, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 498, train_loss = 0.9940876277796633, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 499, train_loss = 0.9938069842755795, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|██▋                                                                            | 1/30 [09:05<4:23:45, 545.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "2th- epoch: 0, train_loss = 389.7669277135283, train_acc = 0.7914531904983698\n",
      "test Acc 0.9050279329608939:\n",
      "2th- epoch: 1, train_loss = 97.51683250069618, train_acc = 0.922566371681416\n",
      "test Acc 0.9203910614525139:\n",
      "2th- epoch: 2, train_loss = 60.59521718199176, train_acc = 0.944108057755007\n",
      "test Acc 0.9301675977653632:\n",
      "2th- epoch: 3, train_loss = 42.7439153182022, train_acc = 0.9554028877503493\n",
      "test Acc 0.936219739292365:\n",
      "2th- epoch: 4, train_loss = 30.918806709349155, train_acc = 0.9646017699115044\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 5, train_loss = 23.301501466579793, train_acc = 0.9724033535165347\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 6, train_loss = 18.415302913323103, train_acc = 0.9781089892873778\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 7, train_loss = 14.834573583364545, train_acc = 0.9803213786679087\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 8, train_loss = 12.137092708304408, train_acc = 0.9829995342338146\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 9, train_loss = 10.042428048633155, train_acc = 0.9856776897997206\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 10, train_loss = 8.461278358779964, train_acc = 0.9880065207265952\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 11, train_loss = 7.2065512711851625, train_acc = 0.9889380530973452\n",
      "test Acc 0.9543761638733705:\n",
      "2th- epoch: 12, train_loss = 6.141753928124672, train_acc = 0.9901024685607824\n",
      "test Acc 0.9543761638733705:\n",
      "2th- epoch: 13, train_loss = 5.2792318699357565, train_acc = 0.9913833255705635\n",
      "test Acc 0.9553072625698324:\n",
      "2th- epoch: 14, train_loss = 4.587135234847665, train_acc = 0.9925477410340009\n",
      "test Acc 0.9548417132216015:\n",
      "2th- epoch: 15, train_loss = 4.085357026808197, train_acc = 0.9931299487657196\n",
      "test Acc 0.9539106145251397:\n",
      "2th- epoch: 16, train_loss = 3.704556349053746, train_acc = 0.9934792734047508\n",
      "test Acc 0.9543761638733705:\n",
      "2th- epoch: 17, train_loss = 3.410961629502708, train_acc = 0.9940614811364695\n",
      "test Acc 0.9534450651769087:\n",
      "2th- epoch: 18, train_loss = 3.174855101533467, train_acc = 0.9941779226828132\n",
      "test Acc 0.9548417132216015:\n",
      "2th- epoch: 19, train_loss = 2.979611110247788, train_acc = 0.994294364229157\n",
      "test Acc 0.9543761638733705:\n",
      "2th- epoch: 20, train_loss = 2.8187974941247376, train_acc = 0.9944108057755007\n",
      "test Acc 0.9539106145251397:\n",
      "2th- epoch: 21, train_loss = 2.676483592178556, train_acc = 0.9946436888681882\n",
      "test Acc 0.9543761638733705:\n",
      "2th- epoch: 22, train_loss = 2.545172813042882, train_acc = 0.9949930135072194\n",
      "test Acc 0.9548417132216015:\n",
      "2th- epoch: 23, train_loss = 2.4307479009294184, train_acc = 0.9951094550535631\n",
      "test Acc 0.9553072625698324:\n",
      "2th- epoch: 24, train_loss = 2.3228118801489472, train_acc = 0.9952258965999069\n",
      "test Acc 0.9567039106145251:\n",
      "2th- epoch: 25, train_loss = 2.2285101475863485, train_acc = 0.9952258965999069\n",
      "test Acc 0.9557728119180633:\n",
      "2th- epoch: 26, train_loss = 2.1494951064960333, train_acc = 0.995575221238938\n",
      "test Acc 0.9562383612662942:\n",
      "2th- epoch: 27, train_loss = 2.08168042699981, train_acc = 0.9956916627852818\n",
      "test Acc 0.9567039106145251:\n",
      "2th- epoch: 28, train_loss = 2.0091487880126806, train_acc = 0.995575221238938\n",
      "test Acc 0.957169459962756:\n",
      "2th- epoch: 29, train_loss = 1.9396200530900387, train_acc = 0.995575221238938\n",
      "test Acc 0.957635009310987:\n",
      "2th- epoch: 30, train_loss = 1.8872507602645783, train_acc = 0.995575221238938\n",
      "test Acc 0.957635009310987:\n",
      "2th- epoch: 31, train_loss = 1.8441929112450453, train_acc = 0.9958081043316255\n",
      "test Acc 0.9581005586592178:\n",
      "2th- epoch: 32, train_loss = 1.7990984718053369, train_acc = 0.9958081043316255\n",
      "test Acc 0.9594972067039106:\n",
      "2th- epoch: 33, train_loss = 1.7652381124644307, train_acc = 0.9959245458779693\n",
      "test Acc 0.9594972067039106:\n",
      "2th- epoch: 34, train_loss = 1.733696776755096, train_acc = 0.9959245458779693\n",
      "test Acc 0.9590316573556797:\n",
      "2th- epoch: 35, train_loss = 1.707064736947359, train_acc = 0.9959245458779693\n",
      "test Acc 0.9599627560521415:\n",
      "2th- epoch: 36, train_loss = 1.686487996019423, train_acc = 0.9959245458779693\n",
      "test Acc 0.9594972067039106:\n",
      "2th- epoch: 37, train_loss = 1.6694623613730073, train_acc = 0.9959245458779693\n",
      "test Acc 0.9594972067039106:\n",
      "2th- epoch: 38, train_loss = 1.645561097189784, train_acc = 0.996040987424313\n",
      "test Acc 0.9594972067039106:\n",
      "2th- epoch: 39, train_loss = 1.6354008503258228, train_acc = 0.996040987424313\n",
      "test Acc 0.9594972067039106:\n",
      "2th- epoch: 40, train_loss = 1.6203959404156194, train_acc = 0.996040987424313\n",
      "test Acc 0.9599627560521415:\n",
      "2th- epoch: 41, train_loss = 1.6067937426269054, train_acc = 0.996040987424313\n",
      "test Acc 0.9599627560521415:\n",
      "2th- epoch: 42, train_loss = 1.5972611134275212, train_acc = 0.996040987424313\n",
      "test Acc 0.9604283054003724:\n",
      "2th- epoch: 43, train_loss = 1.585307814180851, train_acc = 0.996040987424313\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 44, train_loss = 1.5745500897392049, train_acc = 0.996040987424313\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 45, train_loss = 1.5651759058237076, train_acc = 0.996040987424313\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 46, train_loss = 1.556450929492712, train_acc = 0.996040987424313\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 47, train_loss = 1.5491872349084588, train_acc = 0.996040987424313\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 48, train_loss = 1.5385023672133684, train_acc = 0.996040987424313\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 49, train_loss = 1.5312846923916368, train_acc = 0.996040987424313\n",
      "test Acc 0.9613594040968343:\n",
      "2th- epoch: 50, train_loss = 1.5188497137278318, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 51, train_loss = 1.5149284743965836, train_acc = 0.9961574289706567\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 52, train_loss = 1.5098727395088645, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 53, train_loss = 1.4996107264159946, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 54, train_loss = 1.4933947014360456, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 55, train_loss = 1.4854314712138148, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 56, train_loss = 1.48130318026233, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 57, train_loss = 1.4739935733377934, train_acc = 0.9963903120633442\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 58, train_loss = 1.468812469393015, train_acc = 0.9963903120633442\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 59, train_loss = 1.4609430047421483, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 60, train_loss = 1.4543650417326717, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 61, train_loss = 1.4492745511233807, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 62, train_loss = 1.4450600643904181, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 63, train_loss = 1.4389755055308342, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 64, train_loss = 1.4309406913816929, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 65, train_loss = 1.428199926391244, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 66, train_loss = 1.423134193450096, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 67, train_loss = 1.4188045604823856, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 68, train_loss = 1.4139309382735519, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 69, train_loss = 1.4094325341284275, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 70, train_loss = 1.40505035717797, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 71, train_loss = 1.4000568445771933, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 72, train_loss = 1.3963866190315457, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 73, train_loss = 1.392104612037656, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 74, train_loss = 1.3888257990329294, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 75, train_loss = 1.3836102814675542, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 76, train_loss = 1.3806673008948565, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 77, train_loss = 1.3752497738896636, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 78, train_loss = 1.3723087844700785, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 79, train_loss = 1.3683719386608573, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 80, train_loss = 1.3655228496791096, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 81, train_loss = 1.361669338613865, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 82, train_loss = 1.3585662307887105, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 83, train_loss = 1.352604919418809, train_acc = 0.996506753609688\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 84, train_loss = 1.3510451304464368, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 85, train_loss = 1.3481798848806648, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 86, train_loss = 1.3450794884265633, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 87, train_loss = 1.3424345422536135, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 88, train_loss = 1.3375845663249493, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 89, train_loss = 1.3342533533723326, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 90, train_loss = 1.3296059711574344, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 91, train_loss = 1.3285752882511588, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 92, train_loss = 1.3247974974365206, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 93, train_loss = 1.3230634170322446, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 94, train_loss = 1.319362655907753, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 95, train_loss = 1.3148641853331355, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 96, train_loss = 1.314232051372528, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 97, train_loss = 1.3122876553534297, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 98, train_loss = 1.3096635316760512, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 99, train_loss = 1.304736724749091, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 100, train_loss = 1.300472628325224, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 101, train_loss = 1.3003241034894018, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 102, train_loss = 1.2982766187487869, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 103, train_loss = 1.29505015288305, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 104, train_loss = 1.2918075025081635, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 105, train_loss = 1.2879395162017317, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 106, train_loss = 1.2863539370446233, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 107, train_loss = 1.2849371265619993, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 108, train_loss = 1.2820633761584759, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 109, train_loss = 1.2781040028930875, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 110, train_loss = 1.2779533409775468, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 111, train_loss = 1.274667015299201, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 112, train_loss = 1.2699301186949015, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 113, train_loss = 1.2728045831099735, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 114, train_loss = 1.2659972036854015, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 115, train_loss = 1.2655578733756556, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 116, train_loss = 1.25974280139053, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 117, train_loss = 1.2604748141020536, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 118, train_loss = 1.2598597488031373, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 119, train_loss = 1.254934936761856, train_acc = 0.9962738705170004\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 120, train_loss = 1.2543028381987824, train_acc = 0.9962738705170004\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 121, train_loss = 1.2517165367826237, train_acc = 0.9962738705170004\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 122, train_loss = 1.2489793909116997, train_acc = 0.9962738705170004\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 123, train_loss = 1.249421248830913, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 124, train_loss = 1.24709554141009, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 125, train_loss = 1.2428163724616752, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 126, train_loss = 1.2451043861583457, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 127, train_loss = 1.2418641336262226, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 128, train_loss = 1.2374775521457195, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 129, train_loss = 1.238758676998259, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 130, train_loss = 1.2346832752227783, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 131, train_loss = 1.2312085678204312, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 132, train_loss = 1.232231117784977, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 133, train_loss = 1.2288455342277302, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 134, train_loss = 1.2257753772064461, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 135, train_loss = 1.226372183613421, train_acc = 0.9963903120633442\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 136, train_loss = 1.2231870330870152, train_acc = 0.996506753609688\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 137, train_loss = 1.223010523863195, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 138, train_loss = 1.2199869317337289, train_acc = 0.996506753609688\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 139, train_loss = 1.2210631097332225, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 140, train_loss = 1.2168375216424465, train_acc = 0.996506753609688\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 141, train_loss = 1.2139829633160844, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 142, train_loss = 1.2090646264477982, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 143, train_loss = 1.207379745937942, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 144, train_loss = 1.2065377409235225, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 145, train_loss = 1.2053737677633762, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 146, train_loss = 1.2047718428075314, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 147, train_loss = 1.2024110990241752, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 148, train_loss = 1.2021373398602009, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 149, train_loss = 1.199688977249025, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 150, train_loss = 1.1992316842079163, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 151, train_loss = 1.1969614078625455, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 152, train_loss = 1.197147037833929, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 153, train_loss = 1.1951492428779602, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 154, train_loss = 1.1956019376739278, train_acc = 0.9966231951560317\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 155, train_loss = 1.1932490170001984, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 156, train_loss = 1.193044609077333, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 157, train_loss = 1.1938994104639278, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 158, train_loss = 1.1903818597420468, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 159, train_loss = 1.191693540662527, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 160, train_loss = 1.188779816031456, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 161, train_loss = 1.1897278614342213, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 162, train_loss = 1.1867419543341384, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 163, train_loss = 1.1878365923985257, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 164, train_loss = 1.187854810304998, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 165, train_loss = 1.1849529457613244, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 166, train_loss = 1.1854313512667431, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 167, train_loss = 1.1830649450421333, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 168, train_loss = 1.183587621897459, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 169, train_loss = 1.1839989610016346, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 170, train_loss = 1.1800925930365338, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 171, train_loss = 1.183100047208427, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 172, train_loss = 1.1809927485883236, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 173, train_loss = 1.1790679593905224, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 174, train_loss = 1.178730866558908, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 175, train_loss = 1.1813791369422688, train_acc = 0.9966231951560317\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 176, train_loss = 1.1772092978135333, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 177, train_loss = 1.1763707188292756, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 178, train_loss = 1.1785077030435787, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 179, train_loss = 1.1752510654405341, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 180, train_loss = 1.1740328470841632, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 181, train_loss = 1.1774866941050277, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 182, train_loss = 1.173058362059237, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 183, train_loss = 1.1717554318383918, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 184, train_loss = 1.1748708325103507, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 185, train_loss = 1.1710549630224705, train_acc = 0.9966231951560317\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 186, train_loss = 1.1723610957487836, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 187, train_loss = 1.1688917775973096, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 188, train_loss = 1.1696840139702545, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 189, train_loss = 1.167311148095905, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 190, train_loss = 1.1692457137032761, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 191, train_loss = 1.1674790730103268, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 192, train_loss = 1.1673767417669296, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 193, train_loss = 1.1656152494251728, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 194, train_loss = 1.1638988430313475, train_acc = 0.9967396367023754\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 195, train_loss = 1.1650997859724157, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 196, train_loss = 1.1610829569399357, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 197, train_loss = 1.1614057272672653, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 198, train_loss = 1.1601904183626175, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 199, train_loss = 1.1627210043370724, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 200, train_loss = 1.160827939707815, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 201, train_loss = 1.158877087134897, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 202, train_loss = 1.1578323058784008, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 203, train_loss = 1.1555722430348396, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 204, train_loss = 1.159983844805538, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 205, train_loss = 1.1573217461518652, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 206, train_loss = 1.155288544792711, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 207, train_loss = 1.156071025878191, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 208, train_loss = 1.1529785270504362, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 209, train_loss = 1.1562198040373914, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 210, train_loss = 1.1532580579332716, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 211, train_loss = 1.151072711993038, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 212, train_loss = 1.1532949221618765, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 213, train_loss = 1.1508547092489607, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 214, train_loss = 1.149332774180948, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 215, train_loss = 1.1482478318102949, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 216, train_loss = 1.1524150383957021, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 217, train_loss = 1.147420957684517, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 218, train_loss = 1.1465913566462405, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 219, train_loss = 1.1463422700762749, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 220, train_loss = 1.1461598351597786, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 221, train_loss = 1.1491793443747156, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 222, train_loss = 1.1461703640707128, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 223, train_loss = 1.1439276921264536, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 224, train_loss = 1.1462364941835403, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 225, train_loss = 1.1425004502125375, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 226, train_loss = 1.1448191652707465, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 227, train_loss = 1.1425220196433656, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 228, train_loss = 1.1427661751695268, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 229, train_loss = 1.139843825250864, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 230, train_loss = 1.1404623314738274, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 231, train_loss = 1.1376012240834825, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 232, train_loss = 1.1359886129685037, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 233, train_loss = 1.139211367815733, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 234, train_loss = 1.1345709351189726, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 235, train_loss = 1.1366725017614954, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 236, train_loss = 1.1332018437497027, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 237, train_loss = 1.1317289546132088, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 238, train_loss = 1.1323226292915933, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 239, train_loss = 1.1316489316523075, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 240, train_loss = 1.135364431887865, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 241, train_loss = 1.1335230668373697, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 242, train_loss = 1.130168356001377, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 243, train_loss = 1.1280538936443918, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 244, train_loss = 1.1307680656500452, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 245, train_loss = 1.1279695381708734, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 246, train_loss = 1.126238906133949, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 247, train_loss = 1.128655726712168, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 248, train_loss = 1.125261244673311, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 249, train_loss = 1.1237644317261584, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 250, train_loss = 1.1230550967156887, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 251, train_loss = 1.1251187610141642, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 252, train_loss = 1.1222454532980919, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 253, train_loss = 1.1197975774593942, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 254, train_loss = 1.1189226681999571, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 255, train_loss = 1.1181471856943972, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 256, train_loss = 1.1176902949810028, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 257, train_loss = 1.1157540592066653, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 258, train_loss = 1.1155023810752027, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 259, train_loss = 1.1149281250945933, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 260, train_loss = 1.117321470130264, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 261, train_loss = 1.116772599518299, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 262, train_loss = 1.112891212105751, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 263, train_loss = 1.1124064698815346, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 264, train_loss = 1.1149498360864527, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 265, train_loss = 1.1111306014172442, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 266, train_loss = 1.1085893101990223, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 267, train_loss = 1.107568281393469, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 268, train_loss = 1.1074852297715552, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 269, train_loss = 1.1066437773406506, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 270, train_loss = 1.109054180484236, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 271, train_loss = 1.1062666972466104, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 272, train_loss = 1.1045631679407961, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 273, train_loss = 1.1036245909817808, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 274, train_loss = 1.1029281901828654, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 275, train_loss = 1.1016339187808626, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 276, train_loss = 1.1047626584768295, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 277, train_loss = 1.1026153142265684, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 278, train_loss = 1.100732779752434, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 279, train_loss = 1.1010639021806128, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 280, train_loss = 1.0973665975034237, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 281, train_loss = 1.0963367658368952, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 282, train_loss = 1.0955699160695076, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 283, train_loss = 1.0953953067473776, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 284, train_loss = 1.0971493447832472, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 285, train_loss = 1.0929758461825259, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 286, train_loss = 1.0924697903283231, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 287, train_loss = 1.0947727262973785, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 288, train_loss = 1.0945844401903742, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 289, train_loss = 1.0899683386087418, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 290, train_loss = 1.088184489559353, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 291, train_loss = 1.0875678906850226, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 292, train_loss = 1.0863526376597292, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 293, train_loss = 1.0854120862968557, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 294, train_loss = 1.0844606434293382, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 295, train_loss = 1.083878883469879, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 296, train_loss = 1.082459160435974, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 297, train_loss = 1.084470260888338, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 298, train_loss = 1.080613906186045, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 299, train_loss = 1.0793068235107057, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 300, train_loss = 1.0790658742189407, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 301, train_loss = 1.0777054689824581, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 302, train_loss = 1.080363600205601, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 303, train_loss = 1.0766558994837396, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 304, train_loss = 1.075525866199314, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 305, train_loss = 1.0754702923186414, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 306, train_loss = 1.0744068957865238, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 307, train_loss = 1.0733262275643938, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 308, train_loss = 1.0717098588756926, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 309, train_loss = 1.0703358426690102, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 310, train_loss = 1.0705656756945245, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 311, train_loss = 1.0698480804749124, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 312, train_loss = 1.0692319783083803, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 313, train_loss = 1.0681530982255936, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 314, train_loss = 1.067905413608969, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 315, train_loss = 1.0668650505431287, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 316, train_loss = 1.0655635955445177, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 317, train_loss = 1.0652263065167062, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 318, train_loss = 1.064169763278187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 319, train_loss = 1.063845215987385, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 320, train_loss = 1.0624702709428675, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 321, train_loss = 1.0613451624922163, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 322, train_loss = 1.0610291150696867, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 323, train_loss = 1.060677537072479, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 324, train_loss = 1.059316119801224, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 325, train_loss = 1.0578725288323767, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 326, train_loss = 1.0588173866271973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 327, train_loss = 1.0571663603186607, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 328, train_loss = 1.0567459451667673, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 329, train_loss = 1.0555648778863542, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 330, train_loss = 1.054918047040701, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 331, train_loss = 1.054255926359474, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 332, train_loss = 1.0537384984381788, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 333, train_loss = 1.051928661763668, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 334, train_loss = 1.0513037741184235, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 335, train_loss = 1.050719774018944, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 336, train_loss = 1.049638537067949, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 337, train_loss = 1.0492479751519568, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 338, train_loss = 1.0493174778930552, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 339, train_loss = 1.047845089186012, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 340, train_loss = 1.0480261743068695, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 341, train_loss = 1.0459969763942354, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 342, train_loss = 1.0451263561844826, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 343, train_loss = 1.0448835293464072, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 344, train_loss = 1.04354416082424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 345, train_loss = 1.0430466830730438, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 346, train_loss = 1.042777514707268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 347, train_loss = 1.042085587978363, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 348, train_loss = 1.0408622014037974, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 349, train_loss = 1.0426806869618304, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 350, train_loss = 1.0409138972572691, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 351, train_loss = 1.0400449608750932, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 352, train_loss = 1.0399788754693873, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 353, train_loss = 1.040232150506199, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 354, train_loss = 1.0392698260657198, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 355, train_loss = 1.038811652611912, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 356, train_loss = 1.038207439083635, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 357, train_loss = 1.0376420716456778, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 358, train_loss = 1.038547587890207, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 359, train_loss = 1.0385470775254362, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 360, train_loss = 1.0363827819637663, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 361, train_loss = 1.0355091728270054, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 362, train_loss = 1.0348143763840199, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 363, train_loss = 1.0340674445033073, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 364, train_loss = 1.0334595305212133, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 365, train_loss = 1.0330595051236742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 366, train_loss = 1.032628187287628, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 367, train_loss = 1.0318100191652775, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 368, train_loss = 1.0332243082411878, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 369, train_loss = 1.0327781798951037, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 370, train_loss = 1.031144996482908, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 371, train_loss = 1.0305161165706522, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 372, train_loss = 1.0299973289183981, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 373, train_loss = 1.029665241640032, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 374, train_loss = 1.028841192524851, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 375, train_loss = 1.0285707972943783, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 376, train_loss = 1.0277288394681818, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 377, train_loss = 1.02689878891033, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 378, train_loss = 1.0289493737109296, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 379, train_loss = 1.0283711664378643, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 380, train_loss = 1.026402382802189, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 381, train_loss = 1.0255775041878223, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 382, train_loss = 1.0251122253648646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 383, train_loss = 1.0254109961279028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 384, train_loss = 1.0254028836898215, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 385, train_loss = 1.0249733229466074, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 386, train_loss = 1.0248210045210726, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 387, train_loss = 1.023788342874468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 388, train_loss = 1.025035072118044, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 389, train_loss = 1.0246418180577166, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 390, train_loss = 1.0243978848047846, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 391, train_loss = 1.0214339320846193, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 392, train_loss = 1.0209663696587086, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 393, train_loss = 1.0208815187215805, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 394, train_loss = 1.0197855557016737, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 395, train_loss = 1.0196869273968332, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 396, train_loss = 1.019062021125137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 397, train_loss = 1.0187908634543419, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 398, train_loss = 1.0181495038159483, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 399, train_loss = 1.019760336726904, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 400, train_loss = 1.0189417948313348, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 401, train_loss = 1.0186253488063812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 402, train_loss = 1.0168568876870268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 403, train_loss = 1.0164997068532102, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 404, train_loss = 1.0163045922927267, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 405, train_loss = 1.0155763116963499, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 406, train_loss = 1.015031911432743, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 407, train_loss = 1.0148111296184652, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 408, train_loss = 1.01419447113949, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 409, train_loss = 1.0136880849786394, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 410, train_loss = 1.0149281546473503, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 411, train_loss = 1.0152581272013776, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 412, train_loss = 1.0123980479947932, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 413, train_loss = 1.0119479695968039, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 414, train_loss = 1.0119779470078356, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 415, train_loss = 1.0114397034049034, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 416, train_loss = 1.0113287568092346, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 417, train_loss = 1.010856335360586, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 418, train_loss = 1.0113891400396824, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 419, train_loss = 1.0105921626091003, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 420, train_loss = 1.0117904817052477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 421, train_loss = 1.0122768903784163, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 422, train_loss = 1.00959850351137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 423, train_loss = 1.0094123035669327, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 424, train_loss = 1.0089996245988004, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 425, train_loss = 1.0083527316637628, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 426, train_loss = 1.008071737986029, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 427, train_loss = 1.007710146408499, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 428, train_loss = 1.007418834913551, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 429, train_loss = 1.0067141043655283, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 430, train_loss = 1.0077026560902596, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 431, train_loss = 1.0085448076315515, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 432, train_loss = 1.005974106490612, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 433, train_loss = 1.0052949997298128, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 434, train_loss = 1.0052806437015533, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 435, train_loss = 1.0049302726984024, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 436, train_loss = 1.0042140657715208, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 437, train_loss = 1.0040257362015836, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 438, train_loss = 1.002756501238764, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 439, train_loss = 1.0022620148956776, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 440, train_loss = 1.0032907500863075, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 441, train_loss = 1.0038527411707037, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 442, train_loss = 1.001294174540817, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 443, train_loss = 1.0009367975108034, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 444, train_loss = 1.000445385772764, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 445, train_loss = 1.0001314021646976, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 446, train_loss = 0.9996852527074225, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 447, train_loss = 0.9993013652674563, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 448, train_loss = 0.9993720352649689, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 449, train_loss = 0.9989005339630239, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 450, train_loss = 0.9977707850448496, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 451, train_loss = 0.9994324333965778, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 452, train_loss = 0.9999256369956129, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 453, train_loss = 0.9972108329347975, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 454, train_loss = 0.9968702445439703, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 455, train_loss = 0.9965788672379858, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 456, train_loss = 0.9962213250510104, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 457, train_loss = 0.9960999240465753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 458, train_loss = 0.9957468956708908, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 459, train_loss = 0.9950268442444212, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 460, train_loss = 0.9941590999551408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 461, train_loss = 0.9958415155597322, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 462, train_loss = 0.9966662252954848, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 463, train_loss = 0.9944653895981901, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 464, train_loss = 0.9940312653779984, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 465, train_loss = 0.9943797203413851, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 466, train_loss = 0.9935559791811102, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 467, train_loss = 0.9938358664512634, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 468, train_loss = 0.9930721695236571, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 469, train_loss = 0.9926111834756739, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 470, train_loss = 0.991910186905443, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 471, train_loss = 0.9933663370720751, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 472, train_loss = 0.9941272164396651, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 473, train_loss = 0.9916355821005709, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 474, train_loss = 0.9910794223360426, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 475, train_loss = 0.990635946393013, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 476, train_loss = 0.9902021288871765, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 477, train_loss = 0.9901761574037664, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 478, train_loss = 0.9899550154805183, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 479, train_loss = 0.9897107506803877, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 480, train_loss = 0.9876048689075105, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 481, train_loss = 0.9891642903276079, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 482, train_loss = 0.9898093193769455, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 483, train_loss = 0.987035562593519, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 484, train_loss = 0.9871121905744076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 485, train_loss = 0.9870251913853281, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 486, train_loss = 0.9862376091368787, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 487, train_loss = 0.9858655482530594, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 488, train_loss = 0.9855231580622785, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 489, train_loss = 0.9853027847893827, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 490, train_loss = 0.9851843404285319, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 491, train_loss = 0.9840238081924326, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 492, train_loss = 0.9862263438590162, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 493, train_loss = 0.9842102900147438, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 494, train_loss = 0.9835837905593507, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 495, train_loss = 0.9834427448622591, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 496, train_loss = 0.983079864334286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 497, train_loss = 0.9827331354208582, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 498, train_loss = 0.9823065685741312, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 499, train_loss = 0.9821659376211755, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|█████▎                                                                         | 2/30 [18:06<4:14:02, 544.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "3th- epoch: 0, train_loss = 390.9190699458122, train_acc = 0.8033302282254309\n",
      "test Acc 0.9059590316573557:\n",
      "3th- epoch: 1, train_loss = 98.11374075710773, train_acc = 0.9208197484862599\n",
      "test Acc 0.9222532588454376:\n",
      "3th- epoch: 2, train_loss = 59.65365299768746, train_acc = 0.9445738239403819\n",
      "test Acc 0.9329608938547486:\n",
      "3th- epoch: 3, train_loss = 41.20061797183007, train_acc = 0.9572659524918491\n",
      "test Acc 0.9343575418994413:\n",
      "3th- epoch: 4, train_loss = 29.89100372302346, train_acc = 0.966115510013973\n",
      "test Acc 0.9371508379888268:\n",
      "3th- epoch: 5, train_loss = 22.197278800187632, train_acc = 0.9734513274336283\n",
      "test Acc 0.9399441340782123:\n",
      "3th- epoch: 6, train_loss = 17.092630671919324, train_acc = 0.9777596646483465\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 7, train_loss = 13.540724930702709, train_acc = 0.9809035863996274\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 8, train_loss = 11.066155300824903, train_acc = 0.9838146250582208\n",
      "test Acc 0.9459962756052142:\n",
      "3th- epoch: 9, train_loss = 9.248396051407326, train_acc = 0.9862598975314392\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 10, train_loss = 7.847682310908567, train_acc = 0.9878900791802515\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 11, train_loss = 6.780473314225674, train_acc = 0.9888216115510013\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 12, train_loss = 5.919651228934526, train_acc = 0.9905682347461574\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 13, train_loss = 5.172061520337593, train_acc = 0.9919655333022822\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 14, train_loss = 4.633185225247871, train_acc = 0.9927806241266884\n",
      "test Acc 0.952048417132216:\n",
      "3th- epoch: 15, train_loss = 4.220182757824659, train_acc = 0.9935957149510946\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 16, train_loss = 3.863643488555681, train_acc = 0.9941779226828132\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 17, train_loss = 3.548942728608381, train_acc = 0.9945272473218444\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 18, train_loss = 3.269804608076811, train_acc = 0.9947601304145319\n",
      "test Acc 0.952513966480447:\n",
      "3th- epoch: 19, train_loss = 3.030907752632629, train_acc = 0.9952258965999069\n",
      "test Acc 0.9529795158286778:\n",
      "3th- epoch: 20, train_loss = 2.8370650758733973, train_acc = 0.9958081043316255\n",
      "test Acc 0.952048417132216:\n",
      "3th- epoch: 21, train_loss = 2.6826566022937186, train_acc = 0.9961574289706567\n",
      "test Acc 0.952513966480447:\n",
      "3th- epoch: 22, train_loss = 2.5684724735328928, train_acc = 0.996040987424313\n",
      "test Acc 0.9534450651769087:\n",
      "3th- epoch: 23, train_loss = 2.467265377403237, train_acc = 0.9963903120633442\n",
      "test Acc 0.9534450651769087:\n",
      "3th- epoch: 24, train_loss = 2.3749412819743156, train_acc = 0.9963903120633442\n",
      "test Acc 0.9543761638733705:\n",
      "3th- epoch: 25, train_loss = 2.2910093689570203, train_acc = 0.996506753609688\n",
      "test Acc 0.9529795158286778:\n",
      "3th- epoch: 26, train_loss = 2.2185123277595267, train_acc = 0.9963903120633442\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 27, train_loss = 2.159616349847056, train_acc = 0.996506753609688\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 28, train_loss = 2.1019307473907247, train_acc = 0.9966231951560317\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 29, train_loss = 2.058478318154812, train_acc = 0.996506753609688\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 30, train_loss = 2.0119372693588957, train_acc = 0.996506753609688\n",
      "test Acc 0.9534450651769087:\n",
      "3th- epoch: 31, train_loss = 1.9662755118915811, train_acc = 0.996506753609688\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 32, train_loss = 1.932655199081637, train_acc = 0.996506753609688\n",
      "test Acc 0.9543761638733705:\n",
      "3th- epoch: 33, train_loss = 1.8919128775596619, train_acc = 0.996506753609688\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 34, train_loss = 1.8513759188354015, train_acc = 0.996506753609688\n",
      "test Acc 0.9543761638733705:\n",
      "3th- epoch: 35, train_loss = 1.8180180962081067, train_acc = 0.9963903120633442\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 36, train_loss = 1.7898709562723525, train_acc = 0.9963903120633442\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 37, train_loss = 1.758585066825617, train_acc = 0.9963903120633442\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 38, train_loss = 1.7234872455592267, train_acc = 0.9963903120633442\n",
      "test Acc 0.9534450651769087:\n",
      "3th- epoch: 39, train_loss = 1.7013493552803993, train_acc = 0.9963903120633442\n",
      "test Acc 0.9543761638733705:\n",
      "3th- epoch: 40, train_loss = 1.6725462165777571, train_acc = 0.9963903120633442\n",
      "test Acc 0.9543761638733705:\n",
      "3th- epoch: 41, train_loss = 1.647452515840996, train_acc = 0.9962738705170004\n",
      "test Acc 0.9534450651769087:\n",
      "3th- epoch: 42, train_loss = 1.6169706483487971, train_acc = 0.9963903120633442\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 43, train_loss = 1.5896973138151225, train_acc = 0.9963903120633442\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 44, train_loss = 1.5790377644298133, train_acc = 0.9966231951560317\n",
      "test Acc 0.9543761638733705:\n",
      "3th- epoch: 45, train_loss = 1.562191341072321, train_acc = 0.996506753609688\n",
      "test Acc 0.9548417132216015:\n",
      "3th- epoch: 46, train_loss = 1.554164888948435, train_acc = 0.9966231951560317\n",
      "test Acc 0.9553072625698324:\n",
      "3th- epoch: 47, train_loss = 1.534717289119726, train_acc = 0.9966231951560317\n",
      "test Acc 0.9557728119180633:\n",
      "3th- epoch: 48, train_loss = 1.5305339395999908, train_acc = 0.9966231951560317\n",
      "test Acc 0.9553072625698324:\n",
      "3th- epoch: 49, train_loss = 1.5158857206552057, train_acc = 0.996506753609688\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 50, train_loss = 1.5110308354051085, train_acc = 0.9966231951560317\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 51, train_loss = 1.5003496048302623, train_acc = 0.996506753609688\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 52, train_loss = 1.4920612784771947, train_acc = 0.9967396367023754\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 53, train_loss = 1.4835484412760707, train_acc = 0.996506753609688\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 54, train_loss = 1.4779908085911302, train_acc = 0.9966231951560317\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 55, train_loss = 1.4669501297175884, train_acc = 0.996506753609688\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 56, train_loss = 1.4644733381719561, train_acc = 0.9966231951560317\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 57, train_loss = 1.4536311477422714, train_acc = 0.9966231951560317\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 58, train_loss = 1.4481385474427952, train_acc = 0.996506753609688\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 59, train_loss = 1.4420196910723462, train_acc = 0.996506753609688\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 60, train_loss = 1.438021348170878, train_acc = 0.996506753609688\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 61, train_loss = 1.4337514787912369, train_acc = 0.996506753609688\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 62, train_loss = 1.4247044498697505, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "3th- epoch: 63, train_loss = 1.4205791614949703, train_acc = 0.9966231951560317\n",
      "test Acc 0.957169459962756:\n",
      "3th- epoch: 64, train_loss = 1.4179999132975354, train_acc = 0.9967396367023754\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 65, train_loss = 1.4136816834434285, train_acc = 0.9966231951560317\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 66, train_loss = 1.4088429274634109, train_acc = 0.9966231951560317\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 67, train_loss = 1.3997284558936371, train_acc = 0.9967396367023754\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 68, train_loss = 1.3975484520196915, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 69, train_loss = 1.3943669547661557, train_acc = 0.9966231951560317\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 70, train_loss = 1.3905222515240894, train_acc = 0.9966231951560317\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 71, train_loss = 1.3914886129423394, train_acc = 0.9967396367023754\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 72, train_loss = 1.3820411873384728, train_acc = 0.9967396367023754\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 73, train_loss = 1.3809562101960182, train_acc = 0.9966231951560317\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 74, train_loss = 1.3754428712054505, train_acc = 0.9966231951560317\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 75, train_loss = 1.3731100348159089, train_acc = 0.9966231951560317\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 76, train_loss = 1.3709305922166095, train_acc = 0.9966231951560317\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 77, train_loss = 1.3637141597791924, train_acc = 0.9967396367023754\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 78, train_loss = 1.361388182886003, train_acc = 0.9966231951560317\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 79, train_loss = 1.3587199238463654, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 80, train_loss = 1.3558850871995674, train_acc = 0.9966231951560317\n",
      "test Acc 0.9567039106145251:\n",
      "3th- epoch: 81, train_loss = 1.3547815059646382, train_acc = 0.9966231951560317\n",
      "test Acc 0.9567039106145251:\n",
      "3th- epoch: 82, train_loss = 1.3485373606272333, train_acc = 0.9968560782487191\n",
      "test Acc 0.9567039106145251:\n",
      "3th- epoch: 83, train_loss = 1.3463853982575529, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "3th- epoch: 84, train_loss = 1.343520068872749, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "3th- epoch: 85, train_loss = 1.3419217057526112, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 86, train_loss = 1.33613309512657, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 87, train_loss = 1.3336654764898412, train_acc = 0.9968560782487191\n",
      "test Acc 0.9567039106145251:\n",
      "3th- epoch: 88, train_loss = 1.3315138965845108, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 89, train_loss = 1.3292586654424667, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 90, train_loss = 1.3273377157747746, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 91, train_loss = 1.3231720328330994, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 92, train_loss = 1.3219779257960909, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 93, train_loss = 1.3185917499176867, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 94, train_loss = 1.3173699664585001, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 95, train_loss = 1.3179710159711249, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 96, train_loss = 1.3118893690407276, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 97, train_loss = 1.3088243156671524, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 98, train_loss = 1.3090925253927708, train_acc = 0.9967396367023754\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 99, train_loss = 1.3034928180277348, train_acc = 0.9967396367023754\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 100, train_loss = 1.3029649332165718, train_acc = 0.9967396367023754\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 101, train_loss = 1.2996979604176886, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 102, train_loss = 1.2981486022472382, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 103, train_loss = 1.296325636405527, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 104, train_loss = 1.2958586874119646, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 105, train_loss = 1.289705865085125, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 106, train_loss = 1.2885620867200487, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 107, train_loss = 1.2867799165360339, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 108, train_loss = 1.2857942419759638, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 109, train_loss = 1.282735458265961, train_acc = 0.9968560782487191\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 110, train_loss = 1.279894853632868, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 111, train_loss = 1.279624146718561, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 112, train_loss = 1.2771063223481178, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 113, train_loss = 1.2770176505036943, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 114, train_loss = 1.2716007704548247, train_acc = 0.9968560782487191\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 115, train_loss = 1.2713452714197047, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 116, train_loss = 1.2680239292494662, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 117, train_loss = 1.2692730178423517, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 118, train_loss = 1.268602871645271, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 119, train_loss = 1.2637349131218798, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 120, train_loss = 1.2625030701346986, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 121, train_loss = 1.2610559264830954, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 122, train_loss = 1.258338700979948, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 123, train_loss = 1.2629216151945002, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 124, train_loss = 1.2542685990520113, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 125, train_loss = 1.2527262941002846, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 126, train_loss = 1.2513048388063908, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 127, train_loss = 1.2505180674306757, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 128, train_loss = 1.250050101429224, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 129, train_loss = 1.245219148695469, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 130, train_loss = 1.2456925647966273, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 131, train_loss = 1.2433395721018314, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 132, train_loss = 1.240705727290333, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 133, train_loss = 1.2404015250504017, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 134, train_loss = 1.2378448930867307, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 135, train_loss = 1.2333928582556837, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 136, train_loss = 1.234062023460865, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 137, train_loss = 1.2341626534871466, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 138, train_loss = 1.2353656540326483, train_acc = 0.9967396367023754\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 139, train_loss = 1.2285953052341938, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 140, train_loss = 1.2269707694649696, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 141, train_loss = 1.2250732791908376, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 142, train_loss = 1.2226266016550653, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 143, train_loss = 1.2242162078619003, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 144, train_loss = 1.221515083063423, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 145, train_loss = 1.2215628114827268, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 146, train_loss = 1.218732422838002, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 147, train_loss = 1.2195092712845508, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 148, train_loss = 1.216917081424981, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 149, train_loss = 1.2175728119909763, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 150, train_loss = 1.2130573205649853, train_acc = 0.9968560782487191\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 151, train_loss = 1.2115103056039516, train_acc = 0.9968560782487191\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 152, train_loss = 1.2124938505385217, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 153, train_loss = 1.207357262572259, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 154, train_loss = 1.211747328439742, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 155, train_loss = 1.20817544435522, train_acc = 0.9968560782487191\n",
      "test Acc 0.9590316573556797:\n",
      "3th- epoch: 156, train_loss = 1.2059071846306324, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 157, train_loss = 1.2047915868461132, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 158, train_loss = 1.2014140474293526, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 159, train_loss = 1.20240293318966, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 160, train_loss = 1.2038626347984973, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 161, train_loss = 1.2006591794397536, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 162, train_loss = 1.1964513709153834, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 163, train_loss = 1.1966938724126521, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 164, train_loss = 1.1940830014646053, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 165, train_loss = 1.1972387706246082, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 166, train_loss = 1.1962601107861701, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 167, train_loss = 1.1910741788651649, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 168, train_loss = 1.1909280990566913, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 169, train_loss = 1.188437441984206, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 170, train_loss = 1.191575410464793, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 171, train_loss = 1.187653873115778, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 172, train_loss = 1.1896019292380515, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 173, train_loss = 1.1864498344566528, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 174, train_loss = 1.1871146957073506, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 175, train_loss = 1.182640982171506, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 176, train_loss = 1.1856377497315407, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 177, train_loss = 1.18227531885168, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 178, train_loss = 1.186228770762682, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 179, train_loss = 1.178701522449046, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 180, train_loss = 1.1796471439301968, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 181, train_loss = 1.177931005755454, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 182, train_loss = 1.178078760704011, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 183, train_loss = 1.1793186937775317, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 184, train_loss = 1.1749818486478034, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 185, train_loss = 1.1749348143730458, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 186, train_loss = 1.1742649674415588, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 187, train_loss = 1.1726167276501656, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 188, train_loss = 1.1725795604288578, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 189, train_loss = 1.170083240916938, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 190, train_loss = 1.1726138765607175, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 191, train_loss = 1.171205413838834, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 192, train_loss = 1.1698478894923028, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 193, train_loss = 1.1695577067639533, train_acc = 0.9970889613414066\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 194, train_loss = 1.1658374009039107, train_acc = 0.9970889613414066\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 195, train_loss = 1.1668107795212563, train_acc = 0.9970889613414066\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 196, train_loss = 1.1677998850736913, train_acc = 0.9970889613414066\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 197, train_loss = 1.1649254734311398, train_acc = 0.9970889613414066\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 198, train_loss = 1.1645597306396667, train_acc = 0.9970889613414066\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 199, train_loss = 1.1633392932508286, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 200, train_loss = 1.1609621519837674, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 201, train_loss = 1.1601219264175597, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 202, train_loss = 1.159090311577529, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 203, train_loss = 1.1609122740719613, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 204, train_loss = 1.1631374967601005, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 205, train_loss = 1.1576977173481282, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 206, train_loss = 1.1599618804957572, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 207, train_loss = 1.1541406524684135, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 208, train_loss = 1.1578961536288261, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 209, train_loss = 1.1547843180596828, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 210, train_loss = 1.1555861954893771, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 211, train_loss = 1.155459081133813, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 212, train_loss = 1.157191292693824, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 213, train_loss = 1.1491607539355755, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 214, train_loss = 1.1532571936641034, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 215, train_loss = 1.1499251586701575, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 216, train_loss = 1.1536377879474458, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 217, train_loss = 1.1489584185183048, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 218, train_loss = 1.151132732629776, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 219, train_loss = 1.15068145220539, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 220, train_loss = 1.1476244901623431, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 221, train_loss = 1.1483078760411445, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 222, train_loss = 1.1466060280799866, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 223, train_loss = 1.1486745215952396, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 224, train_loss = 1.1423370415959653, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 225, train_loss = 1.1460330970585346, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 226, train_loss = 1.1469800099730492, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 227, train_loss = 1.1418777095768746, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 228, train_loss = 1.1431504959855374, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 229, train_loss = 1.1415389254689217, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 230, train_loss = 1.1420232231412228, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 231, train_loss = 1.1377431315686408, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 232, train_loss = 1.1419587768614292, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 233, train_loss = 1.139057611426324, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 234, train_loss = 1.1372413523495197, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 235, train_loss = 1.1383656238522235, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 236, train_loss = 1.1368944024052325, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 237, train_loss = 1.1346546063814458, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 238, train_loss = 1.1365743329133693, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 239, train_loss = 1.13329004993102, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 240, train_loss = 1.1357462207470235, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 241, train_loss = 1.1310355688128766, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 242, train_loss = 1.1319055259227753, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 243, train_loss = 1.1310810608174506, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 244, train_loss = 1.1282112362478074, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 245, train_loss = 1.1302423973884288, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 246, train_loss = 1.128623212376624, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 247, train_loss = 1.1278707583751384, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 248, train_loss = 1.1309356515612308, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 249, train_loss = 1.129334314415246, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 250, train_loss = 1.1276797143127624, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 251, train_loss = 1.1265718961749371, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 252, train_loss = 1.1275817851219472, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 253, train_loss = 1.1251714453101158, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 254, train_loss = 1.124995597949237, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 255, train_loss = 1.1230667320396606, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 256, train_loss = 1.1266610622406006, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 257, train_loss = 1.123358827084303, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 258, train_loss = 1.118389808883876, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 259, train_loss = 1.1218625927958783, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 260, train_loss = 1.1207936865594093, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 261, train_loss = 1.1207950698826608, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 262, train_loss = 1.119566352417678, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 263, train_loss = 1.1222135697807971, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 264, train_loss = 1.1188129211459454, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 265, train_loss = 1.12052384018898, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 266, train_loss = 1.1154409001264867, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 267, train_loss = 1.118005638321847, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 268, train_loss = 1.1152468199525174, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 269, train_loss = 1.1167895247544948, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 270, train_loss = 1.115059749534339, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 271, train_loss = 1.1162242827322189, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 272, train_loss = 1.1137687414884567, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 273, train_loss = 1.113576252013445, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 274, train_loss = 1.113893528779954, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 275, train_loss = 1.1124643410239514, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 276, train_loss = 1.1125662277136144, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 277, train_loss = 1.1120515080783662, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 278, train_loss = 1.111184399574995, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 279, train_loss = 1.1073920217659179, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 280, train_loss = 1.107965679218978, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 281, train_loss = 1.1071994925532636, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 282, train_loss = 1.1071338516976539, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 283, train_loss = 1.1045479240510758, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 284, train_loss = 1.106211755424738, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 285, train_loss = 1.1057677914704982, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 286, train_loss = 1.1054149406645593, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 287, train_loss = 1.1043860539793968, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 288, train_loss = 1.1030294671654701, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 289, train_loss = 1.1045256120469276, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 290, train_loss = 1.1013727945592109, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 291, train_loss = 1.1031226217746735, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 292, train_loss = 1.101729574302226, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 293, train_loss = 1.1017833153400716, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 294, train_loss = 1.100219843288869, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 295, train_loss = 1.1004226257409755, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 296, train_loss = 1.1006683856248856, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 297, train_loss = 1.0984180383384228, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 298, train_loss = 1.0988403372466564, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 299, train_loss = 1.097792216887683, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 300, train_loss = 1.0974284050371352, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 301, train_loss = 1.0978136248886585, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 302, train_loss = 1.0970343214776221, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 303, train_loss = 1.0969444029033184, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 304, train_loss = 1.0964843978490535, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 305, train_loss = 1.0948127694427967, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 306, train_loss = 1.0944761869814101, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 307, train_loss = 1.0949424877762794, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 308, train_loss = 1.0933947749435902, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 309, train_loss = 1.0926064935829345, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 310, train_loss = 1.0927297038342658, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 311, train_loss = 1.0924272847678367, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 312, train_loss = 1.0912388575579826, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 313, train_loss = 1.0918769538402557, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 314, train_loss = 1.090586436292142, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 315, train_loss = 1.0896321646869183, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 316, train_loss = 1.0896103878822032, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 317, train_loss = 1.0902520579602424, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 318, train_loss = 1.087447809675723, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 319, train_loss = 1.0882287646327313, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 320, train_loss = 1.088380998620778, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 321, train_loss = 1.087397925555706, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 322, train_loss = 1.087404356649131, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 323, train_loss = 1.08683605119586, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 324, train_loss = 1.0865496111418906, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 325, train_loss = 1.0861118535194692, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 326, train_loss = 1.0848400493468944, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 327, train_loss = 1.0852456775810424, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 328, train_loss = 1.082603686800212, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 329, train_loss = 1.0842363648116589, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 330, train_loss = 1.0835263344142732, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 331, train_loss = 1.081567150851697, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 332, train_loss = 1.0827613100409508, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 333, train_loss = 1.0819736942648888, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 334, train_loss = 1.0807968353237811, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 335, train_loss = 1.0801691636443138, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 336, train_loss = 1.0790701272580918, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 337, train_loss = 1.079246078928918, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 338, train_loss = 1.0795801331605617, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 339, train_loss = 1.0796513284240064, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 340, train_loss = 1.078051141152173, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 341, train_loss = 1.078156749406844, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 342, train_loss = 1.0757533224914368, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 343, train_loss = 1.0770476423203945, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 344, train_loss = 1.0763970166444778, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 345, train_loss = 1.074606339136153, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 346, train_loss = 1.0756053042914573, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 347, train_loss = 1.07520267243126, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 348, train_loss = 1.0739864545557793, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 349, train_loss = 1.073170281946659, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 350, train_loss = 1.0736742789540585, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 351, train_loss = 1.0733386638257798, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 352, train_loss = 1.0737305705752078, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 353, train_loss = 1.0720636410023872, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 354, train_loss = 1.0725225557889644, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 355, train_loss = 1.0712449476122856, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 356, train_loss = 1.0698060505092144, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 357, train_loss = 1.0709006413817406, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 358, train_loss = 1.0702477271352109, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 359, train_loss = 1.0687069905306998, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 360, train_loss = 1.0702245198190212, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 361, train_loss = 1.0687297160420712, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 362, train_loss = 1.0690501096341904, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 363, train_loss = 1.0683449072148505, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 364, train_loss = 1.0676935389637947, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 365, train_loss = 1.0662535255160037, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 366, train_loss = 1.0666613144185249, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 367, train_loss = 1.0657044164836407, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 368, train_loss = 1.066236987709999, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 369, train_loss = 1.065592672675848, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 370, train_loss = 1.0656009179856483, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 371, train_loss = 1.0648287174608413, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 372, train_loss = 1.0626362301409245, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 373, train_loss = 1.0649031661450863, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 374, train_loss = 1.063808857152253, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 375, train_loss = 1.0625822581350803, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 376, train_loss = 1.0628943480551243, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 377, train_loss = 1.0622411407530308, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 378, train_loss = 1.0624551164601144, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 379, train_loss = 1.0611581703033153, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 380, train_loss = 1.0597021989524364, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 381, train_loss = 1.0614085135366622, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 382, train_loss = 1.0598777619507018, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 383, train_loss = 1.0602201037108898, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 384, train_loss = 1.0588848739862442, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 385, train_loss = 1.0591461273525056, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 386, train_loss = 1.057635651281089, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 387, train_loss = 1.0583446212112904, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 388, train_loss = 1.057870578020811, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 389, train_loss = 1.0582210086286068, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 390, train_loss = 1.057015380511075, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 391, train_loss = 1.0561228332426253, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 392, train_loss = 1.0563117054607574, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 393, train_loss = 1.0544104812051955, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 394, train_loss = 1.0552222703900043, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 395, train_loss = 1.0557491108775139, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 396, train_loss = 1.0542985200881958, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 397, train_loss = 1.0559592805802822, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 398, train_loss = 1.0538646231088933, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 399, train_loss = 1.05227092901805, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 400, train_loss = 1.051179098585635, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 401, train_loss = 1.0526947677135468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 402, train_loss = 1.051558123281211, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 403, train_loss = 1.0522968235109147, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 404, train_loss = 1.0501619788501557, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 405, train_loss = 1.0513687717411813, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 406, train_loss = 1.050427178541213, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 407, train_loss = 1.0495724442098435, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 408, train_loss = 1.0477381013333797, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 409, train_loss = 1.0496155756209191, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 410, train_loss = 1.0506464528534707, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 411, train_loss = 1.0481376734878722, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 412, train_loss = 1.049662193903714, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 413, train_loss = 1.0499118405077752, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 414, train_loss = 1.0467370301485062, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 415, train_loss = 1.0472431158032123, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 416, train_loss = 1.0467656130585965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 417, train_loss = 1.0464655421674252, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 418, train_loss = 1.0474940054118633, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 419, train_loss = 1.0455006795618829, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 420, train_loss = 1.0445745090637502, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 421, train_loss = 1.0450937524437904, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 422, train_loss = 1.0434819906949997, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 423, train_loss = 1.0435518349204358, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 424, train_loss = 1.0425521420929726, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 425, train_loss = 1.0437387228012085, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 426, train_loss = 1.0459042477104958, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 427, train_loss = 1.0425158267225925, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 428, train_loss = 1.0420333693418797, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 429, train_loss = 1.0434605106711388, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 430, train_loss = 1.0419728569686413, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 431, train_loss = 1.041074068596572, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 432, train_loss = 1.0397767573595047, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 433, train_loss = 1.0415180536601838, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 434, train_loss = 1.0426542771365348, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 435, train_loss = 1.0394077611472312, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 436, train_loss = 1.0382771703098115, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 437, train_loss = 1.0413739333544072, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 438, train_loss = 1.0396209806203842, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 439, train_loss = 1.0390667617321014, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 440, train_loss = 1.0372504306342307, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 441, train_loss = 1.0379357772562798, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 442, train_loss = 1.037453946968526, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 443, train_loss = 1.03669910008648, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 444, train_loss = 1.0361808414254483, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 445, train_loss = 1.037906438112259, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 446, train_loss = 1.035464776059598, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 447, train_loss = 1.0345159185435477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 448, train_loss = 1.037057897696286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 449, train_loss = 1.0345266635213193, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 450, train_loss = 1.033477071672678, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 451, train_loss = 1.0341989621520042, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 452, train_loss = 1.0342054242883023, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 453, train_loss = 1.0343121116366092, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 454, train_loss = 1.0344004146754742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 455, train_loss = 1.0336681144926843, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 456, train_loss = 1.035818732032567, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 457, train_loss = 1.0321370201800164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 458, train_loss = 1.0319837108254433, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 459, train_loss = 1.0346628365423385, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 460, train_loss = 1.0322673047576245, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 461, train_loss = 1.0315894770119485, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 462, train_loss = 1.0316300690174103, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 463, train_loss = 1.0293774480614957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 464, train_loss = 1.0309647843241692, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 465, train_loss = 1.030404174080104, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 466, train_loss = 1.02983432883957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 467, train_loss = 1.0312441686783131, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 468, train_loss = 1.0301761155333224, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 469, train_loss = 1.0274116334821883, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 470, train_loss = 1.0308967890832719, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 471, train_loss = 1.0293147104475793, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 472, train_loss = 1.0278752632439137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 473, train_loss = 1.0260749459266663, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 474, train_loss = 1.0274952935669717, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 475, train_loss = 1.027225386351347, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 476, train_loss = 1.0266492341961566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 477, train_loss = 1.0264073573052883, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 478, train_loss = 1.0238219959046546, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 479, train_loss = 1.023626122623682, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 480, train_loss = 1.0240668207406998, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 481, train_loss = 1.0270193293690681, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 482, train_loss = 1.025184011707097, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 483, train_loss = 1.0244935701284703, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 484, train_loss = 1.0242009038720425, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 485, train_loss = 1.0241034626960754, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 486, train_loss = 1.0240733660757542, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 487, train_loss = 1.0231833880152408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 488, train_loss = 1.0231004009638127, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 489, train_loss = 1.0248543905709084, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 490, train_loss = 1.0226970451567468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 491, train_loss = 1.020525602003545, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 492, train_loss = 1.0219813535604771, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 493, train_loss = 1.022062669197112, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 494, train_loss = 1.0200340797509853, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 495, train_loss = 1.0191924919690791, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 496, train_loss = 1.020877931267023, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 497, train_loss = 1.0219060021136102, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 498, train_loss = 1.0202197904382047, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 499, train_loss = 1.0202822635565099, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|███████▉                                                                       | 3/30 [27:10<4:04:51, 544.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "4th- epoch: 0, train_loss = 352.67088793218136, train_acc = 0.8079878900791803\n",
      "test Acc 0.8947858472998138:\n",
      "4th- epoch: 1, train_loss = 97.71204688632861, train_acc = 0.9138332557056358\n",
      "test Acc 0.9236499068901304:\n",
      "4th- epoch: 2, train_loss = 59.42326772212982, train_acc = 0.9407312529110387\n",
      "test Acc 0.9269087523277467:\n",
      "4th- epoch: 3, train_loss = 40.71936623658985, train_acc = 0.9551700046576619\n",
      "test Acc 0.9329608938547486:\n",
      "4th- epoch: 4, train_loss = 29.32440279237926, train_acc = 0.9637866790870983\n",
      "test Acc 0.9385474860335196:\n",
      "4th- epoch: 5, train_loss = 21.790106551721692, train_acc = 0.9720540288775035\n",
      "test Acc 0.9408752327746741:\n",
      "4th- epoch: 6, train_loss = 16.946861601434648, train_acc = 0.9769445738239404\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 7, train_loss = 13.679421368055046, train_acc = 0.9804378202142524\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 8, train_loss = 11.244904022663832, train_acc = 0.9832324173265021\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 9, train_loss = 9.441282828804106, train_acc = 0.9855612482533768\n",
      "test Acc 0.952048417132216:\n",
      "4th- epoch: 10, train_loss = 8.10876596858725, train_acc = 0.9869585468095017\n",
      "test Acc 0.952513966480447:\n",
      "4th- epoch: 11, train_loss = 7.085531181190163, train_acc = 0.9881229622729389\n",
      "test Acc 0.9543761638733705:\n",
      "4th- epoch: 12, train_loss = 6.226268588099629, train_acc = 0.9891709361900326\n",
      "test Acc 0.9562383612662942:\n",
      "4th- epoch: 13, train_loss = 5.5335736139677465, train_acc = 0.9904517931998137\n",
      "test Acc 0.9562383612662942:\n",
      "4th- epoch: 14, train_loss = 4.969651418272406, train_acc = 0.9916162086632511\n",
      "test Acc 0.9567039106145251:\n",
      "4th- epoch: 15, train_loss = 4.507154916645959, train_acc = 0.9914997671169073\n",
      "test Acc 0.9557728119180633:\n",
      "4th- epoch: 16, train_loss = 4.110469811828807, train_acc = 0.9925477410340009\n",
      "test Acc 0.9562383612662942:\n",
      "4th- epoch: 17, train_loss = 3.7364299036562443, train_acc = 0.9925477410340009\n",
      "test Acc 0.957169459962756:\n",
      "4th- epoch: 18, train_loss = 3.4218882594723254, train_acc = 0.9928970656730322\n",
      "test Acc 0.9567039106145251:\n",
      "4th- epoch: 19, train_loss = 3.157160844653845, train_acc = 0.9937121564974383\n",
      "test Acc 0.9581005586592178:\n",
      "4th- epoch: 20, train_loss = 2.9234673703322187, train_acc = 0.9939450395901258\n",
      "test Acc 0.9590316573556797:\n",
      "4th- epoch: 21, train_loss = 2.7528034696588293, train_acc = 0.9944108057755007\n",
      "test Acc 0.9585661080074488:\n",
      "4th- epoch: 22, train_loss = 2.5866736074676737, train_acc = 0.9946436888681882\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 23, train_loss = 2.4565670800511725, train_acc = 0.9951094550535631\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 24, train_loss = 2.3439897398347966, train_acc = 0.9952258965999069\n",
      "test Acc 0.9581005586592178:\n",
      "4th- epoch: 25, train_loss = 2.2448154973681085, train_acc = 0.995575221238938\n",
      "test Acc 0.9590316573556797:\n",
      "4th- epoch: 26, train_loss = 2.1505437183077447, train_acc = 0.996040987424313\n",
      "test Acc 0.9590316573556797:\n",
      "4th- epoch: 27, train_loss = 2.0885270535945892, train_acc = 0.996040987424313\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 28, train_loss = 2.022958882153034, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 29, train_loss = 1.9743798573908862, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 30, train_loss = 1.9339119531214237, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 31, train_loss = 1.8981500789523125, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 32, train_loss = 1.8666691482067108, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 33, train_loss = 1.8378086822631303, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 34, train_loss = 1.810280176490778, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 35, train_loss = 1.7917211912572384, train_acc = 0.9966231951560317\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 36, train_loss = 1.7646264284849167, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 37, train_loss = 1.7469961792230606, train_acc = 0.9967396367023754\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 38, train_loss = 1.7272600804863032, train_acc = 0.9967396367023754\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 39, train_loss = 1.707916609942913, train_acc = 0.9967396367023754\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 40, train_loss = 1.6935721362533513, train_acc = 0.9967396367023754\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 41, train_loss = 1.6807743161916733, train_acc = 0.9967396367023754\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 42, train_loss = 1.6642216965556145, train_acc = 0.9967396367023754\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 43, train_loss = 1.6506085842847824, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 44, train_loss = 1.636455009371275, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 45, train_loss = 1.6257499208149966, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 46, train_loss = 1.6062843526306096, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 47, train_loss = 1.5964504194853362, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 48, train_loss = 1.5833003831503447, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 49, train_loss = 1.5696534179151058, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 50, train_loss = 1.5632183477282524, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 51, train_loss = 1.5529815927147865, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 52, train_loss = 1.5467864995298441, train_acc = 0.996506753609688\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 53, train_loss = 1.5305637642741203, train_acc = 0.996506753609688\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 54, train_loss = 1.524267591536045, train_acc = 0.996506753609688\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 55, train_loss = 1.5175453387200832, train_acc = 0.996506753609688\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 56, train_loss = 1.5062319648859557, train_acc = 0.996506753609688\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 57, train_loss = 1.500155477464432, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 58, train_loss = 1.4918408741650637, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 59, train_loss = 1.4829546113905963, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 60, train_loss = 1.478786364197731, train_acc = 0.9963903120633442\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 61, train_loss = 1.4670135043561459, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 62, train_loss = 1.4615514700708445, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 63, train_loss = 1.4550476732256357, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 64, train_loss = 1.450867601990467, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 65, train_loss = 1.4432729668915272, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 66, train_loss = 1.436683172985795, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 67, train_loss = 1.431006977960351, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 68, train_loss = 1.4270699334592791, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 69, train_loss = 1.4193753401486902, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 70, train_loss = 1.415511291474104, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 71, train_loss = 1.409129623323679, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 72, train_loss = 1.4014034407882718, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 73, train_loss = 1.4006629176437855, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 74, train_loss = 1.3968428733496694, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 75, train_loss = 1.3910294051020173, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 76, train_loss = 1.3875788487493992, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 77, train_loss = 1.3763684618024854, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 78, train_loss = 1.3702428763062926, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 79, train_loss = 1.3714766626508208, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 80, train_loss = 1.3647111517639132, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 81, train_loss = 1.3608914365322562, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 82, train_loss = 1.358707686260459, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 83, train_loss = 1.353309181824443, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 84, train_loss = 1.3502123939542798, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 85, train_loss = 1.347781091928482, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 86, train_loss = 1.3405629297049018, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 87, train_loss = 1.3393709597439738, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 88, train_loss = 1.3376459988503484, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 89, train_loss = 1.3294385857880116, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 90, train_loss = 1.3256333532481221, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 91, train_loss = 1.3215628464968177, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 92, train_loss = 1.3209309987723827, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 93, train_loss = 1.3183853551745415, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 94, train_loss = 1.3158411395997973, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 95, train_loss = 1.3117987799196271, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 96, train_loss = 1.3067258186638355, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 97, train_loss = 1.302493775889161, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 98, train_loss = 1.3011867093591718, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 99, train_loss = 1.299032295748475, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 100, train_loss = 1.2955648452043533, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 101, train_loss = 1.2924060001969337, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 102, train_loss = 1.2877794255764456, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 103, train_loss = 1.2895214806048898, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 104, train_loss = 1.2833986679761438, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 105, train_loss = 1.2800220760254888, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 106, train_loss = 1.2786776932625799, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 107, train_loss = 1.2766191152186366, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 108, train_loss = 1.2715750721545191, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 109, train_loss = 1.2703302440495463, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 110, train_loss = 1.268068158373353, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 111, train_loss = 1.2640475245862035, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 112, train_loss = 1.262366623923299, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 113, train_loss = 1.2620027946977643, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 114, train_loss = 1.2568575143814087, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 115, train_loss = 1.2576728810818167, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 116, train_loss = 1.2522012616245775, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 117, train_loss = 1.2511603881866904, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 118, train_loss = 1.249753783151391, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 119, train_loss = 1.2443216579704313, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 120, train_loss = 1.242610311761382, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 121, train_loss = 1.2427108238189248, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 122, train_loss = 1.2403333770780591, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 123, train_loss = 1.2365015372633934, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 124, train_loss = 1.2360739670693874, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 125, train_loss = 1.233553106590989, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 126, train_loss = 1.2290256693959236, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 127, train_loss = 1.2252242838294478, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 128, train_loss = 1.2261009948997525, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 129, train_loss = 1.222586984440568, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 130, train_loss = 1.2220812092273263, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 131, train_loss = 1.2196384208946256, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 132, train_loss = 1.2159048480243655, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 133, train_loss = 1.2125194407999516, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 134, train_loss = 1.2104538058192702, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 135, train_loss = 1.2041560014040442, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 136, train_loss = 1.2004301423876313, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 137, train_loss = 1.2032247794122668, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 138, train_loss = 1.1940968371927738, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 139, train_loss = 1.1974413047282724, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 140, train_loss = 1.190529943756701, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 141, train_loss = 1.1929597109556198, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 142, train_loss = 1.1844832263886929, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 143, train_loss = 1.1899617624803795, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 144, train_loss = 1.1793225718065514, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 145, train_loss = 1.185354163251759, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 146, train_loss = 1.1772977535947575, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 147, train_loss = 1.1829580875710235, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 148, train_loss = 1.1752152368426323, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 149, train_loss = 1.172390346728207, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 150, train_loss = 1.172653529793024, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 151, train_loss = 1.1705419967547641, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 152, train_loss = 1.169029633201717, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 153, train_loss = 1.1680775086060748, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 154, train_loss = 1.1654792986810207, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 155, train_loss = 1.1653372993096127, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 156, train_loss = 1.1621850095689297, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 157, train_loss = 1.159267714865564, train_acc = 0.9970889613414066\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 158, train_loss = 1.1577014215290546, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 159, train_loss = 1.1577017096205964, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 160, train_loss = 1.1562628013416543, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 161, train_loss = 1.1545848064124584, train_acc = 0.9970889613414066\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 162, train_loss = 1.1524099508897052, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 163, train_loss = 1.151707744844316, train_acc = 0.9970889613414066\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 164, train_loss = 1.1486257811411633, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 165, train_loss = 1.1488650515675545, train_acc = 0.9970889613414066\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 166, train_loss = 1.1460336235686555, train_acc = 0.9970889613414066\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 167, train_loss = 1.150818981230259, train_acc = 0.9970889613414066\n",
      "test Acc 0.962756052141527:\n",
      "4th- epoch: 168, train_loss = 1.1454079138711677, train_acc = 0.9970889613414066\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 169, train_loss = 1.14205150926864, train_acc = 0.9970889613414066\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 170, train_loss = 1.1420808012262569, train_acc = 0.9970889613414066\n",
      "test Acc 0.962756052141527:\n",
      "4th- epoch: 171, train_loss = 1.1396780088543892, train_acc = 0.9970889613414066\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 172, train_loss = 1.1388307636007085, train_acc = 0.9970889613414066\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 173, train_loss = 1.138301574937941, train_acc = 0.9970889613414066\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 174, train_loss = 1.1363436169922352, train_acc = 0.9970889613414066\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 175, train_loss = 1.1341274070218788, train_acc = 0.9970889613414066\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 176, train_loss = 1.1346089839935303, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 177, train_loss = 1.1311516563073383, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 178, train_loss = 1.1307854937986122, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 179, train_loss = 1.1289164448753581, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 180, train_loss = 1.1286170644088998, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 181, train_loss = 1.1272519777194248, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 182, train_loss = 1.126005741454719, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 183, train_loss = 1.1252205558121204, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 184, train_loss = 1.1238575975075946, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 185, train_loss = 1.1225566528737545, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 186, train_loss = 1.1218464449048042, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 187, train_loss = 1.120412045471312, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 188, train_loss = 1.1187729413286434, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 189, train_loss = 1.1176187557503, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 190, train_loss = 1.1169340970591293, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 191, train_loss = 1.1146198523565545, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 192, train_loss = 1.1148285940289497, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 193, train_loss = 1.1135733115152107, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 194, train_loss = 1.1138006125911488, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 195, train_loss = 1.1106368874534382, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 196, train_loss = 1.1092772707343102, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 197, train_loss = 1.1131522804498672, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 198, train_loss = 1.1072640120983124, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 199, train_loss = 1.1062902435660362, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 200, train_loss = 1.105842617653252, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 201, train_loss = 1.1088063841089024, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 202, train_loss = 1.1032174142674194, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 203, train_loss = 1.1012636236846447, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 204, train_loss = 1.1060080081224442, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 205, train_loss = 1.1015233683065162, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 206, train_loss = 1.1006196911112056, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 207, train_loss = 1.0991251282393932, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 208, train_loss = 1.0979079777971492, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 209, train_loss = 1.0968265570700169, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 210, train_loss = 1.0966857348903432, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 211, train_loss = 1.0958958479241119, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 212, train_loss = 1.095190640538931, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 213, train_loss = 1.0940409824252129, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 214, train_loss = 1.0925057493150234, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 215, train_loss = 1.0927959904074669, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 216, train_loss = 1.091364149004221, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 217, train_loss = 1.089865436159016, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 218, train_loss = 1.0889004332348122, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 219, train_loss = 1.0884321803823696, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 220, train_loss = 1.0867034805341973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 221, train_loss = 1.0864993830546155, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 222, train_loss = 1.0851244454606785, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 223, train_loss = 1.0854314838870778, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 224, train_loss = 1.082965049892664, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 225, train_loss = 1.0825388294979348, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 226, train_loss = 1.0810174395664944, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 227, train_loss = 1.0814582121893181, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 228, train_loss = 1.081368657447456, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 229, train_loss = 1.0795720890164375, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 230, train_loss = 1.0780613832175732, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 231, train_loss = 1.0783150767310872, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 232, train_loss = 1.077721676476358, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 233, train_loss = 1.0764964086338296, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 234, train_loss = 1.075217116624117, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 235, train_loss = 1.0734669081866741, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 236, train_loss = 1.0746443358584656, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 237, train_loss = 1.0726775377988815, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 238, train_loss = 1.071897624678968, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 239, train_loss = 1.0711979543193593, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 240, train_loss = 1.07113379240036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 241, train_loss = 1.0708932653069496, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 242, train_loss = 1.0686644042507396, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 243, train_loss = 1.0689527156428085, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 244, train_loss = 1.0682740025222301, train_acc = 0.9975547275267815\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 245, train_loss = 1.0658060399218812, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 246, train_loss = 1.0660488133653416, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 247, train_loss = 1.0655569806694984, train_acc = 0.9975547275267815\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 248, train_loss = 1.0633571570142522, train_acc = 0.9975547275267815\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 249, train_loss = 1.0647812498136773, train_acc = 0.9975547275267815\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 250, train_loss = 1.06333901360631, train_acc = 0.9975547275267815\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 251, train_loss = 1.0633584012612118, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 252, train_loss = 1.0624441504478455, train_acc = 0.9975547275267815\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 253, train_loss = 1.0607026517391205, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 254, train_loss = 1.0616144736632123, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 255, train_loss = 1.0593803822994232, train_acc = 0.9975547275267815\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 256, train_loss = 1.0596633603199734, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 257, train_loss = 1.0598888248205185, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 258, train_loss = 1.058019428201078, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 259, train_loss = 1.0581573285162449, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 260, train_loss = 1.0565701214, train_acc = 0.9975547275267815\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 261, train_loss = 1.0576313100755215, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 262, train_loss = 1.055789839476347, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 263, train_loss = 1.0559679282232537, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 264, train_loss = 1.0540110518559231, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 265, train_loss = 1.0554902143776417, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 266, train_loss = 1.0543725614770665, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 267, train_loss = 1.0538483349009766, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 268, train_loss = 1.052557232476829, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 269, train_loss = 1.0524081165567623, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 270, train_loss = 1.051499684654118, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 271, train_loss = 1.0512893261984573, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 272, train_loss = 1.0517285888417973, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 273, train_loss = 1.0502120616511093, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 274, train_loss = 1.0493967235088348, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 275, train_loss = 1.0488953702151775, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 276, train_loss = 1.048682159431337, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 277, train_loss = 1.0494178695007577, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 278, train_loss = 1.0471859773024335, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 279, train_loss = 1.0467398203909397, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 280, train_loss = 1.0470393312498345, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 281, train_loss = 1.0450371975675807, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 282, train_loss = 1.0453301332890987, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 283, train_loss = 1.0453068688511848, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 284, train_loss = 1.0442259423434734, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 285, train_loss = 1.0436903536319733, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 286, train_loss = 1.0436535750850453, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 287, train_loss = 1.042906312890409, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 288, train_loss = 1.0422532322481857, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 289, train_loss = 1.0425833463668823, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 290, train_loss = 1.039858819298388, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 291, train_loss = 1.039203946791531, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 292, train_loss = 1.0390594527125359, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 293, train_loss = 1.0395356242879643, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 294, train_loss = 1.0378861340359435, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 295, train_loss = 1.0380267972723232, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 296, train_loss = 1.037421943001391, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 297, train_loss = 1.0374294432476745, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 298, train_loss = 1.0371557238177047, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 299, train_loss = 1.0361896989270463, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 300, train_loss = 1.0345664819105878, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 301, train_loss = 1.0348762360736146, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 302, train_loss = 1.0341036841273308, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 303, train_loss = 1.0337328749374137, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 304, train_loss = 1.0337322180494084, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 305, train_loss = 1.0325965322554111, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 306, train_loss = 1.0327873205169453, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 307, train_loss = 1.0313647985458374, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 308, train_loss = 1.0317919005974545, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 309, train_loss = 1.0310468226671219, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 310, train_loss = 1.0312949977815151, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 311, train_loss = 1.0300135140641942, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 312, train_loss = 1.0299190444275155, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 313, train_loss = 1.029197824500443, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 314, train_loss = 1.0283664974049316, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 315, train_loss = 1.0272892129942193, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 316, train_loss = 1.0280537543221726, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 317, train_loss = 1.0265490785241127, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 318, train_loss = 1.0267323590815067, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 319, train_loss = 1.025663004569651, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 320, train_loss = 1.0259650076404796, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 321, train_loss = 1.025065557412745, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 322, train_loss = 1.025566109768988, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 323, train_loss = 1.0238760374486446, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 324, train_loss = 1.0234957337379456, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 325, train_loss = 1.0224440631791367, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 326, train_loss = 1.0226074370220886, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 327, train_loss = 1.0230013666077866, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 328, train_loss = 1.0217733643949032, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 329, train_loss = 1.0212718658149242, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 330, train_loss = 1.0216456775888219, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 331, train_loss = 1.020502374820353, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 332, train_loss = 1.0211529893203988, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 333, train_loss = 1.0196656435728073, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 334, train_loss = 1.0191762832328095, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 335, train_loss = 1.0191796409562812, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 336, train_loss = 1.0180533838793053, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 337, train_loss = 1.018270784370543, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 338, train_loss = 1.0172709139660583, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 339, train_loss = 1.0166413026527152, train_acc = 0.9975547275267815\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 340, train_loss = 1.0172839723527431, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 341, train_loss = 1.016273844987154, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 342, train_loss = 1.0164588267580257, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 343, train_loss = 1.0171562135219574, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 344, train_loss = 1.0144512206315994, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 345, train_loss = 1.0164298353120103, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 346, train_loss = 1.0149066535159363, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 347, train_loss = 1.0129523016512394, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 348, train_loss = 1.0154753103852272, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 349, train_loss = 1.0147226663902984, train_acc = 0.9975547275267815\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 350, train_loss = 1.0137694912627921, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 351, train_loss = 1.0124189307316556, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 352, train_loss = 1.012562415249704, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 353, train_loss = 1.0125026938840165, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 354, train_loss = 1.0105210232213722, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 355, train_loss = 1.011744583644031, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 356, train_loss = 1.0114152804017067, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 357, train_loss = 1.0103411016389146, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 358, train_loss = 1.0102245869711624, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 359, train_loss = 1.008539547525288, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 360, train_loss = 1.0096392966806889, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 361, train_loss = 1.0099240144118085, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 362, train_loss = 1.0097766096369014, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 363, train_loss = 1.0090714780017151, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 364, train_loss = 1.0084398314356804, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 365, train_loss = 1.0083453034385457, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 366, train_loss = 1.0078768990933895, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 367, train_loss = 1.007380443312286, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 368, train_loss = 1.0066178254783154, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 369, train_loss = 1.0061554933563457, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 370, train_loss = 1.0051814528778777, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 371, train_loss = 1.006800980620028, train_acc = 0.9975547275267815\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 372, train_loss = 1.0056265406310558, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 373, train_loss = 1.0052345618605614, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 374, train_loss = 1.0045310631394386, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 375, train_loss = 1.004359823964478, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 376, train_loss = 1.0039440977052436, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 377, train_loss = 1.0032225896939053, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 378, train_loss = 1.0040005544797168, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 379, train_loss = 1.0024674919768586, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 380, train_loss = 1.003416790314077, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 381, train_loss = 1.0025755427777767, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 382, train_loss = 1.00167564178264, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 383, train_loss = 1.0016415330246673, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 384, train_loss = 1.0020456885322346, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 385, train_loss = 1.0009216318503604, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 386, train_loss = 1.0008311519995914, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 387, train_loss = 0.9999609366059303, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 388, train_loss = 0.9990874181166873, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 389, train_loss = 0.9988713301718235, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 390, train_loss = 0.9993592575192451, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 391, train_loss = 0.9987129792571068, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 392, train_loss = 0.9985997291878448, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 393, train_loss = 0.9972224285229458, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 394, train_loss = 0.9982479723767028, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 395, train_loss = 0.997627620898129, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 396, train_loss = 0.9971599864438758, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 397, train_loss = 0.9965969187542214, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 398, train_loss = 0.9961604240015731, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 399, train_loss = 0.9965385509058251, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 400, train_loss = 0.9956700640395866, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 401, train_loss = 0.9953224919736385, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 402, train_loss = 0.9953968909903779, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 403, train_loss = 0.9947007745504379, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 404, train_loss = 0.9943790609613643, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 405, train_loss = 0.9936987621113076, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 406, train_loss = 0.9940911220983253, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 407, train_loss = 0.9934189692139626, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 408, train_loss = 0.9932373762130737, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 409, train_loss = 0.9924298202022328, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 410, train_loss = 0.9922803404406295, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 411, train_loss = 0.9927269617692218, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 412, train_loss = 0.9924510580822243, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 413, train_loss = 0.9910588661805377, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 414, train_loss = 0.9911314994096756, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 415, train_loss = 0.9898329290226684, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 416, train_loss = 0.9911257686690078, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 417, train_loss = 0.9908548295497894, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 418, train_loss = 0.9893267912193551, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 419, train_loss = 0.9894793977364316, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 420, train_loss = 0.9891457458361401, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 421, train_loss = 0.9888942415491329, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 422, train_loss = 0.9888932195826783, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 423, train_loss = 0.9880152729674592, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 424, train_loss = 0.988336003072618, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 425, train_loss = 0.9877947767599835, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 426, train_loss = 0.9874901634975686, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 427, train_loss = 0.9859557263553143, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 428, train_loss = 0.9872308609410538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 429, train_loss = 0.9864672087132931, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 430, train_loss = 0.9851588954552426, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 431, train_loss = 0.9856782568022027, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 432, train_loss = 0.9854757376015186, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 433, train_loss = 0.9852870193644776, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 434, train_loss = 0.985251035541296, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 435, train_loss = 0.985094449169992, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 436, train_loss = 0.9842781734987511, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 437, train_loss = 0.9833510667085648, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 438, train_loss = 0.9835178193970933, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 439, train_loss = 0.983419439442514, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 440, train_loss = 0.9833213786259876, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 441, train_loss = 0.9827369960621581, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 442, train_loss = 0.9837658939286484, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 443, train_loss = 0.9820609390735626, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 444, train_loss = 0.981606895722507, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 445, train_loss = 0.9812764177695499, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 446, train_loss = 0.9817166576758609, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 447, train_loss = 0.9804238316937699, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 448, train_loss = 0.9803083650767803, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 449, train_loss = 0.9803720576092019, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 450, train_loss = 0.9798003534451709, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 451, train_loss = 0.9797688672915683, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 452, train_loss = 0.979147344827652, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 453, train_loss = 0.9788392173722968, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 454, train_loss = 0.9787851559594856, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 455, train_loss = 0.9782437408939586, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 456, train_loss = 0.97801548615098, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 457, train_loss = 0.9785625201984658, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 458, train_loss = 0.9777710723355995, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 459, train_loss = 0.9786709820255055, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 460, train_loss = 0.9768587102516904, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 461, train_loss = 0.9767687308267341, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 462, train_loss = 0.9771432988345623, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 463, train_loss = 0.9768560317679658, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 464, train_loss = 0.975283474974276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 465, train_loss = 0.9763530418276787, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 466, train_loss = 0.9755508328453288, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 467, train_loss = 0.9746455438435078, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 468, train_loss = 0.9750643459483399, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 469, train_loss = 0.9751501282080426, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 470, train_loss = 0.9736420884728432, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 471, train_loss = 0.9742828235030174, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 472, train_loss = 0.9740303282960667, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 473, train_loss = 0.9740370536819682, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 474, train_loss = 0.9733669298366294, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 475, train_loss = 0.973339839525579, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 476, train_loss = 0.9720429529770627, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 477, train_loss = 0.9725702740252018, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 478, train_loss = 0.9716968946158886, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 479, train_loss = 0.9715272883549915, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 480, train_loss = 0.9722077486439957, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 481, train_loss = 0.9712407266124501, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 482, train_loss = 0.9705261786803021, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 483, train_loss = 0.9716990316883312, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 484, train_loss = 0.9705982717350707, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 485, train_loss = 0.9696871414780617, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 486, train_loss = 0.9699342126623378, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 487, train_loss = 0.9697785538955941, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 488, train_loss = 0.9685219402090297, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 489, train_loss = 0.9701266984120593, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 490, train_loss = 0.9687713347375393, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 491, train_loss = 0.9685957419351325, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 492, train_loss = 0.9683475742713199, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 493, train_loss = 0.9680074428542866, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 494, train_loss = 0.967265864215733, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 495, train_loss = 0.9675034532920108, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 496, train_loss = 0.9671682243570103, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 497, train_loss = 0.9672929135485901, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 498, train_loss = 0.9669820057824836, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 499, train_loss = 0.966907188296318, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|██████████▌                                                                    | 4/30 [36:13<3:55:35, 543.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "5th- epoch: 0, train_loss = 343.2602571598254, train_acc = 0.8183511877037727\n",
      "test Acc 0.9064245810055865:\n",
      "5th- epoch: 1, train_loss = 94.14536420005606, train_acc = 0.9217512808570097\n",
      "test Acc 0.9292364990689013:\n",
      "5th- epoch: 2, train_loss = 58.25858826440526, train_acc = 0.9451560316721006\n",
      "test Acc 0.9315642458100558:\n",
      "5th- epoch: 3, train_loss = 41.30551262696099, train_acc = 0.9591290172333489\n",
      "test Acc 0.9366852886405959:\n",
      "5th- epoch: 4, train_loss = 30.91948378831148, train_acc = 0.9679785747554728\n",
      "test Acc 0.9380819366852886:\n",
      "5th- epoch: 5, train_loss = 24.226959016174078, train_acc = 0.9732184443409408\n",
      "test Acc 0.9366852886405959:\n",
      "5th- epoch: 6, train_loss = 19.12405874079559, train_acc = 0.9777596646483465\n",
      "test Acc 0.9366852886405959:\n",
      "5th- epoch: 7, train_loss = 15.296914234757423, train_acc = 0.9810200279459711\n",
      "test Acc 0.9366852886405959:\n",
      "5th- epoch: 8, train_loss = 12.452364303171635, train_acc = 0.9838146250582208\n",
      "test Acc 0.9376163873370578:\n",
      "5th- epoch: 9, train_loss = 10.312969277263619, train_acc = 0.9853283651606893\n",
      "test Acc 0.9413407821229051:\n",
      "5th- epoch: 10, train_loss = 8.65336410945747, train_acc = 0.9877736376339078\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 11, train_loss = 7.405940306663979, train_acc = 0.9888216115510013\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 12, train_loss = 6.440570698410738, train_acc = 0.989869585468095\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 13, train_loss = 5.682221438095439, train_acc = 0.99033535165347\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 14, train_loss = 5.022384954616427, train_acc = 0.9914997671169073\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 15, train_loss = 4.457699018239509, train_acc = 0.9926641825803446\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 16, train_loss = 4.031132751435507, train_acc = 0.9930135072193759\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 17, train_loss = 3.6710454548010603, train_acc = 0.9932463903120633\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 18, train_loss = 3.362166921258904, train_acc = 0.9934792734047508\n",
      "test Acc 0.9506517690875232:\n",
      "5th- epoch: 19, train_loss = 3.098658631904982, train_acc = 0.993828598043782\n",
      "test Acc 0.9515828677839852:\n",
      "5th- epoch: 20, train_loss = 2.865243073552847, train_acc = 0.994294364229157\n",
      "test Acc 0.9529795158286778:\n",
      "5th- epoch: 21, train_loss = 2.6912013633409515, train_acc = 0.9951094550535631\n",
      "test Acc 0.9534450651769087:\n",
      "5th- epoch: 22, train_loss = 2.549758930457756, train_acc = 0.9952258965999069\n",
      "test Acc 0.9539106145251397:\n",
      "5th- epoch: 23, train_loss = 2.435760659398511, train_acc = 0.9952258965999069\n",
      "test Acc 0.9543761638733705:\n",
      "5th- epoch: 24, train_loss = 2.331551469163969, train_acc = 0.9954587796925943\n",
      "test Acc 0.9543761638733705:\n",
      "5th- epoch: 25, train_loss = 2.2402811080683023, train_acc = 0.995575221238938\n",
      "test Acc 0.9543761638733705:\n",
      "5th- epoch: 26, train_loss = 2.1577430434990674, train_acc = 0.995575221238938\n",
      "test Acc 0.9548417132216015:\n",
      "5th- epoch: 27, train_loss = 2.074967809021473, train_acc = 0.995575221238938\n",
      "test Acc 0.9548417132216015:\n",
      "5th- epoch: 28, train_loss = 1.9976994760800153, train_acc = 0.995575221238938\n",
      "test Acc 0.9553072625698324:\n",
      "5th- epoch: 29, train_loss = 1.934892990393564, train_acc = 0.995575221238938\n",
      "test Acc 0.9557728119180633:\n",
      "5th- epoch: 30, train_loss = 1.864416955737397, train_acc = 0.9956916627852818\n",
      "test Acc 0.9557728119180633:\n",
      "5th- epoch: 31, train_loss = 1.8106719595380127, train_acc = 0.9956916627852818\n",
      "test Acc 0.9557728119180633:\n",
      "5th- epoch: 32, train_loss = 1.7568587951827794, train_acc = 0.9958081043316255\n",
      "test Acc 0.9557728119180633:\n",
      "5th- epoch: 33, train_loss = 1.7143892359454185, train_acc = 0.9959245458779693\n",
      "test Acc 0.9557728119180633:\n",
      "5th- epoch: 34, train_loss = 1.6755139257293195, train_acc = 0.996040987424313\n",
      "test Acc 0.9557728119180633:\n",
      "5th- epoch: 35, train_loss = 1.6371225130278617, train_acc = 0.996040987424313\n",
      "test Acc 0.9557728119180633:\n",
      "5th- epoch: 36, train_loss = 1.6069656845647842, train_acc = 0.9963903120633442\n",
      "test Acc 0.9557728119180633:\n",
      "5th- epoch: 37, train_loss = 1.5798992190975696, train_acc = 0.9963903120633442\n",
      "test Acc 0.9562383612662942:\n",
      "5th- epoch: 38, train_loss = 1.5529402170795947, train_acc = 0.996506753609688\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 39, train_loss = 1.532832495868206, train_acc = 0.996506753609688\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 40, train_loss = 1.5120486989617348, train_acc = 0.9966231951560317\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 41, train_loss = 1.4965320725459605, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 42, train_loss = 1.4834770660381764, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 43, train_loss = 1.4702019281685352, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 44, train_loss = 1.4570402342360467, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 45, train_loss = 1.446995196165517, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 46, train_loss = 1.437095301807858, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 47, train_loss = 1.4259682236006483, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 48, train_loss = 1.4189205119619146, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 49, train_loss = 1.409041258157231, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 50, train_loss = 1.4021135593065992, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 51, train_loss = 1.3915839804103598, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 52, train_loss = 1.3848424317548051, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 53, train_loss = 1.3781206794083118, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 54, train_loss = 1.37216319644358, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 55, train_loss = 1.3653395945439115, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 56, train_loss = 1.3599766691913828, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 57, train_loss = 1.353485862375237, train_acc = 0.9969725197950629\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 58, train_loss = 1.348373632878065, train_acc = 0.9969725197950629\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 59, train_loss = 1.3434941992163658, train_acc = 0.9969725197950629\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 60, train_loss = 1.3376269614091143, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 61, train_loss = 1.3322466859826818, train_acc = 0.9968560782487191\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 62, train_loss = 1.328767710714601, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 63, train_loss = 1.3225278382888064, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 64, train_loss = 1.3175206942250952, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 65, train_loss = 1.3137356949737296, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 66, train_loss = 1.3082267455756664, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 67, train_loss = 1.3035080010304227, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 68, train_loss = 1.3002453210065141, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 69, train_loss = 1.2950318902730942, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 70, train_loss = 1.2920161274960265, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 71, train_loss = 1.2849763296544552, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 72, train_loss = 1.2773936154553667, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 73, train_loss = 1.2749077565968037, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 74, train_loss = 1.271277933032252, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 75, train_loss = 1.2683420379762538, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 76, train_loss = 1.2645560664241202, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 77, train_loss = 1.2621316301519983, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 78, train_loss = 1.2567098873551004, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 79, train_loss = 1.2548632224206813, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 80, train_loss = 1.2518607713282108, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 81, train_loss = 1.248947097628843, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 82, train_loss = 1.2466933143441565, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 83, train_loss = 1.2419094133074395, train_acc = 0.9967396367023754\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 84, train_loss = 1.2385167814791203, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 85, train_loss = 1.2366515274043195, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 86, train_loss = 1.2335304853622802, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 87, train_loss = 1.2312071844935417, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 88, train_loss = 1.2267831824719906, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 89, train_loss = 1.2252393613453023, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 90, train_loss = 1.2230446115136147, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 91, train_loss = 1.2206771683995612, train_acc = 0.9967396367023754\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 92, train_loss = 1.216767466336023, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 93, train_loss = 1.2159077885444276, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 94, train_loss = 1.2136442798073404, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 95, train_loss = 1.2116397631471045, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 96, train_loss = 1.2088205156032927, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 97, train_loss = 1.2063225681777112, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 98, train_loss = 1.2044392104144208, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 99, train_loss = 1.2021303598885424, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 100, train_loss = 1.2000872194766998, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 101, train_loss = 1.1972538456320763, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 102, train_loss = 1.1959701317246072, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 103, train_loss = 1.1934220008552074, train_acc = 0.9967396367023754\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 104, train_loss = 1.1904516629874706, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 105, train_loss = 1.1888359561562538, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 106, train_loss = 1.1850080825388432, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 107, train_loss = 1.182858232408762, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 108, train_loss = 1.178595521778334, train_acc = 0.9969725197950629\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 109, train_loss = 1.1778303384780884, train_acc = 0.9969725197950629\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 110, train_loss = 1.175960308581125, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 111, train_loss = 1.1730826472048648, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 112, train_loss = 1.171058343083132, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 113, train_loss = 1.1693982742726803, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 114, train_loss = 1.1673992673750035, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 115, train_loss = 1.1669530992512591, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 116, train_loss = 1.1643950032885186, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 117, train_loss = 1.1624540500342846, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 118, train_loss = 1.1608093368413392, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 119, train_loss = 1.1592287470994052, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 120, train_loss = 1.1584811458887998, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 121, train_loss = 1.1566257886588573, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 122, train_loss = 1.1544646161200944, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 123, train_loss = 1.152969983726507, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 124, train_loss = 1.1511182511749212, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 125, train_loss = 1.1504394983348902, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 126, train_loss = 1.1488307677209377, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 127, train_loss = 1.1468246430158615, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 128, train_loss = 1.145658669382101, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 129, train_loss = 1.1446649754943792, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 130, train_loss = 1.1427186764776707, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 131, train_loss = 1.141786308347946, train_acc = 0.9968560782487191\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 132, train_loss = 1.1402169366774615, train_acc = 0.9969725197950629\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 133, train_loss = 1.139234084635973, train_acc = 0.9969725197950629\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 134, train_loss = 1.1370345912873745, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 135, train_loss = 1.135045556962723, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 136, train_loss = 1.1342439899744932, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 137, train_loss = 1.1324393028917257, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 138, train_loss = 1.1317385906877462, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 139, train_loss = 1.1312535740435123, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 140, train_loss = 1.12824490541243, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 141, train_loss = 1.1268028542399406, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 142, train_loss = 1.1257216657104436, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 143, train_loss = 1.1247804115118925, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 144, train_loss = 1.1235641638340894, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 145, train_loss = 1.1216157749295235, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 146, train_loss = 1.1211213568749372, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 147, train_loss = 1.1200518993136939, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 148, train_loss = 1.1186508337559644, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 149, train_loss = 1.117510406911606, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 150, train_loss = 1.1154434233903885, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 151, train_loss = 1.1160154206154402, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 152, train_loss = 1.114485427737236, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 153, train_loss = 1.1133623123168945, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 154, train_loss = 1.111524198204279, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 155, train_loss = 1.1107140915992204, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 156, train_loss = 1.1097752153873444, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 157, train_loss = 1.1088619033398572, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 158, train_loss = 1.1079508115944918, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 159, train_loss = 1.1074956891534384, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 160, train_loss = 1.1053505378367845, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 161, train_loss = 1.1061548764409963, train_acc = 0.9970889613414066\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 162, train_loss = 1.1037951918842737, train_acc = 0.9970889613414066\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 163, train_loss = 1.1038143746554852, train_acc = 0.9970889613414066\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 164, train_loss = 1.1025902455148753, train_acc = 0.9970889613414066\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 165, train_loss = 1.1008096536097582, train_acc = 0.9970889613414066\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 166, train_loss = 1.099944553017849, train_acc = 0.9970889613414066\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 167, train_loss = 1.0996958451869432, train_acc = 0.9970889613414066\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 168, train_loss = 1.0983735732734203, train_acc = 0.9970889613414066\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 169, train_loss = 1.0973563157022, train_acc = 0.9970889613414066\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 170, train_loss = 1.0965584603545722, train_acc = 0.9970889613414066\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 171, train_loss = 1.096609577536583, train_acc = 0.9970889613414066\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 172, train_loss = 1.0941837342979852, train_acc = 0.9972054028877504\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 173, train_loss = 1.0947363687155303, train_acc = 0.9972054028877504\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 174, train_loss = 1.0928096075949725, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 175, train_loss = 1.0931449569761753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 176, train_loss = 1.091258523374563, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 177, train_loss = 1.0904417000710964, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 178, train_loss = 1.0892659487726633, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 179, train_loss = 1.088991100579733, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 180, train_loss = 1.0883383726177271, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 181, train_loss = 1.0882857578399125, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 182, train_loss = 1.0862806340155657, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 183, train_loss = 1.0860074746015016, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 184, train_loss = 1.0853907925484236, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 185, train_loss = 1.0844827493128832, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 186, train_loss = 1.083662237972021, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 187, train_loss = 1.0836466973123606, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 188, train_loss = 1.0818085434439126, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 189, train_loss = 1.0815415518882219, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 190, train_loss = 1.0821559776959475, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 191, train_loss = 1.0800995342433453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 192, train_loss = 1.0791399193403777, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 193, train_loss = 1.0786399357020855, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 194, train_loss = 1.0785803931357805, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 195, train_loss = 1.0776635060610715, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 196, train_loss = 1.0763318935933057, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 197, train_loss = 1.0758939186634962, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 198, train_loss = 1.0747660286724567, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 199, train_loss = 1.0743004071118776, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 200, train_loss = 1.0745955134334508, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 201, train_loss = 1.0734200477600098, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 202, train_loss = 1.0723296801152173, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 203, train_loss = 1.0716321915388107, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 204, train_loss = 1.0720871475932654, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 205, train_loss = 1.0708442901668604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 206, train_loss = 1.0702602739038412, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 207, train_loss = 1.0691887065768242, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 208, train_loss = 1.0700413907470647, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 209, train_loss = 1.0678519966604654, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 210, train_loss = 1.0673393098113593, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 211, train_loss = 1.0668630537984427, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 212, train_loss = 1.0668348955514375, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 213, train_loss = 1.0659996159374714, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 214, train_loss = 1.065369619667763, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 215, train_loss = 1.064235412835842, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 216, train_loss = 1.065233912318945, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 217, train_loss = 1.063060191780096, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 218, train_loss = 1.063341493398184, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 219, train_loss = 1.0622996799647808, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 220, train_loss = 1.0622309297323227, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 221, train_loss = 1.0608736748399679, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 222, train_loss = 1.0614537211658899, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 223, train_loss = 1.0599746890366077, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 224, train_loss = 1.0601259122195188, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 225, train_loss = 1.058333254099125, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 226, train_loss = 1.0586305161414202, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 227, train_loss = 1.0585716428759042, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 228, train_loss = 1.057394818722969, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 229, train_loss = 1.0565851417777594, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 230, train_loss = 1.0565437028708402, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 231, train_loss = 1.055696777999401, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 232, train_loss = 1.0546592945756856, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 233, train_loss = 1.054725557565689, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 234, train_loss = 1.0545458843407687, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 235, train_loss = 1.0532931983470917, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 236, train_loss = 1.0531518571078777, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 237, train_loss = 1.0524421458540019, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 238, train_loss = 1.0520198357698973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 239, train_loss = 1.0518801175057888, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 240, train_loss = 1.0510457617638167, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 241, train_loss = 1.0507437934575137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 242, train_loss = 1.0503861457109451, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 243, train_loss = 1.0496342927217484, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 244, train_loss = 1.0486042176635237, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 245, train_loss = 1.0486078846006421, train_acc = 0.9973218444340941\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 246, train_loss = 1.0483157498092623, train_acc = 0.9973218444340941\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 247, train_loss = 1.047676442816737, train_acc = 0.9973218444340941\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 248, train_loss = 1.0467578346579103, train_acc = 0.9973218444340941\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 249, train_loss = 1.04657547424722, train_acc = 0.9973218444340941\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 250, train_loss = 1.0460519840271445, train_acc = 0.9973218444340941\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 251, train_loss = 1.0458462871611118, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 252, train_loss = 1.0451921920030145, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 253, train_loss = 1.0449900639505358, train_acc = 0.9975547275267815\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 254, train_loss = 1.0436973050236702, train_acc = 0.9976711690731253\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 255, train_loss = 1.0440074379293947, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 256, train_loss = 1.0431650653481483, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 257, train_loss = 1.0424968525767326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 258, train_loss = 1.0424980359821348, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 259, train_loss = 1.0418419266788987, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 260, train_loss = 1.0416608030645875, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 261, train_loss = 1.0415699097065954, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 262, train_loss = 1.040204240634921, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 263, train_loss = 1.0400872242898913, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 264, train_loss = 1.0396547242999077, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 265, train_loss = 1.0386820236890344, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 266, train_loss = 1.0385394468903542, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 267, train_loss = 1.038599925741437, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 268, train_loss = 1.0380374230444431, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 269, train_loss = 1.0371165958495112, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 270, train_loss = 1.036923514053342, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 271, train_loss = 1.036142482116702, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 272, train_loss = 1.0353534556925297, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 273, train_loss = 1.0358330979943275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 274, train_loss = 1.0351129658520222, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 275, train_loss = 1.0344618720264407, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 276, train_loss = 1.034330628812313, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 277, train_loss = 1.0348596721887589, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 278, train_loss = 1.0336155245749978, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 279, train_loss = 1.0325830727815628, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 280, train_loss = 1.0324364664702443, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 281, train_loss = 1.0320184218435315, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 282, train_loss = 1.0316043446509866, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 283, train_loss = 1.031092065080884, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 284, train_loss = 1.0312294028699398, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 285, train_loss = 1.0308696553111076, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 286, train_loss = 1.0297715105116367, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 287, train_loss = 1.029508342340705, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 288, train_loss = 1.0287386973650428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 289, train_loss = 1.028378979608533, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 290, train_loss = 1.0284246963710757, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 291, train_loss = 1.0283823857753305, train_acc = 0.9977876106194691\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 292, train_loss = 1.0278113633394241, train_acc = 0.9977876106194691\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 293, train_loss = 1.0272196593432454, train_acc = 0.9977876106194691\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 294, train_loss = 1.026572447270155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 295, train_loss = 1.026128845915082, train_acc = 0.9977876106194691\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 296, train_loss = 1.0254597800521879, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 297, train_loss = 1.0255236513912678, train_acc = 0.9977876106194691\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 298, train_loss = 1.025126077234745, train_acc = 0.9977876106194691\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 299, train_loss = 1.0249331941158744, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 300, train_loss = 1.024734063699725, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 301, train_loss = 1.023844966039178, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 302, train_loss = 1.0233822253794642, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 303, train_loss = 1.0228735990822315, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 304, train_loss = 1.0230362800211878, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 305, train_loss = 1.0226970377116231, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 306, train_loss = 1.0220251505525084, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 307, train_loss = 1.0211507727653952, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 308, train_loss = 1.0210795775055885, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 309, train_loss = 1.0205812975764275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 310, train_loss = 1.0199435042886762, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 311, train_loss = 1.0195568054914474, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 312, train_loss = 1.019900785133359, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 313, train_loss = 1.0196515073330374, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 314, train_loss = 1.0190735148935346, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 315, train_loss = 1.0185858011245728, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 316, train_loss = 1.0177297927439213, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 317, train_loss = 1.0173609244375257, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 318, train_loss = 1.0181484955101041, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 319, train_loss = 1.0167901453824015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 320, train_loss = 1.016488816589117, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 321, train_loss = 1.015945537641528, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 322, train_loss = 1.0161648516805144, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 323, train_loss = 1.0149118155241013, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 324, train_loss = 1.0148561124951812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 325, train_loss = 1.0156096704304218, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 326, train_loss = 1.0141488201916218, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 327, train_loss = 1.0135177820920944, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 328, train_loss = 1.0138257232756587, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 329, train_loss = 1.0134499395935563, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 330, train_loss = 1.0130046022386523, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 331, train_loss = 1.012861584618804, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 332, train_loss = 1.012121235326049, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 333, train_loss = 1.011680118739605, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 334, train_loss = 1.0114789418876171, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 335, train_loss = 1.0111317858099937, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 336, train_loss = 1.0109000888915034, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 337, train_loss = 1.0104610435664654, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 338, train_loss = 1.0097259283065796, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 339, train_loss = 1.0093166480510263, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 340, train_loss = 1.0097282653005095, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 341, train_loss = 1.0088465052394895, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 342, train_loss = 1.0087996100337477, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 343, train_loss = 1.0083882808685303, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 344, train_loss = 1.0078317473380594, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 345, train_loss = 1.0072570939810248, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 346, train_loss = 1.0070850240736036, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 347, train_loss = 1.0070985443890095, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 348, train_loss = 1.0069924481213093, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 349, train_loss = 1.006872960671899, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 350, train_loss = 1.0055179831833811, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 351, train_loss = 1.0051935675292043, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 352, train_loss = 1.005180612206459, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 353, train_loss = 1.0051397892384557, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 354, train_loss = 1.0051660885364981, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 355, train_loss = 1.0043144201190444, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 356, train_loss = 1.0038483726530103, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 357, train_loss = 1.0035969937889604, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 358, train_loss = 1.0030296954064397, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 359, train_loss = 1.0026966892182827, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 360, train_loss = 1.002803357943776, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 361, train_loss = 1.0023768097162247, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 362, train_loss = 1.0018656266183825, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 363, train_loss = 1.0014835769979982, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 364, train_loss = 1.0014676712453365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 365, train_loss = 1.0011705942451954, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 366, train_loss = 1.000666867941618, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 367, train_loss = 1.000664616629365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 368, train_loss = 1.0001019674091367, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 369, train_loss = 0.9994734860956669, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 370, train_loss = 0.9995135776698589, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 371, train_loss = 0.9990699253976345, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 372, train_loss = 0.9985938891768456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 373, train_loss = 0.9982321374118328, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 374, train_loss = 0.9982447984366445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 375, train_loss = 0.9976831314415904, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 376, train_loss = 0.9976825366466073, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 377, train_loss = 0.9976691181509523, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 378, train_loss = 0.9962373698799638, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 379, train_loss = 0.9962493603379698, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 380, train_loss = 0.9968580466957064, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 381, train_loss = 0.9954725851566764, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 382, train_loss = 0.9954368894250365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 383, train_loss = 0.9955856849701377, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 384, train_loss = 0.9950242874474498, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 385, train_loss = 0.9951357779355021, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 386, train_loss = 0.9942000185401412, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 387, train_loss = 0.9938101284205914, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 388, train_loss = 0.9939680173993111, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 389, train_loss = 0.9936058546154527, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 390, train_loss = 0.992863851293805, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 391, train_loss = 0.9926935819239588, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 392, train_loss = 0.9922927853913279, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 393, train_loss = 0.9920929223299026, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 394, train_loss = 0.9922139284462901, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 395, train_loss = 0.991227733597043, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 396, train_loss = 0.9911801430134801, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 397, train_loss = 0.9910782190709142, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 398, train_loss = 0.9905146509408951, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 399, train_loss = 0.9903478908090619, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 400, train_loss = 0.9901798864157172, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 401, train_loss = 0.9896547632961301, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 402, train_loss = 0.9894297483115224, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 403, train_loss = 0.9890959026961355, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 404, train_loss = 0.9887416400015354, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 405, train_loss = 0.9888136436493369, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 406, train_loss = 0.988163794085267, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 407, train_loss = 0.9876937965600519, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 408, train_loss = 0.9876375782041578, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 409, train_loss = 0.9871048356144456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 410, train_loss = 0.987301463886979, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 411, train_loss = 0.9867251117975684, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 412, train_loss = 0.9870319155306788, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 413, train_loss = 0.9866104895918397, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 414, train_loss = 0.9855263878853293, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 415, train_loss = 0.9855661690235138, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 416, train_loss = 0.9851256161928177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 417, train_loss = 0.9846217520534992, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 418, train_loss = 0.9845704212784767, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 419, train_loss = 0.9845195934176445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 420, train_loss = 0.9842997615487548, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 421, train_loss = 0.984196928635356, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 422, train_loss = 0.9833670283405809, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 423, train_loss = 0.9835144629032584, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 424, train_loss = 0.9830535613000393, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 425, train_loss = 0.9825240398495225, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 426, train_loss = 0.9820616183133097, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 427, train_loss = 0.9818373446614714, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 428, train_loss = 0.9821152786462335, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 429, train_loss = 0.981815246239421, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 430, train_loss = 0.9810889077634783, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 431, train_loss = 0.9812179990112782, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 432, train_loss = 0.9806990933866473, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 433, train_loss = 0.9806807761342498, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 434, train_loss = 0.9803987319319276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 435, train_loss = 0.9801250236778287, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 436, train_loss = 0.9795237382204505, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 437, train_loss = 0.9797114009707002, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 438, train_loss = 0.9784807898104191, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 439, train_loss = 0.9784216644911794, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 440, train_loss = 0.978663694113493, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 441, train_loss = 0.9785683341324329, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 442, train_loss = 0.978586483746767, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 443, train_loss = 0.9779657435865374, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 444, train_loss = 0.9773173568100901, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 445, train_loss = 0.9769633350224467, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 446, train_loss = 0.977802054330823, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 447, train_loss = 0.9767888821661472, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 448, train_loss = 0.976211354136467, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 449, train_loss = 0.9767512654216262, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 450, train_loss = 0.9765107830316992, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 451, train_loss = 0.976097604885581, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 452, train_loss = 0.9751215316355228, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 453, train_loss = 0.9747921116650105, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 454, train_loss = 0.9752801780850859, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 455, train_loss = 0.974574784442666, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 456, train_loss = 0.9748720203788253, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 457, train_loss = 0.9742945407779189, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 458, train_loss = 0.973874149218318, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 459, train_loss = 0.9740101806819439, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 460, train_loss = 0.9735548359603854, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 461, train_loss = 0.9731622276158305, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 462, train_loss = 0.9726485051214695, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 463, train_loss = 0.9728225233702688, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 464, train_loss = 0.9729566226451425, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 465, train_loss = 0.9723064179270295, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 466, train_loss = 0.97182606284332, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 467, train_loss = 0.9721256730408641, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 468, train_loss = 0.9716225452721119, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 469, train_loss = 0.9708227378578158, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 470, train_loss = 0.9707170675246743, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 471, train_loss = 0.970853216946125, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 472, train_loss = 0.970687045410159, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 473, train_loss = 0.9707375007419614, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 474, train_loss = 0.9704157834203215, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 475, train_loss = 0.9701632795186015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 476, train_loss = 0.9695454128086567, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 477, train_loss = 0.9691416124551324, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 478, train_loss = 0.9690231581480475, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 479, train_loss = 0.9690891678183107, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 480, train_loss = 0.9689874226896791, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 481, train_loss = 0.9682092989532975, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 482, train_loss = 0.9679086481482955, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 483, train_loss = 0.9679661132395267, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 484, train_loss = 0.9682940095663071, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 485, train_loss = 0.9671069420874119, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 486, train_loss = 0.9667978733778, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 487, train_loss = 0.966922986015561, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 488, train_loss = 0.9665807175188093, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 489, train_loss = 0.9664999904780416, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 490, train_loss = 0.966271294906619, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 491, train_loss = 0.9661691759974929, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 492, train_loss = 0.9659409287123708, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 493, train_loss = 0.9650342141540023, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 494, train_loss = 0.965185762688634, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 495, train_loss = 0.9650828825979261, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 496, train_loss = 0.9651323656289605, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 497, train_loss = 0.9642069699912099, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 498, train_loss = 0.9642957113683224, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 499, train_loss = 0.9648659527301788, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█████████████▏                                                                 | 5/30 [45:15<3:46:18, 543.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "6th- epoch: 0, train_loss = 360.4026316702366, train_acc = 0.8071727992547741\n",
      "test Acc 0.8924581005586593:\n",
      "6th- epoch: 1, train_loss = 86.3103583852353, train_acc = 0.9223334885887284\n",
      "test Acc 0.9222532588454376:\n",
      "6th- epoch: 2, train_loss = 53.09013032045914, train_acc = 0.9494643688868188\n",
      "test Acc 0.9343575418994413:\n",
      "6th- epoch: 3, train_loss = 36.63157640770078, train_acc = 0.9581974848625989\n",
      "test Acc 0.9338919925512105:\n",
      "6th- epoch: 4, train_loss = 26.60162947839126, train_acc = 0.9677456916627852\n",
      "test Acc 0.9343575418994413:\n",
      "6th- epoch: 5, train_loss = 20.17453049006872, train_acc = 0.9738006520726595\n",
      "test Acc 0.9366852886405959:\n",
      "6th- epoch: 6, train_loss = 15.700289910077117, train_acc = 0.9788076385654402\n",
      "test Acc 0.9408752327746741:\n",
      "6th- epoch: 7, train_loss = 12.58627087122295, train_acc = 0.9823008849557522\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 8, train_loss = 10.322788901627064, train_acc = 0.9848625989753144\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 9, train_loss = 8.628433396457694, train_acc = 0.9871914299021891\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 10, train_loss = 7.336469733447302, train_acc = 0.9883558453656265\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 11, train_loss = 6.362112359434832, train_acc = 0.989869585468095\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 12, train_loss = 5.542001885653008, train_acc = 0.9912668840242198\n",
      "test Acc 0.9511173184357542:\n",
      "6th- epoch: 13, train_loss = 4.881816256791353, train_acc = 0.9914997671169073\n",
      "test Acc 0.9515828677839852:\n",
      "6th- epoch: 14, train_loss = 4.278856565535534, train_acc = 0.9916162086632511\n",
      "test Acc 0.9529795158286778:\n",
      "6th- epoch: 15, train_loss = 3.7905378080904484, train_acc = 0.9927806241266884\n",
      "test Acc 0.9548417132216015:\n",
      "6th- epoch: 16, train_loss = 3.403153238206869, train_acc = 0.9933628318584071\n",
      "test Acc 0.9548417132216015:\n",
      "6th- epoch: 17, train_loss = 3.084293300897116, train_acc = 0.9940614811364695\n",
      "test Acc 0.9553072625698324:\n",
      "6th- epoch: 18, train_loss = 2.8182618506252766, train_acc = 0.9941779226828132\n",
      "test Acc 0.9562383612662942:\n",
      "6th- epoch: 19, train_loss = 2.624835606664419, train_acc = 0.994294364229157\n",
      "test Acc 0.9567039106145251:\n",
      "6th- epoch: 20, train_loss = 2.4550032218394335, train_acc = 0.9946436888681882\n",
      "test Acc 0.957635009310987:\n",
      "6th- epoch: 21, train_loss = 2.3266132660210133, train_acc = 0.9949930135072194\n",
      "test Acc 0.957635009310987:\n",
      "6th- epoch: 22, train_loss = 2.187046319246292, train_acc = 0.9949930135072194\n",
      "test Acc 0.9567039106145251:\n",
      "6th- epoch: 23, train_loss = 2.0983079833386, train_acc = 0.9952258965999069\n",
      "test Acc 0.957169459962756:\n",
      "6th- epoch: 24, train_loss = 1.9997260781528894, train_acc = 0.9952258965999069\n",
      "test Acc 0.957169459962756:\n",
      "6th- epoch: 25, train_loss = 1.9448631207051221, train_acc = 0.9952258965999069\n",
      "test Acc 0.957169459962756:\n",
      "6th- epoch: 26, train_loss = 1.8678043571708258, train_acc = 0.9952258965999069\n",
      "test Acc 0.9567039106145251:\n",
      "6th- epoch: 27, train_loss = 1.8198511525988579, train_acc = 0.9952258965999069\n",
      "test Acc 0.9585661080074488:\n",
      "6th- epoch: 28, train_loss = 1.781853905558819, train_acc = 0.9952258965999069\n",
      "test Acc 0.9585661080074488:\n",
      "6th- epoch: 29, train_loss = 1.7409963496029377, train_acc = 0.9954587796925943\n",
      "test Acc 0.9581005586592178:\n",
      "6th- epoch: 30, train_loss = 1.7110883320274297, train_acc = 0.995575221238938\n",
      "test Acc 0.9590316573556797:\n",
      "6th- epoch: 31, train_loss = 1.6663238803448621, train_acc = 0.9958081043316255\n",
      "test Acc 0.9590316573556797:\n",
      "6th- epoch: 32, train_loss = 1.6455107145011425, train_acc = 0.9956916627852818\n",
      "test Acc 0.9581005586592178:\n",
      "6th- epoch: 33, train_loss = 1.6164009633066598, train_acc = 0.9958081043316255\n",
      "test Acc 0.9590316573556797:\n",
      "6th- epoch: 34, train_loss = 1.5906257654278306, train_acc = 0.9958081043316255\n",
      "test Acc 0.9585661080074488:\n",
      "6th- epoch: 35, train_loss = 1.5725013477203902, train_acc = 0.996040987424313\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 36, train_loss = 1.5498321875929832, train_acc = 0.9959245458779693\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 37, train_loss = 1.5361666927783517, train_acc = 0.9961574289706567\n",
      "test Acc 0.9585661080074488:\n",
      "6th- epoch: 38, train_loss = 1.5174326462001773, train_acc = 0.9961574289706567\n",
      "test Acc 0.9585661080074488:\n",
      "6th- epoch: 39, train_loss = 1.5043364030570956, train_acc = 0.9961574289706567\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 40, train_loss = 1.4822805213480024, train_acc = 0.9961574289706567\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 41, train_loss = 1.4681193505675765, train_acc = 0.9962738705170004\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 42, train_loss = 1.459596903368947, train_acc = 0.9961574289706567\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 43, train_loss = 1.450381333634141, train_acc = 0.9962738705170004\n",
      "test Acc 0.9604283054003724:\n",
      "6th- epoch: 44, train_loss = 1.429139405488968, train_acc = 0.9962738705170004\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 45, train_loss = 1.4244223448185949, train_acc = 0.9962738705170004\n",
      "test Acc 0.9590316573556797:\n",
      "6th- epoch: 46, train_loss = 1.4143513167946367, train_acc = 0.9961574289706567\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 47, train_loss = 1.4019474051892757, train_acc = 0.9961574289706567\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 48, train_loss = 1.3937430034129648, train_acc = 0.996506753609688\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 49, train_loss = 1.3857993644924136, train_acc = 0.9961574289706567\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 50, train_loss = 1.3726163618266582, train_acc = 0.9966231951560317\n",
      "test Acc 0.9590316573556797:\n",
      "6th- epoch: 51, train_loss = 1.3693916040210752, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 52, train_loss = 1.3600515971629648, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 53, train_loss = 1.3510673890559701, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 54, train_loss = 1.3433567260653945, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 55, train_loss = 1.3407345066516427, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 56, train_loss = 1.3287612323911162, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "6th- epoch: 57, train_loss = 1.3261989454476861, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "6th- epoch: 58, train_loss = 1.3170371477754088, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 59, train_loss = 1.3127839105873136, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "6th- epoch: 60, train_loss = 1.306151585027692, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 61, train_loss = 1.3001624618918868, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 62, train_loss = 1.2976124261767836, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 63, train_loss = 1.2874873392283916, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "6th- epoch: 64, train_loss = 1.287066510572913, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "6th- epoch: 65, train_loss = 1.2764949972479371, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "6th- epoch: 66, train_loss = 1.2772716134786606, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 67, train_loss = 1.2679741866886616, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 68, train_loss = 1.2674654039292363, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 69, train_loss = 1.2588848720042733, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 70, train_loss = 1.2614775610418292, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 71, train_loss = 1.2521802460105391, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 72, train_loss = 1.251602781310794, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 73, train_loss = 1.2447760713548632, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 74, train_loss = 1.2411094556300668, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 75, train_loss = 1.2365532629191875, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 76, train_loss = 1.2322110123932362, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 77, train_loss = 1.2287320258765249, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 78, train_loss = 1.2262130069284467, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 79, train_loss = 1.22517882163811, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 80, train_loss = 1.2192845568060875, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 81, train_loss = 1.2159657490701647, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 82, train_loss = 1.2132368969469098, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 83, train_loss = 1.211887463927269, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 84, train_loss = 1.2088938653469086, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 85, train_loss = 1.2062052761466475, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 86, train_loss = 1.2030623306782218, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 87, train_loss = 1.2005373959691497, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 88, train_loss = 1.198636865869048, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 89, train_loss = 1.1979542635381222, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 90, train_loss = 1.1940947162656812, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 91, train_loss = 1.1923839822411537, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 92, train_loss = 1.1899293822498294, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 93, train_loss = 1.18729701389384, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 94, train_loss = 1.1861983041017083, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 95, train_loss = 1.1832639065833064, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 96, train_loss = 1.182006873190403, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 97, train_loss = 1.1790903645305661, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 98, train_loss = 1.1765912063419819, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 99, train_loss = 1.1760549110622378, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 100, train_loss = 1.173501268029213, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 101, train_loss = 1.1723591623158427, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 102, train_loss = 1.1719741163105937, train_acc = 0.9968560782487191\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 103, train_loss = 1.168910684682487, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 104, train_loss = 1.168012261390686, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 105, train_loss = 1.1671220945790992, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 106, train_loss = 1.1646640188992023, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 107, train_loss = 1.1632128208875656, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 108, train_loss = 1.1616868488490582, train_acc = 0.9970889613414066\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 109, train_loss = 1.160464994609356, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 110, train_loss = 1.1582857271059765, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 111, train_loss = 1.1571277851835475, train_acc = 0.9969725197950629\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 112, train_loss = 1.155823290348053, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 113, train_loss = 1.1549608521163464, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 114, train_loss = 1.1542855674997554, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 115, train_loss = 1.1517287927345023, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 116, train_loss = 1.1503071871920838, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 117, train_loss = 1.148627423994185, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 118, train_loss = 1.1491598176435218, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 119, train_loss = 1.146657225988747, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 120, train_loss = 1.1456126806660905, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 121, train_loss = 1.1443990468978882, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 122, train_loss = 1.1422046720981598, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 123, train_loss = 1.1406103471890674, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 124, train_loss = 1.1414238723591552, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 125, train_loss = 1.1402171192094102, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 126, train_loss = 1.1382042902187095, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 127, train_loss = 1.136690378189087, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 128, train_loss = 1.136338344462274, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 129, train_loss = 1.135130545742868, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 130, train_loss = 1.1344432458281517, train_acc = 0.9973218444340941\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 131, train_loss = 1.1327030720785842, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 132, train_loss = 1.1316012851893902, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 133, train_loss = 1.130320084594132, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 134, train_loss = 1.1292666904628277, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 135, train_loss = 1.1287890449166298, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 136, train_loss = 1.1285323041156516, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 137, train_loss = 1.1257990176454769, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 138, train_loss = 1.1253311124964966, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 139, train_loss = 1.1246476123706088, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 140, train_loss = 1.1251671152786002, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 141, train_loss = 1.1227994722648873, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 142, train_loss = 1.1215470557435765, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 143, train_loss = 1.1205322953537689, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 144, train_loss = 1.119781706482172, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 145, train_loss = 1.1190535525456653, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 146, train_loss = 1.1182516850531101, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 147, train_loss = 1.1168604629710899, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 148, train_loss = 1.116237769521831, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 149, train_loss = 1.114981759339571, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 150, train_loss = 1.1138001667932258, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 151, train_loss = 1.1151140083893551, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 152, train_loss = 1.113388047866465, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 153, train_loss = 1.111615973211883, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 154, train_loss = 1.1112568564713001, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 155, train_loss = 1.1110023384317174, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 156, train_loss = 1.109038520604372, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 157, train_loss = 1.1077725552022457, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 158, train_loss = 1.1082070246338844, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 159, train_loss = 1.1079163141548634, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 160, train_loss = 1.1055409039036022, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 161, train_loss = 1.1052150018513203, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 162, train_loss = 1.1049192709251656, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 163, train_loss = 1.1046792877241387, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 164, train_loss = 1.1028318082317128, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 165, train_loss = 1.1011528000235558, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 166, train_loss = 1.1011886099950061, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 167, train_loss = 1.100578237324953, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 168, train_loss = 1.0998247737661586, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 169, train_loss = 1.0974949387236848, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 170, train_loss = 1.09790028383577, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 171, train_loss = 1.0974591535850777, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 172, train_loss = 1.096338678151369, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 173, train_loss = 1.0951550578101887, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 174, train_loss = 1.094829149544239, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 175, train_loss = 1.0937134437263012, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 176, train_loss = 1.0935683138668537, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 177, train_loss = 1.0924550642594113, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 178, train_loss = 1.0916725881397724, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 179, train_loss = 1.0910320418552146, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 180, train_loss = 1.0916199708954082, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 181, train_loss = 1.0897353676482453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 182, train_loss = 1.0891410397962318, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 183, train_loss = 1.087845642119646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 184, train_loss = 1.0876912710591569, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 185, train_loss = 1.086205064006208, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 186, train_loss = 1.086071698613523, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 187, train_loss = 1.0852221039458527, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 188, train_loss = 1.0861596278846264, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 189, train_loss = 1.0836422915235744, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 190, train_loss = 1.082785019032599, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 191, train_loss = 1.0822923344894662, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 192, train_loss = 1.0829176915212884, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 193, train_loss = 1.0810226413086639, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 194, train_loss = 1.0803841439410462, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 195, train_loss = 1.079829624541162, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 196, train_loss = 1.0790756369606243, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 197, train_loss = 1.078181224562286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 198, train_loss = 1.0775753955022083, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 199, train_loss = 1.077310403190495, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 200, train_loss = 1.0761446965261712, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 201, train_loss = 1.0759859619065537, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 202, train_loss = 1.0748051876798854, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 203, train_loss = 1.073829875640513, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 204, train_loss = 1.0742097472175374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 205, train_loss = 1.072629881404282, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 206, train_loss = 1.072769422084093, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 207, train_loss = 1.0717358278707252, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 208, train_loss = 1.072008017450571, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 209, train_loss = 1.0705821576193557, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 210, train_loss = 1.0697147684768424, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 211, train_loss = 1.069732533149363, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 212, train_loss = 1.069010583065392, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 213, train_loss = 1.0686371723786579, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 214, train_loss = 1.0700906701385975, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 215, train_loss = 1.0674796427265392, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 216, train_loss = 1.0662374384701252, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 217, train_loss = 1.0654391683638096, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 218, train_loss = 1.0650435226634727, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 219, train_loss = 1.0653143897652626, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 220, train_loss = 1.063958163060306, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 221, train_loss = 1.0662092665806995, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 222, train_loss = 1.062445655465126, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 223, train_loss = 1.0623305179178715, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 224, train_loss = 1.061409310750605, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 225, train_loss = 1.0612420588731766, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 226, train_loss = 1.0605888540521846, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 227, train_loss = 1.0601002449766384, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 228, train_loss = 1.0613495161160245, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 229, train_loss = 1.0592097168191685, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 230, train_loss = 1.058332017310022, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 231, train_loss = 1.0576015574260964, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 232, train_loss = 1.0572257277890458, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 233, train_loss = 1.0564419788643136, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 234, train_loss = 1.0559072804971947, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 235, train_loss = 1.0575711776837124, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 236, train_loss = 1.0567500640972867, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 237, train_loss = 1.0542310612872825, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 238, train_loss = 1.0536700213924632, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 239, train_loss = 1.052504959203361, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 240, train_loss = 1.052859562136291, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 241, train_loss = 1.0520416398867383, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 242, train_loss = 1.051800474524498, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 243, train_loss = 1.052343020834087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 244, train_loss = 1.050662737339735, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 245, train_loss = 1.0496489641591324, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 246, train_loss = 1.0488865301012993, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 247, train_loss = 1.0488201131447568, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 248, train_loss = 1.0475383326411247, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 249, train_loss = 1.0482476875185966, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 250, train_loss = 1.0460915515795932, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 251, train_loss = 1.0467425460592494, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 252, train_loss = 1.0454538576304913, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 253, train_loss = 1.0452709632590995, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 254, train_loss = 1.0453447649852023, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 255, train_loss = 1.0470452221707092, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 256, train_loss = 1.0436692821458564, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 257, train_loss = 1.043120493493916, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 258, train_loss = 1.0429882245734916, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 259, train_loss = 1.0425359606742859, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 260, train_loss = 1.0414058317765011, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 261, train_loss = 1.0408146915360703, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 262, train_loss = 1.040447112172842, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 263, train_loss = 1.0407217529937043, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 264, train_loss = 1.0394223568364396, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 265, train_loss = 1.0406291894614697, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 266, train_loss = 1.038452239088656, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 267, train_loss = 1.0406154580414295, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 268, train_loss = 1.0376657471060753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 269, train_loss = 1.0366968462840305, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 270, train_loss = 1.03726453831041, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 271, train_loss = 1.034639611840248, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 272, train_loss = 1.0356483310461044, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 273, train_loss = 1.0336331650614738, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 274, train_loss = 1.0337090877219453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 275, train_loss = 1.0333073325455189, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 276, train_loss = 1.0323194501324906, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 277, train_loss = 1.0328141252175556, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 278, train_loss = 1.03085094565904, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 279, train_loss = 1.0316731445491314, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 280, train_loss = 1.0298534842804656, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 281, train_loss = 1.0301005877554417, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 282, train_loss = 1.0302247814834118, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 283, train_loss = 1.028254975877644, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 284, train_loss = 1.0300024052485242, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 285, train_loss = 1.0284328957422986, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 286, train_loss = 1.0273696283475147, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 287, train_loss = 1.0279541326090111, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 288, train_loss = 1.0266385090872063, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 289, train_loss = 1.0277366625741706, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 290, train_loss = 1.0262675868943916, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 291, train_loss = 1.025443371385336, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 292, train_loss = 1.0255169396623387, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 293, train_loss = 1.025140764810203, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 294, train_loss = 1.0245045336559997, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 295, train_loss = 1.02637902895367, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 296, train_loss = 1.0277104191482067, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 297, train_loss = 1.0247695371508598, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 298, train_loss = 1.0240646973252296, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 299, train_loss = 1.0231666304171085, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 300, train_loss = 1.0220579604283557, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 301, train_loss = 1.0218732953071594, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 302, train_loss = 1.021381368242146, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 303, train_loss = 1.0234055183827877, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 304, train_loss = 1.0236555176452384, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 305, train_loss = 1.0230958039537654, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 306, train_loss = 1.0191855318844318, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 307, train_loss = 1.0200013232752099, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 308, train_loss = 1.0183415462597623, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 309, train_loss = 1.0214855931699276, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 310, train_loss = 1.0204111312850728, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 311, train_loss = 1.0195080824196339, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 312, train_loss = 1.0173087604343891, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 313, train_loss = 1.01761421313131, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 314, train_loss = 1.0188959700390114, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 315, train_loss = 1.0195642188191414, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 316, train_loss = 1.01816777264321, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 317, train_loss = 1.0154169090092182, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 318, train_loss = 1.0153833739459515, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 319, train_loss = 1.0174515806138515, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 320, train_loss = 1.0170238142236485, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 321, train_loss = 1.0167960599064827, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 322, train_loss = 1.0137101523578167, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 323, train_loss = 1.015071727335453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 324, train_loss = 1.0157051583155408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 325, train_loss = 1.0157400431708083, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 326, train_loss = 1.0149837086573825, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 327, train_loss = 1.0154008554891334, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 328, train_loss = 1.0151829843744054, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 329, train_loss = 1.0146843952461495, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 330, train_loss = 1.0138385966420174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 331, train_loss = 1.0140426928774104, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 332, train_loss = 1.013390717409493, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 333, train_loss = 1.0131861406043754, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 334, train_loss = 1.0097491666674614, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 335, train_loss = 1.012350458651781, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 336, train_loss = 1.011645698301436, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 337, train_loss = 1.011969167739153, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 338, train_loss = 1.0175419176594005, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 339, train_loss = 1.015919810779451, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 340, train_loss = 1.0166516030803905, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 341, train_loss = 1.0167668337599025, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 342, train_loss = 1.0165942733510747, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 343, train_loss = 1.0160708203911781, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 344, train_loss = 1.0149030685424805, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 345, train_loss = 1.0154273062944412, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 346, train_loss = 1.0144652922972455, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 347, train_loss = 1.0136127819641843, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 348, train_loss = 1.013188856341003, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 349, train_loss = 1.012644408889173, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 350, train_loss = 1.0130754845813499, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 351, train_loss = 1.0127878387793317, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 352, train_loss = 1.0116012704893365, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 353, train_loss = 1.0120348793789162, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 354, train_loss = 1.0114864433780895, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 355, train_loss = 1.012053153164743, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 356, train_loss = 1.0102062039077282, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 357, train_loss = 1.009868297725916, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 358, train_loss = 1.010016854852438, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 359, train_loss = 1.0094866541548981, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 360, train_loss = 1.0087418891489506, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 361, train_loss = 1.008696235716343, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 362, train_loss = 1.0090478894635453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 363, train_loss = 1.00755274171388, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 364, train_loss = 1.0074780086652027, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 365, train_loss = 1.0068787361160503, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 366, train_loss = 1.0064837336540222, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 367, train_loss = 1.006982901446463, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 368, train_loss = 1.0060725286602974, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 369, train_loss = 1.0060694888234138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 370, train_loss = 1.0040616914629936, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 371, train_loss = 1.0021519524379983, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 372, train_loss = 1.0023989528417587, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 373, train_loss = 1.0042998207136407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 374, train_loss = 1.0038746731952415, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 375, train_loss = 1.0040712083355174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 376, train_loss = 1.0031938540414558, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 377, train_loss = 1.0035728948787437, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 378, train_loss = 1.0029074388221488, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 379, train_loss = 1.0024405904114246, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 380, train_loss = 1.0001842305064201, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 381, train_loss = 0.9989591464400291, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 382, train_loss = 0.9984013214707375, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 383, train_loss = 1.0010725085958256, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 384, train_loss = 1.0016372886821046, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 385, train_loss = 1.0021942245439277, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 386, train_loss = 1.0005311196073308, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 387, train_loss = 0.9998650228008046, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 388, train_loss = 0.9991393275558949, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 389, train_loss = 0.9995795004069805, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 390, train_loss = 0.9969487239941373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 391, train_loss = 0.9960148284808383, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 392, train_loss = 0.9964012938216911, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 393, train_loss = 0.9976559827737219, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 394, train_loss = 0.9971555657684803, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 395, train_loss = 0.9955748841166496, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 396, train_loss = 0.9956892617046833, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 397, train_loss = 0.9945206356533163, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 398, train_loss = 0.9959681878499396, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 399, train_loss = 0.9941870470865979, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 400, train_loss = 0.9936404166146531, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 401, train_loss = 0.9924790300428867, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 402, train_loss = 0.995315490908979, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 403, train_loss = 0.9919676557183266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 404, train_loss = 0.9921372098251595, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 405, train_loss = 0.9909079695753462, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 406, train_loss = 0.9928623524792783, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 407, train_loss = 0.9915509844795451, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 408, train_loss = 0.9908884229771502, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 409, train_loss = 0.9896996729075909, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 410, train_loss = 0.9925678471736319, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 411, train_loss = 0.9915544465184212, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 412, train_loss = 0.9911076823882468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 413, train_loss = 0.9912613133601553, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 414, train_loss = 0.9911960040517442, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 415, train_loss = 0.9886318196877255, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 416, train_loss = 0.9902701725586667, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 417, train_loss = 0.9882866963744164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 418, train_loss = 0.9899381647519476, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 419, train_loss = 0.9873513169586658, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 420, train_loss = 0.9865812957286835, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 421, train_loss = 0.9865120773501985, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 422, train_loss = 0.9880386690310843, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 423, train_loss = 0.9867618183307059, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 424, train_loss = 0.9862031576521986, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 425, train_loss = 0.9849041402339935, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 426, train_loss = 0.9874987813345797, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 427, train_loss = 0.985748636227072, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 428, train_loss = 0.9845290246121294, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 429, train_loss = 0.9841287682465918, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 430, train_loss = 0.9862536142281897, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 431, train_loss = 0.9861389882862568, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 432, train_loss = 0.9860056030265696, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 433, train_loss = 0.9857136743776209, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 434, train_loss = 0.9858947706707113, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 435, train_loss = 0.9833192229270935, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 436, train_loss = 0.9825649559497833, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 437, train_loss = 0.9813777518756979, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 438, train_loss = 0.9845566526055336, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 439, train_loss = 0.9814906306564808, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 440, train_loss = 0.9808868740983598, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 441, train_loss = 0.9804197673984163, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 442, train_loss = 0.9828748144209385, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 443, train_loss = 0.9810925635210879, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 444, train_loss = 0.9799957039467699, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 445, train_loss = 0.9795964223631017, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 446, train_loss = 0.982237500447809, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 447, train_loss = 0.9793872721493244, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 448, train_loss = 0.9795405517033942, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 449, train_loss = 0.980067778378725, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 450, train_loss = 0.9802667635194666, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 451, train_loss = 0.9803514604755037, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 452, train_loss = 0.9806748790033453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 453, train_loss = 0.980332974344492, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 454, train_loss = 0.9777624209709757, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 455, train_loss = 0.9763953213878267, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 456, train_loss = 0.97737942263484, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 457, train_loss = 0.9789359793066978, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 458, train_loss = 0.9793161389716261, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 459, train_loss = 0.9785450125746138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 460, train_loss = 0.9782119592018717, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 461, train_loss = 0.9778581224381924, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 462, train_loss = 0.9781437342353456, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 463, train_loss = 0.9773726239800453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 464, train_loss = 0.9773415016643412, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 465, train_loss = 0.9768273855261214, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 466, train_loss = 0.9757760179527395, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 467, train_loss = 0.9764576492198103, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 468, train_loss = 0.9763762702532404, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 469, train_loss = 0.9761946015059948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 470, train_loss = 0.9762090605981939, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 471, train_loss = 0.9734083190560341, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 472, train_loss = 0.972981662798702, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 473, train_loss = 0.9728424027562141, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 474, train_loss = 0.9745221038647287, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 475, train_loss = 0.971864444512903, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 476, train_loss = 0.9714071626476652, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 477, train_loss = 0.971047521878063, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 478, train_loss = 0.9731774131469138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 479, train_loss = 0.9736070483922958, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 480, train_loss = 0.9733465562276251, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 481, train_loss = 0.9731601427010901, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 482, train_loss = 0.9727280040569894, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 483, train_loss = 0.9703399005047686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 484, train_loss = 0.9707622031382925, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 485, train_loss = 0.9695298386104696, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 486, train_loss = 0.9710028779991262, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 487, train_loss = 0.9693461023271084, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 488, train_loss = 0.9689120935909159, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 489, train_loss = 0.96793832878393, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 490, train_loss = 0.9705740908793814, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 491, train_loss = 0.9687491729855537, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 492, train_loss = 0.9675942324101925, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 493, train_loss = 0.9676475288979418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 494, train_loss = 0.9689995236694813, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 495, train_loss = 0.9694367510564916, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 496, train_loss = 0.9692902229726315, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 497, train_loss = 0.9681968788318045, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 498, train_loss = 0.966852950554312, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 499, train_loss = 0.9662387085445516, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|███████████████▊                                                               | 6/30 [54:17<3:37:11, 542.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "7th- epoch: 0, train_loss = 371.5670643597841, train_acc = 0.8023986958546809\n",
      "test Acc 0.88268156424581:\n",
      "7th- epoch: 1, train_loss = 93.39013853156939, train_acc = 0.9194224499301351\n",
      "test Acc 0.9278398510242085:\n",
      "7th- epoch: 2, train_loss = 57.666470197960734, train_acc = 0.9436422915696321\n",
      "test Acc 0.9380819366852886:\n",
      "7th- epoch: 3, train_loss = 40.172339130192995, train_acc = 0.9573823940381928\n",
      "test Acc 0.9413407821229051:\n",
      "7th- epoch: 4, train_loss = 30.14137613028288, train_acc = 0.966581276199348\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 5, train_loss = 23.550549348816276, train_acc = 0.9733348858872846\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 6, train_loss = 18.737051957286894, train_acc = 0.9775267815556591\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 7, train_loss = 15.016046431846917, train_acc = 0.9812529110386586\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 8, train_loss = 12.275592108257115, train_acc = 0.9829995342338146\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 9, train_loss = 10.087800642475486, train_acc = 0.9855612482533768\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 10, train_loss = 8.337626822758466, train_acc = 0.9864927806241267\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 11, train_loss = 6.900700240395963, train_acc = 0.9884722869119702\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 12, train_loss = 5.807371604256332, train_acc = 0.9895202608290639\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 13, train_loss = 4.96894933283329, train_acc = 0.9912668840242198\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 14, train_loss = 4.352077042451128, train_acc = 0.9919655333022822\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 15, train_loss = 3.877296381397173, train_acc = 0.9932463903120633\n",
      "test Acc 0.9515828677839852:\n",
      "7th- epoch: 16, train_loss = 3.4854374018032104, train_acc = 0.9937121564974383\n",
      "test Acc 0.9515828677839852:\n",
      "7th- epoch: 17, train_loss = 3.1888994900509715, train_acc = 0.9941779226828132\n",
      "test Acc 0.9515828677839852:\n",
      "7th- epoch: 18, train_loss = 2.9667277224361897, train_acc = 0.9947601304145319\n",
      "test Acc 0.9534450651769087:\n",
      "7th- epoch: 19, train_loss = 2.7663747787009925, train_acc = 0.9951094550535631\n",
      "test Acc 0.9543761638733705:\n",
      "7th- epoch: 20, train_loss = 2.6219868920743465, train_acc = 0.9949930135072194\n",
      "test Acc 0.9553072625698324:\n",
      "7th- epoch: 21, train_loss = 2.4764315268257633, train_acc = 0.9952258965999069\n",
      "test Acc 0.9557728119180633:\n",
      "7th- epoch: 22, train_loss = 2.3621962008764967, train_acc = 0.9953423381462506\n",
      "test Acc 0.9562383612662942:\n",
      "7th- epoch: 23, train_loss = 2.2530341440578923, train_acc = 0.9954587796925943\n",
      "test Acc 0.9567039106145251:\n",
      "7th- epoch: 24, train_loss = 2.1612075734883547, train_acc = 0.9954587796925943\n",
      "test Acc 0.9567039106145251:\n",
      "7th- epoch: 25, train_loss = 2.074432179913856, train_acc = 0.995575221238938\n",
      "test Acc 0.9567039106145251:\n",
      "7th- epoch: 26, train_loss = 1.9962742514908314, train_acc = 0.995575221238938\n",
      "test Acc 0.957169459962756:\n",
      "7th- epoch: 27, train_loss = 1.9388391077518463, train_acc = 0.9958081043316255\n",
      "test Acc 0.957169459962756:\n",
      "7th- epoch: 28, train_loss = 1.8798442427068949, train_acc = 0.9959245458779693\n",
      "test Acc 0.9581005586592178:\n",
      "7th- epoch: 29, train_loss = 1.8223618423799053, train_acc = 0.996040987424313\n",
      "test Acc 0.9585661080074488:\n",
      "7th- epoch: 30, train_loss = 1.778603266342543, train_acc = 0.9961574289706567\n",
      "test Acc 0.9581005586592178:\n",
      "7th- epoch: 31, train_loss = 1.7392785804113373, train_acc = 0.996040987424313\n",
      "test Acc 0.957635009310987:\n",
      "7th- epoch: 32, train_loss = 1.7023333205725066, train_acc = 0.996040987424313\n",
      "test Acc 0.9581005586592178:\n",
      "7th- epoch: 33, train_loss = 1.6653887231950648, train_acc = 0.9961574289706567\n",
      "test Acc 0.9581005586592178:\n",
      "7th- epoch: 34, train_loss = 1.6398377995938063, train_acc = 0.9959245458779693\n",
      "test Acc 0.9590316573556797:\n",
      "7th- epoch: 35, train_loss = 1.6201935528661124, train_acc = 0.9962738705170004\n",
      "test Acc 0.9590316573556797:\n",
      "7th- epoch: 36, train_loss = 1.5907630125875585, train_acc = 0.9962738705170004\n",
      "test Acc 0.9594972067039106:\n",
      "7th- epoch: 37, train_loss = 1.5766067281365395, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "7th- epoch: 38, train_loss = 1.5573545824736357, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "7th- epoch: 39, train_loss = 1.539939884096384, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "7th- epoch: 40, train_loss = 1.5210107297752984, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "7th- epoch: 41, train_loss = 1.50988350372063, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "7th- epoch: 42, train_loss = 1.4960840083658695, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "7th- epoch: 43, train_loss = 1.4845170310582034, train_acc = 0.996506753609688\n",
      "test Acc 0.9594972067039106:\n",
      "7th- epoch: 44, train_loss = 1.4751299967174418, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "7th- epoch: 45, train_loss = 1.4644127798383124, train_acc = 0.9966231951560317\n",
      "test Acc 0.9594972067039106:\n",
      "7th- epoch: 46, train_loss = 1.4532112932647578, train_acc = 0.9966231951560317\n",
      "test Acc 0.9594972067039106:\n",
      "7th- epoch: 47, train_loss = 1.4448024698649533, train_acc = 0.9966231951560317\n",
      "test Acc 0.9594972067039106:\n",
      "7th- epoch: 48, train_loss = 1.4344523530453444, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 49, train_loss = 1.423284659802448, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "7th- epoch: 50, train_loss = 1.417236102744937, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 51, train_loss = 1.4057325788890012, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 52, train_loss = 1.3949583477224223, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 53, train_loss = 1.3926168028265238, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 54, train_loss = 1.3841874941135757, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "7th- epoch: 55, train_loss = 1.3795532621443272, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 56, train_loss = 1.3676686193794012, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "7th- epoch: 57, train_loss = 1.362606255337596, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "7th- epoch: 58, train_loss = 1.3552847877144814, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "7th- epoch: 59, train_loss = 1.349999116093386, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "7th- epoch: 60, train_loss = 1.3459522717748769, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "7th- epoch: 61, train_loss = 1.3386292972718365, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "7th- epoch: 62, train_loss = 1.331756769970525, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 63, train_loss = 1.3269514578278176, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "7th- epoch: 64, train_loss = 1.323687448457349, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 65, train_loss = 1.3161249266122468, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 66, train_loss = 1.3126231015776284, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 67, train_loss = 1.3071129259769805, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 68, train_loss = 1.3029701964114793, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 69, train_loss = 1.296366635710001, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 70, train_loss = 1.2950616981834173, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 71, train_loss = 1.2891058903187513, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 72, train_loss = 1.2815633757563774, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 73, train_loss = 1.2807166824641172, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 74, train_loss = 1.273670942231547, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 75, train_loss = 1.2698765744862612, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 76, train_loss = 1.2688069362193346, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 77, train_loss = 1.2636313755065203, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 78, train_loss = 1.2588497158139944, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 79, train_loss = 1.256101659819251, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 80, train_loss = 1.250495041400427, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 81, train_loss = 1.2502445125428494, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 82, train_loss = 1.2461859416216612, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "7th- epoch: 83, train_loss = 1.2410518998804037, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "7th- epoch: 84, train_loss = 1.23727410347783, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 85, train_loss = 1.2318700216710567, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 86, train_loss = 1.2308400496840477, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 87, train_loss = 1.2303216519358102, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 88, train_loss = 1.2255135843006428, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 89, train_loss = 1.2229295255092438, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 90, train_loss = 1.2212463648465928, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 91, train_loss = 1.2164635801163968, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 92, train_loss = 1.2147230934351683, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 93, train_loss = 1.2115899374184664, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 94, train_loss = 1.2103186324238777, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 95, train_loss = 1.2079766342940275, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 96, train_loss = 1.20589923238731, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 97, train_loss = 1.2010828728380147, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 98, train_loss = 1.2011236529797316, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 99, train_loss = 1.1988555304706097, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 100, train_loss = 1.193752378836507, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 101, train_loss = 1.1917225793004036, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 102, train_loss = 1.1900873643753584, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 103, train_loss = 1.1884850499627646, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 104, train_loss = 1.1858059049991425, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 105, train_loss = 1.1862942433508579, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 106, train_loss = 1.1809844678791706, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 107, train_loss = 1.181579664349556, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 108, train_loss = 1.1784969332220498, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 109, train_loss = 1.1766536527720746, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 110, train_loss = 1.1718934072705451, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 111, train_loss = 1.173339068889618, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 112, train_loss = 1.1716355880198535, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 113, train_loss = 1.1691274493932724, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 114, train_loss = 1.1669678383914288, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 115, train_loss = 1.1663788873702288, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 116, train_loss = 1.163648505375022, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 117, train_loss = 1.1637580332753714, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 118, train_loss = 1.159803810849553, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 119, train_loss = 1.1588081773370504, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 120, train_loss = 1.15602570399642, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 121, train_loss = 1.1564892517926637, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 122, train_loss = 1.1551135437039193, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 123, train_loss = 1.1526188589632511, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 124, train_loss = 1.15131494650268, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 125, train_loss = 1.149308905005455, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 126, train_loss = 1.149512937903637, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 127, train_loss = 1.1476881125418004, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 128, train_loss = 1.1465593744069338, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 129, train_loss = 1.1451962074788753, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 130, train_loss = 1.1440288461744785, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 131, train_loss = 1.1427120150474366, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 132, train_loss = 1.1407966340484563, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 133, train_loss = 1.1409822634013835, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 134, train_loss = 1.138106008991599, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 135, train_loss = 1.138036323711276, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 136, train_loss = 1.1356801303627435, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 137, train_loss = 1.1337514414044563, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 138, train_loss = 1.133138783276081, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 139, train_loss = 1.131734099239111, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 140, train_loss = 1.130693169310689, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 141, train_loss = 1.1305384530278388, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 142, train_loss = 1.1286838383821305, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 143, train_loss = 1.1268148446979467, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 144, train_loss = 1.127106818050379, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 145, train_loss = 1.1245290630758973, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 146, train_loss = 1.123257810875657, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 147, train_loss = 1.1226017822918948, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 148, train_loss = 1.1211162793188123, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 149, train_loss = 1.120553250730154, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 150, train_loss = 1.119255897894618, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 151, train_loss = 1.1188924045563908, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 152, train_loss = 1.1167387571185827, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 153, train_loss = 1.1147383960633306, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 154, train_loss = 1.1137203574180603, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 155, train_loss = 1.112100312486291, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 156, train_loss = 1.1116339315922232, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 157, train_loss = 1.108759040638688, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 158, train_loss = 1.1096734299062518, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 159, train_loss = 1.1088134447782068, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 160, train_loss = 1.1060533157287864, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 161, train_loss = 1.1075559090822935, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 162, train_loss = 1.1046421962528257, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 163, train_loss = 1.1036955515592126, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 164, train_loss = 1.1032201014459133, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 165, train_loss = 1.1019950707704993, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 166, train_loss = 1.1017660293728113, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 167, train_loss = 1.098515128091094, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 168, train_loss = 1.1005458403378725, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 169, train_loss = 1.099322277426836, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 170, train_loss = 1.0968686385749606, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 171, train_loss = 1.096642763048294, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 172, train_loss = 1.0943439956754446, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 173, train_loss = 1.0943761263042688, train_acc = 0.9970889613414066\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 174, train_loss = 1.093749463558197, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 175, train_loss = 1.0942873594613047, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 176, train_loss = 1.0904594219027786, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 177, train_loss = 1.0919946146459552, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 178, train_loss = 1.0888255015015602, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 179, train_loss = 1.0891901459544897, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 180, train_loss = 1.0885971107782098, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 181, train_loss = 1.0865754994301824, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 182, train_loss = 1.086244101941702, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 183, train_loss = 1.08524564281106, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 184, train_loss = 1.0847926462738542, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 185, train_loss = 1.0825899858027697, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 186, train_loss = 1.0828302440495463, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 187, train_loss = 1.082722233608365, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 188, train_loss = 1.0804544103593798, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 189, train_loss = 1.0801249984651804, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 190, train_loss = 1.080471693232539, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 191, train_loss = 1.0771555304527283, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 192, train_loss = 1.078217917427537, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 193, train_loss = 1.0775097689329414, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 194, train_loss = 1.0755545552819967, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 195, train_loss = 1.0752096859068843, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 196, train_loss = 1.0754014564008685, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 197, train_loss = 1.0728090355842141, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 198, train_loss = 1.0732871176005574, train_acc = 0.9970889613414066\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 199, train_loss = 1.071802984297392, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 200, train_loss = 1.0711048040539026, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 201, train_loss = 1.0702968997211428, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 202, train_loss = 1.0685143775044708, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 203, train_loss = 1.068808292344329, train_acc = 0.9972054028877504\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 204, train_loss = 1.0687817347497912, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 205, train_loss = 1.0670899525284767, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 206, train_loss = 1.0662513940333156, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 207, train_loss = 1.0663875453174114, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 208, train_loss = 1.0651715453714132, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 209, train_loss = 1.064796486243722, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 210, train_loss = 1.0631530433893204, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 211, train_loss = 1.062085224315524, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 212, train_loss = 1.0621237798332004, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 213, train_loss = 1.0616093662829371, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 214, train_loss = 1.0610216688364744, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 215, train_loss = 1.059597171843052, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 216, train_loss = 1.058692609265563, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 217, train_loss = 1.0579271049500676, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 218, train_loss = 1.0577490559517173, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 219, train_loss = 1.0577984619885683, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 220, train_loss = 1.05573374281812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 221, train_loss = 1.0552362464368343, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 222, train_loss = 1.0561837920249673, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 223, train_loss = 1.0544660091400146, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 224, train_loss = 1.053390396758914, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 225, train_loss = 1.0523517963738414, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 226, train_loss = 1.0524952889682027, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 227, train_loss = 1.0507367091922788, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 228, train_loss = 1.0515484896750422, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 229, train_loss = 1.0495391556323739, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 230, train_loss = 1.0486452436744003, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 231, train_loss = 1.0487168369145365, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 232, train_loss = 1.0485899870545836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 233, train_loss = 1.0465949239878682, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 234, train_loss = 1.0473397641180782, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 235, train_loss = 1.0452544509171275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 236, train_loss = 1.0442981558589963, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 237, train_loss = 1.045119888454792, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 238, train_loss = 1.0425995693803998, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 239, train_loss = 1.0440458618104458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 240, train_loss = 1.0435354597866535, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 241, train_loss = 1.0406604893505573, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 242, train_loss = 1.040506177887437, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 243, train_loss = 1.0417710039764643, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 244, train_loss = 1.0388340521603823, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 245, train_loss = 1.0393031109124422, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 246, train_loss = 1.0393999281077413, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 247, train_loss = 1.037587100014207, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 248, train_loss = 1.0377333195210667, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 249, train_loss = 1.0366023940296145, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 250, train_loss = 1.035621514543891, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 251, train_loss = 1.03512538720679, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 252, train_loss = 1.0349535805435153, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 253, train_loss = 1.03398110345006, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 254, train_loss = 1.0322193341999082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 255, train_loss = 1.0334323874412803, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 256, train_loss = 1.0328140761703253, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 257, train_loss = 1.0313904322683811, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 258, train_loss = 1.0314115025103092, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 259, train_loss = 1.030170425772667, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 260, train_loss = 1.0295561887323856, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 261, train_loss = 1.0301781532616587, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 262, train_loss = 1.028934232890606, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 263, train_loss = 1.0275105498731136, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 264, train_loss = 1.0272280697972747, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 265, train_loss = 1.0271931787283393, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 266, train_loss = 1.0257431666104821, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 267, train_loss = 1.0266364514827728, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 268, train_loss = 1.0247636400163174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 269, train_loss = 1.0238942044525174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 270, train_loss = 1.023889375224826, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 271, train_loss = 1.0233259958476992, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 272, train_loss = 1.0216445128171472, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 273, train_loss = 1.0233306822628947, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 274, train_loss = 1.0208893157541752, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 275, train_loss = 1.021143812686205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 276, train_loss = 1.020611674830434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 277, train_loss = 1.0206690567283658, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 278, train_loss = 1.0182706005871296, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 279, train_loss = 1.019029868140933, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 280, train_loss = 1.0181951448321342, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 281, train_loss = 1.0178069050161866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 282, train_loss = 1.0173763893544674, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 283, train_loss = 1.016685393944499, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 284, train_loss = 1.0160823638289003, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 285, train_loss = 1.0149878573865863, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 286, train_loss = 1.014701501771924, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 287, train_loss = 1.0140696689486504, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 288, train_loss = 1.0141872341482667, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 289, train_loss = 1.014781712248805, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 290, train_loss = 1.0112438251526328, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 291, train_loss = 1.0140769705176353, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 292, train_loss = 1.0112956004886655, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 293, train_loss = 1.0100542828440666, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 294, train_loss = 1.010786687329528, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 295, train_loss = 1.0100459791719913, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 296, train_loss = 1.0089454973785905, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 297, train_loss = 1.0095283066184493, train_acc = 0.9975547275267815\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 298, train_loss = 1.0081126354634762, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 299, train_loss = 1.0076487797050504, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 300, train_loss = 1.0075201777071925, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 301, train_loss = 1.00709558899689, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 302, train_loss = 1.0055661300866632, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 303, train_loss = 1.0060638450086117, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 304, train_loss = 1.0053101989178685, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 305, train_loss = 1.0037872480897931, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 306, train_loss = 1.0057396292686462, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 307, train_loss = 1.0044379929749994, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 308, train_loss = 1.0053161059768172, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 309, train_loss = 1.0051391410379438, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 310, train_loss = 1.0019911229610443, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 311, train_loss = 1.0016142179520102, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 312, train_loss = 1.0014609806239605, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 313, train_loss = 1.001946700111148, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 314, train_loss = 1.00056782241154, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 315, train_loss = 1.0004338882863522, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 316, train_loss = 1.000368042543414, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 317, train_loss = 0.9992764716298552, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 318, train_loss = 0.9992263143212767, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 319, train_loss = 0.9981313981115818, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 320, train_loss = 0.9992249260394601, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 321, train_loss = 0.9976566930563422, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 322, train_loss = 0.9979413909168215, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 323, train_loss = 0.9978840053081512, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 324, train_loss = 0.9975311445741681, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 325, train_loss = 0.9973523418157129, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 326, train_loss = 0.9944640534667997, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 327, train_loss = 0.9942451119422913, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 328, train_loss = 0.9947871280164691, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 329, train_loss = 0.9936597049236298, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 330, train_loss = 0.9951192748994799, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 331, train_loss = 0.9935957988054724, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 332, train_loss = 0.9925235671253176, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 333, train_loss = 0.9927093250007601, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 334, train_loss = 0.9912606365978718, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 335, train_loss = 0.9929804814310046, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 336, train_loss = 0.9921324625611305, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 337, train_loss = 0.9915201154799433, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 338, train_loss = 0.9912039116024971, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 339, train_loss = 0.9893265801219968, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 340, train_loss = 0.9892172751278849, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 341, train_loss = 0.9888603029103251, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 342, train_loss = 0.9895064122974873, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 343, train_loss = 0.9895060050039319, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 344, train_loss = 0.9886086781771155, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 345, train_loss = 0.987165555357933, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 346, train_loss = 0.986778799444437, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 347, train_loss = 0.9859717637300491, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 348, train_loss = 0.9850562388746766, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 349, train_loss = 0.9853017342538806, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 350, train_loss = 0.9849433327763109, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 351, train_loss = 0.9847594574093819, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 352, train_loss = 0.9828227087855339, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 353, train_loss = 0.9841707634477643, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 354, train_loss = 0.9834687002003193, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 355, train_loss = 0.9834866685123416, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 356, train_loss = 0.9835541633219691, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 357, train_loss = 0.9819613906292943, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 358, train_loss = 0.981189351528883, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 359, train_loss = 0.9828465208411217, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 360, train_loss = 0.9813504231424304, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 361, train_loss = 0.9804576461465331, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 362, train_loss = 0.980283971875906, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 363, train_loss = 0.9797320477664471, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 364, train_loss = 0.9792241056711646, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 365, train_loss = 0.9788965272455243, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 366, train_loss = 0.9791650300176116, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 367, train_loss = 0.9784844343812438, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 368, train_loss = 0.9777851750404807, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 369, train_loss = 0.9772926370351342, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 370, train_loss = 0.9770931427628966, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 371, train_loss = 0.9767472234816523, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 372, train_loss = 0.9770946502685547, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 373, train_loss = 0.9771539109497098, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 374, train_loss = 0.9769883553235559, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 375, train_loss = 0.9765145815908909, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 376, train_loss = 0.9761699723749189, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 377, train_loss = 0.9745327246637316, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 378, train_loss = 0.9733602019696264, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 379, train_loss = 0.9749793807714013, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 380, train_loss = 0.9746958787291078, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 381, train_loss = 0.9740264428110095, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 382, train_loss = 0.9731245078146458, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 383, train_loss = 0.9731536855251761, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 384, train_loss = 0.9727422570140334, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 385, train_loss = 0.972080669060233, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 386, train_loss = 0.9707976306526689, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 387, train_loss = 0.9708055518567562, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 388, train_loss = 0.970472355678794, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 389, train_loss = 0.9693191858677892, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 390, train_loss = 0.9726848937571049, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 391, train_loss = 0.9701924721448449, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 392, train_loss = 0.969847263142583, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 393, train_loss = 0.969434130936861, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 394, train_loss = 0.9695751095860032, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 395, train_loss = 0.9683108031749725, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 396, train_loss = 0.9678258250205545, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 397, train_loss = 0.9666865890176268, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 398, train_loss = 0.9691413951368304, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 399, train_loss = 0.9688791024236707, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 400, train_loss = 0.9697536031453637, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 401, train_loss = 0.9668184580950765, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 402, train_loss = 0.9667984334082576, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 403, train_loss = 0.9691647340805503, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 404, train_loss = 0.9653713914303808, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 405, train_loss = 0.9674133819789859, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 406, train_loss = 0.9645215210766764, train_acc = 0.9976711690731253\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 407, train_loss = 0.9635776653885841, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 408, train_loss = 0.9631578909902601, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 409, train_loss = 0.964386352643487, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 410, train_loss = 0.9661973913462134, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 411, train_loss = 0.9626048132777214, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 412, train_loss = 0.9638570075185271, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 413, train_loss = 0.9630689074547263, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 414, train_loss = 0.9655542361288099, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 415, train_loss = 0.9620159889309434, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 416, train_loss = 0.9643457432539435, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 417, train_loss = 0.9603708585054846, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 418, train_loss = 0.9621258489787579, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 419, train_loss = 0.9618156030774117, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 420, train_loss = 0.9605869228689699, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 421, train_loss = 0.9599979370832443, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 422, train_loss = 0.9624522452504607, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 423, train_loss = 0.9597145542502403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 424, train_loss = 0.9614810794591904, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 425, train_loss = 0.9591086308209924, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 426, train_loss = 0.9588524314312963, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 427, train_loss = 0.9601623465568991, train_acc = 0.9976711690731253\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 428, train_loss = 0.9579581245779991, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 429, train_loss = 0.9596434608101845, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 430, train_loss = 0.9577901760785608, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 431, train_loss = 0.9583801341505023, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 432, train_loss = 0.9567041670234175, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 433, train_loss = 0.958771372839692, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 434, train_loss = 0.9568931038229493, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 435, train_loss = 0.9559812992811203, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 436, train_loss = 0.9577007492334815, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 437, train_loss = 0.9555561405868502, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 438, train_loss = 0.9547706904559163, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 439, train_loss = 0.9560950982122449, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 440, train_loss = 0.9584113123564748, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 441, train_loss = 0.9537727199494839, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 442, train_loss = 0.9564859420061111, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 443, train_loss = 0.9534435855894117, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 444, train_loss = 0.9549090452492237, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 445, train_loss = 0.9533041467220755, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 446, train_loss = 0.9541194463818101, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 447, train_loss = 0.954659237220767, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 448, train_loss = 0.9529244427831145, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 449, train_loss = 0.9528702422976494, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 450, train_loss = 0.9526764539332362, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 451, train_loss = 0.9546592409460573, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 452, train_loss = 0.952973261475563, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 453, train_loss = 0.9509820565581322, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 454, train_loss = 0.9535366619675187, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 455, train_loss = 0.9510781976132421, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 456, train_loss = 0.9517040811479092, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 457, train_loss = 0.9499104941933183, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 458, train_loss = 0.950342457741499, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 459, train_loss = 0.951956766351941, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 460, train_loss = 0.9494769535958767, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 461, train_loss = 0.9511110012681456, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 462, train_loss = 0.9485718322248431, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 463, train_loss = 0.9499879516661167, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 464, train_loss = 0.9521759984345408, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 465, train_loss = 0.9473978790192632, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 466, train_loss = 0.9504761335701915, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 467, train_loss = 0.9476932063698769, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 468, train_loss = 0.9474402368068695, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 469, train_loss = 0.9500076770782471, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 470, train_loss = 0.9475338570773602, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 471, train_loss = 0.9469778835773468, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 472, train_loss = 0.9478730596601963, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 473, train_loss = 0.947597739592311, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 474, train_loss = 0.9490688790829154, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 475, train_loss = 0.9465508510620566, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 476, train_loss = 0.94676308085036, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 477, train_loss = 0.9454575094132451, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 478, train_loss = 0.9442666793911485, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 479, train_loss = 0.9465031052677659, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 480, train_loss = 0.9439296101481887, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 481, train_loss = 0.9442688735871343, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 482, train_loss = 0.9465516979544191, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 483, train_loss = 0.9441272492258577, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 484, train_loss = 0.9468317901046248, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 485, train_loss = 0.9432303992361994, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 486, train_loss = 0.9449431672692299, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 487, train_loss = 0.9441181098372908, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 488, train_loss = 0.9426759916095762, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 489, train_loss = 0.9422136445791693, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 490, train_loss = 0.9443519674241543, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 491, train_loss = 0.9416704215109348, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 492, train_loss = 0.9431278544216184, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 493, train_loss = 0.9423876975924941, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 494, train_loss = 0.9427437906415435, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 495, train_loss = 0.9432078239769908, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 496, train_loss = 0.9418577191681834, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 497, train_loss = 0.9431603538541822, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 498, train_loss = 0.9407785957009764, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 499, train_loss = 0.9417174234986305, train_acc = 0.9976711690731253\n",
      "test Acc 0.9678770949720671:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|█████████████████▉                                                           | 7/30 [1:03:20<3:28:10, 543.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "8th- epoch: 0, train_loss = 364.1501520872116, train_acc = 0.803679552864462\n",
      "test Acc 0.8631284916201117:\n",
      "8th- epoch: 1, train_loss = 95.23957821726799, train_acc = 0.9207033069399162\n",
      "test Acc 0.9236499068901304:\n",
      "8th- epoch: 2, train_loss = 57.55039009638131, train_acc = 0.9428272007452259\n",
      "test Acc 0.9338919925512105:\n",
      "8th- epoch: 3, train_loss = 39.561412719398504, train_acc = 0.9587796925943176\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 4, train_loss = 28.97162890434265, train_acc = 0.9654168607359106\n",
      "test Acc 0.9418063314711359:\n",
      "8th- epoch: 5, train_loss = 22.052322416260722, train_acc = 0.9719375873311598\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 6, train_loss = 17.314006672546384, train_acc = 0.9771774569166278\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 7, train_loss = 13.901904192905931, train_acc = 0.9804378202142524\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 8, train_loss = 11.366570601858257, train_acc = 0.9833488588728458\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 9, train_loss = 9.416156572289765, train_acc = 0.9860270144387517\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 10, train_loss = 7.886348160915077, train_acc = 0.9876571960875641\n",
      "test Acc 0.9497206703910615:\n",
      "8th- epoch: 11, train_loss = 6.675454550422728, train_acc = 0.9888216115510013\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 12, train_loss = 5.71551446927333, train_acc = 0.9895202608290639\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 13, train_loss = 4.9734768882990465, train_acc = 0.9905682347461574\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 14, train_loss = 4.418086177400255, train_acc = 0.9914997671169073\n",
      "test Acc 0.952513966480447:\n",
      "8th- epoch: 15, train_loss = 4.0025752183719305, train_acc = 0.9925477410340009\n",
      "test Acc 0.9534450651769087:\n",
      "8th- epoch: 16, train_loss = 3.6603514289745362, train_acc = 0.9926641825803446\n",
      "test Acc 0.9534450651769087:\n",
      "8th- epoch: 17, train_loss = 3.3847740860655904, train_acc = 0.9927806241266884\n",
      "test Acc 0.9529795158286778:\n",
      "8th- epoch: 18, train_loss = 3.144139056719723, train_acc = 0.9930135072193759\n",
      "test Acc 0.9534450651769087:\n",
      "8th- epoch: 19, train_loss = 2.9049492049234686, train_acc = 0.9931299487657196\n",
      "test Acc 0.9534450651769087:\n",
      "8th- epoch: 20, train_loss = 2.7004397491255077, train_acc = 0.9932463903120633\n",
      "test Acc 0.9548417132216015:\n",
      "8th- epoch: 21, train_loss = 2.541211955714971, train_acc = 0.9934792734047508\n",
      "test Acc 0.9553072625698324:\n",
      "8th- epoch: 22, train_loss = 2.4074817646032898, train_acc = 0.9937121564974383\n",
      "test Acc 0.9548417132216015:\n",
      "8th- epoch: 23, train_loss = 2.29633855742577, train_acc = 0.993828598043782\n",
      "test Acc 0.9557728119180633:\n",
      "8th- epoch: 24, train_loss = 2.190243525590631, train_acc = 0.9940614811364695\n",
      "test Acc 0.9553072625698324:\n",
      "8th- epoch: 25, train_loss = 2.108771536804852, train_acc = 0.9941779226828132\n",
      "test Acc 0.9553072625698324:\n",
      "8th- epoch: 26, train_loss = 2.0360887185670435, train_acc = 0.9946436888681882\n",
      "test Acc 0.9557728119180633:\n",
      "8th- epoch: 27, train_loss = 1.9625346753746271, train_acc = 0.9951094550535631\n",
      "test Acc 0.9557728119180633:\n",
      "8th- epoch: 28, train_loss = 1.9140952043235302, train_acc = 0.9952258965999069\n",
      "test Acc 0.9553072625698324:\n",
      "8th- epoch: 29, train_loss = 1.8709461298567476, train_acc = 0.9951094550535631\n",
      "test Acc 0.9553072625698324:\n",
      "8th- epoch: 30, train_loss = 1.8220628527196823, train_acc = 0.9954587796925943\n",
      "test Acc 0.9562383612662942:\n",
      "8th- epoch: 31, train_loss = 1.7897000066004694, train_acc = 0.9953423381462506\n",
      "test Acc 0.9562383612662942:\n",
      "8th- epoch: 32, train_loss = 1.7510374522098573, train_acc = 0.9958081043316255\n",
      "test Acc 0.9562383612662942:\n",
      "8th- epoch: 33, train_loss = 1.7275072171614738, train_acc = 0.995575221238938\n",
      "test Acc 0.9562383612662942:\n",
      "8th- epoch: 34, train_loss = 1.6948962408714578, train_acc = 0.9959245458779693\n",
      "test Acc 0.9567039106145251:\n",
      "8th- epoch: 35, train_loss = 1.674049647837819, train_acc = 0.9959245458779693\n",
      "test Acc 0.9567039106145251:\n",
      "8th- epoch: 36, train_loss = 1.645297444112657, train_acc = 0.9959245458779693\n",
      "test Acc 0.957169459962756:\n",
      "8th- epoch: 37, train_loss = 1.6234532020389452, train_acc = 0.9959245458779693\n",
      "test Acc 0.957169459962756:\n",
      "8th- epoch: 38, train_loss = 1.6025107968598604, train_acc = 0.9959245458779693\n",
      "test Acc 0.957169459962756:\n",
      "8th- epoch: 39, train_loss = 1.5855635721236467, train_acc = 0.9959245458779693\n",
      "test Acc 0.957635009310987:\n",
      "8th- epoch: 40, train_loss = 1.5645040829331265, train_acc = 0.996040987424313\n",
      "test Acc 0.957169459962756:\n",
      "8th- epoch: 41, train_loss = 1.5537869200707064, train_acc = 0.996040987424313\n",
      "test Acc 0.957635009310987:\n",
      "8th- epoch: 42, train_loss = 1.53394078835845, train_acc = 0.996040987424313\n",
      "test Acc 0.9581005586592178:\n",
      "8th- epoch: 43, train_loss = 1.521067647729069, train_acc = 0.996040987424313\n",
      "test Acc 0.9581005586592178:\n",
      "8th- epoch: 44, train_loss = 1.5057635976336314, train_acc = 0.9961574289706567\n",
      "test Acc 0.9585661080074488:\n",
      "8th- epoch: 45, train_loss = 1.498030543945788, train_acc = 0.9961574289706567\n",
      "test Acc 0.9581005586592178:\n",
      "8th- epoch: 46, train_loss = 1.4803956891410053, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "8th- epoch: 47, train_loss = 1.4711398780345917, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "8th- epoch: 48, train_loss = 1.4600798215251416, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "8th- epoch: 49, train_loss = 1.4517529274671688, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "8th- epoch: 50, train_loss = 1.4381777396556572, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "8th- epoch: 51, train_loss = 1.4335792953279451, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "8th- epoch: 52, train_loss = 1.4216655154377804, train_acc = 0.996506753609688\n",
      "test Acc 0.9594972067039106:\n",
      "8th- epoch: 53, train_loss = 1.4140427308957442, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "8th- epoch: 54, train_loss = 1.400990927904786, train_acc = 0.9966231951560317\n",
      "test Acc 0.9594972067039106:\n",
      "8th- epoch: 55, train_loss = 1.398606860464497, train_acc = 0.9966231951560317\n",
      "test Acc 0.9594972067039106:\n",
      "8th- epoch: 56, train_loss = 1.386811379030405, train_acc = 0.9966231951560317\n",
      "test Acc 0.9594972067039106:\n",
      "8th- epoch: 57, train_loss = 1.3831831458956003, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "8th- epoch: 58, train_loss = 1.3747809452470392, train_acc = 0.996506753609688\n",
      "test Acc 0.9594972067039106:\n",
      "8th- epoch: 59, train_loss = 1.3652372871656553, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 60, train_loss = 1.360176516311185, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "8th- epoch: 61, train_loss = 1.3539134933744208, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 62, train_loss = 1.3486339754526853, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 63, train_loss = 1.3421313248909428, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 64, train_loss = 1.3373118656818406, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 65, train_loss = 1.3305637267185375, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 66, train_loss = 1.326715630981198, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 67, train_loss = 1.3197647512788535, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 68, train_loss = 1.3160281503442093, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 69, train_loss = 1.3105615488966578, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 70, train_loss = 1.3070882118990994, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 71, train_loss = 1.3012243762859725, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 72, train_loss = 1.298964087931381, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 73, train_loss = 1.2928533384911134, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 74, train_loss = 1.2904302469323738, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 75, train_loss = 1.2849556949586258, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "8th- epoch: 76, train_loss = 1.2829737034990103, train_acc = 0.9963903120633442\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 77, train_loss = 1.27900925938593, train_acc = 0.996506753609688\n",
      "test Acc 0.9613594040968343:\n",
      "8th- epoch: 78, train_loss = 1.273477580944018, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 79, train_loss = 1.2729087504558265, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 80, train_loss = 1.2696358532775776, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 81, train_loss = 1.2625498329653055, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 82, train_loss = 1.2632511996562243, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 83, train_loss = 1.258557832799852, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 84, train_loss = 1.2558674761094153, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 85, train_loss = 1.2509640808348195, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 86, train_loss = 1.2498780070673092, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 87, train_loss = 1.2477678346112953, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 88, train_loss = 1.2443296142519102, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 89, train_loss = 1.2411674152463092, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 90, train_loss = 1.2391754864584072, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 91, train_loss = 1.2350964515135274, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 92, train_loss = 1.2337400113101467, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 93, train_loss = 1.2305466691032052, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 94, train_loss = 1.2287828139960766, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 95, train_loss = 1.224995131175092, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 96, train_loss = 1.2248032790375873, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 97, train_loss = 1.2222371298921644, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 98, train_loss = 1.218909397990501, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 99, train_loss = 1.2177841289667413, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 100, train_loss = 1.2157099057585583, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 101, train_loss = 1.2127978736534715, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 102, train_loss = 1.211317640809284, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 103, train_loss = 1.2093856004066765, train_acc = 0.9969725197950629\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 104, train_loss = 1.2049305024556816, train_acc = 0.9970889613414066\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 105, train_loss = 1.2048486509229406, train_acc = 0.9969725197950629\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 106, train_loss = 1.2014727465939359, train_acc = 0.9969725197950629\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 107, train_loss = 1.2005246452390566, train_acc = 0.9970889613414066\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 108, train_loss = 1.1986735715399846, train_acc = 0.9970889613414066\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 109, train_loss = 1.1969802271705703, train_acc = 0.9970889613414066\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 110, train_loss = 1.195325243366824, train_acc = 0.9970889613414066\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 111, train_loss = 1.1918130818157806, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 112, train_loss = 1.1912903049160377, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 113, train_loss = 1.1895091361366212, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 114, train_loss = 1.187477099323587, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 115, train_loss = 1.1852969649844454, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 116, train_loss = 1.1825989861172275, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 117, train_loss = 1.1831402721218183, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 118, train_loss = 1.1820836110637174, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 119, train_loss = 1.1778345628044917, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 120, train_loss = 1.176718706417887, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 121, train_loss = 1.175823111552745, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 122, train_loss = 1.1737885902039125, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 123, train_loss = 1.1738862786442041, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 124, train_loss = 1.169442088190408, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 125, train_loss = 1.1680328912698315, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 126, train_loss = 1.1687869592569768, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 127, train_loss = 1.1672179237939417, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 128, train_loss = 1.1638726047240198, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 129, train_loss = 1.1635728164910688, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 130, train_loss = 1.1623161689713015, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 131, train_loss = 1.1611050812862231, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 132, train_loss = 1.1597389449962066, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 133, train_loss = 1.1560648380182101, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 134, train_loss = 1.1581559594123974, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 135, train_loss = 1.157037842553109, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 136, train_loss = 1.153541801184474, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 137, train_loss = 1.1535833440721035, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 138, train_loss = 1.1508093001320958, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 139, train_loss = 1.1497381141743972, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 140, train_loss = 1.1506965622902499, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 141, train_loss = 1.1478536459617317, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 142, train_loss = 1.1462486521340907, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 143, train_loss = 1.147398534383683, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 144, train_loss = 1.143567966606497, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 145, train_loss = 1.1415406799278571, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 146, train_loss = 1.1431632537096448, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 147, train_loss = 1.1414546843916469, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 148, train_loss = 1.1380503798536665, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 149, train_loss = 1.1377704405858822, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 150, train_loss = 1.1380782956257463, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 151, train_loss = 1.136052068322897, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 152, train_loss = 1.1353982269465632, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 153, train_loss = 1.1335061288737052, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 154, train_loss = 1.133144133415044, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 155, train_loss = 1.1327149265744083, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 156, train_loss = 1.1323421538509137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 157, train_loss = 1.1286168359220028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 158, train_loss = 1.1280030893794901, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 159, train_loss = 1.1271119055636518, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 160, train_loss = 1.1275881013534672, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 161, train_loss = 1.127616108085931, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 162, train_loss = 1.1257081981748343, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 163, train_loss = 1.124852366745472, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 164, train_loss = 1.1224984852597117, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 165, train_loss = 1.1234658282883174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 166, train_loss = 1.1221716819964058, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 167, train_loss = 1.1210974327586882, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 168, train_loss = 1.1195687260478735, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 169, train_loss = 1.1188669639341242, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 170, train_loss = 1.1184450512118929, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 171, train_loss = 1.1178751181178086, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 172, train_loss = 1.116894768550992, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 173, train_loss = 1.1150498467795842, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 174, train_loss = 1.115180168300867, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 175, train_loss = 1.1156179374083877, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 176, train_loss = 1.1132217111698992, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 177, train_loss = 1.1133898627012968, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 178, train_loss = 1.112737267587363, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 179, train_loss = 1.1109883496537805, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 180, train_loss = 1.110233834322571, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 181, train_loss = 1.1112189792729623, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 182, train_loss = 1.10865187831223, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 183, train_loss = 1.107397898722411, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 184, train_loss = 1.1071186438202858, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 185, train_loss = 1.1074749060608156, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 186, train_loss = 1.1071851175911434, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 187, train_loss = 1.105037200886727, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 188, train_loss = 1.1041320261247165, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 189, train_loss = 1.104496607247711, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 190, train_loss = 1.1039217375218868, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 191, train_loss = 1.1014864978678816, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 192, train_loss = 1.1010136641561985, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 193, train_loss = 1.101868615794956, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 194, train_loss = 1.1022253232076764, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 195, train_loss = 1.1005547953136556, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 196, train_loss = 1.0983083841092594, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 197, train_loss = 1.0991779038049572, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 198, train_loss = 1.0995002662129991, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 199, train_loss = 1.0964222503826022, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 200, train_loss = 1.0965432533994317, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 201, train_loss = 1.0963616355620616, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 202, train_loss = 1.09445362072438, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 203, train_loss = 1.0934788926206238, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 204, train_loss = 1.0941357401497953, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 205, train_loss = 1.0930750553197868, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 206, train_loss = 1.0918406924865849, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 207, train_loss = 1.091364669304312, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 208, train_loss = 1.0906982331835025, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 209, train_loss = 1.0903195121027238, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 210, train_loss = 1.0898297345265746, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 211, train_loss = 1.0893205789216154, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 212, train_loss = 1.088434999499441, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 213, train_loss = 1.087806451756478, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 214, train_loss = 1.0867802404500253, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 215, train_loss = 1.0863999454304576, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 216, train_loss = 1.0861897592731111, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 217, train_loss = 1.0850285617634654, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 218, train_loss = 1.084561531431973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 219, train_loss = 1.0837256979830272, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 220, train_loss = 1.084032286889851, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 221, train_loss = 1.0830764158927195, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 222, train_loss = 1.0834112549200654, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 223, train_loss = 1.0820032668598287, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 224, train_loss = 1.0814376234375231, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 225, train_loss = 1.08014065772295, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 226, train_loss = 1.0805691784880764, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 227, train_loss = 1.079728399094165, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 228, train_loss = 1.0791255145632022, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 229, train_loss = 1.0785102269910567, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 230, train_loss = 1.0782214878126979, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 231, train_loss = 1.0775134569666989, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 232, train_loss = 1.0773325798400037, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 233, train_loss = 1.0757434886581905, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 234, train_loss = 1.0755836078897119, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 235, train_loss = 1.0750765098891861, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 236, train_loss = 1.0737601707987778, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 237, train_loss = 1.0705505395308137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 238, train_loss = 1.0713666925839789, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 239, train_loss = 1.0712442640215158, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 240, train_loss = 1.0696463330350525, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 241, train_loss = 1.069454560365557, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 242, train_loss = 1.0689041266850836, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 243, train_loss = 1.0672466919459112, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 244, train_loss = 1.0680197197943926, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 245, train_loss = 1.0651025511324406, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 246, train_loss = 1.0651107573248737, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 247, train_loss = 1.0640698873139627, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 248, train_loss = 1.0634195542261295, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 249, train_loss = 1.0647956688590057, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 250, train_loss = 1.0634870973117359, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 251, train_loss = 1.064132206451177, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 252, train_loss = 1.0613849982619286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 253, train_loss = 1.0617469120770693, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 254, train_loss = 1.05865858433026, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 255, train_loss = 1.058438538264454, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 256, train_loss = 1.0580730130895972, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 257, train_loss = 1.057343323405803, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 258, train_loss = 1.0561736014969938, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 259, train_loss = 1.0572306755930185, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 260, train_loss = 1.0551618638746731, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 261, train_loss = 1.0552686235569126, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 262, train_loss = 1.0561793074011803, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 263, train_loss = 1.05514372543621, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 264, train_loss = 1.0532485926523805, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 265, train_loss = 1.0540863132737286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 266, train_loss = 1.0530971235893958, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 267, train_loss = 1.0515065278559632, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 268, train_loss = 1.0520567276216752, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 269, train_loss = 1.0526718331202574, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 270, train_loss = 1.0504318502098613, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 271, train_loss = 1.0506094458214648, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 272, train_loss = 1.0498504511378997, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 273, train_loss = 1.0481049045920372, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 274, train_loss = 1.0486774947494268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 275, train_loss = 1.0488307431041903, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 276, train_loss = 1.0469817787707143, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 277, train_loss = 1.048406551435619, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 278, train_loss = 1.046169643446774, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 279, train_loss = 1.0464410038366623, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 280, train_loss = 1.045704189222306, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 281, train_loss = 1.0462757608220272, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 282, train_loss = 1.0449138272851997, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 283, train_loss = 1.0452148605436378, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 284, train_loss = 1.0439910952300124, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 285, train_loss = 1.0436411718837917, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 286, train_loss = 1.0422989842481911, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 287, train_loss = 1.0426025572232902, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 288, train_loss = 1.0436453057154722, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 289, train_loss = 1.040735942311585, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 290, train_loss = 1.0417293488681025, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 291, train_loss = 1.040050187613815, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 292, train_loss = 1.0411137117371254, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 293, train_loss = 1.0405992208980024, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 294, train_loss = 1.0390720303803391, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 295, train_loss = 1.0394893678203516, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 296, train_loss = 1.0384698840789497, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 297, train_loss = 1.0380018989853852, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 298, train_loss = 1.0383947868831456, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 299, train_loss = 1.0368686667643487, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 300, train_loss = 1.0374494488351047, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 301, train_loss = 1.0364594259299338, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 302, train_loss = 1.0358239323832095, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 303, train_loss = 1.0362075438424654, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 304, train_loss = 1.0348033177033358, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 305, train_loss = 1.0357257779687643, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 306, train_loss = 1.0345931967422075, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 307, train_loss = 1.0347958994098008, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 308, train_loss = 1.03304999725151, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 309, train_loss = 1.0332251655236178, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 310, train_loss = 1.0324004270769365, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 311, train_loss = 1.0329228493683331, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 312, train_loss = 1.033080853831052, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 313, train_loss = 1.0309315345548384, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 314, train_loss = 1.0318233796097047, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 315, train_loss = 1.0308760202788108, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 316, train_loss = 1.0305200147740834, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 317, train_loss = 1.031018298741401, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 318, train_loss = 1.0294446616135247, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 319, train_loss = 1.0304599907249212, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 320, train_loss = 1.0284489368386858, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 321, train_loss = 1.0289360458664305, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 322, train_loss = 1.028156134299934, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 323, train_loss = 1.0274881894401915, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 324, train_loss = 1.028028360567987, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 325, train_loss = 1.027631144348561, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 326, train_loss = 1.0268965379036672, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 327, train_loss = 1.0258798460308753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 328, train_loss = 1.0258218261114962, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 329, train_loss = 1.0255682400129444, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 330, train_loss = 1.0253732896708243, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 331, train_loss = 1.0254785561301105, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 332, train_loss = 1.0252152569592, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 333, train_loss = 1.0237673328556411, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 334, train_loss = 1.0230715153738856, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 335, train_loss = 1.0217237252109044, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 336, train_loss = 1.0224269765130884, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 337, train_loss = 1.0215289055668109, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 338, train_loss = 1.0218896945007145, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 339, train_loss = 1.0200720019638538, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 340, train_loss = 1.0204835195727355, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 341, train_loss = 1.0208314371593588, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 342, train_loss = 1.020480635266722, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 343, train_loss = 1.0184282837435603, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 344, train_loss = 1.017755979206413, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 345, train_loss = 1.018397148076474, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 346, train_loss = 1.0184234571643174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 347, train_loss = 1.0176481644921296, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 348, train_loss = 1.0173621204048686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 349, train_loss = 1.0169916513077624, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 350, train_loss = 1.0175694113895588, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 351, train_loss = 1.0172783530615561, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 352, train_loss = 1.0151021011806733, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 353, train_loss = 1.0160509617999196, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 354, train_loss = 1.014908818371623, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 355, train_loss = 1.0156562921292789, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 356, train_loss = 1.0156172647439234, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 357, train_loss = 1.0152400744445913, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 358, train_loss = 1.0131522262236103, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 359, train_loss = 1.014099007781624, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 360, train_loss = 1.0127609819173813, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 361, train_loss = 1.0127157229399018, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 362, train_loss = 1.012501299574069, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 363, train_loss = 1.011807517032139, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 364, train_loss = 1.0111905540106818, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 365, train_loss = 1.0123379651522555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 366, train_loss = 1.0104668803578534, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 367, train_loss = 1.0106601974694058, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 368, train_loss = 1.0098580268277146, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 369, train_loss = 1.0112409682078578, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 370, train_loss = 1.0118089747084014, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 371, train_loss = 1.0110756263202347, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 372, train_loss = 1.0085409100865945, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 373, train_loss = 1.0086460551647178, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 374, train_loss = 1.0093578001251444, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 375, train_loss = 1.008144738345436, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 376, train_loss = 1.0075736893741123, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 377, train_loss = 1.0071364779723808, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 378, train_loss = 1.00713463379725, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 379, train_loss = 1.0084469818575599, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 380, train_loss = 1.0076641537780233, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 381, train_loss = 1.0070529550830543, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 382, train_loss = 1.0051113797235303, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 383, train_loss = 1.0054493247116625, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 384, train_loss = 1.0052539961761795, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 385, train_loss = 1.0053402395169542, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 386, train_loss = 1.0046177870644897, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 387, train_loss = 1.004837508098717, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 388, train_loss = 1.0042053133765876, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 389, train_loss = 1.004289366712328, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 390, train_loss = 1.0032527826442674, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 391, train_loss = 1.0031830634979997, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 392, train_loss = 1.0027075597899966, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 393, train_loss = 1.0031273447202693, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 394, train_loss = 1.0020595758578565, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 395, train_loss = 1.002187291305745, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 396, train_loss = 1.0026623653939168, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 397, train_loss = 1.0018495048752811, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 398, train_loss = 1.0010870869919017, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 399, train_loss = 1.0007245212509588, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 400, train_loss = 1.000993761641439, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 401, train_loss = 1.0004725519283966, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 402, train_loss = 0.9999604642107442, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 403, train_loss = 0.9997173812589608, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 404, train_loss = 0.998987152648624, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 405, train_loss = 0.9987570025841706, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 406, train_loss = 0.998344912291941, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 407, train_loss = 0.9994178818888031, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 408, train_loss = 0.9995683677079796, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 409, train_loss = 0.999422527715069, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 410, train_loss = 0.9973284482839517, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 411, train_loss = 0.9967113951570354, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 412, train_loss = 0.9968062273874239, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 413, train_loss = 0.996239677479025, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 414, train_loss = 0.9960710435225337, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 415, train_loss = 0.9963278324394196, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 416, train_loss = 0.9956982506155327, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 417, train_loss = 0.9954655081382953, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 418, train_loss = 0.995499242504593, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 419, train_loss = 0.9950898733804934, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 420, train_loss = 0.9949329946539365, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 421, train_loss = 0.9937717194552533, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 422, train_loss = 0.9947796749947884, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 423, train_loss = 0.9945967892999761, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 424, train_loss = 0.9928879058388702, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 425, train_loss = 0.9927191421156749, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 426, train_loss = 0.9932847417658195, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 427, train_loss = 0.9924261365486018, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 428, train_loss = 0.9919825833057985, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 429, train_loss = 0.9918224323773757, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 430, train_loss = 0.9914201073115692, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 431, train_loss = 0.9909362330035947, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 432, train_loss = 0.9912843588972464, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 433, train_loss = 0.9900939222025045, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 434, train_loss = 0.9907078976211778, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 435, train_loss = 0.9907497934000276, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 436, train_loss = 0.9905207738047466, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 437, train_loss = 0.9893271928885952, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 438, train_loss = 0.9891810709377751, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 439, train_loss = 0.9879922115178488, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 440, train_loss = 0.9886935306312807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 441, train_loss = 0.9880083584757813, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 442, train_loss = 0.9886062511177443, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 443, train_loss = 0.9886561092753254, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 444, train_loss = 0.9876563436882861, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 445, train_loss = 0.9874347061850131, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 446, train_loss = 0.9870250064013817, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 447, train_loss = 0.9863223245665722, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 448, train_loss = 0.9863042692486488, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 449, train_loss = 0.9861341112227819, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 450, train_loss = 0.9857864647237875, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 451, train_loss = 0.9854083992140659, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 452, train_loss = 0.9855732945325144, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 453, train_loss = 0.9852415363238833, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 454, train_loss = 0.9845330095085956, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 455, train_loss = 0.9857805299870961, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 456, train_loss = 0.9847885986855545, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 457, train_loss = 0.9838780336249329, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 458, train_loss = 0.9841741758864373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 459, train_loss = 0.9835422872965864, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 460, train_loss = 0.9836992870550603, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 461, train_loss = 0.9830376292411529, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 462, train_loss = 0.9826262343740382, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 463, train_loss = 0.9823451720876619, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 464, train_loss = 0.9822557879779197, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 465, train_loss = 0.9817521597724408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 466, train_loss = 0.9816289213886193, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 467, train_loss = 0.9810883357022249, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 468, train_loss = 0.981663866667077, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 469, train_loss = 0.9806865368736908, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 470, train_loss = 0.980412559776596, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 471, train_loss = 0.9805947198365175, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 472, train_loss = 0.979730586095684, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 473, train_loss = 0.9799047169108235, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 474, train_loss = 0.9800301890354604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 475, train_loss = 0.9786756602516107, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 476, train_loss = 0.9793487258320965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 477, train_loss = 0.9794521261937916, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 478, train_loss = 0.9786122522782534, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 479, train_loss = 0.9779015430649451, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 480, train_loss = 0.9774418534179858, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 481, train_loss = 0.9776260599610396, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 482, train_loss = 0.977451466529601, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 483, train_loss = 0.9763744461051829, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 484, train_loss = 0.9780058100186579, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 485, train_loss = 0.9773296556850255, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 486, train_loss = 0.9764070444507524, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 487, train_loss = 0.9756119543053501, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 488, train_loss = 0.9758905718335882, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 489, train_loss = 0.9756273505045101, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 490, train_loss = 0.9746909419882286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 491, train_loss = 0.9753089299665589, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 492, train_loss = 0.9750118967895105, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 493, train_loss = 0.9751737186343234, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 494, train_loss = 0.974157731019659, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 495, train_loss = 0.9742482285073493, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 496, train_loss = 0.9742279902457085, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 497, train_loss = 0.9743707368797914, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 498, train_loss = 0.9733386594270996, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 499, train_loss = 0.9731962471669249, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|████████████████████▌                                                        | 8/30 [1:12:34<3:20:17, 546.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "9th- epoch: 0, train_loss = 333.6544457525015, train_acc = 0.817768979972054\n",
      "test Acc 0.8477653631284916:\n",
      "9th- epoch: 1, train_loss = 96.06964146345854, train_acc = 0.926059618071728\n",
      "test Acc 0.9348230912476723:\n",
      "9th- epoch: 2, train_loss = 61.33372279396281, train_acc = 0.9487657196087564\n",
      "test Acc 0.9390130353817505:\n",
      "9th- epoch: 3, train_loss = 43.174013026989996, train_acc = 0.9590125756870052\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 4, train_loss = 32.191155852982774, train_acc = 0.9659990684676293\n",
      "test Acc 0.9436685288640596:\n",
      "9th- epoch: 5, train_loss = 24.60923311416991, train_acc = 0.9721704704238472\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 6, train_loss = 19.08418269851245, train_acc = 0.9774103400093154\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 7, train_loss = 15.021945688407868, train_acc = 0.9804378202142524\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 8, train_loss = 12.11009416426532, train_acc = 0.9838146250582208\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 9, train_loss = 9.873128408333287, train_acc = 0.9870749883558454\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 10, train_loss = 8.289597499882802, train_acc = 0.9887051700046576\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 11, train_loss = 7.0645099631510675, train_acc = 0.9899860270144387\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 12, train_loss = 6.073729118332267, train_acc = 0.9911504424778761\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 13, train_loss = 5.314975251909345, train_acc = 0.9917326502095948\n",
      "test Acc 0.9506517690875232:\n",
      "9th- epoch: 14, train_loss = 4.708842372521758, train_acc = 0.9925477410340009\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 15, train_loss = 4.178580044303089, train_acc = 0.9926641825803446\n",
      "test Acc 0.9506517690875232:\n",
      "9th- epoch: 16, train_loss = 3.7705243865493685, train_acc = 0.9935957149510946\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 17, train_loss = 3.4331325504463166, train_acc = 0.994294364229157\n",
      "test Acc 0.9515828677839852:\n",
      "9th- epoch: 18, train_loss = 3.1636410476639867, train_acc = 0.9945272473218444\n",
      "test Acc 0.952513966480447:\n",
      "9th- epoch: 19, train_loss = 2.9289616227615625, train_acc = 0.9948765719608756\n",
      "test Acc 0.952048417132216:\n",
      "9th- epoch: 20, train_loss = 2.7279341083485633, train_acc = 0.9951094550535631\n",
      "test Acc 0.952513966480447:\n",
      "9th- epoch: 21, train_loss = 2.535885861609131, train_acc = 0.9947601304145319\n",
      "test Acc 0.952513966480447:\n",
      "9th- epoch: 22, train_loss = 2.371987360762432, train_acc = 0.9949930135072194\n",
      "test Acc 0.9529795158286778:\n",
      "9th- epoch: 23, train_loss = 2.231908127083443, train_acc = 0.9952258965999069\n",
      "test Acc 0.9529795158286778:\n",
      "9th- epoch: 24, train_loss = 2.1174243359128013, train_acc = 0.9953423381462506\n",
      "test Acc 0.952048417132216:\n",
      "9th- epoch: 25, train_loss = 2.0227089941035956, train_acc = 0.9954587796925943\n",
      "test Acc 0.952513966480447:\n",
      "9th- epoch: 26, train_loss = 1.9491110139060766, train_acc = 0.995575221238938\n",
      "test Acc 0.9529795158286778:\n",
      "9th- epoch: 27, train_loss = 1.8898231823695824, train_acc = 0.9958081043316255\n",
      "test Acc 0.9539106145251397:\n",
      "9th- epoch: 28, train_loss = 1.843937853584066, train_acc = 0.9959245458779693\n",
      "test Acc 0.9543761638733705:\n",
      "9th- epoch: 29, train_loss = 1.8064745299052447, train_acc = 0.996040987424313\n",
      "test Acc 0.9543761638733705:\n",
      "9th- epoch: 30, train_loss = 1.7746366228093393, train_acc = 0.996040987424313\n",
      "test Acc 0.9553072625698324:\n",
      "9th- epoch: 31, train_loss = 1.7385544329299591, train_acc = 0.996040987424313\n",
      "test Acc 0.9553072625698324:\n",
      "9th- epoch: 32, train_loss = 1.7092858781688847, train_acc = 0.9961574289706567\n",
      "test Acc 0.9557728119180633:\n",
      "9th- epoch: 33, train_loss = 1.6932271852274425, train_acc = 0.9961574289706567\n",
      "test Acc 0.9562383612662942:\n",
      "9th- epoch: 34, train_loss = 1.6659609868074767, train_acc = 0.9961574289706567\n",
      "test Acc 0.9553072625698324:\n",
      "9th- epoch: 35, train_loss = 1.6465059200418182, train_acc = 0.9961574289706567\n",
      "test Acc 0.9553072625698324:\n",
      "9th- epoch: 36, train_loss = 1.6283229351392947, train_acc = 0.9961574289706567\n",
      "test Acc 0.9562383612662942:\n",
      "9th- epoch: 37, train_loss = 1.6109835025272332, train_acc = 0.9961574289706567\n",
      "test Acc 0.9557728119180633:\n",
      "9th- epoch: 38, train_loss = 1.5945519336964935, train_acc = 0.9961574289706567\n",
      "test Acc 0.9553072625698324:\n",
      "9th- epoch: 39, train_loss = 1.5829904931597412, train_acc = 0.9961574289706567\n",
      "test Acc 0.9557728119180633:\n",
      "9th- epoch: 40, train_loss = 1.5664567317289766, train_acc = 0.9961574289706567\n",
      "test Acc 0.9557728119180633:\n",
      "9th- epoch: 41, train_loss = 1.5494967769773211, train_acc = 0.9962738705170004\n",
      "test Acc 0.9562383612662942:\n",
      "9th- epoch: 42, train_loss = 1.5362440811877605, train_acc = 0.9962738705170004\n",
      "test Acc 0.9567039106145251:\n",
      "9th- epoch: 43, train_loss = 1.5276579571946058, train_acc = 0.9962738705170004\n",
      "test Acc 0.957169459962756:\n",
      "9th- epoch: 44, train_loss = 1.5128585079219192, train_acc = 0.9962738705170004\n",
      "test Acc 0.957635009310987:\n",
      "9th- epoch: 45, train_loss = 1.50119805461145, train_acc = 0.9962738705170004\n",
      "test Acc 0.957169459962756:\n",
      "9th- epoch: 46, train_loss = 1.4874284050893039, train_acc = 0.9962738705170004\n",
      "test Acc 0.957635009310987:\n",
      "9th- epoch: 47, train_loss = 1.4781743695493788, train_acc = 0.9962738705170004\n",
      "test Acc 0.957169459962756:\n",
      "9th- epoch: 48, train_loss = 1.4702424823772162, train_acc = 0.9962738705170004\n",
      "test Acc 0.957635009310987:\n",
      "9th- epoch: 49, train_loss = 1.4582424809632357, train_acc = 0.9962738705170004\n",
      "test Acc 0.957635009310987:\n",
      "9th- epoch: 50, train_loss = 1.451320727210259, train_acc = 0.9962738705170004\n",
      "test Acc 0.9581005586592178:\n",
      "9th- epoch: 51, train_loss = 1.4384637037292123, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 52, train_loss = 1.4346147381293122, train_acc = 0.9962738705170004\n",
      "test Acc 0.9581005586592178:\n",
      "9th- epoch: 53, train_loss = 1.4200730910524726, train_acc = 0.9962738705170004\n",
      "test Acc 0.9585661080074488:\n",
      "9th- epoch: 54, train_loss = 1.4188425266183913, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "9th- epoch: 55, train_loss = 1.408258166484302, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 56, train_loss = 1.4016426437010523, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 57, train_loss = 1.3947127872670535, train_acc = 0.9962738705170004\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 58, train_loss = 1.3912699439097196, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "9th- epoch: 59, train_loss = 1.3809207825397607, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "9th- epoch: 60, train_loss = 1.377238171407953, train_acc = 0.996506753609688\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 61, train_loss = 1.3683006038481835, train_acc = 0.996506753609688\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 62, train_loss = 1.3658574977016542, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 63, train_loss = 1.3604673039226327, train_acc = 0.9966231951560317\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 64, train_loss = 1.3551281086110976, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 65, train_loss = 1.3468816584500019, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 66, train_loss = 1.3451138026139233, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 67, train_loss = 1.3380481725616846, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 68, train_loss = 1.3331503981316928, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 69, train_loss = 1.3297516619059024, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 70, train_loss = 1.322746258461848, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 71, train_loss = 1.3207506353792269, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 72, train_loss = 1.3172846970555838, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 73, train_loss = 1.314927366678603, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 74, train_loss = 1.3066855582874268, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 75, train_loss = 1.3069858267699601, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 76, train_loss = 1.2985371608228888, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 77, train_loss = 1.2986165042966604, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 78, train_loss = 1.2936619000247447, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 79, train_loss = 1.289592960922164, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 80, train_loss = 1.2870755674521206, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 81, train_loss = 1.285697304061614, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 82, train_loss = 1.2786121612443822, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 83, train_loss = 1.2769531051599188, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 84, train_loss = 1.2738839214871405, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 85, train_loss = 1.2722715081908973, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 86, train_loss = 1.2677952938975068, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 87, train_loss = 1.265136713438551, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 88, train_loss = 1.2614525396638783, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 89, train_loss = 1.25719641293108, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 90, train_loss = 1.256500047747977, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 91, train_loss = 1.2522035837755539, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 92, train_loss = 1.2536851944896625, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 93, train_loss = 1.2482803891180083, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 94, train_loss = 1.2438230701518478, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 95, train_loss = 1.242447642769548, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 96, train_loss = 1.2396665806882083, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 97, train_loss = 1.2408901088638231, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 98, train_loss = 1.2360173274064437, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 99, train_loss = 1.2305967198917642, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 100, train_loss = 1.2316674587782472, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 101, train_loss = 1.228726282948628, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 102, train_loss = 1.2275544148869812, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 103, train_loss = 1.2220293420687085, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 104, train_loss = 1.220396517237532, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 105, train_loss = 1.217757563033956, train_acc = 0.9969725197950629\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 106, train_loss = 1.214929582507466, train_acc = 0.9969725197950629\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 107, train_loss = 1.2139230723987566, train_acc = 0.9969725197950629\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 108, train_loss = 1.2125818194326712, train_acc = 0.9969725197950629\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 109, train_loss = 1.2109362502087606, train_acc = 0.9969725197950629\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 110, train_loss = 1.2116202565375715, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 111, train_loss = 1.2101474549417617, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 112, train_loss = 1.2074631794093875, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 113, train_loss = 1.2055790139129385, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 114, train_loss = 1.204258439989644, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 115, train_loss = 1.2022081427276134, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 116, train_loss = 1.2014354272541823, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 117, train_loss = 1.2007795725949109, train_acc = 0.9970889613414066\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 118, train_loss = 1.2008465946855722, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 119, train_loss = 1.1962038499041228, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 120, train_loss = 1.1948146175127476, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 121, train_loss = 1.1940312773658661, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 122, train_loss = 1.1915230516606243, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 123, train_loss = 1.1909137777256547, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 124, train_loss = 1.1902187860105187, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 125, train_loss = 1.1879767449572682, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 126, train_loss = 1.1848516274912981, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 127, train_loss = 1.1843638645950705, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 128, train_loss = 1.1824657913966803, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 129, train_loss = 1.1817040008754702, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 130, train_loss = 1.18262135128316, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 131, train_loss = 1.1791527766763465, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 132, train_loss = 1.1777757233940065, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 133, train_loss = 1.1754289621749194, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 134, train_loss = 1.1773366797715425, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 135, train_loss = 1.1744865523214685, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 136, train_loss = 1.174236318023759, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 137, train_loss = 1.171602945891209, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 138, train_loss = 1.1709558611473767, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 139, train_loss = 1.1670893329428509, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 140, train_loss = 1.1684741751960246, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 141, train_loss = 1.1642652952141361, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 142, train_loss = 1.1635493571666302, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 143, train_loss = 1.1626189550152048, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 144, train_loss = 1.1610736157017527, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 145, train_loss = 1.1592625980265439, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 146, train_loss = 1.1595467753504636, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 147, train_loss = 1.1574442293931497, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 148, train_loss = 1.156788370150025, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 149, train_loss = 1.1569649890298024, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 150, train_loss = 1.155857341873343, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 151, train_loss = 1.154377598737483, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 152, train_loss = 1.1531169030349702, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 153, train_loss = 1.1513406370795565, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 154, train_loss = 1.150523649994284, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 155, train_loss = 1.1480670539895073, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 156, train_loss = 1.1476646668743342, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 157, train_loss = 1.148648401562241, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 158, train_loss = 1.1473021910060197, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 159, train_loss = 1.144370842652279, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 160, train_loss = 1.1451741311029764, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 161, train_loss = 1.1434509931132197, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 162, train_loss = 1.1433535804244457, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 163, train_loss = 1.1401752654201118, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 164, train_loss = 1.1396678195596905, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 165, train_loss = 1.1371834991296055, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 166, train_loss = 1.1374354783183662, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 167, train_loss = 1.138990969004226, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 168, train_loss = 1.1358097434713272, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 169, train_loss = 1.1353854481858434, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 170, train_loss = 1.1324481894262135, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 171, train_loss = 1.1322644789033802, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 172, train_loss = 1.130690803125617, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 173, train_loss = 1.1293296748044668, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 174, train_loss = 1.129957744225976, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 175, train_loss = 1.1271272720041452, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 176, train_loss = 1.1260524142271606, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 177, train_loss = 1.1252289861440659, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 178, train_loss = 1.1240121012815507, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 179, train_loss = 1.121434485001373, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 180, train_loss = 1.122616331325844, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 181, train_loss = 1.1213867835904239, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 182, train_loss = 1.1185171869583428, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 183, train_loss = 1.119951480999589, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 184, train_loss = 1.119244315123069, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 185, train_loss = 1.1182216212619096, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 186, train_loss = 1.1156466349493712, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 187, train_loss = 1.11712216748856, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 188, train_loss = 1.115626489976421, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 189, train_loss = 1.1153505334368674, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 190, train_loss = 1.1140446197241545, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 191, train_loss = 1.1136028269102098, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 192, train_loss = 1.1129127241874812, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 193, train_loss = 1.111152034252882, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 194, train_loss = 1.1103853375389008, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 195, train_loss = 1.1095194600784453, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 196, train_loss = 1.110177400682005, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 197, train_loss = 1.1092398705222877, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 198, train_loss = 1.1082304454612313, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 199, train_loss = 1.106589644914493, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 200, train_loss = 1.1070008552633226, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 201, train_loss = 1.1053608013753546, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 202, train_loss = 1.1048347327159718, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 203, train_loss = 1.1034426402766258, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 204, train_loss = 1.104237716368516, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 205, train_loss = 1.1022457230865257, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 206, train_loss = 1.1027573376195505, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 207, train_loss = 1.1024777196143987, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 208, train_loss = 1.100091002881527, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 209, train_loss = 1.1013881664257497, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 210, train_loss = 1.1026047853956698, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 211, train_loss = 1.09806919679977, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 212, train_loss = 1.0999874880799325, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 213, train_loss = 1.098080737676355, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 214, train_loss = 1.0966820706817089, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 215, train_loss = 1.0976006365381181, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 216, train_loss = 1.0954899056378054, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 217, train_loss = 1.0941189915902214, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 218, train_loss = 1.0953319496911718, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 219, train_loss = 1.0945531603210839, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 220, train_loss = 1.0922610690031433, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 221, train_loss = 1.0927589633065509, train_acc = 0.9973218444340941\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 222, train_loss = 1.0919960444007302, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 223, train_loss = 1.0921570897771744, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 224, train_loss = 1.0914849086402683, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 225, train_loss = 1.0886546814726898, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 226, train_loss = 1.0898313529178267, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 227, train_loss = 1.088621964401682, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 228, train_loss = 1.0880609339437797, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 229, train_loss = 1.0873536584549583, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 230, train_loss = 1.0875862207030877, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 231, train_loss = 1.0854772731327103, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 232, train_loss = 1.0887723912019283, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 233, train_loss = 1.0859572871995624, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 234, train_loss = 1.0835259210216464, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 235, train_loss = 1.0871025477026706, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 236, train_loss = 1.0832457039869041, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 237, train_loss = 1.084597421118815, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 238, train_loss = 1.0826219129012316, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 239, train_loss = 1.0818188553093933, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 240, train_loss = 1.0801041561571765, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 241, train_loss = 1.0815692560572643, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 242, train_loss = 1.0796004635340068, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 243, train_loss = 1.0804875671528862, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 244, train_loss = 1.0787175621371716, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 245, train_loss = 1.077304835722316, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 246, train_loss = 1.0783030661114026, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 247, train_loss = 1.0776662883945392, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 248, train_loss = 1.077337205868389, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 249, train_loss = 1.0752236193875433, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 250, train_loss = 1.076056568941567, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 251, train_loss = 1.0750164172713994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 252, train_loss = 1.0754753513392643, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 253, train_loss = 1.0747684981542989, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 254, train_loss = 1.0733496640459634, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 255, train_loss = 1.0735006275353953, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 256, train_loss = 1.0721144951312453, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 257, train_loss = 1.0731848460491165, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 258, train_loss = 1.0710813975092606, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 259, train_loss = 1.0721401928094565, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 260, train_loss = 1.0706132514751516, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 261, train_loss = 1.0706519632367417, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 262, train_loss = 1.0695549786905758, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 263, train_loss = 1.0682556270985515, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 264, train_loss = 1.0691548092872836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 265, train_loss = 1.0687846781002008, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 266, train_loss = 1.067141860279662, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 267, train_loss = 1.0648742937119096, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 268, train_loss = 1.0668103288116981, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 269, train_loss = 1.0654593250583275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 270, train_loss = 1.0661504981690086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 271, train_loss = 1.0648159842021414, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 272, train_loss = 1.0631124506835476, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 273, train_loss = 1.0648833131417632, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 274, train_loss = 1.0635927203984465, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 275, train_loss = 1.0623306981797214, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 276, train_loss = 1.0633926047376008, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 277, train_loss = 1.0608435726971948, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 278, train_loss = 1.0623409137697308, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 279, train_loss = 1.0612065349632758, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 280, train_loss = 1.0611524335326976, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 281, train_loss = 1.060880792880198, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 282, train_loss = 1.0608207532277447, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 283, train_loss = 1.059760075993836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 284, train_loss = 1.0584144559397828, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 285, train_loss = 1.0611889420179068, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 286, train_loss = 1.0578957464313135, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 287, train_loss = 1.058955816028174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 288, train_loss = 1.0569311272993218, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 289, train_loss = 1.0590026819481864, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 290, train_loss = 1.0564566734610707, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 291, train_loss = 1.0580636790837161, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 292, train_loss = 1.0556285443381057, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 293, train_loss = 1.0556832506554201, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 294, train_loss = 1.0535536090101232, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 295, train_loss = 1.0558566981562763, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 296, train_loss = 1.055003661334922, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 297, train_loss = 1.051464962794853, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 298, train_loss = 1.052240223478293, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 299, train_loss = 1.0514496951873298, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 300, train_loss = 1.0509987825644203, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 301, train_loss = 1.0513083694168017, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 302, train_loss = 1.050641116045881, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 303, train_loss = 1.0502274846148794, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 304, train_loss = 1.050481164282246, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 305, train_loss = 1.0495876029963256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 306, train_loss = 1.0493343189664301, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 307, train_loss = 1.0487974261268391, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 308, train_loss = 1.048671821867174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 309, train_loss = 1.0465928202975192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 310, train_loss = 1.046954359364463, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 311, train_loss = 1.0458871499504312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 312, train_loss = 1.0463432508331607, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 313, train_loss = 1.0482330598388216, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 314, train_loss = 1.0460509609911242, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 315, train_loss = 1.0437642857359606, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 316, train_loss = 1.0460480538677075, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 317, train_loss = 1.0438315669525764, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 318, train_loss = 1.044859242043458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 319, train_loss = 1.0430452777436585, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 320, train_loss = 1.0434094903976074, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 321, train_loss = 1.041666304015962, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 322, train_loss = 1.0441494291299023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 323, train_loss = 1.0417632376775146, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 324, train_loss = 1.0434340287174564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 325, train_loss = 1.042486654878303, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 326, train_loss = 1.0400900034292135, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 327, train_loss = 1.0405914715738618, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 328, train_loss = 1.0406196266121697, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 329, train_loss = 1.0399450631739455, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 330, train_loss = 1.0395112100522965, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 331, train_loss = 1.0388546489048167, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 332, train_loss = 1.038888778675755, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 333, train_loss = 1.0373103038218687, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 334, train_loss = 1.037648421828635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 335, train_loss = 1.0371583176529384, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 336, train_loss = 1.0365507902970421, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 337, train_loss = 1.0370540636358783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 338, train_loss = 1.037257111951476, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 339, train_loss = 1.036263202848204, train_acc = 0.9974382859804378\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 340, train_loss = 1.0342656568391249, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 341, train_loss = 1.0345889834788977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 342, train_loss = 1.0339914540891186, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 343, train_loss = 1.0366007457487285, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 344, train_loss = 1.033228571737709, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 345, train_loss = 1.0336008970043622, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 346, train_loss = 1.0362561813963111, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 347, train_loss = 1.0317877957495512, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 348, train_loss = 1.0338238402327988, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 349, train_loss = 1.0322546388415503, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 350, train_loss = 1.0346592843416147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 351, train_loss = 1.031384830661409, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 352, train_loss = 1.0328503391356207, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 353, train_loss = 1.0301259931366076, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 354, train_loss = 1.0315868997058715, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 355, train_loss = 1.0276091278428794, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 356, train_loss = 1.031119005077926, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 357, train_loss = 1.0300430781862815, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 358, train_loss = 1.0284812242607586, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 359, train_loss = 1.0273068546302966, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 360, train_loss = 1.0262776408708305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 361, train_loss = 1.0278509028357803, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 362, train_loss = 1.0264995198740507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 363, train_loss = 1.0276451987811015, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 364, train_loss = 1.0266211369962548, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 365, train_loss = 1.0265116270966246, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 366, train_loss = 1.0249178739686613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 367, train_loss = 1.024177467385016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 368, train_loss = 1.0237057451959117, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 369, train_loss = 1.0248287590511609, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 370, train_loss = 1.0240624404686969, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 371, train_loss = 1.0238380846058135, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 372, train_loss = 1.0238208330629277, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 373, train_loss = 1.022860397475597, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 374, train_loss = 1.023120165707951, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 375, train_loss = 1.0247410964875598, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 376, train_loss = 1.022098552370153, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 377, train_loss = 1.0211875176682952, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 378, train_loss = 1.023997811404115, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 379, train_loss = 1.0211386643641163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 380, train_loss = 1.0227168638302828, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 381, train_loss = 1.0201137376207043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 382, train_loss = 1.022080426766479, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 383, train_loss = 1.0197712694862275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 384, train_loss = 1.0215919858383131, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 385, train_loss = 1.0187548710746341, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 386, train_loss = 1.0208984760101885, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 387, train_loss = 1.0173186038809945, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 388, train_loss = 1.0187857566852472, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 389, train_loss = 1.0202891195003758, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 390, train_loss = 1.0169194749905728, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 391, train_loss = 1.019442852040811, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 392, train_loss = 1.019891885924153, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 393, train_loss = 1.0174381734032067, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 394, train_loss = 1.01501703003305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 395, train_loss = 1.0158709166498738, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 396, train_loss = 1.0149520701961592, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 397, train_loss = 1.0145432145582163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 398, train_loss = 1.0154641985500348, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 399, train_loss = 1.0149799134160276, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 400, train_loss = 1.0138141919087502, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 401, train_loss = 1.0140204405688564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 402, train_loss = 1.0127845606548362, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 403, train_loss = 1.013502526540833, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 404, train_loss = 1.0128453743600403, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 405, train_loss = 1.0130477587881614, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 406, train_loss = 1.0116328072108445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 407, train_loss = 1.0120225012651645, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 408, train_loss = 1.0101453610186581, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 409, train_loss = 1.011349620508554, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 410, train_loss = 1.0095921146203182, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 411, train_loss = 1.01182210969273, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 412, train_loss = 1.0084969075978734, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 413, train_loss = 1.0108502428556676, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 414, train_loss = 1.0097094396842294, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 415, train_loss = 1.0086931833138806, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 416, train_loss = 1.011115923327452, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 417, train_loss = 1.007963798037963, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 418, train_loss = 1.0108262571229716, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 419, train_loss = 1.0072493893603678, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 420, train_loss = 1.0100923064164817, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 421, train_loss = 1.0079668218022562, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 422, train_loss = 1.0076470383719425, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 423, train_loss = 1.005877774914552, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 424, train_loss = 1.0068537365077646, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 425, train_loss = 1.005999995075399, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 426, train_loss = 1.005432348465547, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 427, train_loss = 1.0058984816205339, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 428, train_loss = 1.0045141208320274, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 429, train_loss = 1.0053997544091544, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 430, train_loss = 1.0040958287063404, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 431, train_loss = 1.00358877992403, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 432, train_loss = 1.0024418627508567, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 433, train_loss = 1.0040276735671796, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 434, train_loss = 1.004385510845168, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 435, train_loss = 1.00361390033504, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 436, train_loss = 1.0025799408831517, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 437, train_loss = 1.0023769757826813, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 438, train_loss = 1.0018524441620684, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 439, train_loss = 1.001748467235302, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 440, train_loss = 1.0032591245035292, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 441, train_loss = 1.0015336614087573, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 442, train_loss = 1.0002587497365312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 443, train_loss = 1.0032629191191518, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 444, train_loss = 1.0000545938382857, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 445, train_loss = 1.002473276515957, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 446, train_loss = 1.0004372578114271, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 447, train_loss = 0.9998887290930725, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 448, train_loss = 0.9993691980853328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 449, train_loss = 0.9992408127873205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 450, train_loss = 1.0004420111436048, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 451, train_loss = 0.9987440110635362, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 452, train_loss = 0.9976621046007494, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 453, train_loss = 0.9977372805369669, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 454, train_loss = 0.9972090473820572, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 455, train_loss = 0.9972080769439344, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 456, train_loss = 0.9966590164040099, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 457, train_loss = 0.996275073113793, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 458, train_loss = 0.9957135595832369, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 459, train_loss = 0.9963103349218727, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 460, train_loss = 0.9953646254434716, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 461, train_loss = 0.9957652827943093, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 462, train_loss = 0.9946868051265483, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 463, train_loss = 0.9951441952725872, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 464, train_loss = 0.9942857526257285, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 465, train_loss = 0.9945183522650041, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 466, train_loss = 0.9936005562121863, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 467, train_loss = 0.9933984941744711, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 468, train_loss = 0.9954654708781163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 469, train_loss = 0.9929191448536585, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 470, train_loss = 0.9948538307799026, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 471, train_loss = 0.9934930986200925, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 472, train_loss = 0.992851309980324, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 473, train_loss = 0.9925019766160403, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 474, train_loss = 0.9916290745604783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 475, train_loss = 0.9917509577280725, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 476, train_loss = 0.9923758102740976, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 477, train_loss = 0.9914802397470339, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 478, train_loss = 0.9907007265501306, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 479, train_loss = 0.9909364639388514, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 480, train_loss = 0.9905230243239203, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 481, train_loss = 0.9891132499687956, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 482, train_loss = 0.9885609359116643, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 483, train_loss = 0.9882205164831248, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 484, train_loss = 0.9877943311221316, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 485, train_loss = 0.9881139621502371, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 486, train_loss = 0.9871139804963605, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 487, train_loss = 0.9876207850102219, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 488, train_loss = 0.9868558226153255, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 489, train_loss = 0.9869780201188405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 490, train_loss = 0.9865799222243368, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 491, train_loss = 0.9862950383176212, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 492, train_loss = 0.9855763092418783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 493, train_loss = 0.9880845463412697, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 494, train_loss = 0.9847840464572073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 495, train_loss = 0.9872355081824935, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 496, train_loss = 0.9869927153267781, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 497, train_loss = 0.9850693149128347, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 498, train_loss = 0.9862406917964108, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 499, train_loss = 0.9854188762255944, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███████████████████████                                                      | 9/30 [1:22:20<3:15:23, 558.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "10th- epoch: 0, train_loss = 385.555439600721, train_acc = 0.8042617605961807\n",
      "test Acc 0.8957169459962756:\n",
      "10th- epoch: 1, train_loss = 94.78455435857177, train_acc = 0.9226828132277597\n",
      "test Acc 0.9152700186219739:\n",
      "10th- epoch: 2, train_loss = 58.29564590379596, train_acc = 0.945854680950163\n",
      "test Acc 0.9338919925512105:\n",
      "10th- epoch: 3, train_loss = 40.703817094443366, train_acc = 0.9598276665114113\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 4, train_loss = 30.384348758263513, train_acc = 0.9666977177456917\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 5, train_loss = 23.807653174502775, train_acc = 0.9739170936190032\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 6, train_loss = 18.996145782992244, train_acc = 0.9776432231020028\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 7, train_loss = 15.135669981711544, train_acc = 0.9811364694923148\n",
      "test Acc 0.9492551210428305:\n",
      "10th- epoch: 8, train_loss = 12.150168567255605, train_acc = 0.9840475081509082\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 9, train_loss = 10.062565938569605, train_acc = 0.9856776897997206\n",
      "test Acc 0.952513966480447:\n",
      "10th- epoch: 10, train_loss = 8.439747310243547, train_acc = 0.9875407545412203\n",
      "test Acc 0.952048417132216:\n",
      "10th- epoch: 11, train_loss = 7.121425381250447, train_acc = 0.9892873777363763\n",
      "test Acc 0.952513966480447:\n",
      "10th- epoch: 12, train_loss = 6.099326596275205, train_acc = 0.9899860270144387\n",
      "test Acc 0.9529795158286778:\n",
      "10th- epoch: 13, train_loss = 5.230056143045658, train_acc = 0.9909175593851887\n",
      "test Acc 0.9529795158286778:\n",
      "10th- epoch: 14, train_loss = 4.536225498653948, train_acc = 0.9923148579413135\n",
      "test Acc 0.9534450651769087:\n",
      "10th- epoch: 15, train_loss = 3.9928783563373145, train_acc = 0.9930135072193759\n",
      "test Acc 0.9529795158286778:\n",
      "10th- epoch: 16, train_loss = 3.5768659260647837, train_acc = 0.9931299487657196\n",
      "test Acc 0.9543761638733705:\n",
      "10th- epoch: 17, train_loss = 3.2532463182287756, train_acc = 0.9933628318584071\n",
      "test Acc 0.9553072625698324:\n",
      "10th- epoch: 18, train_loss = 2.9708941858261824, train_acc = 0.9939450395901258\n",
      "test Acc 0.9557728119180633:\n",
      "10th- epoch: 19, train_loss = 2.735979721270269, train_acc = 0.9947601304145319\n",
      "test Acc 0.9553072625698324:\n",
      "10th- epoch: 20, train_loss = 2.5478435259719845, train_acc = 0.9947601304145319\n",
      "test Acc 0.9557728119180633:\n",
      "10th- epoch: 21, train_loss = 2.385427162895212, train_acc = 0.9951094550535631\n",
      "test Acc 0.9562383612662942:\n",
      "10th- epoch: 22, train_loss = 2.2528862223553006, train_acc = 0.9956916627852818\n",
      "test Acc 0.9557728119180633:\n",
      "10th- epoch: 23, train_loss = 2.1473231304844376, train_acc = 0.9958081043316255\n",
      "test Acc 0.9562383612662942:\n",
      "10th- epoch: 24, train_loss = 2.049985328922048, train_acc = 0.9959245458779693\n",
      "test Acc 0.9562383612662942:\n",
      "10th- epoch: 25, train_loss = 1.9732672454265412, train_acc = 0.996040987424313\n",
      "test Acc 0.9567039106145251:\n",
      "10th- epoch: 26, train_loss = 1.9059751191234682, train_acc = 0.996040987424313\n",
      "test Acc 0.9567039106145251:\n",
      "10th- epoch: 27, train_loss = 1.84470388139016, train_acc = 0.9962738705170004\n",
      "test Acc 0.9567039106145251:\n",
      "10th- epoch: 28, train_loss = 1.7976371163094882, train_acc = 0.9963903120633442\n",
      "test Acc 0.957635009310987:\n",
      "10th- epoch: 29, train_loss = 1.7599354243429843, train_acc = 0.9963903120633442\n",
      "test Acc 0.957169459962756:\n",
      "10th- epoch: 30, train_loss = 1.7296867608092725, train_acc = 0.9962738705170004\n",
      "test Acc 0.957635009310987:\n",
      "10th- epoch: 31, train_loss = 1.7033098468964454, train_acc = 0.9963903120633442\n",
      "test Acc 0.957635009310987:\n",
      "10th- epoch: 32, train_loss = 1.6783934662526008, train_acc = 0.9963903120633442\n",
      "test Acc 0.957635009310987:\n",
      "10th- epoch: 33, train_loss = 1.655244344699895, train_acc = 0.9963903120633442\n",
      "test Acc 0.9581005586592178:\n",
      "10th- epoch: 34, train_loss = 1.6353938892425504, train_acc = 0.9963903120633442\n",
      "test Acc 0.9581005586592178:\n",
      "10th- epoch: 35, train_loss = 1.6184795441513415, train_acc = 0.9963903120633442\n",
      "test Acc 0.9585661080074488:\n",
      "10th- epoch: 36, train_loss = 1.5979170387145132, train_acc = 0.9963903120633442\n",
      "test Acc 0.9585661080074488:\n",
      "10th- epoch: 37, train_loss = 1.5804344904609025, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 38, train_loss = 1.562945844605565, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 39, train_loss = 1.548790154280141, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 40, train_loss = 1.5358462119475007, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 41, train_loss = 1.525498134229565, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 42, train_loss = 1.5131885401642649, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 43, train_loss = 1.5016888725804165, train_acc = 0.996506753609688\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 44, train_loss = 1.4918295838142512, train_acc = 0.996506753609688\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 45, train_loss = 1.484021043215762, train_acc = 0.9966231951560317\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 46, train_loss = 1.474351094570011, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 47, train_loss = 1.464759799069725, train_acc = 0.996506753609688\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 48, train_loss = 1.4584626537980512, train_acc = 0.996506753609688\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 49, train_loss = 1.4483812726539327, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 50, train_loss = 1.440990211252938, train_acc = 0.9962738705170004\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 51, train_loss = 1.4345317980769323, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 52, train_loss = 1.4262268419115571, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 53, train_loss = 1.4201411920803366, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 54, train_loss = 1.413495687462273, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 55, train_loss = 1.406730373040773, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 56, train_loss = 1.400718556556967, train_acc = 0.9963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 57, train_loss = 1.3974632857862161, train_acc = 0.9962738705170004\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 58, train_loss = 1.3905364321981324, train_acc = 0.9962738705170004\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 59, train_loss = 1.384444086579606, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 60, train_loss = 1.3788699979922967, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 61, train_loss = 1.3736181791609852, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 62, train_loss = 1.3682290080032544, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 63, train_loss = 1.363715719387983, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 64, train_loss = 1.3604507522541098, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 65, train_loss = 1.3564449875266291, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 66, train_loss = 1.3498623582272558, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 67, train_loss = 1.346836323660682, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 68, train_loss = 1.3426875175791793, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 69, train_loss = 1.338730382747599, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 70, train_loss = 1.3358777497633127, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 71, train_loss = 1.3300576216279296, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 72, train_loss = 1.3269865316688083, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 73, train_loss = 1.324046616544365, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 74, train_loss = 1.3207813013141276, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 75, train_loss = 1.317280367075, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 76, train_loss = 1.3143489244030206, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 77, train_loss = 1.3108778675887152, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 78, train_loss = 1.307888955809176, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 79, train_loss = 1.3043832671828568, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 80, train_loss = 1.3017857145750895, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 81, train_loss = 1.2993572313571349, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 82, train_loss = 1.2960124640158028, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 83, train_loss = 1.2936138026416302, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 84, train_loss = 1.2910725524052395, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 85, train_loss = 1.2885512550492422, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 86, train_loss = 1.2855407014358207, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 87, train_loss = 1.283708190858306, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 88, train_loss = 1.2802729062605067, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 89, train_loss = 1.2773261140901013, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 90, train_loss = 1.2743611127370968, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 91, train_loss = 1.272108945682703, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 92, train_loss = 1.2692568579223007, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 93, train_loss = 1.2673141538034542, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 94, train_loss = 1.264910390287696, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 95, train_loss = 1.2630701147354557, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 96, train_loss = 1.2605019252150669, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 97, train_loss = 1.2588193434421555, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 98, train_loss = 1.2559617021252052, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "10th- epoch: 99, train_loss = 1.2534867473877966, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 100, train_loss = 1.2523052631877363, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 101, train_loss = 1.2507392100524157, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 102, train_loss = 1.2477268485818058, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 103, train_loss = 1.2460164797157631, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 104, train_loss = 1.245438877493143, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 105, train_loss = 1.2426902472507209, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 106, train_loss = 1.241090363902913, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 107, train_loss = 1.2402071859687567, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 108, train_loss = 1.237284088121669, train_acc = 0.9966231951560317\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 109, train_loss = 1.2361297863535583, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 110, train_loss = 1.2358220181558863, train_acc = 0.9966231951560317\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 111, train_loss = 1.2332576822955161, train_acc = 0.9966231951560317\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 112, train_loss = 1.2310068795122788, train_acc = 0.9966231951560317\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 113, train_loss = 1.2300246911254362, train_acc = 0.9967396367023754\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 114, train_loss = 1.2285957989151939, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 115, train_loss = 1.227470896905288, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 116, train_loss = 1.22514508493623, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 117, train_loss = 1.2244113439592184, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 118, train_loss = 1.2223967030076892, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 119, train_loss = 1.2218578510219231, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 120, train_loss = 1.2200159347485169, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 121, train_loss = 1.2184357447185903, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 122, train_loss = 1.2170240732011735, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 123, train_loss = 1.2162472572308616, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 124, train_loss = 1.214194899504946, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 125, train_loss = 1.2136745834359317, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 126, train_loss = 1.2120096960206865, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 127, train_loss = 1.2103384768488468, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 128, train_loss = 1.209263862845546, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 129, train_loss = 1.2087982654338703, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 130, train_loss = 1.20710267675895, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 131, train_loss = 1.205817887072044, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 132, train_loss = 1.2045974667998962, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 133, train_loss = 1.2034187355529866, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 134, train_loss = 1.2025953436168493, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 135, train_loss = 1.2013244937043055, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 136, train_loss = 1.2002313348566531, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 137, train_loss = 1.1995135397519334, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 138, train_loss = 1.1971513923854218, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 139, train_loss = 1.197476922381611, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 140, train_loss = 1.1951178701492609, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 141, train_loss = 1.1947507160148234, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 142, train_loss = 1.1932589947609813, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 143, train_loss = 1.1929836750859977, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 144, train_loss = 1.190768103035225, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 145, train_loss = 1.1902990977978334, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 146, train_loss = 1.1897230848335312, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 147, train_loss = 1.1889461383107118, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 148, train_loss = 1.187770965778327, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 149, train_loss = 1.186044700538332, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 150, train_loss = 1.1862967692068196, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 151, train_loss = 1.1836581705501885, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 152, train_loss = 1.1829390040729777, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 153, train_loss = 1.1822177220601588, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 154, train_loss = 1.1804085309850052, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 155, train_loss = 1.17966668963345, train_acc = 0.9967396367023754\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 156, train_loss = 1.1781981422464014, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 157, train_loss = 1.1773997137424885, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 158, train_loss = 1.1769542933543562, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 159, train_loss = 1.1755183174609556, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 160, train_loss = 1.174895958705747, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 161, train_loss = 1.1745930693214177, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 162, train_loss = 1.172944281483069, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 163, train_loss = 1.1720564941642806, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 164, train_loss = 1.1713441444662749, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 165, train_loss = 1.1700785662978888, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 166, train_loss = 1.1695577146383584, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 167, train_loss = 1.167281291061954, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 168, train_loss = 1.1669325903858407, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 169, train_loss = 1.1668950735693215, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 170, train_loss = 1.1653895814306452, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 171, train_loss = 1.1640374926719232, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 172, train_loss = 1.1630596271716058, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 173, train_loss = 1.162355292668508, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 174, train_loss = 1.1614996093921945, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 175, train_loss = 1.1606186442877515, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 176, train_loss = 1.1591251046265825, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 177, train_loss = 1.1589035028591752, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 178, train_loss = 1.1576678678393364, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 179, train_loss = 1.156890629325062, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 180, train_loss = 1.1556346708312049, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 181, train_loss = 1.1548604842610075, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 182, train_loss = 1.154226936167106, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 183, train_loss = 1.1531914316583425, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 184, train_loss = 1.1528647748418734, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 185, train_loss = 1.152046889612393, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 186, train_loss = 1.1500091583802714, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 187, train_loss = 1.1501599149778485, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 188, train_loss = 1.148927606176585, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 189, train_loss = 1.147533977557032, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 190, train_loss = 1.1466445077676326, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 191, train_loss = 1.1462204984054551, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 192, train_loss = 1.1457279845271842, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 193, train_loss = 1.1446828520856798, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 194, train_loss = 1.143965268660395, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 195, train_loss = 1.1430326514746412, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 196, train_loss = 1.1420380254276097, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 197, train_loss = 1.140781007859914, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 198, train_loss = 1.1400849192868918, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 199, train_loss = 1.1396140994838788, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 200, train_loss = 1.1387535794638097, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 201, train_loss = 1.1376729171388433, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 202, train_loss = 1.136495196573378, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 203, train_loss = 1.1354422392323613, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 204, train_loss = 1.1353923146016314, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 205, train_loss = 1.1345674207768752, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 206, train_loss = 1.132944457080157, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 207, train_loss = 1.132018093019724, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 208, train_loss = 1.131473302062659, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 209, train_loss = 1.1305963688864722, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 210, train_loss = 1.129674178082496, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 211, train_loss = 1.1285847565159202, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 212, train_loss = 1.1279817431568517, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 213, train_loss = 1.1266689614058123, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 214, train_loss = 1.1261450041420176, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 215, train_loss = 1.1253257314674556, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 216, train_loss = 1.1243398844599142, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 217, train_loss = 1.1235324793160544, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 218, train_loss = 1.1226588737554266, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 219, train_loss = 1.122019026428461, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 220, train_loss = 1.1207964660934522, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 221, train_loss = 1.1201405742540373, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 222, train_loss = 1.1190220157950534, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 223, train_loss = 1.118390575669764, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 224, train_loss = 1.1169782266952097, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 225, train_loss = 1.1159498919732869, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 226, train_loss = 1.1151078905313625, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 227, train_loss = 1.114563406445086, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 228, train_loss = 1.1135374278164818, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 229, train_loss = 1.1128919539041817, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 230, train_loss = 1.1118165954612778, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 231, train_loss = 1.110686649721174, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 232, train_loss = 1.109877891060023, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 233, train_loss = 1.1087838602252305, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 234, train_loss = 1.107547316387354, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 235, train_loss = 1.1060444080867455, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 236, train_loss = 1.1061864046714618, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 237, train_loss = 1.105061515700072, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 238, train_loss = 1.104324609194009, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 239, train_loss = 1.1023867200128734, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 240, train_loss = 1.1020712608806207, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 241, train_loss = 1.101632817495556, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 242, train_loss = 1.100269515220134, train_acc = 0.9969725197950629\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 243, train_loss = 1.0990878885277198, train_acc = 0.9970889613414066\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 244, train_loss = 1.0987698834724142, train_acc = 0.9970889613414066\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 245, train_loss = 1.0979398510753526, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 246, train_loss = 1.0967777937985375, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 247, train_loss = 1.0951330326497555, train_acc = 0.9972054028877504\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 248, train_loss = 1.0946626911536441, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 249, train_loss = 1.0945084000341012, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 250, train_loss = 1.0929831860921695, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 251, train_loss = 1.0920660292395041, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 252, train_loss = 1.0911804613060667, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 253, train_loss = 1.0904270109385834, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 254, train_loss = 1.0900995299816714, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 255, train_loss = 1.0888708916827454, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 256, train_loss = 1.087800553686975, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 257, train_loss = 1.087605687789619, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 258, train_loss = 1.086824414007424, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 259, train_loss = 1.0854309378191829, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 260, train_loss = 1.0850383071228862, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 261, train_loss = 1.084439662285149, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 262, train_loss = 1.083154828287661, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 263, train_loss = 1.082391180410923, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 264, train_loss = 1.082086709640862, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 265, train_loss = 1.0810307348147035, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 266, train_loss = 1.0804767301306129, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 267, train_loss = 1.0800333383158431, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 268, train_loss = 1.079141415655613, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 269, train_loss = 1.0781702930107713, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 270, train_loss = 1.0775398518890142, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 271, train_loss = 1.0776551735252724, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 272, train_loss = 1.0762792363166227, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 273, train_loss = 1.0755981219335808, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 274, train_loss = 1.0750767821446061, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 275, train_loss = 1.074465832360147, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 276, train_loss = 1.0737906862050295, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 277, train_loss = 1.0737440073862672, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 278, train_loss = 1.0724940799773321, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 279, train_loss = 1.072040528371872, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 280, train_loss = 1.0719672851264477, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 281, train_loss = 1.070937336422503, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 282, train_loss = 1.0696705393493176, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 283, train_loss = 1.0703205450772657, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 284, train_loss = 1.0695161878466024, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 285, train_loss = 1.068482685215713, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 286, train_loss = 1.0682703107595444, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 287, train_loss = 1.0676279102117405, train_acc = 0.9975547275267815\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 288, train_loss = 1.0664911062121973, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 289, train_loss = 1.066100273594202, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 290, train_loss = 1.0660263154059066, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 291, train_loss = 1.0653857979923487, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 292, train_loss = 1.0645464245826588, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 293, train_loss = 1.0641545578837395, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 294, train_loss = 1.063627130970417, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 295, train_loss = 1.0632348976432695, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 296, train_loss = 1.0624331713988795, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 297, train_loss = 1.061652007199882, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 298, train_loss = 1.061665963694395, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 299, train_loss = 1.0611829378976836, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 300, train_loss = 1.060429560020566, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 301, train_loss = 1.0602123333737836, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 302, train_loss = 1.0594158613457694, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 303, train_loss = 1.0588293299078941, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 304, train_loss = 1.0583425583317876, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 305, train_loss = 1.0578747264444246, train_acc = 0.9977876106194691\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 306, train_loss = 1.0568331883623614, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 307, train_loss = 1.0560383178890334, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 308, train_loss = 1.056294078938663, train_acc = 0.9977876106194691\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 309, train_loss = 1.0551369348540902, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 310, train_loss = 1.0547490625976934, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 311, train_loss = 1.054209526941122, train_acc = 0.9977876106194691\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 312, train_loss = 1.0537051328792586, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 313, train_loss = 1.05378596639639, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 314, train_loss = 1.0528732994571328, train_acc = 0.9977876106194691\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 315, train_loss = 1.0522072852254496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 316, train_loss = 1.0517741550356732, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 317, train_loss = 1.051509427219571, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 318, train_loss = 1.051540280073823, train_acc = 0.9977876106194691\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 319, train_loss = 1.0505691512153135, train_acc = 0.9977876106194691\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 320, train_loss = 1.050002034753561, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 321, train_loss = 1.049588490590395, train_acc = 0.9977876106194691\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 322, train_loss = 1.0493549636230455, train_acc = 0.9977876106194691\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 323, train_loss = 1.0489533760919585, train_acc = 0.9977876106194691\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 324, train_loss = 1.0482451509087696, train_acc = 0.9976711690731253\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 325, train_loss = 1.0477085818201886, train_acc = 0.9977876106194691\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 326, train_loss = 1.0479453410953283, train_acc = 0.9977876106194691\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 327, train_loss = 1.0468573349862709, train_acc = 0.9977876106194691\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 328, train_loss = 1.0462420359253883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 329, train_loss = 1.0460687850936665, train_acc = 0.9977876106194691\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 330, train_loss = 1.046239147275628, train_acc = 0.9977876106194691\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 331, train_loss = 1.0453209526240244, train_acc = 0.9977876106194691\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 332, train_loss = 1.0445116621776833, train_acc = 0.9977876106194691\n",
      "test Acc 0.9641527001862198:\n",
      "10th- epoch: 333, train_loss = 1.0443292440249934, train_acc = 0.9977876106194691\n",
      "test Acc 0.9641527001862198:\n",
      "10th- epoch: 334, train_loss = 1.0436878176406026, train_acc = 0.9977876106194691\n",
      "test Acc 0.9641527001862198:\n",
      "10th- epoch: 335, train_loss = 1.0439290062859072, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 336, train_loss = 1.0431650417522178, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 337, train_loss = 1.0425297540277825, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 338, train_loss = 1.0421673655509949, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 339, train_loss = 1.0414126720279455, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 340, train_loss = 1.0413835057988763, train_acc = 0.9977876106194691\n",
      "test Acc 0.9641527001862198:\n",
      "10th- epoch: 341, train_loss = 1.0408044417090423, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 342, train_loss = 1.040286640949489, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 343, train_loss = 1.0407007103785872, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 344, train_loss = 1.039558111999213, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 345, train_loss = 1.0398177628703706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 346, train_loss = 1.0391749804839492, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 347, train_loss = 1.0385134934149391, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 348, train_loss = 1.0379476305097342, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 349, train_loss = 1.0380950141698122, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 350, train_loss = 1.0373183765150316, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 351, train_loss = 1.0364548129327886, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 352, train_loss = 1.0364134879782796, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 353, train_loss = 1.0360052458308928, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 354, train_loss = 1.0361502574123733, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 355, train_loss = 1.035605737939477, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 356, train_loss = 1.0350247009955638, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 357, train_loss = 1.0341304152570956, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 358, train_loss = 1.0345269097015262, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 359, train_loss = 1.0339032247029536, train_acc = 0.9977876106194691\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 360, train_loss = 1.033465538173914, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 361, train_loss = 1.0328398138917692, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 362, train_loss = 1.0326287227981084, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 363, train_loss = 1.0321193632371433, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 364, train_loss = 1.0319047626107931, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 365, train_loss = 1.0317178362347477, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 366, train_loss = 1.0309465822465427, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 367, train_loss = 1.0303266259543307, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 368, train_loss = 1.030295079573989, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 369, train_loss = 1.0304277325049043, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 370, train_loss = 1.0293683791533113, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 371, train_loss = 1.0290412756912701, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 372, train_loss = 1.0285486852117174, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 373, train_loss = 1.0284221731126308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 374, train_loss = 1.0281555804722302, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 375, train_loss = 1.0278382636606693, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 376, train_loss = 1.026948331233143, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 377, train_loss = 1.026991242852091, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 378, train_loss = 1.0263239685446024, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 379, train_loss = 1.026113058131159, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 380, train_loss = 1.0256816906221502, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 381, train_loss = 1.025424358125747, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 382, train_loss = 1.0248738660775416, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 383, train_loss = 1.0245323755480058, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 384, train_loss = 1.024127640761435, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 385, train_loss = 1.0239551371596463, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 386, train_loss = 1.0233344829939597, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 387, train_loss = 1.023582392372191, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 388, train_loss = 1.022957998327911, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 389, train_loss = 1.0224297642707825, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 390, train_loss = 1.0225315727293491, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 391, train_loss = 1.021741676144302, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 392, train_loss = 1.0211756424978375, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 393, train_loss = 1.0209637371190183, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 394, train_loss = 1.0212550424039364, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 395, train_loss = 1.0204650585837953, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 396, train_loss = 1.0197764771692164, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 397, train_loss = 1.0194898179433949, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 398, train_loss = 1.0196314925960905, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 399, train_loss = 1.0190464251973026, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 400, train_loss = 1.0184807733930938, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 401, train_loss = 1.0181080345064402, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 402, train_loss = 1.0181646179407835, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 403, train_loss = 1.0177056081593037, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 404, train_loss = 1.0168597425035841, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 405, train_loss = 1.0166769834868319, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 406, train_loss = 1.0159691746048338, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 407, train_loss = 1.0165092814713717, train_acc = 0.9977876106194691\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 408, train_loss = 1.016107877716422, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 409, train_loss = 1.0154740617908828, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 410, train_loss = 1.0150363308675878, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 411, train_loss = 1.0144745192192204, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 412, train_loss = 1.0143134165555239, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 413, train_loss = 1.0139520782977343, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 414, train_loss = 1.014092169702053, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 415, train_loss = 1.0135497115552425, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 416, train_loss = 1.0128583367913961, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 417, train_loss = 1.0126495193690062, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 418, train_loss = 1.0123766791075468, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 419, train_loss = 1.0119466595351696, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 420, train_loss = 1.011767836909712, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 421, train_loss = 1.0115616067014344, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 422, train_loss = 1.0110102177895897, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 423, train_loss = 1.0104979791976803, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 424, train_loss = 1.0110549591481686, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 425, train_loss = 1.0100475835315592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 426, train_loss = 1.0096549882255204, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 427, train_loss = 1.0091166204474575, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 428, train_loss = 1.009057054296136, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 429, train_loss = 1.009289413690567, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 430, train_loss = 1.0084325789175637, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 431, train_loss = 1.0080285059921152, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 432, train_loss = 1.0077984357885725, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 433, train_loss = 1.0074667874723673, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 434, train_loss = 1.007366341229499, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 435, train_loss = 1.0070854425430298, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 436, train_loss = 1.0060294183604128, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 437, train_loss = 1.006097296874941, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 438, train_loss = 1.0057521003000147, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 439, train_loss = 1.0057218577712774, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 440, train_loss = 1.005488236743986, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 441, train_loss = 1.004806686192751, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 442, train_loss = 1.0045869636051066, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 443, train_loss = 1.004049192491948, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 444, train_loss = 1.0038824304938316, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 445, train_loss = 1.0037567348517769, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 446, train_loss = 1.0031214927621477, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 447, train_loss = 1.0029939257838123, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 448, train_loss = 1.0025299334265583, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 449, train_loss = 1.0024788354821794, train_acc = 0.9977876106194691\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 450, train_loss = 1.0022904382385605, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 451, train_loss = 1.0016704071313143, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 452, train_loss = 1.0016295555979013, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 453, train_loss = 1.000885264325916, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 454, train_loss = 1.0009618544318073, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 455, train_loss = 1.0004935978613503, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 456, train_loss = 1.0000835464634292, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 457, train_loss = 1.0000280520580418, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 458, train_loss = 0.9995001306124323, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 459, train_loss = 0.9997826547660225, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 460, train_loss = 0.9992324355989695, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 461, train_loss = 0.9983962519727356, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 462, train_loss = 0.9983194923661358, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 463, train_loss = 0.9985735335685604, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 464, train_loss = 0.998156014829874, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 465, train_loss = 0.9975936176888354, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 466, train_loss = 0.9971010908484459, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 467, train_loss = 0.9974543564021587, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 468, train_loss = 0.9969442691653967, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 469, train_loss = 0.996532492339611, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 470, train_loss = 0.9962706509977579, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 471, train_loss = 0.9958309773355722, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 472, train_loss = 0.9956803638488054, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 473, train_loss = 0.9952314694710367, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 474, train_loss = 0.9952183831483126, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 475, train_loss = 0.9949000310152769, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 476, train_loss = 0.9943201417736418, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 477, train_loss = 0.9941261938474781, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 478, train_loss = 0.9938707631081343, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 479, train_loss = 0.993617453303159, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 480, train_loss = 0.9935847545675642, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 481, train_loss = 0.9932838423810608, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 482, train_loss = 0.9927114682905085, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 483, train_loss = 0.9923412340394862, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 484, train_loss = 0.9925100995860703, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 485, train_loss = 0.9920661014803045, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 486, train_loss = 0.9910241514444351, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 487, train_loss = 0.9913676964752085, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 488, train_loss = 0.9912122127898328, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 489, train_loss = 0.9910879600793123, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 490, train_loss = 0.9902536955960386, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 491, train_loss = 0.9903359624258883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 492, train_loss = 0.990033541496814, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 493, train_loss = 0.9900410026311874, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 494, train_loss = 0.9893680947534449, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 495, train_loss = 0.9890279745050066, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 496, train_loss = 0.9889177891127474, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 497, train_loss = 0.9887839810289734, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 498, train_loss = 0.9883146074898832, train_acc = 0.9979040521658128\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 499, train_loss = 0.9880328550934792, train_acc = 0.9977876106194691\n",
      "test Acc 0.9660148975791434:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|█████████████████████████▎                                                  | 10/30 [1:32:27<3:10:58, 572.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "11th- epoch: 0, train_loss = 385.02344286441803, train_acc = 0.7964601769911505\n",
      "test Acc 0.8878026070763501:\n",
      "11th- epoch: 1, train_loss = 92.88712099567056, train_acc = 0.915929203539823\n",
      "test Acc 0.925512104283054:\n",
      "11th- epoch: 2, train_loss = 57.91508698090911, train_acc = 0.941895668374476\n",
      "test Acc 0.936219739292365:\n",
      "11th- epoch: 3, train_loss = 40.14330065995455, train_acc = 0.9562179785747554\n",
      "test Acc 0.9408752327746741:\n",
      "11th- epoch: 4, train_loss = 29.616647381335497, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 5, train_loss = 22.61776800826192, train_acc = 0.9711224965067536\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 6, train_loss = 17.800927814096212, train_acc = 0.975780158360503\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 7, train_loss = 14.247863318771124, train_acc = 0.9799720540288775\n",
      "test Acc 0.9511173184357542:\n",
      "11th- epoch: 8, train_loss = 11.544103058520705, train_acc = 0.9827666511411272\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 9, train_loss = 9.60216445964761, train_acc = 0.9847461574289706\n",
      "test Acc 0.9539106145251397:\n",
      "11th- epoch: 10, train_loss = 8.230100764660165, train_acc = 0.9864927806241267\n",
      "test Acc 0.9543761638733705:\n",
      "11th- epoch: 11, train_loss = 7.173931552679278, train_acc = 0.9882394038192828\n",
      "test Acc 0.9557728119180633:\n",
      "11th- epoch: 12, train_loss = 6.3157791359117255, train_acc = 0.9892873777363763\n",
      "test Acc 0.9567039106145251:\n",
      "11th- epoch: 13, train_loss = 5.564318695454858, train_acc = 0.9897531439217513\n",
      "test Acc 0.9581005586592178:\n",
      "11th- epoch: 14, train_loss = 4.950872115790844, train_acc = 0.9905682347461574\n",
      "test Acc 0.9590316573556797:\n",
      "11th- epoch: 15, train_loss = 4.440005883574486, train_acc = 0.9917326502095948\n",
      "test Acc 0.9594972067039106:\n",
      "11th- epoch: 16, train_loss = 4.0249288802733645, train_acc = 0.9923148579413135\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 17, train_loss = 3.6597363961627707, train_acc = 0.9928970656730322\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 18, train_loss = 3.3608565652975813, train_acc = 0.9931299487657196\n",
      "test Acc 0.9590316573556797:\n",
      "11th- epoch: 19, train_loss = 3.1016664119670168, train_acc = 0.9932463903120633\n",
      "test Acc 0.9594972067039106:\n",
      "11th- epoch: 20, train_loss = 2.886258972226642, train_acc = 0.9937121564974383\n",
      "test Acc 0.9585661080074488:\n",
      "11th- epoch: 21, train_loss = 2.703389501781203, train_acc = 0.9939450395901258\n",
      "test Acc 0.9590316573556797:\n",
      "11th- epoch: 22, train_loss = 2.5374148786067963, train_acc = 0.9941779226828132\n",
      "test Acc 0.9590316573556797:\n",
      "11th- epoch: 23, train_loss = 2.394765182165429, train_acc = 0.9945272473218444\n",
      "test Acc 0.9585661080074488:\n",
      "11th- epoch: 24, train_loss = 2.2485262466361746, train_acc = 0.9948765719608756\n",
      "test Acc 0.9590316573556797:\n",
      "11th- epoch: 25, train_loss = 2.1417358269682154, train_acc = 0.9951094550535631\n",
      "test Acc 0.9594972067039106:\n",
      "11th- epoch: 26, train_loss = 2.0341848731040955, train_acc = 0.9952258965999069\n",
      "test Acc 0.9604283054003724:\n",
      "11th- epoch: 27, train_loss = 1.9541859527816996, train_acc = 0.9954587796925943\n",
      "test Acc 0.9594972067039106:\n",
      "11th- epoch: 28, train_loss = 1.8910744289169088, train_acc = 0.995575221238938\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 29, train_loss = 1.841321182786487, train_acc = 0.996040987424313\n",
      "test Acc 0.9594972067039106:\n",
      "11th- epoch: 30, train_loss = 1.8065254054963589, train_acc = 0.9959245458779693\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 31, train_loss = 1.7720357179641724, train_acc = 0.9959245458779693\n",
      "test Acc 0.9594972067039106:\n",
      "11th- epoch: 32, train_loss = 1.7402525966754183, train_acc = 0.996040987424313\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 33, train_loss = 1.7118721107835881, train_acc = 0.9959245458779693\n",
      "test Acc 0.9594972067039106:\n",
      "11th- epoch: 34, train_loss = 1.6894546511466615, train_acc = 0.9958081043316255\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 35, train_loss = 1.6641567188198678, train_acc = 0.9958081043316255\n",
      "test Acc 0.9604283054003724:\n",
      "11th- epoch: 36, train_loss = 1.6453176227514632, train_acc = 0.9959245458779693\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 37, train_loss = 1.6248984138364904, train_acc = 0.9959245458779693\n",
      "test Acc 0.9604283054003724:\n",
      "11th- epoch: 38, train_loss = 1.6036240098183043, train_acc = 0.996040987424313\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 39, train_loss = 1.5914152922923677, train_acc = 0.9959245458779693\n",
      "test Acc 0.9608938547486033:\n",
      "11th- epoch: 40, train_loss = 1.5704300838406198, train_acc = 0.9959245458779693\n",
      "test Acc 0.9608938547486033:\n",
      "11th- epoch: 41, train_loss = 1.5689360313117504, train_acc = 0.9959245458779693\n",
      "test Acc 0.9608938547486033:\n",
      "11th- epoch: 42, train_loss = 1.5445342101156712, train_acc = 0.996040987424313\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 43, train_loss = 1.5350542987580411, train_acc = 0.996040987424313\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 44, train_loss = 1.5189872731571086, train_acc = 0.9961574289706567\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 45, train_loss = 1.5083260933752172, train_acc = 0.9961574289706567\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 46, train_loss = 1.4981713742017746, train_acc = 0.9962738705170004\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 47, train_loss = 1.4873858951032162, train_acc = 0.9962738705170004\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 48, train_loss = 1.4783455555443652, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 49, train_loss = 1.4664433797006495, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 50, train_loss = 1.461434702097904, train_acc = 0.9961574289706567\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 51, train_loss = 1.443341330945259, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 52, train_loss = 1.4361230010690633, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 53, train_loss = 1.4319252421555575, train_acc = 0.9961574289706567\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 54, train_loss = 1.4216845904884394, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 55, train_loss = 1.4162809277477209, train_acc = 0.9961574289706567\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 56, train_loss = 1.4056014778616372, train_acc = 0.9961574289706567\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 57, train_loss = 1.3974191918969154, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 58, train_loss = 1.3914352233114187, train_acc = 0.996040987424313\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 59, train_loss = 1.3842966867086943, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 60, train_loss = 1.3786096299591009, train_acc = 0.996040987424313\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 61, train_loss = 1.375647034496069, train_acc = 0.9961574289706567\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 62, train_loss = 1.3677489422261715, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 63, train_loss = 1.3635845954122487, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 64, train_loss = 1.3508842351438943, train_acc = 0.9961574289706567\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 65, train_loss = 1.350263205677038, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 66, train_loss = 1.342406297713751, train_acc = 0.9961574289706567\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 67, train_loss = 1.3399197732505854, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 68, train_loss = 1.3341729889216367, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 69, train_loss = 1.3302905037999153, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 70, train_loss = 1.3228934904036578, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 71, train_loss = 1.3197084975836333, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 72, train_loss = 1.3137370037438814, train_acc = 0.996506753609688\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 73, train_loss = 1.309507094323635, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 74, train_loss = 1.3044743401405867, train_acc = 0.996506753609688\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 75, train_loss = 1.3014119962754194, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 76, train_loss = 1.2976939752697945, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 77, train_loss = 1.2938768342137337, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 78, train_loss = 1.2925645423529204, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 79, train_loss = 1.288472205400467, train_acc = 0.996506753609688\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 80, train_loss = 1.28685262799263, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 81, train_loss = 1.2784387705323752, train_acc = 0.996506753609688\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 82, train_loss = 1.2791334850189742, train_acc = 0.996506753609688\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 83, train_loss = 1.2778065403399523, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 84, train_loss = 1.2708218370971736, train_acc = 0.996506753609688\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 85, train_loss = 1.269272156059742, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 86, train_loss = 1.262878450244898, train_acc = 0.996506753609688\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 87, train_loss = 1.2648082834930392, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 88, train_loss = 1.2605684672744246, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "11th- epoch: 89, train_loss = 1.255904586359975, train_acc = 0.996506753609688\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 90, train_loss = 1.2561748449952574, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 91, train_loss = 1.2513413056731224, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "11th- epoch: 92, train_loss = 1.2494881811289815, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "11th- epoch: 93, train_loss = 1.245708209768054, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 94, train_loss = 1.2434390969574451, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 95, train_loss = 1.2405546121299267, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 96, train_loss = 1.2405173679144355, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 97, train_loss = 1.2372744120657444, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 98, train_loss = 1.2352902690618066, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 99, train_loss = 1.2301105856895447, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 100, train_loss = 1.2308920087962179, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 101, train_loss = 1.227784605071065, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 102, train_loss = 1.2288733000605134, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 103, train_loss = 1.2225093320012093, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 104, train_loss = 1.2217329392879037, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 105, train_loss = 1.2178686261177063, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 106, train_loss = 1.2185586094856262, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 107, train_loss = 1.2130130815057782, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 108, train_loss = 1.213735702142003, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 109, train_loss = 1.2106740636081668, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 110, train_loss = 1.2054962739348412, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 111, train_loss = 1.207633779689786, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 112, train_loss = 1.2062946036458015, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 113, train_loss = 1.2031522070319625, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 114, train_loss = 1.2010654794721631, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 115, train_loss = 1.2009947026817827, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 116, train_loss = 1.1991177250893088, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 117, train_loss = 1.195472840219736, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 118, train_loss = 1.1940560514776735, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 119, train_loss = 1.1905479046254186, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 120, train_loss = 1.1885677017271519, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 121, train_loss = 1.1931856162846088, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 122, train_loss = 1.1887501540331868, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 123, train_loss = 1.1870494311006041, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 124, train_loss = 1.188074650868657, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 125, train_loss = 1.1837336607277393, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 126, train_loss = 1.1808563098311424, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 127, train_loss = 1.1833022286446067, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 128, train_loss = 1.1792041870503454, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 129, train_loss = 1.178753615662572, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 130, train_loss = 1.1762286101729842, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 131, train_loss = 1.1760842738003703, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 132, train_loss = 1.172840633735177, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 133, train_loss = 1.1758597195148468, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 134, train_loss = 1.1682682683021994, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 135, train_loss = 1.1699133279471425, train_acc = 0.9970889613414066\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 136, train_loss = 1.1668491189630004, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 137, train_loss = 1.1655566332192393, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 138, train_loss = 1.1643334366381168, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 139, train_loss = 1.1646764526813058, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 140, train_loss = 1.1607901168317767, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 141, train_loss = 1.1619915602059336, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 142, train_loss = 1.155361348137376, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 143, train_loss = 1.1556949739606353, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 144, train_loss = 1.1520978175103664, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 145, train_loss = 1.1529631006269483, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 146, train_loss = 1.1502569119184045, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 147, train_loss = 1.1499455273151398, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 148, train_loss = 1.146875952676055, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 149, train_loss = 1.148445921644452, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 150, train_loss = 1.1448945378215285, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 151, train_loss = 1.1462699646799592, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 152, train_loss = 1.1421940686850576, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 153, train_loss = 1.143152038261178, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 154, train_loss = 1.143965519964695, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 155, train_loss = 1.1401034320442704, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 156, train_loss = 1.1385238816292258, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 157, train_loss = 1.138780531779048, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 158, train_loss = 1.1381616207509069, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 159, train_loss = 1.1355341474263696, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 160, train_loss = 1.1368298182933358, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 161, train_loss = 1.1321623263211222, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 162, train_loss = 1.1337014275341062, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 163, train_loss = 1.129956762000802, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 164, train_loss = 1.132337776318309, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 165, train_loss = 1.1286526434123516, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 166, train_loss = 1.1300910127611132, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 167, train_loss = 1.1284314170479774, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 168, train_loss = 1.1291913290770026, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 169, train_loss = 1.1243010808975669, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 170, train_loss = 1.1266858329327079, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 171, train_loss = 1.124056716755149, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 172, train_loss = 1.1260888439865084, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 173, train_loss = 1.1218535477964906, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 174, train_loss = 1.1203270579426317, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 175, train_loss = 1.1195962578058243, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 176, train_loss = 1.1220368097274331, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 177, train_loss = 1.1166231036186218, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 178, train_loss = 1.1160222838370828, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 179, train_loss = 1.1175549663603306, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 180, train_loss = 1.1187084962875815, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 181, train_loss = 1.1142338563950034, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 182, train_loss = 1.1155121996998787, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 183, train_loss = 1.1120781737117795, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 184, train_loss = 1.113590339824441, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 185, train_loss = 1.1105855380446883, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 186, train_loss = 1.112857365355012, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 187, train_loss = 1.1106120894401101, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 188, train_loss = 1.108660750091076, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 189, train_loss = 1.1081754602491856, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 190, train_loss = 1.1055968080909224, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 191, train_loss = 1.1078051179647446, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 192, train_loss = 1.1057291850447655, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 193, train_loss = 1.1064265333116055, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 194, train_loss = 1.102994840592146, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 195, train_loss = 1.1058144184498815, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 196, train_loss = 1.1009282507002354, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 197, train_loss = 1.104510842509626, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 198, train_loss = 1.1033638454973698, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 199, train_loss = 1.10377410302317, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 200, train_loss = 1.0990933924913406, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 201, train_loss = 1.101082550980209, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 202, train_loss = 1.0996100679039955, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 203, train_loss = 1.1003602879718528, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 204, train_loss = 1.0951222678049817, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 205, train_loss = 1.0977308551446185, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 206, train_loss = 1.0965563344434486, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 207, train_loss = 1.0985786579549313, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 208, train_loss = 1.0926629453897476, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 209, train_loss = 1.0963272949084057, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 210, train_loss = 1.0953273388222442, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 211, train_loss = 1.0956258264704957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 212, train_loss = 1.0921371964141144, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 213, train_loss = 1.0921072835699306, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 214, train_loss = 1.0896156231538043, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 215, train_loss = 1.0873025879263878, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 216, train_loss = 1.0911687488332973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 217, train_loss = 1.0870052352547646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 218, train_loss = 1.088944243885635, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 219, train_loss = 1.086590497441648, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 220, train_loss = 1.0911358719095006, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 221, train_loss = 1.0865562992767082, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 222, train_loss = 1.0845672078430653, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 223, train_loss = 1.0859316525384202, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 224, train_loss = 1.0833373752757325, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 225, train_loss = 1.0850800884290948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 226, train_loss = 1.0823022027834668, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 227, train_loss = 1.0844149154945626, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 228, train_loss = 1.080895940460323, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 229, train_loss = 1.0825232652350678, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 230, train_loss = 1.0782186736687436, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 231, train_loss = 1.0824269702061429, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 232, train_loss = 1.081110529601574, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 233, train_loss = 1.0767957468851819, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 234, train_loss = 1.0785602045580163, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 235, train_loss = 1.0786937065422535, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 236, train_loss = 1.0756661693230853, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 237, train_loss = 1.07640813539183, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 238, train_loss = 1.0772174398080097, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 239, train_loss = 1.0760494160131202, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 240, train_loss = 1.0722153571769013, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 241, train_loss = 1.0746653266251087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 242, train_loss = 1.0747514416798367, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 243, train_loss = 1.0711651208475814, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 244, train_loss = 1.074821667127253, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 245, train_loss = 1.0717873076573596, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 246, train_loss = 1.0700911159292446, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 247, train_loss = 1.0731754141525016, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 248, train_loss = 1.0705705545842648, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 249, train_loss = 1.0707382137552486, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 250, train_loss = 1.0667790907100425, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 251, train_loss = 1.0672865025699139, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 252, train_loss = 1.0686848349869251, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 253, train_loss = 1.0670677783564315, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 254, train_loss = 1.0685253615156398, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 255, train_loss = 1.065693831689714, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 256, train_loss = 1.066105837620853, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 257, train_loss = 1.0699767929836526, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 258, train_loss = 1.0661687726751552, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 259, train_loss = 1.0683237922712578, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 260, train_loss = 1.0643234414383187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 261, train_loss = 1.0632547636851086, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 262, train_loss = 1.0640327893197536, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 263, train_loss = 1.0642890098170028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 264, train_loss = 1.0616315801962628, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 265, train_loss = 1.0641535098329769, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 266, train_loss = 1.0599382507280097, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 267, train_loss = 1.0600410401821136, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 268, train_loss = 1.0584546402096748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 269, train_loss = 1.0604517708197818, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 270, train_loss = 1.0582536670044647, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 271, train_loss = 1.0599198912605061, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 272, train_loss = 1.055963077895285, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 273, train_loss = 1.0578262259587063, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 274, train_loss = 1.055457794420363, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 275, train_loss = 1.0557432124987827, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 276, train_loss = 1.0582623643203988, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 277, train_loss = 1.0552964595481171, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 278, train_loss = 1.0560440296903835, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 279, train_loss = 1.0574887754992233, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 280, train_loss = 1.0519023314118385, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 281, train_loss = 1.0546529032289982, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 282, train_loss = 1.054425835609436, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 283, train_loss = 1.051800756402372, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 284, train_loss = 1.0538584850728512, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 285, train_loss = 1.0492669567465782, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 286, train_loss = 1.051865752786398, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 287, train_loss = 1.0490830515846028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 288, train_loss = 1.050383847206831, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 289, train_loss = 1.0532957389950752, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 290, train_loss = 1.050055868923664, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 291, train_loss = 1.049199689179659, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 292, train_loss = 1.0464865254834876, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 293, train_loss = 1.0481947846710682, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 294, train_loss = 1.0465863694771542, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 295, train_loss = 1.0481523474081769, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 296, train_loss = 1.0475889307781472, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 297, train_loss = 1.0485008383766399, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 298, train_loss = 1.0431967191398144, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 299, train_loss = 1.0447682266458287, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 300, train_loss = 1.0441115622743382, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 301, train_loss = 1.0456411639825092, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 302, train_loss = 1.04435082400596, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 303, train_loss = 1.0444172086790786, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 304, train_loss = 1.0430411783381714, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 305, train_loss = 1.0428545139729977, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 306, train_loss = 1.0433533837422146, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 307, train_loss = 1.0420614555478096, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 308, train_loss = 1.0433798730373383, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 309, train_loss = 1.0391569696366787, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 310, train_loss = 1.039826304964663, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 311, train_loss = 1.0381476109250798, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 312, train_loss = 1.0410636750384583, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 313, train_loss = 1.041538942605257, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "11th- epoch: 314, train_loss = 1.0372606081291451, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 315, train_loss = 1.0376155289486633, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 316, train_loss = 1.0386766952797188, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 317, train_loss = 1.0359079750851379, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 318, train_loss = 1.0380971655249596, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 319, train_loss = 1.0392804803923354, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 320, train_loss = 1.036415245383978, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 321, train_loss = 1.036479831986071, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 322, train_loss = 1.0336523838341236, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 323, train_loss = 1.0348050333559513, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 324, train_loss = 1.0328987153843627, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 325, train_loss = 1.0342550488785491, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 326, train_loss = 1.0324533482416882, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 327, train_loss = 1.0333057641983032, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 328, train_loss = 1.0328949453905807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 329, train_loss = 1.0332892797887325, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 330, train_loss = 1.0295466060415492, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 331, train_loss = 1.0304353473111405, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 332, train_loss = 1.0333455192521797, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 333, train_loss = 1.0287032177075162, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 334, train_loss = 1.0295487518087612, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 335, train_loss = 1.0264681366606965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 336, train_loss = 1.0305937491357327, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 337, train_loss = 1.028158638626337, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 338, train_loss = 1.0304857989176526, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 339, train_loss = 1.027680313833116, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 340, train_loss = 1.0271315847858205, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 341, train_loss = 1.0254815903826966, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 342, train_loss = 1.0279896917418228, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 343, train_loss = 1.025219169758202, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 344, train_loss = 1.0267392098903656, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 345, train_loss = 1.0264862167314277, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 346, train_loss = 1.0226549295111909, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 347, train_loss = 1.0238589011132717, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 348, train_loss = 1.024310498185514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 349, train_loss = 1.0240175686776638, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 350, train_loss = 1.0253864501937642, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 351, train_loss = 1.0220553949475288, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 352, train_loss = 1.0229782822207198, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 353, train_loss = 1.020543725542666, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 354, train_loss = 1.0254826582968235, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 355, train_loss = 1.0204767994582653, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 356, train_loss = 1.0221705101430416, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 357, train_loss = 1.0200095549225807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 358, train_loss = 1.0221247139052139, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 359, train_loss = 1.0178293424323783, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 360, train_loss = 1.0199134300128208, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 361, train_loss = 1.0195239173845039, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 362, train_loss = 1.0169798520728364, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 363, train_loss = 1.0213689667507424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 364, train_loss = 1.0167012947276817, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 365, train_loss = 1.019415833055973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 366, train_loss = 1.0174461491405964, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 367, train_loss = 1.0178425498306751, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 368, train_loss = 1.0154750756919384, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 369, train_loss = 1.0163354935721145, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 370, train_loss = 1.016063933573605, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 371, train_loss = 1.0150087264701142, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 372, train_loss = 1.0158012174069881, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 373, train_loss = 1.0155696906149387, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 374, train_loss = 1.0140557922422886, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 375, train_loss = 1.015151996165514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 376, train_loss = 1.0130729340016842, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 377, train_loss = 1.0146232160404907, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 378, train_loss = 1.0128198352977051, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 379, train_loss = 1.0143968338743434, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 380, train_loss = 1.0116802838965668, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 381, train_loss = 1.0134685598313808, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 382, train_loss = 1.0109012201428413, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 383, train_loss = 1.0131248173638596, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 384, train_loss = 1.0130459554493427, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 385, train_loss = 1.0090082734823227, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 386, train_loss = 1.0109270649627433, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 387, train_loss = 1.0098640049473033, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 388, train_loss = 1.0105172867552028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 389, train_loss = 1.0103676269427524, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 390, train_loss = 1.0097180691882386, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 391, train_loss = 1.007543858140707, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 392, train_loss = 1.0095302810295834, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 393, train_loss = 1.0084897403939976, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 394, train_loss = 1.0076712841764675, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 395, train_loss = 1.0072004161775112, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 396, train_loss = 1.0093081891536713, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 397, train_loss = 1.0058507074936642, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 398, train_loss = 1.0101196393370628, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 399, train_loss = 1.0043158307671547, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 400, train_loss = 1.0081583497449174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 401, train_loss = 1.0077361973599182, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 402, train_loss = 1.0043695705608116, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 403, train_loss = 1.0043820291757584, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 404, train_loss = 1.003729676209332, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 405, train_loss = 1.0051300985142007, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 406, train_loss = 1.0053852411583648, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 407, train_loss = 1.005676588662027, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 408, train_loss = 1.0021507938727154, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 409, train_loss = 1.0016418757513748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 410, train_loss = 1.0017379795535817, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 411, train_loss = 1.003600798547268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 412, train_loss = 1.0021866994575248, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 413, train_loss = 1.0025382116436958, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 414, train_loss = 1.0009569004178047, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 415, train_loss = 0.9995198075994267, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 416, train_loss = 1.0025447135194554, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 417, train_loss = 1.003248787172197, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 418, train_loss = 0.9979705860241666, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 419, train_loss = 0.9996023401618004, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 420, train_loss = 0.9988382880910649, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 421, train_loss = 1.0024887708350434, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 422, train_loss = 0.9982000639065518, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 423, train_loss = 0.9985790885984898, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 424, train_loss = 0.9974029784425511, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 425, train_loss = 0.9978797547519207, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 426, train_loss = 0.9952153973281384, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 427, train_loss = 0.9973929611369385, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 428, train_loss = 0.9982868023216724, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 429, train_loss = 0.9939965109006152, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 430, train_loss = 0.9965115798040642, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 431, train_loss = 0.9952267867847695, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 432, train_loss = 0.9962649481967674, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 433, train_loss = 0.9949077268465771, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 434, train_loss = 0.9951127953827381, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 435, train_loss = 0.9963759295642376, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 436, train_loss = 0.9914039981886162, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 437, train_loss = 0.9955982441679225, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 438, train_loss = 0.9925743130370392, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 439, train_loss = 0.9942605768665089, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 440, train_loss = 0.994541314743401, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 441, train_loss = 0.9915454139336362, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 442, train_loss = 0.9928485179916606, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 443, train_loss = 0.9920258410274982, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 444, train_loss = 0.9955420667902217, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 445, train_loss = 0.9905382295473828, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 446, train_loss = 0.992805344365479, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 447, train_loss = 0.9907220502718701, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 448, train_loss = 0.9903527398928418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 449, train_loss = 0.9926113486289978, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 450, train_loss = 0.9931572377681732, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 451, train_loss = 0.988020159304142, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 452, train_loss = 0.9918476181701408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 453, train_loss = 0.9881117319091572, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 454, train_loss = 0.9910489283502102, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 455, train_loss = 0.9901620534583344, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 456, train_loss = 0.9905399990602746, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 457, train_loss = 0.9884940472766175, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 458, train_loss = 0.9873204492032528, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 459, train_loss = 0.9895880992189632, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 460, train_loss = 0.9895666688680649, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 461, train_loss = 0.9888365864753723, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 462, train_loss = 0.9854725748300552, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 463, train_loss = 0.9896657255812897, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 464, train_loss = 0.9846983564420952, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 465, train_loss = 0.987223378069757, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 466, train_loss = 0.9880079006179585, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 467, train_loss = 0.9861009381711483, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 468, train_loss = 0.9853306313380017, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 469, train_loss = 0.9881849611774669, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 470, train_loss = 0.9854704861863866, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 471, train_loss = 0.9855503588914871, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 472, train_loss = 0.983039374150394, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 473, train_loss = 0.9866405402644887, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 474, train_loss = 0.9825563641861663, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 475, train_loss = 0.9839279837906361, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 476, train_loss = 0.9857716374099255, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 477, train_loss = 0.9812234205528512, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 478, train_loss = 0.9827952993437066, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 479, train_loss = 0.9814353746696725, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 480, train_loss = 0.9842627458274364, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 481, train_loss = 0.98314716542518, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 482, train_loss = 0.9813946237190976, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 483, train_loss = 0.9830989924594178, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 484, train_loss = 0.979843890912889, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 485, train_loss = 0.9844136672691093, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 486, train_loss = 0.9818468913435936, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 487, train_loss = 0.9779750555753708, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 488, train_loss = 0.9793006454929127, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 489, train_loss = 0.9808612590059056, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 490, train_loss = 0.9778281015678658, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 491, train_loss = 0.9820889631882892, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 492, train_loss = 0.9796321714893566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 493, train_loss = 0.9815313778817654, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 494, train_loss = 0.9760995469987392, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 495, train_loss = 0.9778933078050613, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 496, train_loss = 0.9780830815434456, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 497, train_loss = 0.9764012421146617, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 498, train_loss = 0.979622499398829, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 499, train_loss = 0.9778247512876987, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███████████████████████████▊                                                | 11/30 [1:42:48<3:05:54, 587.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "12th- epoch: 0, train_loss = 434.2252703458071, train_acc = 0.803213786679087\n",
      "test Acc 0.8389199255121043:\n",
      "12th- epoch: 1, train_loss = 99.46573225874454, train_acc = 0.9210526315789473\n",
      "test Acc 0.9264432029795159:\n",
      "12th- epoch: 2, train_loss = 60.385866465978324, train_acc = 0.945388914764788\n",
      "test Acc 0.9334264432029795:\n",
      "12th- epoch: 3, train_loss = 41.625505150295794, train_acc = 0.9581974848625989\n",
      "test Acc 0.9348230912476723:\n",
      "12th- epoch: 4, train_loss = 30.40823989547789, train_acc = 0.9679785747554728\n",
      "test Acc 0.9399441340782123:\n",
      "12th- epoch: 5, train_loss = 23.263497988227755, train_acc = 0.972286911970191\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 6, train_loss = 18.42986901011318, train_acc = 0.9775267815556591\n",
      "test Acc 0.9450651769087524:\n",
      "12th- epoch: 7, train_loss = 14.799266494810581, train_acc = 0.9816022356776898\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 8, train_loss = 11.960019922349602, train_acc = 0.9843968327899395\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 9, train_loss = 9.911402904661372, train_acc = 0.9870749883558454\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 10, train_loss = 8.371134190820158, train_acc = 0.9889380530973452\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 11, train_loss = 7.199068677029572, train_acc = 0.9902189101071263\n",
      "test Acc 0.9515828677839852:\n",
      "12th- epoch: 12, train_loss = 6.177290734252892, train_acc = 0.990801117838845\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 13, train_loss = 5.324438160401769, train_acc = 0.9914997671169073\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 14, train_loss = 4.630088018369861, train_acc = 0.9919655333022822\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 15, train_loss = 4.086094622849487, train_acc = 0.9932463903120633\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 16, train_loss = 3.644639562815428, train_acc = 0.9934792734047508\n",
      "test Acc 0.952048417132216:\n",
      "12th- epoch: 17, train_loss = 3.2756542129209265, train_acc = 0.993828598043782\n",
      "test Acc 0.952048417132216:\n",
      "12th- epoch: 18, train_loss = 2.9984244807856157, train_acc = 0.994294364229157\n",
      "test Acc 0.952513966480447:\n",
      "12th- epoch: 19, train_loss = 2.7782390045467764, train_acc = 0.9946436888681882\n",
      "test Acc 0.9543761638733705:\n",
      "12th- epoch: 20, train_loss = 2.5979359461925924, train_acc = 0.9948765719608756\n",
      "test Acc 0.9539106145251397:\n",
      "12th- epoch: 21, train_loss = 2.442985809291713, train_acc = 0.9951094550535631\n",
      "test Acc 0.9539106145251397:\n",
      "12th- epoch: 22, train_loss = 2.321501676691696, train_acc = 0.9952258965999069\n",
      "test Acc 0.9543761638733705:\n",
      "12th- epoch: 23, train_loss = 2.21676889678929, train_acc = 0.9952258965999069\n",
      "test Acc 0.9548417132216015:\n",
      "12th- epoch: 24, train_loss = 2.110951660084538, train_acc = 0.9954587796925943\n",
      "test Acc 0.9548417132216015:\n",
      "12th- epoch: 25, train_loss = 2.0162243738304824, train_acc = 0.9954587796925943\n",
      "test Acc 0.9548417132216015:\n",
      "12th- epoch: 26, train_loss = 1.929208057350479, train_acc = 0.9956916627852818\n",
      "test Acc 0.9553072625698324:\n",
      "12th- epoch: 27, train_loss = 1.8407609605928883, train_acc = 0.9959245458779693\n",
      "test Acc 0.9562383612662942:\n",
      "12th- epoch: 28, train_loss = 1.7706236983649433, train_acc = 0.9959245458779693\n",
      "test Acc 0.9562383612662942:\n",
      "12th- epoch: 29, train_loss = 1.7057059871731326, train_acc = 0.996040987424313\n",
      "test Acc 0.957169459962756:\n",
      "12th- epoch: 30, train_loss = 1.6458450895734131, train_acc = 0.9959245458779693\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 31, train_loss = 1.5945464938995428, train_acc = 0.996040987424313\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 32, train_loss = 1.5611896232003346, train_acc = 0.9963903120633442\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 33, train_loss = 1.5283212836948223, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 34, train_loss = 1.5082026398740709, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 35, train_loss = 1.4835717473179102, train_acc = 0.9968560782487191\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 36, train_loss = 1.4682986922562122, train_acc = 0.9969725197950629\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 37, train_loss = 1.4538712984067388, train_acc = 0.9969725197950629\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 38, train_loss = 1.436606936622411, train_acc = 0.9969725197950629\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 39, train_loss = 1.4251344532822259, train_acc = 0.9969725197950629\n",
      "test Acc 0.957169459962756:\n",
      "12th- epoch: 40, train_loss = 1.4150474339840002, train_acc = 0.9969725197950629\n",
      "test Acc 0.957169459962756:\n",
      "12th- epoch: 41, train_loss = 1.404144901491236, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 42, train_loss = 1.3946622051298618, train_acc = 0.9969725197950629\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 43, train_loss = 1.3848802976426668, train_acc = 0.9969725197950629\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 44, train_loss = 1.3796054062549956, train_acc = 0.9969725197950629\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 45, train_loss = 1.3697525228490122, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 46, train_loss = 1.3624368158052675, train_acc = 0.9969725197950629\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 47, train_loss = 1.3545297074015252, train_acc = 0.9968560782487191\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 48, train_loss = 1.3470147224143147, train_acc = 0.9968560782487191\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 49, train_loss = 1.3404722276027314, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 50, train_loss = 1.334000967151951, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 51, train_loss = 1.3289829585701227, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 52, train_loss = 1.320162597403396, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 53, train_loss = 1.3133891348843463, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 54, train_loss = 1.3103590567479841, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 55, train_loss = 1.3046518728951924, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 56, train_loss = 1.2999392499332316, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 57, train_loss = 1.297491719305981, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 58, train_loss = 1.2931067061726935, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 59, train_loss = 1.288102068938315, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 60, train_loss = 1.2835408219543751, train_acc = 0.9967396367023754\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 61, train_loss = 1.2822720284457318, train_acc = 0.9967396367023754\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 62, train_loss = 1.2768065184354782, train_acc = 0.9967396367023754\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 63, train_loss = 1.2746851049887482, train_acc = 0.9967396367023754\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 64, train_loss = 1.2691503530368209, train_acc = 0.9967396367023754\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 65, train_loss = 1.2657191172766034, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 66, train_loss = 1.263892349175876, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 67, train_loss = 1.261207789502805, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 68, train_loss = 1.257023581303656, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 69, train_loss = 1.2555488217622042, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 70, train_loss = 1.2526140660047531, train_acc = 0.9968560782487191\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 71, train_loss = 1.2492976213397924, train_acc = 0.9968560782487191\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 72, train_loss = 1.2473860172030982, train_acc = 0.9968560782487191\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 73, train_loss = 1.244536330603296, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 74, train_loss = 1.2422934224305209, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 75, train_loss = 1.2388355381262954, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 76, train_loss = 1.2387589014542755, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 77, train_loss = 1.235601758264238, train_acc = 0.9968560782487191\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 78, train_loss = 1.231761888921028, train_acc = 0.9968560782487191\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 79, train_loss = 1.2257481499982532, train_acc = 0.9969725197950629\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 80, train_loss = 1.2283308953046799, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 81, train_loss = 1.2279165949148592, train_acc = 0.9968560782487191\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 82, train_loss = 1.2190394140779972, train_acc = 0.9969725197950629\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 83, train_loss = 1.2188411510142032, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 84, train_loss = 1.2155117777583655, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 85, train_loss = 1.2126460913568735, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 86, train_loss = 1.20819323262549, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 87, train_loss = 1.2064112406224012, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 88, train_loss = 1.2053902496991213, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 89, train_loss = 1.2029012447892455, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 90, train_loss = 1.2021634727716446, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 91, train_loss = 1.2016028234065743, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 92, train_loss = 1.1997074571700068, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 93, train_loss = 1.1975446927099256, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 94, train_loss = 1.1966730157582788, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 95, train_loss = 1.194521252065897, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 96, train_loss = 1.1935247667133808, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 97, train_loss = 1.194897698238492, train_acc = 0.9969725197950629\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 98, train_loss = 1.1911086980253458, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 99, train_loss = 1.190153969451785, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 100, train_loss = 1.1914081728755264, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 101, train_loss = 1.1863869403750869, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 102, train_loss = 1.1885284992604284, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 103, train_loss = 1.184506906196475, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 104, train_loss = 1.185394786298275, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 105, train_loss = 1.1839063397346763, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 106, train_loss = 1.1805211082100868, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 107, train_loss = 1.183686460062745, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 108, train_loss = 1.1821232661604881, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 109, train_loss = 1.1817294626234798, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 110, train_loss = 1.178777993962285, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 111, train_loss = 1.177835342779872, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 112, train_loss = 1.1748971920460463, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 113, train_loss = 1.1741468695254298, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 114, train_loss = 1.1727205204515485, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 115, train_loss = 1.1723311108798953, train_acc = 0.9973218444340941\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 116, train_loss = 1.1714422218501568, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 117, train_loss = 1.170250474169734, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 118, train_loss = 1.1702476969658164, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 119, train_loss = 1.168550885588047, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 120, train_loss = 1.1671941789536504, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 121, train_loss = 1.1673329745681258, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 122, train_loss = 1.1668312897309079, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 123, train_loss = 1.165108081571816, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 124, train_loss = 1.1655594600961194, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 125, train_loss = 1.1638257155791507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 126, train_loss = 1.1634041902943864, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 127, train_loss = 1.1624119741245522, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 128, train_loss = 1.1621676993891015, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 129, train_loss = 1.1610284578055143, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 130, train_loss = 1.1597082931548357, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 131, train_loss = 1.1606397156938328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 132, train_loss = 1.1593575440347195, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 133, train_loss = 1.1592733263969421, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 134, train_loss = 1.1584571277126088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 135, train_loss = 1.1565037270411267, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 136, train_loss = 1.1571569765583263, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 137, train_loss = 1.1562184610738768, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 138, train_loss = 1.156516565628408, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 139, train_loss = 1.1561023412868963, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 140, train_loss = 1.1546208870931878, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 141, train_loss = 1.1547548485323205, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 142, train_loss = 1.154552356027125, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 143, train_loss = 1.1530906620100723, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 144, train_loss = 1.1517570304349647, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 145, train_loss = 1.1518220504149213, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 146, train_loss = 1.1523616462945938, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 147, train_loss = 1.1500240458772168, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 148, train_loss = 1.1498162479474558, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 149, train_loss = 1.1500267858282314, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 150, train_loss = 1.147889638938068, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 151, train_loss = 1.1481844875961542, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 152, train_loss = 1.1472431483343826, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 153, train_loss = 1.1497590815051808, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 154, train_loss = 1.146962827690004, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 155, train_loss = 1.1457773900256143, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 156, train_loss = 1.1464160233736038, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 157, train_loss = 1.1477365853861556, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 158, train_loss = 1.144863581903337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 159, train_loss = 1.1444373416379676, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 160, train_loss = 1.1422153059393167, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 161, train_loss = 1.1457258469090448, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 162, train_loss = 1.14179833419621, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 163, train_loss = 1.1432908065617085, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 164, train_loss = 1.1395988700314774, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 165, train_loss = 1.1406709123402834, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 166, train_loss = 1.1390843999906792, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 167, train_loss = 1.1416600570082664, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 168, train_loss = 1.1383659839630127, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 169, train_loss = 1.139059883855225, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 170, train_loss = 1.13932155942166, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 171, train_loss = 1.1408648329452262, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 172, train_loss = 1.137358644977212, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 173, train_loss = 1.1389999818056822, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 174, train_loss = 1.135813176013471, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 175, train_loss = 1.13476100564003, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 176, train_loss = 1.1367440354079008, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 177, train_loss = 1.1364695740267052, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 178, train_loss = 1.1344804142936482, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 179, train_loss = 1.1354629565030336, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 180, train_loss = 1.1340349540114403, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 181, train_loss = 1.136705963559507, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 182, train_loss = 1.1334266724661575, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 183, train_loss = 1.1324554054663167, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 184, train_loss = 1.1345879100263119, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 185, train_loss = 1.130645539611578, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 186, train_loss = 1.1314966262652888, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 187, train_loss = 1.1312100893483148, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 188, train_loss = 1.1317151828334318, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 189, train_loss = 1.129386584587337, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 190, train_loss = 1.1293966683224426, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 191, train_loss = 1.1297220699489117, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 192, train_loss = 1.1269439477473497, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 193, train_loss = 1.1279796703383909, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 194, train_loss = 1.1270733941346407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 195, train_loss = 1.1262631683275686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 196, train_loss = 1.1302141665146337, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 197, train_loss = 1.1263492417856469, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 198, train_loss = 1.1267866181806312, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 199, train_loss = 1.1267526131123304, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 200, train_loss = 1.12732287558174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 201, train_loss = 1.1248865773304715, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 202, train_loss = 1.1248492610975518, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 203, train_loss = 1.1247553980574594, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 204, train_loss = 1.1221481288448558, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 205, train_loss = 1.1254691320136772, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 206, train_loss = 1.1232338156551123, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 207, train_loss = 1.1238659707232728, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 208, train_loss = 1.1208232014105306, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 209, train_loss = 1.1237964276224375, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 210, train_loss = 1.1216463961973204, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 211, train_loss = 1.1212633742616163, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 212, train_loss = 1.1217367692515836, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 213, train_loss = 1.120762429512979, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 214, train_loss = 1.1209224915728555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 215, train_loss = 1.1197950864807353, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 216, train_loss = 1.120072857789637, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 217, train_loss = 1.1190063556059613, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 218, train_loss = 1.1187522318214178, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 219, train_loss = 1.1180523696020828, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 220, train_loss = 1.1187193828300224, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 221, train_loss = 1.1167385466396809, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 222, train_loss = 1.1177275522277341, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 223, train_loss = 1.115921026095748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 224, train_loss = 1.1159289659335627, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 225, train_loss = 1.1148638346567168, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 226, train_loss = 1.1153154354542494, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 227, train_loss = 1.11387325450778, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 228, train_loss = 1.1144009536728845, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 229, train_loss = 1.1134362760931253, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 230, train_loss = 1.1162066192700877, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 231, train_loss = 1.1125064014122472, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 232, train_loss = 1.1137912590056658, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 233, train_loss = 1.1113487028851523, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 234, train_loss = 1.113391146682261, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 235, train_loss = 1.1084987347348942, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 236, train_loss = 1.1110250645651831, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 237, train_loss = 1.1096172804609523, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 238, train_loss = 1.1104578468948603, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 239, train_loss = 1.1083319087847485, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 240, train_loss = 1.109594793371798, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 241, train_loss = 1.1063536914662109, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 242, train_loss = 1.1086409048511996, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 243, train_loss = 1.1055868373587145, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 244, train_loss = 1.1065575045868172, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 245, train_loss = 1.1062966367826448, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 246, train_loss = 1.105531686298491, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 247, train_loss = 1.1057832799851894, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 248, train_loss = 1.1056590806692839, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 249, train_loss = 1.105267234146595, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 250, train_loss = 1.106315778568387, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 251, train_loss = 1.1020913763568387, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 252, train_loss = 1.1060650820509181, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 253, train_loss = 1.1014384745285497, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 254, train_loss = 1.1023160237818956, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 255, train_loss = 1.100263729073049, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 256, train_loss = 1.102702084928751, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 257, train_loss = 1.1022363075389876, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 258, train_loss = 1.1018073167651892, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 259, train_loss = 1.100598222888948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 260, train_loss = 1.101126781977655, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 261, train_loss = 1.1000658851116896, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 262, train_loss = 1.100993063300848, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 263, train_loss = 1.0976482989863143, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 264, train_loss = 1.0999881830066442, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 265, train_loss = 1.0973461052999482, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 266, train_loss = 1.09935810292518, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 267, train_loss = 1.0982473169788136, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 268, train_loss = 1.097535372398852, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 269, train_loss = 1.0964722943826928, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 270, train_loss = 1.0964983167723403, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 271, train_loss = 1.0959496647119522, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 272, train_loss = 1.0963614632710232, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 273, train_loss = 1.0931375250220299, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 274, train_loss = 1.0953373722732067, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 275, train_loss = 1.0931680792346015, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 276, train_loss = 1.0949012798591866, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 277, train_loss = 1.0937334652990103, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 278, train_loss = 1.0929994750767946, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 279, train_loss = 1.0925602639690624, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 280, train_loss = 1.0934140787794604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 281, train_loss = 1.0915360376238823, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 282, train_loss = 1.092100948713778, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 283, train_loss = 1.0902775960639701, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 284, train_loss = 1.0908538655712618, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 285, train_loss = 1.0902407802641392, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 286, train_loss = 1.089785266049148, train_acc = 0.9973218444340941\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 287, train_loss = 1.0893359811379923, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 288, train_loss = 1.0894776433706284, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 289, train_loss = 1.089512920625566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 290, train_loss = 1.087793448321463, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 291, train_loss = 1.0888325963169336, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 292, train_loss = 1.08715366510296, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 293, train_loss = 1.087646351508738, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 294, train_loss = 1.087006493784429, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 295, train_loss = 1.0862807451412664, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 296, train_loss = 1.086398699633719, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 297, train_loss = 1.0835770542398677, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 298, train_loss = 1.0844501250758185, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 299, train_loss = 1.0847066032365547, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 300, train_loss = 1.0840295664966106, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 301, train_loss = 1.0840077518150792, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 302, train_loss = 1.0833683367818594, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 303, train_loss = 1.0837196664288058, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 304, train_loss = 1.082140284277557, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 305, train_loss = 1.0833250669165864, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 306, train_loss = 1.0803861555978074, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 307, train_loss = 1.0819864540026174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 308, train_loss = 1.0819801427423954, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 309, train_loss = 1.0802639101966633, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 310, train_loss = 1.0806817288175807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 311, train_loss = 1.079983481518866, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 312, train_loss = 1.079104463882686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 313, train_loss = 1.080140116311668, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 314, train_loss = 1.0783476332799182, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 315, train_loss = 1.0780570941642509, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 316, train_loss = 1.0774826159104123, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 317, train_loss = 1.0779417138546705, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 318, train_loss = 1.077499557286501, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 319, train_loss = 1.0765441885814653, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 320, train_loss = 1.0766568928956985, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 321, train_loss = 1.0766331764534698, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 322, train_loss = 1.0754246345386491, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 323, train_loss = 1.0751867542639957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 324, train_loss = 1.0754108553155675, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 325, train_loss = 1.0742630176246166, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 326, train_loss = 1.0748087434694753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 327, train_loss = 1.0741754211485386, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 328, train_loss = 1.072814224906324, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 329, train_loss = 1.0736904659643187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 330, train_loss = 1.0737526075317874, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 331, train_loss = 1.0716535045430646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 332, train_loss = 1.0722107657566085, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 333, train_loss = 1.0724497511982918, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 334, train_loss = 1.0706485578193679, train_acc = 0.9973218444340941\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 335, train_loss = 1.0711901138201938, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 336, train_loss = 1.071331405393721, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 337, train_loss = 1.0693267012611614, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 338, train_loss = 1.0695038978010416, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 339, train_loss = 1.0703228035345091, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 340, train_loss = 1.0682247461154475, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 341, train_loss = 1.0681083543822751, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 342, train_loss = 1.069545241072774, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 343, train_loss = 1.0681839728131308, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 344, train_loss = 1.0668356766327634, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 345, train_loss = 1.0680845038368716, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 346, train_loss = 1.0666411078200326, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 347, train_loss = 1.0653887453154312, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 348, train_loss = 1.066851396113634, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 349, train_loss = 1.065672234944941, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 350, train_loss = 1.0655444357544184, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 351, train_loss = 1.0653385718687787, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 352, train_loss = 1.0647502318024635, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 353, train_loss = 1.0640006357207312, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 354, train_loss = 1.0642151621505036, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 355, train_loss = 1.0634437712506042, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 356, train_loss = 1.063064522422792, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 357, train_loss = 1.064049253858684, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 358, train_loss = 1.0618256870657206, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 359, train_loss = 1.0618267375975847, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 360, train_loss = 1.0626168996095657, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 361, train_loss = 1.060191618897079, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 362, train_loss = 1.0605130977928638, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 363, train_loss = 1.0610724830403342, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 364, train_loss = 1.0602769311517477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 365, train_loss = 1.059018298983574, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 366, train_loss = 1.0600545232518925, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 367, train_loss = 1.0593285616487265, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 368, train_loss = 1.0587628607972874, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 369, train_loss = 1.0590073373168707, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 370, train_loss = 1.0573446253911243, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 371, train_loss = 1.0582511530592456, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 372, train_loss = 1.0574918457641616, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 373, train_loss = 1.0561317869796767, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 374, train_loss = 1.0571496399716125, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 375, train_loss = 1.0573638770729303, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 376, train_loss = 1.0551841830238118, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 377, train_loss = 1.0559509694576263, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 378, train_loss = 1.0561762147917761, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 379, train_loss = 1.0550084126516595, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 380, train_loss = 1.0536977772935643, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 381, train_loss = 1.0553161545321927, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 382, train_loss = 1.0533464246764197, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 383, train_loss = 1.0531127440408454, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 384, train_loss = 1.0533239115029573, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 385, train_loss = 1.052980942033173, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 386, train_loss = 1.0531242731958628, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 387, train_loss = 1.0525674472228275, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 388, train_loss = 1.0510497043505893, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 389, train_loss = 1.0519732981920242, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 390, train_loss = 1.0519733379260288, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 391, train_loss = 1.0498206950724125, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 392, train_loss = 1.050274300701858, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 393, train_loss = 1.0513412356376648, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 394, train_loss = 1.0486597996205091, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 395, train_loss = 1.0485305190086365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 396, train_loss = 1.0497976783663034, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 397, train_loss = 1.048879407964705, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 398, train_loss = 1.0489957878962741, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 399, train_loss = 1.0482070495709195, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 400, train_loss = 1.0470022006556974, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 401, train_loss = 1.0477624293416739, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 402, train_loss = 1.048827504120709, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 403, train_loss = 1.0464693841859116, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 404, train_loss = 1.0460701218471513, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 405, train_loss = 1.0469300970435143, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 406, train_loss = 1.0457068967298255, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 407, train_loss = 1.0453121854588971, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 408, train_loss = 1.045710515230894, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 409, train_loss = 1.0441030661240802, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 410, train_loss = 1.043688348181604, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 411, train_loss = 1.0447219833731651, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 412, train_loss = 1.0430191612467752, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 413, train_loss = 1.0441415458917618, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 414, train_loss = 1.0436295469626202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 415, train_loss = 1.0424348060041666, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 416, train_loss = 1.0421849197373376, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 417, train_loss = 1.043028232328652, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 418, train_loss = 1.042074083663465, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 419, train_loss = 1.0412755850702524, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 420, train_loss = 1.0415280448869453, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 421, train_loss = 1.0422809037045226, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 422, train_loss = 1.040658932797669, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 423, train_loss = 1.03973353033507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 424, train_loss = 1.040075859054923, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 425, train_loss = 1.0405230230317102, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 426, train_loss = 1.0395151333286776, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 427, train_loss = 1.0380581077188253, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 428, train_loss = 1.0387990145609365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 429, train_loss = 1.0393574467525468, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 430, train_loss = 1.0384013640359626, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 431, train_loss = 1.0356417130678892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 432, train_loss = 1.038083673141955, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 433, train_loss = 1.0371987832113518, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 434, train_loss = 1.0368708322421298, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 435, train_loss = 1.0361850497647538, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 436, train_loss = 1.0348704823627486, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 437, train_loss = 1.035451928153634, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 438, train_loss = 1.036280711494328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 439, train_loss = 1.0347260317430482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 440, train_loss = 1.034141260512115, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 441, train_loss = 1.035116241000651, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 442, train_loss = 1.0352549850940704, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 443, train_loss = 1.0345614403486252, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 444, train_loss = 1.0332017876207829, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 445, train_loss = 1.032734531290771, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 446, train_loss = 1.0345749823973165, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 447, train_loss = 1.0329411663115025, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 448, train_loss = 1.0302604380995035, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 449, train_loss = 1.032638536147715, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 450, train_loss = 1.0318654545917525, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 451, train_loss = 1.031348612777947, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 452, train_loss = 1.0321486418470158, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 453, train_loss = 1.0312541543171392, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 454, train_loss = 1.0297197978943586, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 455, train_loss = 1.0306670845820918, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 456, train_loss = 1.0307218382731662, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 457, train_loss = 1.0305350820199237, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 458, train_loss = 1.02879974742973, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 459, train_loss = 1.0279373787343502, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 460, train_loss = 1.0295779469088302, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 461, train_loss = 1.027767947562097, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 462, train_loss = 1.0274535100907087, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 463, train_loss = 1.02794300889218, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 464, train_loss = 1.0280798164531006, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 465, train_loss = 1.0277703789397492, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 466, train_loss = 1.0248237910345779, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 467, train_loss = 1.0258345995098352, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 468, train_loss = 1.0267222939655767, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 469, train_loss = 1.026840329170227, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 470, train_loss = 1.0267438894734369, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 471, train_loss = 1.0248735795394168, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 472, train_loss = 1.0247798239215626, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 473, train_loss = 1.0255071924402728, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 474, train_loss = 1.024577342592238, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 475, train_loss = 1.0222238190472126, train_acc = 0.9974382859804378\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 476, train_loss = 1.023343757413386, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 477, train_loss = 1.0240879946722998, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 478, train_loss = 1.0241925790905952, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 479, train_loss = 1.0232340786606073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 480, train_loss = 1.0209351132289157, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 481, train_loss = 1.0209533528759493, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 482, train_loss = 1.0216838208361878, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 483, train_loss = 1.02104528745258, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 484, train_loss = 1.0206814718767419, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 485, train_loss = 1.0201058735474362, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 486, train_loss = 1.0199222024530172, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 487, train_loss = 1.0191483249291196, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 488, train_loss = 1.0188639499247074, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 489, train_loss = 1.017996999747993, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 490, train_loss = 1.015537933759333, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 491, train_loss = 1.016580534480454, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 492, train_loss = 1.0171227337195887, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 493, train_loss = 1.01756164804101, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 494, train_loss = 1.015642969556211, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 495, train_loss = 1.0156646048053517, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 496, train_loss = 1.0138698816299438, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 497, train_loss = 1.0159263169989572, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 498, train_loss = 1.0144636829718365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 499, train_loss = 1.0143562027587905, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|██████████████████████████████▍                                             | 12/30 [1:53:12<2:59:27, 598.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "13th- epoch: 0, train_loss = 417.524702295661, train_acc = 0.7966930600838379\n",
      "test Acc 0.8431098696461825:\n",
      "13th- epoch: 1, train_loss = 98.3236294304952, train_acc = 0.9194224499301351\n",
      "test Acc 0.925512104283054:\n",
      "13th- epoch: 2, train_loss = 61.00089010596275, train_acc = 0.9443409408476945\n",
      "test Acc 0.9334264432029795:\n",
      "13th- epoch: 3, train_loss = 43.15961559675634, train_acc = 0.9563344201210993\n",
      "test Acc 0.9343575418994413:\n",
      "13th- epoch: 4, train_loss = 32.56709502264857, train_acc = 0.9654168607359106\n",
      "test Acc 0.9366852886405959:\n",
      "13th- epoch: 5, train_loss = 25.1407687375322, train_acc = 0.9710060549604099\n",
      "test Acc 0.9418063314711359:\n",
      "13th- epoch: 6, train_loss = 19.79728145338595, train_acc = 0.9763623660922217\n",
      "test Acc 0.9483240223463687:\n",
      "13th- epoch: 7, train_loss = 15.971668353304267, train_acc = 0.9804378202142524\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 8, train_loss = 13.349329535849392, train_acc = 0.9833488588728458\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 9, train_loss = 11.353213496506214, train_acc = 0.9856776897997206\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 10, train_loss = 9.771546852774918, train_acc = 0.9864927806241267\n",
      "test Acc 0.9450651769087524:\n",
      "13th- epoch: 11, train_loss = 8.48372440226376, train_acc = 0.9877736376339078\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 12, train_loss = 7.373774325009435, train_acc = 0.9890544946436889\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 13, train_loss = 6.396372597198933, train_acc = 0.989869585468095\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 14, train_loss = 5.601330891251564, train_acc = 0.9904517931998137\n",
      "test Acc 0.9483240223463687:\n",
      "13th- epoch: 15, train_loss = 4.884008259046823, train_acc = 0.9916162086632511\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 16, train_loss = 4.345950147602707, train_acc = 0.992081974848626\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 17, train_loss = 3.897783402353525, train_acc = 0.9927806241266884\n",
      "test Acc 0.9529795158286778:\n",
      "13th- epoch: 18, train_loss = 3.544458447722718, train_acc = 0.9926641825803446\n",
      "test Acc 0.9539106145251397:\n",
      "13th- epoch: 19, train_loss = 3.244894976960495, train_acc = 0.9933628318584071\n",
      "test Acc 0.9553072625698324:\n",
      "13th- epoch: 20, train_loss = 3.0041987516451627, train_acc = 0.9937121564974383\n",
      "test Acc 0.9567039106145251:\n",
      "13th- epoch: 21, train_loss = 2.7996535506099463, train_acc = 0.9940614811364695\n",
      "test Acc 0.957635009310987:\n",
      "13th- epoch: 22, train_loss = 2.614735812880099, train_acc = 0.994294364229157\n",
      "test Acc 0.957169459962756:\n",
      "13th- epoch: 23, train_loss = 2.448796981247142, train_acc = 0.9945272473218444\n",
      "test Acc 0.957635009310987:\n",
      "13th- epoch: 24, train_loss = 2.3228818539064378, train_acc = 0.9949930135072194\n",
      "test Acc 0.9585661080074488:\n",
      "13th- epoch: 25, train_loss = 2.1981273957062513, train_acc = 0.9952258965999069\n",
      "test Acc 0.9581005586592178:\n",
      "13th- epoch: 26, train_loss = 2.1098860905040056, train_acc = 0.9953423381462506\n",
      "test Acc 0.9585661080074488:\n",
      "13th- epoch: 27, train_loss = 2.0297485307091847, train_acc = 0.995575221238938\n",
      "test Acc 0.9594972067039106:\n",
      "13th- epoch: 28, train_loss = 1.9577317158691585, train_acc = 0.9958081043316255\n",
      "test Acc 0.9590316573556797:\n",
      "13th- epoch: 29, train_loss = 1.9044802858261392, train_acc = 0.9959245458779693\n",
      "test Acc 0.9599627560521415:\n",
      "13th- epoch: 30, train_loss = 1.8485024307155982, train_acc = 0.996040987424313\n",
      "test Acc 0.9594972067039106:\n",
      "13th- epoch: 31, train_loss = 1.8019131034379825, train_acc = 0.9962738705170004\n",
      "test Acc 0.9594972067039106:\n",
      "13th- epoch: 32, train_loss = 1.7685166684677824, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "13th- epoch: 33, train_loss = 1.7327812565490603, train_acc = 0.9962738705170004\n",
      "test Acc 0.9608938547486033:\n",
      "13th- epoch: 34, train_loss = 1.7056060088798404, train_acc = 0.9962738705170004\n",
      "test Acc 0.9608938547486033:\n",
      "13th- epoch: 35, train_loss = 1.6770667735254392, train_acc = 0.9963903120633442\n",
      "test Acc 0.9613594040968343:\n",
      "13th- epoch: 36, train_loss = 1.659264664282091, train_acc = 0.9963903120633442\n",
      "test Acc 0.9613594040968343:\n",
      "13th- epoch: 37, train_loss = 1.634369679260999, train_acc = 0.996506753609688\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 38, train_loss = 1.6181038370123133, train_acc = 0.996506753609688\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 39, train_loss = 1.595700798672624, train_acc = 0.996506753609688\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 40, train_loss = 1.5844114607898518, train_acc = 0.996506753609688\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 41, train_loss = 1.5699916466837749, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 42, train_loss = 1.5536386858439073, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 43, train_loss = 1.5417414552066475, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 44, train_loss = 1.5289780308958143, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 45, train_loss = 1.517135138681624, train_acc = 0.9963903120633442\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 46, train_loss = 1.5067491350346245, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 47, train_loss = 1.4940527647850104, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 48, train_loss = 1.4893305540899746, train_acc = 0.9963903120633442\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 49, train_loss = 1.4725648637977429, train_acc = 0.996506753609688\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 50, train_loss = 1.4673707345500588, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "13th- epoch: 51, train_loss = 1.455691153241787, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "13th- epoch: 52, train_loss = 1.4489295131061226, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "13th- epoch: 53, train_loss = 1.437083938100841, train_acc = 0.996506753609688\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 54, train_loss = 1.430053184274584, train_acc = 0.996506753609688\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 55, train_loss = 1.4223108069854788, train_acc = 0.996506753609688\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 56, train_loss = 1.4156683568726294, train_acc = 0.996506753609688\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 57, train_loss = 1.406203287653625, train_acc = 0.996506753609688\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 58, train_loss = 1.399871268775314, train_acc = 0.996506753609688\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 59, train_loss = 1.3947893138974905, train_acc = 0.996506753609688\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 60, train_loss = 1.389126016467344, train_acc = 0.996506753609688\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 61, train_loss = 1.383346795279067, train_acc = 0.996506753609688\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 62, train_loss = 1.3785904475371353, train_acc = 0.996506753609688\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 63, train_loss = 1.3721677393768914, train_acc = 0.996506753609688\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 64, train_loss = 1.3677459114114754, train_acc = 0.996506753609688\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 65, train_loss = 1.3644461414660327, train_acc = 0.996506753609688\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 66, train_loss = 1.356478365138173, train_acc = 0.996506753609688\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 67, train_loss = 1.3566725384443998, train_acc = 0.996506753609688\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 68, train_loss = 1.34826088527916, train_acc = 0.996506753609688\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 69, train_loss = 1.3427732928539626, train_acc = 0.996506753609688\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 70, train_loss = 1.3377340764855035, train_acc = 0.996506753609688\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 71, train_loss = 1.3339322417159565, train_acc = 0.996506753609688\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 72, train_loss = 1.3312742719426751, train_acc = 0.996506753609688\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 73, train_loss = 1.3254075574805029, train_acc = 0.996506753609688\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 74, train_loss = 1.3230862257187255, train_acc = 0.996506753609688\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 75, train_loss = 1.3200356128509156, train_acc = 0.996506753609688\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 76, train_loss = 1.3149496738915332, train_acc = 0.996506753609688\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 77, train_loss = 1.31180541991489, train_acc = 0.996506753609688\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 78, train_loss = 1.3088536756113172, train_acc = 0.996506753609688\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 79, train_loss = 1.3056121322442777, train_acc = 0.996506753609688\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 80, train_loss = 1.3007777414168231, train_acc = 0.996506753609688\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 81, train_loss = 1.2974684468354098, train_acc = 0.996506753609688\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 82, train_loss = 1.2930520030786283, train_acc = 0.996506753609688\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 83, train_loss = 1.2897890011663549, train_acc = 0.996506753609688\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 84, train_loss = 1.2882191129028797, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 85, train_loss = 1.2839971669018269, train_acc = 0.996506753609688\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 86, train_loss = 1.280808534764219, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 87, train_loss = 1.2769539722648915, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 88, train_loss = 1.277298128552502, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 89, train_loss = 1.2719598856347147, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 90, train_loss = 1.2689246206136886, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 91, train_loss = 1.2676089800370391, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 92, train_loss = 1.2612327511014882, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 93, train_loss = 1.260112952440977, train_acc = 0.996506753609688\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 94, train_loss = 1.256703408434987, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 95, train_loss = 1.2551032975316048, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 96, train_loss = 1.250393699243432, train_acc = 0.996506753609688\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 97, train_loss = 1.2486728032527026, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 98, train_loss = 1.244834751210874, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 99, train_loss = 1.243262351170415, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 100, train_loss = 1.2396735108050052, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 101, train_loss = 1.2405350167828146, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 102, train_loss = 1.2349758390337229, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 103, train_loss = 1.2336969124153256, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 104, train_loss = 1.2324180776777212, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 105, train_loss = 1.2280956631002482, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 106, train_loss = 1.2245498315023724, train_acc = 0.996506753609688\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 107, train_loss = 1.2257922319695354, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 108, train_loss = 1.2209420340659562, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 109, train_loss = 1.2186947952432092, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 110, train_loss = 1.220328019320732, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 111, train_loss = 1.2161931597220246, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 112, train_loss = 1.2138971953245346, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 113, train_loss = 1.2118882598879281, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 114, train_loss = 1.2120444104075432, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 115, train_loss = 1.208226236194605, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 116, train_loss = 1.2075903617369477, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 117, train_loss = 1.204303598642582, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 118, train_loss = 1.203614230878884, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 119, train_loss = 1.2003136994317174, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 120, train_loss = 1.201022907771403, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 121, train_loss = 1.196049027144909, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 122, train_loss = 1.1947168115002569, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 123, train_loss = 1.1962041892111301, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 124, train_loss = 1.1921578754263464, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 125, train_loss = 1.1902323681861162, train_acc = 0.9967396367023754\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 126, train_loss = 1.1887915879487991, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 127, train_loss = 1.190121818013722, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 128, train_loss = 1.1858328667876776, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 129, train_loss = 1.186356483027339, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 130, train_loss = 1.182073234260315, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 131, train_loss = 1.1798502008023206, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 132, train_loss = 1.1791610391810536, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 133, train_loss = 1.1782356249168515, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 134, train_loss = 1.1788394566101488, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 135, train_loss = 1.1752844800648745, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 136, train_loss = 1.1739322788489517, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 137, train_loss = 1.1741155966592487, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 138, train_loss = 1.1705275615677238, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 139, train_loss = 1.1699295562284533, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 140, train_loss = 1.16858428157866, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 141, train_loss = 1.1701735664682928, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 142, train_loss = 1.1643588822335005, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 143, train_loss = 1.1625687265768647, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 144, train_loss = 1.1644061651604716, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 145, train_loss = 1.160540697776014, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 146, train_loss = 1.1594882402569056, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 147, train_loss = 1.1584408357739449, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 148, train_loss = 1.1594800564053003, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 149, train_loss = 1.1553245416434947, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 150, train_loss = 1.1547141699120402, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 151, train_loss = 1.1559257985500153, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 152, train_loss = 1.1518794357252773, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 153, train_loss = 1.1507951868698, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 154, train_loss = 1.1506864074617624, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 155, train_loss = 1.148730341650662, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 156, train_loss = 1.1491856665088562, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 157, train_loss = 1.1464885703026084, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 158, train_loss = 1.144925714164856, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 159, train_loss = 1.1441813744604588, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 160, train_loss = 1.1457912409678102, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 161, train_loss = 1.141834210298839, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 162, train_loss = 1.1414813712908654, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 163, train_loss = 1.1406292656174628, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 164, train_loss = 1.1391790794878034, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 165, train_loss = 1.140879192695138, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 166, train_loss = 1.1378178875893354, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 167, train_loss = 1.136071044486016, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 168, train_loss = 1.1352160704991547, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 169, train_loss = 1.1361812284885673, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 170, train_loss = 1.1342170666903257, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 171, train_loss = 1.1324096606113017, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 172, train_loss = 1.1324396883137524, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 173, train_loss = 1.1302887154743075, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 174, train_loss = 1.1313909475429682, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 175, train_loss = 1.1278504991641967, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 176, train_loss = 1.1269712268112926, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 177, train_loss = 1.12623975193128, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 178, train_loss = 1.1254325650370447, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 179, train_loss = 1.125605304419878, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 180, train_loss = 1.1242443338705925, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 181, train_loss = 1.1225000264385017, train_acc = 0.9972054028877504\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 182, train_loss = 1.1219236347824335, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 183, train_loss = 1.123758084300789, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 184, train_loss = 1.1198111359699396, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 185, train_loss = 1.1194852835760685, train_acc = 0.9970889613414066\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 186, train_loss = 1.1185524303728016, train_acc = 0.9972054028877504\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 187, train_loss = 1.1166255132557126, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 188, train_loss = 1.1195401907898486, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 189, train_loss = 1.1159289609640837, train_acc = 0.9972054028877504\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 190, train_loss = 1.1138745581993135, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 191, train_loss = 1.1146166433318285, train_acc = 0.9973218444340941\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 192, train_loss = 1.1137886697688373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 193, train_loss = 1.1150939101353288, train_acc = 0.9973218444340941\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 194, train_loss = 1.111830118112266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 195, train_loss = 1.1108573976234766, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 196, train_loss = 1.1107350601814687, train_acc = 0.9973218444340941\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 197, train_loss = 1.1092263163736789, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 198, train_loss = 1.1094928504171548, train_acc = 0.9973218444340941\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 199, train_loss = 1.1118720453232527, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 200, train_loss = 1.1080556526576402, train_acc = 0.9973218444340941\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 201, train_loss = 1.1072441462165443, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 202, train_loss = 1.1063777873496292, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 203, train_loss = 1.107920401263982, train_acc = 0.9973218444340941\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 204, train_loss = 1.1043637844995828, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 205, train_loss = 1.1043473125173477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 206, train_loss = 1.1041830526664853, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 207, train_loss = 1.1022249568923144, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 208, train_loss = 1.1032847658061655, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 209, train_loss = 1.1037528535089223, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 210, train_loss = 1.1007291069981875, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 211, train_loss = 1.100142456125468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 212, train_loss = 1.0996351217181655, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 213, train_loss = 1.1003457075712504, train_acc = 0.9973218444340941\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 214, train_loss = 1.0988703353796154, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 215, train_loss = 1.097824091091752, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 216, train_loss = 1.096279282355681, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 217, train_loss = 1.095715144998394, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 218, train_loss = 1.095431617111899, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 219, train_loss = 1.097375001598266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 220, train_loss = 1.0933338066533906, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 221, train_loss = 1.093482201496954, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 222, train_loss = 1.093134428258054, train_acc = 0.9974382859804378\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 223, train_loss = 1.0918858774675755, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 224, train_loss = 1.0911897328187479, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 225, train_loss = 1.0932371012168005, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 226, train_loss = 1.0895384135656059, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 227, train_loss = 1.0892551058641402, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 228, train_loss = 1.0892235553619685, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 229, train_loss = 1.0901616343762726, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 230, train_loss = 1.087599527600105, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 231, train_loss = 1.0868346323695732, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 232, train_loss = 1.086089167118189, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 233, train_loss = 1.0853623040602542, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 234, train_loss = 1.0843106956453994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 235, train_loss = 1.085659225951531, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 236, train_loss = 1.0838916368520586, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 237, train_loss = 1.0828898509644205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 238, train_loss = 1.0828733679518336, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 239, train_loss = 1.0817969314521179, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 240, train_loss = 1.0806693457998335, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 241, train_loss = 1.0794820616283687, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 242, train_loss = 1.0799625930958427, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 243, train_loss = 1.0817047557357, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 244, train_loss = 1.0782414408022305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 245, train_loss = 1.0776143310504267, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 246, train_loss = 1.0778662233497016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 247, train_loss = 1.0769820462737698, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 248, train_loss = 1.0787246596155455, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 249, train_loss = 1.0756725169630954, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 250, train_loss = 1.074651424176409, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 251, train_loss = 1.074444378784392, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 252, train_loss = 1.075041860822239, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 253, train_loss = 1.0727967362763593, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 254, train_loss = 1.072849401505664, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 255, train_loss = 1.0721770188974915, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 256, train_loss = 1.0741309038567124, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 257, train_loss = 1.0712413801811635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 258, train_loss = 1.071114147969638, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 259, train_loss = 1.070257456623949, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 260, train_loss = 1.069337044187705, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 261, train_loss = 1.0688948343304219, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 262, train_loss = 1.0706570973125054, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 263, train_loss = 1.067608050769195, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 264, train_loss = 1.0671870702208253, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 265, train_loss = 1.0668634976027533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 266, train_loss = 1.0664311765431194, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 267, train_loss = 1.065807043996756, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 268, train_loss = 1.0645165710448055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 269, train_loss = 1.066854514181614, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 270, train_loss = 1.0637542657350423, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 271, train_loss = 1.0625866529735504, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 272, train_loss = 1.0625011875963537, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 273, train_loss = 1.0628243254759582, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 274, train_loss = 1.0613707985467045, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 275, train_loss = 1.0610520509071648, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 276, train_loss = 1.0627242598420708, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 277, train_loss = 1.0602983216085704, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 278, train_loss = 1.0586068852135213, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 279, train_loss = 1.0596485825517448, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 280, train_loss = 1.0590018752700416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 281, train_loss = 1.0577718750573695, train_acc = 0.9974382859804378\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 282, train_loss = 1.0577218005637405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 283, train_loss = 1.0594995606224984, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 284, train_loss = 1.0563459757249802, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 285, train_loss = 1.055876265047118, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 286, train_loss = 1.0557921008003177, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 287, train_loss = 1.0549806766939582, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 288, train_loss = 1.0548238974733977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 289, train_loss = 1.0542704273684649, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 290, train_loss = 1.0560273953451542, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 291, train_loss = 1.0533853614906548, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 292, train_loss = 1.0515916782896966, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 293, train_loss = 1.0524287431762787, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 294, train_loss = 1.0519435586611507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 295, train_loss = 1.0507487365975976, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 296, train_loss = 1.0509963231161237, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 297, train_loss = 1.049864311076817, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 298, train_loss = 1.04939498163003, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 299, train_loss = 1.0519896227197023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 300, train_loss = 1.049362741105142, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 301, train_loss = 1.0458977579401108, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 302, train_loss = 1.0481609369890066, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 303, train_loss = 1.047513445999357, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 304, train_loss = 1.0469230098387925, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 305, train_loss = 1.0461186639295192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 306, train_loss = 1.044417711746064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 307, train_loss = 1.0476904854440363, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 308, train_loss = 1.0435570107511012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 309, train_loss = 1.0440586769691436, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 310, train_loss = 1.0422191174438922, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 311, train_loss = 1.0434487413876923, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 312, train_loss = 1.0415904672554461, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 313, train_loss = 1.0428858357481658, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 314, train_loss = 1.0407978459261358, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 315, train_loss = 1.044593460392207, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 316, train_loss = 1.0402971978037385, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 317, train_loss = 1.0400694498530356, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 318, train_loss = 1.0410223441867856, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 319, train_loss = 1.0394974847586127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 320, train_loss = 1.0398613642901182, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 321, train_loss = 1.0375117883086205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 322, train_loss = 1.0382681675255299, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 323, train_loss = 1.0412111071200343, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 324, train_loss = 1.0362830174417468, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 325, train_loss = 1.0371355762035819, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 326, train_loss = 1.0360140570701333, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 327, train_loss = 1.0367538395075826, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 328, train_loss = 1.0352215499879094, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 329, train_loss = 1.0358538776636124, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 330, train_loss = 1.0344575382769108, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 331, train_loss = 1.0376084614545107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 332, train_loss = 1.0331085622310638, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 333, train_loss = 1.0331252968608169, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 334, train_loss = 1.0346628967672586, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 335, train_loss = 1.032216913998127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 336, train_loss = 1.031543113916996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 337, train_loss = 1.032631582886097, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 338, train_loss = 1.03074271355581, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 339, train_loss = 1.0350860127509804, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 340, train_loss = 1.0303128229716094, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 341, train_loss = 1.0311671420931816, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 342, train_loss = 1.0298362136818469, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 343, train_loss = 1.030520519707352, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 344, train_loss = 1.02778904994193, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 345, train_loss = 1.0295839947648346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 346, train_loss = 1.0273955754673807, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 347, train_loss = 1.027648553092149, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 348, train_loss = 1.027801922056824, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 349, train_loss = 1.0263837909587892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 350, train_loss = 1.0298789533117088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 351, train_loss = 1.0260974396951497, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 352, train_loss = 1.0258323020971147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 353, train_loss = 1.0251408807671396, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 354, train_loss = 1.0259141218848526, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 355, train_loss = 1.0246026450768113, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 356, train_loss = 1.0234302982426016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 357, train_loss = 1.0235611738899024, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 358, train_loss = 1.0226772042660741, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 359, train_loss = 1.0248866016045213, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 360, train_loss = 1.0220502642914653, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 361, train_loss = 1.0236841095611453, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 362, train_loss = 1.023753395609674, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 363, train_loss = 1.021530426107347, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 364, train_loss = 1.02073117501277, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 365, train_loss = 1.0201668761001201, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 366, train_loss = 1.0219880879594712, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 367, train_loss = 1.01997322247189, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 368, train_loss = 1.0193024137988687, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 369, train_loss = 1.0184522566123633, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 370, train_loss = 1.0224529507831903, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 371, train_loss = 1.0203469367697835, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 372, train_loss = 1.017676887102425, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 373, train_loss = 1.0171659188345075, train_acc = 0.9974382859804378\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 374, train_loss = 1.0171181711630197, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 375, train_loss = 1.0169783486053348, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 376, train_loss = 1.0168556642456679, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 377, train_loss = 1.0199545115901856, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 378, train_loss = 1.0149974732921692, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 379, train_loss = 1.0172112549917074, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 380, train_loss = 1.0144556782470318, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 381, train_loss = 1.0145822145714192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 382, train_loss = 1.0164726143702865, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 383, train_loss = 1.0131765532569261, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 384, train_loss = 1.0132380174472928, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 385, train_loss = 1.0132484817877412, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 386, train_loss = 1.014079567976296, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 387, train_loss = 1.0125359070225386, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 388, train_loss = 1.012309516154346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 389, train_loss = 1.0143031201587291, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 390, train_loss = 1.0128794880583882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 391, train_loss = 1.01006181196135, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 392, train_loss = 1.0112461308017373, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 393, train_loss = 1.0100688130332856, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 394, train_loss = 1.011366057835403, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 395, train_loss = 1.0095322110428242, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 396, train_loss = 1.0089965453371406, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 397, train_loss = 1.0089427422062727, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 398, train_loss = 1.010829615406692, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 399, train_loss = 1.0081344132049708, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 400, train_loss = 1.0075138115062146, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 401, train_loss = 1.0094520266429754, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 402, train_loss = 1.0086124697700143, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 403, train_loss = 1.00751188180584, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 404, train_loss = 1.0062803529872326, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 405, train_loss = 1.0058947947545676, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 406, train_loss = 1.005749808929977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 407, train_loss = 1.0057642878964543, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 408, train_loss = 1.0051554947422119, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 409, train_loss = 1.0063779978081584, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 410, train_loss = 1.004408583350596, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 411, train_loss = 1.00367490046483, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 412, train_loss = 1.0042010890319943, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 413, train_loss = 1.007234636999783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 414, train_loss = 1.0036606046633096, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 415, train_loss = 1.0023503784759669, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 416, train_loss = 1.0025406197382836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 417, train_loss = 1.0039938374684425, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 418, train_loss = 1.001742508567986, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 419, train_loss = 1.001437867365894, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 420, train_loss = 1.000729070045054, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 421, train_loss = 0.9999328364356188, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 422, train_loss = 1.000170518644154, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 423, train_loss = 1.0042532964871498, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 424, train_loss = 0.9998972114844946, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 425, train_loss = 0.9999738903716207, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 426, train_loss = 0.9990880200639367, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 427, train_loss = 1.0003540009856806, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 428, train_loss = 0.9986702051683096, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 429, train_loss = 0.9981179805472493, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 430, train_loss = 0.9981395077556954, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 431, train_loss = 0.9970665204600664, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 432, train_loss = 0.9989505407065735, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 433, train_loss = 0.9969207579270005, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 434, train_loss = 0.9962770929560065, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 435, train_loss = 0.9987220804468961, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 436, train_loss = 0.9979285191147937, train_acc = 0.9974382859804378\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 437, train_loss = 0.9960732636973262, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 438, train_loss = 0.9952578814700246, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 439, train_loss = 0.9952093030660762, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 440, train_loss = 0.9966729416846647, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 441, train_loss = 0.9942366229370236, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 442, train_loss = 0.9938716500400915, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 443, train_loss = 0.994577454708633, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 444, train_loss = 0.9954099329188466, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 445, train_loss = 0.9928540124892606, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 446, train_loss = 0.9930202666073455, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 447, train_loss = 0.9940952674151049, train_acc = 0.9975547275267815\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 448, train_loss = 0.992167702257575, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 449, train_loss = 0.988930650986731, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 450, train_loss = 0.9905214908794733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 451, train_loss = 0.9881382947787642, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 452, train_loss = 0.9879956695513101, train_acc = 0.9975547275267815\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 453, train_loss = 0.9877404710277915, train_acc = 0.9975547275267815\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 454, train_loss = 0.9876394902021275, train_acc = 0.9975547275267815\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 455, train_loss = 0.9870213279500604, train_acc = 0.9975547275267815\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 456, train_loss = 0.9891580613330007, train_acc = 0.9975547275267815\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 457, train_loss = 0.9863249662666931, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 458, train_loss = 0.9868686934933066, train_acc = 0.9975547275267815\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 459, train_loss = 0.988098929017724, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 460, train_loss = 0.9857655232772231, train_acc = 0.9975547275267815\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 461, train_loss = 0.987051791511476, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 462, train_loss = 0.9856456949710264, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 463, train_loss = 0.9846620370299206, train_acc = 0.9975547275267815\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 464, train_loss = 0.9864488476887345, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 465, train_loss = 0.9844196851699962, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 466, train_loss = 0.9839617904872284, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 467, train_loss = 0.9841965483501554, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 468, train_loss = 0.9837539391592145, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 469, train_loss = 0.9849463623613701, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 470, train_loss = 0.9829316874966025, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 471, train_loss = 0.9823074995874777, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 472, train_loss = 0.9841322684660554, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 473, train_loss = 0.9820316853001714, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 474, train_loss = 0.981962445192039, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 475, train_loss = 0.9820157932117581, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 476, train_loss = 0.9812182650566683, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 477, train_loss = 0.98156703915447, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 478, train_loss = 0.980850643478334, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 479, train_loss = 0.984240608602704, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 480, train_loss = 0.9801223094909801, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 481, train_loss = 0.9802806572988629, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 482, train_loss = 0.9800062306821928, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 483, train_loss = 0.9814265205859556, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 484, train_loss = 0.9789866615683422, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 485, train_loss = 0.9786335400640382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 486, train_loss = 0.9787652241066098, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 487, train_loss = 0.9800015045329928, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 488, train_loss = 0.9775925263165846, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 489, train_loss = 0.9778150273486972, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 490, train_loss = 0.9771235886364593, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 491, train_loss = 0.9782310758382664, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 492, train_loss = 0.9787069282829179, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 493, train_loss = 0.9795785412788973, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 494, train_loss = 0.9767578445971594, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 495, train_loss = 0.9763561502695666, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 496, train_loss = 0.9774401414542808, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 497, train_loss = 0.9754461301490664, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 498, train_loss = 0.9750390254557715, train_acc = 0.9975547275267815\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 499, train_loss = 0.9753852676003589, train_acc = 0.9975547275267815\n",
      "test Acc 0.9706703910614525:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████████████████████████████████▉                                           | 13/30 [2:03:36<2:51:41, 605.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "14th- epoch: 0, train_loss = 405.909770026803, train_acc = 0.8075221238938053\n",
      "test Acc 0.88268156424581:\n",
      "14th- epoch: 1, train_loss = 102.93159554650629, train_acc = 0.9196553330228225\n",
      "test Acc 0.9264432029795159:\n",
      "14th- epoch: 2, train_loss = 62.83104819494474, train_acc = 0.9409641360037261\n",
      "test Acc 0.9324953445065177:\n",
      "14th- epoch: 3, train_loss = 43.56703141453909, train_acc = 0.9548206800186306\n",
      "test Acc 0.9352886405959032:\n",
      "14th- epoch: 4, train_loss = 31.901410825550556, train_acc = 0.9647182114578482\n",
      "test Acc 0.9385474860335196:\n",
      "14th- epoch: 5, train_loss = 24.561799326329492, train_acc = 0.9708896134140661\n",
      "test Acc 0.9413407821229051:\n",
      "14th- epoch: 6, train_loss = 19.21496799774468, train_acc = 0.9747321844434094\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 7, train_loss = 15.097474080044776, train_acc = 0.9781089892873778\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 8, train_loss = 12.016743957530707, train_acc = 0.9809035863996274\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 9, train_loss = 9.711039223242551, train_acc = 0.9843968327899395\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 10, train_loss = 8.04400674207136, train_acc = 0.9873078714485328\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 11, train_loss = 6.822156679816544, train_acc = 0.98940381928272\n",
      "test Acc 0.9511173184357542:\n",
      "14th- epoch: 12, train_loss = 5.918079948751256, train_acc = 0.99033535165347\n",
      "test Acc 0.9511173184357542:\n",
      "14th- epoch: 13, train_loss = 5.173142691841349, train_acc = 0.9914997671169073\n",
      "test Acc 0.952048417132216:\n",
      "14th- epoch: 14, train_loss = 4.613169428426772, train_acc = 0.9926641825803446\n",
      "test Acc 0.9511173184357542:\n",
      "14th- epoch: 15, train_loss = 4.20289531792514, train_acc = 0.9930135072193759\n",
      "test Acc 0.952513966480447:\n",
      "14th- epoch: 16, train_loss = 3.8910297947004437, train_acc = 0.993828598043782\n",
      "test Acc 0.952513966480447:\n",
      "14th- epoch: 17, train_loss = 3.628907448379323, train_acc = 0.9939450395901258\n",
      "test Acc 0.952048417132216:\n",
      "14th- epoch: 18, train_loss = 3.3761942010605708, train_acc = 0.9940614811364695\n",
      "test Acc 0.9515828677839852:\n",
      "14th- epoch: 19, train_loss = 3.1730773308081552, train_acc = 0.9941779226828132\n",
      "test Acc 0.9511173184357542:\n",
      "14th- epoch: 20, train_loss = 2.9951379778794944, train_acc = 0.9944108057755007\n",
      "test Acc 0.9515828677839852:\n",
      "14th- epoch: 21, train_loss = 2.827423198148608, train_acc = 0.9947601304145319\n",
      "test Acc 0.9515828677839852:\n",
      "14th- epoch: 22, train_loss = 2.698400914669037, train_acc = 0.9951094550535631\n",
      "test Acc 0.9515828677839852:\n",
      "14th- epoch: 23, train_loss = 2.592580422759056, train_acc = 0.9952258965999069\n",
      "test Acc 0.9515828677839852:\n",
      "14th- epoch: 24, train_loss = 2.500485850730911, train_acc = 0.9954587796925943\n",
      "test Acc 0.9515828677839852:\n",
      "14th- epoch: 25, train_loss = 2.4142462180461735, train_acc = 0.995575221238938\n",
      "test Acc 0.9529795158286778:\n",
      "14th- epoch: 26, train_loss = 2.334950876655057, train_acc = 0.9956916627852818\n",
      "test Acc 0.9534450651769087:\n",
      "14th- epoch: 27, train_loss = 2.2633736518910155, train_acc = 0.9958081043316255\n",
      "test Acc 0.952513966480447:\n",
      "14th- epoch: 28, train_loss = 2.193827301147394, train_acc = 0.995575221238938\n",
      "test Acc 0.9529795158286778:\n",
      "14th- epoch: 29, train_loss = 2.1291732791578397, train_acc = 0.9956916627852818\n",
      "test Acc 0.9529795158286778:\n",
      "14th- epoch: 30, train_loss = 2.06961415335536, train_acc = 0.9956916627852818\n",
      "test Acc 0.9529795158286778:\n",
      "14th- epoch: 31, train_loss = 2.0058559221215546, train_acc = 0.996040987424313\n",
      "test Acc 0.952513966480447:\n",
      "14th- epoch: 32, train_loss = 1.9607053456129506, train_acc = 0.9959245458779693\n",
      "test Acc 0.9539106145251397:\n",
      "14th- epoch: 33, train_loss = 1.9023782546864823, train_acc = 0.996040987424313\n",
      "test Acc 0.9529795158286778:\n",
      "14th- epoch: 34, train_loss = 1.8576612053439021, train_acc = 0.996040987424313\n",
      "test Acc 0.9534450651769087:\n",
      "14th- epoch: 35, train_loss = 1.8118736635660753, train_acc = 0.9963903120633442\n",
      "test Acc 0.9539106145251397:\n",
      "14th- epoch: 36, train_loss = 1.7695705640362576, train_acc = 0.996040987424313\n",
      "test Acc 0.9539106145251397:\n",
      "14th- epoch: 37, train_loss = 1.731538604479283, train_acc = 0.9962738705170004\n",
      "test Acc 0.9539106145251397:\n",
      "14th- epoch: 38, train_loss = 1.6944723040796816, train_acc = 0.9961574289706567\n",
      "test Acc 0.9534450651769087:\n",
      "14th- epoch: 39, train_loss = 1.6632755869068205, train_acc = 0.9962738705170004\n",
      "test Acc 0.9539106145251397:\n",
      "14th- epoch: 40, train_loss = 1.630948263220489, train_acc = 0.9962738705170004\n",
      "test Acc 0.9534450651769087:\n",
      "14th- epoch: 41, train_loss = 1.603059770888649, train_acc = 0.996506753609688\n",
      "test Acc 0.9529795158286778:\n",
      "14th- epoch: 42, train_loss = 1.5772759187966585, train_acc = 0.996506753609688\n",
      "test Acc 0.9534450651769087:\n",
      "14th- epoch: 43, train_loss = 1.557480965158902, train_acc = 0.996506753609688\n",
      "test Acc 0.9539106145251397:\n",
      "14th- epoch: 44, train_loss = 1.5353599591180682, train_acc = 0.9966231951560317\n",
      "test Acc 0.9539106145251397:\n",
      "14th- epoch: 45, train_loss = 1.5142992318724282, train_acc = 0.9968560782487191\n",
      "test Acc 0.9539106145251397:\n",
      "14th- epoch: 46, train_loss = 1.4998218421824276, train_acc = 0.9967396367023754\n",
      "test Acc 0.9539106145251397:\n",
      "14th- epoch: 47, train_loss = 1.4824846044066362, train_acc = 0.9968560782487191\n",
      "test Acc 0.9539106145251397:\n",
      "14th- epoch: 48, train_loss = 1.4729407614213414, train_acc = 0.9966231951560317\n",
      "test Acc 0.9548417132216015:\n",
      "14th- epoch: 49, train_loss = 1.4594315940630622, train_acc = 0.9967396367023754\n",
      "test Acc 0.9543761638733705:\n",
      "14th- epoch: 50, train_loss = 1.4438300018082373, train_acc = 0.9968560782487191\n",
      "test Acc 0.9548417132216015:\n",
      "14th- epoch: 51, train_loss = 1.4369934010319412, train_acc = 0.9969725197950629\n",
      "test Acc 0.9548417132216015:\n",
      "14th- epoch: 52, train_loss = 1.422372404311318, train_acc = 0.9969725197950629\n",
      "test Acc 0.9548417132216015:\n",
      "14th- epoch: 53, train_loss = 1.4142854778910987, train_acc = 0.9969725197950629\n",
      "test Acc 0.9553072625698324:\n",
      "14th- epoch: 54, train_loss = 1.404345057264436, train_acc = 0.9969725197950629\n",
      "test Acc 0.9553072625698324:\n",
      "14th- epoch: 55, train_loss = 1.3963838803465478, train_acc = 0.9972054028877504\n",
      "test Acc 0.9553072625698324:\n",
      "14th- epoch: 56, train_loss = 1.3851914497208782, train_acc = 0.9972054028877504\n",
      "test Acc 0.9557728119180633:\n",
      "14th- epoch: 57, train_loss = 1.3788372399285436, train_acc = 0.9972054028877504\n",
      "test Acc 0.9553072625698324:\n",
      "14th- epoch: 58, train_loss = 1.3717600355739705, train_acc = 0.9972054028877504\n",
      "test Acc 0.9562383612662942:\n",
      "14th- epoch: 59, train_loss = 1.3632226563058794, train_acc = 0.9972054028877504\n",
      "test Acc 0.9557728119180633:\n",
      "14th- epoch: 60, train_loss = 1.3615008273045532, train_acc = 0.9973218444340941\n",
      "test Acc 0.9567039106145251:\n",
      "14th- epoch: 61, train_loss = 1.3503958556684665, train_acc = 0.9973218444340941\n",
      "test Acc 0.9567039106145251:\n",
      "14th- epoch: 62, train_loss = 1.34482369228499, train_acc = 0.9973218444340941\n",
      "test Acc 0.9567039106145251:\n",
      "14th- epoch: 63, train_loss = 1.3412518510594964, train_acc = 0.9973218444340941\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 64, train_loss = 1.330483774188906, train_acc = 0.9973218444340941\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 65, train_loss = 1.3268617995199747, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 66, train_loss = 1.3183263647952117, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 67, train_loss = 1.3164869956090115, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 68, train_loss = 1.3084718689206056, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 69, train_loss = 1.307569235243136, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 70, train_loss = 1.3039136667794082, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 71, train_loss = 1.2976777167059481, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 72, train_loss = 1.2948895782756153, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 73, train_loss = 1.2890751044324134, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 74, train_loss = 1.2848076661175583, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 75, train_loss = 1.2796817040070891, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 76, train_loss = 1.27654921184876, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 77, train_loss = 1.2690440014994238, train_acc = 0.9973218444340941\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 78, train_loss = 1.2684767347818706, train_acc = 0.9973218444340941\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 79, train_loss = 1.265096153219929, train_acc = 0.9973218444340941\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 80, train_loss = 1.2600388605205808, train_acc = 0.9973218444340941\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 81, train_loss = 1.2594268334505614, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 82, train_loss = 1.2546681597304996, train_acc = 0.9973218444340941\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 83, train_loss = 1.249478845653357, train_acc = 0.9973218444340941\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 84, train_loss = 1.2491911164252087, train_acc = 0.9973218444340941\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 85, train_loss = 1.2453707539534662, train_acc = 0.9973218444340941\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 86, train_loss = 1.2396613922028337, train_acc = 0.9973218444340941\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 87, train_loss = 1.2389363880211022, train_acc = 0.9973218444340941\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 88, train_loss = 1.236144037131453, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 89, train_loss = 1.2336506570281927, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 90, train_loss = 1.229890551941935, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 91, train_loss = 1.2276767143630423, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 92, train_loss = 1.2247483204409946, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 93, train_loss = 1.2223664403427392, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 94, train_loss = 1.2190554260159843, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 95, train_loss = 1.2167305999901146, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 96, train_loss = 1.2149249353387859, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 97, train_loss = 1.2131036900973413, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 98, train_loss = 1.2091902231040876, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 99, train_loss = 1.2079730388650205, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 100, train_loss = 1.2070996696129441, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 101, train_loss = 1.201888096780749, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 102, train_loss = 1.1995342328445986, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 103, train_loss = 1.2015458340756595, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 104, train_loss = 1.1970751366170589, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 105, train_loss = 1.19374679797329, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 106, train_loss = 1.193053556024097, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 107, train_loss = 1.1900610124284867, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 108, train_loss = 1.1892416420159861, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 109, train_loss = 1.1842241211270448, train_acc = 0.9973218444340941\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 110, train_loss = 1.1844677978660911, train_acc = 0.9973218444340941\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 111, train_loss = 1.1831020057434216, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 112, train_loss = 1.1795715929183643, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 113, train_loss = 1.1776481185806915, train_acc = 0.9973218444340941\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 114, train_loss = 1.175821471348172, train_acc = 0.9973218444340941\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 115, train_loss = 1.1765263418492395, train_acc = 0.9973218444340941\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 116, train_loss = 1.1750078333716374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 117, train_loss = 1.1710945838422049, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 118, train_loss = 1.1694152601994574, train_acc = 0.9974382859804378\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 119, train_loss = 1.170433971186867, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 120, train_loss = 1.165627445327118, train_acc = 0.9973218444340941\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 121, train_loss = 1.1665024680551142, train_acc = 0.9974382859804378\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 122, train_loss = 1.1620337917411234, train_acc = 0.9974382859804378\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 123, train_loss = 1.1636347849853337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 124, train_loss = 1.159927733868244, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 125, train_loss = 1.1600044735969277, train_acc = 0.9975547275267815\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 126, train_loss = 1.1561406857799739, train_acc = 0.9974382859804378\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 127, train_loss = 1.1542942898813635, train_acc = 0.9975547275267815\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 128, train_loss = 1.1529637157655088, train_acc = 0.9975547275267815\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 129, train_loss = 1.1513651344721438, train_acc = 0.9975547275267815\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 130, train_loss = 1.1504745205602376, train_acc = 0.9975547275267815\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 131, train_loss = 1.1474871037062258, train_acc = 0.9975547275267815\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 132, train_loss = 1.148527946395916, train_acc = 0.9975547275267815\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 133, train_loss = 1.1453100069629727, train_acc = 0.9975547275267815\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 134, train_loss = 1.145293177498388, train_acc = 0.9975547275267815\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 135, train_loss = 1.1426560508552939, train_acc = 0.9975547275267815\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 136, train_loss = 1.1404838867747458, train_acc = 0.9975547275267815\n",
      "test Acc 0.9590316573556797:\n",
      "14th- epoch: 137, train_loss = 1.1420813166332664, train_acc = 0.9975547275267815\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 138, train_loss = 1.1378502508887323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 139, train_loss = 1.1351059152075322, train_acc = 0.9974382859804378\n",
      "test Acc 0.9590316573556797:\n",
      "14th- epoch: 140, train_loss = 1.137024326249957, train_acc = 0.9974382859804378\n",
      "test Acc 0.9590316573556797:\n",
      "14th- epoch: 141, train_loss = 1.134144519615802, train_acc = 0.9974382859804378\n",
      "test Acc 0.9590316573556797:\n",
      "14th- epoch: 142, train_loss = 1.135625094801071, train_acc = 0.9975547275267815\n",
      "test Acc 0.9590316573556797:\n",
      "14th- epoch: 143, train_loss = 1.1313813705928624, train_acc = 0.9975547275267815\n",
      "test Acc 0.9590316573556797:\n",
      "14th- epoch: 144, train_loss = 1.1317839540279238, train_acc = 0.9975547275267815\n",
      "test Acc 0.9590316573556797:\n",
      "14th- epoch: 145, train_loss = 1.129444194099051, train_acc = 0.9974382859804378\n",
      "test Acc 0.9590316573556797:\n",
      "14th- epoch: 146, train_loss = 1.1298209428787231, train_acc = 0.9975547275267815\n",
      "test Acc 0.9590316573556797:\n",
      "14th- epoch: 147, train_loss = 1.1259420050046174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9590316573556797:\n",
      "14th- epoch: 148, train_loss = 1.129063539672643, train_acc = 0.9975547275267815\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 149, train_loss = 1.1242344394995598, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 150, train_loss = 1.1236294649279444, train_acc = 0.9975547275267815\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 151, train_loss = 1.1234359120280715, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 152, train_loss = 1.1203766064718366, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 153, train_loss = 1.1187437600456178, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 154, train_loss = 1.1191858632228104, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 155, train_loss = 1.1168108327983646, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 156, train_loss = 1.1166525253356667, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 157, train_loss = 1.1150902320368914, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 158, train_loss = 1.114420676138252, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 159, train_loss = 1.1141397029423388, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 160, train_loss = 1.1126456901693018, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 161, train_loss = 1.1136352877801983, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 162, train_loss = 1.1091436054557562, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 163, train_loss = 1.1074492707848549, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 164, train_loss = 1.107993280820665, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 165, train_loss = 1.1058323346078396, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 166, train_loss = 1.1055571806355147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 167, train_loss = 1.104907394386828, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 168, train_loss = 1.1027882862836123, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 169, train_loss = 1.1001665480434895, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 170, train_loss = 1.0994389889092417, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 171, train_loss = 1.0997524377889931, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 172, train_loss = 1.0970892792829545, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 173, train_loss = 1.0967654922715155, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 174, train_loss = 1.0973769834527047, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 175, train_loss = 1.0941398550494341, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 176, train_loss = 1.0938433936535148, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 177, train_loss = 1.0935375168919563, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 178, train_loss = 1.0917113862669794, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 179, train_loss = 1.0933806180692045, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 180, train_loss = 1.0901883007027209, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 181, train_loss = 1.0890822506771656, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 182, train_loss = 1.0881750311964424, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 183, train_loss = 1.0879218081681756, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 184, train_loss = 1.0862846757954685, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 185, train_loss = 1.0840238000528188, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 186, train_loss = 1.085310033056885, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 187, train_loss = 1.0818895728589268, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 188, train_loss = 1.0834115470497636, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 189, train_loss = 1.0818335018120706, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 190, train_loss = 1.080310485951486, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 191, train_loss = 1.0812424176110653, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 192, train_loss = 1.0817095233796863, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 193, train_loss = 1.0787989899981767, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 194, train_loss = 1.0774876511859475, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 195, train_loss = 1.076465184960398, train_acc = 0.9974382859804378\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 196, train_loss = 1.077829063331592, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 197, train_loss = 1.0739256430679234, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 198, train_loss = 1.0743057918734848, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 199, train_loss = 1.0720511251856806, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 200, train_loss = 1.0713063891307684, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 201, train_loss = 1.0706017335614888, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 202, train_loss = 1.071680462846416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 203, train_loss = 1.0698757412174018, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 204, train_loss = 1.068565816312912, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 205, train_loss = 1.070378423362854, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 206, train_loss = 1.0669938300270587, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 207, train_loss = 1.065679856503266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 208, train_loss = 1.0648454820475308, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 209, train_loss = 1.065559671333176, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 210, train_loss = 1.0630334937741281, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 211, train_loss = 1.062348521387321, train_acc = 0.9974382859804378\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 212, train_loss = 1.0635515369212953, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 213, train_loss = 1.0610923545900732, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 214, train_loss = 1.06086787271488, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 215, train_loss = 1.0606961275916547, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 216, train_loss = 1.0588456744590076, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 217, train_loss = 1.0599940953106852, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 218, train_loss = 1.0568347350199474, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 219, train_loss = 1.0564511094707996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 220, train_loss = 1.0559459276264533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 221, train_loss = 1.0546478027681587, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 222, train_loss = 1.0576710960594937, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 223, train_loss = 1.0553248246797011, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 224, train_loss = 1.0529967637630762, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 225, train_loss = 1.0521461340467795, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 226, train_loss = 1.0513262929889606, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 227, train_loss = 1.0512363765956252, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 228, train_loss = 1.0514601862887503, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 229, train_loss = 1.048459786688909, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 230, train_loss = 1.0490410570055246, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 231, train_loss = 1.0476952725657611, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 232, train_loss = 1.0477884954307228, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 233, train_loss = 1.047698624432087, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 234, train_loss = 1.0477918983306154, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 235, train_loss = 1.0442725155735388, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 236, train_loss = 1.044489353778772, train_acc = 0.9976711690731253\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 237, train_loss = 1.0437902767807827, train_acc = 0.9976711690731253\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 238, train_loss = 1.0428596333731548, train_acc = 0.9976711690731253\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 239, train_loss = 1.0417725737206638, train_acc = 0.9976711690731253\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 240, train_loss = 1.041683080373332, train_acc = 0.9976711690731253\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 241, train_loss = 1.0414178106366307, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 242, train_loss = 1.0401244214372127, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 243, train_loss = 1.0398578207023093, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 244, train_loss = 1.039430763128621, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 245, train_loss = 1.0378055790570215, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 246, train_loss = 1.03669103016, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 247, train_loss = 1.0365302226055064, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 248, train_loss = 1.0363962076153257, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 249, train_loss = 1.0381036806866177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 250, train_loss = 1.0356271113851108, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 251, train_loss = 1.0342554051676416, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 252, train_loss = 1.0331009488145355, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 253, train_loss = 1.0330213682391332, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 254, train_loss = 1.032516025537916, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 255, train_loss = 1.0335233929508831, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 256, train_loss = 1.0319926381271216, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 257, train_loss = 1.0306348563462961, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 258, train_loss = 1.03005117529392, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 259, train_loss = 1.029353661229834, train_acc = 0.9977876106194691\n",
      "test Acc 0.9604283054003724:\n",
      "14th- epoch: 260, train_loss = 1.0281649274984375, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 261, train_loss = 1.0282915831849095, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 262, train_loss = 1.027374678531487, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 263, train_loss = 1.0281166254135314, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 264, train_loss = 1.026693555075326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 265, train_loss = 1.0263423470169073, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 266, train_loss = 1.026762006469653, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 267, train_loss = 1.0268224286483019, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 268, train_loss = 1.0243317208296503, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 269, train_loss = 1.0236162220826373, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 270, train_loss = 1.0237037412953214, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 271, train_loss = 1.0237792751649977, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 272, train_loss = 1.0234294030233286, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 273, train_loss = 1.0209263392607681, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 274, train_loss = 1.0201417607968324, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 275, train_loss = 1.0228078496511444, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 276, train_loss = 1.0203678518519155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 277, train_loss = 1.0192081151835737, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 278, train_loss = 1.0183154409387498, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 279, train_loss = 1.0190459485384054, train_acc = 0.9977876106194691\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 280, train_loss = 1.0186193179906695, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 281, train_loss = 1.0179610153209069, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 282, train_loss = 1.016641730289848, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 283, train_loss = 1.0157589365480817, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 284, train_loss = 1.0149879548480385, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 285, train_loss = 1.0145037904148921, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 286, train_loss = 1.013671896791493, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 287, train_loss = 1.014363658883667, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 288, train_loss = 1.014891539911332, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 289, train_loss = 1.0145745792324306, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 290, train_loss = 1.0119434622247354, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 291, train_loss = 1.0116269515929162, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 292, train_loss = 1.010945548885502, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 293, train_loss = 1.0103339695706381, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 294, train_loss = 1.0128679303452373, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 295, train_loss = 1.0102221554843709, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 296, train_loss = 1.0091436760267243, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 297, train_loss = 1.0078384981825366, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 298, train_loss = 1.0116486732513295, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 299, train_loss = 1.0072708864099695, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 300, train_loss = 1.0099319351502345, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 301, train_loss = 1.0060858650831506, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 302, train_loss = 1.0082246665042476, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 303, train_loss = 1.0054405931950896, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 304, train_loss = 1.0050904320451082, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 305, train_loss = 1.0076788711594418, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 306, train_loss = 1.0051535373786464, train_acc = 0.9977876106194691\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 307, train_loss = 1.0035665446557687, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 308, train_loss = 1.0029715099735768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 309, train_loss = 1.0051774261519313, train_acc = 0.9980204937121565\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 310, train_loss = 1.0019548922209651, train_acc = 0.9979040521658128\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 311, train_loss = 1.0025488651226624, train_acc = 0.9979040521658128\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 312, train_loss = 1.0015572274569422, train_acc = 0.9979040521658128\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 313, train_loss = 1.0040618454440846, train_acc = 0.9979040521658128\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 314, train_loss = 1.0006197671536938, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 315, train_loss = 1.0011472119949758, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 316, train_loss = 0.9996531512588263, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 317, train_loss = 1.000063481660618, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 318, train_loss = 0.9988226139321341, train_acc = 0.9979040521658128\n",
      "test Acc 0.9613594040968343:\n",
      "14th- epoch: 319, train_loss = 1.0030968659557402, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 320, train_loss = 0.9981491736471071, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 321, train_loss = 0.997167114946933, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 322, train_loss = 0.9963089691809728, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 323, train_loss = 0.9967997169587761, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 324, train_loss = 0.9960186714306474, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 325, train_loss = 0.9956033138223574, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 326, train_loss = 0.9961484494488104, train_acc = 0.9977876106194691\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 327, train_loss = 0.9950950768179609, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 328, train_loss = 0.9943561479449272, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 329, train_loss = 0.9953204418998212, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 330, train_loss = 0.9934240720467642, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 331, train_loss = 0.9928647834676667, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 332, train_loss = 0.993446125103219, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 333, train_loss = 0.9934115943397046, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 334, train_loss = 0.9919130364432931, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 335, train_loss = 0.9910411417586147, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 336, train_loss = 0.9916032252367586, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 337, train_loss = 0.9929122152170748, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 338, train_loss = 0.9906629290562705, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 339, train_loss = 0.9894751791507588, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 340, train_loss = 0.9890874436459853, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 341, train_loss = 0.9887405300614773, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 342, train_loss = 0.9886721187867806, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 343, train_loss = 0.9887792585286661, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 344, train_loss = 0.9884714930085465, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 345, train_loss = 0.9874747798676253, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 346, train_loss = 0.9865160506451502, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 347, train_loss = 0.9885994871947332, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 348, train_loss = 0.9870119473198429, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 349, train_loss = 0.9896899595260038, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 350, train_loss = 0.986750547272095, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 351, train_loss = 0.9871189986588433, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 352, train_loss = 0.9868982112966478, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 353, train_loss = 0.9865246666959138, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 354, train_loss = 0.9874643347793608, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 355, train_loss = 0.9856112088673399, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 356, train_loss = 0.9852933447473333, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 357, train_loss = 0.9852012147093774, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 358, train_loss = 0.9848368323873729, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 359, train_loss = 0.985247432217875, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 360, train_loss = 0.9841873001641943, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 361, train_loss = 0.9832350159194903, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 362, train_loss = 0.9832043404458091, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 363, train_loss = 0.9828623597277328, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 364, train_loss = 0.9825431462741108, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 365, train_loss = 0.9817395597929135, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 366, train_loss = 0.9832755586467101, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 367, train_loss = 0.9815354143138393, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 368, train_loss = 0.9803591164527461, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 369, train_loss = 0.9810357362730429, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 370, train_loss = 0.980712066484557, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 371, train_loss = 0.9805486056720838, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 372, train_loss = 0.9798491918118089, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 373, train_loss = 0.9784176022876636, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 374, train_loss = 0.9826752877925173, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 375, train_loss = 0.9788484985692776, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 376, train_loss = 0.978694862453267, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 377, train_loss = 0.9778651279411861, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 378, train_loss = 0.9785256228642538, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 379, train_loss = 0.9766942689311691, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 380, train_loss = 0.9792612309902324, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 381, train_loss = 0.9763975184396259, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 382, train_loss = 0.9757232031188323, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 383, train_loss = 0.978329071913322, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 384, train_loss = 0.9755288704182021, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 385, train_loss = 0.975674550551048, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 386, train_loss = 0.9743659518644563, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 387, train_loss = 0.9739138155928231, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 388, train_loss = 0.9763340448844247, train_acc = 0.9979040521658128\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 389, train_loss = 0.9740128248231485, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 390, train_loss = 0.9732921856557368, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 391, train_loss = 0.9734851023895317, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 392, train_loss = 0.9734567346386029, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 393, train_loss = 0.9726177235934301, train_acc = 0.9979040521658128\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 394, train_loss = 0.9721238092533895, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 395, train_loss = 0.972548875164648, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 396, train_loss = 0.9730190688278526, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 397, train_loss = 0.9706176845065784, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 398, train_loss = 0.9701395363081247, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 399, train_loss = 0.9708856179131544, train_acc = 0.9980204937121565\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 400, train_loss = 0.9703443875769153, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 401, train_loss = 0.9701146079751197, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 402, train_loss = 0.969820520200301, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 403, train_loss = 0.9696175097487867, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 404, train_loss = 0.9688707281384268, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 405, train_loss = 0.9688601771558751, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 406, train_loss = 0.9683024925761856, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 407, train_loss = 0.9685850652676891, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 408, train_loss = 0.9680611846488318, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 409, train_loss = 0.9675055296174833, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 410, train_loss = 0.9663707182844519, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 411, train_loss = 0.9683225169937941, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 412, train_loss = 0.9665637461002916, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 413, train_loss = 0.9666550082256435, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 414, train_loss = 0.9666951069084462, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 415, train_loss = 0.9650792152096983, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 416, train_loss = 0.9655142888659611, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 417, train_loss = 0.9651317682219087, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 418, train_loss = 0.9649602966019302, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 419, train_loss = 0.9681833580834791, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 420, train_loss = 0.964343784180528, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 421, train_loss = 0.9628031772663235, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 422, train_loss = 0.9657656010240316, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 423, train_loss = 0.9636460972178611, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 424, train_loss = 0.9632429936682456, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 425, train_loss = 0.9620946334325708, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 426, train_loss = 0.9648503883508965, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 427, train_loss = 0.9622090657940134, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 428, train_loss = 0.9624536667615757, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 429, train_loss = 0.9609657994369627, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 430, train_loss = 0.9654059236054309, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 431, train_loss = 0.9607478696634644, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 432, train_loss = 0.960286104316765, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 433, train_loss = 0.9635361466789618, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 434, train_loss = 0.9604686769307591, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 435, train_loss = 0.9594034949332126, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 436, train_loss = 0.9620379180996679, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 437, train_loss = 0.9586369371754699, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 438, train_loss = 0.9616056924933218, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 439, train_loss = 0.9578961217193864, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 440, train_loss = 0.9622028313679039, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 441, train_loss = 0.958304413848964, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 442, train_loss = 0.9579036199502298, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 443, train_loss = 0.9605798936681822, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 444, train_loss = 0.9566264622626477, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 445, train_loss = 0.9592910641622439, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 446, train_loss = 0.9572341825332842, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 447, train_loss = 0.9557660526697873, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 448, train_loss = 0.958798998461134, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 449, train_loss = 0.9564374618930742, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 450, train_loss = 0.955454758797714, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 451, train_loss = 0.9576609141658992, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 452, train_loss = 0.9544989237692789, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 453, train_loss = 0.958790391759976, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 454, train_loss = 0.9554715661215596, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 455, train_loss = 0.9541256737429649, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 456, train_loss = 0.9559257865948894, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 457, train_loss = 0.9530836242847727, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 458, train_loss = 0.9558500481471128, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 459, train_loss = 0.9524035054491833, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 460, train_loss = 0.9553993246918253, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 461, train_loss = 0.9531283261021599, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 462, train_loss = 0.9522668851641356, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 463, train_loss = 0.9545873839342676, train_acc = 0.9980204937121565\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 464, train_loss = 0.9511275390032097, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 465, train_loss = 0.9533953429599933, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 466, train_loss = 0.9512896966589324, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 467, train_loss = 0.9526587218679197, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 468, train_loss = 0.9508936539459683, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 469, train_loss = 0.9495158302197524, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 470, train_loss = 0.9523710762150586, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 471, train_loss = 0.9497884083939425, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 472, train_loss = 0.9488019022792287, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 473, train_loss = 0.9520550483903207, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 474, train_loss = 0.9489912686003663, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 475, train_loss = 0.9529450686350174, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 476, train_loss = 0.9485822488022677, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 477, train_loss = 0.9512801358941942, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 478, train_loss = 0.9479622882390686, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 479, train_loss = 0.9502603856381029, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 480, train_loss = 0.9469587956955365, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 481, train_loss = 0.9499187810179137, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 482, train_loss = 0.9472546511497058, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 483, train_loss = 0.9464945045765489, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 484, train_loss = 0.949314350651548, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 485, train_loss = 0.9461487899934582, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 486, train_loss = 0.9488858583317779, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 487, train_loss = 0.9459958101324446, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 488, train_loss = 0.9456190583696298, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 489, train_loss = 0.9481747468635149, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 490, train_loss = 0.945849383406312, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 491, train_loss = 0.9473216206934012, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 492, train_loss = 0.944660469347582, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 493, train_loss = 0.9446404528171115, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 494, train_loss = 0.9475369426254474, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 495, train_loss = 0.9437861158512533, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 496, train_loss = 0.94636079312113, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 497, train_loss = 0.943672949604661, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 498, train_loss = 0.9458377067167021, train_acc = 0.9980204937121565\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 499, train_loss = 0.9424824685956992, train_acc = 0.9981369352585002\n",
      "test Acc 0.9632216014897579:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|███████████████████████████████████▍                                        | 14/30 [2:14:01<2:43:08, 611.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "15th- epoch: 0, train_loss = 368.5486440761015, train_acc = 0.799720540288775\n",
      "test Acc 0.9008379888268156:\n",
      "15th- epoch: 1, train_loss = 88.13846246385947, train_acc = 0.9174429436422916\n",
      "test Acc 0.9269087523277467:\n",
      "15th- epoch: 2, train_loss = 52.567421657498926, train_acc = 0.9420121099208197\n",
      "test Acc 0.9376163873370578:\n",
      "15th- epoch: 3, train_loss = 34.66066391393542, train_acc = 0.9565673032137867\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 4, train_loss = 24.678006697446108, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 5, train_loss = 18.70263938512653, train_acc = 0.9742664182580345\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 6, train_loss = 14.644133313558996, train_acc = 0.9788076385654402\n",
      "test Acc 0.9506517690875232:\n",
      "15th- epoch: 7, train_loss = 11.647007604129612, train_acc = 0.9820680018630648\n",
      "test Acc 0.952513966480447:\n",
      "15th- epoch: 8, train_loss = 9.44829628849402, train_acc = 0.9846297158826269\n",
      "test Acc 0.9529795158286778:\n",
      "15th- epoch: 9, train_loss = 7.835545452777296, train_acc = 0.9864927806241267\n",
      "test Acc 0.9543761638733705:\n",
      "15th- epoch: 10, train_loss = 6.645856843562797, train_acc = 0.9882394038192828\n",
      "test Acc 0.9562383612662942:\n",
      "15th- epoch: 11, train_loss = 5.653234860626981, train_acc = 0.989869585468095\n",
      "test Acc 0.9562383612662942:\n",
      "15th- epoch: 12, train_loss = 4.910236902534962, train_acc = 0.9913833255705635\n",
      "test Acc 0.957169459962756:\n",
      "15th- epoch: 13, train_loss = 4.350346006453037, train_acc = 0.9925477410340009\n",
      "test Acc 0.957169459962756:\n",
      "15th- epoch: 14, train_loss = 3.9184517078101635, train_acc = 0.9927806241266884\n",
      "test Acc 0.9567039106145251:\n",
      "15th- epoch: 15, train_loss = 3.590398845495656, train_acc = 0.9934792734047508\n",
      "test Acc 0.9562383612662942:\n",
      "15th- epoch: 16, train_loss = 3.3305779373040423, train_acc = 0.993828598043782\n",
      "test Acc 0.9562383612662942:\n",
      "15th- epoch: 17, train_loss = 3.0999836897244677, train_acc = 0.9941779226828132\n",
      "test Acc 0.9562383612662942:\n",
      "15th- epoch: 18, train_loss = 2.918061671196483, train_acc = 0.9945272473218444\n",
      "test Acc 0.9562383612662942:\n",
      "15th- epoch: 19, train_loss = 2.7400428106775507, train_acc = 0.9947601304145319\n",
      "test Acc 0.9567039106145251:\n",
      "15th- epoch: 20, train_loss = 2.5959545510122553, train_acc = 0.9947601304145319\n",
      "test Acc 0.9562383612662942:\n",
      "15th- epoch: 21, train_loss = 2.4630561420926824, train_acc = 0.9947601304145319\n",
      "test Acc 0.9562383612662942:\n",
      "15th- epoch: 22, train_loss = 2.347049228847027, train_acc = 0.9949930135072194\n",
      "test Acc 0.9567039106145251:\n",
      "15th- epoch: 23, train_loss = 2.2444783858954906, train_acc = 0.9951094550535631\n",
      "test Acc 0.9567039106145251:\n",
      "15th- epoch: 24, train_loss = 2.153357816278003, train_acc = 0.9951094550535631\n",
      "test Acc 0.957169459962756:\n",
      "15th- epoch: 25, train_loss = 2.076076572178863, train_acc = 0.9952258965999069\n",
      "test Acc 0.957169459962756:\n",
      "15th- epoch: 26, train_loss = 2.005468465387821, train_acc = 0.995575221238938\n",
      "test Acc 0.9581005586592178:\n",
      "15th- epoch: 27, train_loss = 1.94718925782945, train_acc = 0.9958081043316255\n",
      "test Acc 0.9581005586592178:\n",
      "15th- epoch: 28, train_loss = 1.8949412740767002, train_acc = 0.9959245458779693\n",
      "test Acc 0.9581005586592178:\n",
      "15th- epoch: 29, train_loss = 1.850428475649096, train_acc = 0.9959245458779693\n",
      "test Acc 0.9590316573556797:\n",
      "15th- epoch: 30, train_loss = 1.7980431107571349, train_acc = 0.996040987424313\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 31, train_loss = 1.7622440668055788, train_acc = 0.9962738705170004\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 32, train_loss = 1.7275243240292184, train_acc = 0.9962738705170004\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 33, train_loss = 1.7027020640671253, train_acc = 0.9961574289706567\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 34, train_loss = 1.674220908433199, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 35, train_loss = 1.6548530186410062, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 36, train_loss = 1.6335165786440484, train_acc = 0.996506753609688\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 37, train_loss = 1.6132416029577143, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 38, train_loss = 1.5972872339189053, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 39, train_loss = 1.5855891344253905, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 40, train_loss = 1.5684759840369225, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "15th- epoch: 41, train_loss = 1.5545463512535207, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 42, train_loss = 1.54411680996418, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "15th- epoch: 43, train_loss = 1.5299229348893277, train_acc = 0.9963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 44, train_loss = 1.518726949871052, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "15th- epoch: 45, train_loss = 1.507204910099972, train_acc = 0.9963903120633442\n",
      "test Acc 0.9594972067039106:\n",
      "15th- epoch: 46, train_loss = 1.4988949199323542, train_acc = 0.9963903120633442\n",
      "test Acc 0.9604283054003724:\n",
      "15th- epoch: 47, train_loss = 1.4887144466047175, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "15th- epoch: 48, train_loss = 1.478030917525757, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "15th- epoch: 49, train_loss = 1.4683805194799788, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "15th- epoch: 50, train_loss = 1.4647860440018121, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 51, train_loss = 1.4545026943087578, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 52, train_loss = 1.4472647632064763, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 53, train_loss = 1.4377393896284048, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 54, train_loss = 1.4326424015162047, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 55, train_loss = 1.424055596202379, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 56, train_loss = 1.418140067398781, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 57, train_loss = 1.4130908722581808, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 58, train_loss = 1.4056143177149352, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 59, train_loss = 1.4022675305604935, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "15th- epoch: 60, train_loss = 1.3946934081614017, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "15th- epoch: 61, train_loss = 1.3901141782698687, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "15th- epoch: 62, train_loss = 1.383841622620821, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "15th- epoch: 63, train_loss = 1.3804839389922563, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "15th- epoch: 64, train_loss = 1.3725751998426858, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "15th- epoch: 65, train_loss = 1.3708660031261388, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "15th- epoch: 66, train_loss = 1.3650657249090727, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 67, train_loss = 1.35978870964027, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 68, train_loss = 1.3564119351503905, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 69, train_loss = 1.3505459440348204, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 70, train_loss = 1.3477859658596572, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 71, train_loss = 1.3439247595670167, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 72, train_loss = 1.3400991074740887, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 73, train_loss = 1.3337532753648702, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 74, train_loss = 1.3308505353925284, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 75, train_loss = 1.326130705565447, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 76, train_loss = 1.3226042898895685, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 77, train_loss = 1.3203884685935918, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 78, train_loss = 1.3187884899380151, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 79, train_loss = 1.3135027612152044, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 80, train_loss = 1.3087777756154537, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 81, train_loss = 1.306609039515024, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 82, train_loss = 1.3038264202477876, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 83, train_loss = 1.302156654492137, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 84, train_loss = 1.295624777674675, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 85, train_loss = 1.295223668217659, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 86, train_loss = 1.2914430921227904, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 87, train_loss = 1.2885089007468196, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 88, train_loss = 1.2833512487559346, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 89, train_loss = 1.2840724972338649, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 90, train_loss = 1.2808841168880463, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 91, train_loss = 1.279439331337926, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 92, train_loss = 1.273477969065425, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 93, train_loss = 1.2738508147449465, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 94, train_loss = 1.2706755039544078, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 95, train_loss = 1.2666442121117143, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 96, train_loss = 1.2627385382802458, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 97, train_loss = 1.2653770633041859, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 98, train_loss = 1.2596660666167736, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 99, train_loss = 1.2579953471868066, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 100, train_loss = 1.2550852174608735, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 101, train_loss = 1.2539750884025125, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 102, train_loss = 1.2506454475224018, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 103, train_loss = 1.2471054047346115, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 104, train_loss = 1.245802864432335, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 105, train_loss = 1.2431431499571772, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 106, train_loss = 1.2400205296726199, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 107, train_loss = 1.2363587829022435, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 108, train_loss = 1.2345863419322995, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 109, train_loss = 1.232298790171626, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 110, train_loss = 1.2298406598420115, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 111, train_loss = 1.2274340676813154, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 112, train_loss = 1.2267099668533774, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 113, train_loss = 1.2237004550843267, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 114, train_loss = 1.2211291169078322, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 115, train_loss = 1.2202910532505484, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 116, train_loss = 1.2174684442579746, train_acc = 0.9967396367023754\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 117, train_loss = 1.216785866767168, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 118, train_loss = 1.2127031671552686, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 119, train_loss = 1.2122641007154016, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 120, train_loss = 1.209652968987939, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 121, train_loss = 1.2088160825223895, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 122, train_loss = 1.2053041073231725, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 123, train_loss = 1.205382100000861, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 124, train_loss = 1.2020697866828414, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 125, train_loss = 1.2013778636901407, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 126, train_loss = 1.1996632677764865, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 127, train_loss = 1.1986043689103099, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 128, train_loss = 1.195686873048544, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 129, train_loss = 1.197871123746154, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 130, train_loss = 1.1937931018619565, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 131, train_loss = 1.1927220684738131, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 132, train_loss = 1.1911295441241236, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 133, train_loss = 1.1897090934216976, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 134, train_loss = 1.188443320497754, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 135, train_loss = 1.186283566057682, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 136, train_loss = 1.1858160172851058, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 137, train_loss = 1.1856131839303998, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 138, train_loss = 1.1834560818970203, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 139, train_loss = 1.1808952416031389, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 140, train_loss = 1.1802988375275163, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 141, train_loss = 1.178607617810485, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 142, train_loss = 1.1763366075902013, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 143, train_loss = 1.175836879760027, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 144, train_loss = 1.173851362123969, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 145, train_loss = 1.1730978613049956, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 146, train_loss = 1.1718931533396244, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 147, train_loss = 1.1705152777285548, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 148, train_loss = 1.1682294309139252, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 149, train_loss = 1.1686182084231405, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 150, train_loss = 1.1669098387210397, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 151, train_loss = 1.1655085111706285, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 152, train_loss = 1.1646534117608098, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 153, train_loss = 1.1629972880036803, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 154, train_loss = 1.160878104463336, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 155, train_loss = 1.1601797913463088, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 156, train_loss = 1.1595063979475526, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 157, train_loss = 1.1582598102540942, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 158, train_loss = 1.1586100558488397, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 159, train_loss = 1.1555832922458649, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 160, train_loss = 1.155175040170434, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 161, train_loss = 1.1511952579021454, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 162, train_loss = 1.1522065860481234, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 163, train_loss = 1.1519513130187988, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 164, train_loss = 1.1491113354713889, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 165, train_loss = 1.147294734910247, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 166, train_loss = 1.1481593760399846, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 167, train_loss = 1.1485404397099046, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 168, train_loss = 1.1441089448780986, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 169, train_loss = 1.1450172116310569, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 170, train_loss = 1.1450253364891978, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 171, train_loss = 1.1431605890393257, train_acc = 0.9970889613414066\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 172, train_loss = 1.1413206954748603, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 173, train_loss = 1.1416472792625427, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 174, train_loss = 1.1398743291647406, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 175, train_loss = 1.1387107446789742, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 176, train_loss = 1.1355855291039916, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 177, train_loss = 1.136476069688797, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 178, train_loss = 1.135992386683938, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 179, train_loss = 1.1341966701002093, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 180, train_loss = 1.1345728735177545, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 181, train_loss = 1.133748784661293, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 182, train_loss = 1.1327093752770452, train_acc = 0.9972054028877504\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 183, train_loss = 1.128772800162551, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 184, train_loss = 1.1303689094929723, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 185, train_loss = 1.130641625568387, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 186, train_loss = 1.1292017238884, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 187, train_loss = 1.1259783978312043, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 188, train_loss = 1.1278597501368495, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 189, train_loss = 1.1259663055388955, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 190, train_loss = 1.1253059630544158, train_acc = 0.9972054028877504\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 191, train_loss = 1.1242206059396267, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 192, train_loss = 1.1235425397753716, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 193, train_loss = 1.1237095681281062, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 194, train_loss = 1.1235262751579285, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 195, train_loss = 1.1210752700717421, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 196, train_loss = 1.119695421308279, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 197, train_loss = 1.1192206131963758, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 198, train_loss = 1.1191411738545867, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 199, train_loss = 1.1171300361602334, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 200, train_loss = 1.1150575851352187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 201, train_loss = 1.1151052564382553, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 202, train_loss = 1.1160665204079123, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 203, train_loss = 1.114682791128871, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 204, train_loss = 1.1135056142957183, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 205, train_loss = 1.1113774267287226, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 206, train_loss = 1.1116526536643505, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 207, train_loss = 1.1111633367836475, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 208, train_loss = 1.1097468361258507, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 209, train_loss = 1.1089067334978608, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 210, train_loss = 1.1085191828460665, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 211, train_loss = 1.1058331516833277, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 212, train_loss = 1.1082962888031034, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 213, train_loss = 1.1061549223959446, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 214, train_loss = 1.1044598395674257, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 215, train_loss = 1.1038107424974442, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 216, train_loss = 1.1040045122354059, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 217, train_loss = 1.1020343179552583, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 218, train_loss = 1.102319332465413, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 219, train_loss = 1.1035898116679164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 220, train_loss = 1.099739978715661, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 221, train_loss = 1.1009822500200244, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 222, train_loss = 1.1000249261705903, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 223, train_loss = 1.0971535829157801, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 224, train_loss = 1.0972478985786438, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 225, train_loss = 1.0982660713343648, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 226, train_loss = 1.0969555179326562, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 227, train_loss = 1.096597783267498, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 228, train_loss = 1.0952128184289904, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 229, train_loss = 1.0943383524863748, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 230, train_loss = 1.0951560363173485, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 231, train_loss = 1.093738837793353, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 232, train_loss = 1.0917915366590023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 233, train_loss = 1.0925831235945225, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 234, train_loss = 1.091315597295761, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 235, train_loss = 1.0915663838386536, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 236, train_loss = 1.0933627511112718, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 237, train_loss = 1.090682057038066, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 238, train_loss = 1.090871475636959, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 239, train_loss = 1.0897676460444927, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 240, train_loss = 1.0880178213119507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 241, train_loss = 1.0868658150284318, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 242, train_loss = 1.0872483787388774, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 243, train_loss = 1.0859014714806108, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 244, train_loss = 1.0855846715421649, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 245, train_loss = 1.0841556414961815, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 246, train_loss = 1.084290808692458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 247, train_loss = 1.0858336103410693, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 248, train_loss = 1.0849069468677044, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 249, train_loss = 1.0818835857062368, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 250, train_loss = 1.0815180924982997, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 251, train_loss = 1.0811252507119207, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 252, train_loss = 1.0805242210626602, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 253, train_loss = 1.0813792310655117, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 254, train_loss = 1.0805329879076453, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 255, train_loss = 1.0805217822344275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 256, train_loss = 1.0790849725453882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 257, train_loss = 1.0791676466615172, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 258, train_loss = 1.078577288732049, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 259, train_loss = 1.0777120267302962, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 260, train_loss = 1.0780853889882565, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 261, train_loss = 1.0764933663158445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 262, train_loss = 1.0763155072927475, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 263, train_loss = 1.0753704383969307, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 264, train_loss = 1.0742950662970543, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 265, train_loss = 1.0760103277862072, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 266, train_loss = 1.0732863533048658, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 267, train_loss = 1.072187453508377, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 268, train_loss = 1.0722802057862282, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 269, train_loss = 1.0711026241333457, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 270, train_loss = 1.0713271337299375, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 271, train_loss = 1.0714628025889397, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 272, train_loss = 1.0706648007035255, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 273, train_loss = 1.069604520991561, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 274, train_loss = 1.0683861908764811, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 275, train_loss = 1.068926432475564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 276, train_loss = 1.0681833935232135, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 277, train_loss = 1.0683337549417047, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 278, train_loss = 1.0670171628444223, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 279, train_loss = 1.065063418194768, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 280, train_loss = 1.0659589444549056, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 281, train_loss = 1.0642478267400293, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 282, train_loss = 1.0646511452941922, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 283, train_loss = 1.065823735043523, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 284, train_loss = 1.0635621634573909, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 285, train_loss = 1.0627520295529393, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 286, train_loss = 1.0627694192080526, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 287, train_loss = 1.0624042501003714, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 288, train_loss = 1.061459029719117, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 289, train_loss = 1.0611448970885249, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 290, train_loss = 1.0617192375211744, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 291, train_loss = 1.061137589320424, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 292, train_loss = 1.0595371636300115, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 293, train_loss = 1.0601942700595828, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 294, train_loss = 1.058596733957529, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 295, train_loss = 1.0574910504074069, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 296, train_loss = 1.05725431193423, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 297, train_loss = 1.0565783058555098, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 298, train_loss = 1.056897913411376, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 299, train_loss = 1.057225541517255, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 300, train_loss = 1.0553451391606359, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 301, train_loss = 1.0532979940326186, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 302, train_loss = 1.0545572340488434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 303, train_loss = 1.0551940413861303, train_acc = 0.9974382859804378\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 304, train_loss = 1.0539896575064631, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 305, train_loss = 1.0531409519462613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 306, train_loss = 1.0523442079575034, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 307, train_loss = 1.052177454039338, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 308, train_loss = 1.0510421035141917, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 309, train_loss = 1.0507972401828738, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 310, train_loss = 1.0506370117218466, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 311, train_loss = 1.0488205080182524, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 312, train_loss = 1.05052771542978, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 313, train_loss = 1.0486304933874635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 314, train_loss = 1.0483931762428256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 315, train_loss = 1.0488008533866378, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 316, train_loss = 1.0478695556521416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 317, train_loss = 1.0464884899556637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 318, train_loss = 1.04669991756964, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 319, train_loss = 1.0457660754473181, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 320, train_loss = 1.0453261633665534, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 321, train_loss = 1.0451275917439489, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 322, train_loss = 1.04485272616148, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 323, train_loss = 1.0453500971198082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 324, train_loss = 1.0446417567582102, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 325, train_loss = 1.0435909045190783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 326, train_loss = 1.0428983296005754, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 327, train_loss = 1.042468037456274, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 328, train_loss = 1.0428127025516005, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 329, train_loss = 1.0422332175076008, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 330, train_loss = 1.041620300456998, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 331, train_loss = 1.0409753993153572, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 332, train_loss = 1.0389963972120313, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 333, train_loss = 1.03945613776159, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 334, train_loss = 1.0400013911275892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 335, train_loss = 1.0384627667517634, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 336, train_loss = 1.0388694467692403, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 337, train_loss = 1.0391473968775244, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 338, train_loss = 1.0380004681646824, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 339, train_loss = 1.0378322725446196, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 340, train_loss = 1.0366365797817707, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 341, train_loss = 1.0372880126087693, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 342, train_loss = 1.0359302846045466, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 343, train_loss = 1.0348823927342892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 344, train_loss = 1.0353796680719825, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 345, train_loss = 1.0343542993068695, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 346, train_loss = 1.033718323960784, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 347, train_loss = 1.0337674630136462, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 348, train_loss = 1.0332994510681601, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 349, train_loss = 1.033732580646756, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 350, train_loss = 1.0335229337215424, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 351, train_loss = 1.032922450453043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 352, train_loss = 1.0327146587223979, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 353, train_loss = 1.0320737808942795, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 354, train_loss = 1.0304963899106951, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 355, train_loss = 1.0303464966564206, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 356, train_loss = 1.0304122480301885, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 357, train_loss = 1.0307557297201129, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 358, train_loss = 1.0291244399995776, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 359, train_loss = 1.028621070086956, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 360, train_loss = 1.0281659414322348, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 361, train_loss = 1.0279483919293853, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 362, train_loss = 1.0275569135992555, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 363, train_loss = 1.0272311729640933, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 364, train_loss = 1.0273702007980319, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 365, train_loss = 1.0268502607941628, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 366, train_loss = 1.02581464251125, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 367, train_loss = 1.0254281560555683, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 368, train_loss = 1.0254033071323647, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 369, train_loss = 1.0242764043359784, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 370, train_loss = 1.024262542523502, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 371, train_loss = 1.0235796198248863, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 372, train_loss = 1.0234957747161388, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 373, train_loss = 1.0230290343388333, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 374, train_loss = 1.0232146196067333, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 375, train_loss = 1.0238110112622962, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 376, train_loss = 1.0222385699526058, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 377, train_loss = 1.0224267405792489, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 378, train_loss = 1.0215525291860104, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 379, train_loss = 1.0207753640934243, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 380, train_loss = 1.0216020420193672, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 381, train_loss = 1.0205003668888821, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 382, train_loss = 1.0200027264654636, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 383, train_loss = 1.0194179688915028, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 384, train_loss = 1.018530000001192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 385, train_loss = 1.0186739712953568, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 386, train_loss = 1.0181124111040845, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 387, train_loss = 1.0176361352205276, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 388, train_loss = 1.0169493034482002, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 389, train_loss = 1.016982572771667, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 390, train_loss = 1.0165350586175919, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 391, train_loss = 1.0161988660693169, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 392, train_loss = 1.0160499848425388, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 393, train_loss = 1.0153873724266305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 394, train_loss = 1.0163148567080498, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 395, train_loss = 1.0148959135040059, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 396, train_loss = 1.0141732916235924, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 397, train_loss = 1.0142617759629502, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 398, train_loss = 1.013430946819426, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 399, train_loss = 1.0130575262010098, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 400, train_loss = 1.0127769075334072, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 401, train_loss = 1.0122797787189484, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 402, train_loss = 1.0138802416622639, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 403, train_loss = 1.0120983893648372, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 404, train_loss = 1.0118969778195606, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 405, train_loss = 1.0107403012589202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 406, train_loss = 1.0106887817382812, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 407, train_loss = 1.0104112525805249, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 408, train_loss = 1.0107597832902684, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 409, train_loss = 1.0110905480905785, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 410, train_loss = 1.0095607948824181, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 411, train_loss = 1.0092509115711437, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 412, train_loss = 1.0085825137794018, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 413, train_loss = 1.0092359917834983, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 414, train_loss = 1.0080877232030616, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 415, train_loss = 1.0084474074319587, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 416, train_loss = 1.0070064117535367, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 417, train_loss = 1.0070649559274898, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 418, train_loss = 1.0068211903198971, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 419, train_loss = 1.0062926063910709, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 420, train_loss = 1.0062185538336053, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 421, train_loss = 1.0060355998575687, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 422, train_loss = 1.0046310983598232, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 423, train_loss = 1.004916723817587, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 424, train_loss = 1.0053148989900365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 425, train_loss = 1.0050845605655923, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 426, train_loss = 1.0041192856951966, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 427, train_loss = 1.0034760634080158, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 428, train_loss = 1.0031066449955688, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 429, train_loss = 1.0031205763443722, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 430, train_loss = 1.0028223084882484, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 431, train_loss = 1.002432628221868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 432, train_loss = 1.0021393572314992, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 433, train_loss = 1.0020390637218952, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 434, train_loss = 1.0013729333877563, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 435, train_loss = 1.000978760421276, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 436, train_loss = 1.0005019096061005, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 437, train_loss = 1.000877777732967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 438, train_loss = 1.0017991041167988, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 439, train_loss = 0.9997020488008275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 440, train_loss = 0.9996445278302417, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 441, train_loss = 0.9994601743892417, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 442, train_loss = 0.9989230508581386, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 443, train_loss = 0.9986573172136559, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 444, train_loss = 0.998565827809216, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 445, train_loss = 0.9975546089335694, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 446, train_loss = 0.9977612557486282, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 447, train_loss = 0.9979577896519913, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 448, train_loss = 0.996572016425489, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 449, train_loss = 0.9958920987919555, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 450, train_loss = 0.996832708515285, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 451, train_loss = 0.9956768453121185, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 452, train_loss = 0.9960032949820743, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 453, train_loss = 0.9945483133196831, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 454, train_loss = 0.9946969039738178, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 455, train_loss = 0.9955995393320336, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 456, train_loss = 0.9936491188927903, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 457, train_loss = 0.9943045539184823, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 458, train_loss = 0.9932468794286251, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 459, train_loss = 0.9937949565573945, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 460, train_loss = 0.9925481552854762, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 461, train_loss = 0.9932858757674694, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 462, train_loss = 0.9922712507323013, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 463, train_loss = 0.9922000082806335, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 464, train_loss = 0.9922464179471717, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 465, train_loss = 0.9915606739596114, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 466, train_loss = 0.9917984753847122, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 467, train_loss = 0.9907528360708966, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 468, train_loss = 0.9909762665629387, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 469, train_loss = 0.9900373530908837, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 470, train_loss = 0.9905107468366623, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 471, train_loss = 0.9897209443151951, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 472, train_loss = 0.9900480446740403, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 473, train_loss = 0.9888333665803657, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 474, train_loss = 0.9894532946273102, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 475, train_loss = 0.989061559237598, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 476, train_loss = 0.9879607732073055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 477, train_loss = 0.9882500270978198, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 478, train_loss = 0.9880235704258666, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 479, train_loss = 0.9881128035485744, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 480, train_loss = 0.9878644036725746, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 481, train_loss = 0.9875605143606663, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 482, train_loss = 0.9865885886028991, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 483, train_loss = 0.9870433509349823, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 484, train_loss = 0.9865159839391708, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 485, train_loss = 0.9856180188580765, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 486, train_loss = 0.9849388065413223, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 487, train_loss = 0.9857193815187202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 488, train_loss = 0.9843348364011035, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 489, train_loss = 0.9849851330145611, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 490, train_loss = 0.9845220868810429, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 491, train_loss = 0.9839131037369953, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 492, train_loss = 0.9841181474403129, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 493, train_loss = 0.9833778652027831, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 494, train_loss = 0.9838453382253647, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 495, train_loss = 0.9824993809088483, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 496, train_loss = 0.9832329687997117, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 497, train_loss = 0.9820348086432205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 498, train_loss = 0.9822688661515713, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 499, train_loss = 0.9816231218501343, train_acc = 0.9974382859804378\n",
      "test Acc 0.9655493482309124:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████                                      | 15/30 [2:24:27<2:34:00, 616.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "16th- epoch: 0, train_loss = 369.2286127409898, train_acc = 0.801932929669306\n",
      "test Acc 0.910148975791434:\n",
      "16th- epoch: 1, train_loss = 97.76346748066135, train_acc = 0.9184909175593852\n",
      "test Acc 0.9338919925512105:\n",
      "16th- epoch: 2, train_loss = 59.70682074627257, train_acc = 0.9435258500232883\n",
      "test Acc 0.9432029795158287:\n",
      "16th- epoch: 3, train_loss = 41.75040855753468, train_acc = 0.9562179785747554\n",
      "test Acc 0.9436685288640596:\n",
      "16th- epoch: 4, train_loss = 30.0701577141881, train_acc = 0.9641360037261295\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 5, train_loss = 22.216712084889878, train_acc = 0.9715882626921285\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 6, train_loss = 16.983013668417698, train_acc = 0.9781089892873778\n",
      "test Acc 0.9487895716945997:\n",
      "16th- epoch: 7, train_loss = 13.372507939726347, train_acc = 0.9823008849557522\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 8, train_loss = 10.839638594537973, train_acc = 0.9855612482533768\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 9, train_loss = 8.995959416031837, train_acc = 0.9871914299021891\n",
      "test Acc 0.9529795158286778:\n",
      "16th- epoch: 10, train_loss = 7.580132491886616, train_acc = 0.9895202608290639\n",
      "test Acc 0.9529795158286778:\n",
      "16th- epoch: 11, train_loss = 6.561385219305521, train_acc = 0.9911504424778761\n",
      "test Acc 0.9543761638733705:\n",
      "16th- epoch: 12, train_loss = 5.795909117907286, train_acc = 0.9916162086632511\n",
      "test Acc 0.9557728119180633:\n",
      "16th- epoch: 13, train_loss = 5.178425380348926, train_acc = 0.992081974848626\n",
      "test Acc 0.9557728119180633:\n",
      "16th- epoch: 14, train_loss = 4.633836096763844, train_acc = 0.9925477410340009\n",
      "test Acc 0.9557728119180633:\n",
      "16th- epoch: 15, train_loss = 4.186428869754309, train_acc = 0.9934792734047508\n",
      "test Acc 0.9548417132216015:\n",
      "16th- epoch: 16, train_loss = 3.802194308489561, train_acc = 0.9940614811364695\n",
      "test Acc 0.9548417132216015:\n",
      "16th- epoch: 17, train_loss = 3.5020586463215295, train_acc = 0.9941779226828132\n",
      "test Acc 0.9548417132216015:\n",
      "16th- epoch: 18, train_loss = 3.2423103377223015, train_acc = 0.9944108057755007\n",
      "test Acc 0.9557728119180633:\n",
      "16th- epoch: 19, train_loss = 3.013884086161852, train_acc = 0.9945272473218444\n",
      "test Acc 0.9562383612662942:\n",
      "16th- epoch: 20, train_loss = 2.7982810425310163, train_acc = 0.9946436888681882\n",
      "test Acc 0.957169459962756:\n",
      "16th- epoch: 21, train_loss = 2.610321915402892, train_acc = 0.9951094550535631\n",
      "test Acc 0.957635009310987:\n",
      "16th- epoch: 22, train_loss = 2.4586591819970636, train_acc = 0.995575221238938\n",
      "test Acc 0.9585661080074488:\n",
      "16th- epoch: 23, train_loss = 2.325725364193204, train_acc = 0.9958081043316255\n",
      "test Acc 0.9581005586592178:\n",
      "16th- epoch: 24, train_loss = 2.2140615694224834, train_acc = 0.9959245458779693\n",
      "test Acc 0.9585661080074488:\n",
      "16th- epoch: 25, train_loss = 2.1191529432908283, train_acc = 0.9958081043316255\n",
      "test Acc 0.9581005586592178:\n",
      "16th- epoch: 26, train_loss = 2.0260296165943146, train_acc = 0.9958081043316255\n",
      "test Acc 0.957635009310987:\n",
      "16th- epoch: 27, train_loss = 1.9577869847416878, train_acc = 0.9959245458779693\n",
      "test Acc 0.9585661080074488:\n",
      "16th- epoch: 28, train_loss = 1.8907281880601658, train_acc = 0.996040987424313\n",
      "test Acc 0.9585661080074488:\n",
      "16th- epoch: 29, train_loss = 1.8366621683053381, train_acc = 0.9961574289706567\n",
      "test Acc 0.9581005586592178:\n",
      "16th- epoch: 30, train_loss = 1.780688655871927, train_acc = 0.9963903120633442\n",
      "test Acc 0.9585661080074488:\n",
      "16th- epoch: 31, train_loss = 1.7376662728675, train_acc = 0.9962738705170004\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 32, train_loss = 1.692261952906847, train_acc = 0.9962738705170004\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 33, train_loss = 1.6570252453275316, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 34, train_loss = 1.6169305021576292, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 35, train_loss = 1.587218521784962, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 36, train_loss = 1.5618253983557224, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 37, train_loss = 1.5428743002303236, train_acc = 0.9967396367023754\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 38, train_loss = 1.5234965719282627, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "16th- epoch: 39, train_loss = 1.5097383980937593, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "16th- epoch: 40, train_loss = 1.494200374931097, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "16th- epoch: 41, train_loss = 1.4806917011737823, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 42, train_loss = 1.4745579436421394, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 43, train_loss = 1.4560544577743713, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "16th- epoch: 44, train_loss = 1.4491710501406487, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "16th- epoch: 45, train_loss = 1.4391852219905559, train_acc = 0.9969725197950629\n",
      "test Acc 0.9613594040968343:\n",
      "16th- epoch: 46, train_loss = 1.4350595325231552, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "16th- epoch: 47, train_loss = 1.4272284569833573, train_acc = 0.9969725197950629\n",
      "test Acc 0.9613594040968343:\n",
      "16th- epoch: 48, train_loss = 1.4193060683701333, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 49, train_loss = 1.4164832631740865, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 50, train_loss = 1.4085654368009273, train_acc = 0.9969725197950629\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 51, train_loss = 1.402301199734211, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 52, train_loss = 1.3970217357073125, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 53, train_loss = 1.3911744182314578, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 54, train_loss = 1.38527187580803, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 55, train_loss = 1.3813325725495815, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 56, train_loss = 1.3765677586197853, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "16th- epoch: 57, train_loss = 1.370673901090413, train_acc = 0.9969725197950629\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 58, train_loss = 1.3662739892806712, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 59, train_loss = 1.3591945009920892, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 60, train_loss = 1.3587310065831844, train_acc = 0.9969725197950629\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 61, train_loss = 1.354104715088397, train_acc = 0.9969725197950629\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 62, train_loss = 1.3501379427816573, train_acc = 0.9969725197950629\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 63, train_loss = 1.3451717793941498, train_acc = 0.9968560782487191\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 64, train_loss = 1.3400909577812854, train_acc = 0.9969725197950629\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 65, train_loss = 1.3374819904565811, train_acc = 0.9969725197950629\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 66, train_loss = 1.333109858134776, train_acc = 0.9969725197950629\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 67, train_loss = 1.3298418285939988, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 68, train_loss = 1.3238056376576424, train_acc = 0.9969725197950629\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 69, train_loss = 1.3216536889467534, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 70, train_loss = 1.3195864744484425, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 71, train_loss = 1.31396159902215, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 72, train_loss = 1.3124439554903802, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 73, train_loss = 1.3062825128436089, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 74, train_loss = 1.3059974548723403, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 75, train_loss = 1.3018584735691547, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 76, train_loss = 1.2978176313135918, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 77, train_loss = 1.2949699411783513, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 78, train_loss = 1.2933315485715866, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 79, train_loss = 1.2876391299068928, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 80, train_loss = 1.2867626460883912, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 81, train_loss = 1.2857579017672833, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 82, train_loss = 1.2817769100274745, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 83, train_loss = 1.279530336460084, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 84, train_loss = 1.2781181323025521, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 85, train_loss = 1.2744737515840825, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 86, train_loss = 1.2722277541961375, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 87, train_loss = 1.2683048633243743, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 88, train_loss = 1.2684690306577977, train_acc = 0.9967396367023754\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 89, train_loss = 1.2666055473182496, train_acc = 0.9967396367023754\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 90, train_loss = 1.2602313992883865, train_acc = 0.9967396367023754\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 91, train_loss = 1.25965216755867, train_acc = 0.9967396367023754\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 92, train_loss = 1.259520422667265, train_acc = 0.9967396367023754\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 93, train_loss = 1.2557230641450587, train_acc = 0.9967396367023754\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 94, train_loss = 1.2523672878742218, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 95, train_loss = 1.254337345560998, train_acc = 0.9967396367023754\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 96, train_loss = 1.2483952976763248, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 97, train_loss = 1.248344165584058, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 98, train_loss = 1.2471410433445271, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 99, train_loss = 1.2431717986855801, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 100, train_loss = 1.240470603108406, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 101, train_loss = 1.2375467605888844, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 102, train_loss = 1.2379549418892566, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 103, train_loss = 1.2338471971452236, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 104, train_loss = 1.2310855661835376, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 105, train_loss = 1.2329961247742176, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 106, train_loss = 1.2299496941268444, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 107, train_loss = 1.22657747690846, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 108, train_loss = 1.225458338856697, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 109, train_loss = 1.222869445879951, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 110, train_loss = 1.223318900913, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 111, train_loss = 1.2208747640252113, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 112, train_loss = 1.218939819683328, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 113, train_loss = 1.2200188413262367, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 114, train_loss = 1.217347824324861, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 115, train_loss = 1.2177308065192847, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 116, train_loss = 1.2104776899022909, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 117, train_loss = 1.2139209831757398, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 118, train_loss = 1.2141189463436604, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 119, train_loss = 1.2103506786124854, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 120, train_loss = 1.2095022549228815, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 121, train_loss = 1.2066135257482529, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 122, train_loss = 1.2077313077943472, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 123, train_loss = 1.2041799662010817, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 124, train_loss = 1.2036767092840819, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 125, train_loss = 1.203103307634592, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 126, train_loss = 1.2012372352182865, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 127, train_loss = 1.2002553964657636, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 128, train_loss = 1.1991759973270746, train_acc = 0.9968560782487191\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 129, train_loss = 1.1984478781623693, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 130, train_loss = 1.1960269932942538, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 131, train_loss = 1.1976170105235724, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 132, train_loss = 1.1938619576394558, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 133, train_loss = 1.1935214263694434, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 134, train_loss = 1.1937327769892363, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 135, train_loss = 1.1926648182170538, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 136, train_loss = 1.1936990581452847, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 137, train_loss = 1.187563183407292, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 138, train_loss = 1.190840783218846, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 139, train_loss = 1.188447826852098, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 140, train_loss = 1.1860958375036716, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 141, train_loss = 1.1854000091552734, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 142, train_loss = 1.1845896405475287, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 143, train_loss = 1.1828348177177759, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 144, train_loss = 1.1816033236682415, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 145, train_loss = 1.185671576608911, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 146, train_loss = 1.182410507152781, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 147, train_loss = 1.181781868140206, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 148, train_loss = 1.1786525237066598, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 149, train_loss = 1.1792667992413044, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 150, train_loss = 1.1775625695781855, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 151, train_loss = 1.1761635281145573, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 152, train_loss = 1.176081622640595, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 153, train_loss = 1.1740513506038042, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 154, train_loss = 1.1755010299384594, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 155, train_loss = 1.1739077717065811, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 156, train_loss = 1.172460624326959, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 157, train_loss = 1.1721297825379224, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 158, train_loss = 1.1705323842661528, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 159, train_loss = 1.1719851767020373, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 160, train_loss = 1.1699602864682674, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 161, train_loss = 1.1680349633097649, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 162, train_loss = 1.1683538754778056, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 163, train_loss = 1.1674125790596008, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 164, train_loss = 1.1659138686954975, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 165, train_loss = 1.1642218443257661, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 166, train_loss = 1.1647127096848635, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 167, train_loss = 1.1645017986493258, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 168, train_loss = 1.161578578253284, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 169, train_loss = 1.1631160775823446, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 170, train_loss = 1.1607394206030222, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 171, train_loss = 1.1608792295055537, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 172, train_loss = 1.158255113909945, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 173, train_loss = 1.1573799798889013, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 174, train_loss = 1.1590064018964767, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 175, train_loss = 1.154011285553679, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 176, train_loss = 1.1567299986882063, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 177, train_loss = 1.1530411442117838, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 178, train_loss = 1.1548559131724687, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 179, train_loss = 1.1536094558732657, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 180, train_loss = 1.1529607350630613, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 181, train_loss = 1.1503795174257903, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 182, train_loss = 1.150597058236599, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 183, train_loss = 1.1497779861092567, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 184, train_loss = 1.1496232636272907, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 185, train_loss = 1.147234532982111, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 186, train_loss = 1.148802327613339, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 187, train_loss = 1.1470060050487518, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 188, train_loss = 1.1455441129701285, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 189, train_loss = 1.1461196976406427, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 190, train_loss = 1.1433415723340659, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 191, train_loss = 1.1459132333593516, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 192, train_loss = 1.141109152386889, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 193, train_loss = 1.1428286420805307, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 194, train_loss = 1.1417292170226574, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 195, train_loss = 1.140061603237882, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 196, train_loss = 1.1405091807246208, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 197, train_loss = 1.1380779333412647, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 198, train_loss = 1.1376950542135091, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 199, train_loss = 1.1395952999591827, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 200, train_loss = 1.13453983142972, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 201, train_loss = 1.1357638115687223, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 202, train_loss = 1.1359683473901896, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 203, train_loss = 1.1331679249806257, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 204, train_loss = 1.1347377188503742, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 205, train_loss = 1.1336975519852786, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 206, train_loss = 1.130772863824859, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 207, train_loss = 1.1328367503983827, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 208, train_loss = 1.1292596956091074, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 209, train_loss = 1.1298164439695029, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 210, train_loss = 1.1295323185622692, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 211, train_loss = 1.1274665991468282, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 212, train_loss = 1.1280246910946516, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 213, train_loss = 1.1245904614524989, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 214, train_loss = 1.1257670919103475, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 215, train_loss = 1.1256120602292867, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 216, train_loss = 1.1242040544748306, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 217, train_loss = 1.122626195351586, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 218, train_loss = 1.1234388065831808, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 219, train_loss = 1.1213074723882528, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 220, train_loss = 1.1190769461290984, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 221, train_loss = 1.1212521630031915, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 222, train_loss = 1.1185666359961033, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 223, train_loss = 1.1176732281846853, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 224, train_loss = 1.117611291508183, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 225, train_loss = 1.1152119326097818, train_acc = 0.9968560782487191\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 226, train_loss = 1.116621408611536, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 227, train_loss = 1.1156787313520908, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 228, train_loss = 1.1119538346929403, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 229, train_loss = 1.1133897118270397, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 230, train_loss = 1.1117337259156557, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 231, train_loss = 1.1108574296040388, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 232, train_loss = 1.111410353332758, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 233, train_loss = 1.1104526408016682, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 234, train_loss = 1.1073810532689095, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 235, train_loss = 1.1093059939639716, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 236, train_loss = 1.1067475142581316, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 237, train_loss = 1.105940967798233, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 238, train_loss = 1.1067613363265991, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 239, train_loss = 1.1060200333595276, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 240, train_loss = 1.1036482217414232, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 241, train_loss = 1.1036244593560696, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 242, train_loss = 1.101657085120678, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 243, train_loss = 1.1011458759503512, train_acc = 0.9968560782487191\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 244, train_loss = 1.1044212716324182, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 245, train_loss = 1.0990395384533258, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 246, train_loss = 1.0986142978072166, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 247, train_loss = 1.0981046445667744, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 248, train_loss = 1.0976327148573546, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 249, train_loss = 1.0963831928866057, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 250, train_loss = 1.0956138571100382, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 251, train_loss = 1.0934232845902443, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 252, train_loss = 1.093809677909121, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 253, train_loss = 1.0940830719964652, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 254, train_loss = 1.0905278983218523, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 255, train_loss = 1.0918466821312904, train_acc = 0.9970889613414066\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 256, train_loss = 1.0893698794143347, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 257, train_loss = 1.0900361761450768, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 258, train_loss = 1.0885323124630304, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 259, train_loss = 1.0886784630520197, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 260, train_loss = 1.0869106377167554, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 261, train_loss = 1.086437736948028, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 262, train_loss = 1.0852987964944987, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 263, train_loss = 1.0869554964201598, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 264, train_loss = 1.0845377606647162, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 265, train_loss = 1.083960423867211, train_acc = 0.9970889613414066\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 266, train_loss = 1.0815649554133415, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 267, train_loss = 1.0842806038754134, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 268, train_loss = 1.0788873347146364, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 269, train_loss = 1.0805606928961424, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 270, train_loss = 1.0821020926041456, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 271, train_loss = 1.080180539439425, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 272, train_loss = 1.0754843751592489, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 273, train_loss = 1.080191892881885, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 274, train_loss = 1.0768718719482422, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 275, train_loss = 1.075350359082222, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 276, train_loss = 1.0767513426644655, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 277, train_loss = 1.0750749967992306, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 278, train_loss = 1.0723444633185863, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 279, train_loss = 1.0759552158415318, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 280, train_loss = 1.0714419645564703, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 281, train_loss = 1.0748071745038033, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 282, train_loss = 1.0696234454708247, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 283, train_loss = 1.069579369078383, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 284, train_loss = 1.0710836835205555, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 285, train_loss = 1.0702505633234978, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 286, train_loss = 1.0683141698436884, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 287, train_loss = 1.065604208658442, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 288, train_loss = 1.0683433450758457, train_acc = 0.9972054028877504\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 289, train_loss = 1.0672585542006345, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 290, train_loss = 1.0650290846824646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 291, train_loss = 1.067894694705501, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 292, train_loss = 1.0661787539720535, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 293, train_loss = 1.063998433451161, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 294, train_loss = 1.0652761819465013, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 295, train_loss = 1.0627760117249636, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 296, train_loss = 1.0605529062449932, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 297, train_loss = 1.0644167164964529, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 298, train_loss = 1.0600432877736239, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 299, train_loss = 1.0624536251025347, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 300, train_loss = 1.0595638491213322, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 301, train_loss = 1.0585136140389295, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 302, train_loss = 1.0606244690716267, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 303, train_loss = 1.0607610357301382, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 304, train_loss = 1.056375363220468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 305, train_loss = 1.0581083136303278, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 306, train_loss = 1.0566979050636292, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 307, train_loss = 1.0595897510647774, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 308, train_loss = 1.0520736140506415, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 309, train_loss = 1.055821852137342, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 310, train_loss = 1.0530234922962336, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 311, train_loss = 1.0543151112897249, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 312, train_loss = 1.0534880831837654, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 313, train_loss = 1.0530713225407453, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 314, train_loss = 1.0556547765927462, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 315, train_loss = 1.052119565506473, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 316, train_loss = 1.0527129309875818, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 317, train_loss = 1.0510384974377303, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 318, train_loss = 1.0532145723700523, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 319, train_loss = 1.0467786267399788, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 320, train_loss = 1.0493882186710835, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 321, train_loss = 1.047610950966373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 322, train_loss = 1.049291878938675, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 323, train_loss = 1.0476504911976008, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 324, train_loss = 1.0491611286997795, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 325, train_loss = 1.0471591651439667, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 326, train_loss = 1.0476881886525007, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 327, train_loss = 1.0452081722514777, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 328, train_loss = 1.04686139772366, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 329, train_loss = 1.0444079500930457, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 330, train_loss = 1.0467084820074888, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 331, train_loss = 1.0443063788115978, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 332, train_loss = 1.0423204004764557, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 333, train_loss = 1.0420936283962874, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 334, train_loss = 1.043736072878346, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 335, train_loss = 1.0417483088867812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 336, train_loss = 1.0431457559270711, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 337, train_loss = 1.0421126869814543, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 338, train_loss = 1.0414860285818577, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 339, train_loss = 1.041135096301332, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 340, train_loss = 1.039547512928948, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 341, train_loss = 1.0413074331981989, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 342, train_loss = 1.0418049047393652, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 343, train_loss = 1.0354270276920943, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 344, train_loss = 1.0403289223713728, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 345, train_loss = 1.0377265078323035, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 346, train_loss = 1.0386897747712283, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 347, train_loss = 1.0376004191739412, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 348, train_loss = 1.0379431607825609, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 349, train_loss = 1.0363791075842528, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 350, train_loss = 1.0351673898594527, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 351, train_loss = 1.0348643114166407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 352, train_loss = 1.0343986513717027, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 353, train_loss = 1.0372680984437466, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 354, train_loss = 1.0333303771913052, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 355, train_loss = 1.0343409565584807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 356, train_loss = 1.0343079293770643, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 357, train_loss = 1.0318548430996088, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 358, train_loss = 1.0336064497632833, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 359, train_loss = 1.0338340401649475, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 360, train_loss = 1.0322662678854613, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 361, train_loss = 1.0303080131607203, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 362, train_loss = 1.0304859789712282, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 363, train_loss = 1.0304875125484614, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 364, train_loss = 1.0310703478753567, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 365, train_loss = 1.032007284462452, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 366, train_loss = 1.0280806757509708, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 367, train_loss = 1.0279465727508068, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 368, train_loss = 1.0319146638112215, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 369, train_loss = 1.026882713039413, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 370, train_loss = 1.0297091218335481, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 371, train_loss = 1.0257934555411339, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 372, train_loss = 1.0263747498393059, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 373, train_loss = 1.0291690764324812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 374, train_loss = 1.0256796802086683, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 375, train_loss = 1.0275887971120028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 376, train_loss = 1.0237361751496792, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 377, train_loss = 1.025602225214243, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 378, train_loss = 1.0260104686021805, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 379, train_loss = 1.0238482331233172, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 380, train_loss = 1.0236867691082807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 381, train_loss = 1.02657675122191, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 382, train_loss = 1.0224257881445737, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 383, train_loss = 1.022792534281507, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 384, train_loss = 1.023009019593701, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 385, train_loss = 1.0221737672882227, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 386, train_loss = 1.0227814900381418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 387, train_loss = 1.0221426486968994, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 388, train_loss = 1.020658079534769, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 389, train_loss = 1.0204248763620853, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 390, train_loss = 1.019561154146686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 391, train_loss = 1.0226014256477356, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 392, train_loss = 1.021252679328427, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 393, train_loss = 1.0179376291735025, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 394, train_loss = 1.019232351332903, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 395, train_loss = 1.0212328707175402, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 396, train_loss = 1.0171261243522167, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 397, train_loss = 1.0194157573087068, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 398, train_loss = 1.0192632625503393, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 399, train_loss = 1.0163598271710725, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 400, train_loss = 1.0168303549289703, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 401, train_loss = 1.0180707772569804, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 402, train_loss = 1.0170442697899489, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 403, train_loss = 1.0155311251683088, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 404, train_loss = 1.0145110823214054, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 405, train_loss = 1.0152648588018565, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 406, train_loss = 1.0163831301033497, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 407, train_loss = 1.014513476441607, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 408, train_loss = 1.0134325275821539, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 409, train_loss = 1.013609812905088, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 410, train_loss = 1.014281400789514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 411, train_loss = 1.013373716424212, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 412, train_loss = 1.0128952364129873, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 413, train_loss = 1.012190482269034, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 414, train_loss = 1.0115909700589327, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 415, train_loss = 1.0122324439389558, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 416, train_loss = 1.0124026387929916, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 417, train_loss = 1.012069072574377, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 418, train_loss = 1.0111124229924826, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 419, train_loss = 1.0107465013861656, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 420, train_loss = 1.009471756716266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 421, train_loss = 1.011253573000431, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 422, train_loss = 1.0108831872539668, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 423, train_loss = 1.009506918489933, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 424, train_loss = 1.0084796634810118, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 425, train_loss = 1.0085864203674646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 426, train_loss = 1.0065479141967444, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 427, train_loss = 1.0072939097881317, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 428, train_loss = 1.0108252440886645, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 429, train_loss = 1.0087330241995005, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 430, train_loss = 1.0064569500582365, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 431, train_loss = 1.0057875166339727, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 432, train_loss = 1.0071496901409773, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 433, train_loss = 1.010242034991279, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 434, train_loss = 1.0062796374159007, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 435, train_loss = 1.0046688156826349, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 436, train_loss = 1.0054543030755667, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 437, train_loss = 1.0049508462352605, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 438, train_loss = 1.0052587042255254, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 439, train_loss = 1.002535377939239, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 440, train_loss = 1.0034373228745608, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 441, train_loss = 1.003604895125136, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 442, train_loss = 1.0029877088963985, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 443, train_loss = 1.0052068804698138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 444, train_loss = 1.0043931156396866, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 445, train_loss = 1.0022482102112917, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 446, train_loss = 1.0019350548582224, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 447, train_loss = 1.0012718997895718, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 448, train_loss = 1.0034903983278127, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 449, train_loss = 1.0026862919330597, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 450, train_loss = 1.0022466008858828, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 451, train_loss = 1.001793625454411, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 452, train_loss = 1.0012141801416874, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 453, train_loss = 1.0011562978224902, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 454, train_loss = 1.001144929478869, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 455, train_loss = 1.000697632630363, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 456, train_loss = 0.9990093546612115, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 457, train_loss = 0.9992927921312003, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 458, train_loss = 0.9993286319077015, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 459, train_loss = 0.9974351910250334, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 460, train_loss = 0.9981717454893442, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 461, train_loss = 0.997596086313024, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 462, train_loss = 0.9972658293945642, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 463, train_loss = 0.9982744206981806, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 464, train_loss = 0.996632804472938, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 465, train_loss = 0.9965129755437374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 466, train_loss = 0.9964926491184087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 467, train_loss = 0.9957495853304863, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 468, train_loss = 0.9973162114620209, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 469, train_loss = 0.9952998322742133, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 470, train_loss = 0.9946594561142774, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 471, train_loss = 0.9944968534009604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 472, train_loss = 0.9949717807276102, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 473, train_loss = 0.9956365314619688, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 474, train_loss = 0.9936930984258652, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 475, train_loss = 0.9933106390135436, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 476, train_loss = 0.9958963704602866, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 477, train_loss = 0.9936178028583527, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 478, train_loss = 0.9935262637836786, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 479, train_loss = 0.993698449184194, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 480, train_loss = 0.9931251195566801, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 481, train_loss = 0.9930676867561488, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 482, train_loss = 0.9918199342982916, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 483, train_loss = 0.9920111161964087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 484, train_loss = 0.9920027069747448, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 485, train_loss = 0.9913723692297935, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 486, train_loss = 0.9909317294759603, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 487, train_loss = 0.9905285276472569, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 488, train_loss = 0.9907714898390623, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 489, train_loss = 0.990749578922987, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 490, train_loss = 0.9900310660405012, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 491, train_loss = 0.9892351416247038, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 492, train_loss = 0.9899457097053528, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 493, train_loss = 0.9887735359370708, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 494, train_loss = 0.988809062789187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 495, train_loss = 0.9894050744669585, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 496, train_loss = 0.9889242897434087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 497, train_loss = 0.9888479659957738, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 498, train_loss = 0.9870653487741947, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 499, train_loss = 0.9870534526808115, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|████████████████████████████████████████▌                                   | 16/30 [2:35:00<2:24:56, 621.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "17th- epoch: 0, train_loss = 435.2785174809396, train_acc = 0.7887750349324639\n",
      "test Acc 0.8375232774674115:\n",
      "17th- epoch: 1, train_loss = 89.61078909784555, train_acc = 0.9156963204471356\n",
      "test Acc 0.9194599627560521:\n",
      "17th- epoch: 2, train_loss = 54.53383548371494, train_acc = 0.9435258500232883\n",
      "test Acc 0.930633147113594:\n",
      "17th- epoch: 3, train_loss = 38.82778849918395, train_acc = 0.9570330693991617\n",
      "test Acc 0.9352886405959032:\n",
      "17th- epoch: 4, train_loss = 29.08687220327556, train_acc = 0.9643688868188169\n",
      "test Acc 0.9390130353817505:\n",
      "17th- epoch: 5, train_loss = 22.48537035752088, train_acc = 0.9735677689799721\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 6, train_loss = 18.10156073048711, train_acc = 0.9771774569166278\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 7, train_loss = 14.950548538006842, train_acc = 0.9809035863996274\n",
      "test Acc 0.9459962756052142:\n",
      "17th- epoch: 8, train_loss = 12.494365463033319, train_acc = 0.9827666511411272\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 9, train_loss = 10.549177624750882, train_acc = 0.9852119236143456\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 10, train_loss = 9.031918981578201, train_acc = 0.9870749883558454\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 11, train_loss = 7.822328026872128, train_acc = 0.9884722869119702\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 12, train_loss = 6.8866888782940805, train_acc = 0.9892873777363763\n",
      "test Acc 0.9529795158286778:\n",
      "17th- epoch: 13, train_loss = 6.122218891745433, train_acc = 0.990801117838845\n",
      "test Acc 0.9539106145251397:\n",
      "17th- epoch: 14, train_loss = 5.526500543928705, train_acc = 0.9913833255705635\n",
      "test Acc 0.9539106145251397:\n",
      "17th- epoch: 15, train_loss = 4.992226648842916, train_acc = 0.9918490917559385\n",
      "test Acc 0.9543761638733705:\n",
      "17th- epoch: 16, train_loss = 4.553997718030587, train_acc = 0.9919655333022822\n",
      "test Acc 0.9562383612662942:\n",
      "17th- epoch: 17, train_loss = 4.166897127404809, train_acc = 0.9924312994876572\n",
      "test Acc 0.957169459962756:\n",
      "17th- epoch: 18, train_loss = 3.8336983078625053, train_acc = 0.9930135072193759\n",
      "test Acc 0.957635009310987:\n",
      "17th- epoch: 19, train_loss = 3.5509869956877083, train_acc = 0.9933628318584071\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 20, train_loss = 3.305071789305657, train_acc = 0.9941779226828132\n",
      "test Acc 0.9590316573556797:\n",
      "17th- epoch: 21, train_loss = 3.0903923651203513, train_acc = 0.9944108057755007\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 22, train_loss = 2.8878938381094486, train_acc = 0.9946436888681882\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 23, train_loss = 2.729712424101308, train_acc = 0.9949930135072194\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 24, train_loss = 2.5871232866775244, train_acc = 0.9951094550535631\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 25, train_loss = 2.4595264398958534, train_acc = 0.9953423381462506\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 26, train_loss = 2.3456722744740546, train_acc = 0.9954587796925943\n",
      "test Acc 0.9594972067039106:\n",
      "17th- epoch: 27, train_loss = 2.2423311369493604, train_acc = 0.9954587796925943\n",
      "test Acc 0.9590316573556797:\n",
      "17th- epoch: 28, train_loss = 2.1472406808752567, train_acc = 0.9958081043316255\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 29, train_loss = 2.066205739043653, train_acc = 0.9959245458779693\n",
      "test Acc 0.9590316573556797:\n",
      "17th- epoch: 30, train_loss = 1.9876103780698031, train_acc = 0.9959245458779693\n",
      "test Acc 0.9590316573556797:\n",
      "17th- epoch: 31, train_loss = 1.9138436024077237, train_acc = 0.9959245458779693\n",
      "test Acc 0.9590316573556797:\n",
      "17th- epoch: 32, train_loss = 1.8580867282580584, train_acc = 0.996040987424313\n",
      "test Acc 0.9590316573556797:\n",
      "17th- epoch: 33, train_loss = 1.81034041242674, train_acc = 0.996040987424313\n",
      "test Acc 0.9594972067039106:\n",
      "17th- epoch: 34, train_loss = 1.7670323948841542, train_acc = 0.9962738705170004\n",
      "test Acc 0.9594972067039106:\n",
      "17th- epoch: 35, train_loss = 1.724751664325595, train_acc = 0.9966231951560317\n",
      "test Acc 0.9604283054003724:\n",
      "17th- epoch: 36, train_loss = 1.698375746840611, train_acc = 0.9966231951560317\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 37, train_loss = 1.670990712940693, train_acc = 0.9968560782487191\n",
      "test Acc 0.9594972067039106:\n",
      "17th- epoch: 38, train_loss = 1.6515756917651743, train_acc = 0.9968560782487191\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 39, train_loss = 1.6276385390665382, train_acc = 0.9968560782487191\n",
      "test Acc 0.9604283054003724:\n",
      "17th- epoch: 40, train_loss = 1.612098882207647, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 41, train_loss = 1.5929505731910467, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 42, train_loss = 1.5800542855868116, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 43, train_loss = 1.56743524747435, train_acc = 0.9968560782487191\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 44, train_loss = 1.5497306148754433, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 45, train_loss = 1.5404825750738382, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 46, train_loss = 1.5276793040102348, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 47, train_loss = 1.517403638572432, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 48, train_loss = 1.506988531909883, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 49, train_loss = 1.4991568719269708, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 50, train_loss = 1.4886752720922232, train_acc = 0.9968560782487191\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 51, train_loss = 1.4794605175266042, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 52, train_loss = 1.4715927384095266, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 53, train_loss = 1.4616676022997126, train_acc = 0.9967396367023754\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 54, train_loss = 1.4569788452936336, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 55, train_loss = 1.450289708096534, train_acc = 0.9967396367023754\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 56, train_loss = 1.4395166017347947, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 57, train_loss = 1.4323378643020988, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 58, train_loss = 1.4250816631829366, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 59, train_loss = 1.420788218616508, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 60, train_loss = 1.4126957576954737, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 61, train_loss = 1.4092981652356684, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 62, train_loss = 1.4030740436865017, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 63, train_loss = 1.3974018932785839, train_acc = 0.9968560782487191\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 64, train_loss = 1.3949883648892865, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 65, train_loss = 1.3873780235880986, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 66, train_loss = 1.3812983584357426, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 67, train_loss = 1.3792987488559447, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 68, train_loss = 1.3743356328923255, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 69, train_loss = 1.368666673952248, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 70, train_loss = 1.3692230039741844, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 71, train_loss = 1.361659956339281, train_acc = 0.9969725197950629\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 72, train_loss = 1.3573223006096669, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 73, train_loss = 1.352546344511211, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 74, train_loss = 1.3522630733787082, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 75, train_loss = 1.3470065672299825, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 76, train_loss = 1.3421853465843014, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 77, train_loss = 1.3391536822891794, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 78, train_loss = 1.3355465084896423, train_acc = 0.9969725197950629\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 79, train_loss = 1.3327693156315945, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 80, train_loss = 1.3298746517393738, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 81, train_loss = 1.3255522586987354, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 82, train_loss = 1.3237754967994988, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 83, train_loss = 1.320296787598636, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 84, train_loss = 1.3178818920860067, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 85, train_loss = 1.3133734337752685, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 86, train_loss = 1.311405227635987, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 87, train_loss = 1.3080969531438313, train_acc = 0.9969725197950629\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 88, train_loss = 1.3062370149418712, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 89, train_loss = 1.3056577002280392, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 90, train_loss = 1.2983681898913346, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 91, train_loss = 1.2982892565778457, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 92, train_loss = 1.2944298351067118, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 93, train_loss = 1.2928340505459346, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 94, train_loss = 1.2883137715398334, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 95, train_loss = 1.2903432098100893, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 96, train_loss = 1.2851179959252477, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 97, train_loss = 1.2833402180694975, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 98, train_loss = 1.2818762173410505, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 99, train_loss = 1.277204841549974, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 100, train_loss = 1.275463173573371, train_acc = 0.9969725197950629\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 101, train_loss = 1.2742083328776062, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 102, train_loss = 1.2712175794877112, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 103, train_loss = 1.269920359365642, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 104, train_loss = 1.266781175043434, train_acc = 0.9969725197950629\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 105, train_loss = 1.2658451556344517, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 106, train_loss = 1.2634020764380693, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 107, train_loss = 1.261923342011869, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 108, train_loss = 1.2591470565530472, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 109, train_loss = 1.2578991345944814, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 110, train_loss = 1.2551301824860275, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 111, train_loss = 1.2543479129089974, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 112, train_loss = 1.251218845427502, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 113, train_loss = 1.2484728083072696, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 114, train_loss = 1.2473596749769058, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 115, train_loss = 1.2450483706779778, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 116, train_loss = 1.2423199537151959, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 117, train_loss = 1.2401717966422439, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 118, train_loss = 1.2407856372592505, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 119, train_loss = 1.2388319633028004, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 120, train_loss = 1.2369273033400532, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 121, train_loss = 1.2349399820377585, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 122, train_loss = 1.233192229672568, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 123, train_loss = 1.2312677771551535, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 124, train_loss = 1.2298072894918732, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 125, train_loss = 1.2269191835948732, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 126, train_loss = 1.2242979712609667, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 127, train_loss = 1.2218764454883058, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 128, train_loss = 1.223598239099374, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 129, train_loss = 1.2196894045046065, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 130, train_loss = 1.2178523504990153, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 131, train_loss = 1.216460381343495, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 132, train_loss = 1.2145248576707672, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 133, train_loss = 1.2126956305874046, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 134, train_loss = 1.2118256221001502, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 135, train_loss = 1.2116681277693715, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 136, train_loss = 1.207647790783085, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 137, train_loss = 1.2055479732807726, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 138, train_loss = 1.2041721137647983, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 139, train_loss = 1.2031583454518113, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 140, train_loss = 1.2018600362644065, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 141, train_loss = 1.199027910042787, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 142, train_loss = 1.1970142306236085, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 143, train_loss = 1.1956161195412278, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 144, train_loss = 1.193917567608878, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 145, train_loss = 1.1946411494573113, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 146, train_loss = 1.1893730314041022, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 147, train_loss = 1.1868016317021102, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 148, train_loss = 1.1866856494452804, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 149, train_loss = 1.1862067094480153, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 150, train_loss = 1.183877358213067, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 151, train_loss = 1.1817967457172927, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 152, train_loss = 1.1795076763664838, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 153, train_loss = 1.1776527490874287, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 154, train_loss = 1.1773769894207362, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 155, train_loss = 1.1756795057153795, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 156, train_loss = 1.1742854683252517, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 157, train_loss = 1.172510345611954, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 158, train_loss = 1.1756630847230554, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 159, train_loss = 1.1732533840986434, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 160, train_loss = 1.1711992886848748, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 161, train_loss = 1.1704549860733096, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 162, train_loss = 1.1686535639164504, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 163, train_loss = 1.167568238597596, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 164, train_loss = 1.1663661274651531, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 165, train_loss = 1.1644919967802707, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 166, train_loss = 1.1630050092935562, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 167, train_loss = 1.1630586186947767, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 168, train_loss = 1.1601708001981024, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 169, train_loss = 1.1590341670962516, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 170, train_loss = 1.1581352013163269, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 171, train_loss = 1.1566677163355052, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 172, train_loss = 1.1556050831859466, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 173, train_loss = 1.1541119975445326, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 174, train_loss = 1.1528187870571855, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 175, train_loss = 1.151744111586595, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 176, train_loss = 1.1508937150647398, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 177, train_loss = 1.1492922456527594, train_acc = 0.9969725197950629\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 178, train_loss = 1.1484573585912585, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 179, train_loss = 1.147961392212892, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 180, train_loss = 1.1457123450527433, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 181, train_loss = 1.1442624148912728, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 182, train_loss = 1.143336947541684, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 183, train_loss = 1.1427980056032538, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 184, train_loss = 1.1405117047543172, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 185, train_loss = 1.1396742394717876, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 186, train_loss = 1.1399939217080828, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 187, train_loss = 1.1380370600672904, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 188, train_loss = 1.1367404026386794, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 189, train_loss = 1.1412711910379585, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 190, train_loss = 1.1355771593225654, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 191, train_loss = 1.1342385075986385, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 192, train_loss = 1.132467806659406, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 193, train_loss = 1.1309074073506054, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 194, train_loss = 1.1358527283591684, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 195, train_loss = 1.135902465932304, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 196, train_loss = 1.131632567383349, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 197, train_loss = 1.1312640591931995, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 198, train_loss = 1.1248756209388375, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 199, train_loss = 1.1230918805522379, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 200, train_loss = 1.1289659906178713, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 201, train_loss = 1.1284821135923266, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 202, train_loss = 1.1239875387400389, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 203, train_loss = 1.1216827298921999, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 204, train_loss = 1.1190328017401043, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 205, train_loss = 1.1183742014691234, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 206, train_loss = 1.1191637984738918, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 207, train_loss = 1.116896397434175, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 208, train_loss = 1.1151807314454345, train_acc = 0.9968560782487191\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 209, train_loss = 1.1132641748263268, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 210, train_loss = 1.112500906616333, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 211, train_loss = 1.1126097577362088, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 212, train_loss = 1.1115767328738002, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 213, train_loss = 1.1091512062848778, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 214, train_loss = 1.1087786269636126, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 215, train_loss = 1.108250165663776, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 216, train_loss = 1.1080298215820221, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 217, train_loss = 1.105231602981803, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 218, train_loss = 1.108336749181035, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 219, train_loss = 1.1050859366805525, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 220, train_loss = 1.103541331991437, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 221, train_loss = 1.1015751849190565, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 222, train_loss = 1.1003281374723883, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 223, train_loss = 1.101896515741828, train_acc = 0.9969725197950629\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 224, train_loss = 1.0990400572045473, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 225, train_loss = 1.0986022309662076, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 226, train_loss = 1.0967625500634313, train_acc = 0.9972054028877504\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 227, train_loss = 1.0958385625854135, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 228, train_loss = 1.0940669920964865, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 229, train_loss = 1.09341580576438, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 230, train_loss = 1.09259922678757, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 231, train_loss = 1.0921432254835963, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 232, train_loss = 1.089783150702715, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 233, train_loss = 1.0935226998553844, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 234, train_loss = 1.0887471005989937, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 235, train_loss = 1.0877251646743389, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 236, train_loss = 1.0864190968422918, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 237, train_loss = 1.0864267786964774, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 238, train_loss = 1.0854325269610854, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 239, train_loss = 1.0850513260811567, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 240, train_loss = 1.0842068155034212, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 241, train_loss = 1.0840368755161762, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 242, train_loss = 1.0826209473161725, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 243, train_loss = 1.0822211932390928, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 244, train_loss = 1.0788900485931663, train_acc = 0.9972054028877504\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 245, train_loss = 1.0795667463244172, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 246, train_loss = 1.0811024612485198, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 247, train_loss = 1.0829938563256292, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 248, train_loss = 1.0818836965336232, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 249, train_loss = 1.0830098280421225, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 250, train_loss = 1.0811055772937834, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 251, train_loss = 1.0807614998630015, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 252, train_loss = 1.0748375998809934, train_acc = 0.9972054028877504\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 253, train_loss = 1.0746608328336151, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 254, train_loss = 1.074134892623988, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 255, train_loss = 1.0729749764577718, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 256, train_loss = 1.0715538427903084, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 257, train_loss = 1.0735778723174008, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 258, train_loss = 1.0733272366487654, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 259, train_loss = 1.0732854316011071, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 260, train_loss = 1.0699895980505971, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 261, train_loss = 1.071280010670307, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 262, train_loss = 1.068244518712163, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 263, train_loss = 1.0671280903479783, train_acc = 0.9970889613414066\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 264, train_loss = 1.0682279926986666, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 265, train_loss = 1.0676170044316677, train_acc = 0.9972054028877504\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 266, train_loss = 1.0674161302595166, train_acc = 0.9973218444340941\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 267, train_loss = 1.0657410959975095, train_acc = 0.9972054028877504\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 268, train_loss = 1.0647258162498474, train_acc = 0.9972054028877504\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 269, train_loss = 1.0654541997500928, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 270, train_loss = 1.0664415562787326, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 271, train_loss = 1.0655763425602345, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 272, train_loss = 1.0657536669896217, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 273, train_loss = 1.063959707506001, train_acc = 0.9970889613414066\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 274, train_loss = 1.0619792250654427, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 275, train_loss = 1.0599728568195133, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 276, train_loss = 1.061537608038634, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 277, train_loss = 1.0619135641754838, train_acc = 0.9972054028877504\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 278, train_loss = 1.061255153734237, train_acc = 0.9972054028877504\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 279, train_loss = 1.0595238118694397, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 280, train_loss = 1.0598881624900969, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 281, train_loss = 1.0599965120927664, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 282, train_loss = 1.0593408923596144, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 283, train_loss = 1.0579074518755078, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 284, train_loss = 1.0596660237497417, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 285, train_loss = 1.0568179834372131, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 286, train_loss = 1.0568972611799836, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 287, train_loss = 1.0566906013264088, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 288, train_loss = 1.0542262691742508, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 289, train_loss = 1.0544602692389162, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 290, train_loss = 1.0543844884523423, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 291, train_loss = 1.0487890730873914, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 292, train_loss = 1.0513083251862554, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 293, train_loss = 1.0497205493302317, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 294, train_loss = 1.0475882703176467, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 295, train_loss = 1.0520537112170132, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 296, train_loss = 1.0489228088408709, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 297, train_loss = 1.0504818314948352, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 298, train_loss = 1.046556013796362, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 299, train_loss = 1.0522060487419367, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 300, train_loss = 1.050809308886528, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 301, train_loss = 1.052031530693057, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 302, train_loss = 1.0498972426430555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 303, train_loss = 1.0480092543439241, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 304, train_loss = 1.0486647295765579, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 305, train_loss = 1.04829194676131, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 306, train_loss = 1.0465891415515216, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 307, train_loss = 1.0454236997029511, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 308, train_loss = 1.0483292598946718, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 309, train_loss = 1.0497636827640235, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 310, train_loss = 1.0441428758203983, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 311, train_loss = 1.0498546323069604, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 312, train_loss = 1.0449829267599853, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 313, train_loss = 1.0436242489813594, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 314, train_loss = 1.0444997621962102, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 315, train_loss = 1.0405993129388662, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 316, train_loss = 1.042219242081046, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 317, train_loss = 1.041906354643288, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 318, train_loss = 1.0432282884867163, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 319, train_loss = 1.0407961993478239, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 320, train_loss = 1.0390835922880797, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 321, train_loss = 1.0412228601053357, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 322, train_loss = 1.038930236521992, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 323, train_loss = 1.0367538463324308, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 324, train_loss = 1.0385149186477065, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 325, train_loss = 1.039755391262588, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 326, train_loss = 1.037168622482568, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 327, train_loss = 1.0364979268051684, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 328, train_loss = 1.038749371189624, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 329, train_loss = 1.0335662712604972, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 330, train_loss = 1.039997732572374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 331, train_loss = 1.0331091968546389, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 332, train_loss = 1.0340098615997704, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 333, train_loss = 1.036099594712141, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 334, train_loss = 1.0361551620735554, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 335, train_loss = 1.030834822289762, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 336, train_loss = 1.0319348690100014, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 337, train_loss = 1.0310252889321418, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 338, train_loss = 1.0340047258214327, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 339, train_loss = 1.031006266202894, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 340, train_loss = 1.0311324278154643, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 341, train_loss = 1.0299890055321157, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 342, train_loss = 1.029320242581889, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 343, train_loss = 1.0255755908583524, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 344, train_loss = 1.031566521312925, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 345, train_loss = 1.027210283165914, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 346, train_loss = 1.0309018197003752, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 347, train_loss = 1.0287932360879495, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 348, train_loss = 1.0284724601806374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 349, train_loss = 1.0231345776264789, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 350, train_loss = 1.0242238064965932, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 351, train_loss = 1.0228746309148846, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 352, train_loss = 1.0223573967814445, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 353, train_loss = 1.0204479307867587, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 354, train_loss = 1.0232182268518955, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 355, train_loss = 1.0250642928294837, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 356, train_loss = 1.0283537545910804, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 357, train_loss = 1.0216137780080317, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 358, train_loss = 1.02379984378058, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 359, train_loss = 1.0253930015751394, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 360, train_loss = 1.020328507758677, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 361, train_loss = 1.019688755273819, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 362, train_loss = 1.021535650754231, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 363, train_loss = 1.0258321962319314, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 364, train_loss = 1.0213144232257036, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 365, train_loss = 1.0203319829161046, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 366, train_loss = 1.0180330063012661, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 367, train_loss = 1.0219986729789525, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 368, train_loss = 1.017020647341269, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 369, train_loss = 1.0185249169153394, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 370, train_loss = 1.0161466905847192, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 371, train_loss = 1.0160155141056748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 372, train_loss = 1.015892434559646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 373, train_loss = 1.0169325639290037, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 374, train_loss = 1.0140596095734509, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 375, train_loss = 1.0171848557220073, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 376, train_loss = 1.012881353031844, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 377, train_loss = 1.0131913928780705, train_acc = 0.9973218444340941\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 378, train_loss = 1.0126922072377056, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 379, train_loss = 1.010181098637986, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 380, train_loss = 1.0156386011076393, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 381, train_loss = 1.0119703262244002, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 382, train_loss = 1.0159145706929849, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 383, train_loss = 1.012875244487077, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 384, train_loss = 1.0108948972338112, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 385, train_loss = 1.0103927976451814, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 386, train_loss = 1.0080614859907655, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 387, train_loss = 1.0088977984487428, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 388, train_loss = 1.00816818986641, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 389, train_loss = 1.0074960930869565, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 390, train_loss = 1.0063699497841299, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 391, train_loss = 1.0063692856347188, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 392, train_loss = 1.0068668897729367, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 393, train_loss = 1.0111563468453824, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 394, train_loss = 1.0054383962415159, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 395, train_loss = 1.0061433906666934, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 396, train_loss = 1.0056579486335977, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 397, train_loss = 1.0096179075771943, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 398, train_loss = 1.0072077224831446, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 399, train_loss = 1.0071853010813356, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 400, train_loss = 1.0051675860668183, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 401, train_loss = 1.0070493698585778, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 402, train_loss = 1.0040796723915264, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 403, train_loss = 1.001977243424335, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 404, train_loss = 1.0026178642510786, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 405, train_loss = 1.0029926796778454, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 406, train_loss = 1.0030518557978212, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 407, train_loss = 1.0025857788641588, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 408, train_loss = 1.0022893411005498, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 409, train_loss = 1.005884752572456, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 410, train_loss = 0.9999811687739566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 411, train_loss = 1.0006828335681348, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 412, train_loss = 1.000128771062009, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 413, train_loss = 1.0012810139814974, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 414, train_loss = 1.000680739096424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 415, train_loss = 0.9993743076120154, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 416, train_loss = 0.9975383367054746, train_acc = 0.9973218444340941\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 417, train_loss = 1.0010650943368091, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 418, train_loss = 0.9971946652876795, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 419, train_loss = 0.9963956690626219, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 420, train_loss = 0.9983675720868632, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 421, train_loss = 1.0002850394594134, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 422, train_loss = 0.9953626468413859, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 423, train_loss = 0.9967644270509481, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 424, train_loss = 0.9973122773590148, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 425, train_loss = 0.9967621593968943, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 426, train_loss = 0.9966292676617741, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 427, train_loss = 0.9964422628181637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 428, train_loss = 0.9959797638803138, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 429, train_loss = 0.9935354275730788, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 430, train_loss = 0.995258853501582, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 431, train_loss = 0.9950774757671752, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 432, train_loss = 0.9949620749903261, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 433, train_loss = 0.9940176716409042, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 434, train_loss = 0.9943993140477687, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 435, train_loss = 0.9931322425618418, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 436, train_loss = 0.9938120898223133, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 437, train_loss = 0.9930341517683701, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 438, train_loss = 0.9973106936668046, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 439, train_loss = 0.9924308801055304, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 440, train_loss = 0.9925192772279843, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 441, train_loss = 0.9924175435808138, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 442, train_loss = 0.9917165943406872, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 443, train_loss = 0.9897669993224554, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 444, train_loss = 0.9925406893962645, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 445, train_loss = 0.9927882920965203, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 446, train_loss = 0.9925393566445564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 447, train_loss = 0.9922901544705383, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 448, train_loss = 0.9926851839045412, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 449, train_loss = 0.9916096809829469, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 450, train_loss = 0.9911709843217977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 451, train_loss = 0.9929222929276875, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 452, train_loss = 0.9873625297623221, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 453, train_loss = 0.9887788161213393, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 454, train_loss = 0.9877783934716717, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 455, train_loss = 0.9864566172691411, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 456, train_loss = 0.9883682170475367, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 457, train_loss = 0.9877699403732549, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 458, train_loss = 0.9853989106413792, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 459, train_loss = 0.9862951895411243, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 460, train_loss = 0.9855550024440163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 461, train_loss = 0.99094197035447, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 462, train_loss = 0.9864048535309848, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 463, train_loss = 0.9868685668116086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 464, train_loss = 0.9861308700856171, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 465, train_loss = 0.991245712248201, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 466, train_loss = 0.984672148100799, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 467, train_loss = 0.9859067432771553, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 468, train_loss = 0.9852768647033372, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 469, train_loss = 0.9865775156577001, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 470, train_loss = 0.9867185791226802, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 471, train_loss = 0.9862204407472746, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 472, train_loss = 0.9877017510370933, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 473, train_loss = 0.9836493008260732, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 474, train_loss = 0.9848849219852127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 475, train_loss = 0.9851913652892108, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 476, train_loss = 0.98481622061081, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 477, train_loss = 0.9846081188588869, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 478, train_loss = 0.9835278491591453, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 479, train_loss = 0.9834150170790963, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 480, train_loss = 0.982150019321125, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 481, train_loss = 0.9832551899016835, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 482, train_loss = 0.9833797276369296, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 483, train_loss = 0.9832504095465993, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 484, train_loss = 0.982496845877904, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 485, train_loss = 0.9827277081567445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 486, train_loss = 0.982637500455894, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 487, train_loss = 0.9819300122908317, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 488, train_loss = 0.9809292771460605, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 489, train_loss = 0.9816535091740661, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 490, train_loss = 0.9799496081614052, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 491, train_loss = 0.980878372422012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 492, train_loss = 0.9811354455669061, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 493, train_loss = 0.9829730639467016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 494, train_loss = 0.980168307571148, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 495, train_loss = 0.9799659689088003, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 496, train_loss = 0.9800044668008923, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 497, train_loss = 0.9796226778635173, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 498, train_loss = 0.9791473843724816, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 499, train_loss = 0.9792795489993296, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|███████████████████████████████████████████                                 | 17/30 [2:45:29<2:15:02, 623.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "18th- epoch: 0, train_loss = 408.35411235690117, train_acc = 0.783884489986027\n",
      "test Acc 0.8626629422718808:\n",
      "18th- epoch: 1, train_loss = 95.34984162077308, train_acc = 0.9116208663251048\n",
      "test Acc 0.9301675977653632:\n",
      "18th- epoch: 2, train_loss = 57.72939080465585, train_acc = 0.9381695388914765\n",
      "test Acc 0.9394785847299814:\n",
      "18th- epoch: 3, train_loss = 40.08233708329499, train_acc = 0.9521425244527247\n",
      "test Acc 0.9432029795158287:\n",
      "18th- epoch: 4, train_loss = 29.127354241907597, train_acc = 0.9620400558919422\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 5, train_loss = 22.123360296711326, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 6, train_loss = 17.571004753932357, train_acc = 0.9758965999068467\n",
      "test Acc 0.9501862197392924:\n",
      "18th- epoch: 7, train_loss = 14.411897726356983, train_acc = 0.9790405216581276\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 8, train_loss = 12.10897970572114, train_acc = 0.9817186772240335\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 9, train_loss = 10.368775804527104, train_acc = 0.9838146250582208\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 10, train_loss = 8.952346176840365, train_acc = 0.9860270144387517\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 11, train_loss = 7.7961470717564225, train_acc = 0.9876571960875641\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 12, train_loss = 6.8912999564781785, train_acc = 0.9888216115510013\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 13, train_loss = 6.191591075621545, train_acc = 0.9899860270144387\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 14, train_loss = 5.605113707482815, train_acc = 0.9912668840242198\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 15, train_loss = 5.164218250662088, train_acc = 0.9911504424778761\n",
      "test Acc 0.9515828677839852:\n",
      "18th- epoch: 16, train_loss = 4.744744878727943, train_acc = 0.9916162086632511\n",
      "test Acc 0.9515828677839852:\n",
      "18th- epoch: 17, train_loss = 4.415725360158831, train_acc = 0.9917326502095948\n",
      "test Acc 0.952513966480447:\n",
      "18th- epoch: 18, train_loss = 4.107499377802014, train_acc = 0.992081974848626\n",
      "test Acc 0.9529795158286778:\n",
      "18th- epoch: 19, train_loss = 3.8497872236184776, train_acc = 0.9928970656730322\n",
      "test Acc 0.952513966480447:\n",
      "18th- epoch: 20, train_loss = 3.635239512193948, train_acc = 0.9928970656730322\n",
      "test Acc 0.952513966480447:\n",
      "18th- epoch: 21, train_loss = 3.436533397063613, train_acc = 0.9932463903120633\n",
      "test Acc 0.952513966480447:\n",
      "18th- epoch: 22, train_loss = 3.2285907231271267, train_acc = 0.9933628318584071\n",
      "test Acc 0.952513966480447:\n",
      "18th- epoch: 23, train_loss = 3.0850006476975977, train_acc = 0.9934792734047508\n",
      "test Acc 0.952048417132216:\n",
      "18th- epoch: 24, train_loss = 2.9115772265940905, train_acc = 0.9937121564974383\n",
      "test Acc 0.9529795158286778:\n",
      "18th- epoch: 25, train_loss = 2.790197214577347, train_acc = 0.9939450395901258\n",
      "test Acc 0.952513966480447:\n",
      "18th- epoch: 26, train_loss = 2.659943339880556, train_acc = 0.9940614811364695\n",
      "test Acc 0.952513966480447:\n",
      "18th- epoch: 27, train_loss = 2.5426385551691055, train_acc = 0.994294364229157\n",
      "test Acc 0.9534450651769087:\n",
      "18th- epoch: 28, train_loss = 2.4532922375947237, train_acc = 0.994294364229157\n",
      "test Acc 0.9534450651769087:\n",
      "18th- epoch: 29, train_loss = 2.36219769786112, train_acc = 0.9947601304145319\n",
      "test Acc 0.9539106145251397:\n",
      "18th- epoch: 30, train_loss = 2.285674188286066, train_acc = 0.9945272473218444\n",
      "test Acc 0.9539106145251397:\n",
      "18th- epoch: 31, train_loss = 2.2140137820970267, train_acc = 0.9946436888681882\n",
      "test Acc 0.9543761638733705:\n",
      "18th- epoch: 32, train_loss = 2.1623885228764266, train_acc = 0.9949930135072194\n",
      "test Acc 0.9543761638733705:\n",
      "18th- epoch: 33, train_loss = 2.0907831203658134, train_acc = 0.9946436888681882\n",
      "test Acc 0.9543761638733705:\n",
      "18th- epoch: 34, train_loss = 2.0532972887158394, train_acc = 0.9947601304145319\n",
      "test Acc 0.9548417132216015:\n",
      "18th- epoch: 35, train_loss = 1.9856886200141162, train_acc = 0.9947601304145319\n",
      "test Acc 0.9562383612662942:\n",
      "18th- epoch: 36, train_loss = 1.94839165546, train_acc = 0.9947601304145319\n",
      "test Acc 0.9562383612662942:\n",
      "18th- epoch: 37, train_loss = 1.8984535373747349, train_acc = 0.9949930135072194\n",
      "test Acc 0.957169459962756:\n",
      "18th- epoch: 38, train_loss = 1.867876524105668, train_acc = 0.9949930135072194\n",
      "test Acc 0.957635009310987:\n",
      "18th- epoch: 39, train_loss = 1.8193632178008556, train_acc = 0.9951094550535631\n",
      "test Acc 0.9581005586592178:\n",
      "18th- epoch: 40, train_loss = 1.7912899696966633, train_acc = 0.9951094550535631\n",
      "test Acc 0.9581005586592178:\n",
      "18th- epoch: 41, train_loss = 1.7559514120221138, train_acc = 0.9952258965999069\n",
      "test Acc 0.9590316573556797:\n",
      "18th- epoch: 42, train_loss = 1.7325167407980189, train_acc = 0.9956916627852818\n",
      "test Acc 0.9594972067039106:\n",
      "18th- epoch: 43, train_loss = 1.7020490150898695, train_acc = 0.9958081043316255\n",
      "test Acc 0.9590316573556797:\n",
      "18th- epoch: 44, train_loss = 1.682450651540421, train_acc = 0.9958081043316255\n",
      "test Acc 0.9599627560521415:\n",
      "18th- epoch: 45, train_loss = 1.656797481700778, train_acc = 0.9958081043316255\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 46, train_loss = 1.6423908695578575, train_acc = 0.9958081043316255\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 47, train_loss = 1.6192706311121583, train_acc = 0.9958081043316255\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 48, train_loss = 1.6076997959753498, train_acc = 0.9958081043316255\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 49, train_loss = 1.5912179112201557, train_acc = 0.9959245458779693\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 50, train_loss = 1.5742342844605446, train_acc = 0.996040987424313\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 51, train_loss = 1.56112038588617, train_acc = 0.996040987424313\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 52, train_loss = 1.5412829825654626, train_acc = 0.996040987424313\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 53, train_loss = 1.532191843376495, train_acc = 0.996040987424313\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 54, train_loss = 1.5144408071646467, train_acc = 0.996040987424313\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 55, train_loss = 1.5110284285619855, train_acc = 0.996040987424313\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 56, train_loss = 1.4939681282266974, train_acc = 0.9961574289706567\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 57, train_loss = 1.4808641243726015, train_acc = 0.996040987424313\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 58, train_loss = 1.475896927237045, train_acc = 0.9963903120633442\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 59, train_loss = 1.4597488011349924, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 60, train_loss = 1.4483170040766709, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 61, train_loss = 1.4431480352650397, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 62, train_loss = 1.4329521907493472, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 63, train_loss = 1.4259130523423664, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 64, train_loss = 1.413690622895956, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 65, train_loss = 1.4098521145060658, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 66, train_loss = 1.3995236695627682, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 67, train_loss = 1.3903819604893215, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 68, train_loss = 1.380222309671808, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 69, train_loss = 1.375765211880207, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 70, train_loss = 1.3687989146565087, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 71, train_loss = 1.3624585100333206, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 72, train_loss = 1.3579136462067254, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 73, train_loss = 1.3510573375970125, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 74, train_loss = 1.3457579311798327, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 75, train_loss = 1.3393510412424803, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 76, train_loss = 1.3392124848323874, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 77, train_loss = 1.3344747140072286, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 78, train_loss = 1.3254830581136048, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 79, train_loss = 1.3172253873199224, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 80, train_loss = 1.3140123854391277, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 81, train_loss = 1.3061590353026986, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 82, train_loss = 1.3069366876152344, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 83, train_loss = 1.2993087389622815, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 84, train_loss = 1.2970274705439806, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 85, train_loss = 1.2892993849818595, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 86, train_loss = 1.2860876529593952, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 87, train_loss = 1.2800043751485646, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 88, train_loss = 1.280484914779663, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 89, train_loss = 1.2725434904568829, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 90, train_loss = 1.2684812818770297, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 91, train_loss = 1.2679231162182987, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 92, train_loss = 1.2618116516096052, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 93, train_loss = 1.2571645743737463, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 94, train_loss = 1.2524432980862912, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 95, train_loss = 1.2478531303349882, train_acc = 0.9963903120633442\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 96, train_loss = 1.2477666305203456, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 97, train_loss = 1.240667392296018, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 98, train_loss = 1.2402090030082036, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 99, train_loss = 1.2396196873451117, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 100, train_loss = 1.2365795949008316, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 101, train_loss = 1.232783294719411, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 102, train_loss = 1.2359752838965505, train_acc = 0.9963903120633442\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 103, train_loss = 1.2272329540282954, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 104, train_loss = 1.2225570737791713, train_acc = 0.9963903120633442\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 105, train_loss = 1.2162455849174876, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 106, train_loss = 1.2138231116405223, train_acc = 0.9963903120633442\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 107, train_loss = 1.2146617935213726, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 108, train_loss = 1.2109001513454132, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 109, train_loss = 1.2075929438869935, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 110, train_loss = 1.2076586415350903, train_acc = 0.996506753609688\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 111, train_loss = 1.2060269002104178, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 112, train_loss = 1.2041564261890016, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 113, train_loss = 1.2015465187141672, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 114, train_loss = 1.2010891714307945, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 115, train_loss = 1.1943075624585617, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 116, train_loss = 1.1950972941413056, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 117, train_loss = 1.1953219008864835, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 118, train_loss = 1.1896203370997682, train_acc = 0.9967396367023754\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 119, train_loss = 1.1865804563567508, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 120, train_loss = 1.184016934625106, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 121, train_loss = 1.1808940524642821, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 122, train_loss = 1.179714091354981, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 123, train_loss = 1.1776863237901125, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 124, train_loss = 1.1743077999853995, train_acc = 0.9966231951560317\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 125, train_loss = 1.1745392264856491, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 126, train_loss = 1.1724995434342418, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 127, train_loss = 1.1708234754914884, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 128, train_loss = 1.1685405678581446, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 129, train_loss = 1.16583589813672, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 130, train_loss = 1.163650134956697, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 131, train_loss = 1.1646935101598501, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 132, train_loss = 1.1642435654066503, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 133, train_loss = 1.160747628804529, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 134, train_loss = 1.1615827911009546, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 135, train_loss = 1.158931733429199, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 136, train_loss = 1.1555423393438105, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 137, train_loss = 1.1562202190980315, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 138, train_loss = 1.1540201512689237, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 139, train_loss = 1.1529299397952855, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 140, train_loss = 1.1486283984559122, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 141, train_loss = 1.1490236252138857, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 142, train_loss = 1.1463113172503654, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 143, train_loss = 1.1479181575996336, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 144, train_loss = 1.146861307643121, train_acc = 0.9967396367023754\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 145, train_loss = 1.1448867341096047, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 146, train_loss = 1.1420646579936147, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 147, train_loss = 1.1421478292904794, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 148, train_loss = 1.1400060555897653, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 149, train_loss = 1.1391867330821697, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 150, train_loss = 1.1358564137481153, train_acc = 0.9968560782487191\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 151, train_loss = 1.1302664073591586, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 152, train_loss = 1.129575254075462, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 153, train_loss = 1.1278954083099961, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 154, train_loss = 1.1274087166821118, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 155, train_loss = 1.1251457963662688, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 156, train_loss = 1.1232383819296956, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 157, train_loss = 1.1246560642903205, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 158, train_loss = 1.121431509964168, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 159, train_loss = 1.1198683795519173, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 160, train_loss = 1.119818677805597, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 161, train_loss = 1.1169189270585775, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 162, train_loss = 1.1169520779512823, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 163, train_loss = 1.115223775152117, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 164, train_loss = 1.1145693428406958, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 165, train_loss = 1.1137597216293216, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 166, train_loss = 1.1117155213432852, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 167, train_loss = 1.1115664408134762, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 168, train_loss = 1.1093769116996555, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 169, train_loss = 1.110361619226751, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 170, train_loss = 1.1073385452182265, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 171, train_loss = 1.1076050329284044, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 172, train_loss = 1.1047634774149628, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 173, train_loss = 1.106876328587532, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 174, train_loss = 1.104284530505538, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 175, train_loss = 1.1018226351588964, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 176, train_loss = 1.1031724121421576, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 177, train_loss = 1.0993721590639325, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 178, train_loss = 1.099375958860037, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 179, train_loss = 1.0985407608823152, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 180, train_loss = 1.0962644992396235, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 181, train_loss = 1.0967664740310283, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 182, train_loss = 1.0950655213819118, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 183, train_loss = 1.0959028815850616, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 184, train_loss = 1.0924679907038808, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 185, train_loss = 1.0942695625126362, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 186, train_loss = 1.0904687795118662, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 187, train_loss = 1.0910947254596977, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 188, train_loss = 1.0898862567992182, train_acc = 0.9972054028877504\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 189, train_loss = 1.0886813756078482, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 190, train_loss = 1.0869491680787178, train_acc = 0.9970889613414066\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 191, train_loss = 1.086731712333858, train_acc = 0.9970889613414066\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 192, train_loss = 1.0847868292330531, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 193, train_loss = 1.0839863223955035, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 194, train_loss = 1.0857038516551256, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 195, train_loss = 1.082397323101759, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 196, train_loss = 1.0816732927487465, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 197, train_loss = 1.080171967856586, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 198, train_loss = 1.0818801491259364, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 199, train_loss = 1.078623756460729, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 200, train_loss = 1.0782403005287051, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 201, train_loss = 1.0766083216294646, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 202, train_loss = 1.0820537016988965, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 203, train_loss = 1.080892229147139, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 204, train_loss = 1.0797540489584208, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 205, train_loss = 1.0795482586399885, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 206, train_loss = 1.0784900200815173, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 207, train_loss = 1.0764977158978581, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 208, train_loss = 1.0753315991460113, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 209, train_loss = 1.0765650148241548, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 210, train_loss = 1.0765432240441442, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 211, train_loss = 1.0734228103683563, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 212, train_loss = 1.0728525227605132, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 213, train_loss = 1.0712303267791867, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 214, train_loss = 1.0730862505733967, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 215, train_loss = 1.0720135249866871, train_acc = 0.9972054028877504\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 216, train_loss = 1.0696194410993485, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 217, train_loss = 1.0685615679249167, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 218, train_loss = 1.069511107474682, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 219, train_loss = 1.0694050136953592, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 220, train_loss = 1.0668986250384478, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 221, train_loss = 1.0658612030820223, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 222, train_loss = 1.0651695715932874, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 223, train_loss = 1.0671201758086681, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 224, train_loss = 1.0636841375380754, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 225, train_loss = 1.0636979093105765, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 226, train_loss = 1.063516399517539, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 227, train_loss = 1.0623722529708175, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 228, train_loss = 1.0602259909064742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 229, train_loss = 1.0626448970288038, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 230, train_loss = 1.0618279107584385, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 231, train_loss = 1.0584863657131791, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 232, train_loss = 1.059953073039651, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 233, train_loss = 1.0573353258223506, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 234, train_loss = 1.0579029942600755, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 235, train_loss = 1.057825601354125, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 236, train_loss = 1.057146895371261, train_acc = 0.9972054028877504\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 237, train_loss = 1.0536957603617338, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 238, train_loss = 1.0571053909807233, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 239, train_loss = 1.0534093131573172, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 240, train_loss = 1.0523974420502782, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 241, train_loss = 1.053995911963284, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 242, train_loss = 1.050619796544197, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 243, train_loss = 1.0518601598887471, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 244, train_loss = 1.0511305341497064, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 245, train_loss = 1.0496820236294298, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 246, train_loss = 1.049509586460772, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 247, train_loss = 1.0490072462707758, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 248, train_loss = 1.0498344348743558, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 249, train_loss = 1.0472163086087676, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 250, train_loss = 1.046624003603938, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 251, train_loss = 1.0461151348426938, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 252, train_loss = 1.0445590037852526, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 253, train_loss = 1.045460233464837, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 254, train_loss = 1.0447916487901239, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 255, train_loss = 1.0439300574362278, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 256, train_loss = 1.0432186424732208, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 257, train_loss = 1.041648653030279, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 258, train_loss = 1.0425104914902477, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 259, train_loss = 1.04253114387393, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 260, train_loss = 1.0404419302940369, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 261, train_loss = 1.0420926244260045, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 262, train_loss = 1.0399772375822067, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 263, train_loss = 1.037761836007121, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 264, train_loss = 1.0379002249537734, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 265, train_loss = 1.0389520203025313, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 266, train_loss = 1.0354876176716061, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 267, train_loss = 1.0409624290914508, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 268, train_loss = 1.0374287360609742, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 269, train_loss = 1.0362712107598782, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 270, train_loss = 1.03832883015275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 271, train_loss = 1.0388888505549403, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 272, train_loss = 1.0385913103818893, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 273, train_loss = 1.0367679111659527, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 274, train_loss = 1.0367589270026656, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 275, train_loss = 1.0364607460796833, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 276, train_loss = 1.0362181744276313, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 277, train_loss = 1.0372520076780347, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 278, train_loss = 1.035250352069852, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 279, train_loss = 1.0363552539347438, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 280, train_loss = 1.0340683634130983, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 281, train_loss = 1.0350596203206806, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 282, train_loss = 1.032220458611846, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 283, train_loss = 1.0325585256068734, train_acc = 0.9973218444340941\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 284, train_loss = 1.0321089513599873, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 285, train_loss = 1.032480298235896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 286, train_loss = 1.0303700764925452, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 287, train_loss = 1.03096495445061, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 288, train_loss = 1.029157167300582, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 289, train_loss = 1.030335946008563, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 290, train_loss = 1.0269858657120494, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 291, train_loss = 1.0275133314280538, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 292, train_loss = 1.0230693320481805, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 293, train_loss = 1.0241160752921132, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 294, train_loss = 1.0223658618779154, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 295, train_loss = 1.0221848997025518, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 296, train_loss = 1.0225131710321875, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 297, train_loss = 1.0218835857958766, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 298, train_loss = 1.0224746211169986, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 299, train_loss = 1.0195985908358125, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 300, train_loss = 1.0192610720841913, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 301, train_loss = 1.021060336381197, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 302, train_loss = 1.0190247533173533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 303, train_loss = 1.0197435567824868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 304, train_loss = 1.0173158925026655, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 305, train_loss = 1.0182675514370203, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 306, train_loss = 1.0180400566459866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 307, train_loss = 1.0163977276533842, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 308, train_loss = 1.0146878262312384, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 309, train_loss = 1.016603301584837, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 310, train_loss = 1.0134310318826465, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 311, train_loss = 1.0107925018965034, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 312, train_loss = 1.0086275599896908, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 313, train_loss = 1.0084626891912194, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 314, train_loss = 1.009871395304799, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 315, train_loss = 1.0082300106732873, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 316, train_loss = 1.007522805899498, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 317, train_loss = 1.0059029081166955, train_acc = 0.9974382859804378\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 318, train_loss = 1.0086340717971325, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 319, train_loss = 1.0085959906427888, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 320, train_loss = 1.0105214801878901, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 321, train_loss = 1.0083171942533227, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 322, train_loss = 1.0070732620806666, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 323, train_loss = 1.0037370504142018, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 324, train_loss = 1.006007241710904, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 325, train_loss = 1.0040568001568317, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 326, train_loss = 1.0013578391371993, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 327, train_loss = 1.003268654763815, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 328, train_loss = 1.0010326572955819, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 329, train_loss = 1.002343180894968, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 330, train_loss = 0.9995119230152341, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 331, train_loss = 1.0046050337405177, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 332, train_loss = 1.0036130119115114, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 333, train_loss = 1.0033447202295065, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 334, train_loss = 1.0025035254657269, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 335, train_loss = 0.99958456618333, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 336, train_loss = 0.9982254523783922, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 337, train_loss = 1.003568430118321, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 338, train_loss = 1.0012099351733923, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 339, train_loss = 0.997649684548378, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 340, train_loss = 0.9964159727096558, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 341, train_loss = 0.9976199958473444, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 342, train_loss = 0.9964948855340481, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 343, train_loss = 1.0024353936314583, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 344, train_loss = 0.9982313476502895, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 345, train_loss = 0.9982919283211231, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 346, train_loss = 0.9940634376034723, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 347, train_loss = 0.9948838992640958, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 348, train_loss = 0.9966012251898064, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 349, train_loss = 0.9970001441761269, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 350, train_loss = 0.9961402850822196, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 351, train_loss = 0.9938892461359501, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 352, train_loss = 0.9912608799859299, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 353, train_loss = 0.9927333202213049, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 354, train_loss = 0.9911201111972332, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 355, train_loss = 0.9914317348375334, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 356, train_loss = 0.9903191669509397, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 357, train_loss = 0.989974665142654, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 358, train_loss = 0.9902763850986958, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 359, train_loss = 0.9902982339262962, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 360, train_loss = 0.98855967012787, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 361, train_loss = 0.9888545659705414, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 362, train_loss = 0.9888477163985954, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 363, train_loss = 0.9880200258121477, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 364, train_loss = 0.985870024189353, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 365, train_loss = 0.9867861140519381, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 366, train_loss = 0.9823964089155197, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 367, train_loss = 0.9834829159080982, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 368, train_loss = 0.9826599601656199, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 369, train_loss = 0.9872284090743051, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 370, train_loss = 0.9856038068755879, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 371, train_loss = 0.9853965286165476, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 372, train_loss = 0.9841667090877309, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 373, train_loss = 0.9836244862526655, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 374, train_loss = 0.9801285391076817, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 375, train_loss = 0.9795977398753166, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 376, train_loss = 0.9799248781055212, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 377, train_loss = 0.9788356199860573, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 378, train_loss = 0.9790953348056064, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 379, train_loss = 0.9790354097858653, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 380, train_loss = 0.977735610678792, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 381, train_loss = 0.9782665322200046, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 382, train_loss = 0.9777017856613384, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 383, train_loss = 0.9770952798426151, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 384, train_loss = 0.976933915168047, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 385, train_loss = 0.9809320699423552, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 386, train_loss = 0.9783353507518768, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 387, train_loss = 0.9756162228659377, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 388, train_loss = 0.9753142309709801, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 389, train_loss = 0.9752188014463172, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 390, train_loss = 0.9749966667368426, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 391, train_loss = 0.9741859051064239, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 392, train_loss = 0.9735173558219685, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 393, train_loss = 0.975261894367577, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 394, train_loss = 0.9732813493683352, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 395, train_loss = 0.9728953571393504, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 396, train_loss = 0.9741210496649728, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 397, train_loss = 0.9729705632998957, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 398, train_loss = 0.970922618485929, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 399, train_loss = 0.9729527762756334, train_acc = 0.9974382859804378\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 400, train_loss = 0.9710041719154106, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 401, train_loss = 0.9711426123976707, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 402, train_loss = 0.9701593363060965, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 403, train_loss = 0.9702623765915632, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 404, train_loss = 0.9706899890079512, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 405, train_loss = 0.9703356182799325, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 406, train_loss = 0.9689775872975588, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 407, train_loss = 0.9703453207985149, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 408, train_loss = 0.9725020844489336, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 409, train_loss = 0.9706966796293273, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 410, train_loss = 0.9690667632967234, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 411, train_loss = 0.967927514888288, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 412, train_loss = 0.9668162098751054, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 413, train_loss = 0.9667376379147754, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 414, train_loss = 0.9662716661914601, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 415, train_loss = 0.9672204243615852, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 416, train_loss = 0.9653010200709105, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 417, train_loss = 0.9656490397974267, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 418, train_loss = 0.9648468481973396, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 419, train_loss = 0.9645163634195342, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 420, train_loss = 0.9656300004571676, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 421, train_loss = 0.9642485411241069, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 422, train_loss = 0.9645068254321814, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 423, train_loss = 0.9654414169490337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 424, train_loss = 0.9630354388282285, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 425, train_loss = 0.9628289118409157, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 426, train_loss = 0.9627858294770704, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 427, train_loss = 0.9627715448514209, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 428, train_loss = 0.9673439754769788, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 429, train_loss = 0.96659546779847, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 430, train_loss = 0.9636713943109498, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 431, train_loss = 0.9628270299508586, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 432, train_loss = 0.9607938906774507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 433, train_loss = 0.9612267048432841, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 434, train_loss = 0.9611015176997171, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 435, train_loss = 0.964141434058547, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 436, train_loss = 0.9620109225288616, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 437, train_loss = 0.9641206500455155, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 438, train_loss = 0.9645181223750114, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 439, train_loss = 0.9644952062517405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 440, train_loss = 0.9629822274073376, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 441, train_loss = 0.9618904956951155, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 442, train_loss = 0.9577651489526033, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 443, train_loss = 0.961206728592515, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 444, train_loss = 0.9605041916147457, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 445, train_loss = 0.9623307306319475, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 446, train_loss = 0.9619102446959005, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 447, train_loss = 0.9623484040275798, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 448, train_loss = 0.9600654070600285, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 449, train_loss = 0.9600333211346879, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 450, train_loss = 0.9603511231616721, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 451, train_loss = 0.9601753366514458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 452, train_loss = 0.959874477237463, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 453, train_loss = 0.9596840658559813, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 454, train_loss = 0.9580649696290493, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 455, train_loss = 0.9584165774285793, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 456, train_loss = 0.9578809514641762, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 457, train_loss = 0.9569391869008541, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 458, train_loss = 0.9538764525204897, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 459, train_loss = 0.9573609170838608, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 460, train_loss = 0.954733374841453, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 461, train_loss = 0.9572198403402581, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 462, train_loss = 0.9571311914696707, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 463, train_loss = 0.9569376626386656, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 464, train_loss = 0.9541656405999674, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 465, train_loss = 0.9520609521641745, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 466, train_loss = 0.952450143173337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 467, train_loss = 0.9512128538117395, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 468, train_loss = 0.9510104227811098, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 469, train_loss = 0.9522484056651592, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 470, train_loss = 0.9499035552144051, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 471, train_loss = 0.9498330323622213, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 472, train_loss = 0.9504456333816051, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 473, train_loss = 0.9498758135960088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 474, train_loss = 0.9486011831686483, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 475, train_loss = 0.9512469830588088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 476, train_loss = 0.9481875697747455, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 477, train_loss = 0.9485697112977505, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 478, train_loss = 0.9496827616021619, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 479, train_loss = 0.9479139571412816, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 480, train_loss = 0.9476291798055172, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 481, train_loss = 0.9485830136909499, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 482, train_loss = 0.9468308283612714, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 483, train_loss = 0.9470222617164836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 484, train_loss = 0.947376719363092, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 485, train_loss = 0.9471966580822482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 486, train_loss = 0.9490979146212339, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 487, train_loss = 0.9498977561815991, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 488, train_loss = 0.9452562145888805, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 489, train_loss = 0.9451219905167818, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 490, train_loss = 0.9463556843475089, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 491, train_loss = 0.9455592073500156, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 492, train_loss = 0.9442744838670478, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 493, train_loss = 0.9451508366837515, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 494, train_loss = 0.9481878181322827, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 495, train_loss = 0.947749445833324, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 496, train_loss = 0.9448847702369676, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 497, train_loss = 0.944373456761241, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 498, train_loss = 0.9475287571549416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 499, train_loss = 0.9485720712691545, train_acc = 0.9974382859804378\n",
      "test Acc 0.9636871508379888:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████▌                              | 18/30 [2:55:58<2:05:01, 625.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "19th- epoch: 0, train_loss = 417.2371500059962, train_acc = 0.8020493712156498\n",
      "test Acc 0.861266294227188:\n",
      "19th- epoch: 1, train_loss = 103.86601189273642, train_acc = 0.9144154634373545\n",
      "test Acc 0.9231843575418994:\n",
      "19th- epoch: 2, train_loss = 62.96912042796612, train_acc = 0.9435258500232883\n",
      "test Acc 0.930633147113594:\n",
      "19th- epoch: 3, train_loss = 42.88109250366688, train_acc = 0.9576152771308803\n",
      "test Acc 0.9343575418994413:\n",
      "19th- epoch: 4, train_loss = 31.63156257818264, train_acc = 0.965649743828598\n",
      "test Acc 0.9371508379888268:\n",
      "19th- epoch: 5, train_loss = 24.32674576093632, train_acc = 0.970540288775035\n",
      "test Acc 0.9385474860335196:\n",
      "19th- epoch: 6, train_loss = 19.043873835355043, train_acc = 0.9760130414531905\n",
      "test Acc 0.9390130353817505:\n",
      "19th- epoch: 7, train_loss = 15.099521738789917, train_acc = 0.9796227293898463\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 8, train_loss = 12.204953838139772, train_acc = 0.9832324173265021\n",
      "test Acc 0.9427374301675978:\n",
      "19th- epoch: 9, train_loss = 10.001463231936214, train_acc = 0.9855612482533768\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 10, train_loss = 8.40059196203947, train_acc = 0.9869585468095017\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 11, train_loss = 7.170983916759724, train_acc = 0.9885887284583139\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 12, train_loss = 6.18921391791082, train_acc = 0.989869585468095\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 13, train_loss = 5.416249143570894, train_acc = 0.9906846762925011\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 14, train_loss = 4.816677711904049, train_acc = 0.9916162086632511\n",
      "test Acc 0.9478584729981379:\n",
      "19th- epoch: 15, train_loss = 4.314574525982607, train_acc = 0.992081974848626\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 16, train_loss = 3.9153081191470847, train_acc = 0.9924312994876572\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 17, train_loss = 3.5660560516407713, train_acc = 0.9928970656730322\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 18, train_loss = 3.260971220792271, train_acc = 0.9934792734047508\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 19, train_loss = 3.0199055013945326, train_acc = 0.9939450395901258\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 20, train_loss = 2.806048377067782, train_acc = 0.9941779226828132\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 21, train_loss = 2.6500913811614737, train_acc = 0.9945272473218444\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 22, train_loss = 2.4920668291160837, train_acc = 0.9945272473218444\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 23, train_loss = 2.3615723500261083, train_acc = 0.9946436888681882\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 24, train_loss = 2.2560218883445486, train_acc = 0.9946436888681882\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 25, train_loss = 2.139779604971409, train_acc = 0.9948765719608756\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 26, train_loss = 2.0656670270254835, train_acc = 0.9953423381462506\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 27, train_loss = 1.9856712991604581, train_acc = 0.995575221238938\n",
      "test Acc 0.952513966480447:\n",
      "19th- epoch: 28, train_loss = 1.9112370125949383, train_acc = 0.9958081043316255\n",
      "test Acc 0.9529795158286778:\n",
      "19th- epoch: 29, train_loss = 1.8666733143036254, train_acc = 0.9959245458779693\n",
      "test Acc 0.9534450651769087:\n",
      "19th- epoch: 30, train_loss = 1.802734023600351, train_acc = 0.9961574289706567\n",
      "test Acc 0.9534450651769087:\n",
      "19th- epoch: 31, train_loss = 1.7603327259421349, train_acc = 0.9963903120633442\n",
      "test Acc 0.9534450651769087:\n",
      "19th- epoch: 32, train_loss = 1.7160989518160932, train_acc = 0.9962738705170004\n",
      "test Acc 0.9539106145251397:\n",
      "19th- epoch: 33, train_loss = 1.686673243821133, train_acc = 0.9961574289706567\n",
      "test Acc 0.9539106145251397:\n",
      "19th- epoch: 34, train_loss = 1.6477834929828532, train_acc = 0.9962738705170004\n",
      "test Acc 0.9539106145251397:\n",
      "19th- epoch: 35, train_loss = 1.6253676588530652, train_acc = 0.9963903120633442\n",
      "test Acc 0.9543761638733705:\n",
      "19th- epoch: 36, train_loss = 1.601944098889362, train_acc = 0.9963903120633442\n",
      "test Acc 0.9543761638733705:\n",
      "19th- epoch: 37, train_loss = 1.5840843145851977, train_acc = 0.9963903120633442\n",
      "test Acc 0.9543761638733705:\n",
      "19th- epoch: 38, train_loss = 1.5579527554218657, train_acc = 0.996506753609688\n",
      "test Acc 0.9543761638733705:\n",
      "19th- epoch: 39, train_loss = 1.5519768458907492, train_acc = 0.9963903120633442\n",
      "test Acc 0.9543761638733705:\n",
      "19th- epoch: 40, train_loss = 1.5287057782406919, train_acc = 0.996506753609688\n",
      "test Acc 0.9548417132216015:\n",
      "19th- epoch: 41, train_loss = 1.5055988058447838, train_acc = 0.996506753609688\n",
      "test Acc 0.9553072625698324:\n",
      "19th- epoch: 42, train_loss = 1.4951341921987478, train_acc = 0.996506753609688\n",
      "test Acc 0.9553072625698324:\n",
      "19th- epoch: 43, train_loss = 1.4858028131129686, train_acc = 0.996506753609688\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 44, train_loss = 1.4683038530347403, train_acc = 0.996506753609688\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 45, train_loss = 1.461698363214964, train_acc = 0.9968560782487191\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 46, train_loss = 1.4461457108554896, train_acc = 0.9968560782487191\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 47, train_loss = 1.437235308199888, train_acc = 0.9969725197950629\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 48, train_loss = 1.4238585593702737, train_acc = 0.9969725197950629\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 49, train_loss = 1.4146339135768358, train_acc = 0.9969725197950629\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 50, train_loss = 1.4070124390127603, train_acc = 0.9970889613414066\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 51, train_loss = 1.397287618368864, train_acc = 0.9969725197950629\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 52, train_loss = 1.390090020984644, train_acc = 0.9970889613414066\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 53, train_loss = 1.380582603305811, train_acc = 0.9969725197950629\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 54, train_loss = 1.3736425960960332, train_acc = 0.9970889613414066\n",
      "test Acc 0.9553072625698324:\n",
      "19th- epoch: 55, train_loss = 1.3670207733812276, train_acc = 0.9970889613414066\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 56, train_loss = 1.3593783552350942, train_acc = 0.9970889613414066\n",
      "test Acc 0.9553072625698324:\n",
      "19th- epoch: 57, train_loss = 1.3523917756974697, train_acc = 0.9970889613414066\n",
      "test Acc 0.9553072625698324:\n",
      "19th- epoch: 58, train_loss = 1.346502815693384, train_acc = 0.9970889613414066\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 59, train_loss = 1.3364628218114376, train_acc = 0.9970889613414066\n",
      "test Acc 0.9562383612662942:\n",
      "19th- epoch: 60, train_loss = 1.3314201397297438, train_acc = 0.9970889613414066\n",
      "test Acc 0.9562383612662942:\n",
      "19th- epoch: 61, train_loss = 1.3270840930345003, train_acc = 0.9970889613414066\n",
      "test Acc 0.9567039106145251:\n",
      "19th- epoch: 62, train_loss = 1.3194918843655614, train_acc = 0.9970889613414066\n",
      "test Acc 0.9567039106145251:\n",
      "19th- epoch: 63, train_loss = 1.315326521798852, train_acc = 0.9970889613414066\n",
      "test Acc 0.9567039106145251:\n",
      "19th- epoch: 64, train_loss = 1.3118932209908962, train_acc = 0.9970889613414066\n",
      "test Acc 0.9567039106145251:\n",
      "19th- epoch: 65, train_loss = 1.3053184039890766, train_acc = 0.9972054028877504\n",
      "test Acc 0.9567039106145251:\n",
      "19th- epoch: 66, train_loss = 1.3004284339695005, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 67, train_loss = 1.2962446274905233, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 68, train_loss = 1.29347338154912, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 69, train_loss = 1.2878543895931216, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 70, train_loss = 1.2814084216952324, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 71, train_loss = 1.2803211733698845, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 72, train_loss = 1.2745926516799955, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 73, train_loss = 1.2702041044831276, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 74, train_loss = 1.2676375582814217, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 75, train_loss = 1.266513333961484, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 76, train_loss = 1.2603195284755202, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 77, train_loss = 1.2575496025383472, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 78, train_loss = 1.254560824483633, train_acc = 0.9972054028877504\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 79, train_loss = 1.25388253480196, train_acc = 0.9972054028877504\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 80, train_loss = 1.2471846702246694, train_acc = 0.9972054028877504\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 81, train_loss = 1.2448949341924163, train_acc = 0.9972054028877504\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 82, train_loss = 1.2416524402797222, train_acc = 0.9972054028877504\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 83, train_loss = 1.2411741899995832, train_acc = 0.9972054028877504\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 84, train_loss = 1.2357370853424072, train_acc = 0.9972054028877504\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 85, train_loss = 1.2335563984961482, train_acc = 0.9972054028877504\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 86, train_loss = 1.232121170804021, train_acc = 0.9972054028877504\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 87, train_loss = 1.2295165322721004, train_acc = 0.9973218444340941\n",
      "test Acc 0.9581005586592178:\n",
      "19th- epoch: 88, train_loss = 1.227901450052741, train_acc = 0.9972054028877504\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 89, train_loss = 1.2260960179119138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9581005586592178:\n",
      "19th- epoch: 90, train_loss = 1.2222085135726957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9581005586592178:\n",
      "19th- epoch: 91, train_loss = 1.218351174145937, train_acc = 0.9973218444340941\n",
      "test Acc 0.9581005586592178:\n",
      "19th- epoch: 92, train_loss = 1.2174571976065636, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "19th- epoch: 93, train_loss = 1.2148109947593184, train_acc = 0.9973218444340941\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 94, train_loss = 1.21240792547178, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 95, train_loss = 1.211010770246503, train_acc = 0.9973218444340941\n",
      "test Acc 0.9581005586592178:\n",
      "19th- epoch: 96, train_loss = 1.2098226038069697, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 97, train_loss = 1.2072795579879312, train_acc = 0.9972054028877504\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 98, train_loss = 1.2057905085384846, train_acc = 0.9973218444340941\n",
      "test Acc 0.9585661080074488:\n",
      "19th- epoch: 99, train_loss = 1.2049935472459765, train_acc = 0.9972054028877504\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 100, train_loss = 1.2013117472379236, train_acc = 0.9972054028877504\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 101, train_loss = 1.1995214819908142, train_acc = 0.9973218444340941\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 102, train_loss = 1.1975174956023693, train_acc = 0.9972054028877504\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 103, train_loss = 1.1945695405156584, train_acc = 0.9972054028877504\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 104, train_loss = 1.1943568264396163, train_acc = 0.9972054028877504\n",
      "test Acc 0.9594972067039106:\n",
      "19th- epoch: 105, train_loss = 1.1914459392428398, train_acc = 0.9972054028877504\n",
      "test Acc 0.9594972067039106:\n",
      "19th- epoch: 106, train_loss = 1.1893507142813178, train_acc = 0.9972054028877504\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 107, train_loss = 1.1881901174783707, train_acc = 0.9972054028877504\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 108, train_loss = 1.1870253644883633, train_acc = 0.9972054028877504\n",
      "test Acc 0.9594972067039106:\n",
      "19th- epoch: 109, train_loss = 1.1862091608345509, train_acc = 0.9972054028877504\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 110, train_loss = 1.1842087035329314, train_acc = 0.9972054028877504\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 111, train_loss = 1.1833612248301506, train_acc = 0.9972054028877504\n",
      "test Acc 0.9594972067039106:\n",
      "19th- epoch: 112, train_loss = 1.1824758214206668, train_acc = 0.9972054028877504\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 113, train_loss = 1.1787262608559104, train_acc = 0.9972054028877504\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 114, train_loss = 1.177718470498803, train_acc = 0.9972054028877504\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 115, train_loss = 1.1766874926834134, train_acc = 0.9972054028877504\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 116, train_loss = 1.1733438322989969, train_acc = 0.9973218444340941\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 117, train_loss = 1.1710270407347707, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 118, train_loss = 1.1692206958978204, train_acc = 0.9972054028877504\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 119, train_loss = 1.1677961113600759, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 120, train_loss = 1.1671335597784491, train_acc = 0.9973218444340941\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 121, train_loss = 1.1656262216420146, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 122, train_loss = 1.1652295018284349, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 123, train_loss = 1.1641849875450134, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 124, train_loss = 1.163333705320838, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 125, train_loss = 1.1605165600776672, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 126, train_loss = 1.158450902745244, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 127, train_loss = 1.1571629668324022, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 128, train_loss = 1.1575498841702938, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 129, train_loss = 1.155141585812089, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 130, train_loss = 1.1565953033714322, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 131, train_loss = 1.15449208766222, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 132, train_loss = 1.1529602855443954, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 133, train_loss = 1.1527119750826387, train_acc = 0.9973218444340941\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 134, train_loss = 1.1504553854465485, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 135, train_loss = 1.1508698823599843, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 136, train_loss = 1.148608785122633, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 137, train_loss = 1.1476929001510143, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 138, train_loss = 1.1469840444624424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 139, train_loss = 1.1454374243767234, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 140, train_loss = 1.1462359937577276, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 141, train_loss = 1.144649853304145, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 142, train_loss = 1.1422773611993762, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 143, train_loss = 1.1413679346442223, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 144, train_loss = 1.141060854002717, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 145, train_loss = 1.140362831458333, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 146, train_loss = 1.1384789807052584, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 147, train_loss = 1.137377026185277, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 148, train_loss = 1.1381218557507964, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 149, train_loss = 1.1355081088840961, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 150, train_loss = 1.1349785712809535, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 151, train_loss = 1.1348873997776536, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 152, train_loss = 1.1337548258452443, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 153, train_loss = 1.1327380413858918, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 154, train_loss = 1.1320911559014348, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 155, train_loss = 1.133721978709218, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 156, train_loss = 1.131434657916543, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 157, train_loss = 1.128628204271081, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 158, train_loss = 1.1293945548386546, train_acc = 0.9972054028877504\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 159, train_loss = 1.1285402153880568, train_acc = 0.9973218444340941\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 160, train_loss = 1.1277298666536808, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 161, train_loss = 1.1273355260491371, train_acc = 0.9972054028877504\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 162, train_loss = 1.126683176800725, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 163, train_loss = 1.1249157674610615, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 164, train_loss = 1.1245197231619386, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 165, train_loss = 1.1251365716307191, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 166, train_loss = 1.1223060985357733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 167, train_loss = 1.12304466094065, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 168, train_loss = 1.1210959417076083, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 169, train_loss = 1.1215631663799286, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 170, train_loss = 1.1217353592364816, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 171, train_loss = 1.1194857036025496, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 172, train_loss = 1.119001343846321, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 173, train_loss = 1.1181091864855262, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 174, train_loss = 1.1168063009827165, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 175, train_loss = 1.1165588485746412, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 176, train_loss = 1.1156950605363818, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 177, train_loss = 1.115706513330224, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 178, train_loss = 1.1143179958016844, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 179, train_loss = 1.1141744144260883, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 180, train_loss = 1.1128719175903825, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 181, train_loss = 1.1127811918704538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 182, train_loss = 1.1122119252831908, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 183, train_loss = 1.1104887972323922, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 184, train_loss = 1.1104615529329749, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 185, train_loss = 1.1097718750388594, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 186, train_loss = 1.108864496149181, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 187, train_loss = 1.1111706433221116, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 188, train_loss = 1.1078688738271012, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 189, train_loss = 1.1073599681258202, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 190, train_loss = 1.1059782740994706, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 191, train_loss = 1.105849972613214, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 192, train_loss = 1.1048690751194954, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 193, train_loss = 1.1076210476458073, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 194, train_loss = 1.103895137704967, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 195, train_loss = 1.1038190834224224, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 196, train_loss = 1.1028063967823982, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 197, train_loss = 1.103252287954092, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 198, train_loss = 1.1021943402811303, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 199, train_loss = 1.1006199258044944, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 200, train_loss = 1.1032642535865307, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 201, train_loss = 1.1001184036358609, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 202, train_loss = 1.099913918726088, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 203, train_loss = 1.0979084062055335, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 204, train_loss = 1.0972628531380906, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 205, train_loss = 1.096849904708506, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 206, train_loss = 1.1018674025908695, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 207, train_loss = 1.0973289807661786, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 208, train_loss = 1.0953468258157955, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 209, train_loss = 1.0956989228725433, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 210, train_loss = 1.0947780522183166, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 211, train_loss = 1.0946536151095643, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 212, train_loss = 1.094103572271706, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 213, train_loss = 1.0930927818044438, train_acc = 0.9975547275267815\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 214, train_loss = 1.0953211983069195, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 215, train_loss = 1.0924821508451714, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 216, train_loss = 1.0918911211192608, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 217, train_loss = 1.0909673310816288, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 218, train_loss = 1.0901951057239785, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 219, train_loss = 1.0907561903222813, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 220, train_loss = 1.0897484173401608, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 221, train_loss = 1.087814790509583, train_acc = 0.9975547275267815\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 222, train_loss = 1.0933095229192986, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 223, train_loss = 1.0885446704924107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 224, train_loss = 1.0879012954756035, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 225, train_loss = 1.0874949035569443, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 226, train_loss = 1.0871332908645854, train_acc = 0.9975547275267815\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 227, train_loss = 1.08626512686169, train_acc = 0.9975547275267815\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 228, train_loss = 1.086430517338158, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 229, train_loss = 1.0841682814061642, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 230, train_loss = 1.087614081799984, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 231, train_loss = 1.0836203582584858, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 232, train_loss = 1.0832863996402011, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 233, train_loss = 1.0823550075292587, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 234, train_loss = 1.0823138331397786, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 235, train_loss = 1.084044129900576, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 236, train_loss = 1.0818235240876675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 237, train_loss = 1.0818178417757736, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 238, train_loss = 1.0803263038396835, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 239, train_loss = 1.0831241148189292, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 240, train_loss = 1.080411657691002, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 241, train_loss = 1.0783717831000104, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 242, train_loss = 1.0792032716199174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 243, train_loss = 1.077691721417068, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 244, train_loss = 1.0767447066828026, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 245, train_loss = 1.0802974080070271, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 246, train_loss = 1.0784425499514327, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 247, train_loss = 1.0768830838278518, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 248, train_loss = 1.076472993940115, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 249, train_loss = 1.0754499311224208, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 250, train_loss = 1.0751028868035064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 251, train_loss = 1.0749436753467307, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 252, train_loss = 1.073461397238134, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 253, train_loss = 1.0761781210676418, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 254, train_loss = 1.0725218902007327, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 255, train_loss = 1.0724662716165767, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 256, train_loss = 1.0721361910327687, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 257, train_loss = 1.0729670735672698, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 258, train_loss = 1.0714818611741066, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 259, train_loss = 1.0704434576109634, train_acc = 0.9975547275267815\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 260, train_loss = 1.0715655758976936, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 261, train_loss = 1.0698821482583298, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 262, train_loss = 1.071985837072134, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 263, train_loss = 1.0692420899868011, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 264, train_loss = 1.0700709968805313, train_acc = 0.9974382859804378\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 265, train_loss = 1.0683237587436452, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 266, train_loss = 1.0679904458447709, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 267, train_loss = 1.0669498927891254, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 268, train_loss = 1.067106768488884, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 269, train_loss = 1.0666799284517765, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 270, train_loss = 1.0669856667518616, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 271, train_loss = 1.0652293811217532, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 272, train_loss = 1.0675731835290208, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 273, train_loss = 1.0645597179754986, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 274, train_loss = 1.0660041483715759, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 275, train_loss = 1.0640693542882218, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 276, train_loss = 1.0635590280071483, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 277, train_loss = 1.0616982840001583, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 278, train_loss = 1.0660599668844952, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 279, train_loss = 1.062772778175713, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 280, train_loss = 1.0612018940373673, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 281, train_loss = 1.060783240944147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 282, train_loss = 1.061769234634994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 283, train_loss = 1.060407418757677, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 284, train_loss = 1.0593078061938286, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 285, train_loss = 1.0592438466846943, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 286, train_loss = 1.0579796644524322, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 287, train_loss = 1.061600939683558, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 288, train_loss = 1.05761554712808, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 289, train_loss = 1.0574225311502232, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 290, train_loss = 1.056904907025455, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 291, train_loss = 1.0582312680780888, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 292, train_loss = 1.0570234681144939, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 293, train_loss = 1.0558699443936348, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 294, train_loss = 1.054409109055996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 295, train_loss = 1.0587411584929214, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 296, train_loss = 1.0548420945779071, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 297, train_loss = 1.0538078621029854, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 298, train_loss = 1.05314977964008, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 299, train_loss = 1.053139774747251, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 300, train_loss = 1.0536407704130397, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 301, train_loss = 1.0527965066357865, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 302, train_loss = 1.0517385018392815, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 303, train_loss = 1.0510711980386986, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 304, train_loss = 1.0523113757371902, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 305, train_loss = 1.0517387924119248, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 306, train_loss = 1.0500340200960636, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 307, train_loss = 1.0525923855602741, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 308, train_loss = 1.0494392563923611, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 309, train_loss = 1.0504128982647671, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 310, train_loss = 1.0493957052603946, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 311, train_loss = 1.0492408660575165, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 312, train_loss = 1.0478812629953609, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 313, train_loss = 1.0476275533437729, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 314, train_loss = 1.0485950273796334, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 315, train_loss = 1.0475000689402805, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 316, train_loss = 1.0466080568730831, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 317, train_loss = 1.0462468229234219, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 318, train_loss = 1.0499018256887211, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 319, train_loss = 1.0461507514119148, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 320, train_loss = 1.0450037481859908, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 321, train_loss = 1.0447320590392337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 322, train_loss = 1.0443009634836926, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 323, train_loss = 1.0439148843288422, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 324, train_loss = 1.0447155150250182, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 325, train_loss = 1.0435662865638733, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 326, train_loss = 1.0430777991787181, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 327, train_loss = 1.0424671073778882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 328, train_loss = 1.0418465994298458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 329, train_loss = 1.0428603341206326, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 330, train_loss = 1.041186898946762, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 331, train_loss = 1.0441079015508876, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 332, train_loss = 1.0407048004344688, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 333, train_loss = 1.0403564708904014, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 334, train_loss = 1.0396675753072486, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 335, train_loss = 1.0395480133593082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 336, train_loss = 1.038848993681313, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 337, train_loss = 1.038511261343956, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 338, train_loss = 1.0398097137585864, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 339, train_loss = 1.0388894962743507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 340, train_loss = 1.038116725780128, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 341, train_loss = 1.0371072006746545, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 342, train_loss = 1.0370412679985748, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 343, train_loss = 1.0366504900157452, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 344, train_loss = 1.0375087869688286, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 345, train_loss = 1.03608677288139, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 346, train_loss = 1.038507538534759, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 347, train_loss = 1.0352543046101346, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 348, train_loss = 1.0347736328840256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 349, train_loss = 1.034149095416069, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 350, train_loss = 1.0342455779536976, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 351, train_loss = 1.0352751389145851, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 352, train_loss = 1.0345701562837348, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 353, train_loss = 1.0328896939754486, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 354, train_loss = 1.033010375998856, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 355, train_loss = 1.0325676947832108, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 356, train_loss = 1.0320020367726102, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 357, train_loss = 1.0331664234399796, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 358, train_loss = 1.0318150793536915, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 359, train_loss = 1.0349881363435998, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 360, train_loss = 1.0310375044718967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 361, train_loss = 1.0303857910112129, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 362, train_loss = 1.0300060411318555, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 363, train_loss = 1.031076230108738, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 364, train_loss = 1.0300408874973073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 365, train_loss = 1.0293135978281498, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 366, train_loss = 1.0289321516975178, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 367, train_loss = 1.02855797981465, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 368, train_loss = 1.0280098455623374, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 369, train_loss = 1.0288120545446873, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 370, train_loss = 1.0279324501752853, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 371, train_loss = 1.027704980224371, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 372, train_loss = 1.0272223092615604, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 373, train_loss = 1.026498954743147, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 374, train_loss = 1.0254350068644271, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 375, train_loss = 1.0295312975868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 376, train_loss = 1.026409546531795, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 377, train_loss = 1.0257950549348607, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 378, train_loss = 1.0253197091296897, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 379, train_loss = 1.024326529353857, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 380, train_loss = 1.02402750775218, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 381, train_loss = 1.0250250101089478, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 382, train_loss = 1.0240331453605904, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 383, train_loss = 1.0247276114896522, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 384, train_loss = 1.0243678763508797, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 385, train_loss = 1.0228498466312885, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 386, train_loss = 1.0227249090894475, train_acc = 0.9975547275267815\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 387, train_loss = 1.021951600909233, train_acc = 0.9975547275267815\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 388, train_loss = 1.0231636290773167, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 389, train_loss = 1.0221580093129887, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 390, train_loss = 1.0209166208878742, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 391, train_loss = 1.0236951783299446, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 392, train_loss = 1.0206654220819473, train_acc = 0.9974382859804378\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 393, train_loss = 1.0203601034954772, train_acc = 0.9975547275267815\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 394, train_loss = 1.0196480626837001, train_acc = 0.9975547275267815\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 395, train_loss = 1.0198760330677032, train_acc = 0.9975547275267815\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 396, train_loss = 1.0189361634329543, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 397, train_loss = 1.0197314831093536, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 398, train_loss = 1.019618990518211, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 399, train_loss = 1.0184960874394164, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 400, train_loss = 1.0183476606980548, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 401, train_loss = 1.0178797530606971, train_acc = 0.9975547275267815\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 402, train_loss = 1.017734811954142, train_acc = 0.9975547275267815\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 403, train_loss = 1.018446296453476, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 404, train_loss = 1.0174852038398967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 405, train_loss = 1.016697309911251, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 406, train_loss = 1.0165394519790425, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 407, train_loss = 1.0157693065702915, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 408, train_loss = 1.0181635729968548, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 409, train_loss = 1.015212383121252, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 410, train_loss = 1.0146296210587025, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 411, train_loss = 1.0151539432481513, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 412, train_loss = 1.0147948190569878, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 413, train_loss = 1.0140931084752083, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 414, train_loss = 1.0144100065008388, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 415, train_loss = 1.0150028218849911, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 416, train_loss = 1.013283334672451, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 417, train_loss = 1.0138935185968876, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 418, train_loss = 1.0132309732362046, train_acc = 0.9974382859804378\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 419, train_loss = 1.0123938359320164, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 420, train_loss = 1.0127186439931393, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 421, train_loss = 1.0118815874084248, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 422, train_loss = 1.0113701013251557, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 423, train_loss = 1.0118061862885952, train_acc = 0.9975547275267815\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 424, train_loss = 1.0124913255349384, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 425, train_loss = 1.0136475351973786, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 426, train_loss = 1.0106122816578136, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 427, train_loss = 1.010305383555533, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 428, train_loss = 1.0108284813686623, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 429, train_loss = 1.0095120829864754, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 430, train_loss = 1.0092889554798603, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 431, train_loss = 1.0089040237144218, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 432, train_loss = 1.0089070623143925, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 433, train_loss = 1.008871104568243, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 434, train_loss = 1.0080918607636704, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 435, train_loss = 1.0078706666827202, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 436, train_loss = 1.0086689082309022, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 437, train_loss = 1.0080030014141812, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 438, train_loss = 1.007318786032556, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 439, train_loss = 1.0072142779827118, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 440, train_loss = 1.00638934597373, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 441, train_loss = 1.0090909600257874, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 442, train_loss = 1.0062239033504738, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 443, train_loss = 1.0069189903661027, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 444, train_loss = 1.005941258124949, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 445, train_loss = 1.0055487751960754, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 446, train_loss = 1.0049494169652462, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 447, train_loss = 1.0049902337268577, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 448, train_loss = 1.0055418138726964, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 449, train_loss = 1.00482949862635, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 450, train_loss = 1.0041830825284705, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 451, train_loss = 1.0029631877914653, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 452, train_loss = 1.0038812259808765, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 453, train_loss = 1.0032517400904908, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 454, train_loss = 1.0036344987674966, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 455, train_loss = 1.0030099811629043, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 456, train_loss = 1.0036023246721015, train_acc = 0.9974382859804378\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 457, train_loss = 1.0031754548326717, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 458, train_loss = 1.0024012463763938, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 459, train_loss = 1.0020951951519237, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 460, train_loss = 1.0009025049730553, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 461, train_loss = 1.0046099523679004, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 462, train_loss = 1.0024543454273953, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 463, train_loss = 1.0003000969663844, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 464, train_loss = 0.9996171072125435, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 465, train_loss = 0.9992704639807926, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 466, train_loss = 0.9995967820286751, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 467, train_loss = 0.9997575196102844, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 468, train_loss = 0.9995026141405106, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 469, train_loss = 0.9990386801437126, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 470, train_loss = 0.9982733850702061, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 471, train_loss = 0.9984661377966404, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 472, train_loss = 0.9976180853918777, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 473, train_loss = 1.0013983796015964, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 474, train_loss = 0.9979271963238716, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 475, train_loss = 0.9979048868044629, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 476, train_loss = 0.9970084726810455, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 477, train_loss = 0.9970183273180737, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 478, train_loss = 0.997613384075521, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 479, train_loss = 0.9967998427673592, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 480, train_loss = 0.9968836990519776, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 481, train_loss = 0.996863550193666, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 482, train_loss = 0.995340671390295, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 483, train_loss = 0.9963422330692993, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 484, train_loss = 0.9956728604956879, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 485, train_loss = 0.9950120635330677, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 486, train_loss = 0.9948321605697856, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 487, train_loss = 0.994389858096838, train_acc = 0.9975547275267815\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 488, train_loss = 0.9946400163098588, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 489, train_loss = 0.9947059229016304, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 490, train_loss = 0.9941747871562256, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 491, train_loss = 0.9926084627732052, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 492, train_loss = 0.9958097599446774, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 493, train_loss = 0.9930839488879428, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 494, train_loss = 0.9945574390367256, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 495, train_loss = 0.9931375371888862, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 496, train_loss = 0.9927658562883153, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 497, train_loss = 0.9913378146811738, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 498, train_loss = 0.9910419111474766, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 499, train_loss = 0.992311529815197, train_acc = 0.9975547275267815\n",
      "test Acc 0.962756052141527:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|████████████████████████████████████████████████▏                           | 19/30 [3:06:22<1:54:33, 624.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "20th- epoch: 0, train_loss = 424.2710861861706, train_acc = 0.7945971122496507\n",
      "test Acc 0.883147113594041:\n",
      "20th- epoch: 1, train_loss = 100.66903633874608, train_acc = 0.9187238006520727\n",
      "test Acc 0.9292364990689013:\n",
      "20th- epoch: 2, train_loss = 63.88248936086893, train_acc = 0.9429436422915697\n",
      "test Acc 0.9385474860335196:\n",
      "20th- epoch: 3, train_loss = 44.92394537734799, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 4, train_loss = 33.7376263482729, train_acc = 0.9648346530041919\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 5, train_loss = 25.903825518325903, train_acc = 0.9707731718677224\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 6, train_loss = 20.39844171272125, train_acc = 0.9760130414531905\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 7, train_loss = 16.478284747630823, train_acc = 0.9809035863996274\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 8, train_loss = 13.429674146085745, train_acc = 0.9831159757801584\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 9, train_loss = 11.23629949055612, train_acc = 0.9853283651606893\n",
      "test Acc 0.9529795158286778:\n",
      "20th- epoch: 10, train_loss = 9.592804187283036, train_acc = 0.9867256637168141\n",
      "test Acc 0.952513966480447:\n",
      "20th- epoch: 11, train_loss = 8.275605499118683, train_acc = 0.9890544946436889\n",
      "test Acc 0.9534450651769087:\n",
      "20th- epoch: 12, train_loss = 7.282691343993065, train_acc = 0.9897531439217513\n",
      "test Acc 0.9543761638733705:\n",
      "20th- epoch: 13, train_loss = 6.436531480401754, train_acc = 0.9905682347461574\n",
      "test Acc 0.9553072625698324:\n",
      "20th- epoch: 14, train_loss = 5.778851126640802, train_acc = 0.9911504424778761\n",
      "test Acc 0.9548417132216015:\n",
      "20th- epoch: 15, train_loss = 5.190244171768427, train_acc = 0.9916162086632511\n",
      "test Acc 0.9557728119180633:\n",
      "20th- epoch: 16, train_loss = 4.715729995310539, train_acc = 0.9919655333022822\n",
      "test Acc 0.9557728119180633:\n",
      "20th- epoch: 17, train_loss = 4.3238280192017555, train_acc = 0.9924312994876572\n",
      "test Acc 0.9562383612662942:\n",
      "20th- epoch: 18, train_loss = 3.9653079695999622, train_acc = 0.9930135072193759\n",
      "test Acc 0.9562383612662942:\n",
      "20th- epoch: 19, train_loss = 3.676588434726, train_acc = 0.9930135072193759\n",
      "test Acc 0.9562383612662942:\n",
      "20th- epoch: 20, train_loss = 3.382353742897976, train_acc = 0.9932463903120633\n",
      "test Acc 0.9567039106145251:\n",
      "20th- epoch: 21, train_loss = 3.1467216263408773, train_acc = 0.9933628318584071\n",
      "test Acc 0.957169459962756:\n",
      "20th- epoch: 22, train_loss = 2.9382660699193366, train_acc = 0.993828598043782\n",
      "test Acc 0.9567039106145251:\n",
      "20th- epoch: 23, train_loss = 2.7604127029771917, train_acc = 0.9941779226828132\n",
      "test Acc 0.9567039106145251:\n",
      "20th- epoch: 24, train_loss = 2.6116393047268502, train_acc = 0.9941779226828132\n",
      "test Acc 0.9567039106145251:\n",
      "20th- epoch: 25, train_loss = 2.4825537651777267, train_acc = 0.9944108057755007\n",
      "test Acc 0.957635009310987:\n",
      "20th- epoch: 26, train_loss = 2.361601068347227, train_acc = 0.9946436888681882\n",
      "test Acc 0.9585661080074488:\n",
      "20th- epoch: 27, train_loss = 2.261168359487783, train_acc = 0.9953423381462506\n",
      "test Acc 0.9581005586592178:\n",
      "20th- epoch: 28, train_loss = 2.1715789325535297, train_acc = 0.995575221238938\n",
      "test Acc 0.9585661080074488:\n",
      "20th- epoch: 29, train_loss = 2.0847951732575893, train_acc = 0.9958081043316255\n",
      "test Acc 0.9590316573556797:\n",
      "20th- epoch: 30, train_loss = 2.008174804330338, train_acc = 0.9959245458779693\n",
      "test Acc 0.9585661080074488:\n",
      "20th- epoch: 31, train_loss = 1.9377413640613668, train_acc = 0.9959245458779693\n",
      "test Acc 0.9590316573556797:\n",
      "20th- epoch: 32, train_loss = 1.8809526922996156, train_acc = 0.9959245458779693\n",
      "test Acc 0.9594972067039106:\n",
      "20th- epoch: 33, train_loss = 1.82626648619771, train_acc = 0.9959245458779693\n",
      "test Acc 0.9599627560521415:\n",
      "20th- epoch: 34, train_loss = 1.775307637930382, train_acc = 0.996040987424313\n",
      "test Acc 0.9604283054003724:\n",
      "20th- epoch: 35, train_loss = 1.7361264464561827, train_acc = 0.9961574289706567\n",
      "test Acc 0.9604283054003724:\n",
      "20th- epoch: 36, train_loss = 1.6943757993285544, train_acc = 0.9962738705170004\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 37, train_loss = 1.6589797586202621, train_acc = 0.9962738705170004\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 38, train_loss = 1.6236677480046637, train_acc = 0.9962738705170004\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 39, train_loss = 1.5925296979839914, train_acc = 0.9962738705170004\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 40, train_loss = 1.5610248893499374, train_acc = 0.9961574289706567\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 41, train_loss = 1.5316136169130914, train_acc = 0.9961574289706567\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 42, train_loss = 1.49949474260211, train_acc = 0.9961574289706567\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 43, train_loss = 1.4745200648903847, train_acc = 0.9961574289706567\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 44, train_loss = 1.4557709370856173, train_acc = 0.9961574289706567\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 45, train_loss = 1.4382616244256496, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 46, train_loss = 1.4246116665308364, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 47, train_loss = 1.4131139293313026, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 48, train_loss = 1.3998755986394826, train_acc = 0.9961574289706567\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 49, train_loss = 1.3937489092350006, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 50, train_loss = 1.3834200253186282, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 51, train_loss = 1.374379638582468, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 52, train_loss = 1.3660461778345052, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 53, train_loss = 1.3569738529622555, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 54, train_loss = 1.3530781964363996, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 55, train_loss = 1.344914590328699, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 56, train_loss = 1.3387513346970081, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 57, train_loss = 1.3315587478282396, train_acc = 0.9963903120633442\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 58, train_loss = 1.3251638635993004, train_acc = 0.9963903120633442\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 59, train_loss = 1.3199072455463465, train_acc = 0.9963903120633442\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 60, train_loss = 1.3157524379494134, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 61, train_loss = 1.3100216823222581, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 62, train_loss = 1.3047054236230906, train_acc = 0.996506753609688\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 63, train_loss = 1.3002406942250673, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 64, train_loss = 1.2958982959389687, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 65, train_loss = 1.2920498363673687, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 66, train_loss = 1.2884209007024765, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 67, train_loss = 1.284085607767338, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 68, train_loss = 1.2793455806968268, train_acc = 0.9966231951560317\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 69, train_loss = 1.2747438760998193, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 70, train_loss = 1.2733030194940511, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 71, train_loss = 1.2678853919205721, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 72, train_loss = 1.2657933843729552, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 73, train_loss = 1.2608193047344685, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 74, train_loss = 1.259788304567337, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 75, train_loss = 1.2557491449115332, train_acc = 0.9966231951560317\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 76, train_loss = 1.2545705698430538, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 77, train_loss = 1.249140319734579, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 78, train_loss = 1.2461002518830355, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 79, train_loss = 1.243027150630951, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 80, train_loss = 1.2396492088737432, train_acc = 0.9966231951560317\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 81, train_loss = 1.238888685911661, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 82, train_loss = 1.2338108705880586, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 83, train_loss = 1.2333425407705363, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 84, train_loss = 1.2283634754421655, train_acc = 0.9966231951560317\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 85, train_loss = 1.2274132743477821, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 86, train_loss = 1.223614364862442, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 87, train_loss = 1.2237270908954088, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 88, train_loss = 1.2187253783049528, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 89, train_loss = 1.2174595780670643, train_acc = 0.9967396367023754\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 90, train_loss = 1.2105413104000036, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 91, train_loss = 1.2096954559383448, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 92, train_loss = 1.2061369009315968, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 93, train_loss = 1.2061465568840504, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 94, train_loss = 1.2028662127850112, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 95, train_loss = 1.20103488364839, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 96, train_loss = 1.1999926827847958, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 97, train_loss = 1.1972475548682269, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 98, train_loss = 1.195340989768738, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 99, train_loss = 1.1950537959637586, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 100, train_loss = 1.1911948136985302, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 101, train_loss = 1.1918796636164188, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 102, train_loss = 1.1885490293207113, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 103, train_loss = 1.1890589085815009, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 104, train_loss = 1.1844113878905773, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 105, train_loss = 1.1850249419512693, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 106, train_loss = 1.1815919553337153, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 107, train_loss = 1.1813112162053585, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 108, train_loss = 1.1779687938687857, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 109, train_loss = 1.1770526754262391, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 110, train_loss = 1.1773316102626268, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 111, train_loss = 1.174576881021494, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 112, train_loss = 1.173927377909422, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 113, train_loss = 1.1712642895727186, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 114, train_loss = 1.1702739683241816, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 115, train_loss = 1.1684292157442542, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 116, train_loss = 1.1695138774812222, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 117, train_loss = 1.1645886140613584, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 118, train_loss = 1.166093652442214, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 119, train_loss = 1.1624857981951209, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 120, train_loss = 1.163187824189663, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 121, train_loss = 1.160257127135992, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 122, train_loss = 1.1589181162416935, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 123, train_loss = 1.1594968885183334, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 124, train_loss = 1.1565916389226913, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 125, train_loss = 1.157127719372511, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 126, train_loss = 1.1536329935042886, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 127, train_loss = 1.1531891574413748, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 128, train_loss = 1.1537108359189006, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 129, train_loss = 1.1504914251418086, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 130, train_loss = 1.1513705303223105, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 131, train_loss = 1.1482689430267783, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 132, train_loss = 1.148790525898221, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 133, train_loss = 1.146950741604087, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 134, train_loss = 1.1437773493380519, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 135, train_loss = 1.145251331225154, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 136, train_loss = 1.142396830022335, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 137, train_loss = 1.1431057242007228, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 138, train_loss = 1.1401426966040162, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 139, train_loss = 1.1394146929233102, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 140, train_loss = 1.1398970112204552, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 141, train_loss = 1.1370543539524078, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 142, train_loss = 1.136427481964347, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 143, train_loss = 1.1367771079094382, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 144, train_loss = 1.134163233145955, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 145, train_loss = 1.1332673418073682, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 146, train_loss = 1.1338417939841747, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 147, train_loss = 1.1312083887605695, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 148, train_loss = 1.130494736135006, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 149, train_loss = 1.1289520487189293, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 150, train_loss = 1.1300033902080031, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 151, train_loss = 1.1270388662815094, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 152, train_loss = 1.128505082175252, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 153, train_loss = 1.1242515072226524, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 154, train_loss = 1.123494379222393, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 155, train_loss = 1.1247624841780635, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 156, train_loss = 1.1219247790722875, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 157, train_loss = 1.1214922070503235, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 158, train_loss = 1.1201122316269903, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 159, train_loss = 1.1212040111422539, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 160, train_loss = 1.1179891253559617, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 161, train_loss = 1.1194012997002574, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 162, train_loss = 1.1167287304997444, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 163, train_loss = 1.1158622168004513, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 164, train_loss = 1.116949790462968, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 165, train_loss = 1.1141301306633977, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 166, train_loss = 1.115152519196272, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 167, train_loss = 1.111848543092492, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 168, train_loss = 1.1110154800117016, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 169, train_loss = 1.1119848353118869, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 170, train_loss = 1.1095044985413551, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 171, train_loss = 1.10857501749706, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 172, train_loss = 1.107893196240184, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 173, train_loss = 1.1089775798172923, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 174, train_loss = 1.1056427471339703, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 175, train_loss = 1.10698401927948, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 176, train_loss = 1.1046099166123895, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 177, train_loss = 1.104067234948161, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 178, train_loss = 1.102846723049879, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 179, train_loss = 1.1039018891751766, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 180, train_loss = 1.1009698708803626, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 181, train_loss = 1.1023652479052544, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 182, train_loss = 1.0999544846563367, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 183, train_loss = 1.0987061485648155, train_acc = 0.9969725197950629\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 184, train_loss = 1.0980524284095736, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 185, train_loss = 1.098616128161666, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 186, train_loss = 1.096590959772584, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 187, train_loss = 1.0954477501363726, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 188, train_loss = 1.0964827562420396, train_acc = 0.9970889613414066\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 189, train_loss = 1.0938686020672321, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 190, train_loss = 1.0935333582310705, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 191, train_loss = 1.094336062669754, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 192, train_loss = 1.0917213410139084, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 193, train_loss = 1.0911941143422155, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 194, train_loss = 1.0918083811848192, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 195, train_loss = 1.089858803898096, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 196, train_loss = 1.0889275185763836, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 197, train_loss = 1.0901248082518578, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 198, train_loss = 1.0873207127006026, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 199, train_loss = 1.0881467200815678, train_acc = 0.9972054028877504\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 200, train_loss = 1.0860918896942167, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 201, train_loss = 1.0852700086979894, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 202, train_loss = 1.0863346196711063, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 203, train_loss = 1.0841351486742496, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 204, train_loss = 1.0834223553538322, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 205, train_loss = 1.0822684615850449, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 206, train_loss = 1.0833376124501228, train_acc = 0.9973218444340941\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 207, train_loss = 1.0810713892133208, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 208, train_loss = 1.0798258955328492, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 209, train_loss = 1.0811922277061967, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 210, train_loss = 1.079147166266921, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 211, train_loss = 1.078399361416814, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 212, train_loss = 1.0795420445501804, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 213, train_loss = 1.077539739504573, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 214, train_loss = 1.076478489980218, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 215, train_loss = 1.0774317967443494, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 216, train_loss = 1.075090665370226, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 217, train_loss = 1.0744564036576776, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 218, train_loss = 1.073833655565977, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 219, train_loss = 1.075276563569787, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 220, train_loss = 1.0724746622145176, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 221, train_loss = 1.0718903131783009, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 222, train_loss = 1.0733054292650195, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 223, train_loss = 1.0709729914815398, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 224, train_loss = 1.070091873407364, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 225, train_loss = 1.0714721245021792, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 226, train_loss = 1.0691531797201606, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 227, train_loss = 1.067943874746561, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 228, train_loss = 1.069719236344099, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 229, train_loss = 1.0672039687633514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 230, train_loss = 1.066558949649334, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 231, train_loss = 1.0679793494491605, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 232, train_loss = 1.0652878408582183, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 233, train_loss = 1.0646436872630147, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 234, train_loss = 1.0657897355704335, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 235, train_loss = 1.0640053140668897, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 236, train_loss = 1.0631179176270962, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 237, train_loss = 1.0642515545041533, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 238, train_loss = 1.0620441387145547, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 239, train_loss = 1.0610777561814757, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 240, train_loss = 1.062352488443139, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 241, train_loss = 1.060131698846817, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 242, train_loss = 1.0594235211610794, train_acc = 0.9973218444340941\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 243, train_loss = 1.0607815223484067, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 244, train_loss = 1.0585987431259127, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 245, train_loss = 1.0578440477402182, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 246, train_loss = 1.059179882213357, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 247, train_loss = 1.0568839460611343, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 248, train_loss = 1.055944466337678, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 249, train_loss = 1.057637494057417, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 250, train_loss = 1.055585349604371, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 251, train_loss = 1.0540790197701426, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 252, train_loss = 1.0560600819735555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 253, train_loss = 1.0535536619572667, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 254, train_loss = 1.0528095948247937, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 255, train_loss = 1.0540832206606865, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 256, train_loss = 1.0518201813101768, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 257, train_loss = 1.0527849483041791, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 258, train_loss = 1.0509926602244377, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 259, train_loss = 1.0502337577490835, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 260, train_loss = 1.0515628345310688, train_acc = 0.9973218444340941\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 261, train_loss = 1.0493125592620345, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 262, train_loss = 1.048613270118949, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 263, train_loss = 1.0501140306441812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 264, train_loss = 1.0475720527319936, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 265, train_loss = 1.0463543894438772, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 266, train_loss = 1.0475317388772964, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 267, train_loss = 1.0454334815294715, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 268, train_loss = 1.044085123881814, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 269, train_loss = 1.0459347032010555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 270, train_loss = 1.0429710956959752, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 271, train_loss = 1.0441833101212978, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 272, train_loss = 1.0416378316731425, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 273, train_loss = 1.0403387819678755, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 274, train_loss = 1.0416011574416189, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 275, train_loss = 1.0393867480306653, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 276, train_loss = 1.0388120859861374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 277, train_loss = 1.0404744048864814, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 278, train_loss = 1.0380557725875406, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 279, train_loss = 1.037591639906168, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 280, train_loss = 1.038799598813057, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 281, train_loss = 1.0364954471588135, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 282, train_loss = 1.0361199068574933, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 283, train_loss = 1.0374224968254566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 284, train_loss = 1.0351247936487198, train_acc = 0.9973218444340941\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 285, train_loss = 1.0340932123363018, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 286, train_loss = 1.035461351275444, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 287, train_loss = 1.0337928545923205, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 288, train_loss = 1.0333708661346463, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 289, train_loss = 1.0327703381626634, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 290, train_loss = 1.033981055021286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 291, train_loss = 1.032007145389798, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 292, train_loss = 1.0313724341540365, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 293, train_loss = 1.0304793280811282, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 294, train_loss = 1.0319872076361207, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 295, train_loss = 1.0297303969709901, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 296, train_loss = 1.0289875852613477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 297, train_loss = 1.0289837755262852, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 298, train_loss = 1.0302221563906642, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 299, train_loss = 1.0279167133121518, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 300, train_loss = 1.027601469308138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 301, train_loss = 1.0270096945314435, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 302, train_loss = 1.026423332587001, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 303, train_loss = 1.028234860554221, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 304, train_loss = 1.0259683417825727, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 305, train_loss = 1.0250793062150478, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 306, train_loss = 1.025161846235278, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 307, train_loss = 1.0260754327027826, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 308, train_loss = 1.0238951829524012, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 309, train_loss = 1.0235642939805984, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 310, train_loss = 1.0229529974312754, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 311, train_loss = 1.024293998882058, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 312, train_loss = 1.0223619217722444, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 313, train_loss = 1.0214998498558998, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 314, train_loss = 1.0211764785199193, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 315, train_loss = 1.0226289418787928, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 316, train_loss = 1.0205929589719744, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 317, train_loss = 1.0202766669244738, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 318, train_loss = 1.0195692218840122, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 319, train_loss = 1.0189650195388822, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 320, train_loss = 1.0208994150161743, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 321, train_loss = 1.018642267838004, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 322, train_loss = 1.0177453358919593, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 323, train_loss = 1.017678142830846, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 324, train_loss = 1.0169374135584803, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 325, train_loss = 1.0186988028435735, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 326, train_loss = 1.0162406166346045, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 327, train_loss = 1.0159995394496946, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 328, train_loss = 1.0172977410256863, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 329, train_loss = 1.0149441572575597, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 330, train_loss = 1.0148329796938924, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 331, train_loss = 1.0141989402472973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 332, train_loss = 1.0154225006699562, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 333, train_loss = 1.0134630141110392, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 334, train_loss = 1.0129066805093316, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 335, train_loss = 1.0129653054027585, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 336, train_loss = 1.012100275605917, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 337, train_loss = 1.0118472526519326, train_acc = 0.9973218444340941\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 338, train_loss = 1.01296687994909, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 339, train_loss = 1.0112023341207532, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 340, train_loss = 1.0106407230050536, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 341, train_loss = 1.0103606134653091, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 342, train_loss = 1.0097625466733007, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 343, train_loss = 1.0113799522368936, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 344, train_loss = 1.0091334258468123, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 345, train_loss = 1.008796475827694, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 346, train_loss = 1.010111720606801, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 347, train_loss = 1.0078382467181655, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 348, train_loss = 1.007386761411908, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 349, train_loss = 1.0071475145668956, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 350, train_loss = 1.0065392404794693, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 351, train_loss = 1.00655201326299, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 352, train_loss = 1.007852113500121, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 353, train_loss = 1.0056599527597427, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 354, train_loss = 1.0051907201559516, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 355, train_loss = 1.0064871696085902, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 356, train_loss = 1.0044493041932583, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 357, train_loss = 1.0042309785931138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 358, train_loss = 1.0037957231252221, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 359, train_loss = 1.0036456597299548, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 360, train_loss = 1.0031027110962896, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 361, train_loss = 1.0041232431976823, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 362, train_loss = 1.0025458584277658, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 363, train_loss = 1.0020045191049576, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 364, train_loss = 1.0033252512366744, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 365, train_loss = 1.0010597867221804, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 366, train_loss = 1.0010942295193672, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 367, train_loss = 1.0005965170712443, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 368, train_loss = 1.0001538669021102, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 369, train_loss = 0.9997976409940748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 370, train_loss = 1.0012549348175526, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 371, train_loss = 0.9992767721414566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 372, train_loss = 0.9987664073705673, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 373, train_loss = 0.9983773442654638, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 374, train_loss = 0.9997274105699034, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 375, train_loss = 0.9977931802422972, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 376, train_loss = 0.9973912636487512, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 377, train_loss = 0.9970327826886205, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 378, train_loss = 0.9968428127467632, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 379, train_loss = 0.9963805663137464, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 380, train_loss = 0.9978096994309453, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 381, train_loss = 0.9955288258715882, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 382, train_loss = 0.9953112229704857, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 383, train_loss = 0.9965359854249982, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 384, train_loss = 0.9947634562849998, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 385, train_loss = 0.9945397687479272, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 386, train_loss = 0.9940120590254082, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 387, train_loss = 0.9937291666865349, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 388, train_loss = 0.9952381774783134, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 389, train_loss = 0.9930611861273064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 390, train_loss = 0.9925974694415345, train_acc = 0.9973218444340941\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 391, train_loss = 0.9923832962886081, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 392, train_loss = 0.9921034711078391, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 393, train_loss = 0.9916379315181985, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 394, train_loss = 0.9915590981618152, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 395, train_loss = 0.9907595912591205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 396, train_loss = 0.9926872340365662, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 397, train_loss = 0.9902422539889812, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 398, train_loss = 0.9919550642371178, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 399, train_loss = 0.9895323676391854, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 400, train_loss = 0.9896454960107803, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 401, train_loss = 0.988938931375742, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 402, train_loss = 0.9889901305214153, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 403, train_loss = 0.9885634357706294, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 404, train_loss = 0.9881402676328435, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 405, train_loss = 0.9896339923143387, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 406, train_loss = 0.9873455998822465, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 407, train_loss = 0.987402681261301, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 408, train_loss = 0.9871366905645118, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 409, train_loss = 0.9863787541762576, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 410, train_loss = 0.9863112606108189, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 411, train_loss = 0.987359939761518, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 412, train_loss = 0.9853060791865573, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 413, train_loss = 0.9851920232176781, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 414, train_loss = 0.986342175550817, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 415, train_loss = 0.9848661298528896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 416, train_loss = 0.9847557495013461, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 417, train_loss = 0.9841871770695434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 418, train_loss = 0.9839301283136592, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 419, train_loss = 0.9854567845686688, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 420, train_loss = 0.9830302136615501, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 421, train_loss = 0.9831189289689064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 422, train_loss = 0.9826840187088237, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 423, train_loss = 0.9823303197845235, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 424, train_loss = 0.9838488896712079, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 425, train_loss = 0.9817221735938801, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 426, train_loss = 0.981522262096405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 427, train_loss = 0.9812433049082756, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 428, train_loss = 0.9812868920489564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 429, train_loss = 0.9808385918513522, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 430, train_loss = 0.9806424578055157, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 431, train_loss = 0.980270537234901, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 432, train_loss = 0.9797843794003711, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 433, train_loss = 0.9814756947234855, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 434, train_loss = 0.9794493267909274, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 435, train_loss = 0.9788403411730542, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 436, train_loss = 0.980125043541193, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 437, train_loss = 0.9781613250597729, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 438, train_loss = 0.9779319179579034, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 439, train_loss = 0.9779309493824258, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 440, train_loss = 0.9776085192934261, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 441, train_loss = 0.9789125161842094, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 442, train_loss = 0.9768159873783588, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 443, train_loss = 0.9765837738887058, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 444, train_loss = 0.9764123248532997, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 445, train_loss = 0.975916963070631, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 446, train_loss = 0.9759335803464637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 447, train_loss = 0.9774979551657452, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 448, train_loss = 0.9753404669463634, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 449, train_loss = 0.9750497030690894, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 450, train_loss = 0.9746748171746731, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 451, train_loss = 0.9745981842279434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 452, train_loss = 0.9739639634863124, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 453, train_loss = 0.9760332206860767, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 454, train_loss = 0.973687194287777, train_acc = 0.9974382859804378\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 455, train_loss = 0.9736427776515484, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 456, train_loss = 0.973316968731524, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 457, train_loss = 0.9729623633102165, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 458, train_loss = 0.972380492836237, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 459, train_loss = 0.9742829824463115, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 460, train_loss = 0.9721173979341984, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 461, train_loss = 0.9717425405979156, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 462, train_loss = 0.9716930203139782, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 463, train_loss = 0.9711789414286613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 464, train_loss = 0.9728536841794266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 465, train_loss = 0.9707403878346668, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 466, train_loss = 0.970562203474401, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 467, train_loss = 0.9702231027185917, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 468, train_loss = 0.9698965921998024, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 469, train_loss = 0.9695670679211617, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 470, train_loss = 0.9711226709187031, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 471, train_loss = 0.9690573128536926, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 472, train_loss = 0.9689564344807877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 473, train_loss = 0.9685521808787598, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 474, train_loss = 0.9679951258003712, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 475, train_loss = 0.9682999265714898, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 476, train_loss = 0.9676488538607373, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 477, train_loss = 0.9689474701881409, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 478, train_loss = 0.9674082634373917, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 479, train_loss = 0.9666836696342216, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 480, train_loss = 0.9662252254784107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 481, train_loss = 0.967668062694429, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 482, train_loss = 0.9661065911277547, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 483, train_loss = 0.9658940769731998, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 484, train_loss = 0.9654105628505931, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 485, train_loss = 0.9651748227552162, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 486, train_loss = 0.9645403598769917, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 487, train_loss = 0.966431779168488, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 488, train_loss = 0.964251521974802, train_acc = 0.9974382859804378\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 489, train_loss = 0.9642912000417709, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 490, train_loss = 0.9640475598498597, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 491, train_loss = 0.9635403417050838, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 492, train_loss = 0.9652042264715419, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 493, train_loss = 0.9638004625812755, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 494, train_loss = 0.9632735078557744, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 495, train_loss = 0.9635331307872548, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 496, train_loss = 0.9630198031663895, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 497, train_loss = 0.962681706994772, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 498, train_loss = 0.9641337655484676, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 499, train_loss = 0.9619098318144097, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████████████████████████████████████████████████▋                         | 20/30 [3:16:44<1:43:59, 623.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "21th- epoch: 0, train_loss = 409.4074943959713, train_acc = 0.8012342803912436\n",
      "test Acc 0.835195530726257:\n",
      "21th- epoch: 1, train_loss = 98.86114501580596, train_acc = 0.922566371681416\n",
      "test Acc 0.8556797020484171:\n",
      "21th- epoch: 2, train_loss = 58.415919311344624, train_acc = 0.9449231485794132\n",
      "test Acc 0.9129422718808193:\n",
      "21th- epoch: 3, train_loss = 38.286539774388075, train_acc = 0.9563344201210993\n",
      "test Acc 0.9385474860335196:\n",
      "21th- epoch: 4, train_loss = 26.900271205464378, train_acc = 0.9655333022822543\n",
      "test Acc 0.9436685288640596:\n",
      "21th- epoch: 5, train_loss = 19.501179809914902, train_acc = 0.9726362366092222\n",
      "test Acc 0.9459962756052142:\n",
      "21th- epoch: 6, train_loss = 14.85713663767092, train_acc = 0.9778761061946902\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 7, train_loss = 11.765243858331814, train_acc = 0.9826502095947834\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 8, train_loss = 9.693900717888027, train_acc = 0.9853283651606893\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 9, train_loss = 8.126519346376881, train_acc = 0.9874243129948765\n",
      "test Acc 0.9515828677839852:\n",
      "21th- epoch: 10, train_loss = 6.862499475711957, train_acc = 0.9889380530973452\n",
      "test Acc 0.952513966480447:\n",
      "21th- epoch: 11, train_loss = 5.841855801641941, train_acc = 0.9905682347461574\n",
      "test Acc 0.9529795158286778:\n",
      "21th- epoch: 12, train_loss = 5.044559853151441, train_acc = 0.9910340009315324\n",
      "test Acc 0.9548417132216015:\n",
      "21th- epoch: 13, train_loss = 4.411915850127116, train_acc = 0.9919655333022822\n",
      "test Acc 0.9553072625698324:\n",
      "21th- epoch: 14, train_loss = 3.983507299562916, train_acc = 0.9934792734047508\n",
      "test Acc 0.9548417132216015:\n",
      "21th- epoch: 15, train_loss = 3.620381141314283, train_acc = 0.9939450395901258\n",
      "test Acc 0.9548417132216015:\n",
      "21th- epoch: 16, train_loss = 3.352833284297958, train_acc = 0.9945272473218444\n",
      "test Acc 0.9553072625698324:\n",
      "21th- epoch: 17, train_loss = 3.1329995647538453, train_acc = 0.994294364229157\n",
      "test Acc 0.9553072625698324:\n",
      "21th- epoch: 18, train_loss = 2.9389441923704, train_acc = 0.9946436888681882\n",
      "test Acc 0.9553072625698324:\n",
      "21th- epoch: 19, train_loss = 2.7863511813338846, train_acc = 0.9948765719608756\n",
      "test Acc 0.9553072625698324:\n",
      "21th- epoch: 20, train_loss = 2.6378011179622263, train_acc = 0.9949930135072194\n",
      "test Acc 0.9562383612662942:\n",
      "21th- epoch: 21, train_loss = 2.517533811740577, train_acc = 0.9952258965999069\n",
      "test Acc 0.9562383612662942:\n",
      "21th- epoch: 22, train_loss = 2.4145247450796887, train_acc = 0.9952258965999069\n",
      "test Acc 0.9567039106145251:\n",
      "21th- epoch: 23, train_loss = 2.32598236692138, train_acc = 0.9952258965999069\n",
      "test Acc 0.957169459962756:\n",
      "21th- epoch: 24, train_loss = 2.2542861598776653, train_acc = 0.9954587796925943\n",
      "test Acc 0.957169459962756:\n",
      "21th- epoch: 25, train_loss = 2.193121699267067, train_acc = 0.995575221238938\n",
      "test Acc 0.957169459962756:\n",
      "21th- epoch: 26, train_loss = 2.142221048241481, train_acc = 0.9958081043316255\n",
      "test Acc 0.957635009310987:\n",
      "21th- epoch: 27, train_loss = 2.097107612527907, train_acc = 0.9958081043316255\n",
      "test Acc 0.9581005586592178:\n",
      "21th- epoch: 28, train_loss = 2.0459251719294116, train_acc = 0.9958081043316255\n",
      "test Acc 0.9581005586592178:\n",
      "21th- epoch: 29, train_loss = 2.0087032436858863, train_acc = 0.9958081043316255\n",
      "test Acc 0.9585661080074488:\n",
      "21th- epoch: 30, train_loss = 1.9640683798352256, train_acc = 0.9958081043316255\n",
      "test Acc 0.9585661080074488:\n",
      "21th- epoch: 31, train_loss = 1.9251983347930945, train_acc = 0.9959245458779693\n",
      "test Acc 0.9585661080074488:\n",
      "21th- epoch: 32, train_loss = 1.8936439661192708, train_acc = 0.9959245458779693\n",
      "test Acc 0.9590316573556797:\n",
      "21th- epoch: 33, train_loss = 1.8576779561117291, train_acc = 0.9956916627852818\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 34, train_loss = 1.825498424412217, train_acc = 0.9958081043316255\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 35, train_loss = 1.7872199877165258, train_acc = 0.9958081043316255\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 36, train_loss = 1.7573291485314257, train_acc = 0.9956916627852818\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 37, train_loss = 1.7271598887746222, train_acc = 0.9956916627852818\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 38, train_loss = 1.6889626493793912, train_acc = 0.9956916627852818\n",
      "test Acc 0.9590316573556797:\n",
      "21th- epoch: 39, train_loss = 1.6663388554588892, train_acc = 0.9956916627852818\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 40, train_loss = 1.6440224024117924, train_acc = 0.9956916627852818\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 41, train_loss = 1.6190930609591305, train_acc = 0.995575221238938\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 42, train_loss = 1.6043617583345622, train_acc = 0.9956916627852818\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 43, train_loss = 1.5838265590718947, train_acc = 0.9958081043316255\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 44, train_loss = 1.569390489574289, train_acc = 0.9958081043316255\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 45, train_loss = 1.5515874556731433, train_acc = 0.9958081043316255\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 46, train_loss = 1.5313697032106575, train_acc = 0.9958081043316255\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 47, train_loss = 1.515380938857561, train_acc = 0.9959245458779693\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 48, train_loss = 1.5006851391808596, train_acc = 0.9958081043316255\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 49, train_loss = 1.4896443020552397, train_acc = 0.9959245458779693\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 50, train_loss = 1.477509851421928, train_acc = 0.9959245458779693\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 51, train_loss = 1.466355543670943, train_acc = 0.996040987424313\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 52, train_loss = 1.4543855696392711, train_acc = 0.996040987424313\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 53, train_loss = 1.4459101176762488, train_acc = 0.9959245458779693\n",
      "test Acc 0.9604283054003724:\n",
      "21th- epoch: 54, train_loss = 1.4337438341754023, train_acc = 0.9961574289706567\n",
      "test Acc 0.9604283054003724:\n",
      "21th- epoch: 55, train_loss = 1.4282993983943015, train_acc = 0.9961574289706567\n",
      "test Acc 0.9604283054003724:\n",
      "21th- epoch: 56, train_loss = 1.4206361543328967, train_acc = 0.9961574289706567\n",
      "test Acc 0.9604283054003724:\n",
      "21th- epoch: 57, train_loss = 1.4148087676148862, train_acc = 0.9962738705170004\n",
      "test Acc 0.9604283054003724:\n",
      "21th- epoch: 58, train_loss = 1.408456031611422, train_acc = 0.9963903120633442\n",
      "test Acc 0.9604283054003724:\n",
      "21th- epoch: 59, train_loss = 1.3997419064398855, train_acc = 0.9963903120633442\n",
      "test Acc 0.9604283054003724:\n",
      "21th- epoch: 60, train_loss = 1.3943116840237053, train_acc = 0.9963903120633442\n",
      "test Acc 0.9604283054003724:\n",
      "21th- epoch: 61, train_loss = 1.3866915291873738, train_acc = 0.9963903120633442\n",
      "test Acc 0.9604283054003724:\n",
      "21th- epoch: 62, train_loss = 1.3830441021855222, train_acc = 0.996506753609688\n",
      "test Acc 0.9604283054003724:\n",
      "21th- epoch: 63, train_loss = 1.3766590928426012, train_acc = 0.9963903120633442\n",
      "test Acc 0.9604283054003724:\n",
      "21th- epoch: 64, train_loss = 1.3726693199278088, train_acc = 0.9963903120633442\n",
      "test Acc 0.9608938547486033:\n",
      "21th- epoch: 65, train_loss = 1.3665298830455868, train_acc = 0.9963903120633442\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 66, train_loss = 1.3642493418446975, train_acc = 0.9963903120633442\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 67, train_loss = 1.3562393991742283, train_acc = 0.9963903120633442\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 68, train_loss = 1.3523596851882758, train_acc = 0.9963903120633442\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 69, train_loss = 1.3461442863335833, train_acc = 0.9963903120633442\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 70, train_loss = 1.3444872883119388, train_acc = 0.9963903120633442\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 71, train_loss = 1.341812260565348, train_acc = 0.9963903120633442\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 72, train_loss = 1.338142430409789, train_acc = 0.9963903120633442\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 73, train_loss = 1.3348863731807796, train_acc = 0.9963903120633442\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 74, train_loss = 1.3323162032029359, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 75, train_loss = 1.3268937736720545, train_acc = 0.9963903120633442\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 76, train_loss = 1.327302748497459, train_acc = 0.9962738705170004\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 77, train_loss = 1.3225425788405119, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 78, train_loss = 1.3206446412950754, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 79, train_loss = 1.3156059652537806, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 80, train_loss = 1.3144158670475008, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 81, train_loss = 1.3103578424779698, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 82, train_loss = 1.3083887475222582, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 83, train_loss = 1.3067559325281763, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 84, train_loss = 1.3040836326690624, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 85, train_loss = 1.3044059475214453, train_acc = 0.9962738705170004\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 86, train_loss = 1.3007959682290675, train_acc = 0.9962738705170004\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 87, train_loss = 1.2992692476400407, train_acc = 0.9962738705170004\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 88, train_loss = 1.295594190058182, train_acc = 0.9963903120633442\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 89, train_loss = 1.2958014779287623, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 90, train_loss = 1.2893647880555363, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 91, train_loss = 1.2905850030947477, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 92, train_loss = 1.288541616362636, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 93, train_loss = 1.2858012752403738, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 94, train_loss = 1.280675550806336, train_acc = 0.9962738705170004\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 95, train_loss = 1.2774579826145782, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 96, train_loss = 1.2745812290813774, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 97, train_loss = 1.2749200428370386, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 98, train_loss = 1.2721742900685058, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 99, train_loss = 1.2716900971718132, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 100, train_loss = 1.2691243494991795, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 101, train_loss = 1.2669519639239297, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 102, train_loss = 1.2654165256899432, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 103, train_loss = 1.2637942771762027, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 104, train_loss = 1.2616925173570053, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 105, train_loss = 1.2604248058851226, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 106, train_loss = 1.257703203787969, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 107, train_loss = 1.2562552730887546, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 108, train_loss = 1.2546940750908107, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 109, train_loss = 1.2531098600811674, train_acc = 0.9963903120633442\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 110, train_loss = 1.2504926540423185, train_acc = 0.996506753609688\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 111, train_loss = 1.2493997340425267, train_acc = 0.996506753609688\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 112, train_loss = 1.2498492061495199, train_acc = 0.996506753609688\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 113, train_loss = 1.2484680718407617, train_acc = 0.996506753609688\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 114, train_loss = 1.2464740991927101, train_acc = 0.996506753609688\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 115, train_loss = 1.244103282377182, train_acc = 0.996506753609688\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 116, train_loss = 1.244538525272219, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 117, train_loss = 1.2434834033847437, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 118, train_loss = 1.2404896385633037, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 119, train_loss = 1.2394372676499188, train_acc = 0.9966231951560317\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 120, train_loss = 1.2379384882151498, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 121, train_loss = 1.2369579286314547, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 122, train_loss = 1.2363557829521596, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 123, train_loss = 1.2348249998540268, train_acc = 0.9966231951560317\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 124, train_loss = 1.2333300889804377, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 125, train_loss = 1.2329083190634265, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 126, train_loss = 1.2316494191400125, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 127, train_loss = 1.230823100231646, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 128, train_loss = 1.2290964003987028, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 129, train_loss = 1.2287989691831172, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 130, train_loss = 1.2295354252346442, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 131, train_loss = 1.2261130727492855, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 132, train_loss = 1.2273932675234391, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 133, train_loss = 1.2258577807806432, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 134, train_loss = 1.2241692336610868, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 135, train_loss = 1.2243530598134384, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 136, train_loss = 1.221963788382709, train_acc = 0.9967396367023754\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 137, train_loss = 1.2206373785957112, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 138, train_loss = 1.2217890435495065, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 139, train_loss = 1.2185792145319283, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 140, train_loss = 1.2190003426148905, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 141, train_loss = 1.217948859637545, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 142, train_loss = 1.217376778680773, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 143, train_loss = 1.2152837491594255, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 144, train_loss = 1.215197781486495, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 145, train_loss = 1.2134123048745096, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 146, train_loss = 1.2125740889459848, train_acc = 0.9968560782487191\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 147, train_loss = 1.212362464517355, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 148, train_loss = 1.2107792228925973, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 149, train_loss = 1.2106937681455747, train_acc = 0.9968560782487191\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 150, train_loss = 1.2098708892372088, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 151, train_loss = 1.208477846113965, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 152, train_loss = 1.2061770530417562, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 153, train_loss = 1.2068225353359594, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 154, train_loss = 1.2056498470847146, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 155, train_loss = 1.204760186294152, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 156, train_loss = 1.2037786307846545, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 157, train_loss = 1.2034082198879332, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 158, train_loss = 1.2010202383753494, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 159, train_loss = 1.2014342151815072, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 160, train_loss = 1.1996970681575476, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 161, train_loss = 1.200348427715653, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 162, train_loss = 1.1982372044221847, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 163, train_loss = 1.1987742988494574, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 164, train_loss = 1.1983292946461006, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 165, train_loss = 1.196659136119706, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 166, train_loss = 1.1962615514639765, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 167, train_loss = 1.196069917990826, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 168, train_loss = 1.1937881362027838, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 169, train_loss = 1.192621608846821, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 170, train_loss = 1.1921810600542813, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 171, train_loss = 1.1914002043195069, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 172, train_loss = 1.1912446199785336, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 173, train_loss = 1.1909770334968925, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 174, train_loss = 1.189633194670023, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    read_path = 'D:virus/image/4gram_768/'\n",
    "    \n",
    "    temp = [[],[]]\n",
    "    \n",
    "    Loader = D.File_loader()\n",
    "    data_a, label_a = Loader.read_files(read_path, interp = False)\n",
    "    \n",
    "    idx = np.argsort(label_a)\n",
    "    \n",
    "    sorted_data = data_a[idx].reshape(10736, -1)\n",
    "    sorted_label = sorted(label_a)\n",
    "        \n",
    "    BATCH_SIZE = 64\n",
    "    TOTAL = 30\n",
    "    EPOCH = 500\n",
    "    NUM_CLASS = 9\n",
    "    LR = 0.0001\n",
    "    SEED = [s for s in range(TOTAL)]\n",
    "    INPUT_NODES = 768                   \n",
    "    \n",
    "    CUDA_N = 'cuda:1'\n",
    "    \n",
    "    # creating data indices for spliting\n",
    "    full_dataset = CustomDataset(sorted_data, sorted_label)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # spliting\n",
    "    torch.manual_seed(10)\n",
    "    train_dataset, test_dataset = data.random_split(full_dataset, [train_size, test_size])\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    loss_total = []\n",
    "    acc_total = []\n",
    "    pred_total = []\n",
    "    true_total = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(TOTAL)):\n",
    "        \n",
    "        device = torch.device(CUDA_N if torch.cuda.is_available() else 'cpu')\n",
    "        torch.manual_seed(SEED[i])\n",
    "        net = Net(INPUT_NODES, NUM_CLASS)           \n",
    "        net.to(device)\n",
    "        print(net)\n",
    "        \n",
    "        softmax = nn.Softmax()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=LR, momentum = 0.1)\n",
    "        \n",
    "        loss_list = []\n",
    "        train_acc_list = []\n",
    "        test_acc_list = []\n",
    "        \n",
    "        pred_temp = []\n",
    "        true_temp = []\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            net.train()\n",
    "            running_loss = 0\n",
    "            total = train_size\n",
    "            correct = 0 \n",
    "            \n",
    "            for step, image_and_label in enumerate(train_loader):\n",
    "                inputs, labels = image_and_label            \n",
    "                inputs, labels = inputs.type(torch.FloatTensor).to(device), labels.type(torch.LongTensor).to(device)\n",
    "                \n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, pred = torch.max(outputs, dim=1)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            train_acc = correct/total\n",
    "            loss_list.append(running_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "            print('{}th- epoch: {}, train_loss = {}, train_acc = {}'.format(i+1, epoch, running_loss, train_acc))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                correct = 0\n",
    "                total = test_size\n",
    "                pt, tt = [], []\n",
    "                \n",
    "                for step_t, image_and_label_t in enumerate(test_loader):\n",
    "                    inputs_t, labels_t = image_and_label_t            \n",
    "                    inputs_t, labels_t = inputs_t.type(torch.FloatTensor).to(device), labels_t.type(torch.LongTensor).to(device)\n",
    "                    \n",
    "                    outputs_t = net(inputs_t)\n",
    "                    outputs_t = softmax(outputs_t)\n",
    "                    \n",
    "                    # test accuracy\n",
    "                    _, pred_t = torch.max(outputs_t, dim = 1)\n",
    "                    \n",
    "                    pt.append(pred_t)\n",
    "                    tt.append(labels_t)\n",
    "                    \n",
    "                    correct += (pred_t == labels_t).sum().item()\n",
    "                    \n",
    "                pred_temp.append(torch.cat(pt))\n",
    "                true_temp.append(torch.cat(tt))\n",
    "                \n",
    "                test_acc = correct/total\n",
    "                test_acc_list.append(test_acc)\n",
    "                \n",
    "                print('test Acc {}:'.format(test_acc))\n",
    "                \n",
    "        best_result_index = np.argmax(np.array(test_acc_list))\n",
    "        loss_total.append(loss_list[best_result_index])\n",
    "        acc_total.append(test_acc_list[best_result_index])\n",
    "        pred_total.append(pred_temp[best_result_index].tolist())\n",
    "        true_total.append(true_temp[best_result_index].tolist())\n",
    "        \n",
    "    file_name = 'res/4gram_baseline'\n",
    "    torch.save(net.state_dict(), file_name +'.pth')\n",
    "    \n",
    "    loss_DF = pd.DataFrame(loss_total)\n",
    "    loss_DF.to_csv(file_name+\" loss.csv\")\n",
    "    \n",
    "    acc_DF = pd.DataFrame(acc_total)\n",
    "    acc_DF.to_csv(file_name +\" acc.csv\")\n",
    "    \n",
    "    pred_DF = pd.DataFrame(pred_total)\n",
    "    pred_DF.to_csv(file_name +\" pred.csv\")\n",
    "    \n",
    "    true_DF = pd.DataFrame(true_total)\n",
    "    true_DF.to_csv(file_name +\" true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
