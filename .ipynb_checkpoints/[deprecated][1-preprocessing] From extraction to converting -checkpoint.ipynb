{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import hashlib as h\n",
    "\n",
    "from skimage import io\n",
    "#from ttictoc import TicToc\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### required functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_opcode_lookup_table():\n",
    "    return set(pd.read_csv('opcode_set.csv').apply(lambda x: x.str.lower()).values.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_line_start_lookup_table():\n",
    "    DF = pd.read_excel('D:/virus/code_section.xlsx')\n",
    "    code_section = []\n",
    "    \n",
    "    for i in DF.values.reshape(-1):\n",
    "        section_name, content = i.split('–')\n",
    "        \n",
    "        if 'Code Section' in content:\n",
    "            code_section.append(section_name.replace(' ', '').lower())\n",
    "            \n",
    "    return set(code_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_code(line, start_text):\n",
    "    temp = set(line.lower().split(':'))\n",
    "    temp = temp.intersection(start_text)\n",
    "    \n",
    "    if temp == set():\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_hash_768(opcode_list, bits, gram):\n",
    "    \n",
    "    hash_v = np.zeros([bits[0]])\n",
    "\n",
    "    if gram == None:\n",
    "        \n",
    "        for opcode in opcode_list:\n",
    "            \n",
    "            binary1 = bin(int(h.sha256(opcode.encode()).hexdigest(), 16))[2:]\n",
    "            binary1 = list(binary1)\n",
    "            temp = bits[1] - len(binary1)\n",
    "            for i in range(temp):\n",
    "                binary1.insert(0, '0')\n",
    "\n",
    "            binary2 = bin(int(h.sha512(opcode.encode()).hexdigest(), 16))[2:]\n",
    "            binary2 = list(binary2)\n",
    "            temp = bits[2] - len(binary2)\n",
    "            for i in range(temp):\n",
    "                binary2.insert(0, '0')\n",
    "\n",
    "            binary = binary2 + binary1             # SHA-512 + SHA-256\n",
    "            binary = np.array(list(map(lambda x: -1 if x == '0'else 1, binary)))\n",
    "            hash_v = hash_v + binary\n",
    "    \n",
    "    elif gram == 2:\n",
    "        \n",
    "        opcode_ngram_tuple = list(ngrams(opcode_list, n=gram))\n",
    "        \n",
    "        for word1, word2 in opcode_ngram_tuple:\n",
    "            \n",
    "            opcode = word1+word2\n",
    "            \n",
    "            binary1 = bin(int(h.sha256(opcode.encode()).hexdigest(), 16))[2:]\n",
    "            binary1 = list(binary1)\n",
    "            temp = bits[1] - len(binary1)\n",
    "            for i in range(temp):\n",
    "                binary1.insert(0, '0')\n",
    "\n",
    "            binary2 = bin(int(h.sha512(opcode.encode()).hexdigest(), 16))[2:]\n",
    "            binary2 = list(binary2)\n",
    "            temp = bits[2] - len(binary2)\n",
    "            for i in range(temp):\n",
    "                binary2.insert(0, '0')\n",
    "\n",
    "            binary = binary2 + binary1             # SHA-512 + SHA-256\n",
    "            binary = np.array(list(map(lambda x: -1 if x == '0'else 1, binary)))\n",
    "            hash_v = hash_v + binary\n",
    "\n",
    "    elif gram == 3:\n",
    "        opcode_ngram_tuple = list(ngrams(opcode_list, n=gram))\n",
    "        \n",
    "        for word1, word2, word3 in opcode_ngram_tuple:\n",
    "            \n",
    "            opcode = word1+word2+word3\n",
    "            \n",
    "            binary1 = bin(int(h.sha256(opcode.encode()).hexdigest(), 16))[2:]\n",
    "            binary1 = list(binary1)\n",
    "            temp = bits[1] - len(binary1)\n",
    "            for i in range(temp):\n",
    "                binary1.insert(0, '0')\n",
    "\n",
    "            binary2 = bin(int(h.sha512(opcode.encode()).hexdigest(), 16))[2:]\n",
    "            binary2 = list(binary2)\n",
    "            temp = bits[2] - len(binary2)\n",
    "            for i in range(temp):\n",
    "                binary2.insert(0, '0')\n",
    "\n",
    "            binary = binary2 + binary1             # SHA-512 + SHA-256\n",
    "            binary = np.array(list(map(lambda x: -1 if x == '0'else 1, binary)))\n",
    "            hash_v = hash_v + binary\n",
    "            \n",
    "    elif gram == 4:\n",
    "        opcode_ngram_tuple = list(ngrams(opcode_list, n=gram))\n",
    "        \n",
    "        for word1, word2, word3, word4 in opcode_ngram_tuple:\n",
    "            \n",
    "            opcode = word1+word2+word3+word4\n",
    "            \n",
    "            binary1 = bin(int(h.sha256(opcode.encode()).hexdigest(), 16))[2:]\n",
    "            binary1 = list(binary1)\n",
    "            temp = bits[1] - len(binary1)\n",
    "            for i in range(temp):\n",
    "                binary1.insert(0, '0')\n",
    "\n",
    "            binary2 = bin(int(h.sha512(opcode.encode()).hexdigest(), 16))[2:]\n",
    "            binary2 = list(binary2)\n",
    "            temp = bits[2] - len(binary2)\n",
    "            for i in range(temp):\n",
    "                binary2.insert(0, '0')\n",
    "\n",
    "            binary = binary2 + binary1             # SHA-512 + SHA-256\n",
    "            binary = np.array(list(map(lambda x: -1 if x == '0'else 1, binary)))\n",
    "            hash_v = hash_v + binary\n",
    "            \n",
    "    return hash_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. opcode 룩업 테이블/asm파일의 시작점 룩업 테이블 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'opcode_set.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d82db100343a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mempty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mop_lookup_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_opcode_lookup_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mstart_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_line_start_lookup_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mstart_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.tixt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-6dd1873a2e2d>\u001b[0m in \u001b[0;36mmake_opcode_lookup_table\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_opcode_lookup_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'opcode_set.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'opcode_set.csv'"
     ]
    }
   ],
   "source": [
    "save_path = 'D:/virus/opcode/'\n",
    "file_path = 'D:/virus/asm_data/'\n",
    "\n",
    "empty = set()\n",
    "\n",
    "op_lookup_table = make_opcode_lookup_table()\n",
    "start_text = make_line_start_lookup_table()\n",
    "start_text.add('.tixt')\n",
    "start_text.add('.icode')\n",
    "start_text.add('seg')\n",
    "\n",
    "no_opcode_file = []\n",
    "file_list = os.listdir(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 각 파일로부터 opcode sequence를 추출하고 opcode sequence를 save_path에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = lambda x: True if not start_text[0] in x and not start_text[1] in x else False\n",
    "\n",
    "for num, file in enumerate(file_list):\n",
    "    \n",
    "    file_opcode = []\n",
    "    \n",
    "    for line in open(file_path+file,'r',encoding='ISO-8859-1'):\n",
    "        \n",
    "        if not is_code(line, start_text):\n",
    "            continue\n",
    "\n",
    "        words = line.split()\n",
    "        words = set(words)\n",
    "        \n",
    "        opcode = words.intersection(op_lookup_table)\n",
    "    \n",
    "        if opcode == empty:\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            file_opcode.append(opcode.pop())\n",
    "            continue\n",
    "            \n",
    "    if file_opcode == []:\n",
    "        no_opcode_file.append(file)\n",
    "        print(f\"{file} doesn't have any opcode in CODE or TEXT section\")\n",
    "        continue\n",
    "        \n",
    "    file_name = file.replace('.asm', '.pkl')\n",
    "    \n",
    "    with open(save_path+file_name, 'wb') as fp:\n",
    "        pickle.dump(file_opcode, fp)\n",
    "    \n",
    "    if num% 1000 == 0:\n",
    "        print('Now processing the {}th file'.format(num+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. opcode sequence를 읽어 들인 후, 이미지로 바꾼다음 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TicToc()\n",
    "\n",
    "bits = [768, 256, 512]\n",
    "bits1 = 256\n",
    "bits2 = 512\n",
    "\n",
    "width = 24\n",
    "height = 32\n",
    "save_path ='D:/virus/image/1gram_768/'\n",
    "\n",
    "t.tic()\n",
    "make_img_768(bits, width, height, save_path)  # default: 1garm\n",
    "t.toc()\n",
    "\n",
    "print(t.elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
