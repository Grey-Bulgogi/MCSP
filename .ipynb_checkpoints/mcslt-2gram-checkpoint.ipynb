{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import utility.Data_loader as D\n",
    "from utility.Model import Mcslt\n",
    "from utility.Custom import CustomDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 10736/10736 [00:02<00:00, 5099.10it/s]\n",
      "  0%|                                                                                    | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "1th- epoch: 0, train_loss = 100.64926259219646, train_acc = 0.8105496040987424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DTools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:99: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.8999068901303539:\n",
      "1th- epoch: 1, train_loss = 40.10758416354656, train_acc = 0.9222170470423847\n",
      "test Acc 0.9231843575418994:\n",
      "1th- epoch: 2, train_loss = 31.26131097227335, train_acc = 0.9377037727061015\n",
      "test Acc 0.9329608938547486:\n",
      "1th- epoch: 3, train_loss = 26.368512220680714, train_acc = 0.9451560316721006\n",
      "test Acc 0.936219739292365:\n",
      "1th- epoch: 4, train_loss = 23.120950762182474, train_acc = 0.950279459711225\n",
      "test Acc 0.9404096834264432:\n",
      "1th- epoch: 5, train_loss = 20.70344428345561, train_acc = 0.9552864462040056\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 6, train_loss = 18.813547898083925, train_acc = 0.959944108057755\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 7, train_loss = 17.302119944244623, train_acc = 0.9619236143455985\n",
      "test Acc 0.9511173184357542:\n",
      "1th- epoch: 8, train_loss = 16.06968630477786, train_acc = 0.9646017699115044\n",
      "test Acc 0.952048417132216:\n",
      "1th- epoch: 9, train_loss = 15.03093471005559, train_acc = 0.9673963670237541\n",
      "test Acc 0.952513966480447:\n",
      "1th- epoch: 10, train_loss = 14.141978561878204, train_acc = 0.9694923148579413\n",
      "test Acc 0.9529795158286778:\n",
      "1th- epoch: 11, train_loss = 13.370680466294289, train_acc = 0.9711224965067536\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 12, train_loss = 12.699274316430092, train_acc = 0.9732184443409408\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 13, train_loss = 12.107765294611454, train_acc = 0.9750815090824406\n",
      "test Acc 0.9562383612662942:\n",
      "1th- epoch: 14, train_loss = 11.576930038630962, train_acc = 0.9761294829995343\n",
      "test Acc 0.957635009310987:\n",
      "1th- epoch: 15, train_loss = 11.107159715145826, train_acc = 0.9774103400093154\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 16, train_loss = 10.682028409093618, train_acc = 0.9784583139264089\n",
      "test Acc 0.9590316573556797:\n",
      "1th- epoch: 17, train_loss = 10.294265117496252, train_acc = 0.9790405216581276\n",
      "test Acc 0.9590316573556797:\n",
      "1th- epoch: 18, train_loss = 9.937940865755081, train_acc = 0.9793898462971589\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 19, train_loss = 9.613330736756325, train_acc = 0.98067070330694\n",
      "test Acc 0.9581005586592178:\n",
      "1th- epoch: 20, train_loss = 9.31672878190875, train_acc = 0.9816022356776898\n",
      "test Acc 0.9581005586592178:\n",
      "1th- epoch: 21, train_loss = 9.037128619849682, train_acc = 0.981951560316721\n",
      "test Acc 0.9581005586592178:\n",
      "1th- epoch: 22, train_loss = 8.784548040479422, train_acc = 0.9824173265020959\n",
      "test Acc 0.9581005586592178:\n",
      "1th- epoch: 23, train_loss = 8.543574014678597, train_acc = 0.9826502095947834\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 24, train_loss = 8.31828342191875, train_acc = 0.983698183511877\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 25, train_loss = 8.106016086414456, train_acc = 0.9840475081509082\n",
      "test Acc 0.9590316573556797:\n",
      "1th- epoch: 26, train_loss = 7.907878048717976, train_acc = 0.9840475081509082\n",
      "test Acc 0.9608938547486033:\n",
      "1th- epoch: 27, train_loss = 7.719256222248077, train_acc = 0.9847461574289706\n",
      "test Acc 0.9608938547486033:\n",
      "1th- epoch: 28, train_loss = 7.545370792970061, train_acc = 0.9852119236143456\n",
      "test Acc 0.9608938547486033:\n",
      "1th- epoch: 29, train_loss = 7.380637761205435, train_acc = 0.985444806707033\n",
      "test Acc 0.9613594040968343:\n",
      "1th- epoch: 30, train_loss = 7.2219474874436855, train_acc = 0.9855612482533768\n",
      "test Acc 0.9613594040968343:\n",
      "1th- epoch: 31, train_loss = 7.071672076359391, train_acc = 0.9857941313460643\n",
      "test Acc 0.9613594040968343:\n",
      "1th- epoch: 32, train_loss = 6.927732659503818, train_acc = 0.9860270144387517\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 33, train_loss = 6.792073469609022, train_acc = 0.9861434559850955\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 34, train_loss = 6.658750565722585, train_acc = 0.9870749883558454\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 35, train_loss = 6.537695402279496, train_acc = 0.9874243129948765\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 36, train_loss = 6.415286784991622, train_acc = 0.9873078714485328\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 37, train_loss = 6.302804643288255, train_acc = 0.9875407545412203\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 38, train_loss = 6.191971993073821, train_acc = 0.9877736376339078\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 39, train_loss = 6.0872718170285225, train_acc = 0.9880065207265952\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 40, train_loss = 5.986475208774209, train_acc = 0.9883558453656265\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 41, train_loss = 5.889271959662437, train_acc = 0.9887051700046576\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 42, train_loss = 5.7950981464236975, train_acc = 0.9887051700046576\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 43, train_loss = 5.706704134121537, train_acc = 0.9887051700046576\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 44, train_loss = 5.617545684799552, train_acc = 0.9890544946436889\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 45, train_loss = 5.535734998062253, train_acc = 0.9891709361900326\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 46, train_loss = 5.453775743022561, train_acc = 0.9895202608290639\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 47, train_loss = 5.37606511451304, train_acc = 0.9897531439217513\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 48, train_loss = 5.301255404949188, train_acc = 0.9899860270144387\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 49, train_loss = 5.229272564873099, train_acc = 0.9901024685607824\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 50, train_loss = 5.160673424601555, train_acc = 0.9901024685607824\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 51, train_loss = 5.092946187593043, train_acc = 0.9902189101071263\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 52, train_loss = 5.026302836835384, train_acc = 0.9904517931998137\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 53, train_loss = 4.965975233353674, train_acc = 0.9905682347461574\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 54, train_loss = 4.9042426981031895, train_acc = 0.9906846762925011\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 55, train_loss = 4.842926467768848, train_acc = 0.990801117838845\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 56, train_loss = 4.788108106702566, train_acc = 0.990801117838845\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 57, train_loss = 4.730738158337772, train_acc = 0.990801117838845\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 58, train_loss = 4.677883096970618, train_acc = 0.9912668840242198\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 59, train_loss = 4.624628197401762, train_acc = 0.9912668840242198\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 60, train_loss = 4.572371327318251, train_acc = 0.9914997671169073\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 61, train_loss = 4.522357716225088, train_acc = 0.9916162086632511\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 62, train_loss = 4.474130712449551, train_acc = 0.9914997671169073\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 63, train_loss = 4.427430619485676, train_acc = 0.9914997671169073\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 64, train_loss = 4.385022913105786, train_acc = 0.9914997671169073\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 65, train_loss = 4.336137048900127, train_acc = 0.9914997671169073\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 66, train_loss = 4.294961872510612, train_acc = 0.9914997671169073\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 67, train_loss = 4.251969804055989, train_acc = 0.9914997671169073\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 68, train_loss = 4.212965302169323, train_acc = 0.9914997671169073\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 69, train_loss = 4.1712935315445065, train_acc = 0.9916162086632511\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 70, train_loss = 4.1324507826939225, train_acc = 0.9916162086632511\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 71, train_loss = 4.09486900549382, train_acc = 0.9917326502095948\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 72, train_loss = 4.057534937746823, train_acc = 0.9917326502095948\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 73, train_loss = 4.021838721819222, train_acc = 0.9918490917559385\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 74, train_loss = 3.9851443907245994, train_acc = 0.9918490917559385\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 75, train_loss = 3.953771607019007, train_acc = 0.9918490917559385\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 76, train_loss = 3.919157285243273, train_acc = 0.9918490917559385\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 77, train_loss = 3.883867018856108, train_acc = 0.9919655333022822\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 78, train_loss = 3.8531096884980798, train_acc = 0.9919655333022822\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 79, train_loss = 3.8219276191666722, train_acc = 0.9921984163949698\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 80, train_loss = 3.791252363473177, train_acc = 0.9921984163949698\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 81, train_loss = 3.7612125826999545, train_acc = 0.9921984163949698\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 82, train_loss = 3.7314700186252594, train_acc = 0.9921984163949698\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 83, train_loss = 3.7038470515981317, train_acc = 0.9921984163949698\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 84, train_loss = 3.673756465315819, train_acc = 0.9921984163949698\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 85, train_loss = 3.6460248045623302, train_acc = 0.9923148579413135\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 86, train_loss = 3.619001890067011, train_acc = 0.9923148579413135\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 87, train_loss = 3.5938030765391886, train_acc = 0.9924312994876572\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 88, train_loss = 3.569125717971474, train_acc = 0.9924312994876572\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 89, train_loss = 3.5429441072046757, train_acc = 0.9924312994876572\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 90, train_loss = 3.517360508441925, train_acc = 0.9924312994876572\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 91, train_loss = 3.491993694100529, train_acc = 0.9924312994876572\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 92, train_loss = 3.469098900910467, train_acc = 0.9924312994876572\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 93, train_loss = 3.445211303886026, train_acc = 0.9924312994876572\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 94, train_loss = 3.4210508191026747, train_acc = 0.9924312994876572\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 95, train_loss = 3.399096680339426, train_acc = 0.9925477410340009\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 96, train_loss = 3.3761123553849757, train_acc = 0.9925477410340009\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 97, train_loss = 3.355811255518347, train_acc = 0.9925477410340009\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 98, train_loss = 3.332242179661989, train_acc = 0.9925477410340009\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 99, train_loss = 3.312207266688347, train_acc = 0.9925477410340009\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 100, train_loss = 3.2912034117616713, train_acc = 0.9925477410340009\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 101, train_loss = 3.2695561298169196, train_acc = 0.9925477410340009\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 102, train_loss = 3.2506691701710224, train_acc = 0.9925477410340009\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 103, train_loss = 3.2314746505580842, train_acc = 0.9925477410340009\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 104, train_loss = 3.2089028283953667, train_acc = 0.9926641825803446\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 105, train_loss = 3.189496621489525, train_acc = 0.9926641825803446\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 106, train_loss = 3.1698895818553865, train_acc = 0.9926641825803446\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 107, train_loss = 3.153054176364094, train_acc = 0.9926641825803446\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 108, train_loss = 3.133199362549931, train_acc = 0.9926641825803446\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 109, train_loss = 3.1139683932997286, train_acc = 0.9930135072193759\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 110, train_loss = 3.096542589366436, train_acc = 0.9930135072193759\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 111, train_loss = 3.0804539904929698, train_acc = 0.9932463903120633\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 112, train_loss = 3.063081798609346, train_acc = 0.9933628318584071\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 113, train_loss = 3.047202808316797, train_acc = 0.9932463903120633\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 114, train_loss = 3.0308052175678313, train_acc = 0.9933628318584071\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 115, train_loss = 3.0142087577842176, train_acc = 0.9934792734047508\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 116, train_loss = 2.9978429623879492, train_acc = 0.9933628318584071\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 117, train_loss = 2.9843214279972017, train_acc = 0.9935957149510946\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 118, train_loss = 2.968578641768545, train_acc = 0.9935957149510946\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 119, train_loss = 2.95419834041968, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 120, train_loss = 2.939238461200148, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 121, train_loss = 2.9235491580329835, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 122, train_loss = 2.9096940718591213, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 123, train_loss = 2.894917845726013, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 124, train_loss = 2.8831175616942346, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 125, train_loss = 2.8703638054430485, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 126, train_loss = 2.8561745807528496, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 127, train_loss = 2.8424314334988594, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 128, train_loss = 2.829786045011133, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 129, train_loss = 2.817597111221403, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 130, train_loss = 2.805290194693953, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 131, train_loss = 2.790947654750198, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 132, train_loss = 2.780612056609243, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 133, train_loss = 2.7694931253790855, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 134, train_loss = 2.7568094222806394, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 135, train_loss = 2.7441196353174746, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 136, train_loss = 2.7327411859296262, train_acc = 0.9937121564974383\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 137, train_loss = 2.7229901612736285, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 138, train_loss = 2.712401058524847, train_acc = 0.9935957149510946\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 139, train_loss = 2.6999822929501534, train_acc = 0.9935957149510946\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 140, train_loss = 2.689464010298252, train_acc = 0.9935957149510946\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 141, train_loss = 2.678800992667675, train_acc = 0.9937121564974383\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 142, train_loss = 2.667722884565592, train_acc = 0.993828598043782\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 143, train_loss = 2.6579389721155167, train_acc = 0.9937121564974383\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 144, train_loss = 2.6496005691587925, train_acc = 0.9937121564974383\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 145, train_loss = 2.6372125793714076, train_acc = 0.9937121564974383\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 146, train_loss = 2.6277870039921254, train_acc = 0.993828598043782\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 147, train_loss = 2.6178626033943146, train_acc = 0.993828598043782\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 148, train_loss = 2.6084863927681, train_acc = 0.9940614811364695\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 149, train_loss = 2.5988734178245068, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 150, train_loss = 2.5893613297957927, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 151, train_loss = 2.579667004523799, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 152, train_loss = 2.570378166856244, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 153, train_loss = 2.5630102567374706, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 154, train_loss = 2.5530360031407326, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 155, train_loss = 2.5430710203945637, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 156, train_loss = 2.536312371492386, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 157, train_loss = 2.525679439306259, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 158, train_loss = 2.51732137799263, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 159, train_loss = 2.509898503543809, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 160, train_loss = 2.5007815721910447, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 161, train_loss = 2.493177520809695, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 162, train_loss = 2.485084243118763, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 163, train_loss = 2.4766345731914043, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 164, train_loss = 2.4689106184523553, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 165, train_loss = 2.460342090576887, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 166, train_loss = 2.4526762180030346, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 167, train_loss = 2.4471936759073287, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 168, train_loss = 2.4385533269960433, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 169, train_loss = 2.4302530474960804, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 170, train_loss = 2.4238712701480836, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 171, train_loss = 2.4161786672193557, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 172, train_loss = 2.409224897623062, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 173, train_loss = 2.403025859268382, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 174, train_loss = 2.3951830603182316, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 175, train_loss = 2.38838400808163, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 176, train_loss = 2.380648210644722, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 177, train_loss = 2.3752341505605727, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 178, train_loss = 2.3679538555443287, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 179, train_loss = 2.3621632617432624, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 180, train_loss = 2.3550335268955678, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 181, train_loss = 2.3496324494481087, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 182, train_loss = 2.3425829459447414, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 183, train_loss = 2.3362258337438107, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 184, train_loss = 2.3308980886358768, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 185, train_loss = 2.3227014653384686, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 186, train_loss = 2.3180918756406754, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 187, train_loss = 2.3112685941159725, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 188, train_loss = 2.305242281407118, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 189, train_loss = 2.3012868091464043, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 190, train_loss = 2.295074184658006, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 191, train_loss = 2.2873393285553902, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 192, train_loss = 2.2827350050210953, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 193, train_loss = 2.277854546904564, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 194, train_loss = 2.271886169910431, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 195, train_loss = 2.265735376626253, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 196, train_loss = 2.260558037785813, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 197, train_loss = 2.2547808587551117, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 198, train_loss = 2.2504443116486073, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 199, train_loss = 2.2442358434200287, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 200, train_loss = 2.239523855270818, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 201, train_loss = 2.234229217050597, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 202, train_loss = 2.229643440572545, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 203, train_loss = 2.224614519625902, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 204, train_loss = 2.218157322378829, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 205, train_loss = 2.2151527132373303, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 206, train_loss = 2.208509824005887, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 207, train_loss = 2.2043646301608533, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 208, train_loss = 2.1990988552570343, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 209, train_loss = 2.195158974500373, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 210, train_loss = 2.189820297062397, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 211, train_loss = 2.1854792672675103, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 212, train_loss = 2.180614997865632, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 213, train_loss = 2.1767447479069233, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 214, train_loss = 2.1716905906796455, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 215, train_loss = 2.1668192718643695, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 216, train_loss = 2.1634148645680398, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 217, train_loss = 2.1567673969548196, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 218, train_loss = 2.1538852106314152, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 219, train_loss = 2.1494614717084914, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 220, train_loss = 2.1455278520006686, train_acc = 0.9952258965999069\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 221, train_loss = 2.1407417096197605, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 222, train_loss = 2.135901314439252, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 223, train_loss = 2.1314535301644355, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 224, train_loss = 2.1293626700062305, train_acc = 0.9954587796925943\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 225, train_loss = 2.1244715105276555, train_acc = 0.9954587796925943\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 226, train_loss = 2.11979549867101, train_acc = 0.995575221238938\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 227, train_loss = 2.116300502093509, train_acc = 0.995575221238938\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 228, train_loss = 2.111817843047902, train_acc = 0.995575221238938\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 229, train_loss = 2.108135835500434, train_acc = 0.9953423381462506\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 230, train_loss = 2.1040970608592033, train_acc = 0.995575221238938\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 231, train_loss = 2.1001733851153404, train_acc = 0.995575221238938\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 232, train_loss = 2.0959830943029374, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 233, train_loss = 2.0919976148288697, train_acc = 0.995575221238938\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 234, train_loss = 2.088147271424532, train_acc = 0.995575221238938\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 235, train_loss = 2.084903210401535, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 236, train_loss = 2.0813700444996357, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 237, train_loss = 2.0766015015542507, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 238, train_loss = 2.0735483430325985, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 239, train_loss = 2.069570226012729, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 240, train_loss = 2.065900975256227, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 241, train_loss = 2.062614726484753, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 242, train_loss = 2.0588474795222282, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 243, train_loss = 2.0558102428913116, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 244, train_loss = 2.0517104789614677, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 245, train_loss = 2.047443225979805, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 246, train_loss = 2.0454198891529813, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 247, train_loss = 2.0423575354507193, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 248, train_loss = 2.0385527362814173, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 249, train_loss = 2.0350086925318465, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 250, train_loss = 2.0312602358171716, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 251, train_loss = 2.029112202464603, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 252, train_loss = 2.0239061899483204, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 253, train_loss = 2.022219060570933, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 254, train_loss = 2.0193007303168997, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 255, train_loss = 2.0153172835707664, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 256, train_loss = 2.0117595804622397, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 257, train_loss = 2.008680665283464, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 258, train_loss = 2.005363207310438, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 259, train_loss = 2.0022971580037847, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 260, train_loss = 1.998933482915163, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 261, train_loss = 1.9974627420306206, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 262, train_loss = 1.9939180836081505, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 263, train_loss = 1.990887119085528, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 264, train_loss = 1.988283734768629, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 265, train_loss = 1.984973213286139, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 266, train_loss = 1.980789159773849, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 267, train_loss = 1.9796252710511908, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 268, train_loss = 1.9767598323523998, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 269, train_loss = 1.97361132374499, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 270, train_loss = 1.9714234583079815, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 271, train_loss = 1.9680587016046047, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 272, train_loss = 1.965725090354681, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 273, train_loss = 1.962843089015223, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 274, train_loss = 1.960569461225532, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 275, train_loss = 1.9579579792916775, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 276, train_loss = 1.9550548692932352, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 277, train_loss = 1.9529070804128423, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 278, train_loss = 1.9502652747323737, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 279, train_loss = 1.9474707072367892, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 280, train_loss = 1.9456362687051296, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 281, train_loss = 1.941606910317205, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 282, train_loss = 1.9393636845052242, train_acc = 0.9952258965999069\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 283, train_loss = 1.9365204809000716, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 284, train_loss = 1.9336265003075823, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 285, train_loss = 1.9324763441691175, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 286, train_loss = 1.9289013346424326, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 287, train_loss = 1.9268237327923998, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 288, train_loss = 1.9244696038076654, train_acc = 0.9956916627852818\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 289, train_loss = 1.9219369950005785, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 290, train_loss = 1.9190775627503172, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 291, train_loss = 1.9172775410115719, train_acc = 0.9956916627852818\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 292, train_loss = 1.913896106183529, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 293, train_loss = 1.913424932747148, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 294, train_loss = 1.9100018069148064, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 295, train_loss = 1.9074272314319387, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 296, train_loss = 1.9056997249135748, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 297, train_loss = 1.903280290425755, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 298, train_loss = 1.900695058167912, train_acc = 0.9956916627852818\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 299, train_loss = 1.8969183936715126, train_acc = 0.9956916627852818\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 300, train_loss = 1.8935600481927395, train_acc = 0.9956916627852818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 301, train_loss = 1.8908066438743845, train_acc = 0.9956916627852818\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 302, train_loss = 1.8886181712150574, train_acc = 0.9956916627852818\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 303, train_loss = 1.886801078915596, train_acc = 0.9956916627852818\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 304, train_loss = 1.88388194644358, train_acc = 0.9956916627852818\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 305, train_loss = 1.8816215271363035, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 306, train_loss = 1.8791263438761234, train_acc = 0.9956916627852818\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 307, train_loss = 1.8772499164333567, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 308, train_loss = 1.8753956457367167, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 309, train_loss = 1.8739522099494934, train_acc = 0.9956916627852818\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 310, train_loss = 1.8712421506643295, train_acc = 0.9956916627852818\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 311, train_loss = 1.868691866635345, train_acc = 0.9954587796925943\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 312, train_loss = 1.8664616631576791, train_acc = 0.995575221238938\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 313, train_loss = 1.8638826422393322, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 314, train_loss = 1.8633249128470197, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 315, train_loss = 1.8605767972767353, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 316, train_loss = 1.8589574011275545, train_acc = 0.995575221238938\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 317, train_loss = 1.8563360323896632, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 318, train_loss = 1.8544692732393742, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 319, train_loss = 1.8535867830505595, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 320, train_loss = 1.8506967425346375, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 321, train_loss = 1.8493520232150331, train_acc = 0.9954587796925943\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 322, train_loss = 1.8465771103510633, train_acc = 0.9954587796925943\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 323, train_loss = 1.8451770668616518, train_acc = 0.9954587796925943\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 324, train_loss = 1.8427486853906885, train_acc = 0.9954587796925943\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 325, train_loss = 1.8413548804819584, train_acc = 0.9954587796925943\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 326, train_loss = 1.838885655044578, train_acc = 0.9954587796925943\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 327, train_loss = 1.8380802882602438, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 328, train_loss = 1.8351242765784264, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 329, train_loss = 1.8346503438660875, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 330, train_loss = 1.8316976154455915, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 331, train_loss = 1.8300931254634634, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 332, train_loss = 1.8283150544157252, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 333, train_loss = 1.8264314817497507, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 334, train_loss = 1.8251527696847916, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 335, train_loss = 1.823052511899732, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 336, train_loss = 1.8209892362356186, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 337, train_loss = 1.8197353718569502, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 338, train_loss = 1.8178608193993568, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 339, train_loss = 1.8158695487072691, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 340, train_loss = 1.814328957349062, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 341, train_loss = 1.8122599447378889, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 342, train_loss = 1.8114340975880623, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 343, train_loss = 1.809568788856268, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 344, train_loss = 1.807811338454485, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 345, train_loss = 1.8055384047329426, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 346, train_loss = 1.805060782819055, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 347, train_loss = 1.8031999791273847, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 348, train_loss = 1.8012212304165587, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 349, train_loss = 1.7992580346763134, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 350, train_loss = 1.7975236090132967, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 351, train_loss = 1.7953890872886404, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 352, train_loss = 1.7951732078799978, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 353, train_loss = 1.7936274918029085, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 354, train_loss = 1.7919667921960354, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 355, train_loss = 1.7896114686736837, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 356, train_loss = 1.7882517216494307, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 357, train_loss = 1.7863503160187975, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 358, train_loss = 1.7854700908064842, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 359, train_loss = 1.7841421092161909, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 360, train_loss = 1.781728429137729, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 361, train_loss = 1.7805564975133166, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 362, train_loss = 1.7796680392930284, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 363, train_loss = 1.7782390961656347, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 364, train_loss = 1.7761776322731748, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 365, train_loss = 1.7753076056251302, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 366, train_loss = 1.772757718921639, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 367, train_loss = 1.7716194005915895, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 368, train_loss = 1.7707808328559622, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 369, train_loss = 1.7695226507494226, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 370, train_loss = 1.7675046833464876, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 371, train_loss = 1.7665915302932262, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 372, train_loss = 1.7649758843472227, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 373, train_loss = 1.7637130519142374, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 374, train_loss = 1.7617471417179331, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 375, train_loss = 1.760990347713232, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 376, train_loss = 1.7591227678349242, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 377, train_loss = 1.7583694396307692, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 378, train_loss = 1.7568187130382285, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 379, train_loss = 1.7558224499225616, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 380, train_loss = 1.7538673268863931, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 381, train_loss = 1.752533738850616, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 382, train_loss = 1.751187046407722, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 383, train_loss = 1.7500884967157617, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 384, train_loss = 1.7495696010882966, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 385, train_loss = 1.7477391946013086, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 386, train_loss = 1.7464533907477744, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 387, train_loss = 1.7453267934033647, train_acc = 0.9954587796925943\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 388, train_loss = 1.743100372434128, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 389, train_loss = 1.742327257990837, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 390, train_loss = 1.7412846100633033, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 391, train_loss = 1.739978026598692, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 392, train_loss = 1.7393739583785646, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 393, train_loss = 1.737222747236956, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 394, train_loss = 1.7366196711664088, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 395, train_loss = 1.7348761893808842, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 396, train_loss = 1.7334893445367925, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 397, train_loss = 1.731873657554388, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 398, train_loss = 1.7324150800704956, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 399, train_loss = 1.7295537975733168, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 400, train_loss = 1.7294254166190512, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 401, train_loss = 1.7282727994024754, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 402, train_loss = 1.72651281330036, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 403, train_loss = 1.7255690817837603, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 404, train_loss = 1.7243007968063466, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 405, train_loss = 1.7236532543902285, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 406, train_loss = 1.7214148715138435, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 407, train_loss = 1.7203933807904832, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 408, train_loss = 1.7199044798617251, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 409, train_loss = 1.7193202264606953, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 410, train_loss = 1.7172101574833505, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 411, train_loss = 1.717471255629789, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 412, train_loss = 1.7158257402479649, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 413, train_loss = 1.7142247073352337, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 414, train_loss = 1.712991051375866, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 415, train_loss = 1.7128840548102744, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 416, train_loss = 1.7114708026056178, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 417, train_loss = 1.7109156213700771, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 418, train_loss = 1.7089337718789466, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 419, train_loss = 1.7078838993911631, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 420, train_loss = 1.7074002263252623, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 421, train_loss = 1.7057537834043615, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 422, train_loss = 1.7050867453217506, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 423, train_loss = 1.7037556928698905, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 424, train_loss = 1.7023598179221153, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 425, train_loss = 1.7020872483844869, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 426, train_loss = 1.7010382016305812, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 427, train_loss = 1.6992048832471482, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 428, train_loss = 1.6991696245968342, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 429, train_loss = 1.6977276007528417, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 430, train_loss = 1.6973100925679319, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 431, train_loss = 1.69599400711013, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 432, train_loss = 1.6947669337387197, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 433, train_loss = 1.6946232169866562, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 434, train_loss = 1.69294960424304, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 435, train_loss = 1.6915857953135855, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 436, train_loss = 1.6909544480149634, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 437, train_loss = 1.6898462225799449, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 438, train_loss = 1.6889734913711436, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 439, train_loss = 1.6876406371593475, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 440, train_loss = 1.6873705585603602, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 441, train_loss = 1.6861723624169827, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 442, train_loss = 1.685104372620117, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 443, train_loss = 1.6847888566553593, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 444, train_loss = 1.6838200849597342, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 445, train_loss = 1.6827407963573933, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 446, train_loss = 1.6821534559130669, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 447, train_loss = 1.681113277853001, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 448, train_loss = 1.6795515790581703, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 449, train_loss = 1.6792379058897495, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 450, train_loss = 1.678173144639004, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 451, train_loss = 1.6770221181213856, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 452, train_loss = 1.6769587409798987, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 453, train_loss = 1.675762988626957, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 454, train_loss = 1.6746910462970845, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 455, train_loss = 1.6738162748515606, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 456, train_loss = 1.6722636384074576, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 457, train_loss = 1.6719343637232669, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 458, train_loss = 1.6720405059750192, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 459, train_loss = 1.670437403023243, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 460, train_loss = 1.6693801507353783, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 461, train_loss = 1.6680078518693335, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 462, train_loss = 1.6681158902938478, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 463, train_loss = 1.66751103970455, train_acc = 0.995575221238938\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 464, train_loss = 1.6666152092511766, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 465, train_loss = 1.665446134924423, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 466, train_loss = 1.6650333714787848, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 467, train_loss = 1.6630466704373248, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 468, train_loss = 1.6640664227306843, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 469, train_loss = 1.6621052784030326, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 470, train_loss = 1.661253910511732, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 471, train_loss = 1.6602734575862996, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 472, train_loss = 1.6603227878804319, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 473, train_loss = 1.6588692304794677, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 474, train_loss = 1.6578985142405145, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 475, train_loss = 1.6581322898273356, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 476, train_loss = 1.6562885480816476, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 477, train_loss = 1.6563580172951333, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 478, train_loss = 1.6555982567369938, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 479, train_loss = 1.6545435898005962, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 480, train_loss = 1.653918428986799, train_acc = 0.995575221238938\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 481, train_loss = 1.6519766462151892, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 482, train_loss = 1.651659941941034, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 483, train_loss = 1.6510768893058412, train_acc = 0.995575221238938\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 484, train_loss = 1.6501825923915021, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 485, train_loss = 1.650065275549423, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 486, train_loss = 1.649224595457781, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 487, train_loss = 1.648772666871082, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 488, train_loss = 1.6470818594098091, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 489, train_loss = 1.6467828552122228, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 490, train_loss = 1.6459152686293237, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 491, train_loss = 1.6452547547523864, train_acc = 0.995575221238938\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 492, train_loss = 1.6449505276978016, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 493, train_loss = 1.6440651838784106, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 494, train_loss = 1.6427201007609256, train_acc = 0.995575221238938\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 495, train_loss = 1.642582366883289, train_acc = 0.995575221238938\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 496, train_loss = 1.6417036105995066, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 497, train_loss = 1.6410811804234982, train_acc = 0.995575221238938\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 498, train_loss = 1.640047125518322, train_acc = 0.995575221238938\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 499, train_loss = 1.6399201552267186, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                      | 1/30 [09:02<4:22:25, 542.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "2th- epoch: 0, train_loss = 126.18775202333927, train_acc = 0.7848160223567769\n",
      "test Acc 0.8868715083798883:\n",
      "2th- epoch: 1, train_loss = 42.39623365551233, train_acc = 0.911504424778761\n",
      "test Acc 0.9208566108007449:\n",
      "2th- epoch: 2, train_loss = 31.537923127412796, train_acc = 0.9372380065207266\n",
      "test Acc 0.9404096834264432:\n",
      "2th- epoch: 3, train_loss = 26.486054215580225, train_acc = 0.9479506287843502\n",
      "test Acc 0.9445996275605214:\n",
      "2th- epoch: 4, train_loss = 23.343022897839546, train_acc = 0.9537727061015371\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 5, train_loss = 21.062164559960365, train_acc = 0.9572659524918491\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 6, train_loss = 19.3099375218153, train_acc = 0.9608756404285049\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 7, train_loss = 17.884710922837257, train_acc = 0.9637866790870983\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 8, train_loss = 16.693884439766407, train_acc = 0.9657661853749417\n",
      "test Acc 0.952048417132216:\n",
      "2th- epoch: 9, train_loss = 15.692393247038126, train_acc = 0.9680950163018165\n",
      "test Acc 0.9539106145251397:\n",
      "2th- epoch: 10, train_loss = 14.833282228559256, train_acc = 0.9692594317652539\n",
      "test Acc 0.9543761638733705:\n",
      "2th- epoch: 11, train_loss = 14.07874160259962, train_acc = 0.9708896134140661\n",
      "test Acc 0.9543761638733705:\n",
      "2th- epoch: 12, train_loss = 13.412796938791871, train_acc = 0.9720540288775035\n",
      "test Acc 0.9553072625698324:\n",
      "2th- epoch: 13, train_loss = 12.812590768560767, train_acc = 0.9736842105263158\n",
      "test Acc 0.9567039106145251:\n",
      "2th- epoch: 14, train_loss = 12.265617776662111, train_acc = 0.9748486259897532\n",
      "test Acc 0.9585661080074488:\n",
      "2th- epoch: 15, train_loss = 11.773208290338516, train_acc = 0.9761294829995343\n",
      "test Acc 0.9594972067039106:\n",
      "2th- epoch: 16, train_loss = 11.324394680559635, train_acc = 0.9765952491849091\n",
      "test Acc 0.9604283054003724:\n",
      "2th- epoch: 17, train_loss = 10.908071056008339, train_acc = 0.9776432231020028\n",
      "test Acc 0.9604283054003724:\n",
      "2th- epoch: 18, train_loss = 10.52594780921936, train_acc = 0.9778761061946902\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 19, train_loss = 10.173715500161052, train_acc = 0.9788076385654402\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 20, train_loss = 9.84683932736516, train_acc = 0.9796227293898463\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 21, train_loss = 9.546746408566833, train_acc = 0.9800884955752213\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 22, train_loss = 9.267763072624803, train_acc = 0.9810200279459711\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 23, train_loss = 9.009917812421918, train_acc = 0.9812529110386586\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 24, train_loss = 8.768417287617922, train_acc = 0.981951560316721\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 25, train_loss = 8.543970838189125, train_acc = 0.9827666511411272\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 26, train_loss = 8.33080306649208, train_acc = 0.9834653004191896\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 27, train_loss = 8.128358982503414, train_acc = 0.983698183511877\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 28, train_loss = 7.939403066411614, train_acc = 0.9846297158826269\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 29, train_loss = 7.756561545655131, train_acc = 0.9848625989753144\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 30, train_loss = 7.586453387513757, train_acc = 0.9852119236143456\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 31, train_loss = 7.4257155898958445, train_acc = 0.9853283651606893\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 32, train_loss = 7.270591435953975, train_acc = 0.985444806707033\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 33, train_loss = 7.127371923997998, train_acc = 0.9860270144387517\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 34, train_loss = 6.988794315606356, train_acc = 0.9862598975314392\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 35, train_loss = 6.859022820368409, train_acc = 0.9864927806241267\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 36, train_loss = 6.731901440769434, train_acc = 0.9868421052631579\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 37, train_loss = 6.613848743960261, train_acc = 0.9875407545412203\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 38, train_loss = 6.49848142080009, train_acc = 0.9877736376339078\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 39, train_loss = 6.388496022671461, train_acc = 0.9883558453656265\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 40, train_loss = 6.281234418973327, train_acc = 0.9885887284583139\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 41, train_loss = 6.182226901873946, train_acc = 0.9884722869119702\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 42, train_loss = 6.086553771048784, train_acc = 0.9888216115510013\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 43, train_loss = 5.990516614168882, train_acc = 0.9889380530973452\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 44, train_loss = 5.904408983886242, train_acc = 0.9891709361900326\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 45, train_loss = 5.817231699824333, train_acc = 0.9891709361900326\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 46, train_loss = 5.735263597220182, train_acc = 0.98940381928272\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 47, train_loss = 5.655726981349289, train_acc = 0.9896367023754076\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 48, train_loss = 5.580743081867695, train_acc = 0.9899860270144387\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 49, train_loss = 5.505943740718067, train_acc = 0.9902189101071263\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 50, train_loss = 5.431744862347841, train_acc = 0.9902189101071263\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 51, train_loss = 5.3665922386571765, train_acc = 0.99033535165347\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 52, train_loss = 5.2967743081972, train_acc = 0.99033535165347\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 53, train_loss = 5.23268710821867, train_acc = 0.9902189101071263\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 54, train_loss = 5.167895432561636, train_acc = 0.9904517931998137\n",
      "test Acc 0.9739292364990689:\n",
      "2th- epoch: 55, train_loss = 5.107807356864214, train_acc = 0.9904517931998137\n",
      "test Acc 0.9739292364990689:\n",
      "2th- epoch: 56, train_loss = 5.0479892659932375, train_acc = 0.9906846762925011\n",
      "test Acc 0.9739292364990689:\n",
      "2th- epoch: 57, train_loss = 4.989590666256845, train_acc = 0.9906846762925011\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 58, train_loss = 4.932227946817875, train_acc = 0.9909175593851887\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 59, train_loss = 4.880213920027018, train_acc = 0.9909175593851887\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 60, train_loss = 4.825564864091575, train_acc = 0.9909175593851887\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 61, train_loss = 4.773810813203454, train_acc = 0.9910340009315324\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 62, train_loss = 4.724507276900113, train_acc = 0.9910340009315324\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 63, train_loss = 4.672850291244686, train_acc = 0.9911504424778761\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 64, train_loss = 4.628541660495102, train_acc = 0.9913833255705635\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 65, train_loss = 4.581322714686394, train_acc = 0.9914997671169073\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 66, train_loss = 4.535709868185222, train_acc = 0.9914997671169073\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 67, train_loss = 4.49319470115006, train_acc = 0.9914997671169073\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 68, train_loss = 4.446215615607798, train_acc = 0.9916162086632511\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 69, train_loss = 4.406662476249039, train_acc = 0.9914997671169073\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 70, train_loss = 4.362568409182131, train_acc = 0.9914997671169073\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 71, train_loss = 4.322214024141431, train_acc = 0.9914997671169073\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 72, train_loss = 4.284139776602387, train_acc = 0.9914997671169073\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 73, train_loss = 4.245408350601792, train_acc = 0.9914997671169073\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 74, train_loss = 4.206340962089598, train_acc = 0.9916162086632511\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 75, train_loss = 4.17186651751399, train_acc = 0.9916162086632511\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 76, train_loss = 4.134014517068863, train_acc = 0.9916162086632511\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 77, train_loss = 4.098832105286419, train_acc = 0.9917326502095948\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 78, train_loss = 4.064995328895748, train_acc = 0.9918490917559385\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 79, train_loss = 4.031801310367882, train_acc = 0.9919655333022822\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 80, train_loss = 3.99906587228179, train_acc = 0.9919655333022822\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 81, train_loss = 3.96620952244848, train_acc = 0.9919655333022822\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 82, train_loss = 3.93703605607152, train_acc = 0.9919655333022822\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 83, train_loss = 3.903649960644543, train_acc = 0.992081974848626\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 84, train_loss = 3.875187538564205, train_acc = 0.992081974848626\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 85, train_loss = 3.8447333304211497, train_acc = 0.992081974848626\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 86, train_loss = 3.8164377631619573, train_acc = 0.992081974848626\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 87, train_loss = 3.7865220233798027, train_acc = 0.9921984163949698\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 88, train_loss = 3.759914173744619, train_acc = 0.992081974848626\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 89, train_loss = 3.7313496628776193, train_acc = 0.9921984163949698\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 90, train_loss = 3.7068283641710877, train_acc = 0.9921984163949698\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 91, train_loss = 3.6773836137726903, train_acc = 0.9921984163949698\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 92, train_loss = 3.653729637619108, train_acc = 0.9921984163949698\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 93, train_loss = 3.6305075571872294, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 94, train_loss = 3.6027898914180696, train_acc = 0.9924312994876572\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 95, train_loss = 3.5777788064442575, train_acc = 0.9924312994876572\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 96, train_loss = 3.5550453290343285, train_acc = 0.9924312994876572\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 97, train_loss = 3.5329965665005147, train_acc = 0.9924312994876572\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 98, train_loss = 3.5100893625058234, train_acc = 0.9924312994876572\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 99, train_loss = 3.4873949266038835, train_acc = 0.9924312994876572\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 100, train_loss = 3.4655422992073, train_acc = 0.9924312994876572\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 101, train_loss = 3.443384876009077, train_acc = 0.9924312994876572\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 102, train_loss = 3.421996561344713, train_acc = 0.9926641825803446\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 103, train_loss = 3.400752827525139, train_acc = 0.9925477410340009\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 104, train_loss = 3.38093194225803, train_acc = 0.9927806241266884\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 105, train_loss = 3.3591808429919183, train_acc = 0.9927806241266884\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 106, train_loss = 3.341840571258217, train_acc = 0.9927806241266884\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 107, train_loss = 3.3191149928607047, train_acc = 0.9927806241266884\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 108, train_loss = 3.300926301628351, train_acc = 0.9928970656730322\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 109, train_loss = 3.281843198928982, train_acc = 0.9928970656730322\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 110, train_loss = 3.2635345831513405, train_acc = 0.9930135072193759\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 111, train_loss = 3.246829932089895, train_acc = 0.9930135072193759\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 112, train_loss = 3.227202635258436, train_acc = 0.9930135072193759\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 113, train_loss = 3.2098452374339104, train_acc = 0.9930135072193759\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 114, train_loss = 3.1919631883502007, train_acc = 0.9930135072193759\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 115, train_loss = 3.1739743277430534, train_acc = 0.9930135072193759\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 116, train_loss = 3.1580275506712496, train_acc = 0.9928970656730322\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 117, train_loss = 3.1411088802851737, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 118, train_loss = 3.1261249580420554, train_acc = 0.9932463903120633\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 119, train_loss = 3.1068064272403717, train_acc = 0.9933628318584071\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 120, train_loss = 3.093260211404413, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 121, train_loss = 3.074356665369123, train_acc = 0.9934792734047508\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 122, train_loss = 3.061209537088871, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 123, train_loss = 3.044228009879589, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 124, train_loss = 3.0291357883252203, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 125, train_loss = 3.0150124640204012, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 126, train_loss = 3.000751490239054, train_acc = 0.9934792734047508\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 127, train_loss = 2.9848770373500884, train_acc = 0.9934792734047508\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 128, train_loss = 2.972848744597286, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 129, train_loss = 2.957628767937422, train_acc = 0.9934792734047508\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 130, train_loss = 2.944328796118498, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 131, train_loss = 2.929809166584164, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 132, train_loss = 2.9161982187069952, train_acc = 0.9937121564974383\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 133, train_loss = 2.905801152344793, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 134, train_loss = 2.890879962593317, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 135, train_loss = 2.8797300471924245, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 136, train_loss = 2.864072343800217, train_acc = 0.9937121564974383\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 137, train_loss = 2.8559543737210333, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 138, train_loss = 2.844041360076517, train_acc = 0.9935957149510946\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 139, train_loss = 2.8289871513843536, train_acc = 0.9937121564974383\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 140, train_loss = 2.8174512893892825, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 141, train_loss = 2.8047279394231737, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 142, train_loss = 2.79389880457893, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 143, train_loss = 2.7842480181716383, train_acc = 0.9937121564974383\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 144, train_loss = 2.773393886629492, train_acc = 0.9937121564974383\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 145, train_loss = 2.76238427311182, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 146, train_loss = 2.750900165643543, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 147, train_loss = 2.739899759646505, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 148, train_loss = 2.729697351809591, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 149, train_loss = 2.720919918268919, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 150, train_loss = 2.7107685045339167, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 151, train_loss = 2.6994971721433103, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 152, train_loss = 2.6886944212019444, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 153, train_loss = 2.680717434734106, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 154, train_loss = 2.6687365076504648, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 155, train_loss = 2.6588625186122954, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 156, train_loss = 2.6479720934294164, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 157, train_loss = 2.638645099941641, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 158, train_loss = 2.6304439455270767, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 159, train_loss = 2.6201648279093206, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 160, train_loss = 2.6104342439211905, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 161, train_loss = 2.6024807267822325, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 162, train_loss = 2.5937989824451506, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 163, train_loss = 2.5855937502346933, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 164, train_loss = 2.575970523059368, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 165, train_loss = 2.5676131658256054, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 166, train_loss = 2.558988443110138, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 167, train_loss = 2.5517129846848547, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 168, train_loss = 2.5432524508796632, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 169, train_loss = 2.5344768851064146, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 170, train_loss = 2.528411229606718, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 171, train_loss = 2.518824825529009, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 172, train_loss = 2.512603169772774, train_acc = 0.9941779226828132\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 173, train_loss = 2.504325096961111, train_acc = 0.994294364229157\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 174, train_loss = 2.4981348789297044, train_acc = 0.994294364229157\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 175, train_loss = 2.4884245633147657, train_acc = 0.994294364229157\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 176, train_loss = 2.4826513291336596, train_acc = 0.994294364229157\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 177, train_loss = 2.4748709849081933, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 178, train_loss = 2.4676445140503347, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 179, train_loss = 2.4595353815238923, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 180, train_loss = 2.4535935011226684, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 181, train_loss = 2.4467946998775005, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 182, train_loss = 2.4402278549969196, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 183, train_loss = 2.434715623734519, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 184, train_loss = 2.4263545784633607, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 185, train_loss = 2.420472014695406, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 186, train_loss = 2.413167156279087, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 187, train_loss = 2.406747716246173, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 188, train_loss = 2.4002217650413513, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 189, train_loss = 2.3937531039118767, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 190, train_loss = 2.3877399414777756, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 191, train_loss = 2.3808309275191277, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 192, train_loss = 2.3746195286512375, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 193, train_loss = 2.3699838742613792, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 194, train_loss = 2.3621791240293533, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 195, train_loss = 2.356320259394124, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 196, train_loss = 2.3506194453220814, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 197, train_loss = 2.3438962686341256, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 198, train_loss = 2.3393322229385376, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 199, train_loss = 2.3331239249091595, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 200, train_loss = 2.3274932105559856, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 201, train_loss = 2.322242268593982, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 202, train_loss = 2.3155935753602535, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 203, train_loss = 2.3115453149657696, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 204, train_loss = 2.30557032302022, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 205, train_loss = 2.2996255334001034, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 206, train_loss = 2.294602492125705, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 207, train_loss = 2.288182307034731, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 208, train_loss = 2.2848138983827084, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 209, train_loss = 2.277887274743989, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 210, train_loss = 2.2742613207083195, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 211, train_loss = 2.269252182217315, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 212, train_loss = 2.2631991852540523, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 213, train_loss = 2.2586467799264938, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 214, train_loss = 2.2512526512145996, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 215, train_loss = 2.248152279527858, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 216, train_loss = 2.2424685943406075, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 217, train_loss = 2.238232810050249, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 218, train_loss = 2.2343963719904423, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 219, train_loss = 2.229117588372901, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 220, train_loss = 2.2255658123176545, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 221, train_loss = 2.2194869306404144, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 222, train_loss = 2.2158023219089955, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 223, train_loss = 2.209865442244336, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 224, train_loss = 2.2047848850488663, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 225, train_loss = 2.200268170563504, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 226, train_loss = 2.197171500651166, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 227, train_loss = 2.1913324259221554, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 228, train_loss = 2.1871525421738625, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 229, train_loss = 2.1839916955213994, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 230, train_loss = 2.1783297508955, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 231, train_loss = 2.17528323084116, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 232, train_loss = 2.1703481662552804, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 233, train_loss = 2.1666703708469868, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 234, train_loss = 2.1623718850314617, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 235, train_loss = 2.1573930867016315, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 236, train_loss = 2.155626028776169, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 237, train_loss = 2.149577879579738, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 238, train_loss = 2.1472399681806564, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 239, train_loss = 2.144082885235548, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 240, train_loss = 2.139090410200879, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 241, train_loss = 2.1353919331450015, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 242, train_loss = 2.1324933518189937, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 243, train_loss = 2.1288326729554683, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 244, train_loss = 2.124381073983386, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 245, train_loss = 2.1193246643524617, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 246, train_loss = 2.115694008767605, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 247, train_loss = 2.113531431881711, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 248, train_loss = 2.1090255603194237, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 249, train_loss = 2.106558268191293, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 250, train_loss = 2.1028401863295585, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 251, train_loss = 2.099032423226163, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 252, train_loss = 2.096488120732829, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 253, train_loss = 2.090795134427026, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 254, train_loss = 2.08744032564573, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 255, train_loss = 2.0848176293075085, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 256, train_loss = 2.0814797680359334, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 257, train_loss = 2.078164802165702, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 258, train_loss = 2.074380812468007, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 259, train_loss = 2.0730633188504726, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 260, train_loss = 2.067632469115779, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 261, train_loss = 2.067476539639756, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 262, train_loss = 2.061072463868186, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 263, train_loss = 2.0604181091766804, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 264, train_loss = 2.054822824895382, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 265, train_loss = 2.0523295502644032, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 266, train_loss = 2.049051867099479, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 267, train_loss = 2.0469402372837067, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 268, train_loss = 2.0426488518714905, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 269, train_loss = 2.039047207683325, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 270, train_loss = 2.037500587524846, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 271, train_loss = 2.034956745803356, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 272, train_loss = 2.030787381110713, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 273, train_loss = 2.0278751105070114, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 274, train_loss = 2.0260927986819297, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 275, train_loss = 2.0204804327804595, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 276, train_loss = 2.0210254788398743, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 277, train_loss = 2.015932605834678, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 278, train_loss = 2.014404720393941, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 279, train_loss = 2.0100967821199447, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 280, train_loss = 2.0082170490641147, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 281, train_loss = 2.0037602484226227, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 282, train_loss = 2.003208241192624, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 283, train_loss = 1.9990307588595897, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 284, train_loss = 1.9963337369263172, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 285, train_loss = 1.992976937443018, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 286, train_loss = 1.991729790926911, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 287, train_loss = 1.9877904715249315, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 288, train_loss = 1.9857006693491712, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 289, train_loss = 1.9844230128219351, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 290, train_loss = 1.979392254143022, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 291, train_loss = 1.9790384086081758, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 292, train_loss = 1.974115863442421, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 293, train_loss = 1.9735559622058645, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 294, train_loss = 1.969419981003739, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 295, train_loss = 1.968677124590613, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 296, train_loss = 1.964274536818266, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 297, train_loss = 1.9618368732044473, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 298, train_loss = 1.9592991782119498, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 299, train_loss = 1.9585992991924286, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 300, train_loss = 1.955085443914868, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 301, train_loss = 1.951599775464274, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 302, train_loss = 1.9496955896029249, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 303, train_loss = 1.9494723515817896, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 304, train_loss = 1.9460352584719658, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 305, train_loss = 1.943078293115832, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 306, train_loss = 1.9405930191278458, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 307, train_loss = 1.9380850294837728, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 308, train_loss = 1.9385235831141472, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 309, train_loss = 1.9340061707189307, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 310, train_loss = 1.933896515518427, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 311, train_loss = 1.9288479635724798, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 312, train_loss = 1.9292793286731467, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 313, train_loss = 1.9248879378428683, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 314, train_loss = 1.9228945957729593, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 315, train_loss = 1.9206065833568573, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 316, train_loss = 1.9179561076452956, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 317, train_loss = 1.9154827235033736, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 318, train_loss = 1.9132844805717468, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 319, train_loss = 1.911317971884273, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 320, train_loss = 1.9107221203157678, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 321, train_loss = 1.9082372846314684, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 322, train_loss = 1.9045160027453676, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 323, train_loss = 1.9045966006815434, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 324, train_loss = 1.9018687022617087, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 325, train_loss = 1.8981215158710256, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 326, train_loss = 1.8973144764313474, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 327, train_loss = 1.8964306823909283, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 328, train_loss = 1.892264055670239, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 329, train_loss = 1.8917352060088888, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 330, train_loss = 1.8892339443555102, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 331, train_loss = 1.8873795308172703, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 332, train_loss = 1.8864108584821224, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 333, train_loss = 1.8843510734150186, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 334, train_loss = 1.881387903005816, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 335, train_loss = 1.8799254223704338, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 336, train_loss = 1.877728776424192, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 337, train_loss = 1.8776778491446748, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 338, train_loss = 1.8741799084236845, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 339, train_loss = 1.8736078204819933, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 340, train_loss = 1.870311114937067, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 341, train_loss = 1.871543119312264, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 342, train_loss = 1.8666561655700207, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 343, train_loss = 1.8639318210771307, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 344, train_loss = 1.8663669601082802, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 345, train_loss = 1.8612226098775864, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 346, train_loss = 1.8592041693627834, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 347, train_loss = 1.8585707172751427, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 348, train_loss = 1.8556236861040816, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 349, train_loss = 1.8535630392143503, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 350, train_loss = 1.854467915953137, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 351, train_loss = 1.8498164030024782, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 352, train_loss = 1.8508346850285307, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 353, train_loss = 1.8481764607131481, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 354, train_loss = 1.8464276691665873, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 355, train_loss = 1.8437000500271097, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 356, train_loss = 1.8426681868731976, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 357, train_loss = 1.8401076160371304, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 358, train_loss = 1.8406707147369161, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 359, train_loss = 1.8379729116568342, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 360, train_loss = 1.8353763781487942, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 361, train_loss = 1.8336335556814447, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 362, train_loss = 1.8323843678226694, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 363, train_loss = 1.8301398096373305, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 364, train_loss = 1.8287050127983093, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 365, train_loss = 1.8288243412971497, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 366, train_loss = 1.8263704677810892, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 367, train_loss = 1.8240892899921164, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 368, train_loss = 1.8252204036107287, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 369, train_loss = 1.8212215192615986, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 370, train_loss = 1.8205165913095698, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 371, train_loss = 1.8187931602587923, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 372, train_loss = 1.8170223360648379, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 373, train_loss = 1.8149107123026624, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 374, train_loss = 1.814431469887495, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 375, train_loss = 1.8130320260534063, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 376, train_loss = 1.8112763402750716, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 377, train_loss = 1.8095629314193502, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 378, train_loss = 1.807619026512839, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 379, train_loss = 1.8081375807523727, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 380, train_loss = 1.804444576264359, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 381, train_loss = 1.8038662361213937, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 382, train_loss = 1.802219750941731, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 383, train_loss = 1.8026071799686179, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 384, train_loss = 1.7997469753026962, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 385, train_loss = 1.7973463659873232, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 386, train_loss = 1.796766328276135, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 387, train_loss = 1.7953095585107803, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 388, train_loss = 1.7940793199231848, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 389, train_loss = 1.7941499116132036, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 390, train_loss = 1.790835247724317, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 391, train_loss = 1.7894423753023148, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 392, train_loss = 1.789283680380322, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 393, train_loss = 1.7873593656113371, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 394, train_loss = 1.7862676667282358, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 395, train_loss = 1.785013442276977, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 396, train_loss = 1.7830658368766308, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 397, train_loss = 1.7822505285730585, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 398, train_loss = 1.7807173120090738, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 399, train_loss = 1.778857622295618, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 400, train_loss = 1.77811349183321, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 401, train_loss = 1.7775472378125414, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 402, train_loss = 1.7752829864621162, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 403, train_loss = 1.773276835680008, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 404, train_loss = 1.772029654472135, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 405, train_loss = 1.7716746231308207, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 406, train_loss = 1.7703572250902653, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 407, train_loss = 1.7692637331783772, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 408, train_loss = 1.768826987594366, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 409, train_loss = 1.7659083778271452, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 410, train_loss = 1.7655621418962255, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 411, train_loss = 1.7634379776427522, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 412, train_loss = 1.7623572064330801, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 413, train_loss = 1.7614862322807312, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 414, train_loss = 1.7599206902086735, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 415, train_loss = 1.7589805064490065, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 416, train_loss = 1.760228137136437, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 417, train_loss = 1.7574184028198943, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 418, train_loss = 1.7549492506077513, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 419, train_loss = 1.7545956944813952, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 420, train_loss = 1.7534818314015865, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 421, train_loss = 1.7531295815715566, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 422, train_loss = 1.750586544512771, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 423, train_loss = 1.7518453499069437, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 424, train_loss = 1.7492743706097826, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 425, train_loss = 1.7483662279555574, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 426, train_loss = 1.7459051869809628, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 427, train_loss = 1.7468771574785933, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 428, train_loss = 1.7448451420059428, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 429, train_loss = 1.7444054372608662, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 430, train_loss = 1.7425427002599463, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 431, train_loss = 1.741249488084577, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 432, train_loss = 1.7417188746621832, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 433, train_loss = 1.7388565862784162, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 434, train_loss = 1.737619517953135, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 435, train_loss = 1.736281874240376, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 436, train_loss = 1.7358228923985735, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 437, train_loss = 1.7348679453134537, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 438, train_loss = 1.7334524244070053, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 439, train_loss = 1.731742809235584, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 440, train_loss = 1.732748723239638, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 441, train_loss = 1.731125625432469, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 442, train_loss = 1.7306792015442625, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 443, train_loss = 1.728364024311304, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 444, train_loss = 1.7291949838399887, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 445, train_loss = 1.7264217634801753, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 446, train_loss = 1.725196170329582, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 447, train_loss = 1.7246351018548012, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 448, train_loss = 1.7236758954823017, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 449, train_loss = 1.7226150880451314, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 450, train_loss = 1.723723292350769, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 451, train_loss = 1.720322284847498, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 452, train_loss = 1.718739962845575, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 453, train_loss = 1.7187363554839976, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 454, train_loss = 1.7177907638251781, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 455, train_loss = 1.7158947450225241, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 456, train_loss = 1.7152350072865374, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 457, train_loss = 1.7146974566276185, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 458, train_loss = 1.7132002103026025, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 459, train_loss = 1.7140865835244767, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 460, train_loss = 1.7120968202943914, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 461, train_loss = 1.7121810826356523, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 462, train_loss = 1.710020602971781, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 463, train_loss = 1.7086227971012704, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 464, train_loss = 1.709613620012533, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 465, train_loss = 1.7072596562211402, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 466, train_loss = 1.7071469947695732, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 467, train_loss = 1.7049320650403388, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 468, train_loss = 1.7063007727265358, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 469, train_loss = 1.704248012334574, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 470, train_loss = 1.703394087671768, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 471, train_loss = 1.702365470409859, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 472, train_loss = 1.7011377215385437, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 473, train_loss = 1.7003768633003347, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 474, train_loss = 1.699580681801308, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 475, train_loss = 1.698059671849478, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 476, train_loss = 1.6969291865825653, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 477, train_loss = 1.696929591416847, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 478, train_loss = 1.696561560034752, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 479, train_loss = 1.6948066328768618, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 480, train_loss = 1.6938082140986808, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 481, train_loss = 1.6933795846998692, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 482, train_loss = 1.692788312851917, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 483, train_loss = 1.6909003269975074, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 484, train_loss = 1.6904806556995027, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 485, train_loss = 1.6865033581852913, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 486, train_loss = 1.6906505550141446, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 487, train_loss = 1.6881880548899062, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 488, train_loss = 1.6848709073965438, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 489, train_loss = 1.6838758923113346, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 490, train_loss = 1.6845229119062424, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 491, train_loss = 1.6826704156701453, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 492, train_loss = 1.6849629792268388, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 493, train_loss = 1.6844804708962329, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 494, train_loss = 1.6847445244784467, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 495, train_loss = 1.6842410403187387, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 496, train_loss = 1.681804406165611, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 497, train_loss = 1.6819089514319785, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 498, train_loss = 1.6810184543137439, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 499, train_loss = 1.6799349102075212, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████▊                                                                    | 2/30 [18:05<4:13:18, 542.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "3th- epoch: 0, train_loss = 103.90057855844498, train_acc = 0.7863297624592455\n",
      "test Acc 0.8556797020484171:\n",
      "3th- epoch: 1, train_loss = 40.09911388158798, train_acc = 0.9112715416860736\n",
      "test Acc 0.9134078212290503:\n",
      "3th- epoch: 2, train_loss = 30.716049134731293, train_acc = 0.9358407079646017\n",
      "test Acc 0.9264432029795159:\n",
      "3th- epoch: 3, train_loss = 26.072980005294085, train_acc = 0.9448067070330693\n",
      "test Acc 0.9338919925512105:\n",
      "3th- epoch: 4, train_loss = 23.093431018292904, train_acc = 0.9508616674429436\n",
      "test Acc 0.9385474860335196:\n",
      "3th- epoch: 5, train_loss = 20.90156902000308, train_acc = 0.9551700046576619\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 6, train_loss = 19.20166615024209, train_acc = 0.9593619003260363\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 7, train_loss = 17.822370257228613, train_acc = 0.9628551467163484\n",
      "test Acc 0.9511173184357542:\n",
      "3th- epoch: 8, train_loss = 16.686302857473493, train_acc = 0.9650675360968793\n",
      "test Acc 0.952513966480447:\n",
      "3th- epoch: 9, train_loss = 15.725676082074642, train_acc = 0.9669306008383791\n",
      "test Acc 0.952513966480447:\n",
      "3th- epoch: 10, train_loss = 14.894086355343461, train_acc = 0.9682114578481602\n",
      "test Acc 0.9548417132216015:\n",
      "3th- epoch: 11, train_loss = 14.171307912096381, train_acc = 0.9698416394969726\n",
      "test Acc 0.9557728119180633:\n",
      "3th- epoch: 12, train_loss = 13.520376911386847, train_acc = 0.971821145784816\n",
      "test Acc 0.9557728119180633:\n",
      "3th- epoch: 13, train_loss = 12.942675679922104, train_acc = 0.9729855612482534\n",
      "test Acc 0.957169459962756:\n",
      "3th- epoch: 14, train_loss = 12.42485449463129, train_acc = 0.9738006520726595\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 15, train_loss = 11.947814524173737, train_acc = 0.9743828598043782\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 16, train_loss = 11.51632740162313, train_acc = 0.9748486259897532\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 17, train_loss = 11.121658822521567, train_acc = 0.975780158360503\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 18, train_loss = 10.762062132358551, train_acc = 0.9761294829995343\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 19, train_loss = 10.424551658332348, train_acc = 0.9768281322775967\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 20, train_loss = 10.111941328272223, train_acc = 0.9774103400093154\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 21, train_loss = 9.818209631368518, train_acc = 0.9777596646483465\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 22, train_loss = 9.544249245896935, train_acc = 0.9788076385654402\n",
      "test Acc 0.9622905027932961:\n",
      "3th- epoch: 23, train_loss = 9.288991732522845, train_acc = 0.9798556124825337\n",
      "test Acc 0.962756052141527:\n",
      "3th- epoch: 24, train_loss = 9.045041309669614, train_acc = 0.9803213786679087\n",
      "test Acc 0.9632216014897579:\n",
      "3th- epoch: 25, train_loss = 8.81819006614387, train_acc = 0.98067070330694\n",
      "test Acc 0.9632216014897579:\n",
      "3th- epoch: 26, train_loss = 8.60536085627973, train_acc = 0.9809035863996274\n",
      "test Acc 0.9632216014897579:\n",
      "3th- epoch: 27, train_loss = 8.403367346152663, train_acc = 0.9817186772240335\n",
      "test Acc 0.9632216014897579:\n",
      "3th- epoch: 28, train_loss = 8.215150381438434, train_acc = 0.9823008849557522\n",
      "test Acc 0.9632216014897579:\n",
      "3th- epoch: 29, train_loss = 8.03730675112456, train_acc = 0.9825337680484397\n",
      "test Acc 0.9632216014897579:\n",
      "3th- epoch: 30, train_loss = 7.87073390185833, train_acc = 0.9832324173265021\n",
      "test Acc 0.9632216014897579:\n",
      "3th- epoch: 31, train_loss = 7.70695676933974, train_acc = 0.9835817419655333\n",
      "test Acc 0.962756052141527:\n",
      "3th- epoch: 32, train_loss = 7.556561146862805, train_acc = 0.9838146250582208\n",
      "test Acc 0.9636871508379888:\n",
      "3th- epoch: 33, train_loss = 7.411459694616497, train_acc = 0.9840475081509082\n",
      "test Acc 0.9636871508379888:\n",
      "3th- epoch: 34, train_loss = 7.274344481527805, train_acc = 0.984163949697252\n",
      "test Acc 0.9636871508379888:\n",
      "3th- epoch: 35, train_loss = 7.139122764579952, train_acc = 0.9846297158826269\n",
      "test Acc 0.9641527001862198:\n",
      "3th- epoch: 36, train_loss = 7.014602668583393, train_acc = 0.9848625989753144\n",
      "test Acc 0.9641527001862198:\n",
      "3th- epoch: 37, train_loss = 6.891964706592262, train_acc = 0.9852119236143456\n",
      "test Acc 0.9641527001862198:\n",
      "3th- epoch: 38, train_loss = 6.775149690918624, train_acc = 0.9855612482533768\n",
      "test Acc 0.9646182495344506:\n",
      "3th- epoch: 39, train_loss = 6.660005864687264, train_acc = 0.9856776897997206\n",
      "test Acc 0.9655493482309124:\n",
      "3th- epoch: 40, train_loss = 6.550098526291549, train_acc = 0.9860270144387517\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 41, train_loss = 6.441675151698291, train_acc = 0.9861434559850955\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 42, train_loss = 6.333454390056431, train_acc = 0.986376339077783\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 43, train_loss = 6.23212452698499, train_acc = 0.986376339077783\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 44, train_loss = 6.136037938296795, train_acc = 0.9862598975314392\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 45, train_loss = 6.043909306637943, train_acc = 0.9866092221704704\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 46, train_loss = 5.95339712779969, train_acc = 0.9867256637168141\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 47, train_loss = 5.866447131149471, train_acc = 0.9870749883558454\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 48, train_loss = 5.7824274180457, train_acc = 0.9873078714485328\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 49, train_loss = 5.699583128094673, train_acc = 0.9875407545412203\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 50, train_loss = 5.622249287553132, train_acc = 0.9875407545412203\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 51, train_loss = 5.54727425891906, train_acc = 0.9878900791802515\n",
      "test Acc 0.9664804469273743:\n",
      "3th- epoch: 52, train_loss = 5.472725699655712, train_acc = 0.9880065207265952\n",
      "test Acc 0.9669459962756052:\n",
      "3th- epoch: 53, train_loss = 5.403649245388806, train_acc = 0.9882394038192828\n",
      "test Acc 0.9674115456238361:\n",
      "3th- epoch: 54, train_loss = 5.333460979163647, train_acc = 0.9883558453656265\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 55, train_loss = 5.2684739753603935, train_acc = 0.9887051700046576\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 56, train_loss = 5.204652686603367, train_acc = 0.9888216115510013\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 57, train_loss = 5.142384211532772, train_acc = 0.9888216115510013\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 58, train_loss = 5.079855106770992, train_acc = 0.9889380530973452\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 59, train_loss = 5.020738591440022, train_acc = 0.9889380530973452\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 60, train_loss = 4.963281013071537, train_acc = 0.9892873777363763\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 61, train_loss = 4.9055330427363515, train_acc = 0.98940381928272\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 62, train_loss = 4.85070261079818, train_acc = 0.9896367023754076\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 63, train_loss = 4.796293509192765, train_acc = 0.9896367023754076\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 64, train_loss = 4.745122534222901, train_acc = 0.9896367023754076\n",
      "test Acc 0.9697392923649907:\n",
      "3th- epoch: 65, train_loss = 4.693191180936992, train_acc = 0.9897531439217513\n",
      "test Acc 0.9702048417132216:\n",
      "3th- epoch: 66, train_loss = 4.641849967651069, train_acc = 0.989869585468095\n",
      "test Acc 0.9702048417132216:\n",
      "3th- epoch: 67, train_loss = 4.594976591877639, train_acc = 0.989869585468095\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 68, train_loss = 4.548876203596592, train_acc = 0.9899860270144387\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 69, train_loss = 4.502717894501984, train_acc = 0.99033535165347\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 70, train_loss = 4.4580488577485085, train_acc = 0.9905682347461574\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 71, train_loss = 4.414249767549336, train_acc = 0.9906846762925011\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 72, train_loss = 4.373026388697326, train_acc = 0.990801117838845\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 73, train_loss = 4.3316145511344075, train_acc = 0.9909175593851887\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 74, train_loss = 4.290950179100037, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 75, train_loss = 4.25293615180999, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 76, train_loss = 4.213870721869171, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 77, train_loss = 4.175380577798933, train_acc = 0.9913833255705635\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 78, train_loss = 4.1379028731025755, train_acc = 0.9913833255705635\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 79, train_loss = 4.10119459265843, train_acc = 0.9916162086632511\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 80, train_loss = 4.0663168132305145, train_acc = 0.9917326502095948\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 81, train_loss = 4.030583664774895, train_acc = 0.9918490917559385\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 82, train_loss = 3.997769519686699, train_acc = 0.9918490917559385\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 83, train_loss = 3.965020403265953, train_acc = 0.9918490917559385\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 84, train_loss = 3.9322123057208955, train_acc = 0.992081974848626\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 85, train_loss = 3.9010294848121703, train_acc = 0.992081974848626\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 86, train_loss = 3.8702085316181183, train_acc = 0.992081974848626\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 87, train_loss = 3.8405249565839767, train_acc = 0.9921984163949698\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 88, train_loss = 3.8125713244080544, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 89, train_loss = 3.7818824374116957, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 90, train_loss = 3.7534255809150636, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 91, train_loss = 3.7261033332906663, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 92, train_loss = 3.6981939114630222, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 93, train_loss = 3.6718391091562808, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 94, train_loss = 3.6453232155181468, train_acc = 0.9921984163949698\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 95, train_loss = 3.6200275383889675, train_acc = 0.9921984163949698\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 96, train_loss = 3.594462742563337, train_acc = 0.9921984163949698\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 97, train_loss = 3.5704803578555584, train_acc = 0.9921984163949698\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 98, train_loss = 3.5453131631948054, train_acc = 0.9921984163949698\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 99, train_loss = 3.521169921848923, train_acc = 0.992081974848626\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 100, train_loss = 3.4975845464505255, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 101, train_loss = 3.474493523593992, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 102, train_loss = 3.452101554721594, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 103, train_loss = 3.4295437620021403, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 104, train_loss = 3.4085857830941677, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 105, train_loss = 3.387620896100998, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 106, train_loss = 3.3657550304196775, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 107, train_loss = 3.346013080328703, train_acc = 0.9924312994876572\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 108, train_loss = 3.3265654616989195, train_acc = 0.9924312994876572\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 109, train_loss = 3.3060549325309694, train_acc = 0.9924312994876572\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 110, train_loss = 3.2877005548216403, train_acc = 0.9924312994876572\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 111, train_loss = 3.2678699255920947, train_acc = 0.9924312994876572\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 112, train_loss = 3.2481384836137295, train_acc = 0.9924312994876572\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 113, train_loss = 3.228375038597733, train_acc = 0.9924312994876572\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 114, train_loss = 3.2107112109661102, train_acc = 0.9925477410340009\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 115, train_loss = 3.191748396959156, train_acc = 0.9925477410340009\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 116, train_loss = 3.175003835465759, train_acc = 0.9925477410340009\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 117, train_loss = 3.1574977613054216, train_acc = 0.9926641825803446\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 118, train_loss = 3.1408250792883337, train_acc = 0.9927806241266884\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 119, train_loss = 3.1233333931304514, train_acc = 0.9927806241266884\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 120, train_loss = 3.1073173880577087, train_acc = 0.9927806241266884\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 121, train_loss = 3.0901481471955776, train_acc = 0.9927806241266884\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 122, train_loss = 3.0752155110239983, train_acc = 0.9927806241266884\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 123, train_loss = 3.0593294762074947, train_acc = 0.9928970656730322\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 124, train_loss = 3.043933729175478, train_acc = 0.9930135072193759\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 125, train_loss = 3.0279004462063313, train_acc = 0.9930135072193759\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 126, train_loss = 3.012992937117815, train_acc = 0.9930135072193759\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 127, train_loss = 2.9991769529879093, train_acc = 0.9930135072193759\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 128, train_loss = 2.9843232021667063, train_acc = 0.9931299487657196\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 129, train_loss = 2.9699643230997026, train_acc = 0.9931299487657196\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 130, train_loss = 2.9558412968181074, train_acc = 0.9931299487657196\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 131, train_loss = 2.942781388759613, train_acc = 0.9933628318584071\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 132, train_loss = 2.9285392998717725, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 133, train_loss = 2.9156442335806787, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 134, train_loss = 2.902315676212311, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 135, train_loss = 2.8889585062861443, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 136, train_loss = 2.875628639012575, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 137, train_loss = 2.863663647323847, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 138, train_loss = 2.8504271232523024, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 139, train_loss = 2.839123821351677, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 140, train_loss = 2.8253424293361604, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 141, train_loss = 2.81445744773373, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 142, train_loss = 2.802299519535154, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 143, train_loss = 2.7902306192554533, train_acc = 0.9935957149510946\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 144, train_loss = 2.77902273228392, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 145, train_loss = 2.7669778554700315, train_acc = 0.9935957149510946\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 146, train_loss = 2.7558696107007563, train_acc = 0.9934792734047508\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 147, train_loss = 2.744730909820646, train_acc = 0.9934792734047508\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 148, train_loss = 2.7343355431221426, train_acc = 0.9935957149510946\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 149, train_loss = 2.723738618195057, train_acc = 0.9935957149510946\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 150, train_loss = 2.712595332413912, train_acc = 0.9935957149510946\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 151, train_loss = 2.702894315123558, train_acc = 0.9935957149510946\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 152, train_loss = 2.6926326144021004, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 153, train_loss = 2.682493343949318, train_acc = 0.9937121564974383\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 154, train_loss = 2.671792224049568, train_acc = 0.993828598043782\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 155, train_loss = 2.6621475976426154, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 156, train_loss = 2.6526781853754073, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 157, train_loss = 2.6424047611653805, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 158, train_loss = 2.6336854968685657, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 159, train_loss = 2.62335953861475, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 160, train_loss = 2.6140287679154426, train_acc = 0.9939450395901258\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 161, train_loss = 2.6056854415219277, train_acc = 0.9939450395901258\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 162, train_loss = 2.5961786347907037, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 163, train_loss = 2.586948974756524, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 164, train_loss = 2.578558072447777, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 165, train_loss = 2.569604678777978, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 166, train_loss = 2.5608158248942345, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 167, train_loss = 2.552531458437443, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 168, train_loss = 2.5434600065927953, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 169, train_loss = 2.5355033080559224, train_acc = 0.9941779226828132\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 170, train_loss = 2.5271656054537743, train_acc = 0.994294364229157\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 171, train_loss = 2.51906256750226, train_acc = 0.9941779226828132\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 172, train_loss = 2.510956261307001, train_acc = 0.994294364229157\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 173, train_loss = 2.5020160761196166, train_acc = 0.9941779226828132\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 174, train_loss = 2.4955072354059666, train_acc = 0.994294364229157\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 175, train_loss = 2.487421269295737, train_acc = 0.994294364229157\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 176, train_loss = 2.4796632453799248, train_acc = 0.994294364229157\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 177, train_loss = 2.471942574949935, train_acc = 0.994294364229157\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 178, train_loss = 2.4647342562675476, train_acc = 0.994294364229157\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 179, train_loss = 2.455863443436101, train_acc = 0.994294364229157\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 180, train_loss = 2.449174653738737, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 181, train_loss = 2.4421555150765926, train_acc = 0.994294364229157\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 182, train_loss = 2.4360792860388756, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 183, train_loss = 2.4282105043530464, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 184, train_loss = 2.4215027019381523, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 185, train_loss = 2.4141483940184116, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 186, train_loss = 2.4078623552341014, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 187, train_loss = 2.400934688746929, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 188, train_loss = 2.394152610329911, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 189, train_loss = 2.3878732658922672, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 190, train_loss = 2.3811776663642377, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 191, train_loss = 2.375214147148654, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 192, train_loss = 2.3681294445414096, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 193, train_loss = 2.3613656274974346, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 194, train_loss = 2.356499034911394, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 195, train_loss = 2.3494856369215995, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 196, train_loss = 2.3437813345808536, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 197, train_loss = 2.3371197395026684, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 198, train_loss = 2.3320115345995873, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 199, train_loss = 2.325857140123844, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 200, train_loss = 2.3192435142118484, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 201, train_loss = 2.3144478474278003, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 202, train_loss = 2.3078406900167465, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 203, train_loss = 2.302813284099102, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 204, train_loss = 2.296955782920122, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 205, train_loss = 2.291431983234361, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 206, train_loss = 2.2860624988097697, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 207, train_loss = 2.2805636264383793, train_acc = 0.9944108057755007\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 208, train_loss = 2.275150342611596, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 209, train_loss = 2.270312139065936, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 210, train_loss = 2.2647183674853295, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 211, train_loss = 2.259415030479431, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 212, train_loss = 2.2537605985999107, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 213, train_loss = 2.2491025626659393, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 214, train_loss = 2.2440505686681718, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 215, train_loss = 2.2387259353417903, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 216, train_loss = 2.234846359817311, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 217, train_loss = 2.229245750932023, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 218, train_loss = 2.2241528294980526, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 219, train_loss = 2.2194507110398263, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 220, train_loss = 2.214331754716113, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 221, train_loss = 2.2099424253683537, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 222, train_loss = 2.2055898010730743, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 223, train_loss = 2.200084000825882, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 224, train_loss = 2.1957404997665435, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 225, train_loss = 2.190817669034004, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 226, train_loss = 2.1867525402922183, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 227, train_loss = 2.182031748117879, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 228, train_loss = 2.177623875439167, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 229, train_loss = 2.173464183928445, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 230, train_loss = 2.1689026926178485, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 231, train_loss = 2.1647091694176197, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 232, train_loss = 2.160554201574996, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 233, train_loss = 2.156946128932759, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 234, train_loss = 2.151796283898875, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 235, train_loss = 2.147902276366949, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 236, train_loss = 2.1438755716662854, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 237, train_loss = 2.139835013775155, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 238, train_loss = 2.134957044152543, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 239, train_loss = 2.1319428745191544, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 240, train_loss = 2.1269334740936756, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 241, train_loss = 2.1230917412322015, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 242, train_loss = 2.1192618075292557, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 243, train_loss = 2.1154170110821724, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 244, train_loss = 2.1114537864923477, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 245, train_loss = 2.108068034052849, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 246, train_loss = 2.1031070488970727, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 247, train_loss = 2.100225002737716, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 248, train_loss = 2.096243266016245, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 249, train_loss = 2.0929713409859687, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 250, train_loss = 2.0885861564893275, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 251, train_loss = 2.085323852719739, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 252, train_loss = 2.0815756109077483, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 253, train_loss = 2.077404413372278, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 254, train_loss = 2.074214569060132, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 255, train_loss = 2.071420884341933, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 256, train_loss = 2.0673656575381756, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 257, train_loss = 2.0640806244919077, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 258, train_loss = 2.0610053775599226, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 259, train_loss = 2.056351013481617, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 260, train_loss = 2.054121228517033, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 261, train_loss = 2.050826078862883, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 262, train_loss = 2.046277870773338, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 263, train_loss = 2.0436091708252206, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 264, train_loss = 2.0399773927638307, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 265, train_loss = 2.037555576651357, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 266, train_loss = 2.0342416936764494, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 267, train_loss = 2.0309806080767885, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 268, train_loss = 2.0277960523962975, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 269, train_loss = 2.0240371437976137, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 270, train_loss = 2.020888692350127, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 271, train_loss = 2.018404543399811, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 272, train_loss = 2.0145956178894266, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 273, train_loss = 2.0122694969177246, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 274, train_loss = 2.0090064965188503, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 275, train_loss = 2.0059041244676337, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 276, train_loss = 2.003912054002285, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 277, train_loss = 2.0003237202763557, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 278, train_loss = 1.9971984922885895, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 279, train_loss = 1.9944958426058292, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 280, train_loss = 1.9913651397218928, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 281, train_loss = 1.988982922048308, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 282, train_loss = 1.9855362909147516, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 283, train_loss = 1.9831044115126133, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 284, train_loss = 1.9805475311586633, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 285, train_loss = 1.9776246882975101, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 286, train_loss = 1.9747235079994425, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 287, train_loss = 1.9718709079315886, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 288, train_loss = 1.9695347932865843, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 289, train_loss = 1.9661340353777632, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 290, train_loss = 1.9639459090540186, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 291, train_loss = 1.9613737153122202, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 292, train_loss = 1.9579757353058085, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 293, train_loss = 1.955901296227239, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 294, train_loss = 1.9539242113241926, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 295, train_loss = 1.9509621312608942, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 296, train_loss = 1.9483303390443325, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 297, train_loss = 1.9455139277270064, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 298, train_loss = 1.9426177702844143, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 299, train_loss = 1.9400896144798025, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 300, train_loss = 1.9378649294376373, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 301, train_loss = 1.9361879924545065, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 302, train_loss = 1.9333227388560772, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 303, train_loss = 1.931398638873361, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 304, train_loss = 1.9284613778581843, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 305, train_loss = 1.92558352148626, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 306, train_loss = 1.9237520383903757, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 307, train_loss = 1.9209640672197565, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 308, train_loss = 1.9187673864653334, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 309, train_loss = 1.9165011284640059, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 310, train_loss = 1.914099826128222, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 311, train_loss = 1.9123026033630595, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 312, train_loss = 1.9097415134310722, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 313, train_loss = 1.9068995080888271, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 314, train_loss = 1.9041174551239237, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 315, train_loss = 1.9027346534421667, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 316, train_loss = 1.9005328491330147, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 317, train_loss = 1.8985960955033079, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 318, train_loss = 1.8963081017136574, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 319, train_loss = 1.8941039306810126, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 320, train_loss = 1.8920526070287451, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 321, train_loss = 1.8895067175617442, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 322, train_loss = 1.8874711096286774, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 323, train_loss = 1.8854545740177855, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 324, train_loss = 1.8832471607020125, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 325, train_loss = 1.8812250345945358, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 326, train_loss = 1.8792722435900941, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 327, train_loss = 1.877203993499279, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 328, train_loss = 1.87518757826183, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 329, train_loss = 1.8728177199373022, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 330, train_loss = 1.870174607844092, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 331, train_loss = 1.8692251382162794, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 332, train_loss = 1.8662963211536407, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 333, train_loss = 1.865486158640124, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 334, train_loss = 1.8625690266489983, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 335, train_loss = 1.8608775524189696, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 336, train_loss = 1.8592639738926664, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 337, train_loss = 1.856648713350296, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 338, train_loss = 1.854784989147447, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 339, train_loss = 1.8532850295305252, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 340, train_loss = 1.850958346039988, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 341, train_loss = 1.8490874009439722, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 342, train_loss = 1.8471077419817448, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 343, train_loss = 1.8455112241208553, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 344, train_loss = 1.8438158184289932, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 345, train_loss = 1.8417220438132063, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 346, train_loss = 1.8404330449411646, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 347, train_loss = 1.8378864886472002, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 348, train_loss = 1.8366014746716246, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 349, train_loss = 1.834491784335114, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 350, train_loss = 1.8334621539106593, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 351, train_loss = 1.8318246131530032, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 352, train_loss = 1.8293461414286867, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 353, train_loss = 1.8278107568621635, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 354, train_loss = 1.8254457538714632, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 355, train_loss = 1.8242518715560436, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 356, train_loss = 1.8226490778615698, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 357, train_loss = 1.8200468322029337, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 358, train_loss = 1.818591944873333, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 359, train_loss = 1.8178785219788551, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 360, train_loss = 1.8156235901406035, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 361, train_loss = 1.8140626238891855, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 362, train_loss = 1.8118916526436806, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 363, train_loss = 1.810740027576685, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 364, train_loss = 1.8085261099040508, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 365, train_loss = 1.8068707697093487, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 366, train_loss = 1.8047984590521082, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 367, train_loss = 1.8037323765456676, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 368, train_loss = 1.8023647256195545, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 369, train_loss = 1.801139303832315, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 370, train_loss = 1.798732635914348, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 371, train_loss = 1.7975299718091264, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 372, train_loss = 1.7963572753360495, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 373, train_loss = 1.7940475816139951, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 374, train_loss = 1.7927993424236774, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 375, train_loss = 1.791433141916059, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 376, train_loss = 1.7902780175209045, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 377, train_loss = 1.7882346560945734, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 378, train_loss = 1.7860832897713408, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 379, train_loss = 1.7847995832562447, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 380, train_loss = 1.7838755076518282, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 381, train_loss = 1.7822767036268488, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 382, train_loss = 1.7807766186306253, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 383, train_loss = 1.779184464365244, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 384, train_loss = 1.778494822443463, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 385, train_loss = 1.7770669063320383, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 386, train_loss = 1.7747084448346868, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 387, train_loss = 1.773953452706337, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 388, train_loss = 1.7720497263362631, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 389, train_loss = 1.7708476036787033, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 390, train_loss = 1.7695213444530964, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 391, train_loss = 1.767843889654614, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 392, train_loss = 1.7672577550401911, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 393, train_loss = 1.764821016578935, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 394, train_loss = 1.7635471299290657, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 395, train_loss = 1.7627154228975996, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 396, train_loss = 1.7614754835376516, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 397, train_loss = 1.7597478268435225, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 398, train_loss = 1.758306846022606, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 399, train_loss = 1.7572882188251242, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 400, train_loss = 1.7559427507221699, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 401, train_loss = 1.7547551492461935, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 402, train_loss = 1.752791783423163, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 403, train_loss = 1.7516998624196276, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 404, train_loss = 1.750504169613123, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 405, train_loss = 1.7492444576928392, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 406, train_loss = 1.7481692271539941, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 407, train_loss = 1.7472435993840918, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 408, train_loss = 1.7448167552938685, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 409, train_loss = 1.744849767535925, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 410, train_loss = 1.7435047887265682, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 411, train_loss = 1.741409538895823, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 412, train_loss = 1.740581570775248, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 413, train_loss = 1.7399651681771502, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 414, train_loss = 1.7382580253179185, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 415, train_loss = 1.7376461327075958, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 416, train_loss = 1.7359030929510482, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 417, train_loss = 1.734877263486851, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 418, train_loss = 1.7330734978313558, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 419, train_loss = 1.733503622293938, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 420, train_loss = 1.731111514091026, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 421, train_loss = 1.7296919536893256, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 422, train_loss = 1.72955858084606, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 423, train_loss = 1.7277372404932976, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 424, train_loss = 1.7264663738314994, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 425, train_loss = 1.7248865577275865, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 426, train_loss = 1.7239384899730794, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 427, train_loss = 1.7236768404836766, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 428, train_loss = 1.7222824841737747, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 429, train_loss = 1.7211975641548634, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 430, train_loss = 1.7195510268211365, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 431, train_loss = 1.7190865613520145, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 432, train_loss = 1.7173606070573442, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 433, train_loss = 1.7168561753933318, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 434, train_loss = 1.71525264903903, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 435, train_loss = 1.7147293177549727, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 436, train_loss = 1.7132161098415963, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 437, train_loss = 1.7121516590123065, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 438, train_loss = 1.7109137338702567, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 439, train_loss = 1.7102516181766987, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 440, train_loss = 1.708837064623367, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 441, train_loss = 1.7081054573063739, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 442, train_loss = 1.7071183733642101, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 443, train_loss = 1.705749900371302, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 444, train_loss = 1.7044090802664869, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 445, train_loss = 1.7037984319031239, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 446, train_loss = 1.7022982984781265, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 447, train_loss = 1.701097181707155, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 448, train_loss = 1.700685425370466, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 449, train_loss = 1.6997139267623425, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 450, train_loss = 1.6984996696119197, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 451, train_loss = 1.6974153990740888, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 452, train_loss = 1.69664017111063, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 453, train_loss = 1.6962973127956502, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 454, train_loss = 1.6939474108512513, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 455, train_loss = 1.6941516697406769, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 456, train_loss = 1.692688349634409, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 457, train_loss = 1.6917322154040448, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 458, train_loss = 1.6909682787954807, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 459, train_loss = 1.6897467710077763, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 460, train_loss = 1.6884309339220636, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 461, train_loss = 1.687578399956692, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 462, train_loss = 1.6869742746348493, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 463, train_loss = 1.6865704879164696, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 464, train_loss = 1.6845645482535474, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 465, train_loss = 1.6844299174845219, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 466, train_loss = 1.683402595401276, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 467, train_loss = 1.6816904445295222, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 468, train_loss = 1.6818803015048616, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 469, train_loss = 1.6805160206859, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 470, train_loss = 1.6796135666663758, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 471, train_loss = 1.6788282034103759, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 472, train_loss = 1.677449191629421, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 473, train_loss = 1.6772166788578033, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 474, train_loss = 1.6764099660213105, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 475, train_loss = 1.6753421127796173, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 476, train_loss = 1.674426442652475, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 477, train_loss = 1.6738154478371143, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 478, train_loss = 1.672149674326647, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 479, train_loss = 1.6723496106569655, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 480, train_loss = 1.6710494955186732, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 481, train_loss = 1.6706025240127929, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 482, train_loss = 1.6695407194201834, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 483, train_loss = 1.6679099313914776, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 484, train_loss = 1.667203028977383, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 485, train_loss = 1.6666794009506702, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 486, train_loss = 1.6646309159696102, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 487, train_loss = 1.6648044039611705, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 488, train_loss = 1.6640858774189837, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 489, train_loss = 1.663461573421955, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 490, train_loss = 1.6614753591711633, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 491, train_loss = 1.6611933447420597, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 492, train_loss = 1.6609040523762815, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 493, train_loss = 1.6592041067779064, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 494, train_loss = 1.659228105098009, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 495, train_loss = 1.658865462988615, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 496, train_loss = 1.657297506928444, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 497, train_loss = 1.6567466582055204, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 498, train_loss = 1.6558327724342234, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 499, train_loss = 1.655293504416477, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▎                                                                 | 3/30 [27:07<4:04:06, 542.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "4th- epoch: 0, train_loss = 108.69461387395859, train_acc = 0.8022822543083372\n",
      "test Acc 0.8915270018621974:\n",
      "4th- epoch: 1, train_loss = 37.936294339597225, train_acc = 0.9190731252911039\n",
      "test Acc 0.9278398510242085:\n",
      "4th- epoch: 2, train_loss = 28.93476329743862, train_acc = 0.9377037727061015\n",
      "test Acc 0.9380819366852886:\n",
      "4th- epoch: 3, train_loss = 24.6188601590693, train_acc = 0.9474848625989754\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 4, train_loss = 21.867646768689156, train_acc = 0.9529576152771309\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 5, train_loss = 19.90212193503976, train_acc = 0.9588961341406614\n",
      "test Acc 0.9543761638733705:\n",
      "4th- epoch: 6, train_loss = 18.403668008744717, train_acc = 0.9623893805309734\n",
      "test Acc 0.9567039106145251:\n",
      "4th- epoch: 7, train_loss = 17.195114858448505, train_acc = 0.9648346530041919\n",
      "test Acc 0.9585661080074488:\n",
      "4th- epoch: 8, train_loss = 16.163633085787296, train_acc = 0.9671634839310667\n",
      "test Acc 0.9590316573556797:\n",
      "4th- epoch: 9, train_loss = 15.288871143013239, train_acc = 0.9683278993945039\n",
      "test Acc 0.9590316573556797:\n",
      "4th- epoch: 10, train_loss = 14.526713475584984, train_acc = 0.969608756404285\n",
      "test Acc 0.9590316573556797:\n",
      "4th- epoch: 11, train_loss = 13.854426246136427, train_acc = 0.9713553795994411\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 12, train_loss = 13.263335410505533, train_acc = 0.972286911970191\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 13, train_loss = 12.726996671408415, train_acc = 0.9731020027945971\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 14, train_loss = 12.24540602043271, train_acc = 0.9741499767116907\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 15, train_loss = 11.803822606801987, train_acc = 0.9751979506287843\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 16, train_loss = 11.401286736130714, train_acc = 0.9758965999068467\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 17, train_loss = 11.032979911193252, train_acc = 0.9768281322775967\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 18, train_loss = 10.691516518592834, train_acc = 0.9775267815556591\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 19, train_loss = 10.370480798184872, train_acc = 0.9783418723800652\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 20, train_loss = 10.07111599482596, train_acc = 0.9789240801117839\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 21, train_loss = 9.78971935249865, train_acc = 0.9798556124825337\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 22, train_loss = 9.526549264788628, train_acc = 0.9810200279459711\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 23, train_loss = 9.277763355523348, train_acc = 0.9817186772240335\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 24, train_loss = 9.044804133474827, train_acc = 0.9820680018630648\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 25, train_loss = 8.821823863312602, train_acc = 0.9828830926874709\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 26, train_loss = 8.610559722408652, train_acc = 0.9832324173265021\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 27, train_loss = 8.41043260321021, train_acc = 0.9834653004191896\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 28, train_loss = 8.220414774492383, train_acc = 0.9838146250582208\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 29, train_loss = 8.036199798807502, train_acc = 0.9842803912435957\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 30, train_loss = 7.865742621943355, train_acc = 0.9843968327899395\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 31, train_loss = 7.701310014352202, train_acc = 0.9853283651606893\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 32, train_loss = 7.544256033375859, train_acc = 0.9855612482533768\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 33, train_loss = 7.396226393058896, train_acc = 0.9860270144387517\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 34, train_loss = 7.2505531664937735, train_acc = 0.9862598975314392\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 35, train_loss = 7.1144451927393675, train_acc = 0.9864927806241267\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 36, train_loss = 6.983064588159323, train_acc = 0.9868421052631579\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 37, train_loss = 6.858258372172713, train_acc = 0.9869585468095017\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 38, train_loss = 6.737448761239648, train_acc = 0.9871914299021891\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 39, train_loss = 6.622698877006769, train_acc = 0.9875407545412203\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 40, train_loss = 6.5124436765909195, train_acc = 0.9876571960875641\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 41, train_loss = 6.407882617786527, train_acc = 0.9880065207265952\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 42, train_loss = 6.304404059424996, train_acc = 0.9885887284583139\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 43, train_loss = 6.2054583840072155, train_acc = 0.9887051700046576\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 44, train_loss = 6.111149309203029, train_acc = 0.9890544946436889\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 45, train_loss = 6.0186222065240145, train_acc = 0.9891709361900326\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 46, train_loss = 5.929597125388682, train_acc = 0.9891709361900326\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 47, train_loss = 5.843617852777243, train_acc = 0.98940381928272\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 48, train_loss = 5.756639081984758, train_acc = 0.9899860270144387\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 49, train_loss = 5.673027318902314, train_acc = 0.9902189101071263\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 50, train_loss = 5.5939481519162655, train_acc = 0.99033535165347\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 51, train_loss = 5.5200768718495965, train_acc = 0.9906846762925011\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 52, train_loss = 5.445854767225683, train_acc = 0.9906846762925011\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 53, train_loss = 5.373972188681364, train_acc = 0.990801117838845\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 54, train_loss = 5.305264912545681, train_acc = 0.9909175593851887\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 55, train_loss = 5.23846322670579, train_acc = 0.9909175593851887\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 56, train_loss = 5.174985431134701, train_acc = 0.9909175593851887\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 57, train_loss = 5.114125986583531, train_acc = 0.9910340009315324\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 58, train_loss = 5.053668636828661, train_acc = 0.9910340009315324\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 59, train_loss = 4.998139645904303, train_acc = 0.9912668840242198\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 60, train_loss = 4.942203302867711, train_acc = 0.9914997671169073\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 61, train_loss = 4.887876530177891, train_acc = 0.9914997671169073\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 62, train_loss = 4.834145274944603, train_acc = 0.9916162086632511\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 63, train_loss = 4.785182609222829, train_acc = 0.9917326502095948\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 64, train_loss = 4.732434969395399, train_acc = 0.9916162086632511\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 65, train_loss = 4.6868164436891675, train_acc = 0.9917326502095948\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 66, train_loss = 4.63875421974808, train_acc = 0.9918490917559385\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 67, train_loss = 4.5943784127011895, train_acc = 0.9918490917559385\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 68, train_loss = 4.547680771909654, train_acc = 0.992081974848626\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 69, train_loss = 4.504634704440832, train_acc = 0.992081974848626\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 70, train_loss = 4.462440528906882, train_acc = 0.9919655333022822\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 71, train_loss = 4.42011294234544, train_acc = 0.992081974848626\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 72, train_loss = 4.380961823277175, train_acc = 0.992081974848626\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 73, train_loss = 4.340727612376213, train_acc = 0.9921984163949698\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 74, train_loss = 4.3019468719139695, train_acc = 0.9921984163949698\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 75, train_loss = 4.263755773194134, train_acc = 0.9921984163949698\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 76, train_loss = 4.226836777292192, train_acc = 0.9921984163949698\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 77, train_loss = 4.191275075078011, train_acc = 0.9921984163949698\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 78, train_loss = 4.1562651777639985, train_acc = 0.9921984163949698\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 79, train_loss = 4.122239421121776, train_acc = 0.9921984163949698\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 80, train_loss = 4.0885625490918756, train_acc = 0.9923148579413135\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 81, train_loss = 4.057004460133612, train_acc = 0.9924312994876572\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 82, train_loss = 4.022722848691046, train_acc = 0.9924312994876572\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 83, train_loss = 3.9915095269680023, train_acc = 0.9924312994876572\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 84, train_loss = 3.9611843987368047, train_acc = 0.9925477410340009\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 85, train_loss = 3.9305993146263063, train_acc = 0.9925477410340009\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 86, train_loss = 3.901447827462107, train_acc = 0.9925477410340009\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 87, train_loss = 3.8722477927803993, train_acc = 0.9925477410340009\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 88, train_loss = 3.843272759113461, train_acc = 0.9925477410340009\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 89, train_loss = 3.814758215099573, train_acc = 0.9925477410340009\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 90, train_loss = 3.7895316532813013, train_acc = 0.9926641825803446\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 91, train_loss = 3.7610094100236893, train_acc = 0.9924312994876572\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 92, train_loss = 3.734727217350155, train_acc = 0.9925477410340009\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 93, train_loss = 3.7084645330905914, train_acc = 0.9923148579413135\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 94, train_loss = 3.6825176463462412, train_acc = 0.9924312994876572\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 95, train_loss = 3.6589845954440534, train_acc = 0.9924312994876572\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 96, train_loss = 3.6337202899158, train_acc = 0.9925477410340009\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 97, train_loss = 3.6089201867580414, train_acc = 0.9925477410340009\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 98, train_loss = 3.586209887173027, train_acc = 0.9926641825803446\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 99, train_loss = 3.562196882907301, train_acc = 0.9927806241266884\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 100, train_loss = 3.538968170527369, train_acc = 0.9927806241266884\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 101, train_loss = 3.5177850662730634, train_acc = 0.9928970656730322\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 102, train_loss = 3.4944117912091315, train_acc = 0.9927806241266884\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 103, train_loss = 3.473080533090979, train_acc = 0.9931299487657196\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 104, train_loss = 3.4512231000699103, train_acc = 0.9931299487657196\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 105, train_loss = 3.430151545908302, train_acc = 0.9931299487657196\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 106, train_loss = 3.4109455249272287, train_acc = 0.9931299487657196\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 107, train_loss = 3.3889736109413207, train_acc = 0.9931299487657196\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 108, train_loss = 3.369348634034395, train_acc = 0.9932463903120633\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 109, train_loss = 3.3505159355700016, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 110, train_loss = 3.3302551805973053, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 111, train_loss = 3.3123145662248135, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 112, train_loss = 3.293366519268602, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 113, train_loss = 3.275461958255619, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 114, train_loss = 3.2555335089564323, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 115, train_loss = 3.2386304452084005, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 116, train_loss = 3.2212903425097466, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 117, train_loss = 3.2033969811163843, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 118, train_loss = 3.1873921491205692, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 119, train_loss = 3.1706069209612906, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 120, train_loss = 3.1534993001259863, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 121, train_loss = 3.1370560214854777, train_acc = 0.9935957149510946\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 122, train_loss = 3.1206866814754903, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 123, train_loss = 3.1039922856725752, train_acc = 0.9935957149510946\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 124, train_loss = 3.0888691931031644, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 125, train_loss = 3.0722918868996203, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 126, train_loss = 3.057699979748577, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 127, train_loss = 3.043336315546185, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 128, train_loss = 3.0281557007692754, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 129, train_loss = 3.0128630488179624, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 130, train_loss = 2.998353021685034, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 131, train_loss = 2.984084617346525, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 132, train_loss = 2.9710745103657246, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 133, train_loss = 2.956004017498344, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 134, train_loss = 2.9436105326749384, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 135, train_loss = 2.92835558578372, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 136, train_loss = 2.9179145991802216, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 137, train_loss = 2.9037970900535583, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 138, train_loss = 2.891209864523262, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 139, train_loss = 2.8770792833529413, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 140, train_loss = 2.86431652540341, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 141, train_loss = 2.852153027895838, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 142, train_loss = 2.8415305516682565, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 143, train_loss = 2.827999833971262, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 144, train_loss = 2.8180019543506205, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 145, train_loss = 2.8028992689214647, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 146, train_loss = 2.7933643758296967, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 147, train_loss = 2.7803934342227876, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 148, train_loss = 2.7691004150547087, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 149, train_loss = 2.759299848228693, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 150, train_loss = 2.7476092143915594, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 151, train_loss = 2.7379025034606457, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 152, train_loss = 2.7257131836377084, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 153, train_loss = 2.716121416538954, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 154, train_loss = 2.704548928886652, train_acc = 0.993828598043782\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 155, train_loss = 2.6943310759961605, train_acc = 0.9939450395901258\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 156, train_loss = 2.6835327818989754, train_acc = 0.9939450395901258\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 157, train_loss = 2.6739769726991653, train_acc = 0.9939450395901258\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 158, train_loss = 2.662885586498305, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 159, train_loss = 2.651953996391967, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 160, train_loss = 2.64298228174448, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 161, train_loss = 2.6331563033163548, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 162, train_loss = 2.624162169871852, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 163, train_loss = 2.6142408822197467, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 164, train_loss = 2.604936460731551, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 165, train_loss = 2.594827325316146, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 166, train_loss = 2.5852829962968826, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 167, train_loss = 2.5760044679045677, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 168, train_loss = 2.5670791019219905, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 169, train_loss = 2.5595636528450996, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 170, train_loss = 2.5494482580106705, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 171, train_loss = 2.540397184668109, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 172, train_loss = 2.53071899455972, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 173, train_loss = 2.5218885329086334, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 174, train_loss = 2.5131258231122047, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 175, train_loss = 2.5057046562433243, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 176, train_loss = 2.4970723662991077, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 177, train_loss = 2.4889100790023804, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 178, train_loss = 2.479979234514758, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 179, train_loss = 2.47260233014822, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 180, train_loss = 2.463079307228327, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 181, train_loss = 2.455882624955848, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 182, train_loss = 2.450237075565383, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 183, train_loss = 2.441127422032878, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 184, train_loss = 2.4342084005475044, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 185, train_loss = 2.426457341760397, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 186, train_loss = 2.4197723891120404, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 187, train_loss = 2.4111338753718883, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 188, train_loss = 2.4055518817622215, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 189, train_loss = 2.3976875816006213, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 190, train_loss = 2.389165408909321, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 191, train_loss = 2.384209256619215, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 192, train_loss = 2.375926438719034, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 193, train_loss = 2.369005585787818, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 194, train_loss = 2.3630374323111027, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 195, train_loss = 2.356153956381604, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 196, train_loss = 2.349604232935235, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 197, train_loss = 2.3429876167792827, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 198, train_loss = 2.337363572092727, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 199, train_loss = 2.329834905685857, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 200, train_loss = 2.3219911344349384, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 201, train_loss = 2.3164999198634177, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 202, train_loss = 2.310683500021696, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 203, train_loss = 2.305524470983073, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 204, train_loss = 2.2993163217324764, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 205, train_loss = 2.2939372088294476, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 206, train_loss = 2.2864528212230653, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 207, train_loss = 2.279253289103508, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 208, train_loss = 2.2741146374028176, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 209, train_loss = 2.2691668022889644, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 210, train_loss = 2.2624930057208985, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 211, train_loss = 2.2578309923410416, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 212, train_loss = 2.252716061891988, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 213, train_loss = 2.247015577973798, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 214, train_loss = 2.240619608433917, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 215, train_loss = 2.236313418718055, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 216, train_loss = 2.2313620808999985, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 217, train_loss = 2.226265334757045, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 218, train_loss = 2.219996113330126, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 219, train_loss = 2.214983644662425, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 220, train_loss = 2.210421110270545, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 221, train_loss = 2.2040319219231606, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 222, train_loss = 2.1992581684608012, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 223, train_loss = 2.194409916875884, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 224, train_loss = 2.189152641920373, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 225, train_loss = 2.1835110746324062, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 226, train_loss = 2.178944597719237, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 227, train_loss = 2.1743634592276067, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 228, train_loss = 2.1703641812782735, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 229, train_loss = 2.165446038125083, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 230, train_loss = 2.1616093181073666, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 231, train_loss = 2.154479291290045, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 232, train_loss = 2.1515644614119083, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 233, train_loss = 2.145996504696086, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 234, train_loss = 2.142423511715606, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 235, train_loss = 2.137394916266203, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 236, train_loss = 2.1331522713880986, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 237, train_loss = 2.1286930453497916, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 238, train_loss = 2.124802865087986, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 239, train_loss = 2.120361267356202, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 240, train_loss = 2.1167870338540524, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 241, train_loss = 2.1114083293359727, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 242, train_loss = 2.1069774974603206, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 243, train_loss = 2.1033971507567912, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 244, train_loss = 2.1003815680742264, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 245, train_loss = 2.0953791935462505, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 246, train_loss = 2.091370690613985, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 247, train_loss = 2.0883621524553746, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 248, train_loss = 2.0837252736091614, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 249, train_loss = 2.0799297105986625, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 250, train_loss = 2.0760774698574096, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 251, train_loss = 2.071204564301297, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 252, train_loss = 2.069005971075967, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 253, train_loss = 2.0644896042067558, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 254, train_loss = 2.060911330161616, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 255, train_loss = 2.057024686364457, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 256, train_loss = 2.0533943336922675, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 257, train_loss = 2.049796137958765, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 258, train_loss = 2.0466983143705875, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 259, train_loss = 2.0436524462420493, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 260, train_loss = 2.0397477138321847, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 261, train_loss = 2.0369210194330662, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 262, train_loss = 2.0334413561504334, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 263, train_loss = 2.0279122851788998, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 264, train_loss = 2.0255697071552277, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 265, train_loss = 2.0224347573239356, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 266, train_loss = 2.019386661471799, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 267, train_loss = 2.0150557544548064, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 268, train_loss = 2.013363892911002, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 269, train_loss = 2.009473801823333, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 270, train_loss = 2.0062874916475266, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 271, train_loss = 2.0028820298612118, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 272, train_loss = 1.9989555615466088, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 273, train_loss = 1.9967906549572945, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 274, train_loss = 1.9936230902094394, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 275, train_loss = 1.991142512531951, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 276, train_loss = 1.9871114641427994, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 277, train_loss = 1.9850897453725338, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 278, train_loss = 1.9812472015619278, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 279, train_loss = 1.9786270570475608, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 280, train_loss = 1.9751023810822517, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 281, train_loss = 1.9712547201197594, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 282, train_loss = 1.9691548098344356, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 283, train_loss = 1.966671806992963, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 284, train_loss = 1.9638526178896427, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 285, train_loss = 1.9592090013902634, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 286, train_loss = 1.9593209202867001, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 287, train_loss = 1.953364685177803, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 288, train_loss = 1.9534853510558605, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 289, train_loss = 1.9500967327039689, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 290, train_loss = 1.9468110252637416, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 291, train_loss = 1.9450407959520817, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 292, train_loss = 1.9413566279690713, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 293, train_loss = 1.9378410279750824, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 294, train_loss = 1.9362306732218713, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 295, train_loss = 1.9333276886027306, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 296, train_loss = 1.9307404782157391, train_acc = 0.995575221238938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 297, train_loss = 1.9287972748279572, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 298, train_loss = 1.9250955544412136, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 299, train_loss = 1.9242188967764378, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 300, train_loss = 1.9214249290525913, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 301, train_loss = 1.9182080775499344, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 302, train_loss = 1.917110102949664, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 303, train_loss = 1.9131154380738735, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 304, train_loss = 1.9113187391776592, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 305, train_loss = 1.9079881173092872, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 306, train_loss = 1.9067695029079914, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 307, train_loss = 1.902892354875803, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 308, train_loss = 1.901035028276965, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 309, train_loss = 1.8983885049819946, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 310, train_loss = 1.8966271702665836, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 311, train_loss = 1.89426123467274, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 312, train_loss = 1.892428008140996, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 313, train_loss = 1.8887714769225568, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 314, train_loss = 1.8881036664824933, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 315, train_loss = 1.885932629229501, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 316, train_loss = 1.8840218994300812, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 317, train_loss = 1.8815834298729897, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 318, train_loss = 1.8774622741620988, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 319, train_loss = 1.8763996474444866, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 320, train_loss = 1.875458552269265, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 321, train_loss = 1.872028720797971, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 322, train_loss = 1.869339558063075, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 323, train_loss = 1.8674190912861377, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 324, train_loss = 1.8651510898489505, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 325, train_loss = 1.8635266374330968, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 326, train_loss = 1.8616369527298957, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 327, train_loss = 1.8592004179954529, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 328, train_loss = 1.8574497837107629, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 329, train_loss = 1.8552788693923503, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 330, train_loss = 1.8538851104676723, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 331, train_loss = 1.8511121682822704, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 332, train_loss = 1.8504839316010475, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 333, train_loss = 1.8458980234572664, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 334, train_loss = 1.844837512820959, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 335, train_loss = 1.8437453334918246, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 336, train_loss = 1.8415831426391378, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 337, train_loss = 1.8393028812715784, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 338, train_loss = 1.8368067294359207, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 339, train_loss = 1.8367105411598459, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 340, train_loss = 1.8334426680812612, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 341, train_loss = 1.8330832136562094, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 342, train_loss = 1.8306890489766374, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 343, train_loss = 1.8277971470961347, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 344, train_loss = 1.8263353618094698, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 345, train_loss = 1.8253818725934252, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 346, train_loss = 1.8219635287532583, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 347, train_loss = 1.8207147953798994, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 348, train_loss = 1.820212747901678, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 349, train_loss = 1.8172048492124304, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 350, train_loss = 1.8154258368304, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 351, train_loss = 1.8124944294104353, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 352, train_loss = 1.811457005678676, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 353, train_loss = 1.8100659424671903, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 354, train_loss = 1.8090001866221428, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 355, train_loss = 1.8060462499270216, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 356, train_loss = 1.8053304267814383, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 357, train_loss = 1.804413334815763, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 358, train_loss = 1.801912677823566, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 359, train_loss = 1.8004675233969465, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 360, train_loss = 1.79948430263903, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 361, train_loss = 1.7971330235013738, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 362, train_loss = 1.7947820959379897, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 363, train_loss = 1.7929370974889025, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 364, train_loss = 1.792562267393805, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 365, train_loss = 1.7905008010566235, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 366, train_loss = 1.788474945933558, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 367, train_loss = 1.7865691097686067, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 368, train_loss = 1.7844962365925312, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 369, train_loss = 1.7828102931380272, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 370, train_loss = 1.7828210865845904, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 371, train_loss = 1.7809820622205734, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 372, train_loss = 1.7793402969837189, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 373, train_loss = 1.7763979099690914, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 374, train_loss = 1.775990298599936, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 375, train_loss = 1.7730239927768707, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 376, train_loss = 1.7720643630018458, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 377, train_loss = 1.7704764865338802, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 378, train_loss = 1.7690380526473746, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 379, train_loss = 1.7681610211730003, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 380, train_loss = 1.7661691717803478, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 381, train_loss = 1.7652003975817934, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 382, train_loss = 1.762555276392959, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 383, train_loss = 1.7620200477540493, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 384, train_loss = 1.7607975652208552, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 385, train_loss = 1.7588856356451288, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 386, train_loss = 1.7573497133562341, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 387, train_loss = 1.7572515433421358, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 388, train_loss = 1.7546636536717415, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 389, train_loss = 1.7536520486464724, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 390, train_loss = 1.7512181723723188, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 391, train_loss = 1.7513457164168358, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 392, train_loss = 1.7493721334030852, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 393, train_loss = 1.74922087660525, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 394, train_loss = 1.7490189472446218, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 395, train_loss = 1.7461236728122458, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 396, train_loss = 1.7454366782912984, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 397, train_loss = 1.743133952259086, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 398, train_loss = 1.7415941344806924, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 399, train_loss = 1.739253138541244, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 400, train_loss = 1.739328809082508, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 401, train_loss = 1.7377972640097141, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 402, train_loss = 1.7363309686770663, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 403, train_loss = 1.7354366095969453, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 404, train_loss = 1.7351319653680548, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 405, train_loss = 1.734079547226429, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 406, train_loss = 1.7318670153617859, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 407, train_loss = 1.7316071167588234, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 408, train_loss = 1.728940618573688, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 409, train_loss = 1.7286031296243891, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 410, train_loss = 1.7277070631971583, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 411, train_loss = 1.7256408320972696, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 412, train_loss = 1.724649099051021, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 413, train_loss = 1.7230083495378494, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 414, train_loss = 1.7226199135184288, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 415, train_loss = 1.721164988935925, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 416, train_loss = 1.718483260483481, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 417, train_loss = 1.7181291729211807, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 418, train_loss = 1.7177183305611834, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 419, train_loss = 1.7175990206887946, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 420, train_loss = 1.7157449336955324, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 421, train_loss = 1.7141552654793486, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 422, train_loss = 1.7140878377249464, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 423, train_loss = 1.7133944468805566, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 424, train_loss = 1.7110953144729137, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 425, train_loss = 1.7096070969710127, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 426, train_loss = 1.7093743222067133, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 427, train_loss = 1.7097319265594706, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 428, train_loss = 1.7067581365117803, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 429, train_loss = 1.7063832767307758, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 430, train_loss = 1.704498959123157, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 431, train_loss = 1.7036266662180424, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 432, train_loss = 1.7021663809427992, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 433, train_loss = 1.7024084640434012, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 434, train_loss = 1.7008434695890173, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 435, train_loss = 1.699855923652649, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 436, train_loss = 1.6977187594166026, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 437, train_loss = 1.6976080350577831, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 438, train_loss = 1.6961842501768842, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 439, train_loss = 1.6948474496603012, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 440, train_loss = 1.6950578714022413, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 441, train_loss = 1.693769197911024, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 442, train_loss = 1.6936495527625084, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 443, train_loss = 1.691301368176937, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 444, train_loss = 1.6903935372829437, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 445, train_loss = 1.6902362169930711, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 446, train_loss = 1.6878804651787505, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 447, train_loss = 1.686644925386645, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 448, train_loss = 1.6872798912227154, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 449, train_loss = 1.685946960002184, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 450, train_loss = 1.6856360906967893, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 451, train_loss = 1.6825755214085802, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 452, train_loss = 1.6829926209757105, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 453, train_loss = 1.681390006095171, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 454, train_loss = 1.6814259676029906, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 455, train_loss = 1.6802539465716109, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 456, train_loss = 1.679077702225186, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 457, train_loss = 1.6780810976633802, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 458, train_loss = 1.6761963851749897, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 459, train_loss = 1.6750702237477526, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 460, train_loss = 1.6751691350946203, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 461, train_loss = 1.6738796742865816, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 462, train_loss = 1.6732470405986533, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 463, train_loss = 1.6716997846961021, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 464, train_loss = 1.6718684136867523, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 465, train_loss = 1.6718476290116087, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 466, train_loss = 1.6705375710735098, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 467, train_loss = 1.6690085033187643, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 468, train_loss = 1.667659422964789, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 469, train_loss = 1.6660151792457327, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 470, train_loss = 1.6667679460952058, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 471, train_loss = 1.664852112531662, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 472, train_loss = 1.6642097110161558, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 473, train_loss = 1.6639118827879429, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 474, train_loss = 1.6627593139419332, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 475, train_loss = 1.6611868143081665, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 476, train_loss = 1.660904327989556, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 477, train_loss = 1.6595472072949633, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 478, train_loss = 1.658540186821483, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 479, train_loss = 1.6586064087459818, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 480, train_loss = 1.6580525251338258, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 481, train_loss = 1.6566266864538193, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 482, train_loss = 1.6566729173064232, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 483, train_loss = 1.6547778820386156, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 484, train_loss = 1.6550304256379604, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 485, train_loss = 1.6537094985833392, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 486, train_loss = 1.6538650082657114, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 487, train_loss = 1.6521866010734811, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 488, train_loss = 1.6511033909628168, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 489, train_loss = 1.6509869582951069, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 490, train_loss = 1.6501171862473711, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 491, train_loss = 1.6492929024389014, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 492, train_loss = 1.6493257954716682, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 493, train_loss = 1.647757027298212, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 494, train_loss = 1.6472495818743482, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 495, train_loss = 1.6477577401092276, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 496, train_loss = 1.6458508806535974, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 497, train_loss = 1.6457401042571291, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 498, train_loss = 1.642663661390543, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 499, train_loss = 1.6426790542900562, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████▋                                                               | 4/30 [36:10<3:55:13, 542.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "5th- epoch: 0, train_loss = 111.08853866159916, train_acc = 0.7887750349324639\n",
      "test Acc 0.8864059590316573:\n",
      "5th- epoch: 1, train_loss = 43.164893604815006, train_acc = 0.9153469958081043\n",
      "test Acc 0.9120111731843575:\n",
      "5th- epoch: 2, train_loss = 33.53804633021355, train_acc = 0.9337447601304145\n",
      "test Acc 0.9287709497206704:\n",
      "5th- epoch: 3, train_loss = 28.47831581532955, train_acc = 0.9446902654867256\n",
      "test Acc 0.9352886405959032:\n",
      "5th- epoch: 4, train_loss = 25.15022163465619, train_acc = 0.9503959012575687\n",
      "test Acc 0.9441340782122905:\n",
      "5th- epoch: 5, train_loss = 22.705197729170322, train_acc = 0.9538891476478808\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 6, train_loss = 20.768501430749893, train_acc = 0.9576152771308803\n",
      "test Acc 0.952513966480447:\n",
      "5th- epoch: 7, train_loss = 19.20461856946349, train_acc = 0.9600605496040987\n",
      "test Acc 0.9543761638733705:\n",
      "5th- epoch: 8, train_loss = 17.91327479481697, train_acc = 0.9620400558919422\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 9, train_loss = 16.802156208083034, train_acc = 0.9642524452724732\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 10, train_loss = 15.847357153892517, train_acc = 0.9657661853749417\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 11, train_loss = 15.007921939715743, train_acc = 0.9677456916627852\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 12, train_loss = 14.265815947204828, train_acc = 0.9693758733115976\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 13, train_loss = 13.605855491012335, train_acc = 0.9706567303213787\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 14, train_loss = 13.022507967427373, train_acc = 0.9719375873311598\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 15, train_loss = 12.495906818658113, train_acc = 0.9734513274336283\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 16, train_loss = 12.025574992410839, train_acc = 0.9747321844434094\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 17, train_loss = 11.586371291428804, train_acc = 0.975780158360503\n",
      "test Acc 0.9618249534450651:\n",
      "5th- epoch: 18, train_loss = 11.171561181545258, train_acc = 0.9764788076385654\n",
      "test Acc 0.9622905027932961:\n",
      "5th- epoch: 19, train_loss = 10.788093869574368, train_acc = 0.9776432231020028\n",
      "test Acc 0.962756052141527:\n",
      "5th- epoch: 20, train_loss = 10.440433547832072, train_acc = 0.9785747554727526\n",
      "test Acc 0.962756052141527:\n",
      "5th- epoch: 21, train_loss = 10.114612990990281, train_acc = 0.97973917093619\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 22, train_loss = 9.81473863683641, train_acc = 0.9804378202142524\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 23, train_loss = 9.534063619561493, train_acc = 0.9807871448532837\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 24, train_loss = 9.270771182142198, train_acc = 0.9817186772240335\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 25, train_loss = 9.023093960247934, train_acc = 0.9824173265020959\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 26, train_loss = 8.789473442360759, train_acc = 0.9831159757801584\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 27, train_loss = 8.567131564952433, train_acc = 0.9833488588728458\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 28, train_loss = 8.356962414458394, train_acc = 0.9833488588728458\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 29, train_loss = 8.155578162521124, train_acc = 0.9839310666045645\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 30, train_loss = 7.966214542277157, train_acc = 0.9840475081509082\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 31, train_loss = 7.7808922762051225, train_acc = 0.9845132743362832\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 32, train_loss = 7.610673570074141, train_acc = 0.9850954820680019\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 33, train_loss = 7.446157481521368, train_acc = 0.985444806707033\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 34, train_loss = 7.292778551578522, train_acc = 0.985910572892408\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 35, train_loss = 7.14222397422418, train_acc = 0.986376339077783\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 36, train_loss = 7.007479719817638, train_acc = 0.9868421052631579\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 37, train_loss = 6.87437250604853, train_acc = 0.9871914299021891\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 38, train_loss = 6.746751236729324, train_acc = 0.9873078714485328\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 39, train_loss = 6.627249216660857, train_acc = 0.9877736376339078\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 40, train_loss = 6.51265184301883, train_acc = 0.9881229622729389\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 41, train_loss = 6.404303303454071, train_acc = 0.9884722869119702\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 42, train_loss = 6.298280726652592, train_acc = 0.9887051700046576\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 43, train_loss = 6.196020061150193, train_acc = 0.9885887284583139\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 44, train_loss = 6.096257913857698, train_acc = 0.9888216115510013\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 45, train_loss = 6.000393498223275, train_acc = 0.9890544946436889\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 46, train_loss = 5.908064577262849, train_acc = 0.9890544946436889\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 47, train_loss = 5.820405573584139, train_acc = 0.9890544946436889\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 48, train_loss = 5.738436694256961, train_acc = 0.98940381928272\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 49, train_loss = 5.6589725273661315, train_acc = 0.9895202608290639\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 50, train_loss = 5.579313887283206, train_acc = 0.9895202608290639\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 51, train_loss = 5.503181154374033, train_acc = 0.9895202608290639\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 52, train_loss = 5.429204768966883, train_acc = 0.9896367023754076\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 53, train_loss = 5.359591718297452, train_acc = 0.9897531439217513\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 54, train_loss = 5.291539728175849, train_acc = 0.9897531439217513\n",
      "test Acc 0.972998137802607:\n",
      "5th- epoch: 55, train_loss = 5.223946276586503, train_acc = 0.9899860270144387\n",
      "test Acc 0.973463687150838:\n",
      "5th- epoch: 56, train_loss = 5.160723281092942, train_acc = 0.9902189101071263\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 57, train_loss = 5.097754719201475, train_acc = 0.9902189101071263\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 58, train_loss = 5.039121741894633, train_acc = 0.9904517931998137\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 59, train_loss = 4.979273819364607, train_acc = 0.9905682347461574\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 60, train_loss = 4.921706780791283, train_acc = 0.9905682347461574\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 61, train_loss = 4.867372268345207, train_acc = 0.990801117838845\n",
      "test Acc 0.9748603351955307:\n",
      "5th- epoch: 62, train_loss = 4.814008179586381, train_acc = 0.990801117838845\n",
      "test Acc 0.9753258845437617:\n",
      "5th- epoch: 63, train_loss = 4.761850992683321, train_acc = 0.990801117838845\n",
      "test Acc 0.9753258845437617:\n",
      "5th- epoch: 64, train_loss = 4.7131073218770325, train_acc = 0.990801117838845\n",
      "test Acc 0.9753258845437617:\n",
      "5th- epoch: 65, train_loss = 4.663023607805371, train_acc = 0.9911504424778761\n",
      "test Acc 0.9753258845437617:\n",
      "5th- epoch: 66, train_loss = 4.615324525162578, train_acc = 0.9911504424778761\n",
      "test Acc 0.9753258845437617:\n",
      "5th- epoch: 67, train_loss = 4.569853592664003, train_acc = 0.9911504424778761\n",
      "test Acc 0.9757914338919925:\n",
      "5th- epoch: 68, train_loss = 4.525564361829311, train_acc = 0.9912668840242198\n",
      "test Acc 0.9757914338919925:\n",
      "5th- epoch: 69, train_loss = 4.479674536734819, train_acc = 0.9913833255705635\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 70, train_loss = 4.438186746090651, train_acc = 0.9913833255705635\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 71, train_loss = 4.397953444626182, train_acc = 0.9913833255705635\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 72, train_loss = 4.35592834930867, train_acc = 0.9913833255705635\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 73, train_loss = 4.31608002865687, train_acc = 0.9913833255705635\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 74, train_loss = 4.276136857457459, train_acc = 0.9914997671169073\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 75, train_loss = 4.2386616370640695, train_acc = 0.9914997671169073\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 76, train_loss = 4.2017781203612685, train_acc = 0.9914997671169073\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 77, train_loss = 4.1651325868442655, train_acc = 0.9914997671169073\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 78, train_loss = 4.128328379709274, train_acc = 0.9914997671169073\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 79, train_loss = 4.093853604514152, train_acc = 0.9914997671169073\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 80, train_loss = 4.059867018368095, train_acc = 0.9914997671169073\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 81, train_loss = 4.026425774209201, train_acc = 0.9916162086632511\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 82, train_loss = 3.992836406920105, train_acc = 0.9916162086632511\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 83, train_loss = 3.960354990325868, train_acc = 0.9916162086632511\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 84, train_loss = 3.9296601694077253, train_acc = 0.9916162086632511\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 85, train_loss = 3.898859289009124, train_acc = 0.9917326502095948\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 86, train_loss = 3.86796448007226, train_acc = 0.9918490917559385\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 87, train_loss = 3.8378279889002442, train_acc = 0.9918490917559385\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 88, train_loss = 3.809305892791599, train_acc = 0.9918490917559385\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 89, train_loss = 3.7811803040094674, train_acc = 0.9918490917559385\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 90, train_loss = 3.7536169048398733, train_acc = 0.9919655333022822\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 91, train_loss = 3.7254188344813883, train_acc = 0.9919655333022822\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 92, train_loss = 3.6984615474939346, train_acc = 0.992081974848626\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 93, train_loss = 3.671799465082586, train_acc = 0.9921984163949698\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 94, train_loss = 3.645263334736228, train_acc = 0.9923148579413135\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 95, train_loss = 3.6215187343768775, train_acc = 0.9924312994876572\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 96, train_loss = 3.5954278875142336, train_acc = 0.9925477410340009\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 97, train_loss = 3.57041041739285, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 98, train_loss = 3.5459728674031794, train_acc = 0.9925477410340009\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 99, train_loss = 3.521365493070334, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 100, train_loss = 3.498575708363205, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 101, train_loss = 3.475824703928083, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 102, train_loss = 3.4539681021124125, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 103, train_loss = 3.43136690557003, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 104, train_loss = 3.409406957682222, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 105, train_loss = 3.3885003426112235, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 106, train_loss = 3.3664424484595656, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 107, train_loss = 3.346886065788567, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 108, train_loss = 3.3268246548250318, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 109, train_loss = 3.306575492490083, train_acc = 0.9927806241266884\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 110, train_loss = 3.287806630600244, train_acc = 0.9927806241266884\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 111, train_loss = 3.26845715707168, train_acc = 0.9927806241266884\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 112, train_loss = 3.2493803068064153, train_acc = 0.9928970656730322\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 113, train_loss = 3.2310174088925123, train_acc = 0.9928970656730322\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 114, train_loss = 3.211874206084758, train_acc = 0.9930135072193759\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 115, train_loss = 3.1930710645392537, train_acc = 0.9928970656730322\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 116, train_loss = 3.177803366445005, train_acc = 0.9928970656730322\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 117, train_loss = 3.1588582904078066, train_acc = 0.9928970656730322\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 118, train_loss = 3.1428921171464026, train_acc = 0.9928970656730322\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 119, train_loss = 3.1247919113375247, train_acc = 0.9931299487657196\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 120, train_loss = 3.1083600390702486, train_acc = 0.9930135072193759\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 121, train_loss = 3.09098159102723, train_acc = 0.9931299487657196\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 122, train_loss = 3.074748404789716, train_acc = 0.9931299487657196\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 123, train_loss = 3.059156361967325, train_acc = 0.9931299487657196\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 124, train_loss = 3.042752936948091, train_acc = 0.9931299487657196\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 125, train_loss = 3.026881934143603, train_acc = 0.9932463903120633\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 126, train_loss = 3.012446137610823, train_acc = 0.9932463903120633\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 127, train_loss = 2.997287472244352, train_acc = 0.9932463903120633\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 128, train_loss = 2.9824162675067782, train_acc = 0.9932463903120633\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 129, train_loss = 2.9679861520417035, train_acc = 0.9932463903120633\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 130, train_loss = 2.952845964115113, train_acc = 0.9932463903120633\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 131, train_loss = 2.93881364306435, train_acc = 0.9932463903120633\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 132, train_loss = 2.9245558213442564, train_acc = 0.9932463903120633\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 133, train_loss = 2.9110613772645593, train_acc = 0.9932463903120633\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 134, train_loss = 2.8968472233973444, train_acc = 0.9933628318584071\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 135, train_loss = 2.883928271010518, train_acc = 0.9934792734047508\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 136, train_loss = 2.8692107936367393, train_acc = 0.9934792734047508\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 137, train_loss = 2.8566777328960598, train_acc = 0.9934792734047508\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 138, train_loss = 2.844847597181797, train_acc = 0.9934792734047508\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 139, train_loss = 2.8314645532518625, train_acc = 0.9934792734047508\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 140, train_loss = 2.818191302474588, train_acc = 0.9934792734047508\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 141, train_loss = 2.8056088341400027, train_acc = 0.9934792734047508\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 142, train_loss = 2.793924654368311, train_acc = 0.9935957149510946\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 143, train_loss = 2.7810508077964187, train_acc = 0.9935957149510946\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 144, train_loss = 2.7692270213738084, train_acc = 0.9937121564974383\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 145, train_loss = 2.7568608317524195, train_acc = 0.9937121564974383\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 146, train_loss = 2.745344418566674, train_acc = 0.9937121564974383\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 147, train_loss = 2.733631164766848, train_acc = 0.9937121564974383\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 148, train_loss = 2.723349410109222, train_acc = 0.9937121564974383\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 149, train_loss = 2.71131921838969, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 150, train_loss = 2.6999787618406117, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 151, train_loss = 2.6888323253951967, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 152, train_loss = 2.678727388381958, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 153, train_loss = 2.6675725704990327, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 154, train_loss = 2.6570355109870434, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 155, train_loss = 2.646723189856857, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 156, train_loss = 2.636798703111708, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 157, train_loss = 2.6268752897158265, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 158, train_loss = 2.6156327254138887, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 159, train_loss = 2.6057649170979857, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 160, train_loss = 2.595702471677214, train_acc = 0.9939450395901258\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 161, train_loss = 2.586703998968005, train_acc = 0.9940614811364695\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 162, train_loss = 2.576829132158309, train_acc = 0.9940614811364695\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 163, train_loss = 2.5674259192310274, train_acc = 0.9940614811364695\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 164, train_loss = 2.5587419867515564, train_acc = 0.9940614811364695\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 165, train_loss = 2.548503519035876, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 166, train_loss = 2.5398939247243106, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 167, train_loss = 2.5308507452718914, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 168, train_loss = 2.5223451936617494, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 169, train_loss = 2.5126349325291812, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 170, train_loss = 2.5047862883657217, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 171, train_loss = 2.49611898092553, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 172, train_loss = 2.4877502121962607, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 173, train_loss = 2.4796799100004137, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 174, train_loss = 2.4709828784689307, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 175, train_loss = 2.4625429050065577, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 176, train_loss = 2.454889771528542, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 177, train_loss = 2.4460152606479824, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 178, train_loss = 2.439779561245814, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 179, train_loss = 2.431913822190836, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 180, train_loss = 2.423364636255428, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 181, train_loss = 2.416468413779512, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 182, train_loss = 2.4097047839313745, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 183, train_loss = 2.401173124788329, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 184, train_loss = 2.3951381335500628, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 185, train_loss = 2.3866580044850707, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 186, train_loss = 2.3797737015411258, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 187, train_loss = 2.373637011507526, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 188, train_loss = 2.366623583016917, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 189, train_loss = 2.360428787767887, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 190, train_loss = 2.3527846003416926, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 191, train_loss = 2.3455758071504533, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 192, train_loss = 2.3398883645422757, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 193, train_loss = 2.332826209953055, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 194, train_loss = 2.3262148653157055, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 195, train_loss = 2.32058238517493, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 196, train_loss = 2.314350348431617, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 197, train_loss = 2.3083336723502725, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 198, train_loss = 2.3024475236888975, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 199, train_loss = 2.2956974981352687, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 200, train_loss = 2.2897847041022032, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 201, train_loss = 2.2837195098400116, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 202, train_loss = 2.277395668439567, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 203, train_loss = 2.2718647364526987, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 204, train_loss = 2.266157686477527, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 205, train_loss = 2.25970561360009, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 206, train_loss = 2.2549013602547348, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 207, train_loss = 2.2493695232551545, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 208, train_loss = 2.2434808348771185, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 209, train_loss = 2.237511249957606, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 210, train_loss = 2.2326463183853775, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 211, train_loss = 2.227393420645967, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 212, train_loss = 2.222309719072655, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 213, train_loss = 2.2168333420995623, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 214, train_loss = 2.210855136392638, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 215, train_loss = 2.2059063371270895, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 216, train_loss = 2.200355073204264, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 217, train_loss = 2.194444603752345, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 218, train_loss = 2.1899927326012403, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 219, train_loss = 2.1847656194586307, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 220, train_loss = 2.1803487020079046, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 221, train_loss = 2.1758704292587936, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 222, train_loss = 2.170683005126193, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 223, train_loss = 2.164679120061919, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 224, train_loss = 2.161520119989291, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 225, train_loss = 2.156717805424705, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 226, train_loss = 2.1514260035473853, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 227, train_loss = 2.1472985558211803, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 228, train_loss = 2.142449012491852, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 229, train_loss = 2.1380190877243876, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 230, train_loss = 2.1338307461701334, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 231, train_loss = 2.129587642615661, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 232, train_loss = 2.1256985815707594, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 233, train_loss = 2.120351233286783, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 234, train_loss = 2.1168618963565677, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 235, train_loss = 2.1133171296678483, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 236, train_loss = 2.1082283130381256, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 237, train_loss = 2.1043823417276144, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 238, train_loss = 2.1010376238264143, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 239, train_loss = 2.0962819366250187, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 240, train_loss = 2.093089635716751, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 241, train_loss = 2.088207083521411, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 242, train_loss = 2.0853018327616155, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 243, train_loss = 2.0807849450502545, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 244, train_loss = 2.076587003422901, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 245, train_loss = 2.072818085551262, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 246, train_loss = 2.0696033553685993, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 247, train_loss = 2.0665667389985174, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 248, train_loss = 2.061801469186321, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 249, train_loss = 2.058460361789912, train_acc = 0.9948765719608756\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 250, train_loss = 2.0551842770073563, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 251, train_loss = 2.0514010230544955, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 252, train_loss = 2.0477537852711976, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 253, train_loss = 2.0450499474536628, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 254, train_loss = 2.0406605135649443, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 255, train_loss = 2.037552572786808, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 256, train_loss = 2.0341601034160703, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 257, train_loss = 2.0310576122719795, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 258, train_loss = 2.02690466074273, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 259, train_loss = 2.023657030425966, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 260, train_loss = 2.020025206496939, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 261, train_loss = 2.017244883114472, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 262, train_loss = 2.0141229890286922, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 263, train_loss = 2.011224794900045, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 264, train_loss = 2.0074107833206654, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 265, train_loss = 2.004794333362952, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 266, train_loss = 2.0020273129921407, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 267, train_loss = 1.9981950873043388, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 268, train_loss = 1.99484350415878, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 269, train_loss = 1.9928066115826368, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 270, train_loss = 1.9891508957371116, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 271, train_loss = 1.9864454555790871, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 272, train_loss = 1.9828238764312118, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 273, train_loss = 1.9803866387810558, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 274, train_loss = 1.9771773256361485, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 275, train_loss = 1.9741861692164093, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 276, train_loss = 1.9726884034462273, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 277, train_loss = 1.9694469075184315, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 278, train_loss = 1.9666804340668023, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 279, train_loss = 1.9628059829119593, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 280, train_loss = 1.9602136588655412, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 281, train_loss = 1.9575815891148522, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 282, train_loss = 1.9545066490536556, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 283, train_loss = 1.9515865737339482, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 284, train_loss = 1.949194138054736, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 285, train_loss = 1.946229154826142, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 286, train_loss = 1.9434893893776461, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 287, train_loss = 1.9412483089836314, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 288, train_loss = 1.9383890285389498, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 289, train_loss = 1.9355156522942707, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 290, train_loss = 1.934008913114667, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 291, train_loss = 1.9307241268688813, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 292, train_loss = 1.9289724837290123, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 293, train_loss = 1.9255615816218778, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 294, train_loss = 1.923909459146671, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 295, train_loss = 1.9207100424682721, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 296, train_loss = 1.9186757799470797, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 297, train_loss = 1.9154581278562546, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 298, train_loss = 1.9144289181567729, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 299, train_loss = 1.9107960660476238, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 300, train_loss = 1.9086367993149906, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 301, train_loss = 1.9064212157391012, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 302, train_loss = 1.9042659573024139, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 303, train_loss = 1.9011948665138334, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 304, train_loss = 1.8995119790779427, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 305, train_loss = 1.8966919142985716, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 306, train_loss = 1.894812956219539, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 307, train_loss = 1.8924619097961113, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 308, train_loss = 1.8908359413035214, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 309, train_loss = 1.887915593921207, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 310, train_loss = 1.8859027314465493, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 311, train_loss = 1.8841240464244038, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 312, train_loss = 1.8812650970648974, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 313, train_loss = 1.8793238358339295, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 314, train_loss = 1.8771555648418143, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 315, train_loss = 1.875395194045268, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 316, train_loss = 1.873113838606514, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 317, train_loss = 1.8714732551015913, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 318, train_loss = 1.86921813164372, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 319, train_loss = 1.8672523222630844, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 320, train_loss = 1.8642290602438152, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 321, train_loss = 1.8624786260770634, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 322, train_loss = 1.8607547224964947, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 323, train_loss = 1.8588487763190642, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 324, train_loss = 1.8564134470652789, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 325, train_loss = 1.8549428487895057, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 326, train_loss = 1.8534550837939605, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 327, train_loss = 1.851131483563222, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 328, train_loss = 1.8492189717944711, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 329, train_loss = 1.8476668663788587, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 330, train_loss = 1.8449616970028728, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 331, train_loss = 1.843703337595798, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 332, train_loss = 1.8410010896623135, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 333, train_loss = 1.8394156257854775, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 334, train_loss = 1.8383166245184839, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 335, train_loss = 1.835922666825354, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 336, train_loss = 1.8337308451300487, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 337, train_loss = 1.8322971464367583, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 338, train_loss = 1.8301693698158488, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 339, train_loss = 1.8287495017284527, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 340, train_loss = 1.826638446538709, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 341, train_loss = 1.824514205334708, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 342, train_loss = 1.8232077155262232, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 343, train_loss = 1.8218995336210355, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 344, train_loss = 1.8192887428449467, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 345, train_loss = 1.818448715028353, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 346, train_loss = 1.816484517767094, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 347, train_loss = 1.8147840410238132, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 348, train_loss = 1.81311487138737, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 349, train_loss = 1.811878037522547, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 350, train_loss = 1.8099370012059808, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 351, train_loss = 1.807548955315724, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 352, train_loss = 1.8064502156339586, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 353, train_loss = 1.8046947785187513, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 354, train_loss = 1.8031141262035817, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 355, train_loss = 1.8013985762372613, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 356, train_loss = 1.800128370639868, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 357, train_loss = 1.79785104340408, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 358, train_loss = 1.7964581607375294, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 359, train_loss = 1.7951791459927335, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 360, train_loss = 1.7938905524788424, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 361, train_loss = 1.7921630719210953, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 362, train_loss = 1.7902815797133371, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 363, train_loss = 1.7894505977164954, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 364, train_loss = 1.7874113961588591, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 365, train_loss = 1.7855255004251376, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 366, train_loss = 1.7847737916745245, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 367, train_loss = 1.782434624969028, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 368, train_loss = 1.7819155191536993, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 369, train_loss = 1.7806466675829142, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 370, train_loss = 1.7786669989582151, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 371, train_loss = 1.7772974480176345, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 372, train_loss = 1.776046187034808, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 373, train_loss = 1.7741528525948524, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 374, train_loss = 1.7731698667630553, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 375, train_loss = 1.7715675212675706, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 376, train_loss = 1.7695309332339093, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 377, train_loss = 1.7678517659660429, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 378, train_loss = 1.7669476474402472, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 379, train_loss = 1.7647325355792418, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 380, train_loss = 1.7644024371402338, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 381, train_loss = 1.7629467674996704, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 382, train_loss = 1.7614228460006416, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 383, train_loss = 1.7600817291531712, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 384, train_loss = 1.7586796722607687, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 385, train_loss = 1.757973327068612, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 386, train_loss = 1.7559863761998713, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 387, train_loss = 1.7547440067864954, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 388, train_loss = 1.7535223526647314, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 389, train_loss = 1.752299550571479, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 390, train_loss = 1.7508264548378065, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 391, train_loss = 1.7490953005617484, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 392, train_loss = 1.74811744724866, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 393, train_loss = 1.7469523939071223, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 394, train_loss = 1.7466912420932204, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 395, train_loss = 1.7441556534031406, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 396, train_loss = 1.7434376017190516, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 397, train_loss = 1.74219396233093, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 398, train_loss = 1.7404350182041526, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 399, train_loss = 1.7395239047473297, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 400, train_loss = 1.7381316378014162, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 401, train_loss = 1.7374380971305072, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 402, train_loss = 1.73618008592166, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 403, train_loss = 1.7346666660159826, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 404, train_loss = 1.733535157633014, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 405, train_loss = 1.7329217738006264, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 406, train_loss = 1.731612844276242, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 407, train_loss = 1.729669292224571, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 408, train_loss = 1.7295636248309165, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 409, train_loss = 1.7278183293528855, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 410, train_loss = 1.726912658312358, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 411, train_loss = 1.7254416703945026, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 412, train_loss = 1.7238103359704837, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 413, train_loss = 1.7230009307386354, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 414, train_loss = 1.721700312802568, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 415, train_loss = 1.7212276975624263, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 416, train_loss = 1.7197339959675446, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 417, train_loss = 1.7182691299822181, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 418, train_loss = 1.7174785753013566, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 419, train_loss = 1.7166032675886527, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 420, train_loss = 1.715236486052163, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 421, train_loss = 1.7135034371167421, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 422, train_loss = 1.7130704202572815, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 423, train_loss = 1.7113649554667063, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 424, train_loss = 1.7106470898143016, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 425, train_loss = 1.7093640500679612, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 426, train_loss = 1.7085770215489902, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 427, train_loss = 1.7077756359358318, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 428, train_loss = 1.7063639222760685, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 429, train_loss = 1.705370854062494, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 430, train_loss = 1.704002563667018, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 431, train_loss = 1.7031507324427366, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 432, train_loss = 1.7019196508917958, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 433, train_loss = 1.7010210841544904, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 434, train_loss = 1.69974003668176, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 435, train_loss = 1.6994303152896464, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 436, train_loss = 1.6984033641056158, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 437, train_loss = 1.6975481340195984, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 438, train_loss = 1.6959164222353138, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 439, train_loss = 1.6951955258264206, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 440, train_loss = 1.694086858711671, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 441, train_loss = 1.6929986324976198, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 442, train_loss = 1.692411597352475, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 443, train_loss = 1.6907535213395022, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 444, train_loss = 1.6905880580306984, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 445, train_loss = 1.6896765607525595, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 446, train_loss = 1.6886983723961748, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 447, train_loss = 1.6873051653965376, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 448, train_loss = 1.6866076323203743, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 449, train_loss = 1.6854580896906555, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 450, train_loss = 1.684595960949082, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 451, train_loss = 1.6844033773522824, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 452, train_loss = 1.6831779765780084, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 453, train_loss = 1.6822871813201346, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 454, train_loss = 1.6815292991814204, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 455, train_loss = 1.6799201805260964, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 456, train_loss = 1.6791896144859493, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 457, train_loss = 1.6775760815944523, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 458, train_loss = 1.6775147031876259, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 459, train_loss = 1.6767983598983847, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 460, train_loss = 1.6756251276819967, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 461, train_loss = 1.6744717280962504, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 462, train_loss = 1.6737325896974653, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 463, train_loss = 1.6728908310760744, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 464, train_loss = 1.6726005673408508, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 465, train_loss = 1.6708526505972259, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 466, train_loss = 1.669518743234221, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 467, train_loss = 1.6688542307238095, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 468, train_loss = 1.667995132971555, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 469, train_loss = 1.6670086064841598, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 470, train_loss = 1.6661842711619101, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 471, train_loss = 1.6648845260497183, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 472, train_loss = 1.6642816775129177, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 473, train_loss = 1.6643728579510935, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 474, train_loss = 1.6624598962371238, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 475, train_loss = 1.662248169479426, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 476, train_loss = 1.661193784500938, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 477, train_loss = 1.6604710968094878, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 478, train_loss = 1.6600748246419244, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 479, train_loss = 1.6589209783705883, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 480, train_loss = 1.6579007292166352, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 481, train_loss = 1.6571548344218172, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 482, train_loss = 1.6562406986486167, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 483, train_loss = 1.655588377499953, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 484, train_loss = 1.654882957227528, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 485, train_loss = 1.6537058159592561, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 486, train_loss = 1.653477247338742, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 487, train_loss = 1.6525559562142007, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 488, train_loss = 1.6516300459043123, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 489, train_loss = 1.650678017816972, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 490, train_loss = 1.6502318705315702, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 491, train_loss = 1.6496460090857, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 492, train_loss = 1.6488381154485978, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 493, train_loss = 1.6482450463809073, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 494, train_loss = 1.6471681783441454, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 495, train_loss = 1.6469030705629848, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 496, train_loss = 1.645738435734529, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 497, train_loss = 1.6452170998672955, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 498, train_loss = 1.6441055526956916, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 499, train_loss = 1.643538816832006, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████▏                                                            | 5/30 [45:13<3:46:11, 542.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "6th- epoch: 0, train_loss = 110.49510361254215, train_acc = 0.793549138332557\n",
      "test Acc 0.8854748603351955:\n",
      "6th- epoch: 1, train_loss = 41.37627271562815, train_acc = 0.9160456450861667\n",
      "test Acc 0.9194599627560521:\n",
      "6th- epoch: 2, train_loss = 31.609285980463028, train_acc = 0.9387517466231952\n",
      "test Acc 0.9329608938547486:\n",
      "6th- epoch: 3, train_loss = 26.680094815790653, train_acc = 0.9473684210526315\n",
      "test Acc 0.9348230912476723:\n",
      "6th- epoch: 4, train_loss = 23.41655270010233, train_acc = 0.9537727061015371\n",
      "test Acc 0.9404096834264432:\n",
      "6th- epoch: 5, train_loss = 21.0295033082366, train_acc = 0.9574988355845365\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 6, train_loss = 19.140207175165415, train_acc = 0.9597112249650676\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 7, train_loss = 17.60149773582816, train_acc = 0.9625058220773172\n",
      "test Acc 0.9529795158286778:\n",
      "6th- epoch: 8, train_loss = 16.33266957849264, train_acc = 0.965649743828598\n",
      "test Acc 0.9539106145251397:\n",
      "6th- epoch: 9, train_loss = 15.268677685409784, train_acc = 0.9683278993945039\n",
      "test Acc 0.9553072625698324:\n",
      "6th- epoch: 10, train_loss = 14.36345474794507, train_acc = 0.9697251979506288\n",
      "test Acc 0.9562383612662942:\n",
      "6th- epoch: 11, train_loss = 13.581949733197689, train_acc = 0.9721704704238472\n",
      "test Acc 0.9581005586592178:\n",
      "6th- epoch: 12, train_loss = 12.898818666115403, train_acc = 0.9747321844434094\n",
      "test Acc 0.9590316573556797:\n",
      "6th- epoch: 13, train_loss = 12.293721189722419, train_acc = 0.9761294829995343\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 14, train_loss = 11.76381772942841, train_acc = 0.9769445738239404\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 15, train_loss = 11.28465404175222, train_acc = 0.9781089892873778\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 16, train_loss = 10.850306050851941, train_acc = 0.9795062878435026\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 17, train_loss = 10.460285486653447, train_acc = 0.9804378202142524\n",
      "test Acc 0.9632216014897579:\n",
      "6th- epoch: 18, train_loss = 10.100801102817059, train_acc = 0.9809035863996274\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 19, train_loss = 9.76332963258028, train_acc = 0.9813693525850024\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 20, train_loss = 9.46252941340208, train_acc = 0.981951560316721\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 21, train_loss = 9.173272719606757, train_acc = 0.981951560316721\n",
      "test Acc 0.9646182495344506:\n",
      "6th- epoch: 22, train_loss = 8.903351468965411, train_acc = 0.9827666511411272\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 23, train_loss = 8.649504097178578, train_acc = 0.9834653004191896\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 24, train_loss = 8.41254991106689, train_acc = 0.983698183511877\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 25, train_loss = 8.187832698225975, train_acc = 0.9842803912435957\n",
      "test Acc 0.9650837988826816:\n",
      "6th- epoch: 26, train_loss = 7.978228701278567, train_acc = 0.9853283651606893\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 27, train_loss = 7.782475041225553, train_acc = 0.9856776897997206\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 28, train_loss = 7.590440345928073, train_acc = 0.986376339077783\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 29, train_loss = 7.410953531041741, train_acc = 0.9866092221704704\n",
      "test Acc 0.9650837988826816:\n",
      "6th- epoch: 30, train_loss = 7.240141110494733, train_acc = 0.9866092221704704\n",
      "test Acc 0.9650837988826816:\n",
      "6th- epoch: 31, train_loss = 7.0796384289860725, train_acc = 0.9864927806241267\n",
      "test Acc 0.9650837988826816:\n",
      "6th- epoch: 32, train_loss = 6.927688270807266, train_acc = 0.9870749883558454\n",
      "test Acc 0.9650837988826816:\n",
      "6th- epoch: 33, train_loss = 6.782050043344498, train_acc = 0.9873078714485328\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 34, train_loss = 6.64507083594799, train_acc = 0.9874243129948765\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 35, train_loss = 6.516437279060483, train_acc = 0.9876571960875641\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 36, train_loss = 6.3920059483498335, train_acc = 0.9878900791802515\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 37, train_loss = 6.270579352974892, train_acc = 0.9881229622729389\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 38, train_loss = 6.1600225660949945, train_acc = 0.9882394038192828\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 39, train_loss = 6.053186893463135, train_acc = 0.9884722869119702\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 40, train_loss = 5.948125101625919, train_acc = 0.9884722869119702\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 41, train_loss = 5.8420315310359, train_acc = 0.9887051700046576\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 42, train_loss = 5.748115606606007, train_acc = 0.9888216115510013\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 43, train_loss = 5.655979392118752, train_acc = 0.9891709361900326\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 44, train_loss = 5.569957971572876, train_acc = 0.9892873777363763\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 45, train_loss = 5.482826203107834, train_acc = 0.9892873777363763\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 46, train_loss = 5.403668713755906, train_acc = 0.9896367023754076\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 47, train_loss = 5.323945581912994, train_acc = 0.9897531439217513\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 48, train_loss = 5.2465130761265755, train_acc = 0.9899860270144387\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 49, train_loss = 5.172327622771263, train_acc = 0.9901024685607824\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 50, train_loss = 5.10131507832557, train_acc = 0.9902189101071263\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 51, train_loss = 5.034172770567238, train_acc = 0.9901024685607824\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 52, train_loss = 4.9674382684752345, train_acc = 0.9906846762925011\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 53, train_loss = 4.905049483291805, train_acc = 0.9909175593851887\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 54, train_loss = 4.843222764320672, train_acc = 0.9911504424778761\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 55, train_loss = 4.783982843160629, train_acc = 0.9912668840242198\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 56, train_loss = 4.727855525910854, train_acc = 0.9913833255705635\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 57, train_loss = 4.67135797906667, train_acc = 0.9913833255705635\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 58, train_loss = 4.619591268710792, train_acc = 0.9916162086632511\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 59, train_loss = 4.565928529016674, train_acc = 0.9914997671169073\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 60, train_loss = 4.516146816313267, train_acc = 0.9916162086632511\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 61, train_loss = 4.465265899896622, train_acc = 0.9914997671169073\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 62, train_loss = 4.418966087512672, train_acc = 0.9914997671169073\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 63, train_loss = 4.370696964673698, train_acc = 0.9914997671169073\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 64, train_loss = 4.32749658357352, train_acc = 0.9914997671169073\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 65, train_loss = 4.281348903663456, train_acc = 0.9917326502095948\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 66, train_loss = 4.238537180237472, train_acc = 0.9917326502095948\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 67, train_loss = 4.196048925630748, train_acc = 0.9917326502095948\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 68, train_loss = 4.156621943227947, train_acc = 0.9917326502095948\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 69, train_loss = 4.115452115423977, train_acc = 0.9921984163949698\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 70, train_loss = 4.077811856754124, train_acc = 0.992081974848626\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 71, train_loss = 4.039329235441983, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 72, train_loss = 4.0016291392967105, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 73, train_loss = 3.965979983098805, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 74, train_loss = 3.9304726449772716, train_acc = 0.9921984163949698\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 75, train_loss = 3.8954472690820694, train_acc = 0.9921984163949698\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 76, train_loss = 3.858996187336743, train_acc = 0.9921984163949698\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 77, train_loss = 3.826650443021208, train_acc = 0.9923148579413135\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 78, train_loss = 3.7956482246518135, train_acc = 0.9924312994876572\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 79, train_loss = 3.763290487229824, train_acc = 0.9924312994876572\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 80, train_loss = 3.730973072350025, train_acc = 0.9924312994876572\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 81, train_loss = 3.702494325581938, train_acc = 0.9925477410340009\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 82, train_loss = 3.6731153898872435, train_acc = 0.9926641825803446\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 83, train_loss = 3.642862039152533, train_acc = 0.9926641825803446\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 84, train_loss = 3.615445986390114, train_acc = 0.9927806241266884\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 85, train_loss = 3.5875624218024313, train_acc = 0.9928970656730322\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 86, train_loss = 3.559747417923063, train_acc = 0.9930135072193759\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 87, train_loss = 3.5337835401296616, train_acc = 0.9930135072193759\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 88, train_loss = 3.506503500044346, train_acc = 0.9930135072193759\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 89, train_loss = 3.481794712599367, train_acc = 0.9930135072193759\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 90, train_loss = 3.455393513198942, train_acc = 0.9931299487657196\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 91, train_loss = 3.4319681501947343, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 92, train_loss = 3.4077002755366266, train_acc = 0.9932463903120633\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 93, train_loss = 3.382526222616434, train_acc = 0.9933628318584071\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 94, train_loss = 3.3595713921822608, train_acc = 0.9934792734047508\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 95, train_loss = 3.3368733688257635, train_acc = 0.9934792734047508\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 96, train_loss = 3.3159538581967354, train_acc = 0.9934792734047508\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 97, train_loss = 3.2926107100211084, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 98, train_loss = 3.272297841962427, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 99, train_loss = 3.2509678513742983, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 100, train_loss = 3.2307839966379106, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 101, train_loss = 3.2110518789850175, train_acc = 0.9937121564974383\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 102, train_loss = 3.1912593194283545, train_acc = 0.9937121564974383\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 103, train_loss = 3.1718555563129485, train_acc = 0.9937121564974383\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 104, train_loss = 3.1514595025219023, train_acc = 0.9937121564974383\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 105, train_loss = 3.1340056150220335, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 106, train_loss = 3.1153523423708975, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 107, train_loss = 3.0972775779664516, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 108, train_loss = 3.080737881362438, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 109, train_loss = 3.062829894479364, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 110, train_loss = 3.045062573160976, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 111, train_loss = 3.0280766747891903, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 112, train_loss = 3.0116255641914904, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 113, train_loss = 2.994834240525961, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 114, train_loss = 2.9791089831851423, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 115, train_loss = 2.9639314487576485, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 116, train_loss = 2.9493302144110203, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 117, train_loss = 2.9325787597335875, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 118, train_loss = 2.9165225625038147, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 119, train_loss = 2.903897028416395, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 120, train_loss = 2.88841994991526, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 121, train_loss = 2.8744483068585396, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 122, train_loss = 2.8611469068564475, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 123, train_loss = 2.845557099673897, train_acc = 0.9941779226828132\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 124, train_loss = 2.8336250535212457, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 125, train_loss = 2.819357880856842, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 126, train_loss = 2.80787538504228, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 127, train_loss = 2.79301934549585, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 128, train_loss = 2.781287645222619, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 129, train_loss = 2.769380496116355, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 130, train_loss = 2.755521337268874, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 131, train_loss = 2.743653414072469, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 132, train_loss = 2.73128330335021, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 133, train_loss = 2.720608338713646, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 134, train_loss = 2.7086702052038163, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 135, train_loss = 2.6972659081220627, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 136, train_loss = 2.686236956389621, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 137, train_loss = 2.6750137533526868, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 138, train_loss = 2.663735017180443, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 139, train_loss = 2.6527182285208255, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 140, train_loss = 2.6424565464258194, train_acc = 0.9944108057755007\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 141, train_loss = 2.6316343620419502, train_acc = 0.9944108057755007\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 142, train_loss = 2.621456240536645, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 143, train_loss = 2.6113528918940574, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 144, train_loss = 2.600897402735427, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 145, train_loss = 2.5903116886038333, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 146, train_loss = 2.580528188496828, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 147, train_loss = 2.5726446558255702, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 148, train_loss = 2.561396097065881, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 149, train_loss = 2.552033982006833, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 150, train_loss = 2.5427662928123027, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 151, train_loss = 2.5341797929722816, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 152, train_loss = 2.524400881258771, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 153, train_loss = 2.515693099470809, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 154, train_loss = 2.5068524528760463, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 155, train_loss = 2.4996917832177132, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 156, train_loss = 2.4896376964170486, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 157, train_loss = 2.4813730630557984, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 158, train_loss = 2.473250498296693, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 159, train_loss = 2.4645501486957073, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 160, train_loss = 2.4560851852875203, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 161, train_loss = 2.4486884649377316, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 162, train_loss = 2.4412913385313004, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 163, train_loss = 2.4326025433838367, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 164, train_loss = 2.42423427850008, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 165, train_loss = 2.4176706795115024, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 166, train_loss = 2.40941513213329, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 167, train_loss = 2.4016815547365695, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 168, train_loss = 2.3929209175985307, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 169, train_loss = 2.3868120226543397, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 170, train_loss = 2.379535550950095, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 171, train_loss = 2.3713923830073327, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 172, train_loss = 2.364341128617525, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 173, train_loss = 2.3578295931220055, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 174, train_loss = 2.351161516038701, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 175, train_loss = 2.34523814660497, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 176, train_loss = 2.3367719363886863, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 177, train_loss = 2.3304657216649503, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 178, train_loss = 2.3238963037729263, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 179, train_loss = 2.317556208698079, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 180, train_loss = 2.310306318104267, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 181, train_loss = 2.303633904783055, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 182, train_loss = 2.298559706658125, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 183, train_loss = 2.2907270391006023, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 184, train_loss = 2.285045637516305, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 185, train_loss = 2.278508848277852, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 186, train_loss = 2.271728115854785, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 187, train_loss = 2.2667527869343758, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 188, train_loss = 2.260788182495162, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 189, train_loss = 2.254568140953779, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 190, train_loss = 2.248485529096797, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 191, train_loss = 2.243487364379689, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 192, train_loss = 2.237211528001353, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 193, train_loss = 2.2307971578557044, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 194, train_loss = 2.2267923925537616, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 195, train_loss = 2.2204378123860806, train_acc = 0.9958081043316255\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 196, train_loss = 2.214265750022605, train_acc = 0.9958081043316255\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 197, train_loss = 2.2088209751527756, train_acc = 0.9958081043316255\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 198, train_loss = 2.2035658496897668, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 199, train_loss = 2.199487429112196, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 200, train_loss = 2.1932800251524895, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 201, train_loss = 2.187811630545184, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 202, train_loss = 2.182370326248929, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 203, train_loss = 2.177915535867214, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 204, train_loss = 2.1728509578388184, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 205, train_loss = 2.1672461044508964, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 206, train_loss = 2.163326431065798, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 207, train_loss = 2.1572219356894493, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 208, train_loss = 2.151784325717017, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 209, train_loss = 2.1472072030883282, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 210, train_loss = 2.1431023341137916, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 211, train_loss = 2.1377713395049796, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 212, train_loss = 2.132406387478113, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 213, train_loss = 2.1291378624737263, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 214, train_loss = 2.1246451983461156, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 215, train_loss = 2.1189695708453655, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 216, train_loss = 2.1155837140977383, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 217, train_loss = 2.111039881943725, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 218, train_loss = 2.10588852816727, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 219, train_loss = 2.100432112812996, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 220, train_loss = 2.098622246296145, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 221, train_loss = 2.0925697000930086, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 222, train_loss = 2.089227298856713, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 223, train_loss = 2.0844901502132416, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 224, train_loss = 2.080803560675122, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 225, train_loss = 2.075890451669693, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 226, train_loss = 2.0732717203209177, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 227, train_loss = 2.06856817251537, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 228, train_loss = 2.0641140826046467, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 229, train_loss = 2.0609856843948364, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 230, train_loss = 2.0564581701764837, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 231, train_loss = 2.0528214486548677, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 232, train_loss = 2.049681584001519, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 233, train_loss = 2.0448394902050495, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 234, train_loss = 2.042484247474931, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 235, train_loss = 2.0374860787997022, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 236, train_loss = 2.0340007232734933, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 237, train_loss = 2.030076529830694, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 238, train_loss = 2.0272983325412497, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 239, train_loss = 2.023128970176913, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 240, train_loss = 2.019837102503516, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 241, train_loss = 2.016525169252418, train_acc = 0.9961574289706567\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 242, train_loss = 2.0131027387687936, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 243, train_loss = 2.0114824970951304, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 244, train_loss = 2.0059046720853075, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 245, train_loss = 2.003136530518532, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 246, train_loss = 1.999490582733415, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 247, train_loss = 1.997537555755116, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 248, train_loss = 1.9933959419140592, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 249, train_loss = 1.9887013584375381, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 250, train_loss = 1.9882731387624517, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 251, train_loss = 1.983320202678442, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 252, train_loss = 1.9804532391717657, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 253, train_loss = 1.9780456200242043, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 254, train_loss = 1.9736340282252058, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 255, train_loss = 1.9709792534122244, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 256, train_loss = 1.9686525812139735, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 257, train_loss = 1.9652258331188932, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 258, train_loss = 1.9617885748157278, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 259, train_loss = 1.9599026268115267, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 260, train_loss = 1.956041952013038, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 261, train_loss = 1.9530068772146478, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 262, train_loss = 1.950416412204504, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 263, train_loss = 1.9475590313086286, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 264, train_loss = 1.9449579442152753, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 265, train_loss = 1.941673026769422, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 266, train_loss = 1.9384138224413618, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 267, train_loss = 1.9367267116904259, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 268, train_loss = 1.9337598060956225, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 269, train_loss = 1.9305586913833395, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 270, train_loss = 1.9283073954284191, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 271, train_loss = 1.9248091280460358, train_acc = 0.9959245458779693\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 272, train_loss = 1.9223995370557532, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 273, train_loss = 1.920358935953118, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 274, train_loss = 1.9165130592882633, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 275, train_loss = 1.9139457233250141, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 276, train_loss = 1.9126390628516674, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 277, train_loss = 1.909572035074234, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 278, train_loss = 1.9062214443692937, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 279, train_loss = 1.905563106178306, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 280, train_loss = 1.9007124491035938, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 281, train_loss = 1.9006041126558557, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 282, train_loss = 1.896832425147295, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 283, train_loss = 1.8945749402046204, train_acc = 0.9959245458779693\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 284, train_loss = 1.8919026689836755, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 285, train_loss = 1.8898430615663528, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 286, train_loss = 1.8870916813611984, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 287, train_loss = 1.8843800028553233, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 288, train_loss = 1.8820674555609003, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 289, train_loss = 1.8806742565939203, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 290, train_loss = 1.8774304203689098, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 291, train_loss = 1.875769842416048, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 292, train_loss = 1.8734310828149319, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 293, train_loss = 1.8712505275616422, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 294, train_loss = 1.868885931908153, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 295, train_loss = 1.8654579693684354, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 296, train_loss = 1.8652433106908575, train_acc = 0.9959245458779693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 297, train_loss = 1.860914833843708, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 298, train_loss = 1.8611738085746765, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 299, train_loss = 1.8578851483762264, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 300, train_loss = 1.8555068919667974, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 301, train_loss = 1.8538959237048402, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 302, train_loss = 1.8515888713300228, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 303, train_loss = 1.848785058944486, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 304, train_loss = 1.8484608245780692, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 305, train_loss = 1.8448515856871381, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 306, train_loss = 1.843103171675466, train_acc = 0.9961574289706567\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 307, train_loss = 1.8416179046034813, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 308, train_loss = 1.8377845188369974, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 309, train_loss = 1.8364091838011518, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 310, train_loss = 1.835131941945292, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 311, train_loss = 1.8333927789935842, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 312, train_loss = 1.8314950404455885, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 313, train_loss = 1.8283959279069677, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 314, train_loss = 1.826242670416832, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 315, train_loss = 1.8258911954471841, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 316, train_loss = 1.8222436668584123, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 317, train_loss = 1.8219536803662777, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 318, train_loss = 1.8185281878104433, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 319, train_loss = 1.8178766891360283, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 320, train_loss = 1.8155681006610394, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 321, train_loss = 1.8140672644367442, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 322, train_loss = 1.810769110918045, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 323, train_loss = 1.8106708427658305, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 324, train_loss = 1.8084127008914948, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 325, train_loss = 1.8055475937435403, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 326, train_loss = 1.8061440089950338, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 327, train_loss = 1.802131445496343, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 328, train_loss = 1.8020382648101076, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 329, train_loss = 1.7994269169867039, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 330, train_loss = 1.798091052682139, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 331, train_loss = 1.7957471819827333, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 332, train_loss = 1.7946778474142775, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 333, train_loss = 1.7928999500581995, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 334, train_loss = 1.7908402979373932, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 335, train_loss = 1.7896046452224255, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 336, train_loss = 1.7881566174328327, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 337, train_loss = 1.7852019406855106, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 338, train_loss = 1.7846709651057608, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 339, train_loss = 1.7818585932254791, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 340, train_loss = 1.780362457036972, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 341, train_loss = 1.7793302983045578, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 342, train_loss = 1.7770927846431732, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 343, train_loss = 1.777695958793629, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 344, train_loss = 1.7744839936494827, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 345, train_loss = 1.7723486945033073, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 346, train_loss = 1.7719750466640107, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 347, train_loss = 1.7697317724232562, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 348, train_loss = 1.7677488178014755, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 349, train_loss = 1.7658932295744307, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 350, train_loss = 1.7651885375380516, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 351, train_loss = 1.764913144230377, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 352, train_loss = 1.761313361406792, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 353, train_loss = 1.7607148339156993, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 354, train_loss = 1.759636476635933, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 355, train_loss = 1.758026638359297, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 356, train_loss = 1.7556402906775475, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 357, train_loss = 1.7535749673843384, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 358, train_loss = 1.753687056421768, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 359, train_loss = 1.752833881706465, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 360, train_loss = 1.749817106872797, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 361, train_loss = 1.7491480472381227, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 362, train_loss = 1.7484702530200593, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 363, train_loss = 1.746965229511261, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 364, train_loss = 1.7458721846342087, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 365, train_loss = 1.7416673178668134, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 366, train_loss = 1.742546780675184, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 367, train_loss = 1.741387999325525, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 368, train_loss = 1.7391126565635204, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 369, train_loss = 1.7384218077058904, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 370, train_loss = 1.7368685913388617, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 371, train_loss = 1.7355852238833904, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 372, train_loss = 1.7338759477133863, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 373, train_loss = 1.7327724223141558, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 374, train_loss = 1.7305548923905008, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 375, train_loss = 1.7305035504396074, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 376, train_loss = 1.7291985911433585, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 377, train_loss = 1.7273890500073321, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 378, train_loss = 1.7266711369156837, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 379, train_loss = 1.7245012844796292, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 380, train_loss = 1.724239569157362, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 381, train_loss = 1.722920584201347, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 382, train_loss = 1.7213007137179375, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 383, train_loss = 1.7204796336591244, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 384, train_loss = 1.7193374447524548, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 385, train_loss = 1.7177698947489262, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 386, train_loss = 1.7161113669280894, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 387, train_loss = 1.7156642812187783, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 388, train_loss = 1.7142953189904802, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 389, train_loss = 1.7127471479470842, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 390, train_loss = 1.7115462658111937, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 391, train_loss = 1.710412658751011, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 392, train_loss = 1.707957286387682, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 393, train_loss = 1.7082615904510021, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 394, train_loss = 1.708309871435631, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 395, train_loss = 1.7054519864614122, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 396, train_loss = 1.705010063946247, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 397, train_loss = 1.7029094372992404, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 398, train_loss = 1.7031214646995068, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 399, train_loss = 1.7007053370471112, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 400, train_loss = 1.7005930741433986, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 401, train_loss = 1.6993405222892761, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 402, train_loss = 1.6973249080474488, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 403, train_loss = 1.6977183085982688, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 404, train_loss = 1.696783980994951, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 405, train_loss = 1.6949409010703675, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 406, train_loss = 1.6926634038682096, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 407, train_loss = 1.6924383714795113, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 408, train_loss = 1.6913970385794528, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 409, train_loss = 1.6912046186625957, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 410, train_loss = 1.6897012728150003, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 411, train_loss = 1.6888242227141745, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 412, train_loss = 1.6874351315200329, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 413, train_loss = 1.6864926554262638, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 414, train_loss = 1.6850396406953223, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 415, train_loss = 1.6847426208551042, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 416, train_loss = 1.6839909491245635, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 417, train_loss = 1.6830988911096938, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 418, train_loss = 1.6812946771387942, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 419, train_loss = 1.6813404175336473, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 420, train_loss = 1.6789680260117166, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 421, train_loss = 1.6787915130262263, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 422, train_loss = 1.6773676238954067, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 423, train_loss = 1.6762759002740495, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 424, train_loss = 1.6757919254596345, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 425, train_loss = 1.675045481591951, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 426, train_loss = 1.674147229641676, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 427, train_loss = 1.6733880142564885, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 428, train_loss = 1.67176378890872, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 429, train_loss = 1.6710145808756351, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 430, train_loss = 1.6696661139721982, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 431, train_loss = 1.6684034926001914, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 432, train_loss = 1.668473067402374, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 433, train_loss = 1.666496381163597, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 434, train_loss = 1.666517298668623, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 435, train_loss = 1.6659719347953796, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 436, train_loss = 1.664583417295944, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 437, train_loss = 1.6630812101066113, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 438, train_loss = 1.6621197524364106, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 439, train_loss = 1.662212726951111, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 440, train_loss = 1.6617016730015166, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 441, train_loss = 1.6603903311188333, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 442, train_loss = 1.658092189580202, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 443, train_loss = 1.65858692425536, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 444, train_loss = 1.6566838187281974, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 445, train_loss = 1.6562317870557308, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 446, train_loss = 1.6550816123490222, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 447, train_loss = 1.6538528501987457, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 448, train_loss = 1.6534072533249855, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 449, train_loss = 1.6536318150465377, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 450, train_loss = 1.651420985639561, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 451, train_loss = 1.6509560297126882, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 452, train_loss = 1.6501392896170728, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 453, train_loss = 1.6488796534831636, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 454, train_loss = 1.6464172179694287, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 455, train_loss = 1.6467168641393073, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 456, train_loss = 1.6470233065192588, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 457, train_loss = 1.6453514223103411, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 458, train_loss = 1.6448102841968648, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 459, train_loss = 1.6449388613109477, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 460, train_loss = 1.642659556120634, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 461, train_loss = 1.6429438616032712, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 462, train_loss = 1.6421782299876213, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 463, train_loss = 1.6403131385450251, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 464, train_loss = 1.6400855096871965, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 465, train_loss = 1.6381504125893116, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 466, train_loss = 1.6376184585387819, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 467, train_loss = 1.637836494774092, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 468, train_loss = 1.6359243455226533, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 469, train_loss = 1.6362287402153015, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 470, train_loss = 1.634985821961891, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 471, train_loss = 1.6337846703827381, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 472, train_loss = 1.633906890929211, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 473, train_loss = 1.6328655841643922, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 474, train_loss = 1.6327941715717316, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 475, train_loss = 1.630821105092764, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 476, train_loss = 1.6293156283791177, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 477, train_loss = 1.6305383530561812, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 478, train_loss = 1.6294817117159255, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 479, train_loss = 1.628471963107586, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 480, train_loss = 1.6284395444090478, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 481, train_loss = 1.6273251597885974, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 482, train_loss = 1.6243371317978017, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 483, train_loss = 1.6260150757734664, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 484, train_loss = 1.6263067610561848, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 485, train_loss = 1.6240320056676865, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 486, train_loss = 1.6227184906601906, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 487, train_loss = 1.6233796291053295, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 488, train_loss = 1.6221169183845632, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 489, train_loss = 1.6192756866221316, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 490, train_loss = 1.6206910299952142, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 491, train_loss = 1.6202987246215343, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 492, train_loss = 1.619269651651848, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 493, train_loss = 1.6187692048843019, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 494, train_loss = 1.6181281134486198, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 495, train_loss = 1.6182186479563825, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 496, train_loss = 1.61639727774309, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 497, train_loss = 1.6161687349085696, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 498, train_loss = 1.6155830423231237, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 499, train_loss = 1.615497441322077, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████▌                                                          | 6/30 [54:20<3:37:34, 543.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "7th- epoch: 0, train_loss = 93.45585179328918, train_acc = 0.8068234746157429\n",
      "test Acc 0.8924581005586593:\n",
      "7th- epoch: 1, train_loss = 42.215537786483765, train_acc = 0.916394969725198\n",
      "test Acc 0.9203910614525139:\n",
      "7th- epoch: 2, train_loss = 32.90927780047059, train_acc = 0.9353749417792269\n",
      "test Acc 0.9334264432029795:\n",
      "7th- epoch: 3, train_loss = 27.691766619682312, train_acc = 0.9431765253842571\n",
      "test Acc 0.9366852886405959:\n",
      "7th- epoch: 4, train_loss = 24.16898050904274, train_acc = 0.9485328365160689\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 5, train_loss = 21.545543808490038, train_acc = 0.9537727061015371\n",
      "test Acc 0.9436685288640596:\n",
      "7th- epoch: 6, train_loss = 19.49414797499776, train_acc = 0.9579646017699115\n",
      "test Acc 0.9450651769087524:\n",
      "7th- epoch: 7, train_loss = 17.877407144755125, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 8, train_loss = 16.56070315092802, train_acc = 0.9641360037261295\n",
      "test Acc 0.952048417132216:\n",
      "7th- epoch: 9, train_loss = 15.469830475747585, train_acc = 0.9673963670237541\n",
      "test Acc 0.9553072625698324:\n",
      "7th- epoch: 10, train_loss = 14.546627208590508, train_acc = 0.9693758733115976\n",
      "test Acc 0.9567039106145251:\n",
      "7th- epoch: 11, train_loss = 13.739556953310966, train_acc = 0.9721704704238472\n",
      "test Acc 0.957635009310987:\n",
      "7th- epoch: 12, train_loss = 13.049388848245144, train_acc = 0.9736842105263158\n",
      "test Acc 0.9590316573556797:\n",
      "7th- epoch: 13, train_loss = 12.452097101137042, train_acc = 0.9748486259897532\n",
      "test Acc 0.9590316573556797:\n",
      "7th- epoch: 14, train_loss = 11.917509889230132, train_acc = 0.9761294829995343\n",
      "test Acc 0.9613594040968343:\n",
      "7th- epoch: 15, train_loss = 11.424541121348739, train_acc = 0.9769445738239404\n",
      "test Acc 0.9618249534450651:\n",
      "7th- epoch: 16, train_loss = 10.987800205126405, train_acc = 0.9778761061946902\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 17, train_loss = 10.595058981329203, train_acc = 0.9788076385654402\n",
      "test Acc 0.962756052141527:\n",
      "7th- epoch: 18, train_loss = 10.2341533228755, train_acc = 0.9795062878435026\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 19, train_loss = 9.901502409949899, train_acc = 0.9805542617605962\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 20, train_loss = 9.588780421763659, train_acc = 0.9812529110386586\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 21, train_loss = 9.305198144167662, train_acc = 0.9820680018630648\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 22, train_loss = 9.036678088828921, train_acc = 0.9827666511411272\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 23, train_loss = 8.78671414591372, train_acc = 0.9831159757801584\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 24, train_loss = 8.554423043504357, train_acc = 0.9834653004191896\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 25, train_loss = 8.336659556254745, train_acc = 0.9839310666045645\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 26, train_loss = 8.130103468894958, train_acc = 0.9842803912435957\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 27, train_loss = 7.934924496337771, train_acc = 0.9845132743362832\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 28, train_loss = 7.752308117225766, train_acc = 0.9852119236143456\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 29, train_loss = 7.574689984321594, train_acc = 0.9855612482533768\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 30, train_loss = 7.400500617921352, train_acc = 0.9855612482533768\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 31, train_loss = 7.242203820496798, train_acc = 0.985910572892408\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 32, train_loss = 7.090470789000392, train_acc = 0.9862598975314392\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 33, train_loss = 6.94835171662271, train_acc = 0.9864927806241267\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 34, train_loss = 6.810082757845521, train_acc = 0.9868421052631579\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 35, train_loss = 6.679257990792394, train_acc = 0.9870749883558454\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 36, train_loss = 6.556263854727149, train_acc = 0.9874243129948765\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 37, train_loss = 6.436715269461274, train_acc = 0.9876571960875641\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 38, train_loss = 6.325814861804247, train_acc = 0.9880065207265952\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 39, train_loss = 6.21784970164299, train_acc = 0.9882394038192828\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 40, train_loss = 6.113633023574948, train_acc = 0.9883558453656265\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 41, train_loss = 6.016921224072576, train_acc = 0.9887051700046576\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 42, train_loss = 5.920995494350791, train_acc = 0.9888216115510013\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 43, train_loss = 5.829079968854785, train_acc = 0.9888216115510013\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 44, train_loss = 5.740563353523612, train_acc = 0.9889380530973452\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 45, train_loss = 5.657369939610362, train_acc = 0.9891709361900326\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 46, train_loss = 5.576391709968448, train_acc = 0.9897531439217513\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 47, train_loss = 5.496479470282793, train_acc = 0.9897531439217513\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 48, train_loss = 5.422687828540802, train_acc = 0.9901024685607824\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 49, train_loss = 5.348185248672962, train_acc = 0.99033535165347\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 50, train_loss = 5.278214039281011, train_acc = 0.9902189101071263\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 51, train_loss = 5.211159558966756, train_acc = 0.9904517931998137\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 52, train_loss = 5.144384881481528, train_acc = 0.9905682347461574\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 53, train_loss = 5.082179760560393, train_acc = 0.9905682347461574\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 54, train_loss = 5.01895900350064, train_acc = 0.990801117838845\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 55, train_loss = 4.95849743206054, train_acc = 0.990801117838845\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 56, train_loss = 4.901815279386938, train_acc = 0.9909175593851887\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 57, train_loss = 4.843997575342655, train_acc = 0.9911504424778761\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 58, train_loss = 4.789368061348796, train_acc = 0.9912668840242198\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 59, train_loss = 4.7374322125688195, train_acc = 0.9913833255705635\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 60, train_loss = 4.684324725531042, train_acc = 0.9913833255705635\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 61, train_loss = 4.636332365684211, train_acc = 0.9912668840242198\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 62, train_loss = 4.5863933730870485, train_acc = 0.9913833255705635\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 63, train_loss = 4.539000675082207, train_acc = 0.9916162086632511\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 64, train_loss = 4.494244112633169, train_acc = 0.9916162086632511\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 65, train_loss = 4.448690871708095, train_acc = 0.9917326502095948\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 66, train_loss = 4.405297442339361, train_acc = 0.9917326502095948\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 67, train_loss = 4.361049129627645, train_acc = 0.9917326502095948\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 68, train_loss = 4.319153296761215, train_acc = 0.9917326502095948\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 69, train_loss = 4.278799771331251, train_acc = 0.9918490917559385\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 70, train_loss = 4.239622569642961, train_acc = 0.9918490917559385\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 71, train_loss = 4.200466200709343, train_acc = 0.9918490917559385\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 72, train_loss = 4.163047919981182, train_acc = 0.9919655333022822\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 73, train_loss = 4.124776911921799, train_acc = 0.9919655333022822\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 74, train_loss = 4.088302688673139, train_acc = 0.9919655333022822\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 75, train_loss = 4.054199616424739, train_acc = 0.9919655333022822\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 76, train_loss = 4.019035463221371, train_acc = 0.9919655333022822\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 77, train_loss = 3.984392915852368, train_acc = 0.9919655333022822\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 78, train_loss = 3.9511010721325874, train_acc = 0.9919655333022822\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 79, train_loss = 3.920242238789797, train_acc = 0.9919655333022822\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 80, train_loss = 3.887024517171085, train_acc = 0.9919655333022822\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 81, train_loss = 3.856431762687862, train_acc = 0.9919655333022822\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 82, train_loss = 3.825777524150908, train_acc = 0.9919655333022822\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 83, train_loss = 3.7980744810774922, train_acc = 0.992081974848626\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 84, train_loss = 3.7680696956813335, train_acc = 0.9921984163949698\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 85, train_loss = 3.740037643350661, train_acc = 0.9921984163949698\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 86, train_loss = 3.7118038358166814, train_acc = 0.9921984163949698\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 87, train_loss = 3.6853888854384422, train_acc = 0.9923148579413135\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 88, train_loss = 3.6581395165994763, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 89, train_loss = 3.6320722429081798, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 90, train_loss = 3.6070621432736516, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 91, train_loss = 3.5806803023442626, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 92, train_loss = 3.5568707706406713, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 93, train_loss = 3.5321694826707244, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 94, train_loss = 3.508011430501938, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 95, train_loss = 3.48422475438565, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 96, train_loss = 3.460547906346619, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 97, train_loss = 3.4394984235987067, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 98, train_loss = 3.4163532154634595, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 99, train_loss = 3.395229588262737, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 100, train_loss = 3.3746007857844234, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 101, train_loss = 3.3525613537058234, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 102, train_loss = 3.3318626703694463, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 103, train_loss = 3.3121385956183076, train_acc = 0.9931299487657196\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 104, train_loss = 3.292595840059221, train_acc = 0.9931299487657196\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 105, train_loss = 3.2727836035192013, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 106, train_loss = 3.2534841680899262, train_acc = 0.9931299487657196\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 107, train_loss = 3.2346305325627327, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 108, train_loss = 3.2154280259273946, train_acc = 0.9931299487657196\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 109, train_loss = 3.196840949356556, train_acc = 0.9932463903120633\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 110, train_loss = 3.178926249500364, train_acc = 0.9932463903120633\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 111, train_loss = 3.1612313226796687, train_acc = 0.9932463903120633\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 112, train_loss = 3.1448267973028123, train_acc = 0.9932463903120633\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 113, train_loss = 3.1271426430903375, train_acc = 0.9932463903120633\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 114, train_loss = 3.110017584171146, train_acc = 0.9932463903120633\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 115, train_loss = 3.0935084274969995, train_acc = 0.9932463903120633\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 116, train_loss = 3.077395537402481, train_acc = 0.9932463903120633\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 117, train_loss = 3.0602729781530797, train_acc = 0.9933628318584071\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 118, train_loss = 3.046370478812605, train_acc = 0.9933628318584071\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 119, train_loss = 3.0297739640809596, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 120, train_loss = 3.01430573919788, train_acc = 0.9934792734047508\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 121, train_loss = 2.998776562511921, train_acc = 0.9934792734047508\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 122, train_loss = 2.983545320574194, train_acc = 0.9934792734047508\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 123, train_loss = 2.9678879864513874, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 124, train_loss = 2.9543131007812917, train_acc = 0.9935957149510946\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 125, train_loss = 2.9398745805956423, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 126, train_loss = 2.9252465181052685, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 127, train_loss = 2.9109692499041557, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 128, train_loss = 2.898391233291477, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 129, train_loss = 2.883633241057396, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 130, train_loss = 2.8706156597472727, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 131, train_loss = 2.857086479663849, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 132, train_loss = 2.843638140708208, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 133, train_loss = 2.8322540461085737, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 134, train_loss = 2.8191870017908514, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 135, train_loss = 2.806962739676237, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 136, train_loss = 2.793453791644424, train_acc = 0.9937121564974383\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 137, train_loss = 2.7828514711000025, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 138, train_loss = 2.7712717787362635, train_acc = 0.9940614811364695\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 139, train_loss = 2.759031606372446, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 140, train_loss = 2.74643479520455, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 141, train_loss = 2.7349628298543394, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 142, train_loss = 2.724601175636053, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 143, train_loss = 2.7133454247377813, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 144, train_loss = 2.701834096107632, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 145, train_loss = 2.6919363476336002, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 146, train_loss = 2.6797771179117262, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 147, train_loss = 2.6706477417610586, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 148, train_loss = 2.6605110689997673, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 149, train_loss = 2.6493682130239904, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 150, train_loss = 2.6403405778110027, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 151, train_loss = 2.6283983602188528, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 152, train_loss = 2.6189227998256683, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 153, train_loss = 2.6097083589993417, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 154, train_loss = 2.5997114828787744, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 155, train_loss = 2.591264678630978, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 156, train_loss = 2.581319554243237, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 157, train_loss = 2.5710988617502153, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 158, train_loss = 2.562405022326857, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 159, train_loss = 2.552418562117964, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 160, train_loss = 2.5431264229118824, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 161, train_loss = 2.53561769798398, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 162, train_loss = 2.5256494940258563, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 163, train_loss = 2.5172358751296997, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 164, train_loss = 2.5099609182216227, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 165, train_loss = 2.500423630233854, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 166, train_loss = 2.4912900626659393, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 167, train_loss = 2.48407926177606, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 168, train_loss = 2.4745842330157757, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 169, train_loss = 2.4668408571742475, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 170, train_loss = 2.459167251829058, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 171, train_loss = 2.4514289959333837, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 172, train_loss = 2.442106422036886, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 173, train_loss = 2.4360839165747166, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 174, train_loss = 2.4291347092948854, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 175, train_loss = 2.4206216619350016, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 176, train_loss = 2.4127568774856627, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 177, train_loss = 2.4039616673253477, train_acc = 0.9945272473218444\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 178, train_loss = 2.3980443603359163, train_acc = 0.9945272473218444\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 179, train_loss = 2.3899616077542305, train_acc = 0.9945272473218444\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 180, train_loss = 2.383273819927126, train_acc = 0.9946436888681882\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 181, train_loss = 2.375175682362169, train_acc = 0.9946436888681882\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 182, train_loss = 2.3691734285093844, train_acc = 0.9945272473218444\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 183, train_loss = 2.3607842712663114, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 184, train_loss = 2.3537338473834097, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 185, train_loss = 2.3473175764083862, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 186, train_loss = 2.3409558199346066, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 187, train_loss = 2.3342106826603413, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 188, train_loss = 2.3269345448352396, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 189, train_loss = 2.3209320679306984, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 190, train_loss = 2.3140163444913924, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 191, train_loss = 2.3089690543711185, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 192, train_loss = 2.3006907566450536, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 193, train_loss = 2.2957836277782917, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 194, train_loss = 2.290284838527441, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 195, train_loss = 2.2841660804115236, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 196, train_loss = 2.2777888141572475, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 197, train_loss = 2.2716034688055515, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 198, train_loss = 2.2672851965762675, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 199, train_loss = 2.261271697934717, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 200, train_loss = 2.2549159401096404, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 201, train_loss = 2.250609395559877, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 202, train_loss = 2.243848980870098, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 203, train_loss = 2.2388655967079103, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 204, train_loss = 2.2335986110847443, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 205, train_loss = 2.228090410353616, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 206, train_loss = 2.22352700936608, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 207, train_loss = 2.2173594150226563, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 208, train_loss = 2.213800895959139, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 209, train_loss = 2.20710139721632, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 210, train_loss = 2.2023567606229335, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 211, train_loss = 2.19741278141737, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 212, train_loss = 2.193026648135856, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 213, train_loss = 2.187209998490289, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 214, train_loss = 2.182242742506787, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 215, train_loss = 2.177784771891311, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 216, train_loss = 2.1739165137987584, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 217, train_loss = 2.167833926854655, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 218, train_loss = 2.163135214475915, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 219, train_loss = 2.1586568776983768, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 220, train_loss = 2.1551505874376744, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 221, train_loss = 2.1499988697469234, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 222, train_loss = 2.145657063694671, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 223, train_loss = 2.140661536483094, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 224, train_loss = 2.137031340273097, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 225, train_loss = 2.1320903685409576, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 226, train_loss = 2.128947115270421, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 227, train_loss = 2.1245134721975774, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 228, train_loss = 2.1190739993471652, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 229, train_loss = 2.115972937317565, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 230, train_loss = 2.110317739425227, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 231, train_loss = 2.1067835602443665, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 232, train_loss = 2.102367201121524, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 233, train_loss = 2.098121475428343, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 234, train_loss = 2.093976651551202, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 235, train_loss = 2.0910492960829288, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 236, train_loss = 2.0861234825570136, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 237, train_loss = 2.0829758755862713, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 238, train_loss = 2.0793639831244946, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 239, train_loss = 2.074057084741071, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 240, train_loss = 2.0711629453580827, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 241, train_loss = 2.0687561631202698, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 242, train_loss = 2.062537867575884, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 243, train_loss = 2.0603377744555473, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 244, train_loss = 2.055177255300805, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 245, train_loss = 2.051713580964133, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 246, train_loss = 2.047809150069952, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 247, train_loss = 2.04508247342892, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 248, train_loss = 2.0415870000142604, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 249, train_loss = 2.0372316874563694, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 250, train_loss = 2.0350357305724174, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 251, train_loss = 2.030589709756896, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 252, train_loss = 2.027773403795436, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 253, train_loss = 2.024166998686269, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 254, train_loss = 2.0204478490632027, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 255, train_loss = 2.016613844782114, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 256, train_loss = 2.0147472445387393, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 257, train_loss = 2.010839859722182, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 258, train_loss = 2.0075522523839027, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 259, train_loss = 2.0042999896686524, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 260, train_loss = 2.000818856060505, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 261, train_loss = 1.997520251898095, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 262, train_loss = 1.9940160538535565, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 263, train_loss = 1.992802880704403, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 264, train_loss = 1.9892222571652383, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 265, train_loss = 1.9853431433439255, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 266, train_loss = 1.9820487883407623, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 267, train_loss = 1.9795400064904243, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 268, train_loss = 1.975838802754879, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 269, train_loss = 1.9736297267954797, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 270, train_loss = 1.9708173088729382, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 271, train_loss = 1.9675977255683392, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 272, train_loss = 1.9642460010945797, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 273, train_loss = 1.9613670371472836, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 274, train_loss = 1.9579676401335746, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 275, train_loss = 1.955844295443967, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 276, train_loss = 1.9535048827528954, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 277, train_loss = 1.950265385210514, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 278, train_loss = 1.9469083312433213, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 279, train_loss = 1.9448348979931325, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 280, train_loss = 1.9413867506664246, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 281, train_loss = 1.9392442915122956, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 282, train_loss = 1.936673191608861, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 283, train_loss = 1.93298455956392, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 284, train_loss = 1.9313715684693307, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 285, train_loss = 1.9278952206950635, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 286, train_loss = 1.9255469802301377, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 287, train_loss = 1.9230699378531426, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 288, train_loss = 1.9208469577133656, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 289, train_loss = 1.9178771425504237, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 290, train_loss = 1.916824872372672, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 291, train_loss = 1.9123869116883725, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 292, train_loss = 1.910262753488496, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 293, train_loss = 1.9080976657569408, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 294, train_loss = 1.9052947610616684, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 295, train_loss = 1.9029021088499576, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 296, train_loss = 1.9011774559039623, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 297, train_loss = 1.8986890513915569, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 298, train_loss = 1.8957477423828095, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 299, train_loss = 1.8939904372673482, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 300, train_loss = 1.8903544929344207, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 301, train_loss = 1.8892978292424232, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 302, train_loss = 1.8867381513118744, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 303, train_loss = 1.8839505303185433, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 304, train_loss = 1.881395872682333, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 305, train_loss = 1.879461983917281, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 306, train_loss = 1.877468741266057, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 307, train_loss = 1.8752875414211303, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 308, train_loss = 1.8740001805126667, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 309, train_loss = 1.870682056993246, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 310, train_loss = 1.8688519783318043, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 311, train_loss = 1.866554333595559, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 312, train_loss = 1.8644256319385022, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 313, train_loss = 1.8627439711708575, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 314, train_loss = 1.8606886428315192, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 315, train_loss = 1.8580802616197616, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 316, train_loss = 1.856088535161689, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 317, train_loss = 1.8537019055802375, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 318, train_loss = 1.8523893393576145, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 319, train_loss = 1.84900738671422, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 320, train_loss = 1.8481527951080352, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 321, train_loss = 1.8455456818919629, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 322, train_loss = 1.8427859395742416, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 323, train_loss = 1.8408078227657825, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 324, train_loss = 1.8397629361134022, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 325, train_loss = 1.8370905693154782, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 326, train_loss = 1.8351547345519066, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 327, train_loss = 1.8328564453404397, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 328, train_loss = 1.8309630502481014, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 329, train_loss = 1.8305320627987385, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 330, train_loss = 1.82778433826752, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 331, train_loss = 1.8267753410618752, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 332, train_loss = 1.8234656192362309, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 333, train_loss = 1.822565894573927, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 334, train_loss = 1.8189321284880862, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 335, train_loss = 1.8185668315272778, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 336, train_loss = 1.8167229976970702, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 337, train_loss = 1.8141940584173426, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 338, train_loss = 1.8125641234219074, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 339, train_loss = 1.810503326356411, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 340, train_loss = 1.8099804384401068, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 341, train_loss = 1.8075799755752087, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 342, train_loss = 1.805810751975514, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 343, train_loss = 1.804885716526769, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 344, train_loss = 1.802120354026556, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 345, train_loss = 1.8006930872797966, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 346, train_loss = 1.7983998818090186, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 347, train_loss = 1.797420601011254, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 348, train_loss = 1.7953385213622823, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 349, train_loss = 1.793495443998836, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 350, train_loss = 1.7923159375786781, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 351, train_loss = 1.7903010547161102, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 352, train_loss = 1.7892974776914343, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 353, train_loss = 1.7872294882545248, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 354, train_loss = 1.7859406856587157, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 355, train_loss = 1.7836552821099758, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 356, train_loss = 1.783913403749466, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 357, train_loss = 1.7797576412558556, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 358, train_loss = 1.7802620381116867, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 359, train_loss = 1.7779571959981695, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 360, train_loss = 1.775640994310379, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 361, train_loss = 1.7743596583604813, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 362, train_loss = 1.7745688097784296, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 363, train_loss = 1.7711434537777677, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 364, train_loss = 1.7712197540095076, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 365, train_loss = 1.7681751983473077, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 366, train_loss = 1.766724000335671, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 367, train_loss = 1.764857449918054, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 368, train_loss = 1.7627983564743772, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 369, train_loss = 1.7628281550714746, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 370, train_loss = 1.7604092495748773, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 371, train_loss = 1.7597689144313335, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 372, train_loss = 1.7578960545361042, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 373, train_loss = 1.7573109964141622, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 374, train_loss = 1.7557158073177561, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 375, train_loss = 1.754812820465304, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 376, train_loss = 1.7532451251754537, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 377, train_loss = 1.7509407922625542, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 378, train_loss = 1.7492790719261393, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 379, train_loss = 1.7475648298859596, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 380, train_loss = 1.747342468588613, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 381, train_loss = 1.7459869919111952, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 382, train_loss = 1.7442462580511346, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 383, train_loss = 1.7430655993521214, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 384, train_loss = 1.7423863696167246, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 385, train_loss = 1.740020783036016, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 386, train_loss = 1.7398150699445978, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 387, train_loss = 1.737301453948021, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 388, train_loss = 1.736844103783369, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 389, train_loss = 1.7357597401132807, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 390, train_loss = 1.7340857101371512, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 391, train_loss = 1.7322910465300083, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 392, train_loss = 1.7318463064730167, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 393, train_loss = 1.7300074683735147, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 394, train_loss = 1.7285479567945004, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 395, train_loss = 1.7266596965491772, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 396, train_loss = 1.7268720356514677, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 397, train_loss = 1.7246588096022606, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 398, train_loss = 1.7229525012662634, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 399, train_loss = 1.7232443591346964, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 400, train_loss = 1.720787831931375, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 401, train_loss = 1.7195338135352358, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 402, train_loss = 1.718267124146223, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 403, train_loss = 1.7183363487711176, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 404, train_loss = 1.7160177007317543, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 405, train_loss = 1.7166851660003886, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 406, train_loss = 1.7147895036032423, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 407, train_loss = 1.7141709054121748, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 408, train_loss = 1.7121757889399305, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 409, train_loss = 1.7128255317220464, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 410, train_loss = 1.7086730686714873, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 411, train_loss = 1.7083033820381388, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 412, train_loss = 1.707360826432705, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 413, train_loss = 1.7065356423845515, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 414, train_loss = 1.7053944692015648, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 415, train_loss = 1.7038625379791483, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 416, train_loss = 1.702922505675815, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 417, train_loss = 1.7035682188579813, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 418, train_loss = 1.7011330798268318, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 419, train_loss = 1.7013223804533482, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 420, train_loss = 1.6989206733414903, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 421, train_loss = 1.6977353319525719, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 422, train_loss = 1.6952747367322445, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 423, train_loss = 1.6942841721465811, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 424, train_loss = 1.6941135948291048, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 425, train_loss = 1.6935828514397144, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 426, train_loss = 1.6909889517119154, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 427, train_loss = 1.6903864877531305, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 428, train_loss = 1.6887034252285957, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 429, train_loss = 1.6887868369231, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 430, train_loss = 1.6869445206830278, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 431, train_loss = 1.6868657432496548, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 432, train_loss = 1.6866695024073124, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 433, train_loss = 1.6845983812818304, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 434, train_loss = 1.6837192078819498, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 435, train_loss = 1.683385363430716, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 436, train_loss = 1.6815815331647173, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 437, train_loss = 1.6792406166205183, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 438, train_loss = 1.678410225897096, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 439, train_loss = 1.6792026621988043, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 440, train_loss = 1.6781880719354376, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 441, train_loss = 1.6762955039739609, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 442, train_loss = 1.6756573878228664, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 443, train_loss = 1.6739952005445957, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 444, train_loss = 1.6735347248613834, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 445, train_loss = 1.6730292750289664, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 446, train_loss = 1.6708226004848257, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 447, train_loss = 1.6710171848535538, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 448, train_loss = 1.669607549905777, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 449, train_loss = 1.6693653637776151, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 450, train_loss = 1.668058500974439, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 451, train_loss = 1.6655446328222752, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 452, train_loss = 1.6662688391515985, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 453, train_loss = 1.6653286591172218, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 454, train_loss = 1.6644697015872225, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 455, train_loss = 1.66446727886796, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 456, train_loss = 1.6631280519068241, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 457, train_loss = 1.660941768437624, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 458, train_loss = 1.660853443085216, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 459, train_loss = 1.661021584062837, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 460, train_loss = 1.659087055712007, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 461, train_loss = 1.6591695696115494, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 462, train_loss = 1.6561877677449957, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 463, train_loss = 1.656827556551434, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 464, train_loss = 1.6564483232796192, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 465, train_loss = 1.6552423586836085, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 466, train_loss = 1.6530252546072006, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 467, train_loss = 1.6528450809419155, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 468, train_loss = 1.6514858901500702, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 469, train_loss = 1.65106713026762, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 470, train_loss = 1.6501847468316555, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 471, train_loss = 1.6502061635255814, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 472, train_loss = 1.6488785644760355, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 473, train_loss = 1.6484399376204237, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 474, train_loss = 1.6470711939036846, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 475, train_loss = 1.6464812569320202, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 476, train_loss = 1.6463134251534939, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 477, train_loss = 1.6452402882277966, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 478, train_loss = 1.6431728092720732, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 479, train_loss = 1.6436322666704655, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 480, train_loss = 1.6414425782859325, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 481, train_loss = 1.6410868117818609, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 482, train_loss = 1.6391734592616558, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 483, train_loss = 1.6405091919004917, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 484, train_loss = 1.6390689486870542, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 485, train_loss = 1.6378164427587762, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 486, train_loss = 1.6383848674595356, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 487, train_loss = 1.6362707689404488, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 488, train_loss = 1.6352148639271036, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 489, train_loss = 1.6338337808847427, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 490, train_loss = 1.6351259561488405, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 491, train_loss = 1.6335628653177992, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 492, train_loss = 1.6336371824145317, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 493, train_loss = 1.6317153610289097, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 494, train_loss = 1.6316718558082357, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 495, train_loss = 1.6301608979701996, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 496, train_loss = 1.6285493386676535, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 497, train_loss = 1.629164540558122, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 498, train_loss = 1.6293491385877132, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 499, train_loss = 1.6279231309890747, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|████████████████▌                                                      | 7/30 [1:03:23<3:28:26, 543.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "8th- epoch: 0, train_loss = 104.73707439005375, train_acc = 0.794014904517932\n",
      "test Acc 0.9031657355679702:\n",
      "8th- epoch: 1, train_loss = 40.19258721917868, train_acc = 0.9161620866325105\n",
      "test Acc 0.9250465549348231:\n",
      "8th- epoch: 2, train_loss = 31.28423283994198, train_acc = 0.9368886818816954\n",
      "test Acc 0.9357541899441341:\n",
      "8th- epoch: 3, train_loss = 26.535315711051226, train_acc = 0.9450395901257569\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 4, train_loss = 23.392054785043, train_acc = 0.9500465766185375\n",
      "test Acc 0.9418063314711359:\n",
      "8th- epoch: 5, train_loss = 21.106871098279953, train_acc = 0.9551700046576619\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 6, train_loss = 19.294365096837282, train_acc = 0.9585468095016302\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 7, train_loss = 17.817911118268967, train_acc = 0.9612249650675361\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 8, train_loss = 16.570113014429808, train_acc = 0.9641360037261295\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 9, train_loss = 15.517327763140202, train_acc = 0.9663483931066604\n",
      "test Acc 0.9529795158286778:\n",
      "8th- epoch: 10, train_loss = 14.625040590763092, train_acc = 0.9678621332091291\n",
      "test Acc 0.9553072625698324:\n",
      "8th- epoch: 11, train_loss = 13.842015950009227, train_acc = 0.9699580810433163\n",
      "test Acc 0.9562383612662942:\n",
      "8th- epoch: 12, train_loss = 13.158812062814832, train_acc = 0.9715882626921285\n",
      "test Acc 0.9581005586592178:\n",
      "8th- epoch: 13, train_loss = 12.541121570393443, train_acc = 0.9724033535165347\n",
      "test Acc 0.9594972067039106:\n",
      "8th- epoch: 14, train_loss = 11.993620172142982, train_acc = 0.9735677689799721\n",
      "test Acc 0.9604283054003724:\n",
      "8th- epoch: 15, train_loss = 11.50312989205122, train_acc = 0.9743828598043782\n",
      "test Acc 0.9604283054003724:\n",
      "8th- epoch: 16, train_loss = 11.058724839240313, train_acc = 0.9758965999068467\n",
      "test Acc 0.9613594040968343:\n",
      "8th- epoch: 17, train_loss = 10.661226561293006, train_acc = 0.9764788076385654\n",
      "test Acc 0.9613594040968343:\n",
      "8th- epoch: 18, train_loss = 10.297366620972753, train_acc = 0.9775267815556591\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 19, train_loss = 9.960718410089612, train_acc = 0.9784583139264089\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 20, train_loss = 9.659105848520994, train_acc = 0.97973917093619\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 21, train_loss = 9.37581204622984, train_acc = 0.9807871448532837\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 22, train_loss = 9.109520918689668, train_acc = 0.9809035863996274\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 23, train_loss = 8.868653126060963, train_acc = 0.9814857941313461\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 24, train_loss = 8.632242321968079, train_acc = 0.981951560316721\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 25, train_loss = 8.412859059870243, train_acc = 0.9823008849557522\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 26, train_loss = 8.212743865326047, train_acc = 0.9828830926874709\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 27, train_loss = 8.019067665562034, train_acc = 0.9832324173265021\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 28, train_loss = 7.838550437241793, train_acc = 0.9838146250582208\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 29, train_loss = 7.667285721749067, train_acc = 0.984163949697252\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 30, train_loss = 7.50315528921783, train_acc = 0.9843968327899395\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 31, train_loss = 7.347680516541004, train_acc = 0.9846297158826269\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 32, train_loss = 7.202911887317896, train_acc = 0.9852119236143456\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 33, train_loss = 7.065121967345476, train_acc = 0.985444806707033\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 34, train_loss = 6.935507709160447, train_acc = 0.9861434559850955\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 35, train_loss = 6.8089438155293465, train_acc = 0.9867256637168141\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 36, train_loss = 6.6918566301465034, train_acc = 0.9871914299021891\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 37, train_loss = 6.576228676363826, train_acc = 0.9877736376339078\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 38, train_loss = 6.468681626021862, train_acc = 0.9877736376339078\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 39, train_loss = 6.365362651646137, train_acc = 0.9881229622729389\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 40, train_loss = 6.261533126235008, train_acc = 0.9884722869119702\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 41, train_loss = 6.167183246463537, train_acc = 0.9890544946436889\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 42, train_loss = 6.07376809604466, train_acc = 0.9891709361900326\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 43, train_loss = 5.983248356729746, train_acc = 0.9891709361900326\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 44, train_loss = 5.897299457341433, train_acc = 0.9891709361900326\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 45, train_loss = 5.812342328950763, train_acc = 0.9892873777363763\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 46, train_loss = 5.732352934777737, train_acc = 0.98940381928272\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 47, train_loss = 5.655185693874955, train_acc = 0.9896367023754076\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 48, train_loss = 5.5774939600378275, train_acc = 0.9896367023754076\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 49, train_loss = 5.506202748045325, train_acc = 0.9897531439217513\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 50, train_loss = 5.4331537745893, train_acc = 0.9899860270144387\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 51, train_loss = 5.36453509144485, train_acc = 0.9901024685607824\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 52, train_loss = 5.296862233430147, train_acc = 0.9901024685607824\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 53, train_loss = 5.231954937800765, train_acc = 0.9902189101071263\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 54, train_loss = 5.170192195102572, train_acc = 0.9902189101071263\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 55, train_loss = 5.108906197361648, train_acc = 0.9902189101071263\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 56, train_loss = 5.047690800391138, train_acc = 0.9902189101071263\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 57, train_loss = 4.988819154910743, train_acc = 0.99033535165347\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 58, train_loss = 4.932495787739754, train_acc = 0.99033535165347\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 59, train_loss = 4.877265435643494, train_acc = 0.99033535165347\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 60, train_loss = 4.826069196686149, train_acc = 0.9902189101071263\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 61, train_loss = 4.773780125193298, train_acc = 0.99033535165347\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 62, train_loss = 4.722253825515509, train_acc = 0.9906846762925011\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 63, train_loss = 4.6735367169603705, train_acc = 0.9906846762925011\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 64, train_loss = 4.626757025718689, train_acc = 0.990801117838845\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 65, train_loss = 4.579801767133176, train_acc = 0.990801117838845\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 66, train_loss = 4.53615081962198, train_acc = 0.990801117838845\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 67, train_loss = 4.492005906067789, train_acc = 0.990801117838845\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 68, train_loss = 4.450624476186931, train_acc = 0.990801117838845\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 69, train_loss = 4.4082027757540345, train_acc = 0.990801117838845\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 70, train_loss = 4.365978620015085, train_acc = 0.9909175593851887\n",
      "test Acc 0.9725325884543762:\n",
      "8th- epoch: 71, train_loss = 4.32663385476917, train_acc = 0.9911504424778761\n",
      "test Acc 0.9725325884543762:\n",
      "8th- epoch: 72, train_loss = 4.287338575348258, train_acc = 0.9911504424778761\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 73, train_loss = 4.248346775770187, train_acc = 0.9911504424778761\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 74, train_loss = 4.209338047541678, train_acc = 0.9911504424778761\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 75, train_loss = 4.173381518572569, train_acc = 0.9911504424778761\n",
      "test Acc 0.9725325884543762:\n",
      "8th- epoch: 76, train_loss = 4.138011252507567, train_acc = 0.9913833255705635\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 77, train_loss = 4.103821937926114, train_acc = 0.9912668840242198\n",
      "test Acc 0.9725325884543762:\n",
      "8th- epoch: 78, train_loss = 4.070002700202167, train_acc = 0.9914997671169073\n",
      "test Acc 0.9725325884543762:\n",
      "8th- epoch: 79, train_loss = 4.036183557473123, train_acc = 0.9914997671169073\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 80, train_loss = 4.005982889793813, train_acc = 0.9916162086632511\n",
      "test Acc 0.9725325884543762:\n",
      "8th- epoch: 81, train_loss = 3.971068982966244, train_acc = 0.9917326502095948\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 82, train_loss = 3.939371575601399, train_acc = 0.9917326502095948\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 83, train_loss = 3.9085239404812455, train_acc = 0.9917326502095948\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 84, train_loss = 3.8785914788022637, train_acc = 0.9917326502095948\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 85, train_loss = 3.85113254096359, train_acc = 0.9917326502095948\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 86, train_loss = 3.821658634580672, train_acc = 0.9917326502095948\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 87, train_loss = 3.7940898733213544, train_acc = 0.9918490917559385\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 88, train_loss = 3.7631886610761285, train_acc = 0.9918490917559385\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 89, train_loss = 3.7391343489289284, train_acc = 0.9918490917559385\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 90, train_loss = 3.7117211585864425, train_acc = 0.9918490917559385\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 91, train_loss = 3.68418993242085, train_acc = 0.9919655333022822\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 92, train_loss = 3.660638733766973, train_acc = 0.9919655333022822\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 93, train_loss = 3.634237661957741, train_acc = 0.9919655333022822\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 94, train_loss = 3.6087095038965344, train_acc = 0.992081974848626\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 95, train_loss = 3.5841804053634405, train_acc = 0.992081974848626\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 96, train_loss = 3.560179783962667, train_acc = 0.992081974848626\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 97, train_loss = 3.536759454756975, train_acc = 0.9921984163949698\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 98, train_loss = 3.513590393587947, train_acc = 0.9921984163949698\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 99, train_loss = 3.4925286173820496, train_acc = 0.9921984163949698\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 100, train_loss = 3.4695823518559337, train_acc = 0.9923148579413135\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 101, train_loss = 3.447120080702007, train_acc = 0.9923148579413135\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 102, train_loss = 3.425925163552165, train_acc = 0.9924312994876572\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 103, train_loss = 3.405170072801411, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 104, train_loss = 3.384419137611985, train_acc = 0.9925477410340009\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 105, train_loss = 3.3645763993263245, train_acc = 0.9925477410340009\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 106, train_loss = 3.3450439777225256, train_acc = 0.9926641825803446\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 107, train_loss = 3.3267413955181837, train_acc = 0.9926641825803446\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 108, train_loss = 3.305559122003615, train_acc = 0.9926641825803446\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 109, train_loss = 3.287121830508113, train_acc = 0.9926641825803446\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 110, train_loss = 3.267815970815718, train_acc = 0.9926641825803446\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 111, train_loss = 3.2493081903085113, train_acc = 0.9926641825803446\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 112, train_loss = 3.2308008139953017, train_acc = 0.9928970656730322\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 113, train_loss = 3.2132988115772605, train_acc = 0.9930135072193759\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 114, train_loss = 3.19627742189914, train_acc = 0.9930135072193759\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 115, train_loss = 3.1795640867203474, train_acc = 0.9930135072193759\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 116, train_loss = 3.16214519739151, train_acc = 0.9930135072193759\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 117, train_loss = 3.1437397869303823, train_acc = 0.9931299487657196\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 118, train_loss = 3.1298580346629024, train_acc = 0.9931299487657196\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 119, train_loss = 3.113978191278875, train_acc = 0.9931299487657196\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 120, train_loss = 3.097218041308224, train_acc = 0.9931299487657196\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 121, train_loss = 3.0822908426634967, train_acc = 0.9932463903120633\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 122, train_loss = 3.0652656136080623, train_acc = 0.9932463903120633\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 123, train_loss = 3.0508262659423053, train_acc = 0.9934792734047508\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 124, train_loss = 3.0352277350611985, train_acc = 0.9934792734047508\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 125, train_loss = 3.0208523920737207, train_acc = 0.9934792734047508\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 126, train_loss = 3.007103245705366, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 127, train_loss = 2.991944549139589, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 128, train_loss = 2.978443691972643, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 129, train_loss = 2.9631762141361833, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 130, train_loss = 2.9497454296797514, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 131, train_loss = 2.9367296188138425, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 132, train_loss = 2.9230247014202178, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 133, train_loss = 2.9087137919850647, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 134, train_loss = 2.8964612600393593, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 135, train_loss = 2.8832712788134813, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 136, train_loss = 2.8714276291429996, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 137, train_loss = 2.8590159504674375, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 138, train_loss = 2.845613672863692, train_acc = 0.9937121564974383\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 139, train_loss = 2.8342772256582975, train_acc = 0.9937121564974383\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 140, train_loss = 2.823568298481405, train_acc = 0.9937121564974383\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 141, train_loss = 2.8103765016421676, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 142, train_loss = 2.799149996135384, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 143, train_loss = 2.7873069080524147, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 144, train_loss = 2.7761074933223426, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 145, train_loss = 2.7653683200478554, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 146, train_loss = 2.753853039816022, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 147, train_loss = 2.7426969911903143, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 148, train_loss = 2.73202733322978, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 149, train_loss = 2.721505695488304, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 150, train_loss = 2.711455923039466, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 151, train_loss = 2.7009590030647814, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 152, train_loss = 2.6910122907720506, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 153, train_loss = 2.679971367586404, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 154, train_loss = 2.6706713177263737, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 155, train_loss = 2.660890720319003, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 156, train_loss = 2.6504629333503544, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 157, train_loss = 2.6419062693603337, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 158, train_loss = 2.63155424548313, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 159, train_loss = 2.6223713639192283, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 160, train_loss = 2.613807261455804, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 161, train_loss = 2.6044731810688972, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 162, train_loss = 2.5953051783144474, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 163, train_loss = 2.585332445334643, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 164, train_loss = 2.57790363766253, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 165, train_loss = 2.5685594636015594, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 166, train_loss = 2.5598929920233786, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 167, train_loss = 2.551170621532947, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 168, train_loss = 2.5437076832167804, train_acc = 0.9937121564974383\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 169, train_loss = 2.5350775090046227, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 170, train_loss = 2.52807111479342, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 171, train_loss = 2.5200090794824064, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 172, train_loss = 2.5117105753161013, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 173, train_loss = 2.5029594539664686, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 174, train_loss = 2.49558233236894, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 175, train_loss = 2.488091301638633, train_acc = 0.9940614811364695\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 176, train_loss = 2.4808112387545407, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 177, train_loss = 2.4721352108754218, train_acc = 0.9940614811364695\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 178, train_loss = 2.4651610259898007, train_acc = 0.9940614811364695\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 179, train_loss = 2.4570849831216037, train_acc = 0.9941779226828132\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 180, train_loss = 2.451507138554007, train_acc = 0.9940614811364695\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 181, train_loss = 2.443794267717749, train_acc = 0.9940614811364695\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 182, train_loss = 2.436942519620061, train_acc = 0.9940614811364695\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 183, train_loss = 2.4302175659686327, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 184, train_loss = 2.422089909669012, train_acc = 0.9941779226828132\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 185, train_loss = 2.416804454755038, train_acc = 0.9941779226828132\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 186, train_loss = 2.409404646605253, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 187, train_loss = 2.402992747258395, train_acc = 0.9941779226828132\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 188, train_loss = 2.397038023918867, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 189, train_loss = 2.389930479694158, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 190, train_loss = 2.3831252246163785, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 191, train_loss = 2.3759230277501047, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 192, train_loss = 2.370904511306435, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 193, train_loss = 2.364442631136626, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 194, train_loss = 2.3582953470759094, train_acc = 0.994294364229157\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 195, train_loss = 2.3518471880815923, train_acc = 0.994294364229157\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 196, train_loss = 2.3477708380669355, train_acc = 0.994294364229157\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 197, train_loss = 2.3410683921538293, train_acc = 0.994294364229157\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 198, train_loss = 2.334195399656892, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 199, train_loss = 2.328230831772089, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 200, train_loss = 2.323341302573681, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 201, train_loss = 2.318026375025511, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 202, train_loss = 2.3114225384779274, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 203, train_loss = 2.306086571421474, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 204, train_loss = 2.3005857239477336, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 205, train_loss = 2.2954623461700976, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 206, train_loss = 2.289491528645158, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 207, train_loss = 2.2845809659920633, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 208, train_loss = 2.2793025742284954, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 209, train_loss = 2.272659328300506, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 210, train_loss = 2.268635918851942, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 211, train_loss = 2.264731263741851, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 212, train_loss = 2.2585193277336657, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 213, train_loss = 2.2543877228163183, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 214, train_loss = 2.2482228842563927, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 215, train_loss = 2.2442564591765404, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 216, train_loss = 2.2380064260214567, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 217, train_loss = 2.2343803183175623, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 218, train_loss = 2.2290856656618416, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 219, train_loss = 2.224340342450887, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 220, train_loss = 2.219707299489528, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 221, train_loss = 2.215017484035343, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 222, train_loss = 2.2110256482847035, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 223, train_loss = 2.2059354297816753, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 224, train_loss = 2.20168151659891, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 225, train_loss = 2.1981139867566526, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 226, train_loss = 2.1922038458287716, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 227, train_loss = 2.1890985146164894, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 228, train_loss = 2.1850843485444784, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 229, train_loss = 2.1795407582540065, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 230, train_loss = 2.1756634458433837, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 231, train_loss = 2.1709802616387606, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 232, train_loss = 2.167726404266432, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 233, train_loss = 2.163088632747531, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 234, train_loss = 2.1587121344637126, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 235, train_loss = 2.1543509662151337, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 236, train_loss = 2.1511745725292712, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 237, train_loss = 2.1464745916891843, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 238, train_loss = 2.143022059230134, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 239, train_loss = 2.138850766001269, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 240, train_loss = 2.135146255372092, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 241, train_loss = 2.1315748139750212, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 242, train_loss = 2.127276237355545, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 243, train_loss = 2.1235722929704934, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 244, train_loss = 2.119203592883423, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 245, train_loss = 2.114809289574623, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 246, train_loss = 2.1125626284629107, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 247, train_loss = 2.108425346435979, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 248, train_loss = 2.105267009465024, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 249, train_loss = 2.101106881396845, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 250, train_loss = 2.0983058668207377, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 251, train_loss = 2.094274668721482, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 252, train_loss = 2.0911866172682494, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 253, train_loss = 2.086837097303942, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 254, train_loss = 2.0841105703730136, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 255, train_loss = 2.080775572685525, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 256, train_loss = 2.0775589265394956, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 257, train_loss = 2.0734688583761454, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 258, train_loss = 2.0703779223840684, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 259, train_loss = 2.0675618809182197, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 260, train_loss = 2.063257788075134, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 261, train_loss = 2.060642047552392, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 262, train_loss = 2.0570930030662566, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 263, train_loss = 2.0536102696787566, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 264, train_loss = 2.050661036046222, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 265, train_loss = 2.047832052456215, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 266, train_loss = 2.0446124747395515, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 267, train_loss = 2.0414261564146727, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 268, train_loss = 2.038796113105491, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 269, train_loss = 2.0355241193901747, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 270, train_loss = 2.032315282849595, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 271, train_loss = 2.0294791373889893, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 272, train_loss = 2.0257609207183123, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 273, train_loss = 2.0233544160146266, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 274, train_loss = 2.0199982065241784, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 275, train_loss = 2.0183942038565874, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 276, train_loss = 2.014303496805951, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 277, train_loss = 2.012252228334546, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 278, train_loss = 2.009164597839117, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 279, train_loss = 2.0065357231069356, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 280, train_loss = 2.0036641489714384, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 281, train_loss = 2.0007105153054, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 282, train_loss = 1.998898199526593, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 283, train_loss = 1.9948833927046508, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 284, train_loss = 1.9929095965344459, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 285, train_loss = 1.989854933694005, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 286, train_loss = 1.9876717769075185, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 287, train_loss = 1.9848332509864122, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 288, train_loss = 1.9825382586568594, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 289, train_loss = 1.9793462648522109, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 290, train_loss = 1.9770621124189347, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 291, train_loss = 1.9751014348585159, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 292, train_loss = 1.9712598964106292, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 293, train_loss = 1.9693221796769649, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 294, train_loss = 1.9667704801540822, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 295, train_loss = 1.9643641517031938, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 296, train_loss = 1.9616434660274535, train_acc = 0.9952258965999069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 297, train_loss = 1.9582838658243418, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 298, train_loss = 1.9573856722563505, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 299, train_loss = 1.954295014962554, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 300, train_loss = 1.9525586999952793, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 301, train_loss = 1.949568297015503, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 302, train_loss = 1.9474519200157374, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 303, train_loss = 1.9437498759943992, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 304, train_loss = 1.942150078713894, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 305, train_loss = 1.9401319392491132, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 306, train_loss = 1.9371407225262374, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 307, train_loss = 1.9353508905041963, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 308, train_loss = 1.9326610111165792, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 309, train_loss = 1.9307087429333478, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 310, train_loss = 1.927907156990841, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 311, train_loss = 1.9257977965753525, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 312, train_loss = 1.9240939244627953, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 313, train_loss = 1.9217556733638048, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 314, train_loss = 1.9188847355544567, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 315, train_loss = 1.9170702453702688, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 316, train_loss = 1.9150202851742506, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 317, train_loss = 1.9132835157215595, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 318, train_loss = 1.9106216554064304, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 319, train_loss = 1.9085233646910638, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 320, train_loss = 1.905807801289484, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 321, train_loss = 1.9042409372050315, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 322, train_loss = 1.902374830795452, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 323, train_loss = 1.9003035768400878, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 324, train_loss = 1.8977262750267982, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 325, train_loss = 1.896021093474701, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 326, train_loss = 1.8936797201167792, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 327, train_loss = 1.8921000268310308, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 328, train_loss = 1.8898252814542502, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 329, train_loss = 1.8871443823445588, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 330, train_loss = 1.8859768982511014, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 331, train_loss = 1.8839248183649033, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 332, train_loss = 1.8818588617723435, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 333, train_loss = 1.8798871524631977, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 334, train_loss = 1.8782098933588713, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 335, train_loss = 1.8753535181749612, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 336, train_loss = 1.874152687145397, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 337, train_loss = 1.8722728781867772, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 338, train_loss = 1.870889873476699, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 339, train_loss = 1.867160025285557, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 340, train_loss = 1.8672570772469044, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 341, train_loss = 1.8649095837026834, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 342, train_loss = 1.862311301752925, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 343, train_loss = 1.8615863707382232, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 344, train_loss = 1.858523042872548, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 345, train_loss = 1.8577361560892314, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 346, train_loss = 1.8551731973420829, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 347, train_loss = 1.8537716411519796, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 348, train_loss = 1.8516668137162924, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 349, train_loss = 1.8504747077822685, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 350, train_loss = 1.84874112973921, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 351, train_loss = 1.8474666122347116, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 352, train_loss = 1.8443884688895196, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 353, train_loss = 1.8431894363602623, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 354, train_loss = 1.8405683257151395, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 355, train_loss = 1.8403282215585932, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 356, train_loss = 1.8382523047039285, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 357, train_loss = 1.8358138533076271, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 358, train_loss = 1.8338265648344532, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 359, train_loss = 1.8332411628216505, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 360, train_loss = 1.830761095508933, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 361, train_loss = 1.8296189656248316, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 362, train_loss = 1.827248221845366, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 363, train_loss = 1.8271843896945938, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 364, train_loss = 1.8242552547017112, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 365, train_loss = 1.8232628218829632, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 366, train_loss = 1.821083214133978, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 367, train_loss = 1.820610494702123, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 368, train_loss = 1.8183487616479397, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 369, train_loss = 1.8167471395572647, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 370, train_loss = 1.8143832199275494, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 371, train_loss = 1.8133412320166826, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 372, train_loss = 1.8128005657345057, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 373, train_loss = 1.8101829048246145, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 374, train_loss = 1.809142799465917, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 375, train_loss = 1.807506843120791, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 376, train_loss = 1.8063295608153567, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 377, train_loss = 1.805139372125268, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 378, train_loss = 1.8023297364125028, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 379, train_loss = 1.8019256541738287, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 380, train_loss = 1.8001798372715712, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 381, train_loss = 1.7988555977353826, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 382, train_loss = 1.7967995088547468, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 383, train_loss = 1.7958644926548004, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 384, train_loss = 1.7940049773314968, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 385, train_loss = 1.7922262866050005, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 386, train_loss = 1.791341974050738, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 387, train_loss = 1.790040314779617, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 388, train_loss = 1.788556526764296, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 389, train_loss = 1.7874642027309164, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 390, train_loss = 1.785455639124848, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 391, train_loss = 1.7840359570691362, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 392, train_loss = 1.7841569042066112, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 393, train_loss = 1.780613744049333, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 394, train_loss = 1.7809172620764002, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 395, train_loss = 1.7776928035309538, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 396, train_loss = 1.7778315419564024, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 397, train_loss = 1.7763822072884068, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 398, train_loss = 1.775108634144999, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 399, train_loss = 1.7742101717740297, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 400, train_loss = 1.7728437898913398, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 401, train_loss = 1.770083793089725, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 402, train_loss = 1.7702615708112717, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 403, train_loss = 1.7684343662112951, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 404, train_loss = 1.767620655358769, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 405, train_loss = 1.765762820839882, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 406, train_loss = 1.7637266913661733, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 407, train_loss = 1.7634966932237148, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 408, train_loss = 1.761488634510897, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 409, train_loss = 1.7612012972822413, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 410, train_loss = 1.759157353430055, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 411, train_loss = 1.7585345568368211, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 412, train_loss = 1.7575512336334214, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 413, train_loss = 1.7561512409010902, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 414, train_loss = 1.7544804010540247, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 415, train_loss = 1.7531150188297033, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 416, train_loss = 1.7526618776610121, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 417, train_loss = 1.7507451381534338, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 418, train_loss = 1.7492795698344707, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 419, train_loss = 1.7486413307487965, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 420, train_loss = 1.7475208882242441, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 421, train_loss = 1.7457644207170233, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 422, train_loss = 1.7442295247456059, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 423, train_loss = 1.7440512143075466, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 424, train_loss = 1.7429205408552662, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "8th- epoch: 425, train_loss = 1.7409786010393873, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 426, train_loss = 1.7404728507390246, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 427, train_loss = 1.7389845550060272, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 428, train_loss = 1.7385602028807625, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 429, train_loss = 1.73688686452806, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 430, train_loss = 1.7360828990349546, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "8th- epoch: 431, train_loss = 1.734898574068211, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 432, train_loss = 1.7331120601156726, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 433, train_loss = 1.7320025333901867, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 434, train_loss = 1.7311991788446903, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 435, train_loss = 1.7303033731877804, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 436, train_loss = 1.7284129919717088, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 437, train_loss = 1.7275605108588934, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 438, train_loss = 1.7262579022208229, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 439, train_loss = 1.7258828543126583, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 440, train_loss = 1.7244028808781877, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 441, train_loss = 1.7228033766150475, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 442, train_loss = 1.7227028384804726, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 443, train_loss = 1.7213767804205418, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 444, train_loss = 1.7207816751906648, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 445, train_loss = 1.7197730224579573, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 446, train_loss = 1.7178339045494795, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 447, train_loss = 1.7174648009240627, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 448, train_loss = 1.7153512127697468, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 449, train_loss = 1.7155224749585614, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 450, train_loss = 1.7142446072539315, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 451, train_loss = 1.7126459274441004, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 452, train_loss = 1.7121675051748753, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 453, train_loss = 1.7104446204612032, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 454, train_loss = 1.7097194629022852, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 455, train_loss = 1.7083823457360268, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 456, train_loss = 1.7077158577740192, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 457, train_loss = 1.7070940131088719, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 458, train_loss = 1.7046207363018766, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 459, train_loss = 1.705218780785799, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 460, train_loss = 1.703524699434638, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 461, train_loss = 1.7021404840052128, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 462, train_loss = 1.7021385487169027, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 463, train_loss = 1.7017044300446287, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 464, train_loss = 1.6998904459178448, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 465, train_loss = 1.699164534569718, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 466, train_loss = 1.6978691903641447, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 467, train_loss = 1.6971892783185467, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 468, train_loss = 1.6958660235395655, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 469, train_loss = 1.6951926598558202, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 470, train_loss = 1.6942338602384552, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 471, train_loss = 1.693428361788392, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 472, train_loss = 1.6914837608346716, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 473, train_loss = 1.6920066444436088, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 474, train_loss = 1.689817258506082, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 475, train_loss = 1.6898468093713745, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 476, train_loss = 1.6892107060411945, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 477, train_loss = 1.6869089845567942, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 478, train_loss = 1.6877150455256924, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 479, train_loss = 1.685935360728763, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 480, train_loss = 1.6847642417997122, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 481, train_loss = 1.6838447861373425, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 482, train_loss = 1.682908090413548, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 483, train_loss = 1.6821783197810873, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 484, train_loss = 1.6812530066817999, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 485, train_loss = 1.6808733381330967, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 486, train_loss = 1.6802034123102203, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 487, train_loss = 1.6785667892545462, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 488, train_loss = 1.678178129135631, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 489, train_loss = 1.6769797274610028, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 490, train_loss = 1.6763212227961048, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 491, train_loss = 1.6761553516844288, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 492, train_loss = 1.6749123545596376, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 493, train_loss = 1.6734884766628966, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 494, train_loss = 1.6730679050087929, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 495, train_loss = 1.671322807087563, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 496, train_loss = 1.6705232337117195, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 497, train_loss = 1.6701334360986948, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 498, train_loss = 1.6688323287526146, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 499, train_loss = 1.6690953461220488, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████▉                                                    | 8/30 [1:12:27<3:19:22, 543.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "9th- epoch: 0, train_loss = 119.15285448729992, train_acc = 0.7678155565905915\n",
      "test Acc 0.8649906890130353:\n",
      "9th- epoch: 1, train_loss = 42.46607218682766, train_acc = 0.9104564508616675\n",
      "test Acc 0.9152700186219739:\n",
      "9th- epoch: 2, train_loss = 32.192509576678276, train_acc = 0.9326967862133209\n",
      "test Acc 0.9283054003724395:\n",
      "9th- epoch: 3, train_loss = 27.226513400673866, train_acc = 0.9430600838379134\n",
      "test Acc 0.9357541899441341:\n",
      "9th- epoch: 4, train_loss = 24.028793692588806, train_acc = 0.9494643688868188\n",
      "test Acc 0.9408752327746741:\n",
      "9th- epoch: 5, train_loss = 21.741251714527607, train_acc = 0.9551700046576619\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 6, train_loss = 19.95550499483943, train_acc = 0.9588961341406614\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 7, train_loss = 18.481547724455595, train_acc = 0.9615742897065673\n",
      "test Acc 0.952513966480447:\n",
      "9th- epoch: 8, train_loss = 17.26191769912839, train_acc = 0.9640195621797858\n",
      "test Acc 0.9548417132216015:\n",
      "9th- epoch: 9, train_loss = 16.224170979112387, train_acc = 0.9657661853749417\n",
      "test Acc 0.9562383612662942:\n",
      "9th- epoch: 10, train_loss = 15.34168991446495, train_acc = 0.9675128085700978\n",
      "test Acc 0.9581005586592178:\n",
      "9th- epoch: 11, train_loss = 14.572956535965204, train_acc = 0.9684443409408477\n",
      "test Acc 0.9585661080074488:\n",
      "9th- epoch: 12, train_loss = 13.889190550893545, train_acc = 0.9699580810433163\n",
      "test Acc 0.9594972067039106:\n",
      "9th- epoch: 13, train_loss = 13.28572878986597, train_acc = 0.9710060549604099\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 14, train_loss = 12.739466540515423, train_acc = 0.971821145784816\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 15, train_loss = 12.246286258101463, train_acc = 0.9735677689799721\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 16, train_loss = 11.802394520491362, train_acc = 0.9749650675360969\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 17, train_loss = 11.39313093572855, train_acc = 0.9754308337214718\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 18, train_loss = 11.019428670406342, train_acc = 0.976245924545878\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 19, train_loss = 10.67004731297493, train_acc = 0.9774103400093154\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 20, train_loss = 10.346234070137143, train_acc = 0.9784583139264089\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 21, train_loss = 10.049309257417917, train_acc = 0.9792734047508151\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 22, train_loss = 9.774793528020382, train_acc = 0.9799720540288775\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 23, train_loss = 9.516769107431173, train_acc = 0.9803213786679087\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 24, train_loss = 9.279718767851591, train_acc = 0.9809035863996274\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 25, train_loss = 9.056091286242008, train_acc = 0.9812529110386586\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 26, train_loss = 8.845741571858525, train_acc = 0.981951560316721\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 27, train_loss = 8.64787419885397, train_acc = 0.9824173265020959\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 28, train_loss = 8.459213607013226, train_acc = 0.9828830926874709\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 29, train_loss = 8.280103323981166, train_acc = 0.9835817419655333\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 30, train_loss = 8.109785730019212, train_acc = 0.9838146250582208\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 31, train_loss = 7.946112427860498, train_acc = 0.984163949697252\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 32, train_loss = 7.791270410642028, train_acc = 0.9843968327899395\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 33, train_loss = 7.643136885017157, train_acc = 0.9848625989753144\n",
      "test Acc 0.9702048417132216:\n",
      "9th- epoch: 34, train_loss = 7.502360535785556, train_acc = 0.9848625989753144\n",
      "test Acc 0.9702048417132216:\n",
      "9th- epoch: 35, train_loss = 7.365963641554117, train_acc = 0.9848625989753144\n",
      "test Acc 0.9702048417132216:\n",
      "9th- epoch: 36, train_loss = 7.237325945869088, train_acc = 0.9852119236143456\n",
      "test Acc 0.9702048417132216:\n",
      "9th- epoch: 37, train_loss = 7.114762868732214, train_acc = 0.9856776897997206\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 38, train_loss = 6.992962634190917, train_acc = 0.985910572892408\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 39, train_loss = 6.870896600186825, train_acc = 0.9860270144387517\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 40, train_loss = 6.760187840089202, train_acc = 0.9860270144387517\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 41, train_loss = 6.6553862523287535, train_acc = 0.986376339077783\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 42, train_loss = 6.549727991223335, train_acc = 0.9867256637168141\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 43, train_loss = 6.447043467313051, train_acc = 0.9870749883558454\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 44, train_loss = 6.351485589519143, train_acc = 0.9871914299021891\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 45, train_loss = 6.257726140320301, train_acc = 0.9873078714485328\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 46, train_loss = 6.168608881533146, train_acc = 0.9874243129948765\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 47, train_loss = 6.08105125837028, train_acc = 0.9878900791802515\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 48, train_loss = 5.996908251196146, train_acc = 0.9880065207265952\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 49, train_loss = 5.910705528222024, train_acc = 0.9883558453656265\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 50, train_loss = 5.831924864090979, train_acc = 0.9883558453656265\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 51, train_loss = 5.756724954582751, train_acc = 0.9887051700046576\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 52, train_loss = 5.6788882641121745, train_acc = 0.9889380530973452\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 53, train_loss = 5.607280376367271, train_acc = 0.9891709361900326\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 54, train_loss = 5.532855930738151, train_acc = 0.98940381928272\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 55, train_loss = 5.461685181595385, train_acc = 0.9895202608290639\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 56, train_loss = 5.394901797175407, train_acc = 0.9896367023754076\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 57, train_loss = 5.32992306817323, train_acc = 0.989869585468095\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 58, train_loss = 5.267499356530607, train_acc = 0.9901024685607824\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 59, train_loss = 5.20514393877238, train_acc = 0.9902189101071263\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 60, train_loss = 5.148417399264872, train_acc = 0.99033535165347\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 61, train_loss = 5.089836407452822, train_acc = 0.99033535165347\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 62, train_loss = 5.034109063446522, train_acc = 0.9905682347461574\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 63, train_loss = 4.977932492271066, train_acc = 0.9905682347461574\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 64, train_loss = 4.927596432156861, train_acc = 0.9905682347461574\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 65, train_loss = 4.873588235117495, train_acc = 0.9905682347461574\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 66, train_loss = 4.822617148049176, train_acc = 0.990801117838845\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 67, train_loss = 4.773487510159612, train_acc = 0.9909175593851887\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 68, train_loss = 4.726535465568304, train_acc = 0.990801117838845\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 69, train_loss = 4.679605984129012, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 70, train_loss = 4.63291906286031, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 71, train_loss = 4.5868002055212855, train_acc = 0.9912668840242198\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 72, train_loss = 4.543799601495266, train_acc = 0.9912668840242198\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 73, train_loss = 4.499689415097237, train_acc = 0.9912668840242198\n",
      "test Acc 0.9720670391061452:\n",
      "9th- epoch: 74, train_loss = 4.457654633559287, train_acc = 0.9913833255705635\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 75, train_loss = 4.4151012329384685, train_acc = 0.9914997671169073\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 76, train_loss = 4.374135226942599, train_acc = 0.9916162086632511\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 77, train_loss = 4.334633447229862, train_acc = 0.9916162086632511\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 78, train_loss = 4.296817149035633, train_acc = 0.9916162086632511\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 79, train_loss = 4.258189674466848, train_acc = 0.9916162086632511\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 80, train_loss = 4.2216558856889606, train_acc = 0.9916162086632511\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 81, train_loss = 4.18348691239953, train_acc = 0.9917326502095948\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 82, train_loss = 4.1479160990566015, train_acc = 0.9918490917559385\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 83, train_loss = 4.114091455936432, train_acc = 0.9919655333022822\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 84, train_loss = 4.080050912685692, train_acc = 0.992081974848626\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 85, train_loss = 4.047943121753633, train_acc = 0.992081974848626\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 86, train_loss = 4.013511141762137, train_acc = 0.9921984163949698\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 87, train_loss = 3.981441960670054, train_acc = 0.9924312994876572\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 88, train_loss = 3.9509273702278733, train_acc = 0.9924312994876572\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 89, train_loss = 3.9198022596538067, train_acc = 0.9925477410340009\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 90, train_loss = 3.890053568407893, train_acc = 0.9925477410340009\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 91, train_loss = 3.8595763919875026, train_acc = 0.9925477410340009\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 92, train_loss = 3.830871833488345, train_acc = 0.9925477410340009\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 93, train_loss = 3.8028866397216916, train_acc = 0.9926641825803446\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 94, train_loss = 3.7742355950176716, train_acc = 0.9926641825803446\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 95, train_loss = 3.7456407379359007, train_acc = 0.9926641825803446\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 96, train_loss = 3.717464621178806, train_acc = 0.9926641825803446\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 97, train_loss = 3.692753945477307, train_acc = 0.9925477410340009\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 98, train_loss = 3.6670377841219306, train_acc = 0.9925477410340009\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 99, train_loss = 3.6378284310922027, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 100, train_loss = 3.611531206406653, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 101, train_loss = 3.5871460386551917, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 102, train_loss = 3.5644228574819863, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 103, train_loss = 3.540443643927574, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 104, train_loss = 3.5177677967585623, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 105, train_loss = 3.4943540222011507, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 106, train_loss = 3.4724847585894167, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 107, train_loss = 3.4511587801389396, train_acc = 0.9930135072193759\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 108, train_loss = 3.4275867734104395, train_acc = 0.9930135072193759\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 109, train_loss = 3.4067760668694973, train_acc = 0.9930135072193759\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 110, train_loss = 3.3867079936899245, train_acc = 0.9930135072193759\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 111, train_loss = 3.3671643142588437, train_acc = 0.9931299487657196\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 112, train_loss = 3.3456104383803904, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 113, train_loss = 3.327217960730195, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 114, train_loss = 3.306443580891937, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 115, train_loss = 3.287749372422695, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 116, train_loss = 3.2687327316962183, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 117, train_loss = 3.25107930181548, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 118, train_loss = 3.2332000941969454, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 119, train_loss = 3.2140212287195027, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 120, train_loss = 3.197629255708307, train_acc = 0.9934792734047508\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 121, train_loss = 3.1804767209105194, train_acc = 0.9935957149510946\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 122, train_loss = 3.1630669967271388, train_acc = 0.9935957149510946\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 123, train_loss = 3.14627157850191, train_acc = 0.9935957149510946\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 124, train_loss = 3.1288055782206357, train_acc = 0.9935957149510946\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 125, train_loss = 3.113639411982149, train_acc = 0.9935957149510946\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 126, train_loss = 3.0970673779956996, train_acc = 0.9935957149510946\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 127, train_loss = 3.0801066756248474, train_acc = 0.9935957149510946\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 128, train_loss = 3.06622137920931, train_acc = 0.9935957149510946\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 129, train_loss = 3.050152859184891, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 130, train_loss = 3.035657934844494, train_acc = 0.9935957149510946\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 131, train_loss = 3.0199957727454603, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 132, train_loss = 3.0068628191947937, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 133, train_loss = 2.9917196347378194, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 134, train_loss = 2.9774603620171547, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 135, train_loss = 2.963179456535727, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 136, train_loss = 2.949374083429575, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 137, train_loss = 2.936429336667061, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 138, train_loss = 2.9233932266943157, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 139, train_loss = 2.908915333915502, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 140, train_loss = 2.897881615906954, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 141, train_loss = 2.8834780994802713, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 142, train_loss = 2.873346174135804, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 143, train_loss = 2.8584911334328353, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 144, train_loss = 2.8471173625439405, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 145, train_loss = 2.8346020155586302, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 146, train_loss = 2.8228239249438047, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 147, train_loss = 2.810593380127102, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 148, train_loss = 2.79950083559379, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 149, train_loss = 2.787711217533797, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 150, train_loss = 2.7764270063489676, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 151, train_loss = 2.7634201725013554, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 152, train_loss = 2.752212563995272, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 153, train_loss = 2.7435455680824816, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 154, train_loss = 2.7314841193147004, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 155, train_loss = 2.7223116834647954, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 156, train_loss = 2.710284462198615, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 157, train_loss = 2.700510532129556, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 158, train_loss = 2.6901688002981246, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 159, train_loss = 2.679596208501607, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 160, train_loss = 2.6702797706238925, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 161, train_loss = 2.6592902527190745, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 162, train_loss = 2.6486818031407893, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 163, train_loss = 2.641953670885414, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 164, train_loss = 2.6311950217932463, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 165, train_loss = 2.6221933499909937, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 166, train_loss = 2.6118233930319548, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 167, train_loss = 2.6033851243555546, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 168, train_loss = 2.593959190417081, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 169, train_loss = 2.5861891824752092, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 170, train_loss = 2.57525318255648, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 171, train_loss = 2.5671555413864553, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 172, train_loss = 2.5574360326863825, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 173, train_loss = 2.5495664458721876, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 174, train_loss = 2.5412553045898676, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 175, train_loss = 2.5321957203559577, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 176, train_loss = 2.524579407181591, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 177, train_loss = 2.5150586403906345, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 178, train_loss = 2.5073500969447196, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 179, train_loss = 2.500173394102603, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 180, train_loss = 2.491859069559723, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 181, train_loss = 2.483781933784485, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 182, train_loss = 2.476088935509324, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 183, train_loss = 2.4685079311020672, train_acc = 0.9941779226828132\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 184, train_loss = 2.460929262917489, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 185, train_loss = 2.4536133762449026, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 186, train_loss = 2.4456298742443323, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 187, train_loss = 2.4387575746513903, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 188, train_loss = 2.4304459542036057, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 189, train_loss = 2.4248299920000136, train_acc = 0.9941779226828132\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 190, train_loss = 2.4178799595683813, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 191, train_loss = 2.410397721454501, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 192, train_loss = 2.402809624094516, train_acc = 0.9941779226828132\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 193, train_loss = 2.395807972177863, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 194, train_loss = 2.3880793494172394, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 195, train_loss = 2.38261025166139, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 196, train_loss = 2.3751582633703947, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 197, train_loss = 2.3684590705670416, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 198, train_loss = 2.36337636038661, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 199, train_loss = 2.3552376166917384, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 200, train_loss = 2.3506841473281384, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 201, train_loss = 2.342735556419939, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 202, train_loss = 2.3362622731365263, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 203, train_loss = 2.3309474759735167, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 204, train_loss = 2.32477625599131, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 205, train_loss = 2.3180448287166655, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 206, train_loss = 2.311253795865923, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 207, train_loss = 2.305402832571417, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 208, train_loss = 2.300963851157576, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 209, train_loss = 2.29325849423185, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 210, train_loss = 2.287358076777309, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 211, train_loss = 2.2834556088782847, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 212, train_loss = 2.2760170907713473, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 213, train_loss = 2.271171769592911, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 214, train_loss = 2.2659279331564903, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 215, train_loss = 2.2604435309767723, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 216, train_loss = 2.252540521323681, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 217, train_loss = 2.248985882848501, train_acc = 0.9947601304145319\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 218, train_loss = 2.244720086455345, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 219, train_loss = 2.2374392300844193, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 220, train_loss = 2.2321935307700187, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 221, train_loss = 2.228392381221056, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 222, train_loss = 2.2233149122912437, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 223, train_loss = 2.2171415525954217, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 224, train_loss = 2.2129990954417735, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 225, train_loss = 2.2063938851933926, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 226, train_loss = 2.202496989397332, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 227, train_loss = 2.1969277672469616, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 228, train_loss = 2.1936170160770416, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 229, train_loss = 2.187902079196647, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 230, train_loss = 2.1833932027220726, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 231, train_loss = 2.1777701564133167, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 232, train_loss = 2.1734555065631866, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 233, train_loss = 2.1699435759801418, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 234, train_loss = 2.1648888241034, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 235, train_loss = 2.160967839183286, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 236, train_loss = 2.1562592312693596, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 237, train_loss = 2.150959289399907, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 238, train_loss = 2.1471578900236636, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 239, train_loss = 2.1432610664051026, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 240, train_loss = 2.1383118752855808, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 241, train_loss = 2.1348459385335445, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 242, train_loss = 2.1294855859596282, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 243, train_loss = 2.125152022810653, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 244, train_loss = 2.121781751513481, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 245, train_loss = 2.1163915668148547, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 246, train_loss = 2.11425498011522, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 247, train_loss = 2.1096801597159356, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 248, train_loss = 2.1052608389873058, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 249, train_loss = 2.1007501769345254, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 250, train_loss = 2.0973810118157417, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 251, train_loss = 2.0939077374059707, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 252, train_loss = 2.0899603366851807, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 253, train_loss = 2.0872571107465774, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 254, train_loss = 2.0823828901629895, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 255, train_loss = 2.079197047976777, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 256, train_loss = 2.0758126948494464, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 257, train_loss = 2.0712573528289795, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 258, train_loss = 2.067274923203513, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 259, train_loss = 2.06360837072134, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 260, train_loss = 2.0608640648424625, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 261, train_loss = 2.0573779109399766, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 262, train_loss = 2.0529130187351257, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 263, train_loss = 2.050325670512393, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 264, train_loss = 2.046944656642154, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 265, train_loss = 2.042916115373373, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 266, train_loss = 2.0409858748316765, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 267, train_loss = 2.0359502236824483, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 268, train_loss = 2.0334462772589177, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 269, train_loss = 2.029741008998826, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 270, train_loss = 2.026617740513757, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 271, train_loss = 2.0225594614166766, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 272, train_loss = 2.0199142571073025, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 273, train_loss = 2.0163987155538052, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 274, train_loss = 2.01450131717138, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 275, train_loss = 2.0098672434687614, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 276, train_loss = 2.005865141749382, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 277, train_loss = 2.003941011847928, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 278, train_loss = 1.9995108246803284, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 279, train_loss = 1.997513497946784, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 280, train_loss = 1.994298741221428, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 281, train_loss = 1.9912642985582352, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 282, train_loss = 1.9893077909946442, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 283, train_loss = 1.984952438622713, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 284, train_loss = 1.9839141133707017, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 285, train_loss = 1.9799443173687905, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 286, train_loss = 1.976636302890256, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 287, train_loss = 1.9743470984976739, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 288, train_loss = 1.9712714303750545, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 289, train_loss = 1.9679390490055084, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 290, train_loss = 1.9654642529785633, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 291, train_loss = 1.9629745173733681, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 292, train_loss = 1.9611266006249934, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 293, train_loss = 1.9575965020339936, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 294, train_loss = 1.9542195845860988, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 295, train_loss = 1.9516914647538215, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 296, train_loss = 1.9497477114200592, train_acc = 0.9954587796925943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 297, train_loss = 1.9467100538313389, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 298, train_loss = 1.9442940999288112, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 299, train_loss = 1.9417319509666413, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 300, train_loss = 1.9385693781077862, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 301, train_loss = 1.9365805871784687, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 302, train_loss = 1.9334032621700317, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 303, train_loss = 1.9313926063477993, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 304, train_loss = 1.9285337675828487, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 305, train_loss = 1.9265826232731342, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 306, train_loss = 1.9236519138794392, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 307, train_loss = 1.9216129046399146, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 308, train_loss = 1.9191410392522812, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 309, train_loss = 1.9162623372394592, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 310, train_loss = 1.9146615092176944, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 311, train_loss = 1.9111846562009305, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 312, train_loss = 1.9095803189557046, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 313, train_loss = 1.9063197982031852, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 314, train_loss = 1.905041703255847, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 315, train_loss = 1.9026659552473575, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 316, train_loss = 1.8998888991773129, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 317, train_loss = 1.8972443577367812, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 318, train_loss = 1.8958026990294456, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 319, train_loss = 1.8933829490561038, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 320, train_loss = 1.8912802513223141, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 321, train_loss = 1.8890058670658618, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 322, train_loss = 1.8862335905432701, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 323, train_loss = 1.88489984232001, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 324, train_loss = 1.8826533507090062, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 325, train_loss = 1.8795110050123185, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 326, train_loss = 1.8787914167623967, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 327, train_loss = 1.8754795764107257, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 328, train_loss = 1.8737032997887582, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 329, train_loss = 1.8712615903932601, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 330, train_loss = 1.86960627627559, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 331, train_loss = 1.8681809566915035, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 332, train_loss = 1.865736858220771, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 333, train_loss = 1.8629860307555646, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 334, train_loss = 1.8613560397643596, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 335, train_loss = 1.8589690141379833, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 336, train_loss = 1.8572031494695693, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 337, train_loss = 1.8558531005401164, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 338, train_loss = 1.8535820010583848, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 339, train_loss = 1.8515423648059368, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 340, train_loss = 1.8498523894231766, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 341, train_loss = 1.8471811811905354, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 342, train_loss = 1.8468876618426293, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 343, train_loss = 1.8434752586763352, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 344, train_loss = 1.841446575941518, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 345, train_loss = 1.8404167976696044, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 346, train_loss = 1.8377055923920125, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 347, train_loss = 1.836559371324256, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 348, train_loss = 1.8348316985648125, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 349, train_loss = 1.8322351910173893, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 350, train_loss = 1.8314055588562042, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 351, train_loss = 1.8281384992878884, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 352, train_loss = 1.827895700931549, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 353, train_loss = 1.824834727915004, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 354, train_loss = 1.8235769756138325, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 355, train_loss = 1.822353197960183, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 356, train_loss = 1.8198385995347053, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 357, train_loss = 1.8184162240941077, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 358, train_loss = 1.8156843297183514, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 359, train_loss = 1.8149663880467415, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 360, train_loss = 1.8133322645444423, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 361, train_loss = 1.8119878433644772, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 362, train_loss = 1.810032044770196, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 363, train_loss = 1.8082445412874222, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 364, train_loss = 1.8065263617318124, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 365, train_loss = 1.8056874225148931, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 366, train_loss = 1.8030902806203812, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 367, train_loss = 1.8012556122848764, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 368, train_loss = 1.7997226988663897, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 369, train_loss = 1.7984777229139581, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 370, train_loss = 1.7961772183189169, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 371, train_loss = 1.7945120508084074, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 372, train_loss = 1.7936546864220873, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 373, train_loss = 1.7921304194023833, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 374, train_loss = 1.78908621519804, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 375, train_loss = 1.7896423116326332, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 376, train_loss = 1.787487454712391, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 377, train_loss = 1.7848513635108247, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 378, train_loss = 1.7847199601819739, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 379, train_loss = 1.7826556178042665, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 380, train_loss = 1.7804692201316357, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 381, train_loss = 1.7790570942452177, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 382, train_loss = 1.7778692556312308, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 383, train_loss = 1.7759879777440801, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 384, train_loss = 1.7763101434102282, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 385, train_loss = 1.772791564464569, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 386, train_loss = 1.7725258941063657, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 387, train_loss = 1.7703050164273009, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 388, train_loss = 1.7694409725954756, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 389, train_loss = 1.7677474692463875, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 390, train_loss = 1.7657350488007069, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 391, train_loss = 1.7648880990454927, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 392, train_loss = 1.763191425590776, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 393, train_loss = 1.7627767598023638, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 394, train_loss = 1.7608542703092098, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 395, train_loss = 1.7606330128619447, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 396, train_loss = 1.7571307718753815, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 397, train_loss = 1.7566533772042021, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 398, train_loss = 1.754910366027616, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 399, train_loss = 1.7531925340881571, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 400, train_loss = 1.752980167628266, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 401, train_loss = 1.7519390980014578, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 402, train_loss = 1.7493115700781345, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 403, train_loss = 1.7489808624377474, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 404, train_loss = 1.747793753980659, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 405, train_loss = 1.7466047754278407, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 406, train_loss = 1.7455272661754861, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 407, train_loss = 1.7427341440925375, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 408, train_loss = 1.7429777855286375, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 409, train_loss = 1.74038789793849, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 410, train_loss = 1.7396427044877782, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 411, train_loss = 1.7384608313441277, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 412, train_loss = 1.7376078218221664, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 413, train_loss = 1.734913270920515, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 414, train_loss = 1.7360077997436747, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 415, train_loss = 1.732334554195404, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 416, train_loss = 1.7322539115557447, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 417, train_loss = 1.7311730036744848, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 418, train_loss = 1.7295613636961207, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 419, train_loss = 1.7282312350580469, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 420, train_loss = 1.7272483905544505, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 421, train_loss = 1.7269054452190176, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 422, train_loss = 1.7240282371640205, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 423, train_loss = 1.724675721139647, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 424, train_loss = 1.7225733572850004, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 425, train_loss = 1.719920908450149, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 426, train_loss = 1.7215836296090856, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 427, train_loss = 1.7185476633021608, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 428, train_loss = 1.7178431563079357, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 429, train_loss = 1.7156492186477408, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 430, train_loss = 1.715742244035937, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 431, train_loss = 1.7141788912704214, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 432, train_loss = 1.713597317575477, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 433, train_loss = 1.7124455583980307, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 434, train_loss = 1.7110825726995245, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 435, train_loss = 1.7099021995672956, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 436, train_loss = 1.709257489652373, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 437, train_loss = 1.7072077840566635, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 438, train_loss = 1.706279557198286, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 439, train_loss = 1.7048349007964134, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 440, train_loss = 1.7037246687104926, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 441, train_loss = 1.7031511379173025, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 442, train_loss = 1.702569073648192, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 443, train_loss = 1.7010496718576178, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 444, train_loss = 1.7011771015822887, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 445, train_loss = 1.6992300922283903, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 446, train_loss = 1.6992808716604486, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 447, train_loss = 1.6982489041984081, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 448, train_loss = 1.695382572710514, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 449, train_loss = 1.6950025794794783, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 450, train_loss = 1.6940661879489198, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 451, train_loss = 1.6934296352555975, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 452, train_loss = 1.6921587524702772, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 453, train_loss = 1.6905798179795966, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 454, train_loss = 1.6885807266226038, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 455, train_loss = 1.6892452202737331, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 456, train_loss = 1.6873991762986407, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 457, train_loss = 1.685998002649285, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 458, train_loss = 1.6860883285989985, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 459, train_loss = 1.6843149637570605, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 460, train_loss = 1.6836696142563596, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 461, train_loss = 1.6844024310121313, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 462, train_loss = 1.6811036268481985, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 463, train_loss = 1.6804053956875578, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 464, train_loss = 1.6799876788863912, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 465, train_loss = 1.6788596399128437, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 466, train_loss = 1.6781534416368231, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 467, train_loss = 1.6767485700547695, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 468, train_loss = 1.6762202667305246, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 469, train_loss = 1.674296552897431, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 470, train_loss = 1.6742734499275684, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 471, train_loss = 1.6732548897853121, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 472, train_loss = 1.6723836163291708, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 473, train_loss = 1.6709408959141, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 474, train_loss = 1.670923656434752, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 475, train_loss = 1.669477492570877, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 476, train_loss = 1.6688732877373695, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 477, train_loss = 1.6682387217879295, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 478, train_loss = 1.6668604736914858, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 479, train_loss = 1.6665931144962087, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 480, train_loss = 1.6652687713503838, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 481, train_loss = 1.6645123461494222, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 482, train_loss = 1.6634802892804146, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 483, train_loss = 1.6626860523829237, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 484, train_loss = 1.661483097821474, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 485, train_loss = 1.6608744213590398, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 486, train_loss = 1.6608812361955643, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 487, train_loss = 1.6585702871670946, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 488, train_loss = 1.6574979113647714, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 489, train_loss = 1.6576637191465124, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 490, train_loss = 1.655468383221887, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 491, train_loss = 1.6564211025834084, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 492, train_loss = 1.654978452832438, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 493, train_loss = 1.654335055500269, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 494, train_loss = 1.6528066830942407, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 495, train_loss = 1.6526159308850765, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 496, train_loss = 1.6512747345259413, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 497, train_loss = 1.6508998721837997, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 498, train_loss = 1.6493142483523116, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 499, train_loss = 1.648888165713288, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████████████▎                                                 | 9/30 [1:21:32<3:10:27, 544.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "10th- epoch: 0, train_loss = 115.89155440032482, train_acc = 0.7826036329762459\n",
      "test Acc 0.888268156424581:\n",
      "10th- epoch: 1, train_loss = 42.09839668869972, train_acc = 0.9156963204471356\n",
      "test Acc 0.9269087523277467:\n",
      "10th- epoch: 2, train_loss = 31.975367955863476, train_acc = 0.933977643223102\n",
      "test Acc 0.9371508379888268:\n",
      "10th- epoch: 3, train_loss = 26.802278637886047, train_acc = 0.9442244993013508\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 4, train_loss = 23.47108968347311, train_acc = 0.9517931998136935\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 5, train_loss = 21.116410303860903, train_acc = 0.9558686539357243\n",
      "test Acc 0.9511173184357542:\n",
      "10th- epoch: 6, train_loss = 19.317730005830526, train_acc = 0.9605263157894737\n",
      "test Acc 0.952513966480447:\n",
      "10th- epoch: 7, train_loss = 17.894478492438793, train_acc = 0.963903120633442\n",
      "test Acc 0.9567039106145251:\n",
      "10th- epoch: 8, train_loss = 16.72328521311283, train_acc = 0.965649743828598\n",
      "test Acc 0.957169459962756:\n",
      "10th- epoch: 9, train_loss = 15.715292133390903, train_acc = 0.9670470423847228\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 10, train_loss = 14.85712095350027, train_acc = 0.9691429902189101\n",
      "test Acc 0.9608938547486033:\n",
      "10th- epoch: 11, train_loss = 14.102892231196165, train_acc = 0.97007452258966\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 12, train_loss = 13.432953763753176, train_acc = 0.9710060549604099\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 13, train_loss = 12.836178742349148, train_acc = 0.9720540288775035\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 14, train_loss = 12.287448525428772, train_acc = 0.9731020027945971\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 15, train_loss = 11.796089127659798, train_acc = 0.9744993013507219\n",
      "test Acc 0.9641527001862198:\n",
      "10th- epoch: 16, train_loss = 11.34463476203382, train_acc = 0.9756637168141593\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 17, train_loss = 10.933674272149801, train_acc = 0.9767116907312529\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 18, train_loss = 10.558028498664498, train_acc = 0.977992547741034\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 19, train_loss = 10.217628426849842, train_acc = 0.9783418723800652\n",
      "test Acc 0.9664804469273743:\n",
      "10th- epoch: 20, train_loss = 9.908607183024287, train_acc = 0.9786911970190965\n",
      "test Acc 0.9664804469273743:\n",
      "10th- epoch: 21, train_loss = 9.62031476199627, train_acc = 0.9798556124825337\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 22, train_loss = 9.353532256558537, train_acc = 0.9804378202142524\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 23, train_loss = 9.10244389437139, train_acc = 0.9810200279459711\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 24, train_loss = 8.867520980536938, train_acc = 0.9813693525850024\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 25, train_loss = 8.64686094224453, train_acc = 0.9818351187703773\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 26, train_loss = 8.436440996825695, train_acc = 0.9821844434094085\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 27, train_loss = 8.240326426923275, train_acc = 0.9824173265020959\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 28, train_loss = 8.050758372992277, train_acc = 0.9832324173265021\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 29, train_loss = 7.876367960125208, train_acc = 0.9838146250582208\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 30, train_loss = 7.706937529146671, train_acc = 0.984163949697252\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 31, train_loss = 7.54463960044086, train_acc = 0.9846297158826269\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 32, train_loss = 7.3913687113672495, train_acc = 0.9852119236143456\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 33, train_loss = 7.248920986428857, train_acc = 0.985444806707033\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 34, train_loss = 7.1132809817790985, train_acc = 0.9857941313460643\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 35, train_loss = 6.98354166932404, train_acc = 0.9860270144387517\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 36, train_loss = 6.860820511355996, train_acc = 0.9861434559850955\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 37, train_loss = 6.740476869046688, train_acc = 0.9861434559850955\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 38, train_loss = 6.627596499398351, train_acc = 0.9864927806241267\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 39, train_loss = 6.520030539482832, train_acc = 0.9867256637168141\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 40, train_loss = 6.414459653198719, train_acc = 0.9868421052631579\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 41, train_loss = 6.3151791151613, train_acc = 0.9874243129948765\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 42, train_loss = 6.21748355589807, train_acc = 0.9877736376339078\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 43, train_loss = 6.123965315520763, train_acc = 0.9876571960875641\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 44, train_loss = 6.032414896413684, train_acc = 0.9877736376339078\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 45, train_loss = 5.945892253890634, train_acc = 0.9878900791802515\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 46, train_loss = 5.862216802313924, train_acc = 0.9880065207265952\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 47, train_loss = 5.781409529969096, train_acc = 0.9880065207265952\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 48, train_loss = 5.699625266715884, train_acc = 0.9880065207265952\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 49, train_loss = 5.623193967156112, train_acc = 0.9884722869119702\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 50, train_loss = 5.5501698376610875, train_acc = 0.9884722869119702\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 51, train_loss = 5.476940660737455, train_acc = 0.9888216115510013\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 52, train_loss = 5.406033971346915, train_acc = 0.9888216115510013\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 53, train_loss = 5.338679504580796, train_acc = 0.9888216115510013\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 54, train_loss = 5.271991167217493, train_acc = 0.9889380530973452\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 55, train_loss = 5.206600834615529, train_acc = 0.9891709361900326\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 56, train_loss = 5.145192316733301, train_acc = 0.98940381928272\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 57, train_loss = 5.083561294712126, train_acc = 0.9892873777363763\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 58, train_loss = 5.026026771403849, train_acc = 0.9899860270144387\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 59, train_loss = 4.9681555880233645, train_acc = 0.9902189101071263\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 60, train_loss = 4.913977771997452, train_acc = 0.9904517931998137\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 61, train_loss = 4.85882739815861, train_acc = 0.9906846762925011\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 62, train_loss = 4.806308853439987, train_acc = 0.9905682347461574\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 63, train_loss = 4.756005618721247, train_acc = 0.9906846762925011\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 64, train_loss = 4.704033167101443, train_acc = 0.9906846762925011\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 65, train_loss = 4.6561858700588346, train_acc = 0.9910340009315324\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 66, train_loss = 4.608161977492273, train_acc = 0.9910340009315324\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 67, train_loss = 4.5622371872887015, train_acc = 0.9911504424778761\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 68, train_loss = 4.5153872380033135, train_acc = 0.9911504424778761\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 69, train_loss = 4.473809410817921, train_acc = 0.9910340009315324\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 70, train_loss = 4.428914804011583, train_acc = 0.9912668840242198\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 71, train_loss = 4.387900562025607, train_acc = 0.9913833255705635\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 72, train_loss = 4.34788129851222, train_acc = 0.9913833255705635\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 73, train_loss = 4.307679397054017, train_acc = 0.9914997671169073\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 74, train_loss = 4.2663708524778485, train_acc = 0.9917326502095948\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 75, train_loss = 4.230041194707155, train_acc = 0.9918490917559385\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 76, train_loss = 4.191421241499484, train_acc = 0.9918490917559385\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 77, train_loss = 4.15589523781091, train_acc = 0.9918490917559385\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 78, train_loss = 4.119086686521769, train_acc = 0.9919655333022822\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 79, train_loss = 4.083725837059319, train_acc = 0.9919655333022822\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 80, train_loss = 4.048352885991335, train_acc = 0.9921984163949698\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 81, train_loss = 4.015414461493492, train_acc = 0.9923148579413135\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 82, train_loss = 3.9821979077532887, train_acc = 0.9923148579413135\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 83, train_loss = 3.948397303931415, train_acc = 0.9923148579413135\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 84, train_loss = 3.9171210834756494, train_acc = 0.9923148579413135\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 85, train_loss = 3.885191851295531, train_acc = 0.9923148579413135\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 86, train_loss = 3.8537111142650247, train_acc = 0.9923148579413135\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 87, train_loss = 3.8234390318393707, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 88, train_loss = 3.7929726941511035, train_acc = 0.9924312994876572\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 89, train_loss = 3.764181051403284, train_acc = 0.9924312994876572\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 90, train_loss = 3.736578577198088, train_acc = 0.9924312994876572\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 91, train_loss = 3.7080671889707446, train_acc = 0.9925477410340009\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 92, train_loss = 3.6796565325930715, train_acc = 0.9925477410340009\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 93, train_loss = 3.6516789607703686, train_acc = 0.9925477410340009\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 94, train_loss = 3.626536359079182, train_acc = 0.9926641825803446\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 95, train_loss = 3.600020513869822, train_acc = 0.9926641825803446\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 96, train_loss = 3.575537416152656, train_acc = 0.9925477410340009\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 97, train_loss = 3.5508509101346135, train_acc = 0.9925477410340009\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 98, train_loss = 3.525141485966742, train_acc = 0.9927806241266884\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 99, train_loss = 3.501025377307087, train_acc = 0.9927806241266884\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 100, train_loss = 3.4763478585518897, train_acc = 0.9926641825803446\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 101, train_loss = 3.454797549638897, train_acc = 0.9926641825803446\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 102, train_loss = 3.4314617016352713, train_acc = 0.9926641825803446\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 103, train_loss = 3.408833220601082, train_acc = 0.9927806241266884\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 104, train_loss = 3.389189453329891, train_acc = 0.9927806241266884\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 105, train_loss = 3.365727912634611, train_acc = 0.9927806241266884\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 106, train_loss = 3.3434160612523556, train_acc = 0.9927806241266884\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 107, train_loss = 3.323921417351812, train_acc = 0.9927806241266884\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 108, train_loss = 3.3046206035651267, train_acc = 0.9927806241266884\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 109, train_loss = 3.282512976322323, train_acc = 0.9927806241266884\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 110, train_loss = 3.264133419841528, train_acc = 0.9928970656730322\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 111, train_loss = 3.2456420711241663, train_acc = 0.9928970656730322\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 112, train_loss = 3.2246763347648084, train_acc = 0.9928970656730322\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 113, train_loss = 3.2071103639900684, train_acc = 0.9928970656730322\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 114, train_loss = 3.1874369122087955, train_acc = 0.9930135072193759\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 115, train_loss = 3.1692250058986247, train_acc = 0.9930135072193759\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 116, train_loss = 3.153005259577185, train_acc = 0.9930135072193759\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 117, train_loss = 3.1352003253996372, train_acc = 0.9931299487657196\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 118, train_loss = 3.1162988520227373, train_acc = 0.9932463903120633\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 119, train_loss = 3.1004714742302895, train_acc = 0.9932463903120633\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 120, train_loss = 3.083621261175722, train_acc = 0.9932463903120633\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 121, train_loss = 3.068179259542376, train_acc = 0.9932463903120633\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 122, train_loss = 3.0509959682822227, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 123, train_loss = 3.035807766020298, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 124, train_loss = 3.0192303606308997, train_acc = 0.9933628318584071\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 125, train_loss = 3.00477130478248, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 126, train_loss = 2.988938818220049, train_acc = 0.9933628318584071\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 127, train_loss = 2.9741270816884935, train_acc = 0.9933628318584071\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 128, train_loss = 2.9605841948650777, train_acc = 0.9933628318584071\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 129, train_loss = 2.945661300327629, train_acc = 0.9933628318584071\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 130, train_loss = 2.9316353388130665, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 131, train_loss = 2.9174145027063787, train_acc = 0.9934792734047508\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 132, train_loss = 2.901720456779003, train_acc = 0.9934792734047508\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 133, train_loss = 2.888532185461372, train_acc = 0.9934792734047508\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 134, train_loss = 2.8764028125442564, train_acc = 0.9934792734047508\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 135, train_loss = 2.8620643368922174, train_acc = 0.9934792734047508\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 136, train_loss = 2.850009480956942, train_acc = 0.9934792734047508\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 137, train_loss = 2.8388361199758947, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 138, train_loss = 2.823546311352402, train_acc = 0.9937121564974383\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 139, train_loss = 2.8112893938086927, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 140, train_loss = 2.800136288162321, train_acc = 0.9937121564974383\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 141, train_loss = 2.7867102534510195, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 142, train_loss = 2.776003530714661, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 143, train_loss = 2.7630440182983875, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 144, train_loss = 2.7522649690508842, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 145, train_loss = 2.7396786459721625, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 146, train_loss = 2.7304573878645897, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 147, train_loss = 2.7177151441574097, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 148, train_loss = 2.7071384005248547, train_acc = 0.9937121564974383\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 149, train_loss = 2.6974664381705225, train_acc = 0.9937121564974383\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 150, train_loss = 2.686088731046766, train_acc = 0.9937121564974383\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 151, train_loss = 2.676719143986702, train_acc = 0.9937121564974383\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 152, train_loss = 2.665029080118984, train_acc = 0.9937121564974383\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 153, train_loss = 2.654880865011364, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 154, train_loss = 2.643146345857531, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 155, train_loss = 2.634056454990059, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 156, train_loss = 2.624233284499496, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 157, train_loss = 2.615219628904015, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 158, train_loss = 2.604766098316759, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 159, train_loss = 2.595046818256378, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 160, train_loss = 2.5866365022957325, train_acc = 0.9940614811364695\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 161, train_loss = 2.5774090425111353, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 162, train_loss = 2.567890825215727, train_acc = 0.994294364229157\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 163, train_loss = 2.5585569799877703, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 164, train_loss = 2.550681073218584, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 165, train_loss = 2.541691855993122, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 166, train_loss = 2.531955400016159, train_acc = 0.9940614811364695\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 167, train_loss = 2.5240572006441653, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 168, train_loss = 2.5144201233051717, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 169, train_loss = 2.5071099190972745, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 170, train_loss = 2.497769641224295, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 171, train_loss = 2.4904476664960384, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 172, train_loss = 2.482334739062935, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 173, train_loss = 2.473284692969173, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 174, train_loss = 2.4657302512787282, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 175, train_loss = 2.457833979278803, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 176, train_loss = 2.4509196118451655, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 177, train_loss = 2.442963305860758, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 178, train_loss = 2.4345748126506805, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 179, train_loss = 2.4272947188001126, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 180, train_loss = 2.420349603984505, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 181, train_loss = 2.4138444154523313, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 182, train_loss = 2.405901452060789, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 183, train_loss = 2.3985678430180997, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 184, train_loss = 2.3916090030688792, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 185, train_loss = 2.3848112151026726, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 186, train_loss = 2.377990857930854, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 187, train_loss = 2.3716214920859784, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 188, train_loss = 2.3651839692611247, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 189, train_loss = 2.3584423910360783, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 190, train_loss = 2.3519033927004784, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 191, train_loss = 2.344011704204604, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 192, train_loss = 2.338641518028453, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 193, train_loss = 2.3326137189287692, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 194, train_loss = 2.3254434019327164, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 195, train_loss = 2.319502190919593, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 196, train_loss = 2.313860709546134, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 197, train_loss = 2.3082080755848438, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 198, train_loss = 2.301789415301755, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 199, train_loss = 2.297425067750737, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 200, train_loss = 2.290986778913066, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 201, train_loss = 2.283708757488057, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 202, train_loss = 2.278970367042348, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 203, train_loss = 2.2735234338324517, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 204, train_loss = 2.267413320718333, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 205, train_loss = 2.2622740156948566, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 206, train_loss = 2.255831804126501, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 207, train_loss = 2.2501928459387273, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 208, train_loss = 2.2450071088969707, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 209, train_loss = 2.2418420638423413, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 210, train_loss = 2.234856503782794, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 211, train_loss = 2.2292685620486736, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 212, train_loss = 2.2243672248441726, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 213, train_loss = 2.2197643890976906, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 214, train_loss = 2.2143044795375317, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 215, train_loss = 2.2105818416457623, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 216, train_loss = 2.204508160473779, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 217, train_loss = 2.200613795546815, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 218, train_loss = 2.1962775103747845, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 219, train_loss = 2.1899488780181855, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 220, train_loss = 2.185769495787099, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 221, train_loss = 2.181064111413434, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 222, train_loss = 2.1756291538476944, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 223, train_loss = 2.171776578994468, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 224, train_loss = 2.167444000719115, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 225, train_loss = 2.162335592089221, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 226, train_loss = 2.1594228495378047, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 227, train_loss = 2.1538634821772575, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 228, train_loss = 2.15115753444843, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 229, train_loss = 2.145602874457836, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 230, train_loss = 2.140471624908969, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 231, train_loss = 2.1360453988891095, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 232, train_loss = 2.132156953215599, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 233, train_loss = 2.1288739070296288, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 234, train_loss = 2.1250845044851303, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 235, train_loss = 2.1201193656306714, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 236, train_loss = 2.115633587120101, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 237, train_loss = 2.1108274087309837, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 238, train_loss = 2.1082798168063164, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 239, train_loss = 2.103305588243529, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 240, train_loss = 2.10019792499952, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 241, train_loss = 2.097137012751773, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 242, train_loss = 2.0922429088968784, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 243, train_loss = 2.089980874210596, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 244, train_loss = 2.0859857064206153, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 245, train_loss = 2.0811572272796184, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 246, train_loss = 2.0786767441313714, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 247, train_loss = 2.074831037549302, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 248, train_loss = 2.0713929273188114, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 249, train_loss = 2.067792867543176, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 250, train_loss = 2.0629605415742844, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 251, train_loss = 2.059590668650344, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 252, train_loss = 2.0558118980843574, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 253, train_loss = 2.05257994052954, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 254, train_loss = 2.0496737349312752, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 255, train_loss = 2.046574128093198, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 256, train_loss = 2.0423967614769936, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 257, train_loss = 2.039963636547327, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 258, train_loss = 2.036677098600194, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 259, train_loss = 2.0343307331204414, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 260, train_loss = 2.0293493333738297, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 261, train_loss = 2.0271009120624512, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 262, train_loss = 2.0227627716958523, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 263, train_loss = 2.0185929499566555, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 264, train_loss = 2.0168898527044803, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 265, train_loss = 2.014621891081333, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 266, train_loss = 2.010824006050825, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 267, train_loss = 2.008663397282362, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 268, train_loss = 2.005109738558531, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 269, train_loss = 2.0024809997994453, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 270, train_loss = 1.9989981960970908, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 271, train_loss = 1.9961138230282813, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 272, train_loss = 1.9935510035138577, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 273, train_loss = 1.9898943926673383, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 274, train_loss = 1.988909636856988, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 275, train_loss = 1.984458950581029, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 276, train_loss = 1.9821618038695306, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 277, train_loss = 1.9787204551976174, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 278, train_loss = 1.9764827017206699, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 279, train_loss = 1.973561643389985, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 280, train_loss = 1.9709299232345074, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 281, train_loss = 1.9681458969134837, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 282, train_loss = 1.9655186992604285, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 283, train_loss = 1.9620344664435834, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 284, train_loss = 1.9591160851996392, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 285, train_loss = 1.9574692051392049, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 286, train_loss = 1.9541380133014172, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 287, train_loss = 1.9509328182321042, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 288, train_loss = 1.9495444558560848, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 289, train_loss = 1.9460787437856197, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 290, train_loss = 1.9447880014777184, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 291, train_loss = 1.9412222541868687, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 292, train_loss = 1.9399224061053246, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 293, train_loss = 1.9371403108816594, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 294, train_loss = 1.9336769443470985, train_acc = 0.9956916627852818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 295, train_loss = 1.9321190405171365, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 296, train_loss = 1.9291876864153892, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 297, train_loss = 1.9272029536077753, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 298, train_loss = 1.9254018465289846, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 299, train_loss = 1.9227713234722614, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 300, train_loss = 1.9207878274610266, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 301, train_loss = 1.918706238269806, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 302, train_loss = 1.9154334949562326, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 303, train_loss = 1.9136666767299175, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 304, train_loss = 1.9104053191840649, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 305, train_loss = 1.909319614409469, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 306, train_loss = 1.906971700489521, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 307, train_loss = 1.9051061570644379, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 308, train_loss = 1.9026465950300917, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 309, train_loss = 1.899478460312821, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 310, train_loss = 1.8984511718153954, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 311, train_loss = 1.8953210016479716, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 312, train_loss = 1.8927738294005394, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 313, train_loss = 1.8916353260865435, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 314, train_loss = 1.8901591239264235, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 315, train_loss = 1.8868661299347878, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 316, train_loss = 1.8865495013305917, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 317, train_loss = 1.8845542408525944, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 318, train_loss = 1.8802444636821747, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 319, train_loss = 1.8797114193439484, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 320, train_loss = 1.878140289336443, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 321, train_loss = 1.8759006597101688, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 322, train_loss = 1.8736968077719212, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 323, train_loss = 1.8724702410399914, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 324, train_loss = 1.869473621249199, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 325, train_loss = 1.867982161580585, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 326, train_loss = 1.8663058491656557, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 327, train_loss = 1.864339762716554, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 328, train_loss = 1.8620773380389437, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 329, train_loss = 1.8618730144808069, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 330, train_loss = 1.857146063237451, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 331, train_loss = 1.8565489487955347, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 332, train_loss = 1.8563050167867914, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 333, train_loss = 1.8518227996537462, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 334, train_loss = 1.851358494372107, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 335, train_loss = 1.8502792194485664, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 336, train_loss = 1.8458034247159958, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 337, train_loss = 1.8460625013103709, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 338, train_loss = 1.845362993539311, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 339, train_loss = 1.841345546185039, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 340, train_loss = 1.8407404000172392, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 341, train_loss = 1.8390525728464127, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 342, train_loss = 1.836933990358375, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 343, train_loss = 1.8361189787974581, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 344, train_loss = 1.8339922614395618, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 345, train_loss = 1.8331220311811194, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 346, train_loss = 1.829050296335481, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 347, train_loss = 1.8287549167871475, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 348, train_loss = 1.8289982378482819, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 349, train_loss = 1.8249015100300312, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 350, train_loss = 1.8238648982951418, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 351, train_loss = 1.8235408762702718, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 352, train_loss = 1.8193826116621494, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 353, train_loss = 1.8195032527437434, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 354, train_loss = 1.8164352836320177, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 355, train_loss = 1.8158347842982039, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 356, train_loss = 1.8155478747794405, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 357, train_loss = 1.8116385178873315, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 358, train_loss = 1.812064198195003, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 359, train_loss = 1.8106173947453499, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 360, train_loss = 1.8073105750372633, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 361, train_loss = 1.807369520305656, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 362, train_loss = 1.8064080886542797, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 363, train_loss = 1.802556749433279, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 364, train_loss = 1.8027406918117777, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 365, train_loss = 1.8003110947320238, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 366, train_loss = 1.7998720345785841, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 367, train_loss = 1.7988819231977686, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 368, train_loss = 1.7953272672602907, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 369, train_loss = 1.795851500122808, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 370, train_loss = 1.7937872918555513, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 371, train_loss = 1.7915349639952183, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 372, train_loss = 1.7901873849332333, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 373, train_loss = 1.7879804769763723, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 374, train_loss = 1.787072698236443, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 375, train_loss = 1.7868119342019781, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 376, train_loss = 1.7846900360891595, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 377, train_loss = 1.7838930102298036, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 378, train_loss = 1.781894613057375, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 379, train_loss = 1.781273353844881, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 380, train_loss = 1.7799206835916266, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 381, train_loss = 1.7779026702046394, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 382, train_loss = 1.7775260545313358, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 383, train_loss = 1.7762363801011816, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 384, train_loss = 1.7737442217767239, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 385, train_loss = 1.7731117320945486, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 386, train_loss = 1.7732143426546827, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 387, train_loss = 1.7697460614144802, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 388, train_loss = 1.7701036942889914, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 389, train_loss = 1.7666200970998034, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 390, train_loss = 1.7673128098249435, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 391, train_loss = 1.7653389809420332, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 392, train_loss = 1.7634709663689137, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 393, train_loss = 1.7634786454727873, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 394, train_loss = 1.762392669916153, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 395, train_loss = 1.7602645034203306, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 396, train_loss = 1.7600531838834286, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 397, train_loss = 1.7565054260194302, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 398, train_loss = 1.7560800599167123, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 399, train_loss = 1.754907744587399, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 400, train_loss = 1.7537260353565216, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 401, train_loss = 1.7529620366403833, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 402, train_loss = 1.7515182519564405, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 403, train_loss = 1.7494896687567234, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 404, train_loss = 1.7485224778065458, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 405, train_loss = 1.748075857758522, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 406, train_loss = 1.7466413639485836, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 407, train_loss = 1.7451576739549637, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 408, train_loss = 1.7443044036626816, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 409, train_loss = 1.7439100841293111, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 410, train_loss = 1.7423548623919487, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 411, train_loss = 1.740430818288587, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 412, train_loss = 1.7401016441872343, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 413, train_loss = 1.7384773393860087, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 414, train_loss = 1.737687349319458, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 415, train_loss = 1.736938014626503, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 416, train_loss = 1.7352329877903685, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 417, train_loss = 1.734024502336979, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 418, train_loss = 1.7330006832489744, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 419, train_loss = 1.7322536358842626, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 420, train_loss = 1.731090902001597, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 421, train_loss = 1.7304086200892925, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 422, train_loss = 1.7292331295320764, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 423, train_loss = 1.7283324748277664, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 424, train_loss = 1.726805808604695, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 425, train_loss = 1.7257814580807462, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 426, train_loss = 1.7254142264137045, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 427, train_loss = 1.7241083681583405, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 428, train_loss = 1.7231750091305003, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 429, train_loss = 1.7217727340757847, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 430, train_loss = 1.720762524753809, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 431, train_loss = 1.7198355769505724, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 432, train_loss = 1.7194928923854604, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 433, train_loss = 1.7179571129381657, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 434, train_loss = 1.7167445669183508, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 435, train_loss = 1.7164992851903662, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 436, train_loss = 1.7150831408798695, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 437, train_loss = 1.7142242515692487, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 438, train_loss = 1.7124583771219477, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 439, train_loss = 1.7120480003068224, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 440, train_loss = 1.7112726519117132, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 441, train_loss = 1.710729494690895, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 442, train_loss = 1.7085296735167503, train_acc = 0.9954587796925943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 443, train_loss = 1.7084277620306239, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 444, train_loss = 1.7073801085352898, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 445, train_loss = 1.7063858335604891, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 446, train_loss = 1.7060586934676394, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 447, train_loss = 1.7038697078824043, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 448, train_loss = 1.7034988068044186, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 449, train_loss = 1.703413862735033, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 450, train_loss = 1.7024077387759462, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 451, train_loss = 1.7000627579400316, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 452, train_loss = 1.6999310279497877, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 453, train_loss = 1.6991656584432349, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 454, train_loss = 1.698118751286529, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 455, train_loss = 1.6973454803228378, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 456, train_loss = 1.696591423242353, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 457, train_loss = 1.6961375499377027, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 458, train_loss = 1.6943388258805498, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 459, train_loss = 1.6942766892025247, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 460, train_loss = 1.6932092135539278, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 461, train_loss = 1.6923358564963564, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 462, train_loss = 1.6915499368915334, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 463, train_loss = 1.6908493315568194, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 464, train_loss = 1.6896922389278188, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 465, train_loss = 1.6885180013487116, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 466, train_loss = 1.687980848015286, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 467, train_loss = 1.687512313365005, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 468, train_loss = 1.6863663345575333, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 469, train_loss = 1.6856492075021379, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 470, train_loss = 1.6846888077561744, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 471, train_loss = 1.6836017121677287, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 472, train_loss = 1.6831110107596032, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 473, train_loss = 1.6826159532065503, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 474, train_loss = 1.681981522589922, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 475, train_loss = 1.680700606375467, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 476, train_loss = 1.6800332342390902, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 477, train_loss = 1.6794200490112416, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 478, train_loss = 1.6781212923233397, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 479, train_loss = 1.6775436028838158, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 480, train_loss = 1.6769722911412828, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 481, train_loss = 1.6764306600089185, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 482, train_loss = 1.6750350706279278, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 483, train_loss = 1.6748233760590665, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 484, train_loss = 1.6737828900222667, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 485, train_loss = 1.6729301437735558, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 486, train_loss = 1.6717529607121833, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 487, train_loss = 1.6715758281643502, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 488, train_loss = 1.670681469142437, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 489, train_loss = 1.6696865421836264, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 490, train_loss = 1.669519629329443, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 491, train_loss = 1.6676600712235086, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 492, train_loss = 1.6677975269849412, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 493, train_loss = 1.6665779960458167, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 494, train_loss = 1.6663936848635785, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 495, train_loss = 1.6658599190413952, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 496, train_loss = 1.6650624672765844, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 497, train_loss = 1.6635298331384547, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 498, train_loss = 1.663866436749231, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 499, train_loss = 1.6621794613893144, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████▎                                              | 10/30 [1:30:37<3:01:26, 544.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "11th- epoch: 0, train_loss = 105.91318941116333, train_acc = 0.7821378667908709\n",
      "test Acc 0.8868715083798883:\n",
      "11th- epoch: 1, train_loss = 43.831471629440784, train_acc = 0.912435957149511\n",
      "test Acc 0.9180633147113594:\n",
      "11th- epoch: 2, train_loss = 34.084251061081886, train_acc = 0.9303679552864462\n",
      "test Acc 0.9334264432029795:\n",
      "11th- epoch: 3, train_loss = 28.805090375244617, train_acc = 0.939683278993945\n",
      "test Acc 0.9408752327746741:\n",
      "11th- epoch: 4, train_loss = 25.24021750688553, train_acc = 0.9473684210526315\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 5, train_loss = 22.66324845701456, train_acc = 0.9527247321844434\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 6, train_loss = 20.658645886927843, train_acc = 0.9580810433162552\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 7, train_loss = 19.044373501092196, train_acc = 0.9606427573358174\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 8, train_loss = 17.716058764606714, train_acc = 0.9628551467163484\n",
      "test Acc 0.9543761638733705:\n",
      "11th- epoch: 9, train_loss = 16.57273857295513, train_acc = 0.9654168607359106\n",
      "test Acc 0.9548417132216015:\n",
      "11th- epoch: 10, train_loss = 15.572188664227724, train_acc = 0.9680950163018165\n",
      "test Acc 0.957169459962756:\n",
      "11th- epoch: 11, train_loss = 14.693305227905512, train_acc = 0.9692594317652539\n",
      "test Acc 0.957635009310987:\n",
      "11th- epoch: 12, train_loss = 13.924494843930006, train_acc = 0.9711224965067536\n",
      "test Acc 0.9581005586592178:\n",
      "11th- epoch: 13, train_loss = 13.2438756339252, train_acc = 0.9728691197019096\n",
      "test Acc 0.9590316573556797:\n",
      "11th- epoch: 14, train_loss = 12.63993837684393, train_acc = 0.9735677689799721\n",
      "test Acc 0.9594972067039106:\n",
      "11th- epoch: 15, train_loss = 12.08818257600069, train_acc = 0.974033535165347\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 16, train_loss = 11.591906748712063, train_acc = 0.975780158360503\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 17, train_loss = 11.136708699166775, train_acc = 0.9770610153702841\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 18, train_loss = 10.723086098209023, train_acc = 0.9778761061946902\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 19, train_loss = 10.347532711923122, train_acc = 0.9785747554727526\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 20, train_loss = 10.000441132113338, train_acc = 0.9795062878435026\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 21, train_loss = 9.680364893749356, train_acc = 0.980204937121565\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 22, train_loss = 9.3837237842381, train_acc = 0.9812529110386586\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 23, train_loss = 9.108646765351295, train_acc = 0.981951560316721\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 24, train_loss = 8.856139009818435, train_acc = 0.9821844434094085\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 25, train_loss = 8.619307255372405, train_acc = 0.9829995342338146\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 26, train_loss = 8.396270914003253, train_acc = 0.9834653004191896\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 27, train_loss = 8.186887245625257, train_acc = 0.984163949697252\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 28, train_loss = 7.993819395080209, train_acc = 0.9845132743362832\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 29, train_loss = 7.806447418406606, train_acc = 0.9846297158826269\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 30, train_loss = 7.631611729040742, train_acc = 0.9848625989753144\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 31, train_loss = 7.463923420757055, train_acc = 0.9852119236143456\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 32, train_loss = 7.307186609134078, train_acc = 0.9857941313460643\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 33, train_loss = 7.153997199609876, train_acc = 0.9864927806241267\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 34, train_loss = 7.0131240244954824, train_acc = 0.9870749883558454\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 35, train_loss = 6.8765394147485495, train_acc = 0.9871914299021891\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 36, train_loss = 6.748534804210067, train_acc = 0.9876571960875641\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 37, train_loss = 6.625763041898608, train_acc = 0.9880065207265952\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 38, train_loss = 6.510126611217856, train_acc = 0.9885887284583139\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 39, train_loss = 6.398162027820945, train_acc = 0.9887051700046576\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 40, train_loss = 6.289864810183644, train_acc = 0.9888216115510013\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 41, train_loss = 6.190738616511226, train_acc = 0.9890544946436889\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 42, train_loss = 6.090231450274587, train_acc = 0.9892873777363763\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 43, train_loss = 5.993932321667671, train_acc = 0.9892873777363763\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 44, train_loss = 5.901412735693157, train_acc = 0.9895202608290639\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 45, train_loss = 5.813432586379349, train_acc = 0.9896367023754076\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 46, train_loss = 5.726686037145555, train_acc = 0.9899860270144387\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 47, train_loss = 5.6438911110162735, train_acc = 0.9901024685607824\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 48, train_loss = 5.563542055897415, train_acc = 0.9902189101071263\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 49, train_loss = 5.484375429339707, train_acc = 0.9905682347461574\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 50, train_loss = 5.406525529921055, train_acc = 0.990801117838845\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 51, train_loss = 5.334323972463608, train_acc = 0.990801117838845\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 52, train_loss = 5.264836672693491, train_acc = 0.9909175593851887\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 53, train_loss = 5.197507615201175, train_acc = 0.9909175593851887\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 54, train_loss = 5.133906230330467, train_acc = 0.9909175593851887\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 55, train_loss = 5.069501983933151, train_acc = 0.9910340009315324\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 56, train_loss = 5.009759292006493, train_acc = 0.9910340009315324\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 57, train_loss = 4.9503942700102925, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 58, train_loss = 4.8933637626469135, train_acc = 0.9912668840242198\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 59, train_loss = 4.837976288050413, train_acc = 0.9912668840242198\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 60, train_loss = 4.782764203846455, train_acc = 0.9913833255705635\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 61, train_loss = 4.729162714444101, train_acc = 0.9913833255705635\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 62, train_loss = 4.678312233649194, train_acc = 0.9913833255705635\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 63, train_loss = 4.628394949249923, train_acc = 0.9913833255705635\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 64, train_loss = 4.579137776046991, train_acc = 0.9913833255705635\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 65, train_loss = 4.532803340815008, train_acc = 0.9913833255705635\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 66, train_loss = 4.485959024168551, train_acc = 0.9916162086632511\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 67, train_loss = 4.441585090942681, train_acc = 0.9916162086632511\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 68, train_loss = 4.398855852894485, train_acc = 0.9918490917559385\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 69, train_loss = 4.355535955168307, train_acc = 0.9918490917559385\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 70, train_loss = 4.311886839568615, train_acc = 0.9918490917559385\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 71, train_loss = 4.273227131925523, train_acc = 0.992081974848626\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 72, train_loss = 4.234199007041752, train_acc = 0.9919655333022822\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 73, train_loss = 4.195334556512535, train_acc = 0.992081974848626\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 74, train_loss = 4.158805965445936, train_acc = 0.992081974848626\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 75, train_loss = 4.121485385112464, train_acc = 0.9921984163949698\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 76, train_loss = 4.0855224104598165, train_acc = 0.9921984163949698\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 77, train_loss = 4.051835175603628, train_acc = 0.9924312994876572\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 78, train_loss = 4.016333990730345, train_acc = 0.9924312994876572\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 79, train_loss = 3.981460260692984, train_acc = 0.9924312994876572\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 80, train_loss = 3.9503084369935095, train_acc = 0.9924312994876572\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 81, train_loss = 3.9180254614911973, train_acc = 0.9925477410340009\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 82, train_loss = 3.884530898183584, train_acc = 0.9925477410340009\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 83, train_loss = 3.855146660003811, train_acc = 0.9925477410340009\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 84, train_loss = 3.8250507549382746, train_acc = 0.9926641825803446\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 85, train_loss = 3.7947802282869816, train_acc = 0.9926641825803446\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 86, train_loss = 3.766018791589886, train_acc = 0.9927806241266884\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 87, train_loss = 3.7389408349990845, train_acc = 0.9927806241266884\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 88, train_loss = 3.710856195539236, train_acc = 0.9927806241266884\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 89, train_loss = 3.68479361012578, train_acc = 0.9927806241266884\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 90, train_loss = 3.657640404999256, train_acc = 0.9927806241266884\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 91, train_loss = 3.632291216403246, train_acc = 0.9927806241266884\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 92, train_loss = 3.6071369075216353, train_acc = 0.9927806241266884\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 93, train_loss = 3.5817227787338197, train_acc = 0.9928970656730322\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 94, train_loss = 3.558189657982439, train_acc = 0.9928970656730322\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 95, train_loss = 3.5326120131649077, train_acc = 0.9928970656730322\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 96, train_loss = 3.5096165402792394, train_acc = 0.9930135072193759\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 97, train_loss = 3.4856792860664427, train_acc = 0.9931299487657196\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 98, train_loss = 3.4624826819635928, train_acc = 0.9931299487657196\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 99, train_loss = 3.4395843483507633, train_acc = 0.9932463903120633\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 100, train_loss = 3.4178347713313997, train_acc = 0.9932463903120633\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 101, train_loss = 3.3977611921727657, train_acc = 0.9932463903120633\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 102, train_loss = 3.3756089210510254, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 103, train_loss = 3.355166230350733, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 104, train_loss = 3.3341888561844826, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 105, train_loss = 3.314851733390242, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 106, train_loss = 3.2947712540626526, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 107, train_loss = 3.2756852828897536, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 108, train_loss = 3.257141226436943, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 109, train_loss = 3.2391713187098503, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 110, train_loss = 3.2213654071092606, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 111, train_loss = 3.2010703743435442, train_acc = 0.9934792734047508\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 112, train_loss = 3.1843146816827357, train_acc = 0.9934792734047508\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 113, train_loss = 3.166146541479975, train_acc = 0.9934792734047508\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 114, train_loss = 3.1488755024038255, train_acc = 0.9934792734047508\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 115, train_loss = 3.1330908299423754, train_acc = 0.9934792734047508\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 116, train_loss = 3.1144603192806244, train_acc = 0.9934792734047508\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 117, train_loss = 3.1002285196445882, train_acc = 0.9934792734047508\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 118, train_loss = 3.0828901738859713, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 119, train_loss = 3.067139469087124, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 120, train_loss = 3.0522964000701904, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 121, train_loss = 3.036397159099579, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 122, train_loss = 3.0221850224770606, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 123, train_loss = 3.0068279379047453, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 124, train_loss = 2.9921192340552807, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 125, train_loss = 2.9782472574152052, train_acc = 0.993828598043782\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 126, train_loss = 2.9632192156277597, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 127, train_loss = 2.948452076409012, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 128, train_loss = 2.935982967261225, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 129, train_loss = 2.9221431030891836, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 130, train_loss = 2.9098585806787014, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 131, train_loss = 2.8948815963231027, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 132, train_loss = 2.88184172520414, train_acc = 0.994294364229157\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 133, train_loss = 2.87111251661554, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 134, train_loss = 2.8576119751669466, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 135, train_loss = 2.843846523668617, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 136, train_loss = 2.8324709497392178, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 137, train_loss = 2.8207374014891684, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 138, train_loss = 2.807934943586588, train_acc = 0.9945272473218444\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 139, train_loss = 2.796803429722786, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 140, train_loss = 2.783959390129894, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 141, train_loss = 2.773749941494316, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 142, train_loss = 2.7623660401441157, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 143, train_loss = 2.7508576647378504, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 144, train_loss = 2.7406594292260706, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 145, train_loss = 2.728472575545311, train_acc = 0.9949930135072194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 146, train_loss = 2.7192429900169373, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 147, train_loss = 2.707244584802538, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 148, train_loss = 2.6956415832974017, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 149, train_loss = 2.6878400780260563, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 150, train_loss = 2.6771997462492436, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 151, train_loss = 2.6664946030359715, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 152, train_loss = 2.657055673422292, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 153, train_loss = 2.6467496615368873, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 154, train_loss = 2.63748657819815, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 155, train_loss = 2.628059779526666, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 156, train_loss = 2.6176228001713753, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 157, train_loss = 2.6092259001452476, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 158, train_loss = 2.5988197785336524, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 159, train_loss = 2.5888718962669373, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 160, train_loss = 2.5815305039286613, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 161, train_loss = 2.571588446618989, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 162, train_loss = 2.5640420701820403, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 163, train_loss = 2.554315981687978, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 164, train_loss = 2.5466737400274724, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 165, train_loss = 2.5372159108519554, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 166, train_loss = 2.5276432931423187, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 167, train_loss = 2.5200816344004124, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 168, train_loss = 2.5121148626785725, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 169, train_loss = 2.503646553726867, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 170, train_loss = 2.4946805387735367, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 171, train_loss = 2.4872488726396114, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 172, train_loss = 2.4793493214529008, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 173, train_loss = 2.4722145397681743, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 174, train_loss = 2.463484947802499, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 175, train_loss = 2.456976308254525, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 176, train_loss = 2.448820599587634, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 177, train_loss = 2.441507023992017, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 178, train_loss = 2.434109266847372, train_acc = 0.9951094550535631\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 179, train_loss = 2.426376761170104, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 180, train_loss = 2.420099885435775, train_acc = 0.9951094550535631\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 181, train_loss = 2.411612819880247, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 182, train_loss = 2.405561714200303, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 183, train_loss = 2.3992724120616913, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 184, train_loss = 2.3910146590787917, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 185, train_loss = 2.3860803470015526, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 186, train_loss = 2.377689218847081, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 187, train_loss = 2.373649523826316, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 188, train_loss = 2.3665742117445916, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 189, train_loss = 2.360147126019001, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 190, train_loss = 2.3533933472353965, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 191, train_loss = 2.3477556395810097, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 192, train_loss = 2.341001834720373, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 193, train_loss = 2.33447861042805, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 194, train_loss = 2.3300758253317326, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 195, train_loss = 2.323934319196269, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 196, train_loss = 2.3175654623191804, train_acc = 0.9951094550535631\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 197, train_loss = 2.3108648222405463, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 198, train_loss = 2.305175018729642, train_acc = 0.9951094550535631\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 199, train_loss = 2.299034047871828, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 200, train_loss = 2.2952124488074332, train_acc = 0.9951094550535631\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 201, train_loss = 2.2875602890271693, train_acc = 0.9951094550535631\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 202, train_loss = 2.2829895466566086, train_acc = 0.9951094550535631\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 203, train_loss = 2.277380197076127, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 204, train_loss = 2.272009049775079, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 205, train_loss = 2.2670748941600323, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 206, train_loss = 2.2615911837201566, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 207, train_loss = 2.2569168109912425, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 208, train_loss = 2.250684168189764, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 209, train_loss = 2.2455499309580773, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 210, train_loss = 2.2394234847743064, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 211, train_loss = 2.235938896657899, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 212, train_loss = 2.2292031708639115, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 213, train_loss = 2.2256622712593526, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 214, train_loss = 2.219598578987643, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 215, train_loss = 2.216196705820039, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 216, train_loss = 2.2111000667791814, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 217, train_loss = 2.206545303342864, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 218, train_loss = 2.2006382904946804, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 219, train_loss = 2.19606888666749, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 220, train_loss = 2.191727750003338, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 221, train_loss = 2.187740833731368, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 222, train_loss = 2.183530709473416, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 223, train_loss = 2.177340339869261, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 224, train_loss = 2.173316143453121, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 225, train_loss = 2.1697138894815, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 226, train_loss = 2.164728868752718, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 227, train_loss = 2.159283855231479, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 228, train_loss = 2.155525002628565, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 229, train_loss = 2.152500795898959, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 230, train_loss = 2.147126204101369, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 231, train_loss = 2.1436136588454247, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 232, train_loss = 2.138559174956754, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 233, train_loss = 2.135387609479949, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 234, train_loss = 2.1296205446124077, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 235, train_loss = 2.1271703839302063, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 236, train_loss = 2.1229783680755645, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 237, train_loss = 2.1196167443413287, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 238, train_loss = 2.113819944439456, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 239, train_loss = 2.111045063706115, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 240, train_loss = 2.10787374782376, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 241, train_loss = 2.103513990761712, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 242, train_loss = 2.099877167493105, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 243, train_loss = 2.09748313203454, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 244, train_loss = 2.092955406755209, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 245, train_loss = 2.0902244113385677, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 246, train_loss = 2.084007930010557, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 247, train_loss = 2.081500881584361, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 248, train_loss = 2.077639567432925, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 249, train_loss = 2.0726080301683396, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 250, train_loss = 2.0707380038220435, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 251, train_loss = 2.0655818458180875, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 252, train_loss = 2.063558593392372, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 253, train_loss = 2.0588487535715103, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 254, train_loss = 2.056609297869727, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 255, train_loss = 2.0521676763892174, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 256, train_loss = 2.0490979601163417, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 257, train_loss = 2.0458332065027207, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 258, train_loss = 2.0421691697556525, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 259, train_loss = 2.03943728399463, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 260, train_loss = 2.0358004830777645, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 261, train_loss = 2.0331539425533265, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 262, train_loss = 2.029043984832242, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 263, train_loss = 2.026689513353631, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 264, train_loss = 2.0240090067964047, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 265, train_loss = 2.019421510398388, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 266, train_loss = 2.015791537822224, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 267, train_loss = 2.013118249713443, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 268, train_loss = 2.0104446783661842, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 269, train_loss = 2.006807508529164, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 270, train_loss = 2.0035815922310576, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 271, train_loss = 2.0012840293347836, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 272, train_loss = 1.9977596687385812, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 273, train_loss = 1.9942147321999073, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 274, train_loss = 1.9932038175174966, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 275, train_loss = 1.9892197115113959, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 276, train_loss = 1.987011911929585, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 277, train_loss = 1.983290422707796, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 278, train_loss = 1.9803274212172255, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 279, train_loss = 1.9770736383507028, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 280, train_loss = 1.974309874116443, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 281, train_loss = 1.9726894795894623, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 282, train_loss = 1.9697407335042953, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 283, train_loss = 1.9682577276835218, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 284, train_loss = 1.963758297264576, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 285, train_loss = 1.960838889121078, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 286, train_loss = 1.9581817450234666, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 287, train_loss = 1.9563614750513807, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 288, train_loss = 1.9530348082771525, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 289, train_loss = 1.9494533836841583, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 290, train_loss = 1.9472823614487424, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 291, train_loss = 1.943569996743463, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 292, train_loss = 1.9420785208931193, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 293, train_loss = 1.9393997378647327, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 294, train_loss = 1.9364739209413528, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 295, train_loss = 1.9333088161656633, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 296, train_loss = 1.932306615053676, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 297, train_loss = 1.9292755151400343, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 298, train_loss = 1.9261201148619875, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 299, train_loss = 1.9225894175469875, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 300, train_loss = 1.9218319592764601, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 301, train_loss = 1.918243887485005, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 302, train_loss = 1.9160424806177616, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 303, train_loss = 1.9143035350134596, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 304, train_loss = 1.9120815744390711, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 305, train_loss = 1.9090644953539595, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 306, train_loss = 1.907190639525652, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 307, train_loss = 1.905102608143352, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 308, train_loss = 1.9020186079433188, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 309, train_loss = 1.9000406004488468, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 310, train_loss = 1.896872060955502, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 311, train_loss = 1.8952779434621334, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 312, train_loss = 1.8935662060976028, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 313, train_loss = 1.8902837684145197, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 314, train_loss = 1.8886494785547256, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 315, train_loss = 1.8862436339259148, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 316, train_loss = 1.8851045047631487, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 317, train_loss = 1.8831161161651835, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 318, train_loss = 1.8803318043937907, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 319, train_loss = 1.878104031085968, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 320, train_loss = 1.8758716732263565, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 321, train_loss = 1.8746414730558172, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 322, train_loss = 1.871082124649547, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 323, train_loss = 1.8697125650942326, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 324, train_loss = 1.8671260885894299, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 325, train_loss = 1.8662361787864938, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 326, train_loss = 1.8651332358131185, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 327, train_loss = 1.8609852083027363, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 328, train_loss = 1.8601960837841034, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 329, train_loss = 1.8581900087883696, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 330, train_loss = 1.857286848127842, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 331, train_loss = 1.8548463123152032, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 332, train_loss = 1.8520989008247852, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 333, train_loss = 1.8504560180008411, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 334, train_loss = 1.8494979242095724, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 335, train_loss = 1.8464022452244535, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 336, train_loss = 1.844137983978726, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 337, train_loss = 1.8421932011842728, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 338, train_loss = 1.8411209719488397, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 339, train_loss = 1.840334584354423, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 340, train_loss = 1.8366920687258244, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 341, train_loss = 1.8362722508609295, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 342, train_loss = 1.832487146020867, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 343, train_loss = 1.8327720848610625, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 344, train_loss = 1.8303486816585064, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 345, train_loss = 1.8283737947931513, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 346, train_loss = 1.8268726952373981, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 347, train_loss = 1.824170894920826, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 348, train_loss = 1.8228147402405739, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 349, train_loss = 1.8206772668054327, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 350, train_loss = 1.8184602310648188, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 351, train_loss = 1.817564520984888, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 352, train_loss = 1.8152442425489426, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 353, train_loss = 1.8153925476362929, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 354, train_loss = 1.8129077876219526, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 355, train_loss = 1.8111568266758695, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 356, train_loss = 1.8107629120349884, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 357, train_loss = 1.8069902894785628, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 358, train_loss = 1.80629226192832, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 359, train_loss = 1.8035244395723566, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 360, train_loss = 1.8021141303470358, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 361, train_loss = 1.8015637347707525, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 362, train_loss = 1.79930479824543, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 363, train_loss = 1.7975986935198307, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 364, train_loss = 1.797594040632248, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 365, train_loss = 1.7947829501936212, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 366, train_loss = 1.7942704869201407, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 367, train_loss = 1.7918968772282824, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 368, train_loss = 1.7912404561648145, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 369, train_loss = 1.7883359318366274, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 370, train_loss = 1.7877718297531828, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 371, train_loss = 1.7849371979245916, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 372, train_loss = 1.7842873943736777, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 373, train_loss = 1.7829414358129725, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 374, train_loss = 1.7808489998569712, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 375, train_loss = 1.7796186717459932, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 376, train_loss = 1.7785904532065615, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 377, train_loss = 1.7764091329881921, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 378, train_loss = 1.7754627391695976, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 379, train_loss = 1.7734099799999967, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 380, train_loss = 1.772433283389546, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 381, train_loss = 1.7705572297563776, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 382, train_loss = 1.7704485406866297, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 383, train_loss = 1.76791889348533, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 384, train_loss = 1.7656747959554195, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 385, train_loss = 1.7658284530043602, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 386, train_loss = 1.763807438313961, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 387, train_loss = 1.762427439331077, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 388, train_loss = 1.7600002301624045, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 389, train_loss = 1.760411741794087, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 390, train_loss = 1.7585491040954366, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 391, train_loss = 1.7561049374053255, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 392, train_loss = 1.7552637370536104, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 393, train_loss = 1.7554588975617662, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 394, train_loss = 1.7540211280575022, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 395, train_loss = 1.7534849755465984, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 396, train_loss = 1.7499319525668398, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 397, train_loss = 1.7505691312253475, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 398, train_loss = 1.7476847879588604, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 399, train_loss = 1.746753583312966, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 400, train_loss = 1.7442594977328554, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 401, train_loss = 1.7434194907546043, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 402, train_loss = 1.74396939703729, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 403, train_loss = 1.7410822821548209, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 404, train_loss = 1.741151224821806, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 405, train_loss = 1.7398061280837283, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 406, train_loss = 1.7395823039114475, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 407, train_loss = 1.7374794445931911, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 408, train_loss = 1.7367505604634061, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 409, train_loss = 1.7351053891470656, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 410, train_loss = 1.7327386861434206, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 411, train_loss = 1.7335160449147224, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 412, train_loss = 1.7333506867289543, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 413, train_loss = 1.731105358689092, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 414, train_loss = 1.7298702535917982, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 415, train_loss = 1.7267621593782678, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 416, train_loss = 1.7260429536690935, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 417, train_loss = 1.7249389005592093, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 418, train_loss = 1.7250759029993787, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 419, train_loss = 1.7227362729609013, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 420, train_loss = 1.7213385254144669, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 421, train_loss = 1.7185849336674437, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 422, train_loss = 1.7182301183929667, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 423, train_loss = 1.7185132578015327, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 424, train_loss = 1.7165827291901223, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 425, train_loss = 1.714332093775738, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 426, train_loss = 1.7141958114807494, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 427, train_loss = 1.7137796891038306, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 428, train_loss = 1.7120141759514809, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 429, train_loss = 1.7108539591426961, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 430, train_loss = 1.7083510334487073, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 431, train_loss = 1.7084131787414663, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 432, train_loss = 1.7073599733412266, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 433, train_loss = 1.7066282232408412, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 434, train_loss = 1.7059988391702063, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 435, train_loss = 1.7040467982296832, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 436, train_loss = 1.7034835194353946, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 437, train_loss = 1.7018157479469664, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 438, train_loss = 1.7019924484193325, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 439, train_loss = 1.6995649188756943, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 440, train_loss = 1.6991196225280873, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 441, train_loss = 1.697199986607302, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 442, train_loss = 1.6963358409702778, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 443, train_loss = 1.696091226011049, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 444, train_loss = 1.6958427391946316, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 445, train_loss = 1.6929027922451496, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 446, train_loss = 1.6932292605633847, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 447, train_loss = 1.692308199882973, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 448, train_loss = 1.6926896857912652, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 449, train_loss = 1.6917175737326033, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 450, train_loss = 1.6912401740555651, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 451, train_loss = 1.6890074399416335, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 452, train_loss = 1.6872151519055478, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 453, train_loss = 1.6861579194664955, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 454, train_loss = 1.6862815369968303, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 455, train_loss = 1.6844892390072346, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 456, train_loss = 1.6852086745202541, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 457, train_loss = 1.6842985314433463, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 458, train_loss = 1.6826871546800248, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 459, train_loss = 1.6819269483094104, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 460, train_loss = 1.6798668044502847, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 461, train_loss = 1.6785985839669593, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 462, train_loss = 1.67785893130349, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 463, train_loss = 1.6760702729225159, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 464, train_loss = 1.6753622840042226, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 465, train_loss = 1.6755490998621099, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 466, train_loss = 1.6745064196293242, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 467, train_loss = 1.6721640800242312, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 468, train_loss = 1.6741989813745022, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 469, train_loss = 1.6714859542553313, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 470, train_loss = 1.6722115476732142, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 471, train_loss = 1.6696963024442084, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 472, train_loss = 1.6679573481087573, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 473, train_loss = 1.6675787518615834, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 474, train_loss = 1.666343906254042, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 475, train_loss = 1.6654275047476403, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 476, train_loss = 1.6654638859326951, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 477, train_loss = 1.6644538951222785, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 478, train_loss = 1.663216471672058, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 479, train_loss = 1.6613616446848027, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 480, train_loss = 1.6618475678260438, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 481, train_loss = 1.6610011632437818, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 482, train_loss = 1.6584686997230165, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 483, train_loss = 1.6591153119807132, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 484, train_loss = 1.6581511994008906, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 485, train_loss = 1.6567909034783952, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 486, train_loss = 1.6564658333663829, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 487, train_loss = 1.6556978660519235, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 488, train_loss = 1.6537880462710746, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 489, train_loss = 1.6527349365060218, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 490, train_loss = 1.6530129971797578, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 491, train_loss = 1.653401255607605, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 492, train_loss = 1.6515411411528476, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 493, train_loss = 1.6511268976028077, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 494, train_loss = 1.649447729170788, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 495, train_loss = 1.648613394529093, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 496, train_loss = 1.6481349554960616, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 497, train_loss = 1.649885727732908, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 498, train_loss = 1.6461018820409663, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 499, train_loss = 1.6455594139988534, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████▋                                            | 11/30 [1:39:40<2:52:19, 544.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "12th- epoch: 0, train_loss = 107.21029570698738, train_acc = 0.7962272938984629\n",
      "test Acc 0.8868715083798883:\n",
      "12th- epoch: 1, train_loss = 41.80223961919546, train_acc = 0.915929203539823\n",
      "test Acc 0.9329608938547486:\n",
      "12th- epoch: 2, train_loss = 32.58128770068288, train_acc = 0.935258500232883\n",
      "test Acc 0.9432029795158287:\n",
      "12th- epoch: 3, train_loss = 27.713868524879217, train_acc = 0.945388914764788\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 4, train_loss = 24.44312271475792, train_acc = 0.9514438751746623\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 5, train_loss = 22.028920505195856, train_acc = 0.9563344201210993\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 6, train_loss = 20.14348953589797, train_acc = 0.9598276665114113\n",
      "test Acc 0.9515828677839852:\n",
      "12th- epoch: 7, train_loss = 18.5937317609787, train_acc = 0.9626222636236609\n",
      "test Acc 0.9539106145251397:\n",
      "12th- epoch: 8, train_loss = 17.317458104342222, train_acc = 0.9647182114578482\n",
      "test Acc 0.9557728119180633:\n",
      "12th- epoch: 9, train_loss = 16.230925232172012, train_acc = 0.9672799254774104\n",
      "test Acc 0.9557728119180633:\n",
      "12th- epoch: 10, train_loss = 15.294835522770882, train_acc = 0.9691429902189101\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 11, train_loss = 14.481327705085278, train_acc = 0.9707731718677224\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 12, train_loss = 13.772505354136229, train_acc = 0.9728691197019096\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 13, train_loss = 13.1476159542799, train_acc = 0.9741499767116907\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 14, train_loss = 12.584894053637981, train_acc = 0.975314392175128\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 15, train_loss = 12.073514878749847, train_acc = 0.9767116907312529\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 16, train_loss = 11.601733338087797, train_acc = 0.9776432231020028\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 17, train_loss = 11.176303409039974, train_acc = 0.9784583139264089\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 18, train_loss = 10.790867444127798, train_acc = 0.9789240801117839\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 19, train_loss = 10.435470821335912, train_acc = 0.9795062878435026\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 20, train_loss = 10.106113258749247, train_acc = 0.9798556124825337\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 21, train_loss = 9.797670159488916, train_acc = 0.9805542617605962\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 22, train_loss = 9.513049840927124, train_acc = 0.98067070330694\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 23, train_loss = 9.24258584342897, train_acc = 0.9813693525850024\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 24, train_loss = 8.9913027305156, train_acc = 0.981951560316721\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 25, train_loss = 8.753803610801697, train_acc = 0.9829995342338146\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 26, train_loss = 8.528583012521267, train_acc = 0.9832324173265021\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 27, train_loss = 8.316412458196282, train_acc = 0.9832324173265021\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 28, train_loss = 8.11849383637309, train_acc = 0.9835817419655333\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 29, train_loss = 7.93345713429153, train_acc = 0.984163949697252\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 30, train_loss = 7.758520789444447, train_acc = 0.9846297158826269\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 31, train_loss = 7.595955029129982, train_acc = 0.9849790405216581\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 32, train_loss = 7.439931768923998, train_acc = 0.9855612482533768\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 33, train_loss = 7.289867943152785, train_acc = 0.9857941313460643\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 34, train_loss = 7.14813120290637, train_acc = 0.9861434559850955\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 35, train_loss = 7.012257331982255, train_acc = 0.9862598975314392\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 36, train_loss = 6.884424209594727, train_acc = 0.9864927806241267\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 37, train_loss = 6.7594461385160685, train_acc = 0.9864927806241267\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 38, train_loss = 6.641320049762726, train_acc = 0.9868421052631579\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 39, train_loss = 6.52969703450799, train_acc = 0.9873078714485328\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 40, train_loss = 6.422961810603738, train_acc = 0.9875407545412203\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 41, train_loss = 6.31755275465548, train_acc = 0.9877736376339078\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 42, train_loss = 6.217123715206981, train_acc = 0.9880065207265952\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 43, train_loss = 6.1212192345410585, train_acc = 0.9880065207265952\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 44, train_loss = 6.027710048481822, train_acc = 0.9883558453656265\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 45, train_loss = 5.940092075616121, train_acc = 0.9884722869119702\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 46, train_loss = 5.853023700416088, train_acc = 0.9884722869119702\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 47, train_loss = 5.771839678287506, train_acc = 0.9887051700046576\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 48, train_loss = 5.689811734482646, train_acc = 0.9889380530973452\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 49, train_loss = 5.613950178027153, train_acc = 0.9890544946436889\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 50, train_loss = 5.536706974729896, train_acc = 0.9892873777363763\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 51, train_loss = 5.463283879682422, train_acc = 0.98940381928272\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 52, train_loss = 5.39252770319581, train_acc = 0.9896367023754076\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 53, train_loss = 5.322545778006315, train_acc = 0.989869585468095\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 54, train_loss = 5.255738968029618, train_acc = 0.989869585468095\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 55, train_loss = 5.188176121562719, train_acc = 0.9899860270144387\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 56, train_loss = 5.124665820971131, train_acc = 0.9902189101071263\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 57, train_loss = 5.062296407297254, train_acc = 0.9904517931998137\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 58, train_loss = 5.000856027007103, train_acc = 0.9905682347461574\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 59, train_loss = 4.942559529095888, train_acc = 0.9905682347461574\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 60, train_loss = 4.884865814819932, train_acc = 0.9906846762925011\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 61, train_loss = 4.82889171782881, train_acc = 0.9906846762925011\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 62, train_loss = 4.77414474543184, train_acc = 0.990801117838845\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 63, train_loss = 4.722272831946611, train_acc = 0.9906846762925011\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 64, train_loss = 4.672037581913173, train_acc = 0.990801117838845\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 65, train_loss = 4.622156179510057, train_acc = 0.990801117838845\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 66, train_loss = 4.572268375195563, train_acc = 0.990801117838845\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 67, train_loss = 4.5263834884390235, train_acc = 0.990801117838845\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 68, train_loss = 4.4795841835439205, train_acc = 0.9910340009315324\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 69, train_loss = 4.434020798653364, train_acc = 0.9911504424778761\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 70, train_loss = 4.391110148280859, train_acc = 0.9911504424778761\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 71, train_loss = 4.346469070762396, train_acc = 0.9911504424778761\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 72, train_loss = 4.305471117608249, train_acc = 0.9914997671169073\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 73, train_loss = 4.263870959170163, train_acc = 0.9916162086632511\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 74, train_loss = 4.223714895546436, train_acc = 0.9917326502095948\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 75, train_loss = 4.183190598152578, train_acc = 0.9919655333022822\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 76, train_loss = 4.144568013958633, train_acc = 0.992081974848626\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 77, train_loss = 4.106463701464236, train_acc = 0.9919655333022822\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 78, train_loss = 4.069568671286106, train_acc = 0.9921984163949698\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 79, train_loss = 4.03383653331548, train_acc = 0.992081974848626\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 80, train_loss = 3.9993138005957007, train_acc = 0.9921984163949698\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 81, train_loss = 3.9653499126434326, train_acc = 0.9921984163949698\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 82, train_loss = 3.930780033580959, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 83, train_loss = 3.8972226129844785, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 84, train_loss = 3.8656507721170783, train_acc = 0.9924312994876572\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 85, train_loss = 3.833196177147329, train_acc = 0.9924312994876572\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 86, train_loss = 3.803417614661157, train_acc = 0.9926641825803446\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 87, train_loss = 3.7721390957012773, train_acc = 0.9926641825803446\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 88, train_loss = 3.7427275804802775, train_acc = 0.9926641825803446\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 89, train_loss = 3.713890071026981, train_acc = 0.9926641825803446\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 90, train_loss = 3.6852068975567818, train_acc = 0.9927806241266884\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 91, train_loss = 3.6577766770496964, train_acc = 0.9928970656730322\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 92, train_loss = 3.6310760863125324, train_acc = 0.9928970656730322\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 93, train_loss = 3.603532738983631, train_acc = 0.9928970656730322\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 94, train_loss = 3.5775739839300513, train_acc = 0.9930135072193759\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 95, train_loss = 3.551660898141563, train_acc = 0.9931299487657196\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 96, train_loss = 3.525783095508814, train_acc = 0.9931299487657196\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 97, train_loss = 3.501413557678461, train_acc = 0.9931299487657196\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 98, train_loss = 3.4771871780976653, train_acc = 0.9931299487657196\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 99, train_loss = 3.45333019644022, train_acc = 0.9931299487657196\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 100, train_loss = 3.4299406744539738, train_acc = 0.9931299487657196\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 101, train_loss = 3.4080826193094254, train_acc = 0.9932463903120633\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 102, train_loss = 3.3870407762005925, train_acc = 0.9932463903120633\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 103, train_loss = 3.3642889047041535, train_acc = 0.9932463903120633\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 104, train_loss = 3.3435760801658034, train_acc = 0.9932463903120633\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 105, train_loss = 3.320914689451456, train_acc = 0.9932463903120633\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 106, train_loss = 3.3009171849116683, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 107, train_loss = 3.2810401348397136, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 108, train_loss = 3.2616776563227177, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 109, train_loss = 3.2411740445531905, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 110, train_loss = 3.2226837524212897, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 111, train_loss = 3.2038024119101465, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 112, train_loss = 3.1849050954915583, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 113, train_loss = 3.1671800017356873, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 114, train_loss = 3.1486577526666224, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 115, train_loss = 3.1318897767923772, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 116, train_loss = 3.1139075667597353, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 117, train_loss = 3.098252991680056, train_acc = 0.9935957149510946\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 118, train_loss = 3.081329504493624, train_acc = 0.9937121564974383\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 119, train_loss = 3.0649917819537222, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 120, train_loss = 3.048620104789734, train_acc = 0.9937121564974383\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 121, train_loss = 3.033225055783987, train_acc = 0.9937121564974383\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 122, train_loss = 3.0169309489428997, train_acc = 0.9937121564974383\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 123, train_loss = 3.002459349576384, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 124, train_loss = 2.9868830465711653, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 125, train_loss = 2.9719675071537495, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 126, train_loss = 2.95780116179958, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 127, train_loss = 2.943568515125662, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 128, train_loss = 2.9291744343936443, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 129, train_loss = 2.915313286241144, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 130, train_loss = 2.901553876698017, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 131, train_loss = 2.8887006915174425, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 132, train_loss = 2.8764318265020847, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 133, train_loss = 2.8619566671550274, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 134, train_loss = 2.8484610789455473, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 135, train_loss = 2.836570870131254, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 136, train_loss = 2.823793611023575, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 137, train_loss = 2.811462083365768, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 138, train_loss = 2.7998782359063625, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 139, train_loss = 2.787642096634954, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 140, train_loss = 2.7751365550793707, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 141, train_loss = 2.763237474951893, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 142, train_loss = 2.751780714839697, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 143, train_loss = 2.7404764853417873, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 144, train_loss = 2.729516899678856, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 145, train_loss = 2.7193663329817355, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 146, train_loss = 2.707168899476528, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 147, train_loss = 2.697041163686663, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 148, train_loss = 2.6875074305571616, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 149, train_loss = 2.676521184388548, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 150, train_loss = 2.6656862013041973, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 151, train_loss = 2.655226308386773, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 152, train_loss = 2.645245846360922, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 153, train_loss = 2.635562409181148, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 154, train_loss = 2.625993942376226, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 155, train_loss = 2.6162562682293355, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 156, train_loss = 2.6070578172802925, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 157, train_loss = 2.5981262498535216, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 158, train_loss = 2.588536910712719, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 159, train_loss = 2.579949004109949, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 160, train_loss = 2.569891169667244, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 161, train_loss = 2.5625736215151846, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 162, train_loss = 2.5526276170276105, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 163, train_loss = 2.5454066419042647, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 164, train_loss = 2.5369818806648254, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 165, train_loss = 2.5278897434473038, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 166, train_loss = 2.52015437791124, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 167, train_loss = 2.5116270408034325, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 168, train_loss = 2.504228672478348, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 169, train_loss = 2.495669270399958, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 170, train_loss = 2.4882268398068845, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 171, train_loss = 2.4798101149499416, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 172, train_loss = 2.474145928863436, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 173, train_loss = 2.466362392064184, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 174, train_loss = 2.458287549437955, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 175, train_loss = 2.4505037229973823, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 176, train_loss = 2.442597622750327, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 177, train_loss = 2.4374190494418144, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 178, train_loss = 2.4300183828454465, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 179, train_loss = 2.422458914341405, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 180, train_loss = 2.416005485923961, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 181, train_loss = 2.408880275906995, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 182, train_loss = 2.401712055085227, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 183, train_loss = 2.3953084151726216, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 184, train_loss = 2.3881281539797783, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 185, train_loss = 2.3823046647012234, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 186, train_loss = 2.3748733003158122, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 187, train_loss = 2.3687397863250226, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 188, train_loss = 2.3635087434668094, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 189, train_loss = 2.3563372616190463, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 190, train_loss = 2.350056516705081, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 191, train_loss = 2.3442478391807526, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 192, train_loss = 2.338416653452441, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 193, train_loss = 2.331890944391489, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 194, train_loss = 2.3238124027848244, train_acc = 0.994294364229157\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 195, train_loss = 2.318774787010625, train_acc = 0.994294364229157\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 196, train_loss = 2.313186629442498, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 197, train_loss = 2.3073656547348946, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 198, train_loss = 2.3012410178780556, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 199, train_loss = 2.2961306422948837, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 200, train_loss = 2.2914796744007617, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 201, train_loss = 2.285404046298936, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 202, train_loss = 2.2806111723184586, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 203, train_loss = 2.274597520707175, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 204, train_loss = 2.269237068714574, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 205, train_loss = 2.2649455431383103, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 206, train_loss = 2.2589782762806863, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 207, train_loss = 2.253853277536109, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 208, train_loss = 2.2491198542993516, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 209, train_loss = 2.2432381983380765, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 210, train_loss = 2.238597293617204, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 211, train_loss = 2.2337405793368816, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 212, train_loss = 2.2295744617003947, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 213, train_loss = 2.223751413403079, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 214, train_loss = 2.2193708058912307, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 215, train_loss = 2.214409278007224, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 216, train_loss = 2.210992459207773, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 217, train_loss = 2.20544487494044, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 218, train_loss = 2.2019263294059783, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 219, train_loss = 2.1967470720410347, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 220, train_loss = 2.192474951269105, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 221, train_loss = 2.186538993148133, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 222, train_loss = 2.1834695253055543, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 223, train_loss = 2.1779946126043797, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 224, train_loss = 2.174620885401964, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 225, train_loss = 2.169023111462593, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 226, train_loss = 2.1669792719185352, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 227, train_loss = 2.1614569823723286, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 228, train_loss = 2.157186072319746, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 229, train_loss = 2.153686707140878, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 230, train_loss = 2.148203219054267, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 231, train_loss = 2.1453695457894355, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 232, train_loss = 2.140657002804801, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 233, train_loss = 2.137975501595065, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 234, train_loss = 2.1328227035701275, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 235, train_loss = 2.1293256916105747, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 236, train_loss = 2.1256794035434723, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 237, train_loss = 2.1222807553131133, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 238, train_loss = 2.1182419534306973, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 239, train_loss = 2.1143836441915482, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 240, train_loss = 2.110752982320264, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 241, train_loss = 2.106754157692194, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 242, train_loss = 2.102736593456939, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 243, train_loss = 2.0995020419359207, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 244, train_loss = 2.096888944506645, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 245, train_loss = 2.0914616968948394, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 246, train_loss = 2.0888955916743726, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 247, train_loss = 2.0847311317920685, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 248, train_loss = 2.0810611199121922, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 249, train_loss = 2.0776548199355602, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 250, train_loss = 2.0739439602475613, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 251, train_loss = 2.07248055934906, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 252, train_loss = 2.0665549088735133, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 253, train_loss = 2.066599803743884, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 254, train_loss = 2.0620631154160947, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 255, train_loss = 2.058252364397049, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 256, train_loss = 2.054851974127814, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 257, train_loss = 2.0516135569196194, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 258, train_loss = 2.0485213808715343, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 259, train_loss = 2.045878119766712, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 260, train_loss = 2.0422690969426185, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 261, train_loss = 2.0399363078176975, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 262, train_loss = 2.0358262087684125, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 263, train_loss = 2.032696455717087, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 264, train_loss = 2.030141397146508, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 265, train_loss = 2.026405781507492, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 266, train_loss = 2.0238874356728047, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 267, train_loss = 2.0221082555362955, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 268, train_loss = 2.0187185978284106, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 269, train_loss = 2.0153905724873766, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 270, train_loss = 2.011316263466142, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 271, train_loss = 2.0093598229577765, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 272, train_loss = 2.0073060331633314, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 273, train_loss = 2.004186376929283, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 274, train_loss = 2.000290355295874, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 275, train_loss = 1.9983307285001501, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 276, train_loss = 1.996182051836513, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 277, train_loss = 1.9918173229089007, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 278, train_loss = 1.9907607758650556, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 279, train_loss = 1.9868263812968507, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 280, train_loss = 1.9838105154922232, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 281, train_loss = 1.981863398104906, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 282, train_loss = 1.9782032581279054, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 283, train_loss = 1.9762797703733668, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 284, train_loss = 1.9729340299963951, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 285, train_loss = 1.9714125208556652, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 286, train_loss = 1.9682374919066206, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 287, train_loss = 1.9647468539187685, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 288, train_loss = 1.9633643850684166, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 289, train_loss = 1.9598297016927972, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 290, train_loss = 1.9586682183435187, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 291, train_loss = 1.9559470700332895, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 292, train_loss = 1.952965572476387, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 293, train_loss = 1.9511307565262541, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 294, train_loss = 1.9484646631171927, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 295, train_loss = 1.9455721912672743, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 296, train_loss = 1.9425650052726269, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 297, train_loss = 1.9407431818544865, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 298, train_loss = 1.9382325522601604, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 299, train_loss = 1.9350974075496197, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 300, train_loss = 1.9326025123009458, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 301, train_loss = 1.9295726729324088, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 302, train_loss = 1.9272363409399986, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 303, train_loss = 1.9235957997152582, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 304, train_loss = 1.9230203926563263, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 305, train_loss = 1.9195893505821005, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 306, train_loss = 1.9171221206197515, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 307, train_loss = 1.9162150906631723, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 308, train_loss = 1.9119812411954626, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 309, train_loss = 1.9101713238051161, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 310, train_loss = 1.9081761924317107, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 311, train_loss = 1.9067479148507118, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 312, train_loss = 1.9044914034893736, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 313, train_loss = 1.9005855061113834, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 314, train_loss = 1.899473319412209, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 315, train_loss = 1.897531233727932, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 316, train_loss = 1.8946882585296407, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 317, train_loss = 1.8936160256853327, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 318, train_loss = 1.8911993788788095, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 319, train_loss = 1.887803889811039, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 320, train_loss = 1.8860893273958936, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 321, train_loss = 1.8839232424506918, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 322, train_loss = 1.8831992311170325, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 323, train_loss = 1.8814029147615656, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 324, train_loss = 1.878668487071991, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 325, train_loss = 1.8769458159804344, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 326, train_loss = 1.8744494430720806, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 327, train_loss = 1.872030078084208, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 328, train_loss = 1.8708687759935856, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 329, train_loss = 1.8681367287645116, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 330, train_loss = 1.867158284992911, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 331, train_loss = 1.8649246444692835, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 332, train_loss = 1.8630833476781845, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 333, train_loss = 1.8603486431529745, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 334, train_loss = 1.8598933877656236, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 335, train_loss = 1.8571985935559496, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 336, train_loss = 1.855885182856582, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 337, train_loss = 1.8532272217562422, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 338, train_loss = 1.8516690358519554, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 339, train_loss = 1.849724855273962, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 340, train_loss = 1.848021081299521, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 341, train_loss = 1.846625179052353, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 342, train_loss = 1.8444126397371292, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 343, train_loss = 1.84324235341046, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 344, train_loss = 1.8412283100187778, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 345, train_loss = 1.8396601416170597, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 346, train_loss = 1.838292526663281, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 347, train_loss = 1.8359777616569772, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 348, train_loss = 1.8349200375378132, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 349, train_loss = 1.833073036163114, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 350, train_loss = 1.8316125186393037, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 351, train_loss = 1.8307279869914055, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 352, train_loss = 1.8270984614500776, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 353, train_loss = 1.8266309263417497, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 354, train_loss = 1.8253030218183994, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 355, train_loss = 1.8221328593790531, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 356, train_loss = 1.8213495252421126, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 357, train_loss = 1.8201226753881201, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 358, train_loss = 1.8166870860150084, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 359, train_loss = 1.8171772646019235, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 360, train_loss = 1.8148807808756828, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 361, train_loss = 1.8135306561598554, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 362, train_loss = 1.8117866180837154, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 363, train_loss = 1.8108991049230099, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 364, train_loss = 1.8097323117544875, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 365, train_loss = 1.8073292821645737, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 366, train_loss = 1.8058721609413624, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 367, train_loss = 1.8044246783247218, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 368, train_loss = 1.8028574312338606, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 369, train_loss = 1.8010407350957394, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 370, train_loss = 1.799769427627325, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 371, train_loss = 1.7985106905689463, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 372, train_loss = 1.797263216227293, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 373, train_loss = 1.7964352121343836, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 374, train_loss = 1.7948709303746, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 375, train_loss = 1.7919921824941412, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 376, train_loss = 1.7909735316643491, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 377, train_loss = 1.7899676760425791, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 378, train_loss = 1.7876762511441484, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 379, train_loss = 1.7868644744157791, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 380, train_loss = 1.7857563818106428, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 381, train_loss = 1.7848664335906506, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 382, train_loss = 1.782483940361999, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 383, train_loss = 1.7816760204732418, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 384, train_loss = 1.7796797727933154, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 385, train_loss = 1.7788260877132416, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 386, train_loss = 1.77763055881951, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 387, train_loss = 1.7759147150209174, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 388, train_loss = 1.774223554879427, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 389, train_loss = 1.7737035813042894, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 390, train_loss = 1.771570018143393, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 391, train_loss = 1.7709748795023188, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 392, train_loss = 1.7696568444371223, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 393, train_loss = 1.7676192596554756, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 394, train_loss = 1.7666789504000917, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 395, train_loss = 1.7655560286948457, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 396, train_loss = 1.764745788066648, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 397, train_loss = 1.7633965387940407, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 398, train_loss = 1.7611849283566698, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 399, train_loss = 1.7607017830014229, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 400, train_loss = 1.758893029182218, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 401, train_loss = 1.7590171446790919, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 402, train_loss = 1.7564647482940927, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 403, train_loss = 1.7549258755752817, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 404, train_loss = 1.7547336779534817, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 405, train_loss = 1.7520401887595654, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 406, train_loss = 1.751889158040285, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 407, train_loss = 1.7507919321069494, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 408, train_loss = 1.7498593467171304, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 409, train_loss = 1.748469177633524, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 410, train_loss = 1.747516478120815, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 411, train_loss = 1.7460661170189269, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 412, train_loss = 1.7442167662084103, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 413, train_loss = 1.743643083900679, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 414, train_loss = 1.7427324664895423, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 415, train_loss = 1.7412697710096836, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 416, train_loss = 1.7401912460918538, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 417, train_loss = 1.7383779722149484, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 418, train_loss = 1.7377430250053294, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 419, train_loss = 1.7372751298244111, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 420, train_loss = 1.7360380490426905, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 421, train_loss = 1.7344624337856658, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 422, train_loss = 1.7332358832354657, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 423, train_loss = 1.732924610376358, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 424, train_loss = 1.7307423788006417, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 425, train_loss = 1.7299332730472088, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 426, train_loss = 1.7295439218287356, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 427, train_loss = 1.7275832779705524, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 428, train_loss = 1.7279185689985752, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 429, train_loss = 1.7260872572660446, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 430, train_loss = 1.7251070737838745, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 431, train_loss = 1.724726388871204, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 432, train_loss = 1.7230924926698208, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 433, train_loss = 1.7218440237338655, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 434, train_loss = 1.72011898458004, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 435, train_loss = 1.719872061163187, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 436, train_loss = 1.7186228334903717, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 437, train_loss = 1.7171529829502106, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 438, train_loss = 1.7163952812552452, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 439, train_loss = 1.7149151377379894, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 440, train_loss = 1.7154593206942081, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 441, train_loss = 1.7128505719010718, train_acc = 0.995575221238938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 442, train_loss = 1.7128496058285236, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 443, train_loss = 1.7106639854609966, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 444, train_loss = 1.7114318497478962, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 445, train_loss = 1.7096626262064092, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 446, train_loss = 1.7086374126374722, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 447, train_loss = 1.7078332875971682, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 448, train_loss = 1.7062047098879702, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 449, train_loss = 1.7051380798220634, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 450, train_loss = 1.7044368485803716, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 451, train_loss = 1.7037935617263429, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 452, train_loss = 1.7034226047690026, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 453, train_loss = 1.7026798017323017, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 454, train_loss = 1.7002176865935326, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 455, train_loss = 1.7005128947203048, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 456, train_loss = 1.699235711246729, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 457, train_loss = 1.6984373219311237, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 458, train_loss = 1.6975102325086482, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 459, train_loss = 1.6965167671442032, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 460, train_loss = 1.6943626552820206, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 461, train_loss = 1.6948998384177685, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 462, train_loss = 1.6932785287499428, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 463, train_loss = 1.6924763272400014, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 464, train_loss = 1.6908940635621548, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 465, train_loss = 1.6915369046037085, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 466, train_loss = 1.69044527906226, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 467, train_loss = 1.6889423889224418, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 468, train_loss = 1.6879180148243904, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 469, train_loss = 1.6877719958429225, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 470, train_loss = 1.6863040055031888, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 471, train_loss = 1.685506273061037, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 472, train_loss = 1.6852059178054333, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 473, train_loss = 1.682795142114628, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 474, train_loss = 1.6827680245041847, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 475, train_loss = 1.6816073035006411, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 476, train_loss = 1.681318265676964, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 477, train_loss = 1.6809681368176825, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 478, train_loss = 1.6800019753281958, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 479, train_loss = 1.6782162263989449, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 480, train_loss = 1.6784550857846625, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 481, train_loss = 1.6771785989403725, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 482, train_loss = 1.67614820972085, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 483, train_loss = 1.6754525788128376, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 484, train_loss = 1.6751190188224427, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 485, train_loss = 1.673529288440477, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 486, train_loss = 1.6733315251767635, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 487, train_loss = 1.6716251273755915, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 488, train_loss = 1.6721122239832766, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 489, train_loss = 1.6705807894468307, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 490, train_loss = 1.6708726311917417, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 491, train_loss = 1.669028082222212, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 492, train_loss = 1.6689201009576209, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 493, train_loss = 1.6669351744349115, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 494, train_loss = 1.667096585035324, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 495, train_loss = 1.6657600663602352, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 496, train_loss = 1.6648317277431488, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 497, train_loss = 1.664599532901775, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 498, train_loss = 1.6639247077400796, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 499, train_loss = 1.6630245720152743, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████                                          | 12/30 [1:48:42<2:43:03, 543.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "13th- epoch: 0, train_loss = 110.09092658758163, train_acc = 0.7831858407079646\n",
      "test Acc 0.8729050279329609:\n",
      "13th- epoch: 1, train_loss = 43.50572842359543, train_acc = 0.911504424778761\n",
      "test Acc 0.9273743016759777:\n",
      "13th- epoch: 2, train_loss = 32.57695250585675, train_acc = 0.9338612016767582\n",
      "test Acc 0.9371508379888268:\n",
      "13th- epoch: 3, train_loss = 27.43114423006773, train_acc = 0.9466697717745691\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 4, train_loss = 24.160670079290867, train_acc = 0.952491849091756\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 5, train_loss = 21.76900590956211, train_acc = 0.9563344201210993\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 6, train_loss = 19.91601548716426, train_acc = 0.9591290172333489\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 7, train_loss = 18.421210929751396, train_acc = 0.9609920819748486\n",
      "test Acc 0.9529795158286778:\n",
      "13th- epoch: 8, train_loss = 17.18976143747568, train_acc = 0.9646017699115044\n",
      "test Acc 0.9534450651769087:\n",
      "13th- epoch: 9, train_loss = 16.146117631345987, train_acc = 0.9670470423847228\n",
      "test Acc 0.9553072625698324:\n",
      "13th- epoch: 10, train_loss = 15.24390609934926, train_acc = 0.9680950163018165\n",
      "test Acc 0.957635009310987:\n",
      "13th- epoch: 11, train_loss = 14.463475182652473, train_acc = 0.9701909641360037\n",
      "test Acc 0.9581005586592178:\n",
      "13th- epoch: 12, train_loss = 13.775565788149834, train_acc = 0.9719375873311598\n",
      "test Acc 0.9594972067039106:\n",
      "13th- epoch: 13, train_loss = 13.17413487099111, train_acc = 0.9731020027945971\n",
      "test Acc 0.9599627560521415:\n",
      "13th- epoch: 14, train_loss = 12.6397477183491, train_acc = 0.9739170936190032\n",
      "test Acc 0.9604283054003724:\n",
      "13th- epoch: 15, train_loss = 12.152780449017882, train_acc = 0.975780158360503\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 16, train_loss = 11.704858416691422, train_acc = 0.9767116907312529\n",
      "test Acc 0.9641527001862198:\n",
      "13th- epoch: 17, train_loss = 11.303553994745016, train_acc = 0.9776432231020028\n",
      "test Acc 0.9641527001862198:\n",
      "13th- epoch: 18, train_loss = 10.925146114081144, train_acc = 0.9783418723800652\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 19, train_loss = 10.579710118472576, train_acc = 0.9785747554727526\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 20, train_loss = 10.249598696827888, train_acc = 0.9790405216581276\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 21, train_loss = 9.95016461238265, train_acc = 0.9793898462971589\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 22, train_loss = 9.675427451729774, train_acc = 0.9799720540288775\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 23, train_loss = 9.415800485759974, train_acc = 0.9800884955752213\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 24, train_loss = 9.17142228409648, train_acc = 0.9804378202142524\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 25, train_loss = 8.942325573414564, train_acc = 0.9809035863996274\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 26, train_loss = 8.725924007594585, train_acc = 0.9813693525850024\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 27, train_loss = 8.524328380823135, train_acc = 0.9818351187703773\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 28, train_loss = 8.334308426827192, train_acc = 0.9823008849557522\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 29, train_loss = 8.151540096849203, train_acc = 0.9829995342338146\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 30, train_loss = 7.983971370384097, train_acc = 0.9833488588728458\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 31, train_loss = 7.816931072622538, train_acc = 0.9839310666045645\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 32, train_loss = 7.660880403593183, train_acc = 0.9842803912435957\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 33, train_loss = 7.511805923655629, train_acc = 0.9849790405216581\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 34, train_loss = 7.369370691478252, train_acc = 0.9852119236143456\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 35, train_loss = 7.231006415560842, train_acc = 0.9855612482533768\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 36, train_loss = 7.1026699505746365, train_acc = 0.9860270144387517\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 37, train_loss = 6.975684456527233, train_acc = 0.9862598975314392\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 38, train_loss = 6.8537094462662935, train_acc = 0.9867256637168141\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 39, train_loss = 6.7376257833093405, train_acc = 0.9868421052631579\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 40, train_loss = 6.623968869447708, train_acc = 0.9870749883558454\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 41, train_loss = 6.518400099128485, train_acc = 0.9870749883558454\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 42, train_loss = 6.413576191291213, train_acc = 0.9871914299021891\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 43, train_loss = 6.314727095887065, train_acc = 0.9880065207265952\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 44, train_loss = 6.216482127085328, train_acc = 0.9881229622729389\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 45, train_loss = 6.120723942294717, train_acc = 0.9881229622729389\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 46, train_loss = 6.033357121050358, train_acc = 0.9885887284583139\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 47, train_loss = 5.94482889585197, train_acc = 0.9889380530973452\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 48, train_loss = 5.859721573069692, train_acc = 0.9889380530973452\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 49, train_loss = 5.779682071879506, train_acc = 0.9890544946436889\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 50, train_loss = 5.70134212821722, train_acc = 0.9890544946436889\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 51, train_loss = 5.624774720519781, train_acc = 0.9890544946436889\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 52, train_loss = 5.548904417082667, train_acc = 0.98940381928272\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 53, train_loss = 5.475562117993832, train_acc = 0.98940381928272\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 54, train_loss = 5.405856316909194, train_acc = 0.9896367023754076\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 55, train_loss = 5.338346226140857, train_acc = 0.989869585468095\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 56, train_loss = 5.271549301221967, train_acc = 0.9902189101071263\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 57, train_loss = 5.206240290775895, train_acc = 0.9906846762925011\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 58, train_loss = 5.144962839782238, train_acc = 0.9909175593851887\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 59, train_loss = 5.081425303593278, train_acc = 0.9909175593851887\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 60, train_loss = 5.023509224876761, train_acc = 0.9911504424778761\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 61, train_loss = 4.962730497121811, train_acc = 0.9911504424778761\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 62, train_loss = 4.907284012064338, train_acc = 0.9912668840242198\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 63, train_loss = 4.851602362468839, train_acc = 0.9912668840242198\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 64, train_loss = 4.799065563827753, train_acc = 0.9914997671169073\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 65, train_loss = 4.745917338877916, train_acc = 0.9914997671169073\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 66, train_loss = 4.698105720803142, train_acc = 0.9916162086632511\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 67, train_loss = 4.6491486597806215, train_acc = 0.9916162086632511\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 68, train_loss = 4.600702495314181, train_acc = 0.9916162086632511\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 69, train_loss = 4.55496409535408, train_acc = 0.9916162086632511\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 70, train_loss = 4.50837270822376, train_acc = 0.9916162086632511\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 71, train_loss = 4.463718383572996, train_acc = 0.9917326502095948\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 72, train_loss = 4.421515353024006, train_acc = 0.9917326502095948\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 73, train_loss = 4.379657729528844, train_acc = 0.9917326502095948\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 74, train_loss = 4.338739267550409, train_acc = 0.9917326502095948\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 75, train_loss = 4.297660204581916, train_acc = 0.9917326502095948\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 76, train_loss = 4.260731420479715, train_acc = 0.9919655333022822\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 77, train_loss = 4.221918750554323, train_acc = 0.9918490917559385\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 78, train_loss = 4.18293550144881, train_acc = 0.9919655333022822\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 79, train_loss = 4.145990408025682, train_acc = 0.992081974848626\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 80, train_loss = 4.110330189578235, train_acc = 0.992081974848626\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 81, train_loss = 4.07567775901407, train_acc = 0.9921984163949698\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 82, train_loss = 4.0398516692221165, train_acc = 0.9921984163949698\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 83, train_loss = 4.006053178571165, train_acc = 0.9923148579413135\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 84, train_loss = 3.973677054978907, train_acc = 0.9923148579413135\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 85, train_loss = 3.9419560255482793, train_acc = 0.9923148579413135\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 86, train_loss = 3.9095825916156173, train_acc = 0.9924312994876572\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 87, train_loss = 3.878037642687559, train_acc = 0.9924312994876572\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 88, train_loss = 3.8469484308734536, train_acc = 0.9924312994876572\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 89, train_loss = 3.817705601453781, train_acc = 0.9924312994876572\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 90, train_loss = 3.789967056363821, train_acc = 0.9924312994876572\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 91, train_loss = 3.759803901426494, train_acc = 0.9924312994876572\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 92, train_loss = 3.7332026101648808, train_acc = 0.9924312994876572\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 93, train_loss = 3.7056785253807902, train_acc = 0.9925477410340009\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 94, train_loss = 3.6780006093904376, train_acc = 0.9926641825803446\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 95, train_loss = 3.6526831686496735, train_acc = 0.9926641825803446\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 96, train_loss = 3.626424399204552, train_acc = 0.9926641825803446\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 97, train_loss = 3.600928640924394, train_acc = 0.9926641825803446\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 98, train_loss = 3.576554742641747, train_acc = 0.9926641825803446\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 99, train_loss = 3.55083463806659, train_acc = 0.9927806241266884\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 100, train_loss = 3.526308659464121, train_acc = 0.9927806241266884\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 101, train_loss = 3.503205225802958, train_acc = 0.9927806241266884\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 102, train_loss = 3.4819741621613503, train_acc = 0.9927806241266884\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 103, train_loss = 3.4587849751114845, train_acc = 0.9928970656730322\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 104, train_loss = 3.4370228489860892, train_acc = 0.9928970656730322\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 105, train_loss = 3.4163545444607735, train_acc = 0.9928970656730322\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 106, train_loss = 3.3933413652703166, train_acc = 0.9928970656730322\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 107, train_loss = 3.3740421747788787, train_acc = 0.9931299487657196\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 108, train_loss = 3.3524758284911513, train_acc = 0.9931299487657196\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 109, train_loss = 3.333305071108043, train_acc = 0.9931299487657196\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 110, train_loss = 3.3126649046316743, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 111, train_loss = 3.2932893438264728, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 112, train_loss = 3.275134871713817, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 113, train_loss = 3.257958333939314, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 114, train_loss = 3.236952410079539, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 115, train_loss = 3.220626457594335, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 116, train_loss = 3.20162106025964, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 117, train_loss = 3.1844940185546875, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 118, train_loss = 3.1673891553655267, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 119, train_loss = 3.1495327735319734, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 120, train_loss = 3.1332591734826565, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 121, train_loss = 3.1175016509369016, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 122, train_loss = 3.100326812826097, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 123, train_loss = 3.084248182363808, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 124, train_loss = 3.069181893952191, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 125, train_loss = 3.0536004966124892, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 126, train_loss = 3.035887248814106, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 127, train_loss = 3.0245117442682385, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 128, train_loss = 3.007519873790443, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 129, train_loss = 2.9943713163957, train_acc = 0.9937121564974383\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 130, train_loss = 2.979786743875593, train_acc = 0.9937121564974383\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 131, train_loss = 2.964190846774727, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 132, train_loss = 2.9523676908575, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 133, train_loss = 2.93739253282547, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 134, train_loss = 2.924839994404465, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 135, train_loss = 2.9104733713902533, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 136, train_loss = 2.8988313735462725, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 137, train_loss = 2.88490583980456, train_acc = 0.9939450395901258\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 138, train_loss = 2.8737201443873346, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 139, train_loss = 2.8597520389594138, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 140, train_loss = 2.848189604934305, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 141, train_loss = 2.8345504798926413, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 142, train_loss = 2.824406825006008, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 143, train_loss = 2.8117754622362554, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 144, train_loss = 2.798577794339508, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 145, train_loss = 2.7883133217692375, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 146, train_loss = 2.7759797810576856, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 147, train_loss = 2.7647250718437135, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 148, train_loss = 2.7536980025470257, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 149, train_loss = 2.742251785006374, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 150, train_loss = 2.73132586106658, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 151, train_loss = 2.7219973169267178, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 152, train_loss = 2.7104423134587705, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 153, train_loss = 2.7006699331104755, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 154, train_loss = 2.6899529048241675, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 155, train_loss = 2.680035358760506, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 156, train_loss = 2.669830126222223, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 157, train_loss = 2.659527137875557, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 158, train_loss = 2.649122937116772, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 159, train_loss = 2.638978091534227, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 160, train_loss = 2.629553932696581, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 161, train_loss = 2.620933197438717, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 162, train_loss = 2.6122790523804724, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 163, train_loss = 2.6024407683871686, train_acc = 0.9944108057755007\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 164, train_loss = 2.5936910682357848, train_acc = 0.9944108057755007\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 165, train_loss = 2.584174382034689, train_acc = 0.9944108057755007\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 166, train_loss = 2.573642867151648, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 167, train_loss = 2.564495971892029, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 168, train_loss = 2.5559534705244005, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 169, train_loss = 2.5477087423205376, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 170, train_loss = 2.5390836843289435, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 171, train_loss = 2.5311537235975266, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 172, train_loss = 2.5216642976738513, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 173, train_loss = 2.5138895995914936, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 174, train_loss = 2.5068902210332453, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 175, train_loss = 2.4973645792342722, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 176, train_loss = 2.4893517433665693, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 177, train_loss = 2.4824852286837995, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 178, train_loss = 2.472995340824127, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 179, train_loss = 2.466980017721653, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 180, train_loss = 2.4577967040240765, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 181, train_loss = 2.451196366455406, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 182, train_loss = 2.4445682032965124, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 183, train_loss = 2.4372871690429747, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 184, train_loss = 2.429627075791359, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 185, train_loss = 2.4227695339359343, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 186, train_loss = 2.4162919633090496, train_acc = 0.9945272473218444\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 187, train_loss = 2.408869456499815, train_acc = 0.9946436888681882\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 188, train_loss = 2.4044174761511385, train_acc = 0.9945272473218444\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 189, train_loss = 2.3939970121718943, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 190, train_loss = 2.389675715472549, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 191, train_loss = 2.383729610592127, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 192, train_loss = 2.375746101140976, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 193, train_loss = 2.369867318775505, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 194, train_loss = 2.3630694462917745, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 195, train_loss = 2.3562371297739446, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 196, train_loss = 2.3514499850571156, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 197, train_loss = 2.343290275428444, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 198, train_loss = 2.3381070285104215, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 199, train_loss = 2.33168493071571, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 200, train_loss = 2.325966934207827, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 201, train_loss = 2.3194096139632165, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 202, train_loss = 2.3133100108243525, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 203, train_loss = 2.3065341501496732, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 204, train_loss = 2.3013613808434457, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 205, train_loss = 2.295195362297818, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 206, train_loss = 2.2906580965500325, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 207, train_loss = 2.284969339845702, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 208, train_loss = 2.2790442754048854, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 209, train_loss = 2.2736733593046665, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 210, train_loss = 2.2671099465806037, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 211, train_loss = 2.2626992363948375, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 212, train_loss = 2.2571684035938233, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 213, train_loss = 2.2519004568457603, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 214, train_loss = 2.247093276353553, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 215, train_loss = 2.2422321576159447, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 216, train_loss = 2.2380893651861697, train_acc = 0.9946436888681882\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 217, train_loss = 2.230726720066741, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 218, train_loss = 2.227103194920346, train_acc = 0.9946436888681882\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 219, train_loss = 2.2219271510839462, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 220, train_loss = 2.21696628886275, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 221, train_loss = 2.212177198380232, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 222, train_loss = 2.207174178212881, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 223, train_loss = 2.2025317673105747, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 224, train_loss = 2.198271577479318, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 225, train_loss = 2.1933923948090523, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 226, train_loss = 2.1889718994498253, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 227, train_loss = 2.183638942660764, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 228, train_loss = 2.179760318249464, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 229, train_loss = 2.175069984048605, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 230, train_loss = 2.170331321656704, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 231, train_loss = 2.165796169312671, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 232, train_loss = 2.161397259682417, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 233, train_loss = 2.15739439916797, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 234, train_loss = 2.1524050545413047, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 235, train_loss = 2.1483718517702073, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 236, train_loss = 2.143876187503338, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 237, train_loss = 2.140198614448309, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 238, train_loss = 2.1365506909787655, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 239, train_loss = 2.1311685654800385, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 240, train_loss = 2.12777429074049, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 241, train_loss = 2.1232983868103474, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 242, train_loss = 2.1193994644563645, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 243, train_loss = 2.116198107600212, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 244, train_loss = 2.1113316279370338, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 245, train_loss = 2.107529104920104, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 246, train_loss = 2.1045665442943573, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 247, train_loss = 2.099980878410861, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 248, train_loss = 2.096582118421793, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 249, train_loss = 2.092304439516738, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 250, train_loss = 2.0886644162237644, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 251, train_loss = 2.0852723966818303, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 252, train_loss = 2.0810924370307475, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 253, train_loss = 2.077570992289111, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 254, train_loss = 2.074652514187619, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 255, train_loss = 2.069928587647155, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 256, train_loss = 2.066005722852424, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 257, train_loss = 2.0641381617169827, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 258, train_loss = 2.0605561670381576, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 259, train_loss = 2.0552017390727997, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 260, train_loss = 2.054547343403101, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 261, train_loss = 2.0497085750102997, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 262, train_loss = 2.0464914303738624, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 263, train_loss = 2.0413543458562344, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 264, train_loss = 2.0393362380564213, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 265, train_loss = 2.0359974566381425, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 266, train_loss = 2.032597699435428, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 267, train_loss = 2.0296196278650314, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 268, train_loss = 2.0249659914989024, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 269, train_loss = 2.0230835911352187, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 270, train_loss = 2.0191852264106274, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 271, train_loss = 2.0164785496890545, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 272, train_loss = 2.0124082404654473, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 273, train_loss = 2.0103174820542336, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 274, train_loss = 2.0065837639849633, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 275, train_loss = 2.0042696681339294, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 276, train_loss = 1.9997470763046294, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 277, train_loss = 1.9968210037332028, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 278, train_loss = 1.9940193630754948, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 279, train_loss = 1.990611771820113, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 280, train_loss = 1.9874494187533855, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 281, train_loss = 1.98217448964715, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 282, train_loss = 1.9800980773288757, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 283, train_loss = 1.9767432063817978, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 284, train_loss = 1.9741566579323262, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 285, train_loss = 1.9719459924381226, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 286, train_loss = 1.9681058402638882, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 287, train_loss = 1.9652282781898975, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 288, train_loss = 1.9640239004511386, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 289, train_loss = 1.9592089615762234, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 290, train_loss = 1.9560195989906788, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 291, train_loss = 1.9566695094108582, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 292, train_loss = 1.9508005182724446, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 293, train_loss = 1.9486738767009228, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 294, train_loss = 1.9475002710241824, train_acc = 0.9949930135072194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 295, train_loss = 1.9423936840612441, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 296, train_loss = 1.9406474865972996, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 297, train_loss = 1.9384002399165183, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 298, train_loss = 1.936124611645937, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 299, train_loss = 1.9330733206588775, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 300, train_loss = 1.931103588314727, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 301, train_loss = 1.9284034930169582, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 302, train_loss = 1.9251621912699193, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 303, train_loss = 1.9243655018508434, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 304, train_loss = 1.9211392167489976, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 305, train_loss = 1.918083616765216, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 306, train_loss = 1.91581538063474, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 307, train_loss = 1.9135468527674675, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 308, train_loss = 1.9123887841124088, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 309, train_loss = 1.9094484683591872, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 310, train_loss = 1.9062595043797046, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 311, train_loss = 1.9036645006854087, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 312, train_loss = 1.9019501209259033, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 313, train_loss = 1.9003339398186654, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 314, train_loss = 1.8969652280211449, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 315, train_loss = 1.8953516494948417, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 316, train_loss = 1.89388162153773, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 317, train_loss = 1.8912458952981979, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 318, train_loss = 1.8878367755096406, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 319, train_loss = 1.885847482830286, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 320, train_loss = 1.8828008361160755, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 321, train_loss = 1.8833066733786836, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 322, train_loss = 1.8788244785973802, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 323, train_loss = 1.877184223383665, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 324, train_loss = 1.8743317164480686, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 325, train_loss = 1.8729004189372063, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 326, train_loss = 1.870442962856032, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 327, train_loss = 1.8682410245528445, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 328, train_loss = 1.866678757010959, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 329, train_loss = 1.8649426387855783, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 330, train_loss = 1.8640408962965012, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 331, train_loss = 1.8606639690697193, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 332, train_loss = 1.8578997552394867, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 333, train_loss = 1.85786832368467, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 334, train_loss = 1.853336068452336, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 335, train_loss = 1.8530226337024942, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 336, train_loss = 1.8509753631660715, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 337, train_loss = 1.849840740323998, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 338, train_loss = 1.8472569907316938, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 339, train_loss = 1.8442198360571638, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 340, train_loss = 1.8432343354215845, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 341, train_loss = 1.8426788622746244, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 342, train_loss = 1.8389595784246922, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 343, train_loss = 1.8365648264298216, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 344, train_loss = 1.834892655373551, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 345, train_loss = 1.8343016119906679, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 346, train_loss = 1.8328631644835696, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 347, train_loss = 1.8295919796219096, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 348, train_loss = 1.8284405855229124, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 349, train_loss = 1.8274886198341846, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 350, train_loss = 1.8234234502306208, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 351, train_loss = 1.8236679012188688, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 352, train_loss = 1.820455846725963, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 353, train_loss = 1.8192283859243616, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 354, train_loss = 1.8168850479414687, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 355, train_loss = 1.815646968781948, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 356, train_loss = 1.8147574377944693, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 357, train_loss = 1.8134141390910372, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 358, train_loss = 1.810526912449859, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 359, train_loss = 1.807853096514009, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 360, train_loss = 1.8083525249967352, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 361, train_loss = 1.8052087550750002, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 362, train_loss = 1.8036943500628695, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 363, train_loss = 1.8015479234745726, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 364, train_loss = 1.8028290135553107, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 365, train_loss = 1.79984860366676, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 366, train_loss = 1.7971241971245036, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 367, train_loss = 1.7968180142343044, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 368, train_loss = 1.7949798306217417, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 369, train_loss = 1.7937710210680962, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 370, train_loss = 1.7917400524020195, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 371, train_loss = 1.7882436910877004, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 372, train_loss = 1.7873409440508112, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 373, train_loss = 1.7881178309908137, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 374, train_loss = 1.7851483983686194, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 375, train_loss = 1.7835462242364883, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 376, train_loss = 1.7823797588935122, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 377, train_loss = 1.7795867969980463, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 378, train_loss = 1.7775345804402605, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 379, train_loss = 1.7780918454518542, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 380, train_loss = 1.775352934957482, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 381, train_loss = 1.773813127190806, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 382, train_loss = 1.7734554596245289, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 383, train_loss = 1.7710516043007374, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 384, train_loss = 1.770003559649922, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 385, train_loss = 1.76745004451368, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 386, train_loss = 1.7685538629302755, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 387, train_loss = 1.7660306555917487, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 388, train_loss = 1.7652181187877432, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 389, train_loss = 1.762666211812757, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 390, train_loss = 1.7614549534628168, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 391, train_loss = 1.7598429024219513, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 392, train_loss = 1.7592496672878042, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 393, train_loss = 1.758202894241549, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 394, train_loss = 1.7563038170337677, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 395, train_loss = 1.7540210323641077, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 396, train_loss = 1.7533012045314535, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 397, train_loss = 1.7518612034618855, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 398, train_loss = 1.751956693828106, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 399, train_loss = 1.7485456293215975, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 400, train_loss = 1.748557098209858, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 401, train_loss = 1.7492187345633283, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 402, train_loss = 1.745300135225989, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 403, train_loss = 1.7460471341619268, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 404, train_loss = 1.7422897455981001, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 405, train_loss = 1.7404863759875298, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 406, train_loss = 1.740052675246261, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 407, train_loss = 1.7407829476287588, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 408, train_loss = 1.7370451303431764, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 409, train_loss = 1.7356909090885893, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 410, train_loss = 1.736626579076983, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 411, train_loss = 1.7322777832159773, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 412, train_loss = 1.731751205981709, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 413, train_loss = 1.732205469161272, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 414, train_loss = 1.728395146667026, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 415, train_loss = 1.728905743570067, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 416, train_loss = 1.7274897620081902, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 417, train_loss = 1.7263807617127895, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 418, train_loss = 1.7253069119760767, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 419, train_loss = 1.7261946214130148, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 420, train_loss = 1.7229614444077015, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 421, train_loss = 1.72160305082798, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 422, train_loss = 1.7190580243477598, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 423, train_loss = 1.7193977050483227, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 424, train_loss = 1.716959917335771, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 425, train_loss = 1.717222428531386, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 426, train_loss = 1.7148595713078976, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 427, train_loss = 1.7152190866181627, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 428, train_loss = 1.7136251939227805, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 429, train_loss = 1.7113464685389772, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 430, train_loss = 1.7103212090441957, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 431, train_loss = 1.7105630884179845, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 432, train_loss = 1.708462130278349, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 433, train_loss = 1.7081300852587447, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 434, train_loss = 1.7057385556399822, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 435, train_loss = 1.7077065469929948, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 436, train_loss = 1.7041751990327612, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 437, train_loss = 1.7033045986900106, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 438, train_loss = 1.7030611397931352, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 439, train_loss = 1.7011020282516256, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 440, train_loss = 1.6993882855167612, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 441, train_loss = 1.7012125551700592, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 442, train_loss = 1.6967854039976373, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 443, train_loss = 1.6989962483057752, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 444, train_loss = 1.6935277344891801, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 445, train_loss = 1.6960911663481966, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 446, train_loss = 1.692994687706232, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 447, train_loss = 1.694527999847196, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 448, train_loss = 1.6899212213465944, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 449, train_loss = 1.6930359365651384, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 450, train_loss = 1.6887801116099581, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 451, train_loss = 1.6896248484263197, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 452, train_loss = 1.6876964531838894, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 453, train_loss = 1.6889929188182577, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 454, train_loss = 1.6861800426850095, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 455, train_loss = 1.6851095296442509, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 456, train_loss = 1.6844126483192667, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 457, train_loss = 1.6821833662688732, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 458, train_loss = 1.6839830415556207, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 459, train_loss = 1.6794781647622585, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 460, train_loss = 1.6803064966807142, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 461, train_loss = 1.6777739127865061, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 462, train_loss = 1.6796882785856724, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 463, train_loss = 1.676662601530552, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 464, train_loss = 1.675104288966395, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 465, train_loss = 1.6744484355440363, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 466, train_loss = 1.6745028706500307, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 467, train_loss = 1.673594620078802, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 468, train_loss = 1.67196688556578, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 469, train_loss = 1.67221822461579, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 470, train_loss = 1.6720526590943336, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 471, train_loss = 1.6700025299796835, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 472, train_loss = 1.670690563856624, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 473, train_loss = 1.6678300611674786, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 474, train_loss = 1.6659479141235352, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 475, train_loss = 1.6684413403272629, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 476, train_loss = 1.6643557163188234, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 477, train_loss = 1.6631004264345393, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 478, train_loss = 1.6638473259517923, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 479, train_loss = 1.6625568395247683, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 480, train_loss = 1.6613784419605508, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 481, train_loss = 1.6599891148507595, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 482, train_loss = 1.6619488125434145, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 483, train_loss = 1.658928347111214, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 484, train_loss = 1.6597729449276812, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 485, train_loss = 1.6567195504903793, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 486, train_loss = 1.6561003004317172, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 487, train_loss = 1.657015934586525, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 488, train_loss = 1.6559373624622822, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 489, train_loss = 1.6533883239026181, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 490, train_loss = 1.655794223130215, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 491, train_loss = 1.6519621039624326, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 492, train_loss = 1.6515610975329764, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 493, train_loss = 1.652697301178705, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 494, train_loss = 1.6494256022269838, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 495, train_loss = 1.6486266292631626, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 496, train_loss = 1.649726105213631, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 497, train_loss = 1.6477212086319923, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 498, train_loss = 1.6458339057862759, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 499, train_loss = 1.6479207773809321, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████▎                                       | 13/30 [1:57:45<2:33:54, 543.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "14th- epoch: 0, train_loss = 113.30852463841438, train_acc = 0.8013507219375874\n",
      "test Acc 0.9017690875232774:\n",
      "14th- epoch: 1, train_loss = 42.9876928254962, train_acc = 0.9168607359105729\n",
      "test Acc 0.931098696461825:\n",
      "14th- epoch: 2, train_loss = 33.2076660245657, train_acc = 0.9375873311597578\n",
      "test Acc 0.9380819366852886:\n",
      "14th- epoch: 3, train_loss = 28.21143900230527, train_acc = 0.9466697717745691\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 4, train_loss = 24.910916160792112, train_acc = 0.9529576152771309\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 5, train_loss = 22.459322184324265, train_acc = 0.9573823940381928\n",
      "test Acc 0.9515828677839852:\n",
      "14th- epoch: 6, train_loss = 20.53542087227106, train_acc = 0.9598276665114113\n",
      "test Acc 0.9534450651769087:\n",
      "14th- epoch: 7, train_loss = 18.971129924058914, train_acc = 0.9615742897065673\n",
      "test Acc 0.9548417132216015:\n",
      "14th- epoch: 8, train_loss = 17.681460931897163, train_acc = 0.9637866790870983\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 9, train_loss = 16.597900416702032, train_acc = 0.9662319515603167\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 10, train_loss = 15.685189682990313, train_acc = 0.9673963670237541\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 11, train_loss = 14.881588160991669, train_acc = 0.9687936655798789\n",
      "test Acc 0.9590316573556797:\n",
      "14th- epoch: 12, train_loss = 14.181512136012316, train_acc = 0.9698416394969726\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 13, train_loss = 13.568926014006138, train_acc = 0.9706567303213787\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 14, train_loss = 13.012748816981912, train_acc = 0.9725197950628784\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 15, train_loss = 12.513491794466972, train_acc = 0.9742664182580345\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 16, train_loss = 12.049600580707192, train_acc = 0.9749650675360969\n",
      "test Acc 0.9641527001862198:\n",
      "14th- epoch: 17, train_loss = 11.625849600881338, train_acc = 0.9760130414531905\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 18, train_loss = 11.238334842026234, train_acc = 0.9772938984629715\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 19, train_loss = 10.882617948576808, train_acc = 0.9778761061946902\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 20, train_loss = 10.555007811635733, train_acc = 0.9782254308337215\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 21, train_loss = 10.246837256476283, train_acc = 0.9789240801117839\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 22, train_loss = 9.958257526159286, train_acc = 0.9796227293898463\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 23, train_loss = 9.680565750226378, train_acc = 0.9804378202142524\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 24, train_loss = 9.421164564788342, train_acc = 0.9810200279459711\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 25, train_loss = 9.174606842920184, train_acc = 0.9817186772240335\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 26, train_loss = 8.945085166022182, train_acc = 0.9821844434094085\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 27, train_loss = 8.734862934798002, train_acc = 0.9828830926874709\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 28, train_loss = 8.529927592724562, train_acc = 0.9828830926874709\n",
      "test Acc 0.9664804469273743:\n",
      "14th- epoch: 29, train_loss = 8.336369531229138, train_acc = 0.9833488588728458\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 30, train_loss = 8.158860949799418, train_acc = 0.983698183511877\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 31, train_loss = 7.987096354365349, train_acc = 0.9838146250582208\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 32, train_loss = 7.824702020734549, train_acc = 0.9845132743362832\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 33, train_loss = 7.667334606871009, train_acc = 0.9847461574289706\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 34, train_loss = 7.520242424681783, train_acc = 0.9847461574289706\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 35, train_loss = 7.377742176875472, train_acc = 0.9848625989753144\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 36, train_loss = 7.24269107170403, train_acc = 0.9850954820680019\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 37, train_loss = 7.114774676039815, train_acc = 0.9853283651606893\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 38, train_loss = 6.989352053031325, train_acc = 0.9855612482533768\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 39, train_loss = 6.871144657954574, train_acc = 0.9860270144387517\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 40, train_loss = 6.754548853263259, train_acc = 0.9864927806241267\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 41, train_loss = 6.643742863088846, train_acc = 0.9867256637168141\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 42, train_loss = 6.540375620126724, train_acc = 0.9871914299021891\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 43, train_loss = 6.436501981690526, train_acc = 0.9873078714485328\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 44, train_loss = 6.337523048743606, train_acc = 0.9875407545412203\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 45, train_loss = 6.242024924606085, train_acc = 0.9880065207265952\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 46, train_loss = 6.149354726076126, train_acc = 0.9880065207265952\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 47, train_loss = 6.060608037747443, train_acc = 0.9883558453656265\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 48, train_loss = 5.974411574192345, train_acc = 0.9883558453656265\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 49, train_loss = 5.892142682336271, train_acc = 0.9888216115510013\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 50, train_loss = 5.813154594041407, train_acc = 0.9888216115510013\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 51, train_loss = 5.732816904783249, train_acc = 0.9889380530973452\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 52, train_loss = 5.657952964305878, train_acc = 0.9890544946436889\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 53, train_loss = 5.581861846148968, train_acc = 0.9890544946436889\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 54, train_loss = 5.512912649661303, train_acc = 0.9891709361900326\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 55, train_loss = 5.443669301457703, train_acc = 0.9892873777363763\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 56, train_loss = 5.377917426638305, train_acc = 0.9892873777363763\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 57, train_loss = 5.311465145088732, train_acc = 0.98940381928272\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 58, train_loss = 5.247147764079273, train_acc = 0.9896367023754076\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 59, train_loss = 5.18550178129226, train_acc = 0.9896367023754076\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 60, train_loss = 5.12472674716264, train_acc = 0.9896367023754076\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 61, train_loss = 5.065666232258081, train_acc = 0.989869585468095\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 62, train_loss = 5.007410418242216, train_acc = 0.9901024685607824\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 63, train_loss = 4.952114283107221, train_acc = 0.9904517931998137\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 64, train_loss = 4.899227771908045, train_acc = 0.9904517931998137\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 65, train_loss = 4.84689823910594, train_acc = 0.9905682347461574\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 66, train_loss = 4.79641945566982, train_acc = 0.990801117838845\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 67, train_loss = 4.7454788768664, train_acc = 0.990801117838845\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 68, train_loss = 4.697467087768018, train_acc = 0.990801117838845\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 69, train_loss = 4.648138993419707, train_acc = 0.9910340009315324\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 70, train_loss = 4.600393776781857, train_acc = 0.9911504424778761\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 71, train_loss = 4.555321612395346, train_acc = 0.9912668840242198\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 72, train_loss = 4.51176234241575, train_acc = 0.9913833255705635\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 73, train_loss = 4.464661926031113, train_acc = 0.9914997671169073\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 74, train_loss = 4.424797706305981, train_acc = 0.9914997671169073\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 75, train_loss = 4.382717233151197, train_acc = 0.9918490917559385\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 76, train_loss = 4.340355350635946, train_acc = 0.9918490917559385\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 77, train_loss = 4.3023182125762105, train_acc = 0.9917326502095948\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 78, train_loss = 4.26273287832737, train_acc = 0.9918490917559385\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 79, train_loss = 4.22438242379576, train_acc = 0.9917326502095948\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 80, train_loss = 4.188710211776197, train_acc = 0.9917326502095948\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 81, train_loss = 4.15197376627475, train_acc = 0.9917326502095948\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 82, train_loss = 4.11515826638788, train_acc = 0.9919655333022822\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 83, train_loss = 4.08032897580415, train_acc = 0.9919655333022822\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 84, train_loss = 4.046068231575191, train_acc = 0.9919655333022822\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 85, train_loss = 4.012421112507582, train_acc = 0.992081974848626\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 86, train_loss = 3.980970407836139, train_acc = 0.9921984163949698\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 87, train_loss = 3.947057426907122, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 88, train_loss = 3.9180673621594906, train_acc = 0.9921984163949698\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 89, train_loss = 3.885773948393762, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 90, train_loss = 3.855723191983998, train_acc = 0.9924312994876572\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 91, train_loss = 3.823907144367695, train_acc = 0.9924312994876572\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 92, train_loss = 3.796069481410086, train_acc = 0.9924312994876572\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 93, train_loss = 3.768112520687282, train_acc = 0.9924312994876572\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 94, train_loss = 3.739020314067602, train_acc = 0.9924312994876572\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 95, train_loss = 3.7120954506099224, train_acc = 0.9924312994876572\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 96, train_loss = 3.6841354966163635, train_acc = 0.9925477410340009\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 97, train_loss = 3.6598971923813224, train_acc = 0.9925477410340009\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 98, train_loss = 3.6319219693541527, train_acc = 0.9926641825803446\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 99, train_loss = 3.6057225624099374, train_acc = 0.9926641825803446\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 100, train_loss = 3.580160123296082, train_acc = 0.9927806241266884\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 101, train_loss = 3.5577661469578743, train_acc = 0.9927806241266884\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 102, train_loss = 3.5307998387143016, train_acc = 0.9927806241266884\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 103, train_loss = 3.506818608380854, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 104, train_loss = 3.4861924266442657, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 105, train_loss = 3.461333985440433, train_acc = 0.9928970656730322\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 106, train_loss = 3.4398087998852134, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 107, train_loss = 3.417285074479878, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 108, train_loss = 3.3966386625543237, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 109, train_loss = 3.3767704041674733, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 110, train_loss = 3.3549543023109436, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 111, train_loss = 3.3343989057466388, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 112, train_loss = 3.313109972514212, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 113, train_loss = 3.2957008816301823, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 114, train_loss = 3.2741023898124695, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 115, train_loss = 3.256184565834701, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 116, train_loss = 3.2371650151908398, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 117, train_loss = 3.218063998967409, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 118, train_loss = 3.199791238643229, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 119, train_loss = 3.1828253073617816, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 120, train_loss = 3.164700604043901, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 121, train_loss = 3.1492114663124084, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 122, train_loss = 3.130976601038128, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 123, train_loss = 3.114306555595249, train_acc = 0.9932463903120633\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 124, train_loss = 3.0976358763873577, train_acc = 0.9932463903120633\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 125, train_loss = 3.0843689404428005, train_acc = 0.9934792734047508\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 126, train_loss = 3.06585755944252, train_acc = 0.9934792734047508\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 127, train_loss = 3.050554286688566, train_acc = 0.9934792734047508\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 128, train_loss = 3.0347548075951636, train_acc = 0.9934792734047508\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 129, train_loss = 3.021427024155855, train_acc = 0.9937121564974383\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 130, train_loss = 3.004774650093168, train_acc = 0.9937121564974383\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 131, train_loss = 2.990610271692276, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 132, train_loss = 2.9757512607611716, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 133, train_loss = 2.9614125341176987, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 134, train_loss = 2.947022249456495, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 135, train_loss = 2.93436191836372, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 136, train_loss = 2.9194011888466775, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 137, train_loss = 2.905485653784126, train_acc = 0.9939450395901258\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 138, train_loss = 2.8931597671471536, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 139, train_loss = 2.8802798241376877, train_acc = 0.9941779226828132\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 140, train_loss = 2.866787230130285, train_acc = 0.9939450395901258\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 141, train_loss = 2.85454678023234, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 142, train_loss = 2.841637570410967, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 143, train_loss = 2.830742757767439, train_acc = 0.9941779226828132\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 144, train_loss = 2.816756615880877, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 145, train_loss = 2.8050605952739716, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 146, train_loss = 2.7938651801086962, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 147, train_loss = 2.7817059233784676, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 148, train_loss = 2.7709019244648516, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 149, train_loss = 2.7597484812140465, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 150, train_loss = 2.746914379298687, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 151, train_loss = 2.736286237835884, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 152, train_loss = 2.7263669706881046, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 153, train_loss = 2.7135296030901372, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 154, train_loss = 2.7044337638653815, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 155, train_loss = 2.6939048916101456, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 156, train_loss = 2.6846681111492217, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 157, train_loss = 2.6742523461580276, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 158, train_loss = 2.662844435777515, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 159, train_loss = 2.655033966060728, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 160, train_loss = 2.643776068929583, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 161, train_loss = 2.6350844143889844, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 162, train_loss = 2.6252848492003977, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 163, train_loss = 2.61537978798151, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 164, train_loss = 2.6068259947933257, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 165, train_loss = 2.596980514470488, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 166, train_loss = 2.5886298581026495, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 167, train_loss = 2.579329947475344, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 168, train_loss = 2.5712398886680603, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 169, train_loss = 2.5622276291251183, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 170, train_loss = 2.553620568010956, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 171, train_loss = 2.5439915135502815, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 172, train_loss = 2.5358607568778098, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 173, train_loss = 2.528581292834133, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 174, train_loss = 2.5203554132021964, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 175, train_loss = 2.5120744868181646, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 176, train_loss = 2.5041027651168406, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 177, train_loss = 2.4957914813421667, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 178, train_loss = 2.487398687750101, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 179, train_loss = 2.479367600288242, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 180, train_loss = 2.4722088440321386, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 181, train_loss = 2.4643854186870158, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 182, train_loss = 2.458633705973625, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 183, train_loss = 2.4501039795577526, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 184, train_loss = 2.4426587224006653, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 185, train_loss = 2.4371701613999903, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 186, train_loss = 2.4270429448224604, train_acc = 0.9949930135072194\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 187, train_loss = 2.4220563895069063, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 188, train_loss = 2.41388967493549, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 189, train_loss = 2.408782289829105, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 190, train_loss = 2.4012264534831047, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 191, train_loss = 2.39466210687533, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 192, train_loss = 2.3872382529079914, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 193, train_loss = 2.382865862455219, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 194, train_loss = 2.374549421016127, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 195, train_loss = 2.3700651288963854, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 196, train_loss = 2.361408764962107, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 197, train_loss = 2.354680659715086, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 198, train_loss = 2.350190392229706, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 199, train_loss = 2.343233825173229, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 200, train_loss = 2.338509892579168, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 201, train_loss = 2.3322393149137497, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 202, train_loss = 2.3251079306937754, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 203, train_loss = 2.320563198532909, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 204, train_loss = 2.3144451156258583, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 205, train_loss = 2.3089103647507727, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 206, train_loss = 2.303247867617756, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 207, train_loss = 2.2951072468422353, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 208, train_loss = 2.2921233088709414, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 209, train_loss = 2.285642842296511, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 210, train_loss = 2.2805944210849702, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 211, train_loss = 2.274034528527409, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 212, train_loss = 2.2686825641430914, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 213, train_loss = 2.264023147523403, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 214, train_loss = 2.2579673952423036, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 215, train_loss = 2.25232075760141, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 216, train_loss = 2.2475057183764875, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 217, train_loss = 2.241686087101698, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 218, train_loss = 2.2380255558528006, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 219, train_loss = 2.231854058802128, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 220, train_loss = 2.2282958403229713, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 221, train_loss = 2.2222243808209896, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 222, train_loss = 2.2176802628673613, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 223, train_loss = 2.211963601410389, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 224, train_loss = 2.207601701375097, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 225, train_loss = 2.2030179239809513, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 226, train_loss = 2.197896728757769, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 227, train_loss = 2.192749166395515, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 228, train_loss = 2.1896070265211165, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 229, train_loss = 2.185254244832322, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 230, train_loss = 2.17915328592062, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 231, train_loss = 2.1759111396968365, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 232, train_loss = 2.1715806897263974, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 233, train_loss = 2.1653697416186333, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 234, train_loss = 2.1612341317813843, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 235, train_loss = 2.1568126145284623, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 236, train_loss = 2.1527168452739716, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 237, train_loss = 2.150162189034745, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 238, train_loss = 2.1455088157672435, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 239, train_loss = 2.1402464259881526, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 240, train_loss = 2.135175708681345, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 241, train_loss = 2.131518104346469, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 242, train_loss = 2.1286461937706918, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 243, train_loss = 2.1235645811539143, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 244, train_loss = 2.118826589314267, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 245, train_loss = 2.1150617636740208, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 246, train_loss = 2.1116165332496166, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 247, train_loss = 2.1092483066022396, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 248, train_loss = 2.103751255897805, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 249, train_loss = 2.101374886929989, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 250, train_loss = 2.097540870308876, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 251, train_loss = 2.0915139478165656, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 252, train_loss = 2.0892395477276295, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 253, train_loss = 2.0864937033038586, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 254, train_loss = 2.080932065844536, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 255, train_loss = 2.0783808703999966, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 256, train_loss = 2.0736264798324555, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 257, train_loss = 2.0704649921972305, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 258, train_loss = 2.0669557116925716, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 259, train_loss = 2.0646927393972874, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 260, train_loss = 2.0597955447155982, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 261, train_loss = 2.0571974378544837, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 262, train_loss = 2.0534369100350887, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 263, train_loss = 2.0496501710731536, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 264, train_loss = 2.0448949460405856, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 265, train_loss = 2.043260934529826, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 266, train_loss = 2.0399987660348415, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 267, train_loss = 2.03608151525259, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 268, train_loss = 2.0333804215770215, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 269, train_loss = 2.031487725675106, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 270, train_loss = 2.0259356896858662, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 271, train_loss = 2.0239564913790673, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 272, train_loss = 2.0189700797200203, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 273, train_loss = 2.017773351399228, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 274, train_loss = 2.0140349317807704, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 275, train_loss = 2.010870285332203, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 276, train_loss = 2.008557104738429, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 277, train_loss = 2.0067574169952422, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 278, train_loss = 2.000728639541194, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 279, train_loss = 1.9992605845909566, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 280, train_loss = 1.9960768322926015, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 281, train_loss = 1.9946822698693722, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 282, train_loss = 1.9906674262601882, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 283, train_loss = 1.9885308258235455, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 284, train_loss = 1.9842001423239708, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 285, train_loss = 1.981854974059388, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 286, train_loss = 1.9794794234912843, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 287, train_loss = 1.9759466249961406, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 288, train_loss = 1.9737867538351566, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 289, train_loss = 1.9704999823588878, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 290, train_loss = 1.9679293024819344, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 291, train_loss = 1.9659002285916358, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 292, train_loss = 1.9628209993243217, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 293, train_loss = 1.9582552562933415, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 294, train_loss = 1.9583264142274857, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 295, train_loss = 1.9544083636719733, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 296, train_loss = 1.9531192146241665, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 297, train_loss = 1.948346097022295, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 298, train_loss = 1.9471166208386421, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 299, train_loss = 1.9432523536961526, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 300, train_loss = 1.9427524332422763, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 301, train_loss = 1.9396912194788456, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 302, train_loss = 1.935838658362627, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 303, train_loss = 1.9334101229906082, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 304, train_loss = 1.932693423004821, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 305, train_loss = 1.9277515907306224, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 306, train_loss = 1.9277382902801037, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 307, train_loss = 1.9235881145577878, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 308, train_loss = 1.9211431045550853, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 309, train_loss = 1.919030025601387, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 310, train_loss = 1.916687224060297, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 311, train_loss = 1.9151728004217148, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 312, train_loss = 1.911628883332014, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 313, train_loss = 1.9094792094547302, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 314, train_loss = 1.9082324493210763, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 315, train_loss = 1.905373292742297, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 316, train_loss = 1.9032083228230476, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 317, train_loss = 1.9013863690197468, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 318, train_loss = 1.8992490048985928, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 319, train_loss = 1.8949397567193955, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 320, train_loss = 1.8942283417563885, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 321, train_loss = 1.892009637085721, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 322, train_loss = 1.8892449762206525, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 323, train_loss = 1.8874745331704617, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 324, train_loss = 1.8846140466630459, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 325, train_loss = 1.8825446516275406, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 326, train_loss = 1.8811708081047982, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 327, train_loss = 1.8781251274049282, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 328, train_loss = 1.877354099182412, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 329, train_loss = 1.8758274305146188, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 330, train_loss = 1.8724125537555665, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 331, train_loss = 1.870134426979348, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 332, train_loss = 1.868156121345237, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 333, train_loss = 1.8675638872664422, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 334, train_loss = 1.8651331514120102, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 335, train_loss = 1.8611504312139004, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 336, train_loss = 1.862273869337514, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 337, train_loss = 1.8585554112214595, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 338, train_loss = 1.8564215216320008, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 339, train_loss = 1.8538281444925815, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 340, train_loss = 1.8537259560544044, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 341, train_loss = 1.8504818342626095, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 342, train_loss = 1.8494366891682148, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 343, train_loss = 1.8461829274892807, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 344, train_loss = 1.8452523772139102, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 345, train_loss = 1.843790502520278, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 346, train_loss = 1.8409604702610523, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 347, train_loss = 1.838407913921401, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 348, train_loss = 1.837811590405181, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 349, train_loss = 1.834402808221057, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 350, train_loss = 1.8343076023738831, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 351, train_loss = 1.8320425525307655, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 352, train_loss = 1.829210214316845, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 353, train_loss = 1.8291990656871349, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 354, train_loss = 1.825707932235673, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 355, train_loss = 1.8241937048733234, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 356, train_loss = 1.8226279083173722, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 357, train_loss = 1.8220502163749188, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 358, train_loss = 1.818298313766718, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 359, train_loss = 1.8187768820207566, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 360, train_loss = 1.8159594100434333, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 361, train_loss = 1.8143254679162055, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 362, train_loss = 1.8112085424363613, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 363, train_loss = 1.8111854443559423, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 364, train_loss = 1.8082137468736619, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 365, train_loss = 1.8076748922467232, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 366, train_loss = 1.8066767379641533, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 367, train_loss = 1.8037693712394685, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 368, train_loss = 1.8028926216065884, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 369, train_loss = 1.8017365336418152, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 370, train_loss = 1.7999748712172732, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 371, train_loss = 1.7974062338471413, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 372, train_loss = 1.7959987992653623, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 373, train_loss = 1.7949712723493576, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 374, train_loss = 1.7919151484966278, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 375, train_loss = 1.791727559058927, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 376, train_loss = 1.789903582422994, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 377, train_loss = 1.7875547396251932, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 378, train_loss = 1.7862843945622444, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 379, train_loss = 1.7859432908007875, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 380, train_loss = 1.7828569151461124, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 381, train_loss = 1.7812118182191625, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 382, train_loss = 1.780743936658837, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 383, train_loss = 1.7794288968434557, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 384, train_loss = 1.7774114249041304, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 385, train_loss = 1.7761632961919531, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 386, train_loss = 1.7750716470181942, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 387, train_loss = 1.7731182724237442, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 388, train_loss = 1.771667638211511, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 389, train_loss = 1.7697934744646773, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 390, train_loss = 1.7690113497665152, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 391, train_loss = 1.7673353515565395, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 392, train_loss = 1.7657359776785597, train_acc = 0.9959245458779693\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 393, train_loss = 1.764423924149014, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 394, train_loss = 1.7643446251749992, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 395, train_loss = 1.7620241033146158, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 396, train_loss = 1.7602889550616965, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 397, train_loss = 1.758780237287283, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 398, train_loss = 1.7569362731883302, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 399, train_loss = 1.756671273498796, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 400, train_loss = 1.7551846479764208, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 401, train_loss = 1.7530080042779446, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 402, train_loss = 1.7528768740594387, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 403, train_loss = 1.750398567528464, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 404, train_loss = 1.7497160099446774, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 405, train_loss = 1.748471281141974, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 406, train_loss = 1.747197782038711, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 407, train_loss = 1.744908433407545, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 408, train_loss = 1.7431032545864582, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 409, train_loss = 1.7440877122571692, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 410, train_loss = 1.7415234135696664, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 411, train_loss = 1.739606666029431, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 412, train_loss = 1.7389489064225927, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 413, train_loss = 1.7377244246890768, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 414, train_loss = 1.736982231377624, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 415, train_loss = 1.7355882985284552, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 416, train_loss = 1.7342182447900996, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 417, train_loss = 1.7325189001858234, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 418, train_loss = 1.7321571608772501, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 419, train_loss = 1.7313714908668771, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 420, train_loss = 1.7294612663099542, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 421, train_loss = 1.7271953473100439, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 422, train_loss = 1.7281451672315598, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 423, train_loss = 1.7252878112485632, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 424, train_loss = 1.7242165058851242, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 425, train_loss = 1.7225776066770777, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 426, train_loss = 1.7217603685567155, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 427, train_loss = 1.720644909888506, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 428, train_loss = 1.7197141498327255, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 429, train_loss = 1.7190860273549333, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 430, train_loss = 1.7174012860050425, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 431, train_loss = 1.7165623469045386, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 432, train_loss = 1.7149980490794405, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 433, train_loss = 1.7143766594817862, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 434, train_loss = 1.7127249985933304, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 435, train_loss = 1.7116312818834558, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 436, train_loss = 1.710764421732165, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 437, train_loss = 1.7085020132362843, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 438, train_loss = 1.7084907864918932, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 439, train_loss = 1.7074332684278488, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 440, train_loss = 1.7062410451471806, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 441, train_loss = 1.7058812318136916, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 442, train_loss = 1.7034602524945512, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 443, train_loss = 1.7041202721884474, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 444, train_loss = 1.7020158605882898, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 445, train_loss = 1.7010691264877096, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 446, train_loss = 1.700185506255366, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 447, train_loss = 1.6993333660066128, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 448, train_loss = 1.698043517768383, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 449, train_loss = 1.6969594297697768, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 450, train_loss = 1.6960982432356104, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 451, train_loss = 1.694388127536513, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 452, train_loss = 1.6941009387373924, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 453, train_loss = 1.6927277768263593, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 454, train_loss = 1.6910674957325682, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 455, train_loss = 1.6902184449136257, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 456, train_loss = 1.6910497645149007, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 457, train_loss = 1.6877683153143153, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 458, train_loss = 1.6878590198466554, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 459, train_loss = 1.6861978707602248, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 460, train_loss = 1.6867896852781996, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 461, train_loss = 1.6846037717768922, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 462, train_loss = 1.6834306282689795, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 463, train_loss = 1.6826300248503685, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 464, train_loss = 1.6823314490029588, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 465, train_loss = 1.681455691694282, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 466, train_loss = 1.6796565490076318, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 467, train_loss = 1.677928812801838, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 468, train_loss = 1.6779902651906013, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 469, train_loss = 1.677242043078877, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 470, train_loss = 1.6761387983569875, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 471, train_loss = 1.6756883077323437, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 472, train_loss = 1.674496952444315, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 473, train_loss = 1.6725065236678347, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 474, train_loss = 1.6723746247589588, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 475, train_loss = 1.6717818801989779, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 476, train_loss = 1.6705718202283606, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 477, train_loss = 1.6694257172057405, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 478, train_loss = 1.669011784135364, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 479, train_loss = 1.667427647858858, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 480, train_loss = 1.6663618186721578, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 481, train_loss = 1.666496653109789, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 482, train_loss = 1.6644297490129247, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 483, train_loss = 1.6638073101639748, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 484, train_loss = 1.6632302092621103, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 485, train_loss = 1.6622437176993117, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 486, train_loss = 1.6607145542511716, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 487, train_loss = 1.6603576876223087, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 488, train_loss = 1.6592515470692888, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 489, train_loss = 1.6591428443789482, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 490, train_loss = 1.6572641817620024, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 491, train_loss = 1.6578298272797838, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 492, train_loss = 1.6560131931910291, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 493, train_loss = 1.655459483503364, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 494, train_loss = 1.6541040340671316, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 495, train_loss = 1.654025531024672, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 496, train_loss = 1.652600904344581, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 497, train_loss = 1.6517744163284078, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 498, train_loss = 1.6508202416589484, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 499, train_loss = 1.650053758174181, train_acc = 0.996040987424313\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████████████████████████▋                                     | 14/30 [2:06:47<2:24:47, 542.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "15th- epoch: 0, train_loss = 120.19700223207474, train_acc = 0.78959012575687\n",
      "test Acc 0.883147113594041:\n",
      "15th- epoch: 1, train_loss = 42.51785994321108, train_acc = 0.9147647880763856\n",
      "test Acc 0.925512104283054:\n",
      "15th- epoch: 2, train_loss = 31.886488676071167, train_acc = 0.9329296693060084\n",
      "test Acc 0.9376163873370578:\n",
      "15th- epoch: 3, train_loss = 26.47762479633093, train_acc = 0.9421285514671635\n",
      "test Acc 0.9441340782122905:\n",
      "15th- epoch: 4, train_loss = 22.96200193092227, train_acc = 0.9503959012575687\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 5, train_loss = 20.405875209718943, train_acc = 0.9568001863064741\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 6, train_loss = 18.4793893545866, train_acc = 0.959944108057755\n",
      "test Acc 0.9506517690875232:\n",
      "15th- epoch: 7, train_loss = 16.95504231750965, train_acc = 0.9622729389846297\n",
      "test Acc 0.9529795158286778:\n",
      "15th- epoch: 8, train_loss = 15.72276185452938, train_acc = 0.9648346530041919\n",
      "test Acc 0.9548417132216015:\n",
      "15th- epoch: 9, train_loss = 14.68926377594471, train_acc = 0.9678621332091291\n",
      "test Acc 0.9553072625698324:\n",
      "15th- epoch: 10, train_loss = 13.812160609290004, train_acc = 0.9691429902189101\n",
      "test Acc 0.9567039106145251:\n",
      "15th- epoch: 11, train_loss = 13.060637030750513, train_acc = 0.9712389380530974\n",
      "test Acc 0.9581005586592178:\n",
      "15th- epoch: 12, train_loss = 12.402358908206224, train_acc = 0.9738006520726595\n",
      "test Acc 0.9590316573556797:\n",
      "15th- epoch: 13, train_loss = 11.82563004270196, train_acc = 0.9751979506287843\n",
      "test Acc 0.9604283054003724:\n",
      "15th- epoch: 14, train_loss = 11.312706034630537, train_acc = 0.9763623660922217\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 15, train_loss = 10.846309538930655, train_acc = 0.9776432231020028\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 16, train_loss = 10.425774704664946, train_acc = 0.9785747554727526\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 17, train_loss = 10.038079485297203, train_acc = 0.9795062878435026\n",
      "test Acc 0.9618249534450651:\n",
      "15th- epoch: 18, train_loss = 9.684973511844873, train_acc = 0.9804378202142524\n",
      "test Acc 0.962756052141527:\n",
      "15th- epoch: 19, train_loss = 9.363064844161272, train_acc = 0.9812529110386586\n",
      "test Acc 0.9632216014897579:\n",
      "15th- epoch: 20, train_loss = 9.0675631724298, train_acc = 0.9817186772240335\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 21, train_loss = 8.788413185626268, train_acc = 0.9824173265020959\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 22, train_loss = 8.530497413128614, train_acc = 0.9828830926874709\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 23, train_loss = 8.287622332572937, train_acc = 0.9831159757801584\n",
      "test Acc 0.9641527001862198:\n",
      "15th- epoch: 24, train_loss = 8.060553845018148, train_acc = 0.983698183511877\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 25, train_loss = 7.846408449113369, train_acc = 0.9846297158826269\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 26, train_loss = 7.645250074565411, train_acc = 0.9848625989753144\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 27, train_loss = 7.458559758961201, train_acc = 0.985910572892408\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 28, train_loss = 7.275820642709732, train_acc = 0.9861434559850955\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 29, train_loss = 7.108549607917666, train_acc = 0.9862598975314392\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 30, train_loss = 6.949392171576619, train_acc = 0.9867256637168141\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 31, train_loss = 6.79812428355217, train_acc = 0.9868421052631579\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 32, train_loss = 6.6532246340066195, train_acc = 0.9870749883558454\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 33, train_loss = 6.516413854435086, train_acc = 0.9871914299021891\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 34, train_loss = 6.38668953999877, train_acc = 0.9873078714485328\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 35, train_loss = 6.261634549126029, train_acc = 0.9877736376339078\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 36, train_loss = 6.141837142407894, train_acc = 0.9880065207265952\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 37, train_loss = 6.0286282654851675, train_acc = 0.9884722869119702\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 38, train_loss = 5.9205313846468925, train_acc = 0.9887051700046576\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 39, train_loss = 5.813895832747221, train_acc = 0.9888216115510013\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 40, train_loss = 5.715205727145076, train_acc = 0.9892873777363763\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 41, train_loss = 5.622322542592883, train_acc = 0.9897531439217513\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 42, train_loss = 5.533542137593031, train_acc = 0.9902189101071263\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 43, train_loss = 5.446670969948173, train_acc = 0.9904517931998137\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 44, train_loss = 5.361507076770067, train_acc = 0.990801117838845\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 45, train_loss = 5.283751839771867, train_acc = 0.9909175593851887\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 46, train_loss = 5.201742343604565, train_acc = 0.9912668840242198\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 47, train_loss = 5.129640653729439, train_acc = 0.9912668840242198\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 48, train_loss = 5.054996022954583, train_acc = 0.9913833255705635\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 49, train_loss = 4.986048119142652, train_acc = 0.9914997671169073\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 50, train_loss = 4.919198689982295, train_acc = 0.9917326502095948\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 51, train_loss = 4.854849223047495, train_acc = 0.9919655333022822\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 52, train_loss = 4.792188750579953, train_acc = 0.9918490917559385\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 53, train_loss = 4.732655553147197, train_acc = 0.9919655333022822\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 54, train_loss = 4.674993395805359, train_acc = 0.9921984163949698\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 55, train_loss = 4.618781052529812, train_acc = 0.9921984163949698\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 56, train_loss = 4.564967685379088, train_acc = 0.9921984163949698\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 57, train_loss = 4.513548879884183, train_acc = 0.9921984163949698\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 58, train_loss = 4.460555977188051, train_acc = 0.9921984163949698\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 59, train_loss = 4.410846217535436, train_acc = 0.9923148579413135\n",
      "test Acc 0.9748603351955307:\n",
      "15th- epoch: 60, train_loss = 4.364847376011312, train_acc = 0.9923148579413135\n",
      "test Acc 0.9748603351955307:\n",
      "15th- epoch: 61, train_loss = 4.315717997960746, train_acc = 0.9924312994876572\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 62, train_loss = 4.271970504894853, train_acc = 0.9925477410340009\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 63, train_loss = 4.226193496026099, train_acc = 0.9926641825803446\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 64, train_loss = 4.184341579675674, train_acc = 0.9928970656730322\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 65, train_loss = 4.1394585920497775, train_acc = 0.9928970656730322\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 66, train_loss = 4.100059353746474, train_acc = 0.9928970656730322\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 67, train_loss = 4.06139924377203, train_acc = 0.9928970656730322\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 68, train_loss = 4.021874672733247, train_acc = 0.9928970656730322\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 69, train_loss = 3.984509323723614, train_acc = 0.9931299487657196\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 70, train_loss = 3.947430876083672, train_acc = 0.9931299487657196\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 71, train_loss = 3.9132202556356788, train_acc = 0.9931299487657196\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 72, train_loss = 3.8775280145928264, train_acc = 0.9932463903120633\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 73, train_loss = 3.844138733111322, train_acc = 0.9932463903120633\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 74, train_loss = 3.8111548982560635, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 75, train_loss = 3.778567850589752, train_acc = 0.9934792734047508\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 76, train_loss = 3.7481944477185607, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 77, train_loss = 3.718053807504475, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 78, train_loss = 3.685221217572689, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 79, train_loss = 3.6570594618096948, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 80, train_loss = 3.6269465796649456, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 81, train_loss = 3.599825312383473, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 82, train_loss = 3.5708592673763633, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 83, train_loss = 3.5440067620947957, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 84, train_loss = 3.5181600777432323, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 85, train_loss = 3.4921648064628243, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 86, train_loss = 3.4666329072788358, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 87, train_loss = 3.4415107518434525, train_acc = 0.9935957149510946\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 88, train_loss = 3.4179969169199467, train_acc = 0.9935957149510946\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 89, train_loss = 3.393079844303429, train_acc = 0.9935957149510946\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 90, train_loss = 3.371376105584204, train_acc = 0.9937121564974383\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 91, train_loss = 3.3468746365979314, train_acc = 0.9937121564974383\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 92, train_loss = 3.324560232460499, train_acc = 0.993828598043782\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 93, train_loss = 3.3030748702585697, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 94, train_loss = 3.2808144381269813, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 95, train_loss = 3.2597587602213025, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 96, train_loss = 3.238640953786671, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 97, train_loss = 3.2176176672801375, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 98, train_loss = 3.1989645613357425, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 99, train_loss = 3.17787316814065, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 100, train_loss = 3.159488745033741, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 101, train_loss = 3.1400233833119273, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 102, train_loss = 3.1205136300995946, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 103, train_loss = 3.1031935596838593, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 104, train_loss = 3.083836250938475, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 105, train_loss = 3.0641374783590436, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 106, train_loss = 3.0455912612378597, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 107, train_loss = 3.028779727872461, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 108, train_loss = 3.011084859725088, train_acc = 0.9945272473218444\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 109, train_loss = 2.9944301582872868, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 110, train_loss = 2.977025573607534, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 111, train_loss = 2.96050001680851, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 112, train_loss = 2.9449452995322645, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 113, train_loss = 2.9298546030186117, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 114, train_loss = 2.9151265933178365, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 115, train_loss = 2.8995779305696487, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 116, train_loss = 2.8847259269095957, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 117, train_loss = 2.8699968084692955, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 118, train_loss = 2.8566069938242435, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 119, train_loss = 2.8434155895374715, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 120, train_loss = 2.8291652821935713, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 121, train_loss = 2.816349634435028, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 122, train_loss = 2.8027765243314207, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 123, train_loss = 2.7888558483682573, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 124, train_loss = 2.7763043269515038, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 125, train_loss = 2.7635001577436924, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 126, train_loss = 2.751300548668951, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 127, train_loss = 2.739091206341982, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 128, train_loss = 2.727911554276943, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 129, train_loss = 2.7141576446592808, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 130, train_loss = 2.703711900860071, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 131, train_loss = 2.69148882990703, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 132, train_loss = 2.6800172082148492, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 133, train_loss = 2.669774306472391, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 134, train_loss = 2.6588983512483537, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 135, train_loss = 2.6486070095561445, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 136, train_loss = 2.6362798674963415, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 137, train_loss = 2.6265120804309845, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 138, train_loss = 2.616116741206497, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 139, train_loss = 2.6059602298773825, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 140, train_loss = 2.5970581471920013, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 141, train_loss = 2.586566425859928, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 142, train_loss = 2.5767662972211838, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 143, train_loss = 2.5686590932309628, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 144, train_loss = 2.5571544356644154, train_acc = 0.9953423381462506\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 145, train_loss = 2.5478934473358095, train_acc = 0.9953423381462506\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 146, train_loss = 2.539174938108772, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 147, train_loss = 2.5302457720972598, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 148, train_loss = 2.5205173254944384, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 149, train_loss = 2.5130036659538746, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 150, train_loss = 2.502740120049566, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 151, train_loss = 2.495870105922222, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 152, train_loss = 2.486542528960854, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 153, train_loss = 2.47770152753219, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 154, train_loss = 2.4701258279383183, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 155, train_loss = 2.462787119206041, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 156, train_loss = 2.4539304063655436, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 157, train_loss = 2.445268653333187, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 158, train_loss = 2.4392322772182524, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 159, train_loss = 2.431332105305046, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 160, train_loss = 2.424599129706621, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 161, train_loss = 2.415153124835342, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 162, train_loss = 2.4086138233542442, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 163, train_loss = 2.4015509583987296, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 164, train_loss = 2.3937464989721775, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 165, train_loss = 2.387254759669304, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 166, train_loss = 2.379048941191286, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 167, train_loss = 2.3738595522008836, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 168, train_loss = 2.36661778902635, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 169, train_loss = 2.3597208322025836, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 170, train_loss = 2.3530851914547384, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 171, train_loss = 2.3464619666337967, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 172, train_loss = 2.3407535045407712, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 173, train_loss = 2.3337267176248133, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 174, train_loss = 2.327782807406038, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 175, train_loss = 2.3210049346089363, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 176, train_loss = 2.314903125166893, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 177, train_loss = 2.3090136745013297, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 178, train_loss = 2.3018215782940388, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 179, train_loss = 2.296100022736937, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 180, train_loss = 2.290161943528801, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 181, train_loss = 2.2850460447371006, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 182, train_loss = 2.279193150345236, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 183, train_loss = 2.2721174196340144, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 184, train_loss = 2.267542737070471, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 185, train_loss = 2.2620731010101736, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 186, train_loss = 2.256677115801722, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 187, train_loss = 2.2507384121418, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 188, train_loss = 2.2452319003641605, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 189, train_loss = 2.239760334370658, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 190, train_loss = 2.234940767288208, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 191, train_loss = 2.2291912536602467, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 192, train_loss = 2.2245910454075783, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 193, train_loss = 2.219698954373598, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 194, train_loss = 2.21468673273921, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 195, train_loss = 2.2083666771650314, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 196, train_loss = 2.2046819403767586, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 197, train_loss = 2.1998921260237694, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 198, train_loss = 2.1942810777109116, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 199, train_loss = 2.1898349549155682, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 200, train_loss = 2.185247457353398, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 201, train_loss = 2.1797047432046384, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 202, train_loss = 2.175821363925934, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 203, train_loss = 2.170012043090537, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 204, train_loss = 2.1660590432584286, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 205, train_loss = 2.161574723897502, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 206, train_loss = 2.156081673922017, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 207, train_loss = 2.153136131586507, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 208, train_loss = 2.1476604752242565, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 209, train_loss = 2.1441949780564755, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 210, train_loss = 2.139405157417059, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 211, train_loss = 2.1351228791754693, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 212, train_loss = 2.132037190021947, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 213, train_loss = 2.1271758403163403, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 214, train_loss = 2.122347816824913, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 215, train_loss = 2.117430053651333, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 216, train_loss = 2.1144631456118077, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 217, train_loss = 2.1100426577031612, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 218, train_loss = 2.106122085126117, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 219, train_loss = 2.102887035580352, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 220, train_loss = 2.097311533987522, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 221, train_loss = 2.0943121078889817, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 222, train_loss = 2.090027501108125, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 223, train_loss = 2.0859166246373206, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 224, train_loss = 2.083147180499509, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 225, train_loss = 2.080071510048583, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 226, train_loss = 2.075820115627721, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 227, train_loss = 2.0717744280118495, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 228, train_loss = 2.0673562362790108, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 229, train_loss = 2.064140050439164, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 230, train_loss = 2.0607116061728448, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 231, train_loss = 2.05647782352753, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 232, train_loss = 2.0530097659211606, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 233, train_loss = 2.0488053373992443, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 234, train_loss = 2.0471415247302502, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 235, train_loss = 2.042754791676998, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 236, train_loss = 2.0396916083991528, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 237, train_loss = 2.036012762458995, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 238, train_loss = 2.0328010718803853, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 239, train_loss = 2.0294213071465492, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 240, train_loss = 2.026757877320051, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 241, train_loss = 2.022131811827421, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 242, train_loss = 2.0198871977627277, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 243, train_loss = 2.016429476439953, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 244, train_loss = 2.013034575851634, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 245, train_loss = 2.0105033069849014, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 246, train_loss = 2.006331517128274, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 247, train_loss = 2.004403956234455, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 248, train_loss = 2.0009665340185165, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 249, train_loss = 1.9978561613243073, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 250, train_loss = 1.9940864008385688, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 251, train_loss = 1.9913520961999893, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 252, train_loss = 1.9892916604876518, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 253, train_loss = 1.9864351388532668, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 254, train_loss = 1.9817825220525265, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 255, train_loss = 1.9804669097065926, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 256, train_loss = 1.9767774033825845, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 257, train_loss = 1.9742140546441078, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 258, train_loss = 1.9716686096508056, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 259, train_loss = 1.9689130634069443, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 260, train_loss = 1.9647123899776489, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 261, train_loss = 1.9639332045335323, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 262, train_loss = 1.9605645537376404, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 263, train_loss = 1.9563675958197564, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 264, train_loss = 1.954430989921093, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 265, train_loss = 1.9521871469914913, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 266, train_loss = 1.9486266511958092, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 267, train_loss = 1.946632944047451, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 268, train_loss = 1.9444751043338329, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 269, train_loss = 1.9420338806230575, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 270, train_loss = 1.937974788248539, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 271, train_loss = 1.9371696102898568, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 272, train_loss = 1.93471788498573, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 273, train_loss = 1.931366165401414, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 274, train_loss = 1.929112933576107, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 275, train_loss = 1.9261342224199325, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 276, train_loss = 1.925012357532978, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 277, train_loss = 1.9220374450087547, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 278, train_loss = 1.9181563828606158, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 279, train_loss = 1.917699919315055, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 280, train_loss = 1.914744158508256, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 281, train_loss = 1.9120892770588398, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 282, train_loss = 1.9098048906307667, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 283, train_loss = 1.907849320443347, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 284, train_loss = 1.9052159537095577, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 285, train_loss = 1.9011586904525757, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 286, train_loss = 1.9004416577517986, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 287, train_loss = 1.8973939046263695, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 288, train_loss = 1.8968000847380608, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 289, train_loss = 1.8926724183838814, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 290, train_loss = 1.8913550662109628, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 291, train_loss = 1.8890163898468018, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 292, train_loss = 1.8882517218589783, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 293, train_loss = 1.8845167644321918, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 294, train_loss = 1.8834787321975455, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 295, train_loss = 1.8807030072202906, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 296, train_loss = 1.8795435341307893, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 297, train_loss = 1.8765311116585508, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 298, train_loss = 1.8744758516550064, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 299, train_loss = 1.871026168228127, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 300, train_loss = 1.8709773421287537, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 301, train_loss = 1.8682353608310223, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 302, train_loss = 1.8666547375032678, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 303, train_loss = 1.864154884009622, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 304, train_loss = 1.8617916455259547, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 305, train_loss = 1.8599669598042965, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 306, train_loss = 1.8594686376163736, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 307, train_loss = 1.8557695299386978, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 308, train_loss = 1.8548809811472893, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 309, train_loss = 1.8518692664802074, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 310, train_loss = 1.8515000343322754, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 311, train_loss = 1.8477435918757692, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 312, train_loss = 1.8459791615605354, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 313, train_loss = 1.8458489328622818, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 314, train_loss = 1.8443841263651848, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 315, train_loss = 1.8401296101510525, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 316, train_loss = 1.8381830416619778, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 317, train_loss = 1.838411116390489, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 318, train_loss = 1.8360398324439302, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 319, train_loss = 1.8331873677670956, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 320, train_loss = 1.8331578994402662, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 321, train_loss = 1.829754932434298, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 322, train_loss = 1.8280338495969772, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 323, train_loss = 1.8271360384533182, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 324, train_loss = 1.8251003721961752, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 325, train_loss = 1.822989328415133, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 326, train_loss = 1.821946962387301, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 327, train_loss = 1.8198972580721602, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 328, train_loss = 1.8186085013439879, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 329, train_loss = 1.81737471872475, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 330, train_loss = 1.8150894045829773, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 331, train_loss = 1.8123824248323217, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 332, train_loss = 1.8098243027925491, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 333, train_loss = 1.8105211965739727, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 334, train_loss = 1.809055202989839, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 335, train_loss = 1.8060610257089138, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 336, train_loss = 1.8053252026438713, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 337, train_loss = 1.8042392345378175, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 338, train_loss = 1.801278485567309, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 339, train_loss = 1.8001165837049484, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 340, train_loss = 1.7975091015687212, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 341, train_loss = 1.7960151098668575, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 342, train_loss = 1.7944801984122023, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 343, train_loss = 1.7932501645991579, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 344, train_loss = 1.7929347505560145, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 345, train_loss = 1.7909964298596606, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 346, train_loss = 1.7884658947587013, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 347, train_loss = 1.7877738090464845, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 348, train_loss = 1.7868615513434634, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 349, train_loss = 1.783879460184835, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 350, train_loss = 1.7833766055991873, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 351, train_loss = 1.7820750450482592, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 352, train_loss = 1.7793568248162046, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 353, train_loss = 1.7785215824842453, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 354, train_loss = 1.7776292724302039, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 355, train_loss = 1.775624162168242, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 356, train_loss = 1.7739832686493173, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 357, train_loss = 1.774298166274093, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 358, train_loss = 1.77162329480052, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 359, train_loss = 1.7692015009233728, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 360, train_loss = 1.7683964805910364, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 361, train_loss = 1.767624401836656, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 362, train_loss = 1.766134288161993, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 363, train_loss = 1.7646509247133508, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 364, train_loss = 1.7641243847319856, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 365, train_loss = 1.7627589963376522, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 366, train_loss = 1.761352395056747, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 367, train_loss = 1.7592144956579432, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 368, train_loss = 1.757725284784101, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 369, train_loss = 1.7578306595096365, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 370, train_loss = 1.75627474358771, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 371, train_loss = 1.7544499213108793, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 372, train_loss = 1.7532478794455528, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 373, train_loss = 1.7518140176543966, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 374, train_loss = 1.7507565779378638, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 375, train_loss = 1.7486975118517876, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 376, train_loss = 1.7478116626152769, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 377, train_loss = 1.7478602267801762, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 378, train_loss = 1.7463829455664381, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 379, train_loss = 1.744948452920653, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 380, train_loss = 1.7438611997058615, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 381, train_loss = 1.741349145770073, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 382, train_loss = 1.7409143596887589, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 383, train_loss = 1.7396583519876003, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 384, train_loss = 1.7387383617460728, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 385, train_loss = 1.736898491741158, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 386, train_loss = 1.7349615966668352, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 387, train_loss = 1.7336077304789796, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 388, train_loss = 1.7310387069592252, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 389, train_loss = 1.729235716164112, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 390, train_loss = 1.7285879602422938, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 391, train_loss = 1.727355251670815, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 392, train_loss = 1.7248104425380006, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 393, train_loss = 1.7246786070754752, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 394, train_loss = 1.7236305512487888, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 395, train_loss = 1.721467163413763, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 396, train_loss = 1.7216439507901669, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 397, train_loss = 1.7206482701003551, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 398, train_loss = 1.7199333781609312, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 399, train_loss = 1.7182513462612405, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 400, train_loss = 1.7172205211827531, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 401, train_loss = 1.7154041143367067, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 402, train_loss = 1.7135529132792726, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 403, train_loss = 1.7142637806246057, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 404, train_loss = 1.7129149785032496, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 405, train_loss = 1.7106454049935564, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 406, train_loss = 1.7106069698929787, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 407, train_loss = 1.7086151106050238, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 408, train_loss = 1.7072125226259232, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 409, train_loss = 1.7082759961485863, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 410, train_loss = 1.7059276265790686, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 411, train_loss = 1.7048889758298174, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 412, train_loss = 1.7032550735166296, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 413, train_loss = 1.7032402096083388, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 414, train_loss = 1.7016201242804527, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 415, train_loss = 1.7018050389597192, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 416, train_loss = 1.700051305233501, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 417, train_loss = 1.6987724229693413, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 418, train_loss = 1.6979054348776117, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 419, train_loss = 1.6977841071784496, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 420, train_loss = 1.6955404430627823, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 421, train_loss = 1.6943234615027905, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 422, train_loss = 1.6924980953335762, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 423, train_loss = 1.6939196338644251, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 424, train_loss = 1.692496184259653, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 425, train_loss = 1.6923775238683447, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 426, train_loss = 1.690200787037611, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 427, train_loss = 1.6912389608332887, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 428, train_loss = 1.6889223804464564, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 429, train_loss = 1.6874495769152418, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 430, train_loss = 1.686477051465772, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 431, train_loss = 1.685185071080923, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 432, train_loss = 1.6853075238177553, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 433, train_loss = 1.6840902058174834, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 434, train_loss = 1.6834688372910023, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 435, train_loss = 1.6822804088005796, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 436, train_loss = 1.6803644696483389, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 437, train_loss = 1.6807131121167913, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 438, train_loss = 1.678559597581625, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 439, train_loss = 1.6786330938339233, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 440, train_loss = 1.6780755979707465, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 441, train_loss = 1.676192851155065, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 442, train_loss = 1.6762950706179254, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 443, train_loss = 1.6741253050859086, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 444, train_loss = 1.6737144167418592, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 445, train_loss = 1.6730139590799809, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 446, train_loss = 1.6742852007155307, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 447, train_loss = 1.6712586631183513, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 448, train_loss = 1.671618773310911, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 449, train_loss = 1.6691798183019273, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 450, train_loss = 1.6685086426441558, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 451, train_loss = 1.668212344229687, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 452, train_loss = 1.6678381611709483, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 453, train_loss = 1.6669039763510227, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 454, train_loss = 1.6659189462661743, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 455, train_loss = 1.6662947324221022, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 456, train_loss = 1.6641551479697227, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 457, train_loss = 1.6652559377253056, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 458, train_loss = 1.6608616796438582, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 459, train_loss = 1.6621603183448315, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 460, train_loss = 1.6603250044281594, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 461, train_loss = 1.6586444464628585, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 462, train_loss = 1.659230149060022, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 463, train_loss = 1.6578555355663411, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 464, train_loss = 1.6559604915673845, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 465, train_loss = 1.6563906918163411, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 466, train_loss = 1.6542265278403647, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 467, train_loss = 1.6562941148877144, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 468, train_loss = 1.6534828369622119, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 469, train_loss = 1.65231066319393, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 470, train_loss = 1.6531211609835736, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 471, train_loss = 1.6518129594624043, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 472, train_loss = 1.6509629513020627, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 473, train_loss = 1.6495778784155846, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 474, train_loss = 1.649644199758768, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 475, train_loss = 1.6491438274388202, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 476, train_loss = 1.647238568693865, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 477, train_loss = 1.6469236451084726, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 478, train_loss = 1.6478848506812938, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 479, train_loss = 1.6455849285121076, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 480, train_loss = 1.645828977227211, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 481, train_loss = 1.6444299134309404, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 482, train_loss = 1.6441423346404918, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 483, train_loss = 1.6417497943039052, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 484, train_loss = 1.6434110539848916, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 485, train_loss = 1.6409323562984355, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 486, train_loss = 1.6413587033748627, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 487, train_loss = 1.638911571353674, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 488, train_loss = 1.6403869117493741, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 489, train_loss = 1.63805628195405, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 490, train_loss = 1.6391913183033466, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 491, train_loss = 1.6367170413141139, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 492, train_loss = 1.6374939543311484, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 493, train_loss = 1.6350233455304988, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 494, train_loss = 1.6355281484429725, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 495, train_loss = 1.6353385324473493, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 496, train_loss = 1.632986906915903, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 497, train_loss = 1.6331751868128777, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 498, train_loss = 1.633165743201971, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 499, train_loss = 1.6316478016669862, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████                                   | 15/30 [2:15:49<2:15:39, 542.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "16th- epoch: 0, train_loss = 103.93933291733265, train_acc = 0.8021658127619935\n",
      "test Acc 0.8300744878957169:\n",
      "16th- epoch: 1, train_loss = 42.68801660090685, train_acc = 0.9153469958081043\n",
      "test Acc 0.8896648044692738:\n",
      "16th- epoch: 2, train_loss = 33.15369077771902, train_acc = 0.9343269678621332\n",
      "test Acc 0.9199255121042831:\n",
      "16th- epoch: 3, train_loss = 28.010819256305695, train_acc = 0.9431765253842571\n",
      "test Acc 0.9320297951582868:\n",
      "16th- epoch: 4, train_loss = 24.54947232082486, train_acc = 0.94981369352585\n",
      "test Acc 0.9343575418994413:\n",
      "16th- epoch: 5, train_loss = 21.994068637490273, train_acc = 0.9563344201210993\n",
      "test Acc 0.9404096834264432:\n",
      "16th- epoch: 6, train_loss = 20.093433666974306, train_acc = 0.959944108057755\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 7, train_loss = 18.580722138285637, train_acc = 0.9630880298090359\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 8, train_loss = 17.349255103617907, train_acc = 0.9659990684676293\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 9, train_loss = 16.3070317953825, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 10, train_loss = 15.412249557673931, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 11, train_loss = 14.636202946305275, train_acc = 0.9706567303213787\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 12, train_loss = 13.952262490987778, train_acc = 0.972286911970191\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 13, train_loss = 13.336267028003931, train_acc = 0.9734513274336283\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 14, train_loss = 12.773413721472025, train_acc = 0.9741499767116907\n",
      "test Acc 0.952048417132216:\n",
      "16th- epoch: 15, train_loss = 12.264305263757706, train_acc = 0.9751979506287843\n",
      "test Acc 0.952513966480447:\n",
      "16th- epoch: 16, train_loss = 11.795473784208298, train_acc = 0.976245924545878\n",
      "test Acc 0.9539106145251397:\n",
      "16th- epoch: 17, train_loss = 11.36948312446475, train_acc = 0.9772938984629715\n",
      "test Acc 0.9553072625698324:\n",
      "16th- epoch: 18, train_loss = 10.969185255467892, train_acc = 0.977992547741034\n",
      "test Acc 0.9557728119180633:\n",
      "16th- epoch: 19, train_loss = 10.596330827102065, train_acc = 0.9790405216581276\n",
      "test Acc 0.957169459962756:\n",
      "16th- epoch: 20, train_loss = 10.244380075484514, train_acc = 0.9796227293898463\n",
      "test Acc 0.957169459962756:\n",
      "16th- epoch: 21, train_loss = 9.915473584085703, train_acc = 0.9796227293898463\n",
      "test Acc 0.957635009310987:\n",
      "16th- epoch: 22, train_loss = 9.609045067802072, train_acc = 0.9798556124825337\n",
      "test Acc 0.957635009310987:\n",
      "16th- epoch: 23, train_loss = 9.323121605440974, train_acc = 0.9805542617605962\n",
      "test Acc 0.9581005586592178:\n",
      "16th- epoch: 24, train_loss = 9.055492974817753, train_acc = 0.9809035863996274\n",
      "test Acc 0.9585661080074488:\n",
      "16th- epoch: 25, train_loss = 8.800957050174475, train_acc = 0.9811364694923148\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 26, train_loss = 8.559677882120013, train_acc = 0.9812529110386586\n",
      "test Acc 0.9585661080074488:\n",
      "16th- epoch: 27, train_loss = 8.33122680336237, train_acc = 0.9814857941313461\n",
      "test Acc 0.9585661080074488:\n",
      "16th- epoch: 28, train_loss = 8.11707547493279, train_acc = 0.9820680018630648\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 29, train_loss = 7.913072405382991, train_acc = 0.9826502095947834\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 30, train_loss = 7.721643978729844, train_acc = 0.9832324173265021\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 31, train_loss = 7.541761461645365, train_acc = 0.9833488588728458\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 32, train_loss = 7.369042031466961, train_acc = 0.9840475081509082\n",
      "test Acc 0.9613594040968343:\n",
      "16th- epoch: 33, train_loss = 7.205838588997722, train_acc = 0.9842803912435957\n",
      "test Acc 0.9613594040968343:\n",
      "16th- epoch: 34, train_loss = 7.0501354187726974, train_acc = 0.9846297158826269\n",
      "test Acc 0.9608938547486033:\n",
      "16th- epoch: 35, train_loss = 6.90038650110364, train_acc = 0.9848625989753144\n",
      "test Acc 0.9608938547486033:\n",
      "16th- epoch: 36, train_loss = 6.7611479461193085, train_acc = 0.9857941313460643\n",
      "test Acc 0.9608938547486033:\n",
      "16th- epoch: 37, train_loss = 6.626094171777368, train_acc = 0.9862598975314392\n",
      "test Acc 0.9613594040968343:\n",
      "16th- epoch: 38, train_loss = 6.498929683119059, train_acc = 0.9862598975314392\n",
      "test Acc 0.9613594040968343:\n",
      "16th- epoch: 39, train_loss = 6.376440906897187, train_acc = 0.9864927806241267\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 40, train_loss = 6.2580128740519285, train_acc = 0.9868421052631579\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 41, train_loss = 6.146998500451446, train_acc = 0.9870749883558454\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 42, train_loss = 6.039300234988332, train_acc = 0.9871914299021891\n",
      "test Acc 0.9622905027932961:\n",
      "16th- epoch: 43, train_loss = 5.936483005061746, train_acc = 0.9877736376339078\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 44, train_loss = 5.8379636481404305, train_acc = 0.9878900791802515\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 45, train_loss = 5.7431499268859625, train_acc = 0.9882394038192828\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 46, train_loss = 5.649853201583028, train_acc = 0.9884722869119702\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 47, train_loss = 5.5635201539844275, train_acc = 0.9885887284583139\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 48, train_loss = 5.478194020688534, train_acc = 0.9888216115510013\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 49, train_loss = 5.395230719819665, train_acc = 0.9892873777363763\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 50, train_loss = 5.316891739144921, train_acc = 0.98940381928272\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 51, train_loss = 5.240788206458092, train_acc = 0.9895202608290639\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 52, train_loss = 5.164609694853425, train_acc = 0.9895202608290639\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 53, train_loss = 5.094945347867906, train_acc = 0.9896367023754076\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 54, train_loss = 5.024742906913161, train_acc = 0.989869585468095\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 55, train_loss = 4.95706681907177, train_acc = 0.989869585468095\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 56, train_loss = 4.890817308798432, train_acc = 0.989869585468095\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 57, train_loss = 4.8289984902367, train_acc = 0.9902189101071263\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 58, train_loss = 4.769741899333894, train_acc = 0.99033535165347\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 59, train_loss = 4.710185590200126, train_acc = 0.9904517931998137\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 60, train_loss = 4.652542841620743, train_acc = 0.9904517931998137\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 61, train_loss = 4.597594845108688, train_acc = 0.9904517931998137\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 62, train_loss = 4.543109527789056, train_acc = 0.9904517931998137\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 63, train_loss = 4.491030151955783, train_acc = 0.9905682347461574\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 64, train_loss = 4.4410949079319835, train_acc = 0.9909175593851887\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 65, train_loss = 4.391297661699355, train_acc = 0.9909175593851887\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 66, train_loss = 4.342933550477028, train_acc = 0.9909175593851887\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 67, train_loss = 4.297842325642705, train_acc = 0.9910340009315324\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 68, train_loss = 4.251499109901488, train_acc = 0.9910340009315324\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 69, train_loss = 4.208190816454589, train_acc = 0.9910340009315324\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 70, train_loss = 4.1657759193331, train_acc = 0.9911504424778761\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 71, train_loss = 4.125475690700114, train_acc = 0.9913833255705635\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 72, train_loss = 4.0845408430323005, train_acc = 0.9914997671169073\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 73, train_loss = 4.045986310578883, train_acc = 0.9917326502095948\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 74, train_loss = 4.0076776361092925, train_acc = 0.9917326502095948\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 75, train_loss = 3.97015228215605, train_acc = 0.9918490917559385\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 76, train_loss = 3.933967437595129, train_acc = 0.9919655333022822\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 77, train_loss = 3.899546735920012, train_acc = 0.992081974848626\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 78, train_loss = 3.865093576721847, train_acc = 0.992081974848626\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 79, train_loss = 3.830826566554606, train_acc = 0.9921984163949698\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 80, train_loss = 3.79916503559798, train_acc = 0.9923148579413135\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 81, train_loss = 3.767284427769482, train_acc = 0.9923148579413135\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 82, train_loss = 3.7346955249086022, train_acc = 0.9923148579413135\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 83, train_loss = 3.7051356760784984, train_acc = 0.9925477410340009\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 84, train_loss = 3.6744669461622834, train_acc = 0.9926641825803446\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 85, train_loss = 3.645897224545479, train_acc = 0.9926641825803446\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 86, train_loss = 3.618489828892052, train_acc = 0.9927806241266884\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 87, train_loss = 3.58900111541152, train_acc = 0.9927806241266884\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 88, train_loss = 3.5642955834046006, train_acc = 0.9927806241266884\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 89, train_loss = 3.536012524738908, train_acc = 0.9928970656730322\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 90, train_loss = 3.5115888016298413, train_acc = 0.9930135072193759\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 91, train_loss = 3.4854776561260223, train_acc = 0.9930135072193759\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 92, train_loss = 3.4602280324324965, train_acc = 0.9930135072193759\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 93, train_loss = 3.4363778261467814, train_acc = 0.9930135072193759\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 94, train_loss = 3.413481052033603, train_acc = 0.9932463903120633\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 95, train_loss = 3.3890060372650623, train_acc = 0.9934792734047508\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 96, train_loss = 3.3659372283145785, train_acc = 0.9937121564974383\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 97, train_loss = 3.3429439030587673, train_acc = 0.9937121564974383\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 98, train_loss = 3.3201105017215014, train_acc = 0.9937121564974383\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 99, train_loss = 3.299214978236705, train_acc = 0.9937121564974383\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 100, train_loss = 3.2780204289592803, train_acc = 0.9937121564974383\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 101, train_loss = 3.257280489895493, train_acc = 0.9937121564974383\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 102, train_loss = 3.237229783087969, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 103, train_loss = 3.216973459813744, train_acc = 0.9937121564974383\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 104, train_loss = 3.1978477369993925, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 105, train_loss = 3.1774472426623106, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 106, train_loss = 3.159877340774983, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 107, train_loss = 3.141153296921402, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 108, train_loss = 3.1230566878803074, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 109, train_loss = 3.1050333962775767, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 110, train_loss = 3.087806963827461, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 111, train_loss = 3.070661738049239, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 112, train_loss = 3.0536242672242224, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 113, train_loss = 3.0370520655997097, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 114, train_loss = 3.0207981765270233, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 115, train_loss = 3.004070958122611, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 116, train_loss = 2.9892178014852107, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 117, train_loss = 2.9740339275449514, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 118, train_loss = 2.9584554811008275, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 119, train_loss = 2.9433501828461885, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 120, train_loss = 2.929203239735216, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 121, train_loss = 2.9145510657690465, train_acc = 0.993828598043782\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 122, train_loss = 2.899826968088746, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 123, train_loss = 2.8862388264387846, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 124, train_loss = 2.872552093118429, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 125, train_loss = 2.858963157981634, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 126, train_loss = 2.8458215235732496, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 127, train_loss = 2.8323983498848975, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 128, train_loss = 2.819509185384959, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 129, train_loss = 2.806936338543892, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 130, train_loss = 2.7945775943808258, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 131, train_loss = 2.782951944041997, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 132, train_loss = 2.771541591733694, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 133, train_loss = 2.758440323639661, train_acc = 0.9940614811364695\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 134, train_loss = 2.7468823683448136, train_acc = 0.9940614811364695\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 135, train_loss = 2.736151186749339, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 136, train_loss = 2.72471554717049, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 137, train_loss = 2.7137714494019747, train_acc = 0.9940614811364695\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 138, train_loss = 2.7021476444788277, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 139, train_loss = 2.691362604498863, train_acc = 0.9940614811364695\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 140, train_loss = 2.6807640423066914, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 141, train_loss = 2.6698995656333864, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 142, train_loss = 2.658280737698078, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 143, train_loss = 2.6486865715123713, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 144, train_loss = 2.638449660036713, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 145, train_loss = 2.6288004089146852, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 146, train_loss = 2.6180659788660705, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 147, train_loss = 2.6085220109671354, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 148, train_loss = 2.599269190337509, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 149, train_loss = 2.5893732365220785, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 150, train_loss = 2.5802063471637666, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 151, train_loss = 2.571541449520737, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 152, train_loss = 2.562425192911178, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 153, train_loss = 2.5527996718883514, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 154, train_loss = 2.545249793212861, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 155, train_loss = 2.5366533710621297, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 156, train_loss = 2.5275045968592167, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 157, train_loss = 2.519131552428007, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 158, train_loss = 2.5112568489275873, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 159, train_loss = 2.502878709230572, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 160, train_loss = 2.494394005741924, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 161, train_loss = 2.48589659598656, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 162, train_loss = 2.4784569509793073, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 163, train_loss = 2.47077245824039, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 164, train_loss = 2.4633167050778866, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 165, train_loss = 2.4552364714909345, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 166, train_loss = 2.448107187403366, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 167, train_loss = 2.440552780404687, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 168, train_loss = 2.4338158573955297, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 169, train_loss = 2.426270779920742, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 170, train_loss = 2.4195083889644593, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 171, train_loss = 2.411935993703082, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 172, train_loss = 2.404885782627389, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 173, train_loss = 2.397397654829547, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 174, train_loss = 2.3910814474802464, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 175, train_loss = 2.3838312204461545, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 176, train_loss = 2.377485579578206, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 177, train_loss = 2.3702353693079203, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 178, train_loss = 2.3643047374207526, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 179, train_loss = 2.357741058571264, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 180, train_loss = 2.351385821821168, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 181, train_loss = 2.344723751069978, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 182, train_loss = 2.338573319837451, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 183, train_loss = 2.3329253315459937, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 184, train_loss = 2.326489568920806, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 185, train_loss = 2.3205117881298065, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 186, train_loss = 2.3136485405266285, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 187, train_loss = 2.308653011918068, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 188, train_loss = 2.3026321169454604, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 189, train_loss = 2.296795506728813, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 190, train_loss = 2.2909728654194623, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 191, train_loss = 2.2844797663856298, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 192, train_loss = 2.279531554086134, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 193, train_loss = 2.2739565677475184, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 194, train_loss = 2.268807850079611, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 195, train_loss = 2.263945798156783, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 196, train_loss = 2.256869003176689, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 197, train_loss = 2.252598552731797, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 198, train_loss = 2.2468434621114284, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 199, train_loss = 2.242049549939111, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 200, train_loss = 2.236255633411929, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 201, train_loss = 2.230864856392145, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 202, train_loss = 2.225981443421915, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 203, train_loss = 2.222285272553563, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 204, train_loss = 2.2155938639771193, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 205, train_loss = 2.21136921341531, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 206, train_loss = 2.2069134265184402, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 207, train_loss = 2.201527298660949, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 208, train_loss = 2.1969262447673827, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 209, train_loss = 2.192983526038006, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 210, train_loss = 2.1874891587067395, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 211, train_loss = 2.181915195658803, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 212, train_loss = 2.178215490654111, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 213, train_loss = 2.173809676198289, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 214, train_loss = 2.1696187432389706, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 215, train_loss = 2.1651021155994385, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 216, train_loss = 2.160013632150367, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 217, train_loss = 2.1561029627919197, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 218, train_loss = 2.1513955935370177, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 219, train_loss = 2.147110542282462, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 220, train_loss = 2.1431504420470446, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 221, train_loss = 2.139011712744832, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 222, train_loss = 2.134880667552352, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 223, train_loss = 2.1306585657875985, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 224, train_loss = 2.1269615155179054, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 225, train_loss = 2.1222060695290565, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 226, train_loss = 2.1185301207005978, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 227, train_loss = 2.1152683955151588, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 228, train_loss = 2.1104081757366657, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 229, train_loss = 2.1062745314557105, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 230, train_loss = 2.1030945666134357, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 231, train_loss = 2.0987042132765055, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 232, train_loss = 2.095532540930435, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 233, train_loss = 2.090905113145709, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 234, train_loss = 2.087406602455303, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 235, train_loss = 2.084741144673899, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 236, train_loss = 2.080031333491206, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 237, train_loss = 2.0771036848891526, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 238, train_loss = 2.072636875556782, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 239, train_loss = 2.069780421210453, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 240, train_loss = 2.065263142809272, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 241, train_loss = 2.062269341899082, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 242, train_loss = 2.0581817280035466, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 243, train_loss = 2.0552663567941636, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 244, train_loss = 2.051465454278514, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 245, train_loss = 2.048123073996976, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 246, train_loss = 2.0457050043623894, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 247, train_loss = 2.042023690417409, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 248, train_loss = 2.038174429908395, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 249, train_loss = 2.0350357473362237, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 250, train_loss = 2.032246310962364, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 251, train_loss = 2.028470643563196, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 252, train_loss = 2.0256735600996763, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 253, train_loss = 2.0222525659482926, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 254, train_loss = 2.018953484715894, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 255, train_loss = 2.0163853026460856, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 256, train_loss = 2.0131863311398774, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 257, train_loss = 2.009795065387152, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 258, train_loss = 2.006912368698977, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 259, train_loss = 2.0044210770865902, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 260, train_loss = 2.001198167563416, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 261, train_loss = 1.9977755533764139, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 262, train_loss = 1.994547724723816, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 263, train_loss = 1.9921501061180606, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 264, train_loss = 1.9898245813092217, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 265, train_loss = 1.9865699788788334, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 266, train_loss = 1.983478999347426, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 267, train_loss = 1.9806230552494526, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 268, train_loss = 1.9789947234094143, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 269, train_loss = 1.9748908374458551, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 270, train_loss = 1.972288620308973, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 271, train_loss = 1.9693325534462929, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 272, train_loss = 1.9676530808210373, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 273, train_loss = 1.964559511630796, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 274, train_loss = 1.961672026081942, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 275, train_loss = 1.95934438763652, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 276, train_loss = 1.955905690207146, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 277, train_loss = 1.9542391188442707, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 278, train_loss = 1.9516576826572418, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 279, train_loss = 1.948938094661571, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 280, train_loss = 1.946234449162148, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 281, train_loss = 1.943885175511241, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 282, train_loss = 1.9415444353362545, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 283, train_loss = 1.9390100432792678, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 284, train_loss = 1.936070674448274, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 285, train_loss = 1.9335311552276835, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 286, train_loss = 1.9313445693114772, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 287, train_loss = 1.9292750880122185, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 288, train_loss = 1.9264359679073095, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 289, train_loss = 1.924707630649209, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 290, train_loss = 1.9225450791418552, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 291, train_loss = 1.9197846067836508, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 292, train_loss = 1.9172154553234577, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 293, train_loss = 1.915446943952702, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 294, train_loss = 1.9125900684157386, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 295, train_loss = 1.909851118340157, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 296, train_loss = 1.908817840158008, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 297, train_loss = 1.9064653050154448, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 298, train_loss = 1.9042104365071282, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 299, train_loss = 1.9011088827392086, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 300, train_loss = 1.8991284550866112, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 301, train_loss = 1.8970970883965492, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 302, train_loss = 1.8951311396667734, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 303, train_loss = 1.8934367429465055, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 304, train_loss = 1.891050629899837, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 305, train_loss = 1.8882121940841898, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 306, train_loss = 1.8866802863776684, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 307, train_loss = 1.8843221111455932, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 308, train_loss = 1.8822842774679884, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 309, train_loss = 1.8802699694642797, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 310, train_loss = 1.8790463525801897, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 311, train_loss = 1.8763134237378836, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 312, train_loss = 1.873628911213018, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 313, train_loss = 1.8719769871095195, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 314, train_loss = 1.8704510008683428, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 315, train_loss = 1.8686837380519137, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 316, train_loss = 1.8665343821048737, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 317, train_loss = 1.8646103931823745, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 318, train_loss = 1.8620767934480682, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 319, train_loss = 1.8598005132516846, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 320, train_loss = 1.8581794947385788, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 321, train_loss = 1.856069671572186, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 322, train_loss = 1.854320508777164, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 323, train_loss = 1.8520269027212635, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 324, train_loss = 1.8507263058563694, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 325, train_loss = 1.8490604417165741, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 326, train_loss = 1.8470256458967924, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 327, train_loss = 1.8456867672502995, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 328, train_loss = 1.8433909838786349, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 329, train_loss = 1.8415458103409037, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 330, train_loss = 1.8397012936184183, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 331, train_loss = 1.8387754341820255, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 332, train_loss = 1.836815114482306, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 333, train_loss = 1.8348747193813324, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 334, train_loss = 1.8332043787231669, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 335, train_loss = 1.8314040502300486, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 336, train_loss = 1.8297089313855395, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 337, train_loss = 1.827984937815927, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 338, train_loss = 1.826459132716991, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 339, train_loss = 1.8250535931438208, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 340, train_loss = 1.8232080955058336, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 341, train_loss = 1.8207413317868486, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 342, train_loss = 1.819532054127194, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 343, train_loss = 1.8174781588604674, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 344, train_loss = 1.8161659328034148, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 345, train_loss = 1.8147058058530092, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 346, train_loss = 1.8132992144674063, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 347, train_loss = 1.8117912076413631, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 348, train_loss = 1.8098224233835936, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 349, train_loss = 1.8083140278467909, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 350, train_loss = 1.8066869775066152, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 351, train_loss = 1.8061826130142435, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 352, train_loss = 1.8039112072438002, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 353, train_loss = 1.802302640513517, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 354, train_loss = 1.8004477694630623, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 355, train_loss = 1.798930792720057, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 356, train_loss = 1.7978949522366747, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 357, train_loss = 1.795585069223307, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 358, train_loss = 1.7941220868378878, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 359, train_loss = 1.793209720402956, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 360, train_loss = 1.792030012817122, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 361, train_loss = 1.7907033985247836, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 362, train_loss = 1.7888981072464958, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 363, train_loss = 1.7868249906459823, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 364, train_loss = 1.785792013630271, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 365, train_loss = 1.7848605798790231, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 366, train_loss = 1.78349020332098, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 367, train_loss = 1.7816301081329584, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 368, train_loss = 1.7804938474437222, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 369, train_loss = 1.7797423308948055, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 370, train_loss = 1.7772215455770493, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 371, train_loss = 1.776173093705438, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 372, train_loss = 1.7750584973255172, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 373, train_loss = 1.7730523677309975, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 374, train_loss = 1.7726182533660904, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 375, train_loss = 1.7714854528894648, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 376, train_loss = 1.770158035098575, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 377, train_loss = 1.7680384448030964, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 378, train_loss = 1.766641247435473, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 379, train_loss = 1.7653468269854784, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 380, train_loss = 1.7641793427756056, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 381, train_loss = 1.7622683247318491, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 382, train_loss = 1.7616214007139206, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 383, train_loss = 1.760664213448763, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 384, train_loss = 1.7594529433408752, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 385, train_loss = 1.7582535749534145, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 386, train_loss = 1.7561914039542899, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 387, train_loss = 1.7553908489644527, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 388, train_loss = 1.7545936343958601, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 389, train_loss = 1.7537238294025883, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 390, train_loss = 1.7520730923861265, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 391, train_loss = 1.7507928175618872, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 392, train_loss = 1.749440877349116, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 393, train_loss = 1.7477347627282143, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 394, train_loss = 1.746384077356197, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 395, train_loss = 1.746441543684341, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 396, train_loss = 1.7444505294552073, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 397, train_loss = 1.743857735185884, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 398, train_loss = 1.7421369217336178, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 399, train_loss = 1.7411150491680019, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 400, train_loss = 1.740566226944793, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 401, train_loss = 1.7392937404219992, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 402, train_loss = 1.7378575466573238, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 403, train_loss = 1.7373912527109496, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 404, train_loss = 1.735416492447257, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 405, train_loss = 1.7352579347789288, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 406, train_loss = 1.7330244655604474, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 407, train_loss = 1.7319990222458728, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 408, train_loss = 1.7304678379441611, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 409, train_loss = 1.7296993018244393, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 410, train_loss = 1.7293133537168615, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 411, train_loss = 1.7282896538381465, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 412, train_loss = 1.7262210833723657, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 413, train_loss = 1.7255519572645426, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 414, train_loss = 1.7236870868946426, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 415, train_loss = 1.723440755798947, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 416, train_loss = 1.7226999799604528, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 417, train_loss = 1.7216351702809334, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 418, train_loss = 1.7206728644669056, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 419, train_loss = 1.719112141057849, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 420, train_loss = 1.7174265875364654, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 421, train_loss = 1.7162006224389188, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 422, train_loss = 1.716500838578213, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 423, train_loss = 1.7141622838680632, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 424, train_loss = 1.7135990504175425, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 425, train_loss = 1.7125875471974723, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 426, train_loss = 1.7118651798809879, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 427, train_loss = 1.71027149137808, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 428, train_loss = 1.709455944597721, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 429, train_loss = 1.7084896310116164, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 430, train_loss = 1.707647483155597, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 431, train_loss = 1.7070342215592973, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 432, train_loss = 1.7066702544689178, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 433, train_loss = 1.704668012156617, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 434, train_loss = 1.7046428018365987, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 435, train_loss = 1.7029771550442092, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 436, train_loss = 1.7027390748262405, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 437, train_loss = 1.700407416850794, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 438, train_loss = 1.7008650234784, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 439, train_loss = 1.6982003270532005, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 440, train_loss = 1.6979409574414603, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 441, train_loss = 1.6971253721858375, train_acc = 0.9953423381462506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 442, train_loss = 1.6958835422992706, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 443, train_loss = 1.6954349192674272, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 444, train_loss = 1.694241909950506, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 445, train_loss = 1.6942059167777188, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 446, train_loss = 1.6936086937785149, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 447, train_loss = 1.6925830717082135, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 448, train_loss = 1.6909173894673586, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 449, train_loss = 1.6908176448196173, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 450, train_loss = 1.6884945177589543, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 451, train_loss = 1.6885304513270967, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 452, train_loss = 1.6877315851743333, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 453, train_loss = 1.6865076987887733, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 454, train_loss = 1.686119946942199, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 455, train_loss = 1.6846598386764526, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 456, train_loss = 1.6836217567324638, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 457, train_loss = 1.682862062647473, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 458, train_loss = 1.6826028221403249, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 459, train_loss = 1.6817171331495047, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 460, train_loss = 1.6812670112703927, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 461, train_loss = 1.680063294887077, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 462, train_loss = 1.6784508998389356, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 463, train_loss = 1.6778390749241225, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 464, train_loss = 1.6767279512132518, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 465, train_loss = 1.6761178473825566, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 466, train_loss = 1.6751170319621451, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 467, train_loss = 1.67467337223934, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 468, train_loss = 1.6739089234615676, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 469, train_loss = 1.6734800431877375, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 470, train_loss = 1.6716596918995492, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 471, train_loss = 1.67153100669384, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 472, train_loss = 1.6699333253200166, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 473, train_loss = 1.6698250987683423, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 474, train_loss = 1.668568807945121, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 475, train_loss = 1.6688426596228965, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 476, train_loss = 1.6671795137226582, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 477, train_loss = 1.6663748007267714, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 478, train_loss = 1.6660209379042499, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 479, train_loss = 1.664777600497473, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 480, train_loss = 1.6646480597555637, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 481, train_loss = 1.6634847174282186, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 482, train_loss = 1.6625098151271231, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 483, train_loss = 1.6617755685001612, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 484, train_loss = 1.6609458147431724, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 485, train_loss = 1.6606174136395566, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 486, train_loss = 1.6590698100626469, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 487, train_loss = 1.659248476207722, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 488, train_loss = 1.6579810250550508, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 489, train_loss = 1.6573320248280652, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 490, train_loss = 1.6563237110967748, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 491, train_loss = 1.657033322378993, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 492, train_loss = 1.6547067556530237, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 493, train_loss = 1.654856092587579, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 494, train_loss = 1.6541358145768754, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 495, train_loss = 1.6530745749478228, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 496, train_loss = 1.6520065547083504, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 497, train_loss = 1.6524416294996627, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 498, train_loss = 1.6508469805121422, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 499, train_loss = 1.649422213435173, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████▎                                | 16/30 [2:24:52<2:06:37, 542.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "17th- epoch: 0, train_loss = 107.87365773320198, train_acc = 0.8026315789473685\n",
      "test Acc 0.8654562383612663:\n",
      "17th- epoch: 1, train_loss = 41.79552835971117, train_acc = 0.9177922682813228\n",
      "test Acc 0.898975791433892:\n",
      "17th- epoch: 2, train_loss = 31.800120443105698, train_acc = 0.9377037727061015\n",
      "test Acc 0.9110800744878957:\n",
      "17th- epoch: 3, train_loss = 26.607997179031372, train_acc = 0.9456217978574756\n",
      "test Acc 0.925512104283054:\n",
      "17th- epoch: 4, train_loss = 23.19555378332734, train_acc = 0.9508616674429436\n",
      "test Acc 0.9352886405959032:\n",
      "17th- epoch: 5, train_loss = 20.683591309934855, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 6, train_loss = 18.750700637698174, train_acc = 0.9598276665114113\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 7, train_loss = 17.25967264175415, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 8, train_loss = 16.06069663912058, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 9, train_loss = 15.07855485752225, train_acc = 0.97007452258966\n",
      "test Acc 0.9543761638733705:\n",
      "17th- epoch: 10, train_loss = 14.247501689940691, train_acc = 0.9717047042384723\n",
      "test Acc 0.9562383612662942:\n",
      "17th- epoch: 11, train_loss = 13.533469181507826, train_acc = 0.9732184443409408\n",
      "test Acc 0.9594972067039106:\n",
      "17th- epoch: 12, train_loss = 12.920168921351433, train_acc = 0.9746157428970657\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 13, train_loss = 12.372520133852959, train_acc = 0.9756637168141593\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 14, train_loss = 11.894795015454292, train_acc = 0.9764788076385654\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 15, train_loss = 11.462181590497494, train_acc = 0.9770610153702841\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 16, train_loss = 11.069795597344637, train_acc = 0.9772938984629715\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 17, train_loss = 10.714185394346714, train_acc = 0.9781089892873778\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 18, train_loss = 10.377151906490326, train_acc = 0.9785747554727526\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 19, train_loss = 10.072241881862283, train_acc = 0.9795062878435026\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 20, train_loss = 9.780410969629884, train_acc = 0.9798556124825337\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 21, train_loss = 9.513350227847695, train_acc = 0.9799720540288775\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 22, train_loss = 9.264822378754616, train_acc = 0.9804378202142524\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 23, train_loss = 9.029591735452414, train_acc = 0.9809035863996274\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 24, train_loss = 8.803918389603496, train_acc = 0.9813693525850024\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 25, train_loss = 8.592875240370631, train_acc = 0.9821844434094085\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 26, train_loss = 8.387914845719934, train_acc = 0.9829995342338146\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 27, train_loss = 8.196932731196284, train_acc = 0.983698183511877\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 28, train_loss = 8.011751109734178, train_acc = 0.9839310666045645\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 29, train_loss = 7.840497633442283, train_acc = 0.9842803912435957\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 30, train_loss = 7.676884090527892, train_acc = 0.9846297158826269\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 31, train_loss = 7.521915214136243, train_acc = 0.9846297158826269\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 32, train_loss = 7.37306203506887, train_acc = 0.9847461574289706\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 33, train_loss = 7.23197016865015, train_acc = 0.9853283651606893\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 34, train_loss = 7.095222011208534, train_acc = 0.9856776897997206\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 35, train_loss = 6.967172354459763, train_acc = 0.9860270144387517\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 36, train_loss = 6.8367758840322495, train_acc = 0.9861434559850955\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 37, train_loss = 6.716981286183, train_acc = 0.9862598975314392\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 38, train_loss = 6.604711567983031, train_acc = 0.9866092221704704\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 39, train_loss = 6.493785064667463, train_acc = 0.9871914299021891\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 40, train_loss = 6.390513443388045, train_acc = 0.9874243129948765\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 41, train_loss = 6.289812388829887, train_acc = 0.9878900791802515\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 42, train_loss = 6.193375159054995, train_acc = 0.9883558453656265\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 43, train_loss = 6.101220588199794, train_acc = 0.9884722869119702\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 44, train_loss = 6.010406794957817, train_acc = 0.9885887284583139\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 45, train_loss = 5.924572329968214, train_acc = 0.9887051700046576\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 46, train_loss = 5.83782535046339, train_acc = 0.9888216115510013\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 47, train_loss = 5.757547673769295, train_acc = 0.9891709361900326\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 48, train_loss = 5.678006970323622, train_acc = 0.9892873777363763\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 49, train_loss = 5.601314359344542, train_acc = 0.9892873777363763\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 50, train_loss = 5.527808494865894, train_acc = 0.9892873777363763\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 51, train_loss = 5.456217137165368, train_acc = 0.9892873777363763\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 52, train_loss = 5.3877018401399255, train_acc = 0.9895202608290639\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 53, train_loss = 5.320190862752497, train_acc = 0.9896367023754076\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 54, train_loss = 5.255499673075974, train_acc = 0.9897531439217513\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 55, train_loss = 5.191707368940115, train_acc = 0.9897531439217513\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 56, train_loss = 5.128676392138004, train_acc = 0.989869585468095\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 57, train_loss = 5.069539711810648, train_acc = 0.9899860270144387\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 58, train_loss = 5.010773319751024, train_acc = 0.9902189101071263\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 59, train_loss = 4.9537982707843184, train_acc = 0.99033535165347\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 60, train_loss = 4.896568617783487, train_acc = 0.9906846762925011\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 61, train_loss = 4.841336753219366, train_acc = 0.990801117838845\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 62, train_loss = 4.788314157165587, train_acc = 0.990801117838845\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 63, train_loss = 4.738881465047598, train_acc = 0.9909175593851887\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 64, train_loss = 4.688000396825373, train_acc = 0.9909175593851887\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 65, train_loss = 4.640848544426262, train_acc = 0.9910340009315324\n",
      "test Acc 0.9697392923649907:\n",
      "17th- epoch: 66, train_loss = 4.592057548463345, train_acc = 0.9909175593851887\n",
      "test Acc 0.9697392923649907:\n",
      "17th- epoch: 67, train_loss = 4.547045788727701, train_acc = 0.9911504424778761\n",
      "test Acc 0.9697392923649907:\n",
      "17th- epoch: 68, train_loss = 4.501395356841385, train_acc = 0.9912668840242198\n",
      "test Acc 0.9697392923649907:\n",
      "17th- epoch: 69, train_loss = 4.458014604635537, train_acc = 0.9912668840242198\n",
      "test Acc 0.9697392923649907:\n",
      "17th- epoch: 70, train_loss = 4.415020357817411, train_acc = 0.9913833255705635\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 71, train_loss = 4.373243755660951, train_acc = 0.9913833255705635\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 72, train_loss = 4.332613633014262, train_acc = 0.9914997671169073\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 73, train_loss = 4.293546532746404, train_acc = 0.9916162086632511\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 74, train_loss = 4.255210497882217, train_acc = 0.9916162086632511\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 75, train_loss = 4.216185150202364, train_acc = 0.9914997671169073\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 76, train_loss = 4.180498783942312, train_acc = 0.9916162086632511\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 77, train_loss = 4.142866520676762, train_acc = 0.9914997671169073\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 78, train_loss = 4.106284712906927, train_acc = 0.9918490917559385\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 79, train_loss = 4.073204085230827, train_acc = 0.9918490917559385\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 80, train_loss = 4.039001366589218, train_acc = 0.9918490917559385\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 81, train_loss = 4.007037632167339, train_acc = 0.9918490917559385\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 82, train_loss = 3.972369378898293, train_acc = 0.9918490917559385\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 83, train_loss = 3.9403808191418648, train_acc = 0.9918490917559385\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 84, train_loss = 3.910320760216564, train_acc = 0.9918490917559385\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 85, train_loss = 3.879492865409702, train_acc = 0.9918490917559385\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 86, train_loss = 3.849482296500355, train_acc = 0.9918490917559385\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 87, train_loss = 3.818863155785948, train_acc = 0.9918490917559385\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 88, train_loss = 3.789883006364107, train_acc = 0.9919655333022822\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 89, train_loss = 3.7616759263910353, train_acc = 0.9919655333022822\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 90, train_loss = 3.734003968536854, train_acc = 0.9919655333022822\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 91, train_loss = 3.7074268870055676, train_acc = 0.992081974848626\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 92, train_loss = 3.6781699336133897, train_acc = 0.9921984163949698\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 93, train_loss = 3.653287523891777, train_acc = 0.9921984163949698\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 94, train_loss = 3.627797645982355, train_acc = 0.9921984163949698\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 95, train_loss = 3.6027622148394585, train_acc = 0.9923148579413135\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 96, train_loss = 3.5764924199320376, train_acc = 0.9925477410340009\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 97, train_loss = 3.5509758428670466, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 98, train_loss = 3.529232335742563, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 99, train_loss = 3.505092234816402, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 100, train_loss = 3.4798908308148384, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 101, train_loss = 3.4594424180686474, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 102, train_loss = 3.4357079514302313, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 103, train_loss = 3.4138258025050163, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 104, train_loss = 3.3920262777246535, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 105, train_loss = 3.371847879141569, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 106, train_loss = 3.3498546979390085, train_acc = 0.9928970656730322\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 107, train_loss = 3.3299171566031873, train_acc = 0.9928970656730322\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 108, train_loss = 3.308915668632835, train_acc = 0.9928970656730322\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 109, train_loss = 3.290790559258312, train_acc = 0.9928970656730322\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 110, train_loss = 3.270623877644539, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 111, train_loss = 3.250917164143175, train_acc = 0.9930135072193759\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 112, train_loss = 3.231349028646946, train_acc = 0.9932463903120633\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 113, train_loss = 3.213355647865683, train_acc = 0.9932463903120633\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 114, train_loss = 3.1956117474474013, train_acc = 0.9932463903120633\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 115, train_loss = 3.17731170123443, train_acc = 0.9932463903120633\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 116, train_loss = 3.159545899834484, train_acc = 0.9932463903120633\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 117, train_loss = 3.1429678313434124, train_acc = 0.9932463903120633\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 118, train_loss = 3.126294041518122, train_acc = 0.9933628318584071\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 119, train_loss = 3.1076142340898514, train_acc = 0.9933628318584071\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 120, train_loss = 3.091974904295057, train_acc = 0.9933628318584071\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 121, train_loss = 3.077004113700241, train_acc = 0.9934792734047508\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 122, train_loss = 3.0610049478709698, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 123, train_loss = 3.044664057670161, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 124, train_loss = 3.029187399893999, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 125, train_loss = 3.0134478074032813, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 126, train_loss = 2.998414022149518, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 127, train_loss = 2.9838007390499115, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 128, train_loss = 2.967801533639431, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 129, train_loss = 2.953477560309693, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 130, train_loss = 2.939859573962167, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 131, train_loss = 2.9256054025609046, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 132, train_loss = 2.911300579784438, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 133, train_loss = 2.8982043340802193, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 134, train_loss = 2.885437610326335, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 135, train_loss = 2.8726529951673, train_acc = 0.9941779226828132\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 136, train_loss = 2.859167554648593, train_acc = 0.9941779226828132\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 137, train_loss = 2.8461772974114865, train_acc = 0.9941779226828132\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 138, train_loss = 2.833983262302354, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 139, train_loss = 2.821266483515501, train_acc = 0.9941779226828132\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 140, train_loss = 2.809088787762448, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 141, train_loss = 2.7962989632505924, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 142, train_loss = 2.784074268070981, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 143, train_loss = 2.7733415625989437, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 144, train_loss = 2.762011807411909, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 145, train_loss = 2.7502874445635825, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 146, train_loss = 2.7394340720493346, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 147, train_loss = 2.727941842051223, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 148, train_loss = 2.7164813752751797, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 149, train_loss = 2.7052566695492715, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 150, train_loss = 2.695041333558038, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 151, train_loss = 2.685997150838375, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 152, train_loss = 2.674946417333558, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 153, train_loss = 2.6631306011695415, train_acc = 0.9944108057755007\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 154, train_loss = 2.654260865179822, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 155, train_loss = 2.6441113960463554, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 156, train_loss = 2.63368305680342, train_acc = 0.9944108057755007\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 157, train_loss = 2.624756882665679, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 158, train_loss = 2.6147971663158387, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 159, train_loss = 2.6051988292019814, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 160, train_loss = 2.595913474680856, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 161, train_loss = 2.5867110081017017, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 162, train_loss = 2.5779263488948345, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 163, train_loss = 2.569353972794488, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 164, train_loss = 2.560690713347867, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 165, train_loss = 2.551740914583206, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 166, train_loss = 2.5423100851476192, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 167, train_loss = 2.533742902101949, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 168, train_loss = 2.5257402558345348, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 169, train_loss = 2.516903417883441, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 170, train_loss = 2.5097055931109935, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 171, train_loss = 2.5009129468817264, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 172, train_loss = 2.49225115776062, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 173, train_loss = 2.484897290589288, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 174, train_loss = 2.476694480748847, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 175, train_loss = 2.4690990957897156, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 176, train_loss = 2.4613485757727176, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 177, train_loss = 2.4547960869967937, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 178, train_loss = 2.446753143100068, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 179, train_loss = 2.4388712148647755, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 180, train_loss = 2.428375447867438, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 181, train_loss = 2.4220881424844265, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 182, train_loss = 2.4150456190109253, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 183, train_loss = 2.4074452568311244, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 184, train_loss = 2.400609015254304, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 185, train_loss = 2.394453516928479, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 186, train_loss = 2.3881606683135033, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 187, train_loss = 2.3792313064914197, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 188, train_loss = 2.374149579554796, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 189, train_loss = 2.3666344943922013, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 190, train_loss = 2.3594821766018867, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 191, train_loss = 2.353624824434519, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 192, train_loss = 2.34705875441432, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 193, train_loss = 2.3405275382101536, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 194, train_loss = 2.3352163832169026, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 195, train_loss = 2.3283446058630943, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 196, train_loss = 2.321920237271115, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 197, train_loss = 2.3154504981357604, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 198, train_loss = 2.3098192911129445, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 199, train_loss = 2.3043011848349124, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 200, train_loss = 2.297785719158128, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 201, train_loss = 2.2923999689519405, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 202, train_loss = 2.2871052362024784, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 203, train_loss = 2.2805356718599796, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 204, train_loss = 2.2747953806538135, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 205, train_loss = 2.2689562687883154, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 206, train_loss = 2.264392307610251, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 207, train_loss = 2.2583624148974195, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 208, train_loss = 2.2536910896888003, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 209, train_loss = 2.2483326668152586, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 210, train_loss = 2.2417629597475752, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 211, train_loss = 2.237751400680281, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 212, train_loss = 2.232329865335487, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 213, train_loss = 2.227318207384087, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 214, train_loss = 2.2217580092838034, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 215, train_loss = 2.216759517788887, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 216, train_loss = 2.2116945883026347, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 217, train_loss = 2.207681721658446, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 218, train_loss = 2.2022405130555853, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 219, train_loss = 2.197706423699856, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 220, train_loss = 2.191660417825915, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 221, train_loss = 2.188286097138189, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 222, train_loss = 2.1841094940900803, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 223, train_loss = 2.1778495522448793, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 224, train_loss = 2.1746849616756663, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 225, train_loss = 2.169255096465349, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 226, train_loss = 2.165306138456799, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 227, train_loss = 2.1596842097351328, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 228, train_loss = 2.1549894511699677, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 229, train_loss = 2.150050785392523, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 230, train_loss = 2.1477132787695155, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 231, train_loss = 2.143344902782701, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 232, train_loss = 2.1382438590517268, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 233, train_loss = 2.134471377939917, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 234, train_loss = 2.130127420066856, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 235, train_loss = 2.1252458890667185, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 236, train_loss = 2.1216560415923595, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 237, train_loss = 2.117459960281849, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 238, train_loss = 2.1133025077870116, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 239, train_loss = 2.1091759825358167, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 240, train_loss = 2.1053995428374037, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 241, train_loss = 2.101925882161595, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 242, train_loss = 2.096117626875639, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 243, train_loss = 2.093710654764436, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 244, train_loss = 2.088986055343412, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 245, train_loss = 2.08563344925642, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 246, train_loss = 2.08160437643528, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 247, train_loss = 2.078162351041101, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 248, train_loss = 2.074513810337521, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 249, train_loss = 2.0703057758510113, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 250, train_loss = 2.0676954066148028, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 251, train_loss = 2.0633502999553457, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 252, train_loss = 2.0603076554834843, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 253, train_loss = 2.0566440857946873, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 254, train_loss = 2.0531138690421358, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 255, train_loss = 2.0497236996889114, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 256, train_loss = 2.04564957448747, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 257, train_loss = 2.0423553636064753, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 258, train_loss = 2.0389317435910925, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 259, train_loss = 2.035568686784245, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 260, train_loss = 2.0319413716206327, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 261, train_loss = 2.0291036689886823, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 262, train_loss = 2.025636179954745, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 263, train_loss = 2.0228809701511636, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 264, train_loss = 2.0191283574094996, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 265, train_loss = 2.0153817819664255, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 266, train_loss = 2.0135951600968838, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 267, train_loss = 2.009807664901018, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 268, train_loss = 2.0066240206360817, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 269, train_loss = 2.002951145172119, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 270, train_loss = 2.001060862094164, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 271, train_loss = 1.99794999754522, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 272, train_loss = 1.9941849248716608, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 273, train_loss = 1.991423413157463, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 274, train_loss = 1.9884815166005865, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 275, train_loss = 1.9849523367593065, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 276, train_loss = 1.9821691339602694, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 277, train_loss = 1.9793529895832762, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 278, train_loss = 1.9766807220876217, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 279, train_loss = 1.973616989911534, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 280, train_loss = 1.971753311692737, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 281, train_loss = 1.967671220540069, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 282, train_loss = 1.9657447934150696, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 283, train_loss = 1.962577617377974, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 284, train_loss = 1.9597653187811375, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 285, train_loss = 1.957145863561891, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 286, train_loss = 1.9545639058342203, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 287, train_loss = 1.9515815625200048, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 288, train_loss = 1.949210430146195, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 289, train_loss = 1.9457880891859531, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 290, train_loss = 1.9433076804270968, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 291, train_loss = 1.9414582749595866, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 292, train_loss = 1.9386608736822382, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 293, train_loss = 1.9361178850522265, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 294, train_loss = 1.9337955067167059, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 295, train_loss = 1.9309313707053661, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 296, train_loss = 1.92938581854105, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 297, train_loss = 1.9264258792391047, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 298, train_loss = 1.9241057323524728, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 299, train_loss = 1.9215584844350815, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 300, train_loss = 1.9181746704271063, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 301, train_loss = 1.9163521267473698, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 302, train_loss = 1.9142038399586454, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 303, train_loss = 1.9116362668573856, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 304, train_loss = 1.908659789711237, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 305, train_loss = 1.9076659617712721, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 306, train_loss = 1.9036742113530636, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 307, train_loss = 1.9017845193156973, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 308, train_loss = 1.8996764434268698, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 309, train_loss = 1.8976950546493754, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 310, train_loss = 1.895092242746614, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 311, train_loss = 1.89262293279171, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 312, train_loss = 1.8911723122000694, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 313, train_loss = 1.8883550291648135, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 314, train_loss = 1.8860963098704815, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 315, train_loss = 1.88441487273667, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 316, train_loss = 1.8821236317744479, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 317, train_loss = 1.8802176093449816, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 318, train_loss = 1.8772200904786587, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 319, train_loss = 1.8749609204242006, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 320, train_loss = 1.8734630657127127, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 321, train_loss = 1.8712260784814134, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 322, train_loss = 1.8692939853062853, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 323, train_loss = 1.867547040223144, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 324, train_loss = 1.8647013095906004, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 325, train_loss = 1.8629784869262949, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 326, train_loss = 1.8614880653331056, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 327, train_loss = 1.8587749550351873, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 328, train_loss = 1.8561357632279396, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 329, train_loss = 1.8553437453811057, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 330, train_loss = 1.852613830298651, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 331, train_loss = 1.8498172871768475, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 332, train_loss = 1.849062139808666, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 333, train_loss = 1.8471937936847098, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 334, train_loss = 1.845001130073797, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 335, train_loss = 1.8429133159224875, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 336, train_loss = 1.8409032833878882, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 337, train_loss = 1.8392667509615421, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 338, train_loss = 1.8371158477966674, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 339, train_loss = 1.8352615113253705, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 340, train_loss = 1.8336279268260114, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 341, train_loss = 1.8323395761544816, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 342, train_loss = 1.830075591802597, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 343, train_loss = 1.8277984435553662, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 344, train_loss = 1.8262505854363553, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 345, train_loss = 1.8244593304698355, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 346, train_loss = 1.8226079096202739, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 347, train_loss = 1.8201688838307746, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 348, train_loss = 1.8192038374836557, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 349, train_loss = 1.8174126570229419, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 350, train_loss = 1.815175011754036, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 351, train_loss = 1.8139844710822217, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 352, train_loss = 1.8122212712769397, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 353, train_loss = 1.810657624155283, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 354, train_loss = 1.8090712304110639, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 355, train_loss = 1.8065706503693946, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 356, train_loss = 1.805772586434614, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 357, train_loss = 1.8038544046576135, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 358, train_loss = 1.801816490769852, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 359, train_loss = 1.8001221207086928, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 360, train_loss = 1.7976675083045848, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 361, train_loss = 1.7971139612491243, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 362, train_loss = 1.7954402404720895, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 363, train_loss = 1.7937124446034431, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 364, train_loss = 1.7924076181952842, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 365, train_loss = 1.7900512740015984, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 366, train_loss = 1.7892658722703345, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 367, train_loss = 1.787227239459753, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 368, train_loss = 1.7857344460790046, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 369, train_loss = 1.784661776095163, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 370, train_loss = 1.7827402018010616, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 371, train_loss = 1.7814801968634129, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 372, train_loss = 1.7805028396542184, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 373, train_loss = 1.778373712033499, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 374, train_loss = 1.777086604386568, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 375, train_loss = 1.7751285160775296, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 376, train_loss = 1.7738406881690025, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 377, train_loss = 1.772447131574154, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 378, train_loss = 1.7714874384109862, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 379, train_loss = 1.770289006351959, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 380, train_loss = 1.7677985566551797, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 381, train_loss = 1.7676222597365268, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 382, train_loss = 1.7656406897003762, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 383, train_loss = 1.7639162478153594, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 384, train_loss = 1.7630971458856948, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 385, train_loss = 1.7612416123156436, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 386, train_loss = 1.758951989293564, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 387, train_loss = 1.7575471351738088, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 388, train_loss = 1.7571480845217593, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 389, train_loss = 1.7559711026842706, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 390, train_loss = 1.7540547847747803, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 391, train_loss = 1.753185621171724, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 392, train_loss = 1.7502249963581562, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 393, train_loss = 1.7502225289936177, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 394, train_loss = 1.7488169905846007, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 395, train_loss = 1.7474954947829247, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 396, train_loss = 1.7460551299154758, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 397, train_loss = 1.744838545739185, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 398, train_loss = 1.7429709769785404, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 399, train_loss = 1.7423484387691133, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 400, train_loss = 1.7413529169862159, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 401, train_loss = 1.7391330202226527, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 402, train_loss = 1.7383310596342199, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 403, train_loss = 1.7371069912915118, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 404, train_loss = 1.7353293225169182, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 405, train_loss = 1.7347123349900357, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 406, train_loss = 1.7326409767265432, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 407, train_loss = 1.731788132339716, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 408, train_loss = 1.7302693836390972, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 409, train_loss = 1.7298146399552934, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 410, train_loss = 1.7285301971132867, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 411, train_loss = 1.7272877842187881, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 412, train_loss = 1.7258836614782922, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 413, train_loss = 1.7245240770280361, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 414, train_loss = 1.7225980671937577, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 415, train_loss = 1.7222525465185754, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 416, train_loss = 1.7208600367303006, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 417, train_loss = 1.720073604315985, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 418, train_loss = 1.7189918358926661, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 419, train_loss = 1.7172837667167187, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 420, train_loss = 1.7167950359289534, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 421, train_loss = 1.7152100304956548, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 422, train_loss = 1.7142139884526841, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 423, train_loss = 1.7132435776293278, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 424, train_loss = 1.7111616643960588, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 425, train_loss = 1.7106204864685424, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 426, train_loss = 1.7096687965095043, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 427, train_loss = 1.70900472876383, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 428, train_loss = 1.7072260342538357, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 429, train_loss = 1.7063516701455228, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 430, train_loss = 1.7054072953760624, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 431, train_loss = 1.7039035484194756, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 432, train_loss = 1.7029703967273235, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 433, train_loss = 1.702024472237099, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 434, train_loss = 1.7011925987899303, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 435, train_loss = 1.6999725252389908, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 436, train_loss = 1.6990335161681287, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 437, train_loss = 1.6972882052068599, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 438, train_loss = 1.6969344802200794, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 439, train_loss = 1.6958743396098725, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 440, train_loss = 1.6943351328372955, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 441, train_loss = 1.6941710810060613, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 442, train_loss = 1.6928775496780872, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 443, train_loss = 1.691407072066795, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 444, train_loss = 1.6905198867316358, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 445, train_loss = 1.6897721613640897, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 446, train_loss = 1.6883662070031278, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 447, train_loss = 1.6873165468568914, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 448, train_loss = 1.6868657183949836, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 449, train_loss = 1.6857951444690116, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 450, train_loss = 1.6847756157512777, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 451, train_loss = 1.683433871716261, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 452, train_loss = 1.6830365297500975, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 453, train_loss = 1.681381816684734, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 454, train_loss = 1.6806922790710814, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 455, train_loss = 1.6799297754769213, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 456, train_loss = 1.6790118503267877, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 457, train_loss = 1.6780641078948975, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 458, train_loss = 1.6772904669051059, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 459, train_loss = 1.6761427633464336, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 460, train_loss = 1.6758561941678636, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 461, train_loss = 1.674922424077522, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 462, train_loss = 1.673067616939079, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 463, train_loss = 1.6730529889464378, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 464, train_loss = 1.6715892988140695, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 465, train_loss = 1.670623768121004, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 466, train_loss = 1.6703631356358528, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 467, train_loss = 1.669137667864561, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 468, train_loss = 1.668067832768429, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 469, train_loss = 1.6678902208805084, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 470, train_loss = 1.6660237610340118, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 471, train_loss = 1.6651627396349795, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 472, train_loss = 1.664656347304117, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 473, train_loss = 1.6633222053642385, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 474, train_loss = 1.6631110844318755, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 475, train_loss = 1.6622187060420401, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 476, train_loss = 1.6613393599982373, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 477, train_loss = 1.6601669763331302, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 478, train_loss = 1.6593016870319843, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 479, train_loss = 1.6587435081601143, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 480, train_loss = 1.6583040542900562, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 481, train_loss = 1.6573350044782273, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 482, train_loss = 1.656250812113285, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 483, train_loss = 1.6557932223076932, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 484, train_loss = 1.6545064362580888, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 485, train_loss = 1.6538398166303523, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 486, train_loss = 1.6531911852653138, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 487, train_loss = 1.6523732108180411, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 488, train_loss = 1.6510720923542976, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 489, train_loss = 1.6509547866880894, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 490, train_loss = 1.6493905943934806, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 491, train_loss = 1.6488178807194345, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 492, train_loss = 1.6483733914792538, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 493, train_loss = 1.6476645258371718, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 494, train_loss = 1.6464124197955243, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 495, train_loss = 1.6455027448828332, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 496, train_loss = 1.644984373182524, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 497, train_loss = 1.6443639521603473, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 498, train_loss = 1.6433564226026647, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 499, train_loss = 1.6425355027313344, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████▋                              | 17/30 [2:33:54<1:57:33, 542.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "18th- epoch: 0, train_loss = 101.42842911183834, train_acc = 0.7922682813227759\n",
      "test Acc 0.8854748603351955:\n",
      "18th- epoch: 1, train_loss = 41.419960260391235, train_acc = 0.9145319049836982\n",
      "test Acc 0.9222532588454376:\n",
      "18th- epoch: 2, train_loss = 32.25364777445793, train_acc = 0.9325803446669771\n",
      "test Acc 0.9390130353817505:\n",
      "18th- epoch: 3, train_loss = 27.3325407654047, train_acc = 0.9428272007452259\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 4, train_loss = 24.01680977270007, train_acc = 0.9501630181648812\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 5, train_loss = 21.591693732887506, train_acc = 0.9536562645551933\n",
      "test Acc 0.9515828677839852:\n",
      "18th- epoch: 6, train_loss = 19.753229081630707, train_acc = 0.9574988355845365\n",
      "test Acc 0.952513966480447:\n",
      "18th- epoch: 7, train_loss = 18.256784301251173, train_acc = 0.9607591988821611\n",
      "test Acc 0.9539106145251397:\n",
      "18th- epoch: 8, train_loss = 17.02084325067699, train_acc = 0.9622729389846297\n",
      "test Acc 0.9543761638733705:\n",
      "18th- epoch: 9, train_loss = 15.97510359250009, train_acc = 0.9650675360968793\n",
      "test Acc 0.9567039106145251:\n",
      "18th- epoch: 10, train_loss = 15.079950101673603, train_acc = 0.9673963670237541\n",
      "test Acc 0.957635009310987:\n",
      "18th- epoch: 11, train_loss = 14.300261100754142, train_acc = 0.97007452258966\n",
      "test Acc 0.9581005586592178:\n",
      "18th- epoch: 12, train_loss = 13.61424707248807, train_acc = 0.9714718211457848\n",
      "test Acc 0.9581005586592178:\n",
      "18th- epoch: 13, train_loss = 13.01260251365602, train_acc = 0.9729855612482534\n",
      "test Acc 0.9590316573556797:\n",
      "18th- epoch: 14, train_loss = 12.472462924197316, train_acc = 0.9741499767116907\n",
      "test Acc 0.9599627560521415:\n",
      "18th- epoch: 15, train_loss = 11.992810305207968, train_acc = 0.9758965999068467\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 16, train_loss = 11.54940184764564, train_acc = 0.9768281322775967\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 17, train_loss = 11.148034626618028, train_acc = 0.9776432231020028\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 18, train_loss = 10.778439546003938, train_acc = 0.9785747554727526\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 19, train_loss = 10.446974104270339, train_acc = 0.9789240801117839\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 20, train_loss = 10.134049378335476, train_acc = 0.9795062878435026\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 21, train_loss = 9.846580643206835, train_acc = 0.9805542617605962\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 22, train_loss = 9.575597297400236, train_acc = 0.9811364694923148\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 23, train_loss = 9.319786939769983, train_acc = 0.9816022356776898\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 24, train_loss = 9.085998550057411, train_acc = 0.9820680018630648\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 25, train_loss = 8.862482786178589, train_acc = 0.9823008849557522\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 26, train_loss = 8.646723955869675, train_acc = 0.9827666511411272\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 27, train_loss = 8.444677531719208, train_acc = 0.9829995342338146\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 28, train_loss = 8.255022627301514, train_acc = 0.9834653004191896\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 29, train_loss = 8.070983720943332, train_acc = 0.983698183511877\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 30, train_loss = 7.896613938733935, train_acc = 0.9840475081509082\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 31, train_loss = 7.731907225213945, train_acc = 0.9843968327899395\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 32, train_loss = 7.57549209613353, train_acc = 0.9845132743362832\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 33, train_loss = 7.422538835555315, train_acc = 0.9848625989753144\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 34, train_loss = 7.280733209103346, train_acc = 0.9853283651606893\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 35, train_loss = 7.136736784130335, train_acc = 0.9855612482533768\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 36, train_loss = 7.004802160896361, train_acc = 0.9857941313460643\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 37, train_loss = 6.880309010855854, train_acc = 0.9860270144387517\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 38, train_loss = 6.756032275035977, train_acc = 0.9861434559850955\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 39, train_loss = 6.6389510771259665, train_acc = 0.9867256637168141\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 40, train_loss = 6.528941900469363, train_acc = 0.9870749883558454\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 41, train_loss = 6.416197923012078, train_acc = 0.9873078714485328\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 42, train_loss = 6.312114431522787, train_acc = 0.9875407545412203\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 43, train_loss = 6.209554399363697, train_acc = 0.9877736376339078\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 44, train_loss = 6.111328489147127, train_acc = 0.9881229622729389\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 45, train_loss = 6.017355277203023, train_acc = 0.9884722869119702\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 46, train_loss = 5.922735643573105, train_acc = 0.9887051700046576\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 47, train_loss = 5.833285165950656, train_acc = 0.9887051700046576\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 48, train_loss = 5.743562125600874, train_acc = 0.9889380530973452\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 49, train_loss = 5.658038964495063, train_acc = 0.9889380530973452\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 50, train_loss = 5.574520921334624, train_acc = 0.9891709361900326\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 51, train_loss = 5.497568491846323, train_acc = 0.9895202608290639\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 52, train_loss = 5.42142388690263, train_acc = 0.9897531439217513\n",
      "test Acc 0.9706703910614525:\n",
      "18th- epoch: 53, train_loss = 5.347038215026259, train_acc = 0.989869585468095\n",
      "test Acc 0.9711359404096834:\n",
      "18th- epoch: 54, train_loss = 5.274016078561544, train_acc = 0.989869585468095\n",
      "test Acc 0.9711359404096834:\n",
      "18th- epoch: 55, train_loss = 5.204762117005885, train_acc = 0.9899860270144387\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 56, train_loss = 5.138346831314266, train_acc = 0.9899860270144387\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 57, train_loss = 5.071749419905245, train_acc = 0.9899860270144387\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 58, train_loss = 5.0065759075805545, train_acc = 0.9901024685607824\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 59, train_loss = 4.944235963746905, train_acc = 0.9901024685607824\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 60, train_loss = 4.885943599976599, train_acc = 0.9904517931998137\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 61, train_loss = 4.82931889872998, train_acc = 0.9904517931998137\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 62, train_loss = 4.772004246711731, train_acc = 0.9905682347461574\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 63, train_loss = 4.720285716466606, train_acc = 0.990801117838845\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 64, train_loss = 4.667942056432366, train_acc = 0.9909175593851887\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 65, train_loss = 4.615978283807635, train_acc = 0.9910340009315324\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 66, train_loss = 4.567296891473234, train_acc = 0.9911504424778761\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 67, train_loss = 4.517415744252503, train_acc = 0.9912668840242198\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 68, train_loss = 4.473224048502743, train_acc = 0.9912668840242198\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 69, train_loss = 4.426064590923488, train_acc = 0.9913833255705635\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 70, train_loss = 4.380791142582893, train_acc = 0.9914997671169073\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 71, train_loss = 4.337297935970128, train_acc = 0.9914997671169073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 72, train_loss = 4.295250819995999, train_acc = 0.9914997671169073\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 73, train_loss = 4.253808477893472, train_acc = 0.9914997671169073\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 74, train_loss = 4.212777498178184, train_acc = 0.9917326502095948\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 75, train_loss = 4.175179521553218, train_acc = 0.9917326502095948\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 76, train_loss = 4.1365630105137825, train_acc = 0.9917326502095948\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 77, train_loss = 4.096885221544653, train_acc = 0.9917326502095948\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 78, train_loss = 4.061061445157975, train_acc = 0.9919655333022822\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 79, train_loss = 4.025885900482535, train_acc = 0.9919655333022822\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 80, train_loss = 3.99035463668406, train_acc = 0.9919655333022822\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 81, train_loss = 3.9574786657467484, train_acc = 0.992081974848626\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 82, train_loss = 3.9228417784906924, train_acc = 0.9921984163949698\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 83, train_loss = 3.8903988860547543, train_acc = 0.9921984163949698\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 84, train_loss = 3.8577852421440184, train_acc = 0.9924312994876572\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 85, train_loss = 3.826810770202428, train_acc = 0.9924312994876572\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 86, train_loss = 3.795781242195517, train_acc = 0.9925477410340009\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 87, train_loss = 3.765534109901637, train_acc = 0.9925477410340009\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 88, train_loss = 3.736363871023059, train_acc = 0.9925477410340009\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 89, train_loss = 3.7083976971916854, train_acc = 0.9925477410340009\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 90, train_loss = 3.6795343249104917, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 91, train_loss = 3.652634385507554, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 92, train_loss = 3.6258423938415945, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 93, train_loss = 3.599499825388193, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 94, train_loss = 3.5733253504149616, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 95, train_loss = 3.5468908534385264, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 96, train_loss = 3.5229661012999713, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 97, train_loss = 3.4987087226472795, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 98, train_loss = 3.475884899031371, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 99, train_loss = 3.452032139059156, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 100, train_loss = 3.427672889083624, train_acc = 0.9931299487657196\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 101, train_loss = 3.4071299228817225, train_acc = 0.9931299487657196\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 102, train_loss = 3.385011036414653, train_acc = 0.9931299487657196\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 103, train_loss = 3.362778244074434, train_acc = 0.9931299487657196\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 104, train_loss = 3.3415485504083335, train_acc = 0.9931299487657196\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 105, train_loss = 3.320359210949391, train_acc = 0.9931299487657196\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 106, train_loss = 3.2991652502678335, train_acc = 0.9931299487657196\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 107, train_loss = 3.278211879078299, train_acc = 0.9931299487657196\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 108, train_loss = 3.258704192470759, train_acc = 0.9931299487657196\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 109, train_loss = 3.2399341017007828, train_acc = 0.9931299487657196\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 110, train_loss = 3.2200845293700695, train_acc = 0.9931299487657196\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 111, train_loss = 3.200549719389528, train_acc = 0.9931299487657196\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 112, train_loss = 3.182106610853225, train_acc = 0.9933628318584071\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 113, train_loss = 3.164562326390296, train_acc = 0.9934792734047508\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 114, train_loss = 3.1474217898212373, train_acc = 0.9934792734047508\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 115, train_loss = 3.1284731682389975, train_acc = 0.9935957149510946\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 116, train_loss = 3.110062535852194, train_acc = 0.9935957149510946\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 117, train_loss = 3.0930586899630725, train_acc = 0.9935957149510946\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 118, train_loss = 3.077243904117495, train_acc = 0.9935957149510946\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 119, train_loss = 3.0619359561242163, train_acc = 0.9935957149510946\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 120, train_loss = 3.0453574527055025, train_acc = 0.9937121564974383\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 121, train_loss = 3.0292209782637656, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 122, train_loss = 3.014069177210331, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 123, train_loss = 2.9988243505358696, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 124, train_loss = 2.9847000469453633, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 125, train_loss = 2.967078447341919, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 126, train_loss = 2.9542726525105536, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 127, train_loss = 2.9400102444924414, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 128, train_loss = 2.925231489818543, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 129, train_loss = 2.91134873079136, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 130, train_loss = 2.8993090875446796, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 131, train_loss = 2.883848068770021, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 132, train_loss = 2.872086448594928, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 133, train_loss = 2.859236253425479, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 134, train_loss = 2.844715803861618, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 135, train_loss = 2.8330261767841876, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 136, train_loss = 2.8207762334495783, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 137, train_loss = 2.8078605686314404, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 138, train_loss = 2.7963860840536654, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 139, train_loss = 2.783535722643137, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 140, train_loss = 2.7716015963815153, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 141, train_loss = 2.7616519411094487, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 142, train_loss = 2.7497633402235806, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 143, train_loss = 2.737577533815056, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 144, train_loss = 2.7277242112904787, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 145, train_loss = 2.716330000665039, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 146, train_loss = 2.7056511542759836, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 147, train_loss = 2.694028570782393, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 148, train_loss = 2.685331621672958, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 149, train_loss = 2.6742811831645668, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 150, train_loss = 2.6627488075755537, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 151, train_loss = 2.6542117879725993, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 152, train_loss = 2.6429676502011716, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 153, train_loss = 2.6329568673390895, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 154, train_loss = 2.623894355027005, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 155, train_loss = 2.6141066532582045, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 156, train_loss = 2.605004431679845, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 157, train_loss = 2.5952319155912846, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 158, train_loss = 2.586750252870843, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 159, train_loss = 2.5776096805930138, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 160, train_loss = 2.5673624898772687, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 161, train_loss = 2.5596306566148996, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 162, train_loss = 2.5509177173953503, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 163, train_loss = 2.541215667501092, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 164, train_loss = 2.533868243219331, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 165, train_loss = 2.5248378608375788, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 166, train_loss = 2.5161736209411174, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 167, train_loss = 2.507693041115999, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 168, train_loss = 2.501160368323326, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 169, train_loss = 2.4926313862670213, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 170, train_loss = 2.4855944823939353, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 171, train_loss = 2.4772242847830057, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 172, train_loss = 2.4680907141882926, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 173, train_loss = 2.461536272196099, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 174, train_loss = 2.45274541224353, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 175, train_loss = 2.445960757089779, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 176, train_loss = 2.438895446015522, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 177, train_loss = 2.4325102034490556, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 178, train_loss = 2.4237481832969934, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 179, train_loss = 2.4168090627063066, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 180, train_loss = 2.4088575069326907, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 181, train_loss = 2.4018268778454512, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 182, train_loss = 2.3949224806856364, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 183, train_loss = 2.3889276299159974, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 184, train_loss = 2.3821616612840444, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 185, train_loss = 2.3758658196311444, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 186, train_loss = 2.369168394478038, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 187, train_loss = 2.361572592286393, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 188, train_loss = 2.3559597625862807, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 189, train_loss = 2.3488483286928385, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 190, train_loss = 2.3420941352378577, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 191, train_loss = 2.336561157600954, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 192, train_loss = 2.3302262127399445, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 193, train_loss = 2.323685872135684, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 194, train_loss = 2.3199580411892384, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 195, train_loss = 2.3134688909631222, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 196, train_loss = 2.30607720464468, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 197, train_loss = 2.3013496417552233, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 198, train_loss = 2.2951184276025742, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 199, train_loss = 2.289074894040823, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 200, train_loss = 2.28438898245804, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 201, train_loss = 2.2782630503643304, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 202, train_loss = 2.2719116408843547, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 203, train_loss = 2.2668031703215092, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 204, train_loss = 2.261181193171069, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 205, train_loss = 2.2548168532084674, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 206, train_loss = 2.2501235406380147, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 207, train_loss = 2.244960568845272, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 208, train_loss = 2.240464724600315, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 209, train_loss = 2.2352041602134705, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 210, train_loss = 2.2309366918634623, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 211, train_loss = 2.22377560287714, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 212, train_loss = 2.220024000154808, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 213, train_loss = 2.215224574552849, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 214, train_loss = 2.2098054091911763, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 215, train_loss = 2.2046259716153145, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 216, train_loss = 2.200586336432025, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 217, train_loss = 2.194708786904812, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 218, train_loss = 2.190149578033015, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 219, train_loss = 2.185690416023135, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 220, train_loss = 2.1823559310287237, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 221, train_loss = 2.177961279405281, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 222, train_loss = 2.1730136293917894, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 223, train_loss = 2.16832279227674, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 224, train_loss = 2.1645342633128166, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 225, train_loss = 2.1599502004683018, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 226, train_loss = 2.1553257156629115, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 227, train_loss = 2.1511114209424704, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 228, train_loss = 2.146159475669265, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 229, train_loss = 2.141596971778199, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 230, train_loss = 2.1379127490799874, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 231, train_loss = 2.133519080700353, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 232, train_loss = 2.128808407811448, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 233, train_loss = 2.125510659767315, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 234, train_loss = 2.1207868221681565, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 235, train_loss = 2.1170577604789287, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 236, train_loss = 2.1145950395148247, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 237, train_loss = 2.110501115443185, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 238, train_loss = 2.1059527806937695, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 239, train_loss = 2.1019119631964713, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 240, train_loss = 2.0981842260807753, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 241, train_loss = 2.0952595204580575, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 242, train_loss = 2.0903224151115865, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 243, train_loss = 2.0863637414295226, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 244, train_loss = 2.083963689627126, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 245, train_loss = 2.080382355256006, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 246, train_loss = 2.0762891366612166, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 247, train_loss = 2.0724738899152726, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 248, train_loss = 2.0697409498970956, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 249, train_loss = 2.064718984765932, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 250, train_loss = 2.0624908364843577, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 251, train_loss = 2.059069345938042, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 252, train_loss = 2.055055510951206, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 253, train_loss = 2.051507645053789, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 254, train_loss = 2.0483447536826134, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 255, train_loss = 2.0448501855134964, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 256, train_loss = 2.041636203182861, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 257, train_loss = 2.037664943607524, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 258, train_loss = 2.034867649897933, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 259, train_loss = 2.032062391983345, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 260, train_loss = 2.028341229306534, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 261, train_loss = 2.0258000332396477, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 262, train_loss = 2.0226512055378407, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 263, train_loss = 2.0186725363601, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 264, train_loss = 2.014883666532114, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 265, train_loss = 2.0119104739278555, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 266, train_loss = 2.0095329533796757, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 267, train_loss = 2.0056006007362157, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 268, train_loss = 2.00254003261216, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 269, train_loss = 1.9994770709890872, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 270, train_loss = 1.9974104264983907, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 271, train_loss = 1.994389047846198, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 272, train_loss = 1.9921010906109586, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 273, train_loss = 1.988402514369227, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 274, train_loss = 1.9841715451329947, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 275, train_loss = 1.9824022818356752, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 276, train_loss = 1.9785067351767793, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 277, train_loss = 1.9767569545656443, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 278, train_loss = 1.9739619916072115, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 279, train_loss = 1.9708923822036013, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 280, train_loss = 1.9677354147424921, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 281, train_loss = 1.96634610183537, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 282, train_loss = 1.9626931622624397, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 283, train_loss = 1.960244776098989, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 284, train_loss = 1.957233135937713, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 285, train_loss = 1.9527477715164423, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 286, train_loss = 1.9514264352619648, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 287, train_loss = 1.9487201888114214, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 288, train_loss = 1.9457688132533804, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 289, train_loss = 1.9442436899989843, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 290, train_loss = 1.9396929877111688, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 291, train_loss = 1.938940335647203, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 292, train_loss = 1.9355615135282278, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 293, train_loss = 1.9331246638903394, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 294, train_loss = 1.9312774805584922, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 295, train_loss = 1.9289451638469473, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 296, train_loss = 1.9264561334857717, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 297, train_loss = 1.92381853365805, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 298, train_loss = 1.9214881099760532, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 299, train_loss = 1.9189929278800264, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 300, train_loss = 1.916403315961361, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 301, train_loss = 1.9143840397009626, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 302, train_loss = 1.911978643387556, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 303, train_loss = 1.910074913292192, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 304, train_loss = 1.9065318988868967, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 305, train_loss = 1.905260045081377, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 306, train_loss = 1.9022273620357737, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 307, train_loss = 1.9006141225108877, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 308, train_loss = 1.8981336677679792, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 309, train_loss = 1.8959585279226303, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 310, train_loss = 1.8940932055702433, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 311, train_loss = 1.8921011289348826, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 312, train_loss = 1.888698749244213, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 313, train_loss = 1.8871699757874012, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 314, train_loss = 1.8856667341897264, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 315, train_loss = 1.8828513212502003, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 316, train_loss = 1.880646156729199, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 317, train_loss = 1.8785677688429132, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 318, train_loss = 1.8771239407360554, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 319, train_loss = 1.8748189782490954, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 320, train_loss = 1.87239435443189, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 321, train_loss = 1.8702671764185652, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 322, train_loss = 1.8691112361848354, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 323, train_loss = 1.8659405745565891, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 324, train_loss = 1.863673740415834, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 325, train_loss = 1.8630843436112627, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 326, train_loss = 1.8601003661751747, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 327, train_loss = 1.8582675531506538, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 328, train_loss = 1.8566721640527248, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 329, train_loss = 1.8544666258385405, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 330, train_loss = 1.853268658160232, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 331, train_loss = 1.8500680712750182, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 332, train_loss = 1.848630235879682, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 333, train_loss = 1.8470125632593408, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 334, train_loss = 1.8457052372395992, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 335, train_loss = 1.8426889652619138, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 336, train_loss = 1.8412991861114278, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 337, train_loss = 1.8393213351955637, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 338, train_loss = 1.8383203720441088, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 339, train_loss = 1.8363734098384157, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 340, train_loss = 1.833486138493754, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 341, train_loss = 1.8328222768614069, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 342, train_loss = 1.8303833740064874, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 343, train_loss = 1.828887784271501, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 344, train_loss = 1.8265215965220705, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 345, train_loss = 1.8256499072303995, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 346, train_loss = 1.823014316498302, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 347, train_loss = 1.8223049938678741, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 348, train_loss = 1.8205515505978838, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 349, train_loss = 1.8176576904952526, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 350, train_loss = 1.8170509500196204, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 351, train_loss = 1.814819823950529, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 352, train_loss = 1.8134673461318016, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 353, train_loss = 1.8112781159579754, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 354, train_loss = 1.8101816648850217, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 355, train_loss = 1.8087685108184814, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 356, train_loss = 1.8067927373340353, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 357, train_loss = 1.8046781892189756, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 358, train_loss = 1.8038035096833482, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 359, train_loss = 1.801657062023878, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 360, train_loss = 1.8004089556634426, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 361, train_loss = 1.798720439313911, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 362, train_loss = 1.7963721863925457, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 363, train_loss = 1.7961374135920778, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 364, train_loss = 1.7953604807844386, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 365, train_loss = 1.7929964425275102, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 366, train_loss = 1.7912361348280683, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 367, train_loss = 1.789429179043509, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 368, train_loss = 1.7876598400762305, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 369, train_loss = 1.7871498676249757, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 370, train_loss = 1.784590574563481, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 371, train_loss = 1.783654714585282, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 372, train_loss = 1.782126173377037, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 373, train_loss = 1.7805589586496353, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 374, train_loss = 1.7793149253120646, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 375, train_loss = 1.7769508747151121, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 376, train_loss = 1.776249684393406, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 377, train_loss = 1.7745573371648788, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 378, train_loss = 1.7739160023629665, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 379, train_loss = 1.7719211416551843, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 380, train_loss = 1.7704727575182915, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 381, train_loss = 1.7689239805331454, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 382, train_loss = 1.7681708857417107, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 383, train_loss = 1.7660759141435847, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 384, train_loss = 1.7652657380094752, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 385, train_loss = 1.7625953344395384, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 386, train_loss = 1.7621553366770968, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 387, train_loss = 1.7612456692149863, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 388, train_loss = 1.7595252692699432, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 389, train_loss = 1.7581640854477882, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 390, train_loss = 1.7568763034651056, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 391, train_loss = 1.7552536254515871, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 392, train_loss = 1.7542874416103587, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 393, train_loss = 1.75298146775458, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 394, train_loss = 1.751357930363156, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 395, train_loss = 1.7500470826635137, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 396, train_loss = 1.7500542178750038, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 397, train_loss = 1.7475269250571728, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 398, train_loss = 1.7467508489498869, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 399, train_loss = 1.745708984672092, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 400, train_loss = 1.7437053670873865, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 401, train_loss = 1.7423948781797662, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 402, train_loss = 1.7413574481615797, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 403, train_loss = 1.7397138873348013, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 404, train_loss = 1.739213996916078, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 405, train_loss = 1.73781233408954, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 406, train_loss = 1.736741304397583, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 407, train_loss = 1.7354768613586202, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 408, train_loss = 1.7337362369289622, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 409, train_loss = 1.7324906723806635, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 410, train_loss = 1.7316310008754954, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 411, train_loss = 1.7303532473742962, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 412, train_loss = 1.729072151123546, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 413, train_loss = 1.7283861687174067, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 414, train_loss = 1.7263340851059183, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 415, train_loss = 1.725722137838602, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 416, train_loss = 1.724517478258349, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 417, train_loss = 1.7233317643404007, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 418, train_loss = 1.7227005138993263, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 419, train_loss = 1.720608817995526, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 420, train_loss = 1.7199102950980887, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 421, train_loss = 1.719611416279804, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 422, train_loss = 1.717186945141293, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 423, train_loss = 1.7162489990587346, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 424, train_loss = 1.7157869401271455, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 425, train_loss = 1.7133061761851422, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 426, train_loss = 1.7126977716688998, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 427, train_loss = 1.7121410109102726, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 428, train_loss = 1.7109537671203725, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 429, train_loss = 1.7091862025554292, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 430, train_loss = 1.709516512870323, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 431, train_loss = 1.7075528353452682, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 432, train_loss = 1.7063616911764257, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 433, train_loss = 1.7059277879889123, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 434, train_loss = 1.704061719297897, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 435, train_loss = 1.703617587685585, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 436, train_loss = 1.7028100329334848, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 437, train_loss = 1.7014055947656743, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 438, train_loss = 1.7002281596069224, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 439, train_loss = 1.699426117062103, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 440, train_loss = 1.6978693616692908, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 441, train_loss = 1.6971620619297028, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 442, train_loss = 1.6962669367785566, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 443, train_loss = 1.6955271288752556, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 444, train_loss = 1.6939939123694785, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 445, train_loss = 1.6931900680065155, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 446, train_loss = 1.6926288791000843, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 447, train_loss = 1.6913739033043385, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 448, train_loss = 1.6905234269797802, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 449, train_loss = 1.6889324436779134, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 450, train_loss = 1.688958253711462, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 451, train_loss = 1.687447125732433, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 452, train_loss = 1.685968592762947, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 453, train_loss = 1.6857929180259816, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 454, train_loss = 1.6842075909371488, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 455, train_loss = 1.684349287301302, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 456, train_loss = 1.6825168666546233, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 457, train_loss = 1.681629043072462, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 458, train_loss = 1.6807380567188375, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 459, train_loss = 1.6793707397882827, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 460, train_loss = 1.6796937708859332, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 461, train_loss = 1.6782343809609301, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 462, train_loss = 1.6768962455098517, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 463, train_loss = 1.6758857543463819, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 464, train_loss = 1.6752077899873257, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 465, train_loss = 1.6741525096003897, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 466, train_loss = 1.6736795728211291, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 467, train_loss = 1.6728253091569059, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 468, train_loss = 1.6712918964331038, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 469, train_loss = 1.6703930534422398, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 470, train_loss = 1.6696408353745937, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 471, train_loss = 1.6693512449855916, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 472, train_loss = 1.6682787165045738, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 473, train_loss = 1.6670386108453386, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 474, train_loss = 1.6661639573867433, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 475, train_loss = 1.6658062475617044, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 476, train_loss = 1.6644753403961658, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 477, train_loss = 1.6634269493515603, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 478, train_loss = 1.6630874909460545, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 479, train_loss = 1.662378394335974, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 480, train_loss = 1.660932810336817, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 481, train_loss = 1.6606356774573214, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 482, train_loss = 1.6599527038633823, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 483, train_loss = 1.6590285412967205, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 484, train_loss = 1.6580218635499477, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 485, train_loss = 1.6574989706277847, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 486, train_loss = 1.6562977731227875, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 487, train_loss = 1.655907376378309, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 488, train_loss = 1.6542450971901417, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 489, train_loss = 1.6537488624453545, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 490, train_loss = 1.6535128255491145, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 491, train_loss = 1.6528650373220444, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 492, train_loss = 1.6515310406684875, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 493, train_loss = 1.6508900336921215, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 494, train_loss = 1.6502090406720527, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 495, train_loss = 1.6491343614761718, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 496, train_loss = 1.6485060105915181, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 497, train_loss = 1.647596087306738, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 498, train_loss = 1.6473348923027515, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 499, train_loss = 1.6461974903941154, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████                            | 18/30 [2:42:56<1:48:28, 542.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "19th- epoch: 0, train_loss = 117.58458161354065, train_acc = 0.7876106194690266\n",
      "test Acc 0.8780260707635009:\n",
      "19th- epoch: 1, train_loss = 40.73934967070818, train_acc = 0.916394969725198\n",
      "test Acc 0.914804469273743:\n",
      "19th- epoch: 2, train_loss = 30.69610169157386, train_acc = 0.9368886818816954\n",
      "test Acc 0.9366852886405959:\n",
      "19th- epoch: 3, train_loss = 25.680314112454653, train_acc = 0.9455053563111319\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 4, train_loss = 22.459307048469782, train_acc = 0.9535398230088495\n",
      "test Acc 0.952513966480447:\n",
      "19th- epoch: 5, train_loss = 20.139185670763254, train_acc = 0.9592454587796926\n",
      "test Acc 0.952513966480447:\n",
      "19th- epoch: 6, train_loss = 18.34933828189969, train_acc = 0.9629715882626921\n",
      "test Acc 0.9543761638733705:\n",
      "19th- epoch: 7, train_loss = 16.914335824549198, train_acc = 0.9650675360968793\n",
      "test Acc 0.9553072625698324:\n",
      "19th- epoch: 8, train_loss = 15.742943918332458, train_acc = 0.9673963670237541\n",
      "test Acc 0.9581005586592178:\n",
      "19th- epoch: 9, train_loss = 14.75970271974802, train_acc = 0.9697251979506288\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 10, train_loss = 13.91772422939539, train_acc = 0.971821145784816\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 11, train_loss = 13.179997054859996, train_acc = 0.9733348858872846\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 12, train_loss = 12.523617601022124, train_acc = 0.9751979506287843\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 13, train_loss = 11.95104132220149, train_acc = 0.9758965999068467\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 14, train_loss = 11.44233750551939, train_acc = 0.9767116907312529\n",
      "test Acc 0.9641527001862198:\n",
      "19th- epoch: 15, train_loss = 10.976224906742573, train_acc = 0.9774103400093154\n",
      "test Acc 0.9641527001862198:\n",
      "19th- epoch: 16, train_loss = 10.562505589798093, train_acc = 0.9783418723800652\n",
      "test Acc 0.9650837988826816:\n",
      "19th- epoch: 17, train_loss = 10.186199557036161, train_acc = 0.9791569632044713\n",
      "test Acc 0.9655493482309124:\n",
      "19th- epoch: 18, train_loss = 9.842687748372555, train_acc = 0.9793898462971589\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 19, train_loss = 9.528872026130557, train_acc = 0.9804378202142524\n",
      "test Acc 0.9660148975791434:\n",
      "19th- epoch: 20, train_loss = 9.238882591947913, train_acc = 0.9811364694923148\n",
      "test Acc 0.9660148975791434:\n",
      "19th- epoch: 21, train_loss = 8.972254745662212, train_acc = 0.9818351187703773\n",
      "test Acc 0.9660148975791434:\n",
      "19th- epoch: 22, train_loss = 8.725415486842394, train_acc = 0.9824173265020959\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 23, train_loss = 8.493548119440675, train_acc = 0.9831159757801584\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 24, train_loss = 8.274126151576638, train_acc = 0.9835817419655333\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 25, train_loss = 8.073889957740903, train_acc = 0.9842803912435957\n",
      "test Acc 0.9669459962756052:\n",
      "19th- epoch: 26, train_loss = 7.883100800216198, train_acc = 0.9849790405216581\n",
      "test Acc 0.9669459962756052:\n",
      "19th- epoch: 27, train_loss = 7.704700709320605, train_acc = 0.985444806707033\n",
      "test Acc 0.9669459962756052:\n",
      "19th- epoch: 28, train_loss = 7.534167199395597, train_acc = 0.9855612482533768\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 29, train_loss = 7.373590020462871, train_acc = 0.9860270144387517\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 30, train_loss = 7.223649984225631, train_acc = 0.9862598975314392\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 31, train_loss = 7.080616411752999, train_acc = 0.986376339077783\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 32, train_loss = 6.943756275810301, train_acc = 0.9866092221704704\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 33, train_loss = 6.812774553894997, train_acc = 0.9866092221704704\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 34, train_loss = 6.6883647963404655, train_acc = 0.9866092221704704\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 35, train_loss = 6.568273446522653, train_acc = 0.9871914299021891\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 36, train_loss = 6.453486037440598, train_acc = 0.9871914299021891\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 37, train_loss = 6.3401435343548656, train_acc = 0.9874243129948765\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 38, train_loss = 6.232556733302772, train_acc = 0.9876571960875641\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 39, train_loss = 6.131378679536283, train_acc = 0.9875407545412203\n",
      "test Acc 0.9674115456238361:\n",
      "19th- epoch: 40, train_loss = 6.033218468539417, train_acc = 0.9878900791802515\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 41, train_loss = 5.937526696361601, train_acc = 0.9880065207265952\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 42, train_loss = 5.846841983497143, train_acc = 0.9882394038192828\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 43, train_loss = 5.758662377484143, train_acc = 0.9883558453656265\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 44, train_loss = 5.672245403751731, train_acc = 0.9887051700046576\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 45, train_loss = 5.590907230973244, train_acc = 0.9889380530973452\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 46, train_loss = 5.509991714730859, train_acc = 0.98940381928272\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 47, train_loss = 5.431007655337453, train_acc = 0.9896367023754076\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 48, train_loss = 5.35647485870868, train_acc = 0.9897531439217513\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 49, train_loss = 5.284397637471557, train_acc = 0.9896367023754076\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 50, train_loss = 5.21358313318342, train_acc = 0.9896367023754076\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 51, train_loss = 5.146294394508004, train_acc = 0.9896367023754076\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 52, train_loss = 5.078720271587372, train_acc = 0.9896367023754076\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 53, train_loss = 5.012347369454801, train_acc = 0.989869585468095\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 54, train_loss = 4.949842973612249, train_acc = 0.99033535165347\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 55, train_loss = 4.888075678609312, train_acc = 0.99033535165347\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 56, train_loss = 4.830042307265103, train_acc = 0.9905682347461574\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 57, train_loss = 4.773044356144965, train_acc = 0.9905682347461574\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 58, train_loss = 4.718499085865915, train_acc = 0.9910340009315324\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 59, train_loss = 4.664140268228948, train_acc = 0.9911504424778761\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 60, train_loss = 4.6133850160986185, train_acc = 0.9911504424778761\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 61, train_loss = 4.56318764667958, train_acc = 0.9911504424778761\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 62, train_loss = 4.513934578746557, train_acc = 0.9912668840242198\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 63, train_loss = 4.466915862634778, train_acc = 0.9912668840242198\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 64, train_loss = 4.420600266195834, train_acc = 0.9912668840242198\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 65, train_loss = 4.375438099727035, train_acc = 0.9912668840242198\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 66, train_loss = 4.331200765445828, train_acc = 0.9914997671169073\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 67, train_loss = 4.2881377367302775, train_acc = 0.9916162086632511\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 68, train_loss = 4.247010390274227, train_acc = 0.9917326502095948\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 69, train_loss = 4.206915459595621, train_acc = 0.9917326502095948\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 70, train_loss = 4.167933304794133, train_acc = 0.9917326502095948\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 71, train_loss = 4.129024798050523, train_acc = 0.9918490917559385\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 72, train_loss = 4.093756818212569, train_acc = 0.9918490917559385\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 73, train_loss = 4.055214744992554, train_acc = 0.9918490917559385\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 74, train_loss = 4.020166207104921, train_acc = 0.9918490917559385\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 75, train_loss = 3.982884363271296, train_acc = 0.9918490917559385\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 76, train_loss = 3.948175369761884, train_acc = 0.9919655333022822\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 77, train_loss = 3.9155266946181655, train_acc = 0.9921984163949698\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 78, train_loss = 3.881796875037253, train_acc = 0.9921984163949698\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 79, train_loss = 3.850503820925951, train_acc = 0.9921984163949698\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 80, train_loss = 3.8202934870496392, train_acc = 0.9923148579413135\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 81, train_loss = 3.7884078789502382, train_acc = 0.9924312994876572\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 82, train_loss = 3.759464147500694, train_acc = 0.9921984163949698\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 83, train_loss = 3.7287355680018663, train_acc = 0.9923148579413135\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 84, train_loss = 3.698645480442792, train_acc = 0.9924312994876572\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 85, train_loss = 3.670421785209328, train_acc = 0.9923148579413135\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 86, train_loss = 3.642718695104122, train_acc = 0.9924312994876572\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 87, train_loss = 3.615017860662192, train_acc = 0.9923148579413135\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 88, train_loss = 3.588764384854585, train_acc = 0.9925477410340009\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 89, train_loss = 3.562984796240926, train_acc = 0.9926641825803446\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 90, train_loss = 3.538878530729562, train_acc = 0.9926641825803446\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 91, train_loss = 3.514806856866926, train_acc = 0.9926641825803446\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 92, train_loss = 3.4900839086622, train_acc = 0.9925477410340009\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 93, train_loss = 3.466688798740506, train_acc = 0.9927806241266884\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 94, train_loss = 3.4437605440616608, train_acc = 0.9927806241266884\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 95, train_loss = 3.42096913093701, train_acc = 0.9927806241266884\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 96, train_loss = 3.3993301764130592, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 97, train_loss = 3.37682164600119, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 98, train_loss = 3.3550427299924195, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 99, train_loss = 3.3341825385577977, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 100, train_loss = 3.3129515941254795, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 101, train_loss = 3.2928632120601833, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 102, train_loss = 3.2726356089115143, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 103, train_loss = 3.2532299836166203, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 104, train_loss = 3.234548497479409, train_acc = 0.9932463903120633\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 105, train_loss = 3.213032128289342, train_acc = 0.9932463903120633\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 106, train_loss = 3.196037984918803, train_acc = 0.9932463903120633\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 107, train_loss = 3.1760550416074693, train_acc = 0.9932463903120633\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 108, train_loss = 3.159520157147199, train_acc = 0.9932463903120633\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 109, train_loss = 3.140291807707399, train_acc = 0.9932463903120633\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 110, train_loss = 3.1225363151170313, train_acc = 0.9932463903120633\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 111, train_loss = 3.1062595415860415, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 112, train_loss = 3.0879049892537296, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 113, train_loss = 3.0712208631448448, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 114, train_loss = 3.053335428237915, train_acc = 0.9933628318584071\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 115, train_loss = 3.0363484076224267, train_acc = 0.9934792734047508\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 116, train_loss = 3.018328128848225, train_acc = 0.993828598043782\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 117, train_loss = 3.002542331814766, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 118, train_loss = 2.987778175622225, train_acc = 0.9939450395901258\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 119, train_loss = 2.9721291991882026, train_acc = 0.9939450395901258\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 120, train_loss = 2.9566301037557423, train_acc = 0.9940614811364695\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 121, train_loss = 2.941288923844695, train_acc = 0.9940614811364695\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 122, train_loss = 2.9261983651667833, train_acc = 0.9940614811364695\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 123, train_loss = 2.912248453591019, train_acc = 0.9940614811364695\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 124, train_loss = 2.8981576557271183, train_acc = 0.9940614811364695\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 125, train_loss = 2.8839404857717454, train_acc = 0.9940614811364695\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 126, train_loss = 2.8678706805221736, train_acc = 0.9940614811364695\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 127, train_loss = 2.8568373932503164, train_acc = 0.9940614811364695\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 128, train_loss = 2.8428917303681374, train_acc = 0.9940614811364695\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 129, train_loss = 2.8302209633402526, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 130, train_loss = 2.81749400915578, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 131, train_loss = 2.8034469527192414, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 132, train_loss = 2.791644626762718, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 133, train_loss = 2.778639063704759, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 134, train_loss = 2.7660076464526355, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 135, train_loss = 2.754294747952372, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 136, train_loss = 2.743307371158153, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 137, train_loss = 2.730097040068358, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 138, train_loss = 2.7196947522461414, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 139, train_loss = 2.7074434403330088, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 140, train_loss = 2.697597663849592, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 141, train_loss = 2.685241149738431, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 142, train_loss = 2.675002339761704, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 143, train_loss = 2.6636530426330864, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 144, train_loss = 2.6535188197158277, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 145, train_loss = 2.6426763287745416, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 146, train_loss = 2.6319450507871807, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 147, train_loss = 2.621859449893236, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 148, train_loss = 2.61210198700428, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 149, train_loss = 2.6016353801824152, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 150, train_loss = 2.5916046504862607, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 151, train_loss = 2.5814730445854366, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 152, train_loss = 2.5733328387141228, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 153, train_loss = 2.5628902222961187, train_acc = 0.994294364229157\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 154, train_loss = 2.5545567921362817, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 155, train_loss = 2.5440093614161015, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 156, train_loss = 2.535398196429014, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 157, train_loss = 2.5252585746347904, train_acc = 0.9945272473218444\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 158, train_loss = 2.517365255858749, train_acc = 0.9945272473218444\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 159, train_loss = 2.5077465511858463, train_acc = 0.9945272473218444\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 160, train_loss = 2.4995501562952995, train_acc = 0.9945272473218444\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 161, train_loss = 2.49133330443874, train_acc = 0.9945272473218444\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 162, train_loss = 2.4833577102981508, train_acc = 0.9945272473218444\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 163, train_loss = 2.473724447656423, train_acc = 0.9945272473218444\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 164, train_loss = 2.4649564088322222, train_acc = 0.9945272473218444\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 165, train_loss = 2.457623064983636, train_acc = 0.9945272473218444\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 166, train_loss = 2.4500745334662497, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 167, train_loss = 2.441555969417095, train_acc = 0.9945272473218444\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 168, train_loss = 2.433321943040937, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 169, train_loss = 2.425251183565706, train_acc = 0.9945272473218444\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 170, train_loss = 2.4183792606927454, train_acc = 0.9945272473218444\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 171, train_loss = 2.4095656615681946, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 172, train_loss = 2.4035574067384005, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 173, train_loss = 2.3957880083471537, train_acc = 0.9945272473218444\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 174, train_loss = 2.3881015703082085, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 175, train_loss = 2.3807436474598944, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 176, train_loss = 2.373892979696393, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 177, train_loss = 2.3662511850707233, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 178, train_loss = 2.3596839574165642, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 179, train_loss = 2.3527597014326602, train_acc = 0.9945272473218444\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 180, train_loss = 2.3454921636730433, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 181, train_loss = 2.3390748407691717, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 182, train_loss = 2.331847558962181, train_acc = 0.9945272473218444\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 183, train_loss = 2.325199758633971, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 184, train_loss = 2.3188961688429117, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 185, train_loss = 2.310889846412465, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 186, train_loss = 2.3059226262848824, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 187, train_loss = 2.30024256487377, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 188, train_loss = 2.2921772841364145, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 189, train_loss = 2.2869069625157863, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 190, train_loss = 2.281225886195898, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 191, train_loss = 2.274536908371374, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 192, train_loss = 2.2688552502077073, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 193, train_loss = 2.263740671100095, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 194, train_loss = 2.256863297196105, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 195, train_loss = 2.2522469081450254, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 196, train_loss = 2.244757106527686, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 197, train_loss = 2.2411319750826806, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 198, train_loss = 2.23494568397291, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 199, train_loss = 2.2280117247719318, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 200, train_loss = 2.222958069294691, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 201, train_loss = 2.21709834295325, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 202, train_loss = 2.2145814888644964, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 203, train_loss = 2.207569910911843, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 204, train_loss = 2.2031087551731616, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 205, train_loss = 2.1976322748232633, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 206, train_loss = 2.192372064338997, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 207, train_loss = 2.188543042866513, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 208, train_loss = 2.1829577467869967, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 209, train_loss = 2.177468589739874, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 210, train_loss = 2.1732158444356173, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 211, train_loss = 2.168495863676071, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 212, train_loss = 2.162801484344527, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 213, train_loss = 2.1594462904613465, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 214, train_loss = 2.154787014471367, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 215, train_loss = 2.1485645051579922, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 216, train_loss = 2.1454361162614077, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 217, train_loss = 2.1403742029797286, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 218, train_loss = 2.13750411500223, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 219, train_loss = 2.130489618750289, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 220, train_loss = 2.127243322553113, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 221, train_loss = 2.1217070780694485, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 222, train_loss = 2.119479573564604, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 223, train_loss = 2.113836818607524, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 224, train_loss = 2.110793887404725, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 225, train_loss = 2.104816807433963, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 226, train_loss = 2.102329921675846, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 227, train_loss = 2.0972630430478603, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 228, train_loss = 2.093925355700776, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 229, train_loss = 2.0895942121278495, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 230, train_loss = 2.085775276646018, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 231, train_loss = 2.081738331122324, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 232, train_loss = 2.0779648579191417, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 233, train_loss = 2.0739138275384903, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 234, train_loss = 2.0708432078827173, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 235, train_loss = 2.0655646200757474, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 236, train_loss = 2.063151962356642, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 237, train_loss = 2.0586251050699502, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 238, train_loss = 2.0567343707662076, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 239, train_loss = 2.0517872627824545, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 240, train_loss = 2.04770906153135, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 241, train_loss = 2.044987727655098, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 242, train_loss = 2.0391990065108985, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 243, train_loss = 2.0367084108293056, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 244, train_loss = 2.033738521160558, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 245, train_loss = 2.0293937746901065, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 246, train_loss = 2.0268226470798254, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 247, train_loss = 2.022585653932765, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 248, train_loss = 2.01958220009692, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 249, train_loss = 2.0173292693216354, train_acc = 0.9951094550535631\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 250, train_loss = 2.012863650219515, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 251, train_loss = 2.0086962685454637, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 252, train_loss = 2.006593619706109, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 253, train_loss = 2.0031004566699266, train_acc = 0.9952258965999069\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 254, train_loss = 2.0003470194060355, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 255, train_loss = 1.9962517644744366, train_acc = 0.9954587796925943\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 256, train_loss = 1.9939567521214485, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 257, train_loss = 1.9903403967618942, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 258, train_loss = 1.9876993857324123, train_acc = 0.9954587796925943\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 259, train_loss = 1.9844057627487928, train_acc = 0.9954587796925943\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 260, train_loss = 1.9823252882342786, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 261, train_loss = 1.9785926844924688, train_acc = 0.9954587796925943\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 262, train_loss = 1.9758591025602072, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 263, train_loss = 1.9723060335963964, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 264, train_loss = 1.9709187608677894, train_acc = 0.995575221238938\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 265, train_loss = 1.9660889368969947, train_acc = 0.995575221238938\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 266, train_loss = 1.9645382643211633, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 267, train_loss = 1.961154096527025, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 268, train_loss = 1.9584186349529773, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 269, train_loss = 1.9561274356674403, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 270, train_loss = 1.9530157030094415, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 271, train_loss = 1.9500734664034098, train_acc = 0.9958081043316255\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 272, train_loss = 1.9473599300254136, train_acc = 0.9958081043316255\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 273, train_loss = 1.9446265629958361, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 274, train_loss = 1.9417556643020362, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 275, train_loss = 1.9394331581424922, train_acc = 0.9958081043316255\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 276, train_loss = 1.937029144493863, train_acc = 0.9959245458779693\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 277, train_loss = 1.9340832587331533, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 278, train_loss = 1.9317609679419547, train_acc = 0.9958081043316255\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 279, train_loss = 1.9300824410747737, train_acc = 0.9961574289706567\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 280, train_loss = 1.9270805921405554, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 281, train_loss = 1.9245332770515233, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 282, train_loss = 1.9217432842124254, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 283, train_loss = 1.9195387500803918, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 284, train_loss = 1.9162332743871957, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 285, train_loss = 1.9146283436566591, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 286, train_loss = 1.9122818522155285, train_acc = 0.9958081043316255\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 287, train_loss = 1.9099560379981995, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 288, train_loss = 1.9082797188311815, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 289, train_loss = 1.9042073066812009, train_acc = 0.996040987424313\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 290, train_loss = 1.9022730260621756, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 291, train_loss = 1.9007528822403401, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 292, train_loss = 1.8978900134097785, train_acc = 0.9958081043316255\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 293, train_loss = 1.8952196065802127, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 294, train_loss = 1.8937126602977514, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 295, train_loss = 1.8913306307513267, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 296, train_loss = 1.8887189235538244, train_acc = 0.9958081043316255\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 297, train_loss = 1.8864609103184193, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 298, train_loss = 1.8841404486447573, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 299, train_loss = 1.883016686886549, train_acc = 0.996040987424313\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 300, train_loss = 1.8805820010602474, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 301, train_loss = 1.8788464639801532, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 302, train_loss = 1.8759446367621422, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 303, train_loss = 1.873853350058198, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 304, train_loss = 1.8731837726663798, train_acc = 0.996040987424313\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 305, train_loss = 1.871387245832011, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 306, train_loss = 1.8688317381311208, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 307, train_loss = 1.865607560845092, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 308, train_loss = 1.8638476363848895, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 309, train_loss = 1.8624510653316975, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 310, train_loss = 1.8596651069819927, train_acc = 0.996040987424313\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 311, train_loss = 1.858044258551672, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 312, train_loss = 1.856416067108512, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 313, train_loss = 1.8536617506761104, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 314, train_loss = 1.8517134885769337, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 315, train_loss = 1.8497294869739562, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 316, train_loss = 1.8479695406276733, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 317, train_loss = 1.8475882180500776, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 318, train_loss = 1.8456500861793756, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 319, train_loss = 1.8438127785921097, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 320, train_loss = 1.841244749026373, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 321, train_loss = 1.8386036076117307, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 322, train_loss = 1.8382080558221787, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 323, train_loss = 1.8350916400086135, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 324, train_loss = 1.8336805533617735, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 325, train_loss = 1.8311462465208024, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 326, train_loss = 1.8296670261770487, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 327, train_loss = 1.8283465385902673, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 328, train_loss = 1.8263536330778152, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 329, train_loss = 1.8251186038833112, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 330, train_loss = 1.8234944231808186, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 331, train_loss = 1.821412880672142, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 332, train_loss = 1.8199508755933493, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 333, train_loss = 1.8184779963921756, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 334, train_loss = 1.81656249682419, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 335, train_loss = 1.8143660010537133, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 336, train_loss = 1.8131068287184462, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 337, train_loss = 1.8117807172238827, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 338, train_loss = 1.8093946339795366, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 339, train_loss = 1.8073700064560398, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 340, train_loss = 1.8057430566987023, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 341, train_loss = 1.804242338403128, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 342, train_loss = 1.803189737140201, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 343, train_loss = 1.8014813294867054, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 344, train_loss = 1.8000945405801758, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 345, train_loss = 1.798414010554552, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 346, train_loss = 1.795733405277133, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 347, train_loss = 1.7950573321431875, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 348, train_loss = 1.793568174005486, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 349, train_loss = 1.7920230632880703, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 350, train_loss = 1.7910730888834223, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 351, train_loss = 1.7891314290463924, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 352, train_loss = 1.787828174768947, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 353, train_loss = 1.7860693422844633, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 354, train_loss = 1.7848946129670367, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 355, train_loss = 1.783441056148149, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 356, train_loss = 1.781413142918609, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 357, train_loss = 1.7810472436249256, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 358, train_loss = 1.7783086014678702, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 359, train_loss = 1.7775533752283081, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 360, train_loss = 1.776737449108623, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 361, train_loss = 1.775156962336041, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 362, train_loss = 1.7732095898827538, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 363, train_loss = 1.771565337316133, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 364, train_loss = 1.7695490153273568, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 365, train_loss = 1.7691945905098692, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 366, train_loss = 1.768317686393857, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 367, train_loss = 1.7665896490216255, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 368, train_loss = 1.7648821044713259, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 369, train_loss = 1.76370050071273, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 370, train_loss = 1.762604878633283, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 371, train_loss = 1.7606648249784485, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 372, train_loss = 1.7591821607202291, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 373, train_loss = 1.7588667906820774, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 374, train_loss = 1.7580346098402515, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 375, train_loss = 1.756268054828979, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 376, train_loss = 1.754649360314943, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 377, train_loss = 1.7537610506406054, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 378, train_loss = 1.7528547495603561, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 379, train_loss = 1.7513562329113483, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 380, train_loss = 1.7496439727256075, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 381, train_loss = 1.7479931227862835, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 382, train_loss = 1.747947926982306, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 383, train_loss = 1.7461147103458643, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 384, train_loss = 1.7452475012978539, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 385, train_loss = 1.7439994191518053, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 386, train_loss = 1.7418691454222426, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 387, train_loss = 1.740639291703701, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 388, train_loss = 1.7400095742195845, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 389, train_loss = 1.7385027781128883, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 390, train_loss = 1.7374219434568658, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 391, train_loss = 1.7366659051040187, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 392, train_loss = 1.7360015647718683, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 393, train_loss = 1.7350385865429416, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 394, train_loss = 1.7331962989410385, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 395, train_loss = 1.7329314587404951, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 396, train_loss = 1.7312979139387608, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 397, train_loss = 1.7312709670513868, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 398, train_loss = 1.7292063621571288, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 399, train_loss = 1.7281427314737812, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 400, train_loss = 1.7263911193003878, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 401, train_loss = 1.7263785544782877, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 402, train_loss = 1.7247382750501856, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 403, train_loss = 1.7238753903657198, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 404, train_loss = 1.7217889664461836, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 405, train_loss = 1.7210195896914229, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 406, train_loss = 1.7216343967011198, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 407, train_loss = 1.719629761413671, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 408, train_loss = 1.7191527659306303, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 409, train_loss = 1.7171236717840657, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 410, train_loss = 1.7163693445036188, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 411, train_loss = 1.7150703134248033, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 412, train_loss = 1.713633288280107, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 413, train_loss = 1.7134111864725128, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 414, train_loss = 1.7121530566364527, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 415, train_loss = 1.7127126833656803, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 416, train_loss = 1.7098115583648905, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 417, train_loss = 1.7093550065765157, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 418, train_loss = 1.7079425007104874, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 419, train_loss = 1.7074616303434595, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 420, train_loss = 1.7055717488983646, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 421, train_loss = 1.7048619681736454, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 422, train_loss = 1.704441167996265, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 423, train_loss = 1.7051303330808878, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 424, train_loss = 1.7024692060658708, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 425, train_loss = 1.7004976229509339, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 426, train_loss = 1.699120640172623, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 427, train_loss = 1.6990679701557383, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 428, train_loss = 1.698720200569369, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 429, train_loss = 1.6977360416203737, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 430, train_loss = 1.6974448766559362, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 431, train_loss = 1.6965267931809649, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 432, train_loss = 1.6938641363522038, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 433, train_loss = 1.6932824006071314, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 434, train_loss = 1.6946621239185333, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 435, train_loss = 1.692222736775875, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 436, train_loss = 1.691817358136177, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 437, train_loss = 1.6897129596909508, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 438, train_loss = 1.6898734675487503, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 439, train_loss = 1.6897078534821048, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 440, train_loss = 1.687660362571478, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 441, train_loss = 1.6861147029558197, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 442, train_loss = 1.6868023164570332, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 443, train_loss = 1.684693654999137, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 444, train_loss = 1.6862246226519346, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 445, train_loss = 1.6812780313193798, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 446, train_loss = 1.6842350885272026, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 447, train_loss = 1.6817276161164045, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 448, train_loss = 1.6806141367414966, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 449, train_loss = 1.6810394786298275, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 450, train_loss = 1.679436138481833, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 451, train_loss = 1.6769741935422644, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 452, train_loss = 1.6788125783205032, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 453, train_loss = 1.6763588351896033, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 454, train_loss = 1.6757980404654518, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 455, train_loss = 1.6754537174711004, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 456, train_loss = 1.6734211662551388, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 457, train_loss = 1.6726427804678679, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 458, train_loss = 1.673536621616222, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 459, train_loss = 1.6708702085306868, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 460, train_loss = 1.6702605622122064, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 461, train_loss = 1.671354465186596, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 462, train_loss = 1.6689906660467386, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 463, train_loss = 1.668548023328185, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 464, train_loss = 1.668950188322924, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 465, train_loss = 1.6678317928453907, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 466, train_loss = 1.6663691755384207, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 467, train_loss = 1.6666078300913796, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 468, train_loss = 1.6643980983644724, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 469, train_loss = 1.6645920077571645, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 470, train_loss = 1.663480588584207, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 471, train_loss = 1.66288531513419, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 472, train_loss = 1.662569393753074, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 473, train_loss = 1.6610460095107555, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 474, train_loss = 1.6599783977726474, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 475, train_loss = 1.6598843695828691, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 476, train_loss = 1.658548171282746, train_acc = 0.996040987424313\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 477, train_loss = 1.6581527354428545, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 478, train_loss = 1.656995098455809, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 479, train_loss = 1.6561726270010695, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 480, train_loss = 1.6568957375129685, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 481, train_loss = 1.6555160315474495, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 482, train_loss = 1.6543773636221886, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 483, train_loss = 1.6540214363485575, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 484, train_loss = 1.6533621145645157, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 485, train_loss = 1.6522818902740255, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 486, train_loss = 1.651886267005466, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 487, train_loss = 1.6509019875666127, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 488, train_loss = 1.65002485178411, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 489, train_loss = 1.6495992647251114, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 490, train_loss = 1.6488520199200138, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 491, train_loss = 1.6467156819999218, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 492, train_loss = 1.6470306118717417, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 493, train_loss = 1.647163369343616, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 494, train_loss = 1.6461487797787413, train_acc = 0.996040987424313\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 495, train_loss = 1.6455444153398275, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 496, train_loss = 1.646439258591272, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 497, train_loss = 1.6439616394927725, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 498, train_loss = 1.6428561247885227, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 499, train_loss = 1.6434602724621072, train_acc = 0.996040987424313\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|████████████████████████████████████████████▎                         | 19/30 [2:51:59<1:39:27, 542.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "20th- epoch: 0, train_loss = 107.36397568881512, train_acc = 0.8013507219375874\n",
      "test Acc 0.888268156424581:\n",
      "20th- epoch: 1, train_loss = 42.203599989414215, train_acc = 0.917675826734979\n",
      "test Acc 0.9250465549348231:\n",
      "20th- epoch: 2, train_loss = 32.109659399837255, train_acc = 0.9382859804378202\n",
      "test Acc 0.9366852886405959:\n",
      "20th- epoch: 3, train_loss = 27.141545340418816, train_acc = 0.9466697717745691\n",
      "test Acc 0.9441340782122905:\n",
      "20th- epoch: 4, train_loss = 23.94090372696519, train_acc = 0.9523754075454122\n",
      "test Acc 0.946927374301676:\n",
      "20th- epoch: 5, train_loss = 21.569679617881775, train_acc = 0.955985095482068\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 6, train_loss = 19.71332050487399, train_acc = 0.9606427573358174\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 7, train_loss = 18.197756707668304, train_acc = 0.9629715882626921\n",
      "test Acc 0.952048417132216:\n",
      "20th- epoch: 8, train_loss = 16.9044836089015, train_acc = 0.9648346530041919\n",
      "test Acc 0.9534450651769087:\n",
      "20th- epoch: 9, train_loss = 15.790582180023193, train_acc = 0.9669306008383791\n",
      "test Acc 0.9529795158286778:\n",
      "20th- epoch: 10, train_loss = 14.824639655649662, train_acc = 0.9690265486725663\n",
      "test Acc 0.9539106145251397:\n",
      "20th- epoch: 11, train_loss = 13.972438249737024, train_acc = 0.9704238472286912\n",
      "test Acc 0.9534450651769087:\n",
      "20th- epoch: 12, train_loss = 13.215077612549067, train_acc = 0.9714718211457848\n",
      "test Acc 0.9534450651769087:\n",
      "20th- epoch: 13, train_loss = 12.54744865000248, train_acc = 0.9724033535165347\n",
      "test Acc 0.9539106145251397:\n",
      "20th- epoch: 14, train_loss = 11.952168015763164, train_acc = 0.9735677689799721\n",
      "test Acc 0.9548417132216015:\n",
      "20th- epoch: 15, train_loss = 11.412870259955525, train_acc = 0.9744993013507219\n",
      "test Acc 0.9553072625698324:\n",
      "20th- epoch: 16, train_loss = 10.920168250799179, train_acc = 0.9756637168141593\n",
      "test Acc 0.9567039106145251:\n",
      "20th- epoch: 17, train_loss = 10.463799925521016, train_acc = 0.9763623660922217\n",
      "test Acc 0.957635009310987:\n",
      "20th- epoch: 18, train_loss = 10.045112997293472, train_acc = 0.9772938984629715\n",
      "test Acc 0.9581005586592178:\n",
      "20th- epoch: 19, train_loss = 9.659762119874358, train_acc = 0.9781089892873778\n",
      "test Acc 0.9585661080074488:\n",
      "20th- epoch: 20, train_loss = 9.30785465054214, train_acc = 0.9789240801117839\n",
      "test Acc 0.9599627560521415:\n",
      "20th- epoch: 21, train_loss = 8.984944941475987, train_acc = 0.9803213786679087\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 22, train_loss = 8.68796450458467, train_acc = 0.9813693525850024\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 23, train_loss = 8.412278505042195, train_acc = 0.9818351187703773\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 24, train_loss = 8.160039264708757, train_acc = 0.9823008849557522\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 25, train_loss = 7.924328258261085, train_acc = 0.9831159757801584\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 26, train_loss = 7.701058683916926, train_acc = 0.9839310666045645\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 27, train_loss = 7.4973808117210865, train_acc = 0.9840475081509082\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 28, train_loss = 7.302518164739013, train_acc = 0.9842803912435957\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 29, train_loss = 7.117553761228919, train_acc = 0.9846297158826269\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 30, train_loss = 6.943976163864136, train_acc = 0.9850954820680019\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 31, train_loss = 6.780201820656657, train_acc = 0.9855612482533768\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 32, train_loss = 6.626985549926758, train_acc = 0.9857941313460643\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 33, train_loss = 6.47915431112051, train_acc = 0.9864927806241267\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 34, train_loss = 6.3426434379071, train_acc = 0.9867256637168141\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 35, train_loss = 6.211253182962537, train_acc = 0.9875407545412203\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 36, train_loss = 6.0881104823201895, train_acc = 0.9877736376339078\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 37, train_loss = 5.969402590766549, train_acc = 0.9880065207265952\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 38, train_loss = 5.856192758306861, train_acc = 0.9882394038192828\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 39, train_loss = 5.748583757318556, train_acc = 0.9885887284583139\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 40, train_loss = 5.6449542520567775, train_acc = 0.9887051700046576\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 41, train_loss = 5.547231783159077, train_acc = 0.9892873777363763\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 42, train_loss = 5.453278847038746, train_acc = 0.9895202608290639\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 43, train_loss = 5.361897460184991, train_acc = 0.989869585468095\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 44, train_loss = 5.276624817401171, train_acc = 0.9902189101071263\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 45, train_loss = 5.193319283425808, train_acc = 0.9905682347461574\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 46, train_loss = 5.111207093112171, train_acc = 0.990801117838845\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 47, train_loss = 5.035879795439541, train_acc = 0.9910340009315324\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 48, train_loss = 4.961561196483672, train_acc = 0.9911504424778761\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 49, train_loss = 4.890015434473753, train_acc = 0.9913833255705635\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 50, train_loss = 4.821184461005032, train_acc = 0.9912668840242198\n",
      "test Acc 0.9660148975791434:\n",
      "20th- epoch: 51, train_loss = 4.756863751448691, train_acc = 0.9913833255705635\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 52, train_loss = 4.691479350440204, train_acc = 0.9914997671169073\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 53, train_loss = 4.626944216899574, train_acc = 0.9916162086632511\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 54, train_loss = 4.569451916962862, train_acc = 0.9918490917559385\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 55, train_loss = 4.510469171218574, train_acc = 0.9918490917559385\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 56, train_loss = 4.454015231691301, train_acc = 0.9918490917559385\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 57, train_loss = 4.401646607555449, train_acc = 0.9918490917559385\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 58, train_loss = 4.347647569142282, train_acc = 0.9918490917559385\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 59, train_loss = 4.2964136665686965, train_acc = 0.9918490917559385\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 60, train_loss = 4.248310710303485, train_acc = 0.9918490917559385\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 61, train_loss = 4.200369149446487, train_acc = 0.9918490917559385\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 62, train_loss = 4.154440321028233, train_acc = 0.9919655333022822\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 63, train_loss = 4.109408526681364, train_acc = 0.9919655333022822\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 64, train_loss = 4.065799843519926, train_acc = 0.9919655333022822\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 65, train_loss = 4.0239225989207625, train_acc = 0.9921984163949698\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 66, train_loss = 3.9837029622867703, train_acc = 0.9923148579413135\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 67, train_loss = 3.9441221617162228, train_acc = 0.9924312994876572\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 68, train_loss = 3.9056468000635505, train_acc = 0.9925477410340009\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 69, train_loss = 3.868082200177014, train_acc = 0.9925477410340009\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 70, train_loss = 3.829244438558817, train_acc = 0.9925477410340009\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 71, train_loss = 3.795246994588524, train_acc = 0.9925477410340009\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 72, train_loss = 3.759421647991985, train_acc = 0.9927806241266884\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 73, train_loss = 3.7260061777196825, train_acc = 0.9928970656730322\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 74, train_loss = 3.6940378420986235, train_acc = 0.9928970656730322\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 75, train_loss = 3.660794463008642, train_acc = 0.9928970656730322\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 76, train_loss = 3.6284476690925658, train_acc = 0.9928970656730322\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 77, train_loss = 3.5991383544169366, train_acc = 0.9928970656730322\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 78, train_loss = 3.5704713887535036, train_acc = 0.9930135072193759\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 79, train_loss = 3.5401333360932767, train_acc = 0.9930135072193759\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 80, train_loss = 3.511521579232067, train_acc = 0.9931299487657196\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 81, train_loss = 3.483197331428528, train_acc = 0.9931299487657196\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 82, train_loss = 3.4562236652709544, train_acc = 0.9931299487657196\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 83, train_loss = 3.429903421550989, train_acc = 0.9931299487657196\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 84, train_loss = 3.404299338813871, train_acc = 0.9931299487657196\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 85, train_loss = 3.3768619098700583, train_acc = 0.9931299487657196\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 86, train_loss = 3.3523569009266794, train_acc = 0.9931299487657196\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 87, train_loss = 3.329130555037409, train_acc = 0.9931299487657196\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 88, train_loss = 3.303682569414377, train_acc = 0.9931299487657196\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 89, train_loss = 3.280450383666903, train_acc = 0.9931299487657196\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 90, train_loss = 3.2567783929407597, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 91, train_loss = 3.235543604940176, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 92, train_loss = 3.213878456503153, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 93, train_loss = 3.1919005662202835, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 94, train_loss = 3.1700929291546345, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 95, train_loss = 3.150538869202137, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 96, train_loss = 3.13192675774917, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 97, train_loss = 3.1117089302279055, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 98, train_loss = 3.092566017061472, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 99, train_loss = 3.0739607475697994, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 100, train_loss = 3.0535664469935, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 101, train_loss = 3.0344360494054854, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 102, train_loss = 3.016667801886797, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 103, train_loss = 2.998815628234297, train_acc = 0.9932463903120633\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 104, train_loss = 2.9836703441105783, train_acc = 0.9932463903120633\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 105, train_loss = 2.9661904028616846, train_acc = 0.9932463903120633\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 106, train_loss = 2.94901138311252, train_acc = 0.9932463903120633\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 107, train_loss = 2.9335320466198027, train_acc = 0.9935957149510946\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 108, train_loss = 2.9177470318973064, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 109, train_loss = 2.9025230146944523, train_acc = 0.9937121564974383\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 110, train_loss = 2.8867547982372344, train_acc = 0.993828598043782\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 111, train_loss = 2.87113651400432, train_acc = 0.993828598043782\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 112, train_loss = 2.8579687350429595, train_acc = 0.993828598043782\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 113, train_loss = 2.8414541422389448, train_acc = 0.993828598043782\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 114, train_loss = 2.8280685669742525, train_acc = 0.993828598043782\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 115, train_loss = 2.814627656247467, train_acc = 0.993828598043782\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 116, train_loss = 2.8014284931123257, train_acc = 0.9937121564974383\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 117, train_loss = 2.786290295422077, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 118, train_loss = 2.774393303785473, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 119, train_loss = 2.761290983762592, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 120, train_loss = 2.7476355894468725, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 121, train_loss = 2.734986004885286, train_acc = 0.9940614811364695\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 122, train_loss = 2.7241392359137535, train_acc = 0.9939450395901258\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 123, train_loss = 2.710883887950331, train_acc = 0.9940614811364695\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 124, train_loss = 2.6985365101136267, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 125, train_loss = 2.687378449831158, train_acc = 0.9939450395901258\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 126, train_loss = 2.675584805663675, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 127, train_loss = 2.6652603396214545, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 128, train_loss = 2.6534141288138926, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 129, train_loss = 2.640075869858265, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 130, train_loss = 2.630634149070829, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 131, train_loss = 2.619210013654083, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 132, train_loss = 2.6078447960317135, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 133, train_loss = 2.59812173852697, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 134, train_loss = 2.587131371255964, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 135, train_loss = 2.5759784555993974, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 136, train_loss = 2.566236238926649, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 137, train_loss = 2.557282751891762, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 138, train_loss = 2.546724855899811, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 139, train_loss = 2.537237621843815, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 140, train_loss = 2.526963823940605, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 141, train_loss = 2.5189704499207437, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 142, train_loss = 2.508775882422924, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 143, train_loss = 2.4981804229319096, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 144, train_loss = 2.4900985583662987, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 145, train_loss = 2.4818897782824934, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 146, train_loss = 2.471565742045641, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 147, train_loss = 2.4620795238297433, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 148, train_loss = 2.4544788636267185, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 149, train_loss = 2.4465412236750126, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 150, train_loss = 2.4376231159549206, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 151, train_loss = 2.4314804561436176, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 152, train_loss = 2.4215122424066067, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 153, train_loss = 2.4139825317543, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 154, train_loss = 2.405965607613325, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 155, train_loss = 2.397611993132159, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 156, train_loss = 2.3910581779200584, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 157, train_loss = 2.3838273163419217, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 158, train_loss = 2.374679211527109, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 159, train_loss = 2.36869107815437, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 160, train_loss = 2.3613837745506316, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 161, train_loss = 2.3539725665468723, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 162, train_loss = 2.3464043873827904, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 163, train_loss = 2.3406057357788086, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 164, train_loss = 2.3338166635949165, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 165, train_loss = 2.3264693927485496, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 166, train_loss = 2.318218211410567, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 167, train_loss = 2.3142719056922942, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 168, train_loss = 2.3064879316370934, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 169, train_loss = 2.3005426365416497, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 170, train_loss = 2.294140074402094, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 171, train_loss = 2.288442838937044, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 172, train_loss = 2.2813269768375903, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 173, train_loss = 2.274441173998639, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 174, train_loss = 2.2696107875090092, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 175, train_loss = 2.2628582071047276, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 176, train_loss = 2.2568527061957866, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 177, train_loss = 2.252286506118253, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 178, train_loss = 2.2443103108089417, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 179, train_loss = 2.238977177767083, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 180, train_loss = 2.233515613945201, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 181, train_loss = 2.2283868205267936, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 182, train_loss = 2.224428355693817, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 183, train_loss = 2.217148018302396, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 184, train_loss = 2.213159045903012, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 185, train_loss = 2.206517816754058, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 186, train_loss = 2.2011736531276256, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 187, train_loss = 2.196446080924943, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 188, train_loss = 2.1903529576957226, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 189, train_loss = 2.186080928891897, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 190, train_loss = 2.181269320426509, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 191, train_loss = 2.176736028166488, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 192, train_loss = 2.1712041932623833, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 193, train_loss = 2.165637966245413, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 194, train_loss = 2.1612789493519813, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 195, train_loss = 2.157425335375592, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 196, train_loss = 2.151075857458636, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 197, train_loss = 2.146932157455012, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 198, train_loss = 2.14381538820453, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 199, train_loss = 2.13905531167984, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 200, train_loss = 2.1331930831074715, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 201, train_loss = 2.1285130344331264, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 202, train_loss = 2.1247639555949718, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 203, train_loss = 2.1202895119786263, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 204, train_loss = 2.1157657739240676, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 205, train_loss = 2.111043229699135, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 206, train_loss = 2.1064632136840373, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 207, train_loss = 2.102462250739336, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 208, train_loss = 2.098025318235159, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 209, train_loss = 2.0947860528249294, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 210, train_loss = 2.090529352426529, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 211, train_loss = 2.085185368778184, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 212, train_loss = 2.0835024241823703, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 213, train_loss = 2.0792856588959694, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 214, train_loss = 2.074528048513457, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 215, train_loss = 2.0705328893382102, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 216, train_loss = 2.0658980782609433, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 217, train_loss = 2.0630126122850925, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 218, train_loss = 2.0583433099091053, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 219, train_loss = 2.0547569405753165, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 220, train_loss = 2.051609357120469, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 221, train_loss = 2.0474992990493774, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 222, train_loss = 2.0429156869649887, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 223, train_loss = 2.0403196352999657, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 224, train_loss = 2.0365038327872753, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 225, train_loss = 2.0323951703030616, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 226, train_loss = 2.028520155698061, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 227, train_loss = 2.0267092995345592, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 228, train_loss = 2.0223921935539693, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 229, train_loss = 2.019585233181715, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 230, train_loss = 2.015366035280749, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 231, train_loss = 2.0116976697463542, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 232, train_loss = 2.008821564493701, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 233, train_loss = 2.005085839657113, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 234, train_loss = 2.0019540823996067, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 235, train_loss = 1.9991203707177192, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 236, train_loss = 1.996103711426258, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 237, train_loss = 1.992354491027072, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 238, train_loss = 1.9895134221296757, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 239, train_loss = 1.9861044995486736, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 240, train_loss = 1.9835789452772588, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 241, train_loss = 1.9797136124689132, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 242, train_loss = 1.9774940896313637, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 243, train_loss = 1.9749907415825874, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 244, train_loss = 1.971143287839368, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 245, train_loss = 1.9686561103444546, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 246, train_loss = 1.9657747149467468, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 247, train_loss = 1.9622785050887614, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 248, train_loss = 1.9584010764956474, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 249, train_loss = 1.9559632316231728, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 250, train_loss = 1.9531752143520862, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 251, train_loss = 1.9521929163020104, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 252, train_loss = 1.9479962426703423, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 253, train_loss = 1.9453484315890819, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 254, train_loss = 1.9429135285317898, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 255, train_loss = 1.939337694318965, train_acc = 0.9954587796925943\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 256, train_loss = 1.9354230265598744, train_acc = 0.9954587796925943\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 257, train_loss = 1.9322333100717515, train_acc = 0.9952258965999069\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 258, train_loss = 1.9307567838113755, train_acc = 0.9952258965999069\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 259, train_loss = 1.9282190203666687, train_acc = 0.9952258965999069\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 260, train_loss = 1.924732296494767, train_acc = 0.9952258965999069\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 261, train_loss = 1.921669726492837, train_acc = 0.9952258965999069\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 262, train_loss = 1.920767894713208, train_acc = 0.9952258965999069\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 263, train_loss = 1.9170196938794106, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 264, train_loss = 1.914504837244749, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 265, train_loss = 1.9124130023410544, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 266, train_loss = 1.9103022292256355, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 267, train_loss = 1.906790235429071, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 268, train_loss = 1.9045835807919502, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 269, train_loss = 1.9015729650855064, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 270, train_loss = 1.8987716609844938, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 271, train_loss = 1.8977159932255745, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 272, train_loss = 1.893562855781056, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 273, train_loss = 1.8920691882958636, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 274, train_loss = 1.8920171993086115, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 275, train_loss = 1.8876868784427643, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 276, train_loss = 1.8862513191998005, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 277, train_loss = 1.8829240389168262, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 278, train_loss = 1.8820315500488505, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 279, train_loss = 1.8792140880832449, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 280, train_loss = 1.8775144318351522, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 281, train_loss = 1.8749588454375044, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 282, train_loss = 1.871368213207461, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 283, train_loss = 1.8704391606152058, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 284, train_loss = 1.8685468919575214, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 285, train_loss = 1.8658441925654188, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 286, train_loss = 1.864187441766262, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 287, train_loss = 1.8636157115688547, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 288, train_loss = 1.8602982051670551, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 289, train_loss = 1.8576106317341328, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 290, train_loss = 1.8550488874316216, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 291, train_loss = 1.8530243759742007, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 292, train_loss = 1.8510441990802065, train_acc = 0.9952258965999069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 293, train_loss = 1.848820373415947, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 294, train_loss = 1.8468580655753613, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 295, train_loss = 1.8449668859830126, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 296, train_loss = 1.8434042694279924, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 297, train_loss = 1.8419874062528834, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 298, train_loss = 1.839060957194306, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 299, train_loss = 1.8374100787332281, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 300, train_loss = 1.8362320624291897, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 301, train_loss = 1.833734324784018, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 302, train_loss = 1.8307131057372317, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 303, train_loss = 1.8299806179711595, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 304, train_loss = 1.8288171602180228, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 305, train_loss = 1.826208058744669, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 306, train_loss = 1.8248391337692738, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 307, train_loss = 1.8222935857484117, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 308, train_loss = 1.8207457760581747, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 309, train_loss = 1.818760935217142, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 310, train_loss = 1.8181682837894186, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 311, train_loss = 1.8156257681548595, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 312, train_loss = 1.8139568766346201, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 313, train_loss = 1.8120320104062557, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 314, train_loss = 1.8104323981096968, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 315, train_loss = 1.8089887475362048, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 316, train_loss = 1.8075988428900018, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 317, train_loss = 1.8052130714058876, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 318, train_loss = 1.802423326880671, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 319, train_loss = 1.8017908073961735, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 320, train_loss = 1.8003363435855135, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 321, train_loss = 1.7974659440806136, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 322, train_loss = 1.796927341609262, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 323, train_loss = 1.7950115775456652, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 324, train_loss = 1.7938886346528307, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 325, train_loss = 1.7915127612650394, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 326, train_loss = 1.7906837252667174, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 327, train_loss = 1.7883386798202991, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 328, train_loss = 1.7871983796358109, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 329, train_loss = 1.785316957742907, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 330, train_loss = 1.7837502211332321, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 331, train_loss = 1.7828190425643697, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 332, train_loss = 1.7799740260234103, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 333, train_loss = 1.779507752507925, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 334, train_loss = 1.7772940086433664, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 335, train_loss = 1.7773469351232052, train_acc = 0.9952258965999069\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 336, train_loss = 1.7746286591282114, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 337, train_loss = 1.7739305781433359, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 338, train_loss = 1.7714033300289884, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 339, train_loss = 1.7697777660796419, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 340, train_loss = 1.768555430113338, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 341, train_loss = 1.768161155283451, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 342, train_loss = 1.766327079385519, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 343, train_loss = 1.7646901061525568, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 344, train_loss = 1.7643575891852379, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 345, train_loss = 1.7618450187146664, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 346, train_loss = 1.7598261125385761, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 347, train_loss = 1.7581393644213676, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 348, train_loss = 1.7578969411551952, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 349, train_loss = 1.7563718780875206, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 350, train_loss = 1.754794648499228, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 351, train_loss = 1.752611314295791, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 352, train_loss = 1.7532324095955119, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 353, train_loss = 1.7503072047838941, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 354, train_loss = 1.7497251443564892, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 355, train_loss = 1.7483466131379828, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 356, train_loss = 1.746026543318294, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 357, train_loss = 1.746291292249225, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 358, train_loss = 1.7443422476062551, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 359, train_loss = 1.7430663543054834, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 360, train_loss = 1.7419244050979614, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 361, train_loss = 1.7399962656199932, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 362, train_loss = 1.739174066693522, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 363, train_loss = 1.737850426346995, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 364, train_loss = 1.737343419343233, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 365, train_loss = 1.7348233374068514, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 366, train_loss = 1.7347069507231936, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 367, train_loss = 1.7321947613963857, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 368, train_loss = 1.7316345237195492, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 369, train_loss = 1.7300958646228537, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 370, train_loss = 1.7302818422904238, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 371, train_loss = 1.7274109199643135, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 372, train_loss = 1.7272834293544292, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 373, train_loss = 1.7252897495636716, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 374, train_loss = 1.7246378163108602, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 375, train_loss = 1.7238905181875452, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 376, train_loss = 1.7222127169370651, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 377, train_loss = 1.7205612236866727, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 378, train_loss = 1.7202278847107664, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 379, train_loss = 1.7188807068159804, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 380, train_loss = 1.717487271875143, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 381, train_loss = 1.7169858167180791, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 382, train_loss = 1.715856872498989, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 383, train_loss = 1.7134287804365158, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 384, train_loss = 1.7128416734049097, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 385, train_loss = 1.712294333963655, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 386, train_loss = 1.7110837064683437, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 387, train_loss = 1.7097386432578787, train_acc = 0.9953423381462506\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 388, train_loss = 1.707866600365378, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 389, train_loss = 1.7079542391002178, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 390, train_loss = 1.706546101719141, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 391, train_loss = 1.70548363274429, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 392, train_loss = 1.7043022500583902, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 393, train_loss = 1.7020431099226698, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 394, train_loss = 1.702041813521646, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 395, train_loss = 1.7004404440522194, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 396, train_loss = 1.7012795507907867, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 397, train_loss = 1.6988784136483446, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 398, train_loss = 1.6981148918857798, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 399, train_loss = 1.6960245072841644, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 400, train_loss = 1.6959832273423672, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 401, train_loss = 1.6957342736423016, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 402, train_loss = 1.6937200240790844, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 403, train_loss = 1.6922610774636269, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 404, train_loss = 1.6913317131111398, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 405, train_loss = 1.691745319752954, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 406, train_loss = 1.689651264459826, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 407, train_loss = 1.6890086382627487, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 408, train_loss = 1.688084507943131, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 409, train_loss = 1.6858718345174566, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 410, train_loss = 1.6846880726516247, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 411, train_loss = 1.6850992267718539, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 412, train_loss = 1.6834669274976477, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 413, train_loss = 1.6830197150120512, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 414, train_loss = 1.6811511417618021, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 415, train_loss = 1.6824320442974567, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 416, train_loss = 1.6799560015788302, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 417, train_loss = 1.6808442572364584, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 418, train_loss = 1.6774767438182607, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 419, train_loss = 1.6776502827415243, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 420, train_loss = 1.6767423214623705, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 421, train_loss = 1.6768373064696789, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 422, train_loss = 1.6735839359462261, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 423, train_loss = 1.6739693706622347, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 424, train_loss = 1.6733814924955368, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 425, train_loss = 1.6727354613831267, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 426, train_loss = 1.6708026602864265, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 427, train_loss = 1.670370082021691, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 428, train_loss = 1.669346872717142, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 429, train_loss = 1.6687155129620805, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 430, train_loss = 1.6672747656702995, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 431, train_loss = 1.6677215434610844, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 432, train_loss = 1.6665540399262682, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 433, train_loss = 1.6650394027819857, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 434, train_loss = 1.6638644734630361, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 435, train_loss = 1.6622931869933382, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 436, train_loss = 1.6631129732122645, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 437, train_loss = 1.6606283461442217, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 438, train_loss = 1.6613242017338052, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 439, train_loss = 1.6594210291514173, train_acc = 0.9952258965999069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 440, train_loss = 1.6598260464379564, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 441, train_loss = 1.6568011516937986, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 442, train_loss = 1.6583757748594508, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 443, train_loss = 1.6559127556975, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 444, train_loss = 1.6567450339207426, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 445, train_loss = 1.654987913905643, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 446, train_loss = 1.6534630171954632, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 447, train_loss = 1.6542503970558755, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 448, train_loss = 1.6529349039192311, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 449, train_loss = 1.651942890137434, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 450, train_loss = 1.6511376550188288, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 451, train_loss = 1.6484215669333935, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 452, train_loss = 1.649114282161463, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 453, train_loss = 1.6485153511166573, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 454, train_loss = 1.6492861919105053, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 455, train_loss = 1.6480479600722902, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 456, train_loss = 1.6461722664535046, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 457, train_loss = 1.6452053462271579, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 458, train_loss = 1.6446433502133004, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 459, train_loss = 1.6436618827283382, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 460, train_loss = 1.6436327708070166, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 461, train_loss = 1.6422569428686984, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 462, train_loss = 1.6414030827581882, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 463, train_loss = 1.6401509593124501, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 464, train_loss = 1.641311387240421, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 465, train_loss = 1.6392597667872906, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 466, train_loss = 1.6393423937261105, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 467, train_loss = 1.637468232482206, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 468, train_loss = 1.6378586664795876, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 469, train_loss = 1.6364173429901712, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 470, train_loss = 1.6351731519098394, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 471, train_loss = 1.6340102441608906, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 472, train_loss = 1.6344986123149283, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 473, train_loss = 1.6334194727241993, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 474, train_loss = 1.6324344140593894, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 475, train_loss = 1.6316535187070258, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 476, train_loss = 1.6316790394484997, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 477, train_loss = 1.6311586151714437, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 478, train_loss = 1.6299024671316147, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 479, train_loss = 1.6290109505061992, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 480, train_loss = 1.6285594341461547, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 481, train_loss = 1.6276970729231834, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 482, train_loss = 1.6262055486440659, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 483, train_loss = 1.6261313992436044, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 484, train_loss = 1.6266946184332483, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 485, train_loss = 1.6258390049333684, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 486, train_loss = 1.6235514394938946, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 487, train_loss = 1.6242094884510152, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 488, train_loss = 1.6224490950698964, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 489, train_loss = 1.6231735534965992, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 490, train_loss = 1.6217969208955765, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 491, train_loss = 1.6220753875677474, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 492, train_loss = 1.621260127692949, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 493, train_loss = 1.6194043892319314, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 494, train_loss = 1.618553961336147, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 495, train_loss = 1.6194543913006783, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 496, train_loss = 1.6171450999681838, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 497, train_loss = 1.61780272051692, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 498, train_loss = 1.6158519151504152, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 499, train_loss = 1.6175813103909604, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████▋                       | 20/30 [3:01:02<1:30:28, 542.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "21th- epoch: 0, train_loss = 110.43031527101994, train_acc = 0.7945971122496507\n",
      "test Acc 0.8873370577281192:\n",
      "21th- epoch: 1, train_loss = 41.552692510187626, train_acc = 0.9127852817885421\n",
      "test Acc 0.9185288640595903:\n",
      "21th- epoch: 2, train_loss = 31.026623107492924, train_acc = 0.9344434094084769\n",
      "test Acc 0.9338919925512105:\n",
      "21th- epoch: 3, train_loss = 25.79345501586795, train_acc = 0.9445738239403819\n",
      "test Acc 0.9385474860335196:\n",
      "21th- epoch: 4, train_loss = 22.493091087788343, train_acc = 0.9519096413600373\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 5, train_loss = 20.160108730196953, train_acc = 0.9571495109455054\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 6, train_loss = 18.383721005171537, train_acc = 0.9615742897065673\n",
      "test Acc 0.9515828677839852:\n",
      "21th- epoch: 7, train_loss = 16.97926995716989, train_acc = 0.9637866790870983\n",
      "test Acc 0.9529795158286778:\n",
      "21th- epoch: 8, train_loss = 15.819053139537573, train_acc = 0.9668141592920354\n",
      "test Acc 0.9553072625698324:\n",
      "21th- epoch: 9, train_loss = 14.858813259750605, train_acc = 0.9687936655798789\n",
      "test Acc 0.9562383612662942:\n",
      "21th- epoch: 10, train_loss = 14.049457520246506, train_acc = 0.9704238472286912\n",
      "test Acc 0.9567039106145251:\n",
      "21th- epoch: 11, train_loss = 13.33766857534647, train_acc = 0.9727526781555659\n",
      "test Acc 0.9581005586592178:\n",
      "21th- epoch: 12, train_loss = 12.721948567777872, train_acc = 0.974033535165347\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 13, train_loss = 12.167467908933759, train_acc = 0.9760130414531905\n",
      "test Acc 0.9608938547486033:\n",
      "21th- epoch: 14, train_loss = 11.675164902582765, train_acc = 0.9770610153702841\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 15, train_loss = 11.229759983718395, train_acc = 0.9775267815556591\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 16, train_loss = 10.827624704688787, train_acc = 0.9781089892873778\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 17, train_loss = 10.456599110737443, train_acc = 0.9788076385654402\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 18, train_loss = 10.11841463111341, train_acc = 0.97973917093619\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 19, train_loss = 9.798603188246489, train_acc = 0.980204937121565\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 20, train_loss = 9.50566209666431, train_acc = 0.9807871448532837\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 21, train_loss = 9.229263978078961, train_acc = 0.9813693525850024\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 22, train_loss = 8.969485949724913, train_acc = 0.9824173265020959\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 23, train_loss = 8.730262754485011, train_acc = 0.9827666511411272\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 24, train_loss = 8.505925202742219, train_acc = 0.9829995342338146\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 25, train_loss = 8.29284749366343, train_acc = 0.9834653004191896\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 26, train_loss = 8.09826960787177, train_acc = 0.9839310666045645\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 27, train_loss = 7.914806114509702, train_acc = 0.984163949697252\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 28, train_loss = 7.739510217681527, train_acc = 0.9846297158826269\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 29, train_loss = 7.571137463673949, train_acc = 0.9850954820680019\n",
      "test Acc 0.9669459962756052:\n",
      "21th- epoch: 30, train_loss = 7.410437135025859, train_acc = 0.9853283651606893\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 31, train_loss = 7.261349199339747, train_acc = 0.9857941313460643\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 32, train_loss = 7.117469185963273, train_acc = 0.9860270144387517\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 33, train_loss = 6.9788402412086725, train_acc = 0.986376339077783\n",
      "test Acc 0.9669459962756052:\n",
      "21th- epoch: 34, train_loss = 6.848270494490862, train_acc = 0.9866092221704704\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 35, train_loss = 6.721687309443951, train_acc = 0.9871914299021891\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 36, train_loss = 6.602807054296136, train_acc = 0.9878900791802515\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 37, train_loss = 6.486373976804316, train_acc = 0.9878900791802515\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 38, train_loss = 6.378475189208984, train_acc = 0.9882394038192828\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 39, train_loss = 6.274080059491098, train_acc = 0.9881229622729389\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 40, train_loss = 6.169243356212974, train_acc = 0.9885887284583139\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 41, train_loss = 6.073677563108504, train_acc = 0.9889380530973452\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 42, train_loss = 5.981262332759798, train_acc = 0.9891709361900326\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 43, train_loss = 5.894070236943662, train_acc = 0.9891709361900326\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 44, train_loss = 5.809830362908542, train_acc = 0.9892873777363763\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 45, train_loss = 5.727364703081548, train_acc = 0.9892873777363763\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 46, train_loss = 5.650499635376036, train_acc = 0.9896367023754076\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 47, train_loss = 5.573158161714673, train_acc = 0.9896367023754076\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 48, train_loss = 5.50031247921288, train_acc = 0.9897531439217513\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 49, train_loss = 5.4296916192397475, train_acc = 0.9896367023754076\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 50, train_loss = 5.358542362228036, train_acc = 0.9896367023754076\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 51, train_loss = 5.292832692153752, train_acc = 0.9897531439217513\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 52, train_loss = 5.228545507416129, train_acc = 0.989869585468095\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 53, train_loss = 5.163198665715754, train_acc = 0.9899860270144387\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 54, train_loss = 5.099931665696204, train_acc = 0.99033535165347\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 55, train_loss = 5.039307582192123, train_acc = 0.99033535165347\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 56, train_loss = 4.982938535511494, train_acc = 0.9905682347461574\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 57, train_loss = 4.926008535549045, train_acc = 0.9906846762925011\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 58, train_loss = 4.873225680552423, train_acc = 0.990801117838845\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 59, train_loss = 4.821808671578765, train_acc = 0.9909175593851887\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 60, train_loss = 4.770163620822132, train_acc = 0.9910340009315324\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 61, train_loss = 4.720093413256109, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 62, train_loss = 4.673195914365351, train_acc = 0.9911504424778761\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 63, train_loss = 4.628235408104956, train_acc = 0.9912668840242198\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 64, train_loss = 4.579111664555967, train_acc = 0.9913833255705635\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 65, train_loss = 4.536248163320124, train_acc = 0.9913833255705635\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 66, train_loss = 4.49143635854125, train_acc = 0.9912668840242198\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 67, train_loss = 4.44939327891916, train_acc = 0.9914997671169073\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 68, train_loss = 4.4078842690214515, train_acc = 0.9916162086632511\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 69, train_loss = 4.3663872899487615, train_acc = 0.9918490917559385\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 70, train_loss = 4.328845396637917, train_acc = 0.9918490917559385\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 71, train_loss = 4.2900558658875525, train_acc = 0.9918490917559385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 72, train_loss = 4.253647996578366, train_acc = 0.9919655333022822\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 73, train_loss = 4.214005928486586, train_acc = 0.9919655333022822\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 74, train_loss = 4.1793333776295185, train_acc = 0.9918490917559385\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 75, train_loss = 4.145205980632454, train_acc = 0.992081974848626\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 76, train_loss = 4.109111322555691, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 77, train_loss = 4.077350323554128, train_acc = 0.9923148579413135\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 78, train_loss = 4.045316537376493, train_acc = 0.9921984163949698\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 79, train_loss = 4.012383708264679, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 80, train_loss = 3.978924347553402, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 81, train_loss = 3.9509901800192893, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 82, train_loss = 3.9176321462728083, train_acc = 0.9924312994876572\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 83, train_loss = 3.8921224498189986, train_acc = 0.9924312994876572\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 84, train_loss = 3.861254232469946, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 85, train_loss = 3.830972094088793, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 86, train_loss = 3.805000679101795, train_acc = 0.9924312994876572\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 87, train_loss = 3.777404684573412, train_acc = 0.9924312994876572\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 88, train_loss = 3.749328119214624, train_acc = 0.9926641825803446\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 89, train_loss = 3.7220307565294206, train_acc = 0.9926641825803446\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 90, train_loss = 3.6983378888107836, train_acc = 0.9926641825803446\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 91, train_loss = 3.672966306563467, train_acc = 0.9927806241266884\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 92, train_loss = 3.6460793875157833, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 93, train_loss = 3.622083821799606, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 94, train_loss = 3.59917214140296, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 95, train_loss = 3.5733986645936966, train_acc = 0.9928970656730322\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 96, train_loss = 3.551067469175905, train_acc = 0.9928970656730322\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 97, train_loss = 3.527436365839094, train_acc = 0.9930135072193759\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 98, train_loss = 3.505952589213848, train_acc = 0.9930135072193759\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 99, train_loss = 3.4832346974872053, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 100, train_loss = 3.4612123891711235, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 101, train_loss = 3.440577952656895, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 102, train_loss = 3.419546067714691, train_acc = 0.9931299487657196\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 103, train_loss = 3.3982646041549742, train_acc = 0.9931299487657196\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 104, train_loss = 3.3793499968014657, train_acc = 0.9931299487657196\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 105, train_loss = 3.3580657616257668, train_acc = 0.9932463903120633\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 106, train_loss = 3.336633509490639, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 107, train_loss = 3.318216511514038, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 108, train_loss = 3.3002146794460714, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 109, train_loss = 3.281195502728224, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 110, train_loss = 3.2634546905755997, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 111, train_loss = 3.2439671964384615, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 112, train_loss = 3.2262362339533865, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 113, train_loss = 3.208998495247215, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 114, train_loss = 3.190259087830782, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 115, train_loss = 3.1738020121119916, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 116, train_loss = 3.156747054308653, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 117, train_loss = 3.141463885549456, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 118, train_loss = 3.123879972845316, train_acc = 0.9934792734047508\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 119, train_loss = 3.1069789701141417, train_acc = 0.9934792734047508\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 120, train_loss = 3.0917492122389376, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 121, train_loss = 3.0764608620665967, train_acc = 0.9935957149510946\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 122, train_loss = 3.0616997121833265, train_acc = 0.9934792734047508\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 123, train_loss = 3.0457157865166664, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 124, train_loss = 3.0308966734446585, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 125, train_loss = 3.0140022449195385, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 126, train_loss = 3.002668549772352, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 127, train_loss = 2.9858259696047753, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 128, train_loss = 2.9725072868168354, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 129, train_loss = 2.957651029108092, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 130, train_loss = 2.944035803200677, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 131, train_loss = 2.9301733921747655, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 132, train_loss = 2.917269743978977, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 133, train_loss = 2.9040527914185077, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 134, train_loss = 2.89136203750968, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 135, train_loss = 2.8786373797338456, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 136, train_loss = 2.8654451195616275, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 137, train_loss = 2.8535864911973476, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 138, train_loss = 2.8394582781475037, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 139, train_loss = 2.8265489637851715, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 140, train_loss = 2.814751673489809, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 141, train_loss = 2.8039060558658093, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 142, train_loss = 2.7914031881373376, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 143, train_loss = 2.780519664287567, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 144, train_loss = 2.7688064265530556, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 145, train_loss = 2.757175254402682, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 146, train_loss = 2.745934182079509, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 147, train_loss = 2.734090206446126, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 148, train_loss = 2.724058371037245, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 149, train_loss = 2.7129390847403556, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 150, train_loss = 2.7021056946832687, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 151, train_loss = 2.6921888031065464, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 152, train_loss = 2.681308452039957, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 153, train_loss = 2.6713410194497555, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 154, train_loss = 2.660522097023204, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 155, train_loss = 2.6502401158213615, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 156, train_loss = 2.6398871627170593, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 157, train_loss = 2.629787964047864, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 158, train_loss = 2.620510971872136, train_acc = 0.9940614811364695\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 159, train_loss = 2.6116408556699753, train_acc = 0.9940614811364695\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 160, train_loss = 2.601106472313404, train_acc = 0.9940614811364695\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 161, train_loss = 2.591320112347603, train_acc = 0.9940614811364695\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 162, train_loss = 2.5834659102838486, train_acc = 0.9940614811364695\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 163, train_loss = 2.573963813483715, train_acc = 0.9940614811364695\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 164, train_loss = 2.5634005914907902, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 165, train_loss = 2.5563204649370164, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 166, train_loss = 2.546104095876217, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 167, train_loss = 2.5371501978952438, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 168, train_loss = 2.5278830751776695, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 169, train_loss = 2.519966724095866, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 170, train_loss = 2.5103276495356113, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 171, train_loss = 2.5030490967910737, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 172, train_loss = 2.496530258329585, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 173, train_loss = 2.486056209774688, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 174, train_loss = 2.479315422475338, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 175, train_loss = 2.471387929050252, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 176, train_loss = 2.462676415918395, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 177, train_loss = 2.455173324793577, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 178, train_loss = 2.4485819104593247, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 179, train_loss = 2.43949003261514, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 180, train_loss = 2.4323261615354568, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 181, train_loss = 2.4256656393408775, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 182, train_loss = 2.4182080924510956, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 183, train_loss = 2.4107048597652465, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 184, train_loss = 2.4039013932924718, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 185, train_loss = 2.3964915710967034, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 186, train_loss = 2.388486471027136, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 187, train_loss = 2.3826356902718544, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 188, train_loss = 2.3753625575918704, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 189, train_loss = 2.3672893557231873, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 190, train_loss = 2.3622861716430634, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 191, train_loss = 2.354818527819589, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 192, train_loss = 2.3493243504781276, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 193, train_loss = 2.341832458972931, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 194, train_loss = 2.336224378319457, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 195, train_loss = 2.3295910346787423, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 196, train_loss = 2.3231318544130772, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 197, train_loss = 2.3180193107109517, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 198, train_loss = 2.311790696112439, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 199, train_loss = 2.304974428145215, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 200, train_loss = 2.2997742008883506, train_acc = 0.9944108057755007\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 201, train_loss = 2.293164547532797, train_acc = 0.994294364229157\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 202, train_loss = 2.288684021681547, train_acc = 0.9944108057755007\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 203, train_loss = 2.2819005735218525, train_acc = 0.9944108057755007\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 204, train_loss = 2.276497572660446, train_acc = 0.9945272473218444\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 205, train_loss = 2.2702508096117526, train_acc = 0.9945272473218444\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 206, train_loss = 2.2663349471986294, train_acc = 0.9944108057755007\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 207, train_loss = 2.2595173481386155, train_acc = 0.9945272473218444\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 208, train_loss = 2.2536516387481242, train_acc = 0.9945272473218444\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 209, train_loss = 2.250168691156432, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 210, train_loss = 2.2434097814839333, train_acc = 0.9945272473218444\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 211, train_loss = 2.238070397404954, train_acc = 0.9945272473218444\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 212, train_loss = 2.2340560916345567, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 213, train_loss = 2.2283754907548428, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 214, train_loss = 2.2241355169098824, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 215, train_loss = 2.218982495367527, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 216, train_loss = 2.212980281561613, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 217, train_loss = 2.2087512165308, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 218, train_loss = 2.20384335401468, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 219, train_loss = 2.1994284130632877, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 220, train_loss = 2.1946053069550544, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 221, train_loss = 2.1892102647107095, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 222, train_loss = 2.1847094867844135, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 223, train_loss = 2.182368958950974, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 224, train_loss = 2.1751686421921477, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 225, train_loss = 2.171414560289122, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 226, train_loss = 2.167781097232364, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 227, train_loss = 2.163439535885118, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 228, train_loss = 2.159347388893366, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 229, train_loss = 2.1544324284186587, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 230, train_loss = 2.1493394064018503, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 231, train_loss = 2.146658086567186, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 232, train_loss = 2.1420917784562334, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 233, train_loss = 2.1379519440233707, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 234, train_loss = 2.1338661027839407, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 235, train_loss = 2.1299837256083265, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 236, train_loss = 2.126181837171316, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 237, train_loss = 2.1221873922040686, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 238, train_loss = 2.1174472644925117, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 239, train_loss = 2.1137472254922614, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 240, train_loss = 2.1113123992690817, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 241, train_loss = 2.1058234671363607, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 242, train_loss = 2.102039098739624, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 243, train_loss = 2.0979073122143745, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 244, train_loss = 2.0954641265561804, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 245, train_loss = 2.090834818780422, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 246, train_loss = 2.088142062188126, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 247, train_loss = 2.0847825333476067, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 248, train_loss = 2.0798148600151762, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 249, train_loss = 2.077738112420775, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 250, train_loss = 2.0730464147636667, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 251, train_loss = 2.0685209209332243, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 252, train_loss = 2.0670026080915704, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 253, train_loss = 2.0628774414071813, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 254, train_loss = 2.0598740900168195, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 255, train_loss = 2.055917820543982, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 256, train_loss = 2.0514482433209196, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 257, train_loss = 2.049460651935078, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 258, train_loss = 2.046100822626613, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 259, train_loss = 2.0442752465605736, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 260, train_loss = 2.0394318687031046, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 261, train_loss = 2.0360283429035917, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 262, train_loss = 2.0327717202017084, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 263, train_loss = 2.0303029008209705, train_acc = 0.9951094550535631\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 264, train_loss = 2.027471718727611, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 265, train_loss = 2.0244280298938975, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 266, train_loss = 2.0204106693854555, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 267, train_loss = 2.018475587130524, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 268, train_loss = 2.0147235045442358, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 269, train_loss = 2.011144174844958, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 270, train_loss = 2.00845103955362, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 271, train_loss = 2.0050399204483256, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 272, train_loss = 2.004032053053379, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 273, train_loss = 1.9997440241277218, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 274, train_loss = 1.9969107235083356, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 275, train_loss = 1.9939756753155962, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 276, train_loss = 1.9916173840174451, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 277, train_loss = 1.9876880893716589, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 278, train_loss = 1.9867780233034864, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 279, train_loss = 1.9836486080894247, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 280, train_loss = 1.981134599656798, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 281, train_loss = 1.9766369014978409, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 282, train_loss = 1.976048942655325, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 283, train_loss = 1.9724731718888506, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 284, train_loss = 1.969917368143797, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 285, train_loss = 1.9662019362440333, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 286, train_loss = 1.9653706960380077, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 287, train_loss = 1.9611420258879662, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 288, train_loss = 1.9583350270986557, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 289, train_loss = 1.9561934793600813, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 290, train_loss = 1.9532948968699202, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 291, train_loss = 1.9520074600586668, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 292, train_loss = 1.9493828043341637, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 293, train_loss = 1.9458059830358252, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 294, train_loss = 1.9428287422051653, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 295, train_loss = 1.942317301989533, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 296, train_loss = 1.9386081174015999, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 297, train_loss = 1.9353896379470825, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 298, train_loss = 1.935179941356182, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 299, train_loss = 1.9317596281180158, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 300, train_loss = 1.9291619757423177, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 301, train_loss = 1.9274147698888555, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 302, train_loss = 1.925153698772192, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 303, train_loss = 1.9223983399569988, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 304, train_loss = 1.9196806562831625, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 305, train_loss = 1.9182854680111632, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 306, train_loss = 1.91605781391263, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 307, train_loss = 1.913063128828071, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 308, train_loss = 1.9118574237218127, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 309, train_loss = 1.9091716036200523, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 310, train_loss = 1.9062122901668772, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 311, train_loss = 1.904188595712185, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 312, train_loss = 1.9030941128730774, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 313, train_loss = 1.9003515330841765, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 314, train_loss = 1.897632991313003, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 315, train_loss = 1.8956375978887081, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 316, train_loss = 1.8938960855593905, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 317, train_loss = 1.8933329271385446, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 318, train_loss = 1.8903430439531803, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 319, train_loss = 1.8873453041305766, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 320, train_loss = 1.8859824104001746, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 321, train_loss = 1.8833546402165666, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 322, train_loss = 1.8819460049271584, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 323, train_loss = 1.8800059035420418, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 324, train_loss = 1.877295090467669, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 325, train_loss = 1.8750659190118313, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 326, train_loss = 1.8744144762167707, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 327, train_loss = 1.8711247754981741, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 328, train_loss = 1.8704433863749728, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 329, train_loss = 1.8682816326618195, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 330, train_loss = 1.8659925224492326, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 331, train_loss = 1.8649223981192335, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 332, train_loss = 1.8620353316655383, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 333, train_loss = 1.8608024852583185, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 334, train_loss = 1.8592884577810764, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 335, train_loss = 1.8575688675045967, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 336, train_loss = 1.8553730075946078, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 337, train_loss = 1.8534326540539041, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 338, train_loss = 1.8507172664394602, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 339, train_loss = 1.850596733391285, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 340, train_loss = 1.8471989209065214, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 341, train_loss = 1.8474758826196194, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 342, train_loss = 1.8445282926550135, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 343, train_loss = 1.8428945193300024, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 344, train_loss = 1.8405310859670863, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 345, train_loss = 1.8383393151452765, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 346, train_loss = 1.8379112122347578, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 347, train_loss = 1.8353934647748247, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 348, train_loss = 1.8336395882070065, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 349, train_loss = 1.8319303108146414, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 350, train_loss = 1.8299801833927631, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 351, train_loss = 1.8288159891963005, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 352, train_loss = 1.8271185992052779, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 353, train_loss = 1.8268820941448212, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 354, train_loss = 1.824153477908112, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 355, train_loss = 1.8231671340763569, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 356, train_loss = 1.820659893215634, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 357, train_loss = 1.8187763852765784, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 358, train_loss = 1.8169596468796954, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 359, train_loss = 1.8157294057309628, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 360, train_loss = 1.8144881874322891, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 361, train_loss = 1.8119971317937598, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 362, train_loss = 1.811413706629537, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 363, train_loss = 1.8105272402754053, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 364, train_loss = 1.8075842907419428, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 365, train_loss = 1.8065044594113715, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 366, train_loss = 1.8066331669688225, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 367, train_loss = 1.8040415905416012, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 368, train_loss = 1.8036297857761383, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 369, train_loss = 1.8011256257886998, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 370, train_loss = 1.8003078338806517, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 371, train_loss = 1.7969872181420214, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 372, train_loss = 1.7965428816969506, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 373, train_loss = 1.7946903457050212, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 374, train_loss = 1.7934427348081954, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 375, train_loss = 1.7920304710860364, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 376, train_loss = 1.7910394345526583, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 377, train_loss = 1.7900915357167833, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 378, train_loss = 1.7882911848719232, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 379, train_loss = 1.7853176494245417, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 380, train_loss = 1.784254714846611, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 381, train_loss = 1.7831641025841236, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 382, train_loss = 1.7820962953264825, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 383, train_loss = 1.7809167429804802, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 384, train_loss = 1.7806237414479256, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 385, train_loss = 1.7775267933611758, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 386, train_loss = 1.7776243214611895, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 387, train_loss = 1.7753106293384917, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 388, train_loss = 1.7731219356064685, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 389, train_loss = 1.7720250015263446, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 390, train_loss = 1.7704460844397545, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 391, train_loss = 1.7699414044618607, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 392, train_loss = 1.7688752114772797, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 393, train_loss = 1.767660427838564, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 394, train_loss = 1.7670010216534138, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 395, train_loss = 1.7653672955930233, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 396, train_loss = 1.7644175912137143, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 397, train_loss = 1.7636488837306388, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 398, train_loss = 1.7608617680962197, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 399, train_loss = 1.7618506774306297, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 400, train_loss = 1.7601939725573175, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 401, train_loss = 1.7578103269333951, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 402, train_loss = 1.7567763216793537, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 403, train_loss = 1.7560130978818052, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 404, train_loss = 1.7536615778808482, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 405, train_loss = 1.7535534327034838, train_acc = 0.9951094550535631\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 406, train_loss = 1.7523998245596886, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 407, train_loss = 1.7501837785239331, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 408, train_loss = 1.7501721766893752, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 409, train_loss = 1.748765251308214, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 410, train_loss = 1.7466182361240499, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 411, train_loss = 1.7457905200426467, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 412, train_loss = 1.7439072988927364, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 413, train_loss = 1.744626235216856, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 414, train_loss = 1.742397001653444, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 415, train_loss = 1.7414407159085386, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 416, train_loss = 1.739196399867069, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 417, train_loss = 1.7389507715706713, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 418, train_loss = 1.737732821435202, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 419, train_loss = 1.7375846070353873, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 420, train_loss = 1.7351864973898046, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 421, train_loss = 1.735197986185085, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 422, train_loss = 1.7334091787342913, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 423, train_loss = 1.7323512720759027, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 424, train_loss = 1.7311611796612851, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 425, train_loss = 1.73102518171072, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 426, train_loss = 1.7295979435439222, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 427, train_loss = 1.728504208207596, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 428, train_loss = 1.7276087068021297, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 429, train_loss = 1.7256795205175877, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 430, train_loss = 1.724228248000145, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 431, train_loss = 1.7230263675446622, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 432, train_loss = 1.7229115280206315, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 433, train_loss = 1.7225116242771037, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 434, train_loss = 1.7199455934460275, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 435, train_loss = 1.7211389914155006, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 436, train_loss = 1.7195454600150697, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 437, train_loss = 1.718475999950897, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 438, train_loss = 1.7162872391636483, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 439, train_loss = 1.7160355535452254, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 440, train_loss = 1.7145183918182738, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 441, train_loss = 1.7146743672783487, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 442, train_loss = 1.713397757441271, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 443, train_loss = 1.7112932329182513, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 444, train_loss = 1.710548460483551, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 445, train_loss = 1.7108765828306787, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 446, train_loss = 1.7078601631219499, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 447, train_loss = 1.7083417761023156, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 448, train_loss = 1.7081088262493722, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 449, train_loss = 1.7052062451839447, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 450, train_loss = 1.7057174108922482, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 451, train_loss = 1.7033677746658213, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 452, train_loss = 1.7040449070627801, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 453, train_loss = 1.7019027185742743, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 454, train_loss = 1.7018031415645964, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 455, train_loss = 1.7007704302668571, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 456, train_loss = 1.6998802721500397, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 457, train_loss = 1.6986855517025106, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 458, train_loss = 1.6971193266217597, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 459, train_loss = 1.69782054919051, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 460, train_loss = 1.694475265860092, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 461, train_loss = 1.695624350279104, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 462, train_loss = 1.6949007759685628, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 463, train_loss = 1.692517377436161, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 464, train_loss = 1.6931815122370608, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 465, train_loss = 1.6914641584153287, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 466, train_loss = 1.690896796702873, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 467, train_loss = 1.6903813543613069, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 468, train_loss = 1.6894348834757693, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 469, train_loss = 1.687264276028145, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 470, train_loss = 1.6882345440681092, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 471, train_loss = 1.6870671187643893, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 472, train_loss = 1.6852954377536662, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 473, train_loss = 1.685521975159645, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 474, train_loss = 1.6839048999245279, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 475, train_loss = 1.6827177206869237, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 476, train_loss = 1.6822989496286027, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 477, train_loss = 1.6817382809822448, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 478, train_loss = 1.6812067056889646, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 479, train_loss = 1.6803313232958317, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 480, train_loss = 1.678009846538771, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 481, train_loss = 1.6782334012095816, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 482, train_loss = 1.677336174994707, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 483, train_loss = 1.6766837686300278, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 484, train_loss = 1.6768945083022118, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 485, train_loss = 1.6744671140913852, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 486, train_loss = 1.6743695574696176, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 487, train_loss = 1.672884086787235, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 488, train_loss = 1.672487220435869, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 489, train_loss = 1.6718357602949254, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 490, train_loss = 1.671148939698469, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 491, train_loss = 1.6698092359001748, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 492, train_loss = 1.6691618114709854, train_acc = 0.9952258965999069\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 493, train_loss = 1.6695734597742558, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 494, train_loss = 1.6672830507159233, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 495, train_loss = 1.6671547728474252, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 496, train_loss = 1.6663689886336215, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 497, train_loss = 1.6659271555836312, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 498, train_loss = 1.6638925485312939, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 499, train_loss = 1.6648286792333238, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████                     | 21/30 [3:10:06<1:21:26, 542.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "22th- epoch: 0, train_loss = 127.25541940331459, train_acc = 0.7833022822543083\n",
      "test Acc 0.8896648044692738:\n",
      "22th- epoch: 1, train_loss = 41.436591789126396, train_acc = 0.9125523986958547\n",
      "test Acc 0.9264432029795159:\n",
      "22th- epoch: 2, train_loss = 31.89788932353258, train_acc = 0.9330461108523521\n",
      "test Acc 0.9380819366852886:\n",
      "22th- epoch: 3, train_loss = 26.990378618240356, train_acc = 0.9450395901257569\n",
      "test Acc 0.9450651769087524:\n",
      "22th- epoch: 4, train_loss = 23.791397362947464, train_acc = 0.9527247321844434\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 5, train_loss = 21.443966504186392, train_acc = 0.9562179785747554\n",
      "test Acc 0.9515828677839852:\n",
      "22th- epoch: 6, train_loss = 19.62145236879587, train_acc = 0.9593619003260363\n",
      "test Acc 0.9529795158286778:\n",
      "22th- epoch: 7, train_loss = 18.19322293624282, train_acc = 0.9615742897065673\n",
      "test Acc 0.9529795158286778:\n",
      "22th- epoch: 8, train_loss = 17.000115778297186, train_acc = 0.9636702375407545\n",
      "test Acc 0.9543761638733705:\n",
      "22th- epoch: 9, train_loss = 15.997140534222126, train_acc = 0.965649743828598\n",
      "test Acc 0.9543761638733705:\n",
      "22th- epoch: 10, train_loss = 15.129605531692505, train_acc = 0.9678621332091291\n",
      "test Acc 0.9553072625698324:\n",
      "22th- epoch: 11, train_loss = 14.369942616671324, train_acc = 0.9704238472286912\n",
      "test Acc 0.9562383612662942:\n",
      "22th- epoch: 12, train_loss = 13.707471489906311, train_acc = 0.9717047042384723\n",
      "test Acc 0.957169459962756:\n",
      "22th- epoch: 13, train_loss = 13.12192877754569, train_acc = 0.9729855612482534\n",
      "test Acc 0.957635009310987:\n",
      "22th- epoch: 14, train_loss = 12.595666877925396, train_acc = 0.9742664182580345\n",
      "test Acc 0.957635009310987:\n",
      "22th- epoch: 15, train_loss = 12.104039918631315, train_acc = 0.9755472752678156\n",
      "test Acc 0.9581005586592178:\n",
      "22th- epoch: 16, train_loss = 11.656041253358126, train_acc = 0.9765952491849091\n",
      "test Acc 0.9590316573556797:\n",
      "22th- epoch: 17, train_loss = 11.255818672478199, train_acc = 0.9776432231020028\n",
      "test Acc 0.9594972067039106:\n",
      "22th- epoch: 18, train_loss = 10.885195698589087, train_acc = 0.9782254308337215\n",
      "test Acc 0.9604283054003724:\n",
      "22th- epoch: 19, train_loss = 10.54358447343111, train_acc = 0.9786911970190965\n",
      "test Acc 0.9608938547486033:\n",
      "22th- epoch: 20, train_loss = 10.228427942842245, train_acc = 0.9791569632044713\n",
      "test Acc 0.9608938547486033:\n",
      "22th- epoch: 21, train_loss = 9.927304968237877, train_acc = 0.9796227293898463\n",
      "test Acc 0.9618249534450651:\n",
      "22th- epoch: 22, train_loss = 9.650496842339635, train_acc = 0.98067070330694\n",
      "test Acc 0.9618249534450651:\n",
      "22th- epoch: 23, train_loss = 9.387606360018253, train_acc = 0.9814857941313461\n",
      "test Acc 0.9622905027932961:\n",
      "22th- epoch: 24, train_loss = 9.141170931980014, train_acc = 0.9818351187703773\n",
      "test Acc 0.9632216014897579:\n",
      "22th- epoch: 25, train_loss = 8.907830426469445, train_acc = 0.981951560316721\n",
      "test Acc 0.9632216014897579:\n",
      "22th- epoch: 26, train_loss = 8.688988383859396, train_acc = 0.9821844434094085\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 27, train_loss = 8.481661602854729, train_acc = 0.9825337680484397\n",
      "test Acc 0.9646182495344506:\n",
      "22th- epoch: 28, train_loss = 8.281999120488763, train_acc = 0.9829995342338146\n",
      "test Acc 0.9650837988826816:\n",
      "22th- epoch: 29, train_loss = 8.094475032761693, train_acc = 0.9838146250582208\n",
      "test Acc 0.9655493482309124:\n",
      "22th- epoch: 30, train_loss = 7.913891585543752, train_acc = 0.9840475081509082\n",
      "test Acc 0.9655493482309124:\n",
      "22th- epoch: 31, train_loss = 7.744203723967075, train_acc = 0.9843968327899395\n",
      "test Acc 0.9655493482309124:\n",
      "22th- epoch: 32, train_loss = 7.577809227630496, train_acc = 0.9846297158826269\n",
      "test Acc 0.9655493482309124:\n",
      "22th- epoch: 33, train_loss = 7.42031810246408, train_acc = 0.9848625989753144\n",
      "test Acc 0.9650837988826816:\n",
      "22th- epoch: 34, train_loss = 7.273838521912694, train_acc = 0.9852119236143456\n",
      "test Acc 0.9650837988826816:\n",
      "22th- epoch: 35, train_loss = 7.13155641593039, train_acc = 0.9852119236143456\n",
      "test Acc 0.9655493482309124:\n",
      "22th- epoch: 36, train_loss = 6.996416077017784, train_acc = 0.985444806707033\n",
      "test Acc 0.9655493482309124:\n",
      "22th- epoch: 37, train_loss = 6.869201425462961, train_acc = 0.9855612482533768\n",
      "test Acc 0.9655493482309124:\n",
      "22th- epoch: 38, train_loss = 6.747008420526981, train_acc = 0.985910572892408\n",
      "test Acc 0.9660148975791434:\n",
      "22th- epoch: 39, train_loss = 6.630749894306064, train_acc = 0.9864927806241267\n",
      "test Acc 0.9664804469273743:\n",
      "22th- epoch: 40, train_loss = 6.516694707795978, train_acc = 0.9868421052631579\n",
      "test Acc 0.9660148975791434:\n",
      "22th- epoch: 41, train_loss = 6.408279957249761, train_acc = 0.9870749883558454\n",
      "test Acc 0.9660148975791434:\n",
      "22th- epoch: 42, train_loss = 6.305230192840099, train_acc = 0.9873078714485328\n",
      "test Acc 0.9664804469273743:\n",
      "22th- epoch: 43, train_loss = 6.20429371856153, train_acc = 0.9874243129948765\n",
      "test Acc 0.9664804469273743:\n",
      "22th- epoch: 44, train_loss = 6.106831068173051, train_acc = 0.9877736376339078\n",
      "test Acc 0.9664804469273743:\n",
      "22th- epoch: 45, train_loss = 6.013993911445141, train_acc = 0.9880065207265952\n",
      "test Acc 0.9664804469273743:\n",
      "22th- epoch: 46, train_loss = 5.9211870320141315, train_acc = 0.9882394038192828\n",
      "test Acc 0.9669459962756052:\n",
      "22th- epoch: 47, train_loss = 5.834541290998459, train_acc = 0.9884722869119702\n",
      "test Acc 0.9669459962756052:\n",
      "22th- epoch: 48, train_loss = 5.748003708198667, train_acc = 0.9885887284583139\n",
      "test Acc 0.9669459962756052:\n",
      "22th- epoch: 49, train_loss = 5.668455740436912, train_acc = 0.9887051700046576\n",
      "test Acc 0.9669459962756052:\n",
      "22th- epoch: 50, train_loss = 5.59093526750803, train_acc = 0.9889380530973452\n",
      "test Acc 0.9669459962756052:\n",
      "22th- epoch: 51, train_loss = 5.515006642788649, train_acc = 0.9889380530973452\n",
      "test Acc 0.9674115456238361:\n",
      "22th- epoch: 52, train_loss = 5.442806987091899, train_acc = 0.9891709361900326\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 53, train_loss = 5.3715632651001215, train_acc = 0.9891709361900326\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 54, train_loss = 5.303421728312969, train_acc = 0.98940381928272\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 55, train_loss = 5.235536178573966, train_acc = 0.9895202608290639\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 56, train_loss = 5.171776397153735, train_acc = 0.9899860270144387\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 57, train_loss = 5.106181049719453, train_acc = 0.9901024685607824\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 58, train_loss = 5.043850960209966, train_acc = 0.99033535165347\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 59, train_loss = 4.984318606555462, train_acc = 0.9904517931998137\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 60, train_loss = 4.925109442323446, train_acc = 0.9906846762925011\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 61, train_loss = 4.870466116815805, train_acc = 0.9906846762925011\n",
      "test Acc 0.9683426443202979:\n",
      "22th- epoch: 62, train_loss = 4.816600410267711, train_acc = 0.990801117838845\n",
      "test Acc 0.9683426443202979:\n",
      "22th- epoch: 63, train_loss = 4.763811135664582, train_acc = 0.9909175593851887\n",
      "test Acc 0.9683426443202979:\n",
      "22th- epoch: 64, train_loss = 4.710839061066508, train_acc = 0.9909175593851887\n",
      "test Acc 0.9683426443202979:\n",
      "22th- epoch: 65, train_loss = 4.662174496799707, train_acc = 0.9911504424778761\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 66, train_loss = 4.6128942128270864, train_acc = 0.9911504424778761\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 67, train_loss = 4.566352324560285, train_acc = 0.9916162086632511\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 68, train_loss = 4.518810225650668, train_acc = 0.9916162086632511\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 69, train_loss = 4.4734737277030945, train_acc = 0.9916162086632511\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 70, train_loss = 4.428369140252471, train_acc = 0.9916162086632511\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 71, train_loss = 4.385607094503939, train_acc = 0.9916162086632511\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 72, train_loss = 4.3439927296712995, train_acc = 0.9917326502095948\n",
      "test Acc 0.9683426443202979:\n",
      "22th- epoch: 73, train_loss = 4.301300393417478, train_acc = 0.9917326502095948\n",
      "test Acc 0.9683426443202979:\n",
      "22th- epoch: 74, train_loss = 4.260885712690651, train_acc = 0.9917326502095948\n",
      "test Acc 0.9688081936685289:\n",
      "22th- epoch: 75, train_loss = 4.220781251788139, train_acc = 0.9917326502095948\n",
      "test Acc 0.9688081936685289:\n",
      "22th- epoch: 76, train_loss = 4.181897525675595, train_acc = 0.9917326502095948\n",
      "test Acc 0.9688081936685289:\n",
      "22th- epoch: 77, train_loss = 4.14401781745255, train_acc = 0.9917326502095948\n",
      "test Acc 0.9692737430167597:\n",
      "22th- epoch: 78, train_loss = 4.10800077393651, train_acc = 0.9918490917559385\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 79, train_loss = 4.072235006839037, train_acc = 0.992081974848626\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 80, train_loss = 4.0385238863527775, train_acc = 0.992081974848626\n",
      "test Acc 0.9702048417132216:\n",
      "22th- epoch: 81, train_loss = 4.0039192931726575, train_acc = 0.992081974848626\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 82, train_loss = 3.971417650580406, train_acc = 0.992081974848626\n",
      "test Acc 0.9702048417132216:\n",
      "22th- epoch: 83, train_loss = 3.93826911970973, train_acc = 0.992081974848626\n",
      "test Acc 0.9702048417132216:\n",
      "22th- epoch: 84, train_loss = 3.907220513559878, train_acc = 0.992081974848626\n",
      "test Acc 0.9706703910614525:\n",
      "22th- epoch: 85, train_loss = 3.878080504015088, train_acc = 0.992081974848626\n",
      "test Acc 0.9706703910614525:\n",
      "22th- epoch: 86, train_loss = 3.846895813010633, train_acc = 0.9921984163949698\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 87, train_loss = 3.816949306987226, train_acc = 0.9921984163949698\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 88, train_loss = 3.7893640277907252, train_acc = 0.992081974848626\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 89, train_loss = 3.7596715353429317, train_acc = 0.9923148579413135\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 90, train_loss = 3.731657492928207, train_acc = 0.9924312994876572\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 91, train_loss = 3.7057758923619986, train_acc = 0.9923148579413135\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 92, train_loss = 3.679459731094539, train_acc = 0.9924312994876572\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 93, train_loss = 3.653080992400646, train_acc = 0.9923148579413135\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 94, train_loss = 3.627974074333906, train_acc = 0.9923148579413135\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 95, train_loss = 3.6027484415099025, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 96, train_loss = 3.5780885377898812, train_acc = 0.9923148579413135\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 97, train_loss = 3.5538539234548807, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 98, train_loss = 3.53095277864486, train_acc = 0.9924312994876572\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 99, train_loss = 3.5084586506709456, train_acc = 0.9924312994876572\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 100, train_loss = 3.484288507141173, train_acc = 0.9925477410340009\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 101, train_loss = 3.4637517174705863, train_acc = 0.9925477410340009\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 102, train_loss = 3.4415014488622546, train_acc = 0.9926641825803446\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 103, train_loss = 3.4203575579449534, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 104, train_loss = 3.3988191159442067, train_acc = 0.9927806241266884\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 105, train_loss = 3.3785676322877407, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 106, train_loss = 3.358199864625931, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 107, train_loss = 3.337937311269343, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 108, train_loss = 3.318899436853826, train_acc = 0.9928970656730322\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 109, train_loss = 3.298863261938095, train_acc = 0.9930135072193759\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 110, train_loss = 3.2802348993718624, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 111, train_loss = 3.2625580253079534, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 112, train_loss = 3.241992376744747, train_acc = 0.9930135072193759\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 113, train_loss = 3.2244729846715927, train_acc = 0.9930135072193759\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 114, train_loss = 3.2066536964848638, train_acc = 0.9930135072193759\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 115, train_loss = 3.18910517077893, train_acc = 0.9934792734047508\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 116, train_loss = 3.171664741821587, train_acc = 0.9931299487657196\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 117, train_loss = 3.1541786193847656, train_acc = 0.9935957149510946\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 118, train_loss = 3.1369326040148735, train_acc = 0.9935957149510946\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 119, train_loss = 3.121084830723703, train_acc = 0.9937121564974383\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 120, train_loss = 3.1043494855985045, train_acc = 0.993828598043782\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 121, train_loss = 3.088022295385599, train_acc = 0.993828598043782\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 122, train_loss = 3.072902388870716, train_acc = 0.993828598043782\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 123, train_loss = 3.0569563759490848, train_acc = 0.993828598043782\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 124, train_loss = 3.041483392007649, train_acc = 0.993828598043782\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 125, train_loss = 3.0261998856440187, train_acc = 0.993828598043782\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 126, train_loss = 3.010713960044086, train_acc = 0.993828598043782\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 127, train_loss = 2.9965175688266754, train_acc = 0.993828598043782\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 128, train_loss = 2.9825352705083787, train_acc = 0.993828598043782\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 129, train_loss = 2.9680696823634207, train_acc = 0.993828598043782\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 130, train_loss = 2.9536457248032093, train_acc = 0.9939450395901258\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 131, train_loss = 2.9404452866874635, train_acc = 0.9939450395901258\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 132, train_loss = 2.926371980458498, train_acc = 0.9939450395901258\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 133, train_loss = 2.912230548914522, train_acc = 0.9939450395901258\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 134, train_loss = 2.900219573173672, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 135, train_loss = 2.8870391212403774, train_acc = 0.9939450395901258\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 136, train_loss = 2.8741576322354376, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 137, train_loss = 2.861958718392998, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 138, train_loss = 2.850345349404961, train_acc = 0.9939450395901258\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 139, train_loss = 2.8373870216310024, train_acc = 0.9939450395901258\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 140, train_loss = 2.8243540502153337, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 141, train_loss = 2.8113592988811433, train_acc = 0.9940614811364695\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 142, train_loss = 2.7983324476517737, train_acc = 0.9940614811364695\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 143, train_loss = 2.7874618023633957, train_acc = 0.9941779226828132\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 144, train_loss = 2.7753879413940012, train_acc = 0.994294364229157\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 145, train_loss = 2.762421020772308, train_acc = 0.994294364229157\n",
      "test Acc 0.973463687150838:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 146, train_loss = 2.7528040683828294, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 147, train_loss = 2.7407927089370787, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 148, train_loss = 2.730351862963289, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 149, train_loss = 2.7199945971369743, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 150, train_loss = 2.709352082107216, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 151, train_loss = 2.6985366553999484, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 152, train_loss = 2.6880122958682477, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 153, train_loss = 2.6783095449209213, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 154, train_loss = 2.6679785600863397, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 155, train_loss = 2.658218471799046, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 156, train_loss = 2.6487774760462344, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 157, train_loss = 2.638791507575661, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 158, train_loss = 2.62914510210976, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 159, train_loss = 2.62010008841753, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 160, train_loss = 2.6096418141387403, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 161, train_loss = 2.6010893671773374, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 162, train_loss = 2.591437896247953, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 163, train_loss = 2.5820867978036404, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 164, train_loss = 2.57402673503384, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 165, train_loss = 2.5651437379419804, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 166, train_loss = 2.5563951819203794, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 167, train_loss = 2.54788606101647, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 168, train_loss = 2.539963938295841, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 169, train_loss = 2.5312908440828323, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 170, train_loss = 2.522354766726494, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 171, train_loss = 2.515282806009054, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 172, train_loss = 2.5066473819315434, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 173, train_loss = 2.4979720353148878, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 174, train_loss = 2.4918133108876646, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 175, train_loss = 2.4832558990456164, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 176, train_loss = 2.4762644967995584, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 177, train_loss = 2.4676927900873125, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 178, train_loss = 2.4604853591881692, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 179, train_loss = 2.452980016823858, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 180, train_loss = 2.4460992948152125, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 181, train_loss = 2.437506516929716, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 182, train_loss = 2.431499606464058, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 183, train_loss = 2.424634671304375, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 184, train_loss = 2.4164344258606434, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 185, train_loss = 2.409747526049614, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 186, train_loss = 2.4030167148448527, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 187, train_loss = 2.3956503309309483, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 188, train_loss = 2.389273351524025, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 189, train_loss = 2.382087556179613, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 190, train_loss = 2.3757853233255446, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 191, train_loss = 2.369178634136915, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 192, train_loss = 2.3625371865928173, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 193, train_loss = 2.356996727641672, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 194, train_loss = 2.350075124297291, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 195, train_loss = 2.3434825190342963, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 196, train_loss = 2.337763713207096, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 197, train_loss = 2.3315673754550517, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 198, train_loss = 2.325845340732485, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 199, train_loss = 2.320109078194946, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 200, train_loss = 2.312704319600016, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 201, train_loss = 2.3084115288220346, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 202, train_loss = 2.30216525006108, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 203, train_loss = 2.296440300764516, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 204, train_loss = 2.290852175327018, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 205, train_loss = 2.2848667327780277, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 206, train_loss = 2.278677503345534, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 207, train_loss = 2.273652746109292, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 208, train_loss = 2.268055322347209, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 209, train_loss = 2.2620287388563156, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 210, train_loss = 2.2576629754621536, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 211, train_loss = 2.2521681648213416, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 212, train_loss = 2.246119860559702, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 213, train_loss = 2.241210227133706, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 214, train_loss = 2.2355249288957566, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 215, train_loss = 2.2304947797674686, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 216, train_loss = 2.2253754909615964, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 217, train_loss = 2.2207278285641223, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 218, train_loss = 2.2158341768663377, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 219, train_loss = 2.211178697645664, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 220, train_loss = 2.2060722287278622, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 221, train_loss = 2.200907914666459, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 222, train_loss = 2.196037332294509, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 223, train_loss = 2.1908736303448677, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 224, train_loss = 2.1863525174558163, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 225, train_loss = 2.180979213444516, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 226, train_loss = 2.1779639273881912, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 227, train_loss = 2.1729855090379715, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 228, train_loss = 2.1677731585223228, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 229, train_loss = 2.163954184623435, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 230, train_loss = 2.1588795830029994, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 231, train_loss = 2.1537434954661876, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 232, train_loss = 2.1500637617427856, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 233, train_loss = 2.1457406592089683, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 234, train_loss = 2.1409801717381924, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 235, train_loss = 2.1376768972259015, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 236, train_loss = 2.13280459982343, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 237, train_loss = 2.1284270759206265, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 238, train_loss = 2.1251231643836945, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 239, train_loss = 2.120168399065733, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 240, train_loss = 2.1166199061553925, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 241, train_loss = 2.112415795447305, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 242, train_loss = 2.108264082344249, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 243, train_loss = 2.103614130290225, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 244, train_loss = 2.0995419162791222, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 245, train_loss = 2.096225429326296, train_acc = 0.9953423381462506\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 246, train_loss = 2.092632845044136, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 247, train_loss = 2.0879809632897377, train_acc = 0.995575221238938\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 248, train_loss = 2.084608094068244, train_acc = 0.995575221238938\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 249, train_loss = 2.0814411018509418, train_acc = 0.995575221238938\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 250, train_loss = 2.0774843108374625, train_acc = 0.995575221238938\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 251, train_loss = 2.073201780440286, train_acc = 0.995575221238938\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 252, train_loss = 2.0700666655320674, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 253, train_loss = 2.066257733851671, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 254, train_loss = 2.0623730793595314, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 255, train_loss = 2.0593814130406827, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 256, train_loss = 2.0552733715157956, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 257, train_loss = 2.052585081430152, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 258, train_loss = 2.0485553157050163, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 259, train_loss = 2.0453145925421268, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 260, train_loss = 2.0414177489001304, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 261, train_loss = 2.0385396890342236, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 262, train_loss = 2.034838765859604, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 263, train_loss = 2.0315509524662048, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 264, train_loss = 2.0292177710216492, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 265, train_loss = 2.0257417175453156, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 266, train_loss = 2.0219120632391423, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 267, train_loss = 2.0178940296173096, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 268, train_loss = 2.0152705546934158, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 269, train_loss = 2.012529383180663, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 270, train_loss = 2.009811895666644, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 271, train_loss = 2.0065891332924366, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 272, train_loss = 2.0029846045654267, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 273, train_loss = 2.000102262943983, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 274, train_loss = 1.9962603871244937, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 275, train_loss = 1.9943515062332153, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 276, train_loss = 1.9905322988051921, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 277, train_loss = 1.9876824915409088, train_acc = 0.9956916627852818\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 278, train_loss = 1.9840605470817536, train_acc = 0.9954587796925943\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 279, train_loss = 1.9818366083782166, train_acc = 0.995575221238938\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 280, train_loss = 1.9792150456923991, train_acc = 0.9956916627852818\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 281, train_loss = 1.976275599328801, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 282, train_loss = 1.9723426264245063, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 283, train_loss = 1.9696009668987244, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 284, train_loss = 1.966938139172271, train_acc = 0.9958081043316255\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 285, train_loss = 1.9642428469378501, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 286, train_loss = 1.9620649132411927, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 287, train_loss = 1.9591979298274964, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 288, train_loss = 1.9566058304626495, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 289, train_loss = 1.9541230972390622, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 290, train_loss = 1.95042980206199, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 291, train_loss = 1.9478323545772582, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 292, train_loss = 1.9460030260961503, train_acc = 0.995575221238938\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 293, train_loss = 1.942554410547018, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 294, train_loss = 1.9405000668484718, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 295, train_loss = 1.9373343139886856, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 296, train_loss = 1.9348243947606534, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 297, train_loss = 1.9320394929964095, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 298, train_loss = 1.9296163630206138, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 299, train_loss = 1.9278019380290061, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 300, train_loss = 1.9247318606358021, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 301, train_loss = 1.9219792920630425, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 302, train_loss = 1.9198753561358899, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 303, train_loss = 1.9174414165318012, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 304, train_loss = 1.914755793986842, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 305, train_loss = 1.9121366802137345, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 306, train_loss = 1.9099584072828293, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 307, train_loss = 1.907650725217536, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 308, train_loss = 1.905527275055647, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 309, train_loss = 1.9024975448846817, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 310, train_loss = 1.9010065395850688, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 311, train_loss = 1.898232727078721, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 312, train_loss = 1.896421282319352, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 313, train_loss = 1.893444236367941, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 314, train_loss = 1.891607340425253, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 315, train_loss = 1.8891738269012421, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 316, train_loss = 1.8869604989886284, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 317, train_loss = 1.884670113446191, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 318, train_loss = 1.8825573921203613, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 319, train_loss = 1.8804962622234598, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 320, train_loss = 1.8782276771962643, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 321, train_loss = 1.8755561113357544, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 322, train_loss = 1.8738430080702528, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 323, train_loss = 1.8725183556089178, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 324, train_loss = 1.8691541304579005, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 325, train_loss = 1.867141216993332, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 326, train_loss = 1.865328392595984, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 327, train_loss = 1.863342385739088, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 328, train_loss = 1.8612426953623071, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 329, train_loss = 1.8597168773412704, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 330, train_loss = 1.8571118786931038, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 331, train_loss = 1.8554813315859064, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 332, train_loss = 1.8528563963482156, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 333, train_loss = 1.8515223326394334, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 334, train_loss = 1.8490461371839046, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 335, train_loss = 1.8476131545612589, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 336, train_loss = 1.8450249433517456, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 337, train_loss = 1.843023327528499, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 338, train_loss = 1.8420481830835342, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 339, train_loss = 1.8397012067725882, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 340, train_loss = 1.8373243609676138, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 341, train_loss = 1.8356253256788477, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 342, train_loss = 1.834678240120411, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 343, train_loss = 1.8324418030679226, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 344, train_loss = 1.829651283682324, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 345, train_loss = 1.8284955596318468, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 346, train_loss = 1.8263865100452676, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 347, train_loss = 1.824283417314291, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 348, train_loss = 1.8231719806790352, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 349, train_loss = 1.8213739097118378, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 350, train_loss = 1.8191426458070055, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 351, train_loss = 1.817094781785272, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 352, train_loss = 1.8158533299574628, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 353, train_loss = 1.8141198307275772, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 354, train_loss = 1.812125520198606, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 355, train_loss = 1.8109482129802927, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 356, train_loss = 1.8087491728365421, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 357, train_loss = 1.8080959431827068, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 358, train_loss = 1.8055260429391637, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 359, train_loss = 1.8039333187043667, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 360, train_loss = 1.8024868393549696, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 361, train_loss = 1.801058134646155, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 362, train_loss = 1.7987148141255602, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 363, train_loss = 1.7972170697757974, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 364, train_loss = 1.795559668331407, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 365, train_loss = 1.7939813522389159, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 366, train_loss = 1.7924840511986986, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 367, train_loss = 1.7908723565051332, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 368, train_loss = 1.789045449346304, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 369, train_loss = 1.788058234960772, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 370, train_loss = 1.786175193847157, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 371, train_loss = 1.7845591878285632, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 372, train_loss = 1.7831478664884344, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 373, train_loss = 1.7812289372086525, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 374, train_loss = 1.779395996243693, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 375, train_loss = 1.778208214789629, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 376, train_loss = 1.777878907858394, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 377, train_loss = 1.7755113417515531, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 378, train_loss = 1.7741920253029093, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 379, train_loss = 1.7730127200484276, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 380, train_loss = 1.7708017341792583, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 381, train_loss = 1.769420045078732, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 382, train_loss = 1.767448483617045, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 383, train_loss = 1.7670762488851324, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 384, train_loss = 1.7650698473444209, train_acc = 0.9956916627852818\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 385, train_loss = 1.7646737644681707, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 386, train_loss = 1.762158289551735, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 387, train_loss = 1.7613018763950095, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 388, train_loss = 1.7591641632607207, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 389, train_loss = 1.7581450553843752, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 390, train_loss = 1.7570458762347698, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 391, train_loss = 1.7553820833563805, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 392, train_loss = 1.7540496761212125, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 393, train_loss = 1.7526807636022568, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 394, train_loss = 1.7512474419781938, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 395, train_loss = 1.7506446093320847, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 396, train_loss = 1.7485848603537306, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 397, train_loss = 1.7475806759903207, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 398, train_loss = 1.7458377704024315, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 399, train_loss = 1.7450537495315075, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 400, train_loss = 1.7434674067189917, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 401, train_loss = 1.7424030043184757, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 402, train_loss = 1.741401195526123, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 403, train_loss = 1.7399573400616646, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 404, train_loss = 1.7388166673481464, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 405, train_loss = 1.73721642291639, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 406, train_loss = 1.735672552138567, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 407, train_loss = 1.7345402328064665, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 408, train_loss = 1.733411654829979, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 409, train_loss = 1.7324407870182768, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 410, train_loss = 1.730649328441359, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 411, train_loss = 1.729214671999216, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 412, train_loss = 1.7293491078307852, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 413, train_loss = 1.727011644630693, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 414, train_loss = 1.7260700588813052, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 415, train_loss = 1.7250706976046786, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 416, train_loss = 1.7239261927315965, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 417, train_loss = 1.7228245548903942, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 418, train_loss = 1.722159811644815, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 419, train_loss = 1.7203376168617979, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 420, train_loss = 1.719204125343822, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 421, train_loss = 1.7184674913296476, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 422, train_loss = 1.7165955466916785, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 423, train_loss = 1.7161999879172072, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 424, train_loss = 1.7151011750102043, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 425, train_loss = 1.7136737132677808, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 426, train_loss = 1.712251666933298, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 427, train_loss = 1.7111050933599472, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 428, train_loss = 1.7103512771427631, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 429, train_loss = 1.7093160673975945, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 430, train_loss = 1.7073845341801643, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 431, train_loss = 1.7068308716407046, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 432, train_loss = 1.7057429688284174, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 433, train_loss = 1.7045665010809898, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 434, train_loss = 1.7031271122395992, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 435, train_loss = 1.7033468323061243, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 436, train_loss = 1.7014015516033396, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 437, train_loss = 1.7008203068980947, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 438, train_loss = 1.6989496113965288, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 439, train_loss = 1.6982205957174301, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 440, train_loss = 1.696926905424334, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 441, train_loss = 1.6961562596261501, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 442, train_loss = 1.6946210836758837, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 443, train_loss = 1.6939850188791752, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 444, train_loss = 1.693190272897482, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 445, train_loss = 1.6922290349612013, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 446, train_loss = 1.6909566335380077, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 447, train_loss = 1.6896607974776998, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 448, train_loss = 1.6891521997749805, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 449, train_loss = 1.6876268349587917, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 450, train_loss = 1.6870528906583786, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 451, train_loss = 1.6857499046018347, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 452, train_loss = 1.6855335844447836, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 453, train_loss = 1.6841265968978405, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 454, train_loss = 1.682362130493857, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 455, train_loss = 1.682707862346433, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 456, train_loss = 1.6813202040502802, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 457, train_loss = 1.6806192522635683, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 458, train_loss = 1.679399911314249, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 459, train_loss = 1.6783801391720772, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 460, train_loss = 1.6771656014025211, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 461, train_loss = 1.6766698770225048, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 462, train_loss = 1.6749622909119353, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 463, train_loss = 1.675216426490806, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 464, train_loss = 1.6737775342771783, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 465, train_loss = 1.6730631589889526, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 466, train_loss = 1.6719763713190332, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 467, train_loss = 1.6709822863340378, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 468, train_loss = 1.669696775614284, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 469, train_loss = 1.6693820804357529, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 470, train_loss = 1.668324546306394, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 471, train_loss = 1.6676149852573872, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 472, train_loss = 1.6661986410617828, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 473, train_loss = 1.665609904914163, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 474, train_loss = 1.6654678545892239, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 475, train_loss = 1.6642890932271257, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 476, train_loss = 1.662611212581396, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 477, train_loss = 1.6620807076105848, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 478, train_loss = 1.661240310757421, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 479, train_loss = 1.6599327512085438, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 480, train_loss = 1.6596561247715726, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 481, train_loss = 1.658784152357839, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 482, train_loss = 1.657937822281383, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 483, train_loss = 1.6566804560134187, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 484, train_loss = 1.6565831179032102, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 485, train_loss = 1.6552466874709353, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 486, train_loss = 1.654757401556708, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 487, train_loss = 1.6537515198579058, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 488, train_loss = 1.6534302420914173, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 489, train_loss = 1.6519868187606335, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 490, train_loss = 1.6512652970850468, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 491, train_loss = 1.6510361271793954, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 492, train_loss = 1.6496096017654054, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 493, train_loss = 1.6491536225075833, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 494, train_loss = 1.647848176478874, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 495, train_loss = 1.647587388753891, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 496, train_loss = 1.6467848407919519, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 497, train_loss = 1.6457923439447768, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 498, train_loss = 1.6453733506496064, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 499, train_loss = 1.64447708055377, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████████████████████████████████████████████████▎                  | 22/30 [3:19:08<1:12:21, 542.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "23th- epoch: 0, train_loss = 109.25575223565102, train_acc = 0.7898230088495575\n",
      "test Acc 0.8943202979515829:\n",
      "23th- epoch: 1, train_loss = 38.82944169640541, train_acc = 0.9201210992081975\n",
      "test Acc 0.9324953445065177:\n",
      "23th- epoch: 2, train_loss = 29.855571269989014, train_acc = 0.9384024219841639\n",
      "test Acc 0.9450651769087524:\n",
      "23th- epoch: 3, train_loss = 25.114335767924786, train_acc = 0.9487657196087564\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 4, train_loss = 22.092435907572508, train_acc = 0.9537727061015371\n",
      "test Acc 0.9534450651769087:\n",
      "23th- epoch: 5, train_loss = 19.964155431836843, train_acc = 0.9588961341406614\n",
      "test Acc 0.9557728119180633:\n",
      "23th- epoch: 6, train_loss = 18.295323181897402, train_acc = 0.9620400558919422\n",
      "test Acc 0.957635009310987:\n",
      "23th- epoch: 7, train_loss = 16.940123967826366, train_acc = 0.9636702375407545\n",
      "test Acc 0.9585661080074488:\n",
      "23th- epoch: 8, train_loss = 15.815982170403004, train_acc = 0.9664648346530041\n",
      "test Acc 0.9585661080074488:\n",
      "23th- epoch: 9, train_loss = 14.868960529565811, train_acc = 0.9693758733115976\n",
      "test Acc 0.9608938547486033:\n",
      "23th- epoch: 10, train_loss = 14.045565631240606, train_acc = 0.9713553795994411\n",
      "test Acc 0.9613594040968343:\n",
      "23th- epoch: 11, train_loss = 13.32222468405962, train_acc = 0.9729855612482534\n",
      "test Acc 0.9622905027932961:\n",
      "23th- epoch: 12, train_loss = 12.686193782836199, train_acc = 0.9742664182580345\n",
      "test Acc 0.9632216014897579:\n",
      "23th- epoch: 13, train_loss = 12.119919572025537, train_acc = 0.9749650675360969\n",
      "test Acc 0.9646182495344506:\n",
      "23th- epoch: 14, train_loss = 11.615247510373592, train_acc = 0.976245924545878\n",
      "test Acc 0.9646182495344506:\n",
      "23th- epoch: 15, train_loss = 11.15485143661499, train_acc = 0.9772938984629715\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 16, train_loss = 10.738233000040054, train_acc = 0.9786911970190965\n",
      "test Acc 0.9646182495344506:\n",
      "23th- epoch: 17, train_loss = 10.360811453312635, train_acc = 0.97973917093619\n",
      "test Acc 0.9650837988826816:\n",
      "23th- epoch: 18, train_loss = 10.008026849478483, train_acc = 0.9800884955752213\n",
      "test Acc 0.9655493482309124:\n",
      "23th- epoch: 19, train_loss = 9.691936116665602, train_acc = 0.9809035863996274\n",
      "test Acc 0.9674115456238361:\n",
      "23th- epoch: 20, train_loss = 9.396526921540499, train_acc = 0.9812529110386586\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 21, train_loss = 9.121541757136583, train_acc = 0.9816022356776898\n",
      "test Acc 0.9674115456238361:\n",
      "23th- epoch: 22, train_loss = 8.856239521875978, train_acc = 0.9821844434094085\n",
      "test Acc 0.9683426443202979:\n",
      "23th- epoch: 23, train_loss = 8.610364908352494, train_acc = 0.9831159757801584\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 24, train_loss = 8.374864691868424, train_acc = 0.983698183511877\n",
      "test Acc 0.9692737430167597:\n",
      "23th- epoch: 25, train_loss = 8.160943130031228, train_acc = 0.9842803912435957\n",
      "test Acc 0.9692737430167597:\n",
      "23th- epoch: 26, train_loss = 7.96193159930408, train_acc = 0.9848625989753144\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 27, train_loss = 7.77165618352592, train_acc = 0.9853283651606893\n",
      "test Acc 0.9692737430167597:\n",
      "23th- epoch: 28, train_loss = 7.591890020295978, train_acc = 0.9855612482533768\n",
      "test Acc 0.9692737430167597:\n",
      "23th- epoch: 29, train_loss = 7.421172393485904, train_acc = 0.9860270144387517\n",
      "test Acc 0.9692737430167597:\n",
      "23th- epoch: 30, train_loss = 7.257587196305394, train_acc = 0.9862598975314392\n",
      "test Acc 0.9702048417132216:\n",
      "23th- epoch: 31, train_loss = 7.102893406525254, train_acc = 0.9866092221704704\n",
      "test Acc 0.9702048417132216:\n",
      "23th- epoch: 32, train_loss = 6.9564285054802895, train_acc = 0.9868421052631579\n",
      "test Acc 0.9702048417132216:\n",
      "23th- epoch: 33, train_loss = 6.815203618258238, train_acc = 0.9870749883558454\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 34, train_loss = 6.680370908230543, train_acc = 0.9873078714485328\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 35, train_loss = 6.549358168616891, train_acc = 0.9876571960875641\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 36, train_loss = 6.426927337422967, train_acc = 0.9877736376339078\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 37, train_loss = 6.307134496048093, train_acc = 0.9880065207265952\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 38, train_loss = 6.194686019793153, train_acc = 0.9881229622729389\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 39, train_loss = 6.087219895794988, train_acc = 0.9882394038192828\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 40, train_loss = 5.981463730335236, train_acc = 0.9887051700046576\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 41, train_loss = 5.880821820348501, train_acc = 0.9890544946436889\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 42, train_loss = 5.785874431952834, train_acc = 0.9891709361900326\n",
      "test Acc 0.9725325884543762:\n",
      "23th- epoch: 43, train_loss = 5.694429429247975, train_acc = 0.9892873777363763\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 44, train_loss = 5.60565622895956, train_acc = 0.9892873777363763\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 45, train_loss = 5.520296525210142, train_acc = 0.98940381928272\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 46, train_loss = 5.438577056862414, train_acc = 0.9896367023754076\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 47, train_loss = 5.358244813978672, train_acc = 0.9897531439217513\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 48, train_loss = 5.282100643962622, train_acc = 0.9897531439217513\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 49, train_loss = 5.209120248444378, train_acc = 0.9899860270144387\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 50, train_loss = 5.1366440476849675, train_acc = 0.989869585468095\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 51, train_loss = 5.068177450448275, train_acc = 0.989869585468095\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 52, train_loss = 5.001281436532736, train_acc = 0.9899860270144387\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 53, train_loss = 4.938798024319112, train_acc = 0.9902189101071263\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 54, train_loss = 4.8765887236222625, train_acc = 0.9902189101071263\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 55, train_loss = 4.8173012509942055, train_acc = 0.99033535165347\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 56, train_loss = 4.757160830311477, train_acc = 0.9906846762925011\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 57, train_loss = 4.701709204353392, train_acc = 0.990801117838845\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 58, train_loss = 4.645867391489446, train_acc = 0.9910340009315324\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 59, train_loss = 4.59302959125489, train_acc = 0.9910340009315324\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 60, train_loss = 4.539454945363104, train_acc = 0.9911504424778761\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 61, train_loss = 4.486116317100823, train_acc = 0.9914997671169073\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 62, train_loss = 4.43740254919976, train_acc = 0.9916162086632511\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 63, train_loss = 4.39033767208457, train_acc = 0.9917326502095948\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 64, train_loss = 4.344244912266731, train_acc = 0.9917326502095948\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 65, train_loss = 4.300369673408568, train_acc = 0.9917326502095948\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 66, train_loss = 4.257507762871683, train_acc = 0.9919655333022822\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 67, train_loss = 4.2148512760177255, train_acc = 0.992081974848626\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 68, train_loss = 4.174695578403771, train_acc = 0.992081974848626\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 69, train_loss = 4.134791160933673, train_acc = 0.992081974848626\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 70, train_loss = 4.095732399262488, train_acc = 0.9921984163949698\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 71, train_loss = 4.058858796954155, train_acc = 0.9921984163949698\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 72, train_loss = 4.020423120819032, train_acc = 0.9921984163949698\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 73, train_loss = 3.985670288093388, train_acc = 0.9921984163949698\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 74, train_loss = 3.9485901184380054, train_acc = 0.9923148579413135\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 75, train_loss = 3.914267069660127, train_acc = 0.9924312994876572\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 76, train_loss = 3.8807025477290154, train_acc = 0.9925477410340009\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 77, train_loss = 3.8459425354376435, train_acc = 0.9924312994876572\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 78, train_loss = 3.814373909495771, train_acc = 0.9925477410340009\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 79, train_loss = 3.781853803433478, train_acc = 0.9924312994876572\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 80, train_loss = 3.7520794793963432, train_acc = 0.9925477410340009\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 81, train_loss = 3.7211368707939982, train_acc = 0.9925477410340009\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 82, train_loss = 3.6919031282886863, train_acc = 0.9925477410340009\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 83, train_loss = 3.66343567147851, train_acc = 0.9925477410340009\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 84, train_loss = 3.6359527334570885, train_acc = 0.9925477410340009\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 85, train_loss = 3.608090590685606, train_acc = 0.9925477410340009\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 86, train_loss = 3.5811924189329147, train_acc = 0.9925477410340009\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 87, train_loss = 3.554246012121439, train_acc = 0.9925477410340009\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 88, train_loss = 3.5282958685420454, train_acc = 0.9926641825803446\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 89, train_loss = 3.501981357578188, train_acc = 0.9926641825803446\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 90, train_loss = 3.477927715983242, train_acc = 0.9925477410340009\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 91, train_loss = 3.4543195008300245, train_acc = 0.9925477410340009\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 92, train_loss = 3.4284381144680083, train_acc = 0.9926641825803446\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 93, train_loss = 3.4057988189160824, train_acc = 0.9925477410340009\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 94, train_loss = 3.3828378692269325, train_acc = 0.9926641825803446\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 95, train_loss = 3.3611530289053917, train_acc = 0.9925477410340009\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 96, train_loss = 3.3376134843565524, train_acc = 0.9927806241266884\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 97, train_loss = 3.3150696703232825, train_acc = 0.9927806241266884\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 98, train_loss = 3.2955788797698915, train_acc = 0.9927806241266884\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 99, train_loss = 3.2719636210240424, train_acc = 0.9927806241266884\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 100, train_loss = 3.251287456601858, train_acc = 0.9927806241266884\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 101, train_loss = 3.2307476750575006, train_acc = 0.9927806241266884\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 102, train_loss = 3.211322233080864, train_acc = 0.9927806241266884\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 103, train_loss = 3.1917734458111227, train_acc = 0.9928970656730322\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 104, train_loss = 3.1728147477842867, train_acc = 0.9928970656730322\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 105, train_loss = 3.154260357376188, train_acc = 0.9928970656730322\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 106, train_loss = 3.1350718303583562, train_acc = 0.9928970656730322\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 107, train_loss = 3.1173649900592864, train_acc = 0.9927806241266884\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 108, train_loss = 3.0986142703332007, train_acc = 0.9928970656730322\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 109, train_loss = 3.080615812446922, train_acc = 0.9928970656730322\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 110, train_loss = 3.063118444290012, train_acc = 0.9931299487657196\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 111, train_loss = 3.04624060401693, train_acc = 0.9930135072193759\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 112, train_loss = 3.0295506068505347, train_acc = 0.9931299487657196\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 113, train_loss = 3.0124257155694067, train_acc = 0.9931299487657196\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 114, train_loss = 2.9971449957229197, train_acc = 0.9932463903120633\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 115, train_loss = 2.980652380734682, train_acc = 0.9934792734047508\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 116, train_loss = 2.9647731012664735, train_acc = 0.9934792734047508\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 117, train_loss = 2.949243924114853, train_acc = 0.9934792734047508\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 118, train_loss = 2.9333772137761116, train_acc = 0.9934792734047508\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 119, train_loss = 2.918726196978241, train_acc = 0.9934792734047508\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 120, train_loss = 2.9039978929795325, train_acc = 0.9935957149510946\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 121, train_loss = 2.8893480375409126, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 122, train_loss = 2.8747062399052083, train_acc = 0.9937121564974383\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 123, train_loss = 2.8605436771176755, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 124, train_loss = 2.8462226181291044, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 125, train_loss = 2.8325232453644276, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 126, train_loss = 2.8192760036326945, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 127, train_loss = 2.80578251183033, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 128, train_loss = 2.7929302849806845, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 129, train_loss = 2.780118019785732, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 130, train_loss = 2.7673373059369624, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 131, train_loss = 2.75486454507336, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 132, train_loss = 2.7424654164351523, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 133, train_loss = 2.7297633066773415, train_acc = 0.9940614811364695\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 134, train_loss = 2.717987149953842, train_acc = 0.9940614811364695\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 135, train_loss = 2.7061506547033787, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 136, train_loss = 2.694844333920628, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 137, train_loss = 2.683101274073124, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 138, train_loss = 2.6716365925967693, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 139, train_loss = 2.6603780896402895, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 140, train_loss = 2.6496412553824484, train_acc = 0.9944108057755007\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 141, train_loss = 2.6385931693948805, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 142, train_loss = 2.6280766525305808, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 143, train_loss = 2.616467115934938, train_acc = 0.994294364229157\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 144, train_loss = 2.606569044291973, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 145, train_loss = 2.5954295224510133, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 146, train_loss = 2.5856284820474684, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 147, train_loss = 2.5763452700339258, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 148, train_loss = 2.5660915463231504, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 149, train_loss = 2.5560822202824056, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 150, train_loss = 2.5462430850602686, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 151, train_loss = 2.5365845165215433, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 152, train_loss = 2.5267711258493364, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 153, train_loss = 2.5183169059455395, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 154, train_loss = 2.5084218927659094, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 155, train_loss = 2.4996438324451447, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 156, train_loss = 2.4905552924610674, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 157, train_loss = 2.4821599759161472, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 158, train_loss = 2.473369645420462, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 159, train_loss = 2.4658996909856796, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 160, train_loss = 2.4554055803455412, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 161, train_loss = 2.4478884786367416, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 162, train_loss = 2.4395632655359805, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 163, train_loss = 2.431266827043146, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 164, train_loss = 2.424587571527809, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 165, train_loss = 2.4167110957205296, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 166, train_loss = 2.407636712072417, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 167, train_loss = 2.399909358471632, train_acc = 0.9947601304145319\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 168, train_loss = 2.3932940252125263, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 169, train_loss = 2.385986890643835, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 170, train_loss = 2.3771468587219715, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 171, train_loss = 2.3705651077907532, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 172, train_loss = 2.3628871974069625, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 173, train_loss = 2.356018277583644, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 174, train_loss = 2.349021318135783, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 175, train_loss = 2.3424918577075005, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 176, train_loss = 2.335936025949195, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 177, train_loss = 2.3293470356147736, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 178, train_loss = 2.3219752684235573, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 179, train_loss = 2.3149682234507054, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 180, train_loss = 2.3089062261860818, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 181, train_loss = 2.302065797150135, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 182, train_loss = 2.2953625333029777, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 183, train_loss = 2.2891207672655582, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 184, train_loss = 2.282821501372382, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 185, train_loss = 2.277144030900672, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 186, train_loss = 2.270344391465187, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 187, train_loss = 2.2651903331279755, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 188, train_loss = 2.2583220563828945, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 189, train_loss = 2.2533623601775616, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 190, train_loss = 2.247034848900512, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 191, train_loss = 2.241794199915603, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 192, train_loss = 2.2357365179341286, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 193, train_loss = 2.2303079664707184, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 194, train_loss = 2.223904525162652, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 195, train_loss = 2.2194913018029183, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 196, train_loss = 2.2135036115068942, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 197, train_loss = 2.2087641544640064, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 198, train_loss = 2.202769846888259, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 199, train_loss = 2.196885921061039, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 200, train_loss = 2.1920339588541538, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 201, train_loss = 2.1875199761707336, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 202, train_loss = 2.1823199428617954, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 203, train_loss = 2.176213373662904, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 204, train_loss = 2.1712436575908214, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 205, train_loss = 2.167808083118871, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 206, train_loss = 2.1625941086094826, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 207, train_loss = 2.1572223391849548, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 208, train_loss = 2.15274291485548, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 209, train_loss = 2.147346019744873, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 210, train_loss = 2.1432164174038917, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 211, train_loss = 2.13833874091506, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 212, train_loss = 2.133700003148988, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 213, train_loss = 2.129152071895078, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 214, train_loss = 2.1250021520536393, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 215, train_loss = 2.1198431227821857, train_acc = 0.9952258965999069\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 216, train_loss = 2.116139863850549, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 217, train_loss = 2.1114219191949815, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 218, train_loss = 2.1074400085490197, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 219, train_loss = 2.1027369052171707, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 220, train_loss = 2.098255392163992, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 221, train_loss = 2.094988100230694, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 222, train_loss = 2.090092745842412, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 223, train_loss = 2.086040588794276, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 224, train_loss = 2.0826755750458688, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 225, train_loss = 2.078592489240691, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 226, train_loss = 2.0738912995439023, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 227, train_loss = 2.0700633749365807, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 228, train_loss = 2.06720008328557, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 229, train_loss = 2.062888548942283, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 230, train_loss = 2.058596519054845, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 231, train_loss = 2.0551204110961407, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 232, train_loss = 2.0508850999176502, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 233, train_loss = 2.0474033046048135, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 234, train_loss = 2.0434673365671188, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 235, train_loss = 2.039940766990185, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 236, train_loss = 2.036845923634246, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 237, train_loss = 2.0329599902033806, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 238, train_loss = 2.0287705052178353, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 239, train_loss = 2.0254205625969917, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 240, train_loss = 2.0228028807323426, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 241, train_loss = 2.018830716609955, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 242, train_loss = 2.015574385644868, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 243, train_loss = 2.011041444959119, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 244, train_loss = 2.0083716958761215, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 245, train_loss = 2.005592916160822, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 246, train_loss = 2.0023344680666924, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 247, train_loss = 1.9986432392615825, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 248, train_loss = 1.996066064806655, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 249, train_loss = 1.9915268893819302, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 250, train_loss = 1.9887051705736667, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 251, train_loss = 1.986158876447007, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 252, train_loss = 1.9828550294041634, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 253, train_loss = 1.9796760603785515, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 254, train_loss = 1.975985825061798, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 255, train_loss = 1.9733857426326722, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 256, train_loss = 1.9710184819996357, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 257, train_loss = 1.9675004221498966, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 258, train_loss = 1.9644872918725014, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 259, train_loss = 1.9612326670903713, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 260, train_loss = 1.9591490712482482, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 261, train_loss = 1.9556940582115203, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 262, train_loss = 1.9532969656866044, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 263, train_loss = 1.9501272588968277, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 264, train_loss = 1.9472725577652454, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 265, train_loss = 1.9447591330390424, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 266, train_loss = 1.9418082300107926, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 267, train_loss = 1.9388905104715377, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 268, train_loss = 1.9359916150569916, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 269, train_loss = 1.9329319397220388, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 270, train_loss = 1.9304193010320887, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 271, train_loss = 1.9278725137701258, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 272, train_loss = 1.9250525012612343, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 273, train_loss = 1.9227718996116892, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 274, train_loss = 1.920119529007934, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 275, train_loss = 1.9178871624171734, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 276, train_loss = 1.915164521546103, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 277, train_loss = 1.9129013965139166, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 278, train_loss = 1.9098799787461758, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 279, train_loss = 1.9070711322128773, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 280, train_loss = 1.9049505852162838, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 281, train_loss = 1.9023740105330944, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 282, train_loss = 1.8996024107327685, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 283, train_loss = 1.8976558769354597, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 284, train_loss = 1.8946401663124561, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 285, train_loss = 1.8926010156283155, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 286, train_loss = 1.8899894244968891, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 287, train_loss = 1.8878421150147915, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 288, train_loss = 1.8854933691909537, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 289, train_loss = 1.8829909712076187, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 290, train_loss = 1.8808955351123586, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 291, train_loss = 1.87850047275424, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 292, train_loss = 1.87667803093791, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 293, train_loss = 1.8742744997143745, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 294, train_loss = 1.87179436290171, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 295, train_loss = 1.8696949208388105, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 296, train_loss = 1.8675157862016931, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 297, train_loss = 1.8657194724073634, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 298, train_loss = 1.8633802197873592, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 299, train_loss = 1.8613786734640598, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 300, train_loss = 1.8590337919304147, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 301, train_loss = 1.8568451404571533, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 302, train_loss = 1.854660471319221, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 303, train_loss = 1.8525945817818865, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 304, train_loss = 1.8508565364172682, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 305, train_loss = 1.8487609662115574, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 306, train_loss = 1.846816142438911, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 307, train_loss = 1.8445988235762343, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 308, train_loss = 1.8425625873496756, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 309, train_loss = 1.8403364544501528, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 310, train_loss = 1.8384242244064808, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 311, train_loss = 1.8367900177836418, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 312, train_loss = 1.8349361108848825, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 313, train_loss = 1.8322869004914537, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 314, train_loss = 1.8309740101685748, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 315, train_loss = 1.829170306562446, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 316, train_loss = 1.8268379321089014, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 317, train_loss = 1.8251572152366862, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 318, train_loss = 1.8232420968124643, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 319, train_loss = 1.8215062618255615, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 320, train_loss = 1.8196192806353793, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 321, train_loss = 1.8174776770174503, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 322, train_loss = 1.816147324978374, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 323, train_loss = 1.8138421401381493, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 324, train_loss = 1.8123811992118135, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 325, train_loss = 1.8102649276843295, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 326, train_loss = 1.8085324739804491, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 327, train_loss = 1.8070604266831651, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 328, train_loss = 1.8051816808292642, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 329, train_loss = 1.8038818886270747, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 330, train_loss = 1.8017514297971502, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 331, train_loss = 1.8001130843767896, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 332, train_loss = 1.7975064540514722, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 333, train_loss = 1.7972672817995772, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 334, train_loss = 1.7952623218297958, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 335, train_loss = 1.7933448752155527, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 336, train_loss = 1.7916381793329492, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 337, train_loss = 1.7898833826184273, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 338, train_loss = 1.788296633749269, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 339, train_loss = 1.7869898354401812, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 340, train_loss = 1.7857575453817844, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 341, train_loss = 1.7834943694761023, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 342, train_loss = 1.7818582890322432, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 343, train_loss = 1.780466739088297, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 344, train_loss = 1.7790438048541546, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 345, train_loss = 1.7773088639369234, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 346, train_loss = 1.7752963552484289, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 347, train_loss = 1.7744815772166476, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 348, train_loss = 1.7725891856243834, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 349, train_loss = 1.7707457566866651, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 350, train_loss = 1.770012671709992, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 351, train_loss = 1.7682931572198868, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 352, train_loss = 1.7667973762145266, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 353, train_loss = 1.765118824900128, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 354, train_loss = 1.7636963116237894, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 355, train_loss = 1.7622154131531715, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 356, train_loss = 1.7602747628698125, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 357, train_loss = 1.759393877000548, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 358, train_loss = 1.757381214410998, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 359, train_loss = 1.7562552690505981, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 360, train_loss = 1.7550155023345724, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 361, train_loss = 1.7538857497274876, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 362, train_loss = 1.752177013666369, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 363, train_loss = 1.7506126662483439, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 364, train_loss = 1.7492273822426796, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 365, train_loss = 1.7483969604363665, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 366, train_loss = 1.7466902919113636, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 367, train_loss = 1.7454998207977042, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 368, train_loss = 1.7441098801791668, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 369, train_loss = 1.7428615601966158, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 370, train_loss = 1.7416069334140047, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 371, train_loss = 1.7397657273104414, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 372, train_loss = 1.738261686055921, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 373, train_loss = 1.7371281633386388, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 374, train_loss = 1.7359308762243018, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 375, train_loss = 1.7351395388832316, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 376, train_loss = 1.7336229780921713, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 377, train_loss = 1.7321751825511456, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 378, train_loss = 1.7307342489948496, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 379, train_loss = 1.7297628285596147, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 380, train_loss = 1.7278427308192477, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 381, train_loss = 1.7273894859245047, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 382, train_loss = 1.7257775577018037, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 383, train_loss = 1.7245619148015976, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 384, train_loss = 1.72310383990407, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 385, train_loss = 1.7220618352293968, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 386, train_loss = 1.7212345401057974, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 387, train_loss = 1.7196542732417583, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 388, train_loss = 1.7186287058284506, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 389, train_loss = 1.717371835024096, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 390, train_loss = 1.716425913036801, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 391, train_loss = 1.7154113464057446, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 392, train_loss = 1.714012754498981, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 393, train_loss = 1.712672029971145, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 394, train_loss = 1.7113777684280649, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 395, train_loss = 1.7104255110025406, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 396, train_loss = 1.7094260765006766, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 397, train_loss = 1.708422044874169, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 398, train_loss = 1.7070497311651707, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 399, train_loss = 1.7057445893296972, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 400, train_loss = 1.7053319873521104, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 401, train_loss = 1.7039939140668139, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 402, train_loss = 1.702331984997727, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 403, train_loss = 1.7021849801531062, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 404, train_loss = 1.7006771130254492, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 405, train_loss = 1.6994372867047787, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 406, train_loss = 1.6985920356819406, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 407, train_loss = 1.6973269792506471, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 408, train_loss = 1.6965624131262302, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 409, train_loss = 1.6954604847123846, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 410, train_loss = 1.6944647071650252, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 411, train_loss = 1.6930744908750057, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 412, train_loss = 1.6919229390332475, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 413, train_loss = 1.6913878755876794, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 414, train_loss = 1.689838164835237, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 415, train_loss = 1.6888843948836438, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 416, train_loss = 1.6884081599419005, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 417, train_loss = 1.6874546433100477, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 418, train_loss = 1.6860225697164424, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 419, train_loss = 1.6849643041496165, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 420, train_loss = 1.6842008717358112, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 421, train_loss = 1.6835963602061383, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 422, train_loss = 1.682221346825827, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 423, train_loss = 1.6808929828112014, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 424, train_loss = 1.6802650007302873, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 425, train_loss = 1.679561988741625, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 426, train_loss = 1.6780746628646739, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 427, train_loss = 1.6772321052849293, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 428, train_loss = 1.676280555606354, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 429, train_loss = 1.675704921304714, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 430, train_loss = 1.6741517446935177, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 431, train_loss = 1.673555867106188, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 432, train_loss = 1.6728050236706622, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 433, train_loss = 1.6716373239760287, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 434, train_loss = 1.671178465068806, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 435, train_loss = 1.6697327457368374, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 436, train_loss = 1.66874524083687, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 437, train_loss = 1.6682726952130906, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 438, train_loss = 1.6673787012696266, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 439, train_loss = 1.66647918272065, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 440, train_loss = 1.6656737588346004, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 441, train_loss = 1.6646700948476791, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 442, train_loss = 1.6636148926918395, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 443, train_loss = 1.66292404133128, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 444, train_loss = 1.6618044252390973, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 445, train_loss = 1.6616344600915909, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 446, train_loss = 1.6605744386906736, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 447, train_loss = 1.6591839988832362, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 448, train_loss = 1.6591676485841163, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 449, train_loss = 1.657645344734192, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 450, train_loss = 1.6569979998166673, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 451, train_loss = 1.656356240331661, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 452, train_loss = 1.655612704635132, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 453, train_loss = 1.6542838613386266, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 454, train_loss = 1.6536351603572257, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 455, train_loss = 1.6525401771068573, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 456, train_loss = 1.6524140586261638, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 457, train_loss = 1.6512040346860886, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 458, train_loss = 1.6499893355066888, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 459, train_loss = 1.6496493431623094, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 460, train_loss = 1.648877814412117, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 461, train_loss = 1.6483173693413846, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 462, train_loss = 1.6474390837247483, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 463, train_loss = 1.6465349930222146, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 464, train_loss = 1.6458204264636151, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 465, train_loss = 1.6450485115055926, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 466, train_loss = 1.6441750426893122, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 467, train_loss = 1.6433657333254814, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 468, train_loss = 1.6425894064013846, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 469, train_loss = 1.641704807698261, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 470, train_loss = 1.6414824376697652, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 471, train_loss = 1.6402073626522906, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 472, train_loss = 1.6399344727396965, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 473, train_loss = 1.6391017523710616, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 474, train_loss = 1.63793969276594, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 475, train_loss = 1.637583586096298, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 476, train_loss = 1.6364398461882956, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 477, train_loss = 1.636127085715998, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 478, train_loss = 1.6354533496196382, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 479, train_loss = 1.6343470786814578, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 480, train_loss = 1.6336956185405143, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 481, train_loss = 1.6331261495943181, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 482, train_loss = 1.6326996646821499, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 483, train_loss = 1.6313384038512595, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 484, train_loss = 1.631212342530489, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 485, train_loss = 1.6306244432926178, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 486, train_loss = 1.62956004840089, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 487, train_loss = 1.6287949706311338, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 488, train_loss = 1.6282154197688214, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 489, train_loss = 1.6278976475005038, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 490, train_loss = 1.6267258723382838, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 491, train_loss = 1.6261678151786327, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 492, train_loss = 1.6255709491670132, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 493, train_loss = 1.625047488778364, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 494, train_loss = 1.6237211053376086, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 495, train_loss = 1.6236660716240294, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 496, train_loss = 1.6226045812363736, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 497, train_loss = 1.6223010867834091, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 498, train_loss = 1.6213668684358709, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 499, train_loss = 1.6206221704487689, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████▋                | 23/30 [3:28:12<1:03:22, 543.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "24th- epoch: 0, train_loss = 115.67594040930271, train_acc = 0.7980903586399627\n",
      "test Acc 0.8803538175046555:\n",
      "24th- epoch: 1, train_loss = 41.58495197445154, train_acc = 0.9155798789007918\n",
      "test Acc 0.9264432029795159:\n",
      "24th- epoch: 2, train_loss = 32.41995342820883, train_acc = 0.9351420586865393\n",
      "test Acc 0.9385474860335196:\n",
      "24th- epoch: 3, train_loss = 27.419733971357346, train_acc = 0.9450395901257569\n",
      "test Acc 0.9422718808193669:\n",
      "24th- epoch: 4, train_loss = 24.178152836859226, train_acc = 0.9513274336283186\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 5, train_loss = 21.803983449935913, train_acc = 0.9563344201210993\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 6, train_loss = 19.94301875308156, train_acc = 0.9598276665114113\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 7, train_loss = 18.431148938834667, train_acc = 0.9633209129017233\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 8, train_loss = 17.192236602306366, train_acc = 0.965649743828598\n",
      "test Acc 0.952513966480447:\n",
      "24th- epoch: 9, train_loss = 16.1413506641984, train_acc = 0.9673963670237541\n",
      "test Acc 0.9539106145251397:\n",
      "24th- epoch: 10, train_loss = 15.233803067356348, train_acc = 0.969608756404285\n",
      "test Acc 0.9543761638733705:\n",
      "24th- epoch: 11, train_loss = 14.444592822343111, train_acc = 0.9704238472286912\n",
      "test Acc 0.9548417132216015:\n",
      "24th- epoch: 12, train_loss = 13.757245507091284, train_acc = 0.9711224965067536\n",
      "test Acc 0.9567039106145251:\n",
      "24th- epoch: 13, train_loss = 13.141115428879857, train_acc = 0.9731020027945971\n",
      "test Acc 0.9567039106145251:\n",
      "24th- epoch: 14, train_loss = 12.596568696200848, train_acc = 0.9738006520726595\n",
      "test Acc 0.9585661080074488:\n",
      "24th- epoch: 15, train_loss = 12.107654171064496, train_acc = 0.9750815090824406\n",
      "test Acc 0.9594972067039106:\n",
      "24th- epoch: 16, train_loss = 11.652435261756182, train_acc = 0.9756637168141593\n",
      "test Acc 0.9604283054003724:\n",
      "24th- epoch: 17, train_loss = 11.247812107205391, train_acc = 0.9763623660922217\n",
      "test Acc 0.9608938547486033:\n",
      "24th- epoch: 18, train_loss = 10.866719175130129, train_acc = 0.9767116907312529\n",
      "test Acc 0.9608938547486033:\n",
      "24th- epoch: 19, train_loss = 10.514562463387847, train_acc = 0.9770610153702841\n",
      "test Acc 0.9622905027932961:\n",
      "24th- epoch: 20, train_loss = 10.186578232795, train_acc = 0.9781089892873778\n",
      "test Acc 0.9622905027932961:\n",
      "24th- epoch: 21, train_loss = 9.875460959970951, train_acc = 0.9785747554727526\n",
      "test Acc 0.9636871508379888:\n",
      "24th- epoch: 22, train_loss = 9.584594374522567, train_acc = 0.9790405216581276\n",
      "test Acc 0.9636871508379888:\n",
      "24th- epoch: 23, train_loss = 9.306164687499404, train_acc = 0.9790405216581276\n",
      "test Acc 0.9650837988826816:\n",
      "24th- epoch: 24, train_loss = 9.042562123388052, train_acc = 0.9800884955752213\n",
      "test Acc 0.9655493482309124:\n",
      "24th- epoch: 25, train_loss = 8.794664554297924, train_acc = 0.9803213786679087\n",
      "test Acc 0.9650837988826816:\n",
      "24th- epoch: 26, train_loss = 8.567818719893694, train_acc = 0.9809035863996274\n",
      "test Acc 0.9650837988826816:\n",
      "24th- epoch: 27, train_loss = 8.353184912353754, train_acc = 0.9811364694923148\n",
      "test Acc 0.9664804469273743:\n",
      "24th- epoch: 28, train_loss = 8.154641015455127, train_acc = 0.9814857941313461\n",
      "test Acc 0.9669459962756052:\n",
      "24th- epoch: 29, train_loss = 7.96133148483932, train_acc = 0.981951560316721\n",
      "test Acc 0.9678770949720671:\n",
      "24th- epoch: 30, train_loss = 7.776592703536153, train_acc = 0.9825337680484397\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 31, train_loss = 7.601259853690863, train_acc = 0.9829995342338146\n",
      "test Acc 0.9678770949720671:\n",
      "24th- epoch: 32, train_loss = 7.4389268178492785, train_acc = 0.983698183511877\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 33, train_loss = 7.2823861464858055, train_acc = 0.9840475081509082\n",
      "test Acc 0.9678770949720671:\n",
      "24th- epoch: 34, train_loss = 7.130890494212508, train_acc = 0.9842803912435957\n",
      "test Acc 0.9678770949720671:\n",
      "24th- epoch: 35, train_loss = 6.990757694467902, train_acc = 0.9843968327899395\n",
      "test Acc 0.9678770949720671:\n",
      "24th- epoch: 36, train_loss = 6.853155188262463, train_acc = 0.9848625989753144\n",
      "test Acc 0.9683426443202979:\n",
      "24th- epoch: 37, train_loss = 6.720791084691882, train_acc = 0.9856776897997206\n",
      "test Acc 0.9683426443202979:\n",
      "24th- epoch: 38, train_loss = 6.597830856218934, train_acc = 0.9860270144387517\n",
      "test Acc 0.9683426443202979:\n",
      "24th- epoch: 39, train_loss = 6.4805225152522326, train_acc = 0.986376339077783\n",
      "test Acc 0.9683426443202979:\n",
      "24th- epoch: 40, train_loss = 6.3645230159163475, train_acc = 0.9868421052631579\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 41, train_loss = 6.253204824402928, train_acc = 0.9870749883558454\n",
      "test Acc 0.9683426443202979:\n",
      "24th- epoch: 42, train_loss = 6.1510828752070665, train_acc = 0.9871914299021891\n",
      "test Acc 0.9683426443202979:\n",
      "24th- epoch: 43, train_loss = 6.044322079047561, train_acc = 0.9871914299021891\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 44, train_loss = 5.9503997806459665, train_acc = 0.9873078714485328\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 45, train_loss = 5.8538631442934275, train_acc = 0.9876571960875641\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 46, train_loss = 5.764731770381331, train_acc = 0.9881229622729389\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 47, train_loss = 5.677383350208402, train_acc = 0.9883558453656265\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 48, train_loss = 5.595415772870183, train_acc = 0.9885887284583139\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 49, train_loss = 5.513185957446694, train_acc = 0.9891709361900326\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 50, train_loss = 5.434699071571231, train_acc = 0.98940381928272\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 51, train_loss = 5.360217331908643, train_acc = 0.9895202608290639\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 52, train_loss = 5.286287768743932, train_acc = 0.9896367023754076\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 53, train_loss = 5.214764416217804, train_acc = 0.9897531439217513\n",
      "test Acc 0.9711359404096834:\n",
      "24th- epoch: 54, train_loss = 5.147763061337173, train_acc = 0.9901024685607824\n",
      "test Acc 0.9711359404096834:\n",
      "24th- epoch: 55, train_loss = 5.0827756524086, train_acc = 0.9904517931998137\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 56, train_loss = 5.019275852479041, train_acc = 0.9904517931998137\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 57, train_loss = 4.951957513578236, train_acc = 0.9904517931998137\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 58, train_loss = 4.897090446203947, train_acc = 0.9902189101071263\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 59, train_loss = 4.833797320723534, train_acc = 0.9904517931998137\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 60, train_loss = 4.775974164716899, train_acc = 0.9904517931998137\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 61, train_loss = 4.723002544604242, train_acc = 0.9906846762925011\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 62, train_loss = 4.668849431909621, train_acc = 0.9910340009315324\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 63, train_loss = 4.613561280071735, train_acc = 0.9910340009315324\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 64, train_loss = 4.566522286273539, train_acc = 0.9910340009315324\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 65, train_loss = 4.515990420244634, train_acc = 0.9911504424778761\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 66, train_loss = 4.466722751967609, train_acc = 0.9912668840242198\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 67, train_loss = 4.420046873390675, train_acc = 0.9916162086632511\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 68, train_loss = 4.379448618739843, train_acc = 0.9914997671169073\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 69, train_loss = 4.333192393183708, train_acc = 0.9919655333022822\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 70, train_loss = 4.290194717235863, train_acc = 0.9919655333022822\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 71, train_loss = 4.242614998482168, train_acc = 0.992081974848626\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 72, train_loss = 4.200773089192808, train_acc = 0.9923148579413135\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 73, train_loss = 4.157277467660606, train_acc = 0.9921984163949698\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 74, train_loss = 4.12032254319638, train_acc = 0.9921984163949698\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 75, train_loss = 4.081069017760456, train_acc = 0.9923148579413135\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 76, train_loss = 4.0431828908622265, train_acc = 0.9923148579413135\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 77, train_loss = 4.006637931801379, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 78, train_loss = 3.968524939380586, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 79, train_loss = 3.9359060311689973, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 80, train_loss = 3.9062318289652467, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 81, train_loss = 3.8745244182646275, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 82, train_loss = 3.8386605754494667, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 83, train_loss = 3.8079872503876686, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 84, train_loss = 3.779364195652306, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 85, train_loss = 3.7480120649561286, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 86, train_loss = 3.719770302064717, train_acc = 0.9932463903120633\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 87, train_loss = 3.6921904059126973, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 88, train_loss = 3.664099928922951, train_acc = 0.9932463903120633\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 89, train_loss = 3.635574348270893, train_acc = 0.9932463903120633\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 90, train_loss = 3.610326205380261, train_acc = 0.9933628318584071\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 91, train_loss = 3.5831299871206284, train_acc = 0.9933628318584071\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 92, train_loss = 3.5567603884264827, train_acc = 0.9933628318584071\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 93, train_loss = 3.5340375686064363, train_acc = 0.9934792734047508\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 94, train_loss = 3.5062363147735596, train_acc = 0.9934792734047508\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 95, train_loss = 3.4835565807297826, train_acc = 0.9934792734047508\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 96, train_loss = 3.46222132910043, train_acc = 0.9934792734047508\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 97, train_loss = 3.4387222304940224, train_acc = 0.9934792734047508\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 98, train_loss = 3.4153693141415715, train_acc = 0.9934792734047508\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 99, train_loss = 3.3929822416976094, train_acc = 0.9934792734047508\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 100, train_loss = 3.371915644966066, train_acc = 0.9934792734047508\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 101, train_loss = 3.35042021330446, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 102, train_loss = 3.330192788504064, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 103, train_loss = 3.310254029929638, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 104, train_loss = 3.2890667729079723, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 105, train_loss = 3.269128172658384, train_acc = 0.993828598043782\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 106, train_loss = 3.24940596614033, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 107, train_loss = 3.230721388012171, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 108, train_loss = 3.2119046598672867, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 109, train_loss = 3.193196422420442, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 110, train_loss = 3.1742407740093768, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 111, train_loss = 3.157543511595577, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 112, train_loss = 3.1403935528360307, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 113, train_loss = 3.123285790439695, train_acc = 0.9939450395901258\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 114, train_loss = 3.105691486503929, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 115, train_loss = 3.0886745960451663, train_acc = 0.9939450395901258\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 116, train_loss = 3.0706904367543757, train_acc = 0.9940614811364695\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 117, train_loss = 3.0562451756559312, train_acc = 0.9940614811364695\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 118, train_loss = 3.039296668022871, train_acc = 0.9940614811364695\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 119, train_loss = 3.0236051068641245, train_acc = 0.9940614811364695\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 120, train_loss = 3.010394239332527, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 121, train_loss = 2.9942582272924483, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 122, train_loss = 2.9789738743565977, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 123, train_loss = 2.9656741432845592, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 124, train_loss = 2.950111374258995, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 125, train_loss = 2.9366508163511753, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 126, train_loss = 2.9215242019854486, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 127, train_loss = 2.9078926160000265, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 128, train_loss = 2.893697775900364, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 129, train_loss = 2.8800050816498697, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 130, train_loss = 2.8684933171607554, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 131, train_loss = 2.8535381122492254, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 132, train_loss = 2.841587085276842, train_acc = 0.994294364229157\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 133, train_loss = 2.829334232956171, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 134, train_loss = 2.8152751312591136, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 135, train_loss = 2.8032961636781693, train_acc = 0.994294364229157\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 136, train_loss = 2.7913775271736085, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 137, train_loss = 2.781096337828785, train_acc = 0.9944108057755007\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 138, train_loss = 2.766369044780731, train_acc = 0.994294364229157\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 139, train_loss = 2.758127307984978, train_acc = 0.9944108057755007\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 140, train_loss = 2.746107561979443, train_acc = 0.9944108057755007\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 141, train_loss = 2.7339436784386635, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 142, train_loss = 2.723962686955929, train_acc = 0.994294364229157\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 143, train_loss = 2.712825904134661, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 144, train_loss = 2.702246814966202, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 145, train_loss = 2.688576329499483, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 146, train_loss = 2.6793954796157777, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 147, train_loss = 2.670158388558775, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 148, train_loss = 2.6599581777118146, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 149, train_loss = 2.6499984660185874, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 150, train_loss = 2.6400739825330675, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 151, train_loss = 2.628752063959837, train_acc = 0.994294364229157\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 152, train_loss = 2.6208623819984496, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 153, train_loss = 2.6118332147598267, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 154, train_loss = 2.6018829247914255, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 155, train_loss = 2.5931173129938543, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 156, train_loss = 2.5845146365463734, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 157, train_loss = 2.5745482444763184, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 158, train_loss = 2.5654582022689283, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 159, train_loss = 2.555431465152651, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 160, train_loss = 2.547708135098219, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 161, train_loss = 2.5379466600716114, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 162, train_loss = 2.530168758239597, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 163, train_loss = 2.5221759737469256, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 164, train_loss = 2.5130549110472202, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 165, train_loss = 2.5054690898396075, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 166, train_loss = 2.4966817745007575, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 167, train_loss = 2.48955025523901, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 168, train_loss = 2.482750804629177, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 169, train_loss = 2.4736949019134045, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 170, train_loss = 2.466129157692194, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 171, train_loss = 2.460183784365654, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 172, train_loss = 2.450633385684341, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 173, train_loss = 2.444938053842634, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 174, train_loss = 2.4364486425183713, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 175, train_loss = 2.4287105412222445, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 176, train_loss = 2.4224942922592163, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 177, train_loss = 2.414577639196068, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 178, train_loss = 2.409275148063898, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 179, train_loss = 2.4020441249012947, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 180, train_loss = 2.394938603043556, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 181, train_loss = 2.3873728825710714, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 182, train_loss = 2.3804975650273263, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 183, train_loss = 2.373677851166576, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 184, train_loss = 2.3673369586467743, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 185, train_loss = 2.3621271909214556, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 186, train_loss = 2.355991445481777, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 187, train_loss = 2.3498562672175467, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 188, train_loss = 2.342248313128948, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 189, train_loss = 2.336935833096504, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 190, train_loss = 2.3305798531509936, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 191, train_loss = 2.3236438841558993, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 192, train_loss = 2.319453307893127, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 193, train_loss = 2.313154596835375, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 194, train_loss = 2.3062805659137666, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 195, train_loss = 2.301712289452553, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 196, train_loss = 2.296107812318951, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 197, train_loss = 2.29149896139279, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 198, train_loss = 2.2840620218776166, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 199, train_loss = 2.277980276849121, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 200, train_loss = 2.2745890780352056, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 201, train_loss = 2.267820868641138, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 202, train_loss = 2.264141204301268, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 203, train_loss = 2.2573935291729867, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 204, train_loss = 2.251588559243828, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 205, train_loss = 2.246073062065989, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 206, train_loss = 2.242252400610596, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 207, train_loss = 2.238594291266054, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 208, train_loss = 2.2321023964323103, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 209, train_loss = 2.228642476256937, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 210, train_loss = 2.22139702597633, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 211, train_loss = 2.2177435643970966, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 212, train_loss = 2.212398561183363, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 213, train_loss = 2.20830013230443, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 214, train_loss = 2.204093426465988, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 215, train_loss = 2.199686268810183, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 216, train_loss = 2.193710201885551, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 217, train_loss = 2.188927698880434, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 218, train_loss = 2.1843972727656364, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 219, train_loss = 2.179864751873538, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 220, train_loss = 2.1768857799470425, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 221, train_loss = 2.1708259123843163, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 222, train_loss = 2.1681594774127007, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 223, train_loss = 2.164306639460847, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 224, train_loss = 2.160008693812415, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 225, train_loss = 2.1566234652418643, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 226, train_loss = 2.1491756588220596, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 227, train_loss = 2.147672625957057, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 228, train_loss = 2.141812368063256, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 229, train_loss = 2.137924135895446, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 230, train_loss = 2.1349318760912865, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 231, train_loss = 2.1299355663359165, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 232, train_loss = 2.1256530929822475, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 233, train_loss = 2.1227525162976235, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 234, train_loss = 2.1193468261044472, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 235, train_loss = 2.113673997344449, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 236, train_loss = 2.112782330485061, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 237, train_loss = 2.109986449358985, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 238, train_loss = 2.1024027541279793, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 239, train_loss = 2.100607519270852, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 240, train_loss = 2.097568879602477, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 241, train_loss = 2.0948915432672948, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 242, train_loss = 2.090421425877139, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 243, train_loss = 2.0883144077379256, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 244, train_loss = 2.083693378837779, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 245, train_loss = 2.079948208061978, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 246, train_loss = 2.07670537638478, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 247, train_loss = 2.0743120908737183, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 248, train_loss = 2.0705865274649113, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 249, train_loss = 2.0652877539396286, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 250, train_loss = 2.0627878953237087, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 251, train_loss = 2.058861921308562, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 252, train_loss = 2.056245221523568, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 253, train_loss = 2.05099955573678, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 254, train_loss = 2.04808097705245, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 255, train_loss = 2.046746841398999, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 256, train_loss = 2.044288081349805, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 257, train_loss = 2.039207961410284, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 258, train_loss = 2.0342491555493325, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 259, train_loss = 2.0324492889922112, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 260, train_loss = 2.030491777928546, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 261, train_loss = 2.0267632219474763, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 262, train_loss = 2.025181698380038, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 263, train_loss = 2.019608687609434, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 264, train_loss = 2.0180006611626595, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 265, train_loss = 2.0147018507122993, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 266, train_loss = 2.012050458462909, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 267, train_loss = 2.00745743396692, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 268, train_loss = 2.0054352942388505, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 269, train_loss = 2.003342668293044, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 270, train_loss = 1.9989728059154004, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 271, train_loss = 1.9965431690216064, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 272, train_loss = 1.9955670002382249, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 273, train_loss = 1.9917976919095963, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 274, train_loss = 1.9912860232871026, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 275, train_loss = 1.9884279817342758, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 276, train_loss = 1.9840370255988091, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 277, train_loss = 1.9825684179086238, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 278, train_loss = 1.9787164579611272, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 279, train_loss = 1.9765590317547321, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 280, train_loss = 1.9747348751407117, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 281, train_loss = 1.9720098723191768, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 282, train_loss = 1.9694273509085178, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 283, train_loss = 1.9670051981229335, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 284, train_loss = 1.9646954846102744, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 285, train_loss = 1.9603921186644584, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 286, train_loss = 1.9588460277300328, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 287, train_loss = 1.9561414159834385, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 288, train_loss = 1.9547447476070374, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 289, train_loss = 1.949556615203619, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 290, train_loss = 1.948614601045847, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 291, train_loss = 1.9475860458333045, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 292, train_loss = 1.9427257452625781, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 293, train_loss = 1.9416402529459447, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 294, train_loss = 1.9393752452451736, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 295, train_loss = 1.9375120352488011, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 296, train_loss = 1.934870906174183, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 297, train_loss = 1.932315896032378, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 298, train_loss = 1.9308877040166408, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 299, train_loss = 1.9269985891878605, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 300, train_loss = 1.9261521324515343, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 301, train_loss = 1.9239712941925973, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 302, train_loss = 1.9199030336458236, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 303, train_loss = 1.9201062868814915, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 304, train_loss = 1.9185250599402934, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 305, train_loss = 1.9148280210793018, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 306, train_loss = 1.9142592947464436, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 307, train_loss = 1.909680386306718, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 308, train_loss = 1.908921393333003, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 309, train_loss = 1.9050148117821664, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 310, train_loss = 1.9043953467626125, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 311, train_loss = 1.9007354378700256, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 312, train_loss = 1.8998290349263698, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 313, train_loss = 1.8974791541695595, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 314, train_loss = 1.8971250529866666, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 315, train_loss = 1.8938683073502034, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 316, train_loss = 1.8903538051526994, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 317, train_loss = 1.8898584533017129, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 318, train_loss = 1.8883957664947957, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 319, train_loss = 1.8859771862626076, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 320, train_loss = 1.8847767934203148, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 321, train_loss = 1.8818703156430274, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 322, train_loss = 1.8807792763691396, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 323, train_loss = 1.8797433401923627, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 324, train_loss = 1.8774935516994447, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 325, train_loss = 1.8773523692507297, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 326, train_loss = 1.8753823761362582, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 327, train_loss = 1.873143820790574, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 328, train_loss = 1.8697685115039349, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 329, train_loss = 1.8680968706030399, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 330, train_loss = 1.8668676316738129, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 331, train_loss = 1.8639079183340073, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 332, train_loss = 1.8627812068443745, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 333, train_loss = 1.8601031142752618, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 334, train_loss = 1.8590219814796, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 335, train_loss = 1.8572175689041615, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 336, train_loss = 1.85567173990421, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 337, train_loss = 1.854705133708194, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 338, train_loss = 1.8526397731620818, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 339, train_loss = 1.8523664872627705, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 340, train_loss = 1.849238323746249, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 341, train_loss = 1.8487140710931271, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 342, train_loss = 1.8459803548175842, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 343, train_loss = 1.8436302717309445, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 344, train_loss = 1.8425823014695197, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 345, train_loss = 1.840186469256878, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 346, train_loss = 1.8394381639081985, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 347, train_loss = 1.837413739413023, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 348, train_loss = 1.8355822388548404, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 349, train_loss = 1.8339156520087272, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 350, train_loss = 1.8307959537487477, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 351, train_loss = 1.8304851588327438, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 352, train_loss = 1.8271082241553813, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 353, train_loss = 1.830337465973571, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 354, train_loss = 1.8260183732490987, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 355, train_loss = 1.82344264164567, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 356, train_loss = 1.823970979778096, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 357, train_loss = 1.8226073037367314, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 358, train_loss = 1.8224326074123383, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 359, train_loss = 1.81925209867768, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 360, train_loss = 1.8185021094977856, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 361, train_loss = 1.8160592231433839, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 362, train_loss = 1.8160852764267474, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 363, train_loss = 1.813573730411008, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 364, train_loss = 1.812554602860473, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 365, train_loss = 1.809348894865252, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 366, train_loss = 1.8079510604729876, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 367, train_loss = 1.8076804602751508, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 368, train_loss = 1.8064439097652212, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 369, train_loss = 1.805703961639665, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 370, train_loss = 1.8041228167712688, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 371, train_loss = 1.8033627793192863, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 372, train_loss = 1.8017570227384567, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 373, train_loss = 1.8001057641813532, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 374, train_loss = 1.7989483773708344, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 375, train_loss = 1.7974348118295893, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 376, train_loss = 1.796677641570568, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 377, train_loss = 1.7950142361223698, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 378, train_loss = 1.7936206869781017, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 379, train_loss = 1.7943689785897732, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 380, train_loss = 1.79201841854956, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 381, train_loss = 1.7912659695139155, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 382, train_loss = 1.7886357431998476, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 383, train_loss = 1.7889443250605837, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 384, train_loss = 1.7874268591403961, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 385, train_loss = 1.7860138155519962, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 386, train_loss = 1.7840138027677312, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 387, train_loss = 1.780606216401793, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 388, train_loss = 1.780959920375608, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 389, train_loss = 1.7797500217566267, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 390, train_loss = 1.7807323361048475, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 391, train_loss = 1.7788011928787455, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 392, train_loss = 1.7775410922477022, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 393, train_loss = 1.7744565680623055, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 394, train_loss = 1.7736159363994375, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 395, train_loss = 1.7724169716238976, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 396, train_loss = 1.7723444662988186, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 397, train_loss = 1.770911380648613, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 398, train_loss = 1.7687046279897913, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 399, train_loss = 1.7670978208770975, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 400, train_loss = 1.765672785579227, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 401, train_loss = 1.7655518427491188, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 402, train_loss = 1.763164988369681, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 403, train_loss = 1.7651359798619524, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 404, train_loss = 1.760375135927461, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 405, train_loss = 1.7622911408543587, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 406, train_loss = 1.7599074443569407, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 407, train_loss = 1.7587647946784273, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 408, train_loss = 1.7582223663339391, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 409, train_loss = 1.7575330076506361, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 410, train_loss = 1.754177232622169, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 411, train_loss = 1.7521976294228807, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 412, train_loss = 1.7520421607187018, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 413, train_loss = 1.75046606361866, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 414, train_loss = 1.7489586435258389, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 415, train_loss = 1.7497030533850193, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 416, train_loss = 1.7462135093519464, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 417, train_loss = 1.7453389005968347, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 418, train_loss = 1.7445444837212563, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 419, train_loss = 1.7447167126229033, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 420, train_loss = 1.7443562721600756, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 421, train_loss = 1.7430489311227575, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 422, train_loss = 1.7413344731321558, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 423, train_loss = 1.740921733318828, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 424, train_loss = 1.7398009970784187, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 425, train_loss = 1.7369350554654375, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 426, train_loss = 1.7367995331296697, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 427, train_loss = 1.736605310230516, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 428, train_loss = 1.7370287565281615, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 429, train_loss = 1.735297360806726, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 430, train_loss = 1.7330676093697548, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 431, train_loss = 1.7347717210650444, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 432, train_loss = 1.7339867105474696, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 433, train_loss = 1.7315151753136888, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 434, train_loss = 1.7279878755798563, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 435, train_loss = 1.7302332818508148, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 436, train_loss = 1.7277766031911597, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 437, train_loss = 1.7262826958904043, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 438, train_loss = 1.7274436242878437, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 439, train_loss = 1.7227140987524763, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 440, train_loss = 1.7255170656135306, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 441, train_loss = 1.7236740179359913, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 442, train_loss = 1.7199011308839545, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 443, train_loss = 1.7217865189304575, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 444, train_loss = 1.7197018414735794, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 445, train_loss = 1.7207170004257932, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 446, train_loss = 1.7175665870308876, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 447, train_loss = 1.7179810479283333, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 448, train_loss = 1.7182172226021066, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 449, train_loss = 1.7145177138736472, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 450, train_loss = 1.7161248413613066, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 451, train_loss = 1.7129074657568708, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 452, train_loss = 1.7141989693045616, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 453, train_loss = 1.7135094305267558, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 454, train_loss = 1.7123598605394363, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 455, train_loss = 1.7126870738575235, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 456, train_loss = 1.7090459801256657, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 457, train_loss = 1.7093894369900227, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 458, train_loss = 1.7080989828100428, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 459, train_loss = 1.706672222702764, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 460, train_loss = 1.7071803584694862, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 461, train_loss = 1.7064637976000085, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 462, train_loss = 1.7042601654538885, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 463, train_loss = 1.705830454826355, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 464, train_loss = 1.703237614245154, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 465, train_loss = 1.7043624880025163, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 466, train_loss = 1.7032210925826803, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 467, train_loss = 1.7033016694476828, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 468, train_loss = 1.7003277192125097, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 469, train_loss = 1.700811812072061, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 470, train_loss = 1.6970682529499754, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 471, train_loss = 1.6980571498861536, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 472, train_loss = 1.696328674792312, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 473, train_loss = 1.697083176462911, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 474, train_loss = 1.6944760344922543, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 475, train_loss = 1.6935080761322752, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 476, train_loss = 1.6935741243651137, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 477, train_loss = 1.6915505217621103, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 478, train_loss = 1.692648912430741, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 479, train_loss = 1.6918970955302939, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 480, train_loss = 1.6897725723683834, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 481, train_loss = 1.6894605867564678, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 482, train_loss = 1.6891718953847885, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 483, train_loss = 1.687065415084362, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 484, train_loss = 1.6880259836325422, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 485, train_loss = 1.6876365505158901, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 486, train_loss = 1.6854318864643574, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 487, train_loss = 1.6869132444262505, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 488, train_loss = 1.6852855645120144, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 489, train_loss = 1.6828586285701022, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 490, train_loss = 1.6856215918669477, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 491, train_loss = 1.6819879958638921, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 492, train_loss = 1.6837402222445235, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 493, train_loss = 1.6814768984913826, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 494, train_loss = 1.6811075123259798, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 495, train_loss = 1.678979797870852, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 496, train_loss = 1.6800497310468927, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 497, train_loss = 1.6793449347605929, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 498, train_loss = 1.6780873810639605, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 499, train_loss = 1.6764950416982174, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████▌              | 24/30 [3:37:15<54:18, 543.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "25th- epoch: 0, train_loss = 118.49549621343613, train_acc = 0.7829529576152772\n",
      "test Acc 0.8868715083798883:\n",
      "25th- epoch: 1, train_loss = 41.95682406425476, train_acc = 0.912435957149511\n",
      "test Acc 0.9213221601489758:\n",
      "25th- epoch: 2, train_loss = 31.697894111275673, train_acc = 0.9356078248719143\n",
      "test Acc 0.9334264432029795:\n",
      "25th- epoch: 3, train_loss = 26.726380087435246, train_acc = 0.944108057755007\n",
      "test Acc 0.9445996275605214:\n",
      "25th- epoch: 4, train_loss = 23.548087805509567, train_acc = 0.9505123428039124\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 5, train_loss = 21.275924049317837, train_acc = 0.9562179785747554\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 6, train_loss = 19.530117709189653, train_acc = 0.9592454587796926\n",
      "test Acc 0.9534450651769087:\n",
      "25th- epoch: 7, train_loss = 18.112330608069897, train_acc = 0.962156497438286\n",
      "test Acc 0.9539106145251397:\n",
      "25th- epoch: 8, train_loss = 16.94036178663373, train_acc = 0.9643688868188169\n",
      "test Acc 0.9562383612662942:\n",
      "25th- epoch: 9, train_loss = 15.930669222027063, train_acc = 0.9663483931066604\n",
      "test Acc 0.957169459962756:\n",
      "25th- epoch: 10, train_loss = 15.072741217911243, train_acc = 0.9669306008383791\n",
      "test Acc 0.957169459962756:\n",
      "25th- epoch: 11, train_loss = 14.322801258414984, train_acc = 0.9692594317652539\n",
      "test Acc 0.957635009310987:\n",
      "25th- epoch: 12, train_loss = 13.653965830802917, train_acc = 0.9710060549604099\n",
      "test Acc 0.9585661080074488:\n",
      "25th- epoch: 13, train_loss = 13.053552024066448, train_acc = 0.9726362366092222\n",
      "test Acc 0.9585661080074488:\n",
      "25th- epoch: 14, train_loss = 12.50786592438817, train_acc = 0.9732184443409408\n",
      "test Acc 0.9590316573556797:\n",
      "25th- epoch: 15, train_loss = 12.020754005759954, train_acc = 0.9746157428970657\n",
      "test Acc 0.9590316573556797:\n",
      "25th- epoch: 16, train_loss = 11.569153629243374, train_acc = 0.9754308337214718\n",
      "test Acc 0.9608938547486033:\n",
      "25th- epoch: 17, train_loss = 11.16611336171627, train_acc = 0.9764788076385654\n",
      "test Acc 0.9613594040968343:\n",
      "25th- epoch: 18, train_loss = 10.789613552391529, train_acc = 0.9768281322775967\n",
      "test Acc 0.962756052141527:\n",
      "25th- epoch: 19, train_loss = 10.443094089627266, train_acc = 0.9775267815556591\n",
      "test Acc 0.9636871508379888:\n",
      "25th- epoch: 20, train_loss = 10.123652916401625, train_acc = 0.9784583139264089\n",
      "test Acc 0.9646182495344506:\n",
      "25th- epoch: 21, train_loss = 9.825019359588623, train_acc = 0.9790405216581276\n",
      "test Acc 0.9650837988826816:\n",
      "25th- epoch: 22, train_loss = 9.548234649002552, train_acc = 0.9798556124825337\n",
      "test Acc 0.9655493482309124:\n",
      "25th- epoch: 23, train_loss = 9.289721865206957, train_acc = 0.980204937121565\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 24, train_loss = 9.045830791816115, train_acc = 0.98067070330694\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 25, train_loss = 8.817205376923084, train_acc = 0.9811364694923148\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 26, train_loss = 8.60381231829524, train_acc = 0.9825337680484397\n",
      "test Acc 0.9664804469273743:\n",
      "25th- epoch: 27, train_loss = 8.398121723905206, train_acc = 0.9826502095947834\n",
      "test Acc 0.9664804469273743:\n",
      "25th- epoch: 28, train_loss = 8.20621451549232, train_acc = 0.9832324173265021\n",
      "test Acc 0.9669459962756052:\n",
      "25th- epoch: 29, train_loss = 8.02078753337264, train_acc = 0.9833488588728458\n",
      "test Acc 0.9674115456238361:\n",
      "25th- epoch: 30, train_loss = 7.845593651756644, train_acc = 0.9833488588728458\n",
      "test Acc 0.9674115456238361:\n",
      "25th- epoch: 31, train_loss = 7.6798234190791845, train_acc = 0.983698183511877\n",
      "test Acc 0.9674115456238361:\n",
      "25th- epoch: 32, train_loss = 7.5194773729890585, train_acc = 0.984163949697252\n",
      "test Acc 0.9674115456238361:\n",
      "25th- epoch: 33, train_loss = 7.369189528748393, train_acc = 0.9845132743362832\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 34, train_loss = 7.223132126033306, train_acc = 0.9847461574289706\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 35, train_loss = 7.085958713665605, train_acc = 0.9848625989753144\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 36, train_loss = 6.953746028244495, train_acc = 0.9853283651606893\n",
      "test Acc 0.9692737430167597:\n",
      "25th- epoch: 37, train_loss = 6.827137757092714, train_acc = 0.9855612482533768\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 38, train_loss = 6.704115254804492, train_acc = 0.9856776897997206\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 39, train_loss = 6.590746169909835, train_acc = 0.985910572892408\n",
      "test Acc 0.9702048417132216:\n",
      "25th- epoch: 40, train_loss = 6.477148527279496, train_acc = 0.9862598975314392\n",
      "test Acc 0.9702048417132216:\n",
      "25th- epoch: 41, train_loss = 6.372896933928132, train_acc = 0.9868421052631579\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 42, train_loss = 6.2690010610967875, train_acc = 0.9873078714485328\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 43, train_loss = 6.170621270313859, train_acc = 0.9874243129948765\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 44, train_loss = 6.073419136926532, train_acc = 0.9874243129948765\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 45, train_loss = 5.983689323067665, train_acc = 0.9877736376339078\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 46, train_loss = 5.895798206329346, train_acc = 0.9877736376339078\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 47, train_loss = 5.8092125579714775, train_acc = 0.9877736376339078\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 48, train_loss = 5.725485859438777, train_acc = 0.9881229622729389\n",
      "test Acc 0.9711359404096834:\n",
      "25th- epoch: 49, train_loss = 5.644716961309314, train_acc = 0.9882394038192828\n",
      "test Acc 0.9711359404096834:\n",
      "25th- epoch: 50, train_loss = 5.5690268483012915, train_acc = 0.9884722869119702\n",
      "test Acc 0.9711359404096834:\n",
      "25th- epoch: 51, train_loss = 5.4943525567650795, train_acc = 0.9887051700046576\n",
      "test Acc 0.9711359404096834:\n",
      "25th- epoch: 52, train_loss = 5.421770922839642, train_acc = 0.9891709361900326\n",
      "test Acc 0.9716014897579144:\n",
      "25th- epoch: 53, train_loss = 5.349474424496293, train_acc = 0.9892873777363763\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 54, train_loss = 5.279990469105542, train_acc = 0.9896367023754076\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 55, train_loss = 5.215277343988419, train_acc = 0.989869585468095\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 56, train_loss = 5.147235035896301, train_acc = 0.9899860270144387\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 57, train_loss = 5.083488531410694, train_acc = 0.99033535165347\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 58, train_loss = 5.02168686222285, train_acc = 0.99033535165347\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 59, train_loss = 4.965081791393459, train_acc = 0.9905682347461574\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 60, train_loss = 4.904835055582225, train_acc = 0.9904517931998137\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 61, train_loss = 4.848264887928963, train_acc = 0.9904517931998137\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 62, train_loss = 4.79161390196532, train_acc = 0.9905682347461574\n",
      "test Acc 0.9725325884543762:\n",
      "25th- epoch: 63, train_loss = 4.738925700075924, train_acc = 0.9905682347461574\n",
      "test Acc 0.9725325884543762:\n",
      "25th- epoch: 64, train_loss = 4.687153746373951, train_acc = 0.9905682347461574\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 65, train_loss = 4.634000241756439, train_acc = 0.9906846762925011\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 66, train_loss = 4.587956085801125, train_acc = 0.990801117838845\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 67, train_loss = 4.539213170297444, train_acc = 0.990801117838845\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 68, train_loss = 4.490595671348274, train_acc = 0.9910340009315324\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 69, train_loss = 4.445890632458031, train_acc = 0.9911504424778761\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 70, train_loss = 4.402415449731052, train_acc = 0.9912668840242198\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 71, train_loss = 4.356987188570201, train_acc = 0.9912668840242198\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 72, train_loss = 4.313471752218902, train_acc = 0.9916162086632511\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 73, train_loss = 4.272155026905239, train_acc = 0.9916162086632511\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 74, train_loss = 4.232054963707924, train_acc = 0.9917326502095948\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 75, train_loss = 4.18985382001847, train_acc = 0.9917326502095948\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 76, train_loss = 4.15075212251395, train_acc = 0.9918490917559385\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 77, train_loss = 4.111037169583142, train_acc = 0.9918490917559385\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 78, train_loss = 4.06957368273288, train_acc = 0.9919655333022822\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 79, train_loss = 4.032388351857662, train_acc = 0.9919655333022822\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 80, train_loss = 3.9953637421131134, train_acc = 0.992081974848626\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 81, train_loss = 3.9574766298756003, train_acc = 0.992081974848626\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 82, train_loss = 3.9237233540043235, train_acc = 0.9921984163949698\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 83, train_loss = 3.8894466189667583, train_acc = 0.9923148579413135\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 84, train_loss = 3.8562188735231757, train_acc = 0.9923148579413135\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 85, train_loss = 3.8236361434683204, train_acc = 0.9923148579413135\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 86, train_loss = 3.7925042919814587, train_acc = 0.9924312994876572\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 87, train_loss = 3.76160045620054, train_acc = 0.9925477410340009\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 88, train_loss = 3.733102918602526, train_acc = 0.9926641825803446\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 89, train_loss = 3.7034943597391248, train_acc = 0.9926641825803446\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 90, train_loss = 3.675284898839891, train_acc = 0.9926641825803446\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 91, train_loss = 3.6456397054716945, train_acc = 0.9926641825803446\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 92, train_loss = 3.6180164562538266, train_acc = 0.9926641825803446\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 93, train_loss = 3.5918670361861587, train_acc = 0.9928970656730322\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 94, train_loss = 3.5650130920112133, train_acc = 0.9928970656730322\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 95, train_loss = 3.5392777919769287, train_acc = 0.9928970656730322\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 96, train_loss = 3.515276080928743, train_acc = 0.9928970656730322\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 97, train_loss = 3.4887730376794934, train_acc = 0.9928970656730322\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 98, train_loss = 3.465340968221426, train_acc = 0.9928970656730322\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 99, train_loss = 3.441954297013581, train_acc = 0.9928970656730322\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 100, train_loss = 3.417947147972882, train_acc = 0.9931299487657196\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 101, train_loss = 3.394553165882826, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 102, train_loss = 3.3729688958264887, train_acc = 0.9931299487657196\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 103, train_loss = 3.349925552960485, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 104, train_loss = 3.3279564939439297, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 105, train_loss = 3.3064927235245705, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 106, train_loss = 3.2854977347888052, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 107, train_loss = 3.2640826092101634, train_acc = 0.9937121564974383\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 108, train_loss = 3.24614160368219, train_acc = 0.9937121564974383\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 109, train_loss = 3.2242670506238937, train_acc = 0.9937121564974383\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 110, train_loss = 3.206212675664574, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 111, train_loss = 3.1864935755729675, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 112, train_loss = 3.1686370237730443, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 113, train_loss = 3.147805042564869, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 114, train_loss = 3.132770571857691, train_acc = 0.993828598043782\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 115, train_loss = 3.113097285386175, train_acc = 0.9941779226828132\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 116, train_loss = 3.095559845212847, train_acc = 0.9939450395901258\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 117, train_loss = 3.077923819422722, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 118, train_loss = 3.0612635551951826, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 119, train_loss = 3.045953743159771, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 120, train_loss = 3.027325590606779, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 121, train_loss = 3.011864768806845, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 122, train_loss = 2.99672419577837, train_acc = 0.9941779226828132\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 123, train_loss = 2.9814005866646767, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 124, train_loss = 2.964212970342487, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 125, train_loss = 2.9501650682650506, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 126, train_loss = 2.93430487299338, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 127, train_loss = 2.9205222316086292, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 128, train_loss = 2.9054757095873356, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 129, train_loss = 2.8910466148518026, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 130, train_loss = 2.876742346677929, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 131, train_loss = 2.8647240214049816, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 132, train_loss = 2.8511728295125067, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 133, train_loss = 2.8378827087581158, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 134, train_loss = 2.8226445824839175, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 135, train_loss = 2.8118323385715485, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 136, train_loss = 2.7986467666924, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 137, train_loss = 2.7862243936397135, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 138, train_loss = 2.7738416702486575, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 139, train_loss = 2.7617812319658697, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 140, train_loss = 2.7487158589065075, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 141, train_loss = 2.73502978682518, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 142, train_loss = 2.7248989730142057, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 143, train_loss = 2.7132699005305767, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 144, train_loss = 2.7027846090495586, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 145, train_loss = 2.6908819624222815, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 146, train_loss = 2.680503983050585, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 147, train_loss = 2.6698115677572787, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 148, train_loss = 2.6598206856288016, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 149, train_loss = 2.649536664132029, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 150, train_loss = 2.6396986418403685, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 151, train_loss = 2.6287575736641884, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 152, train_loss = 2.6176086864434183, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 153, train_loss = 2.6089953198097646, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 154, train_loss = 2.6003975444473326, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 155, train_loss = 2.5893789059482515, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 156, train_loss = 2.579895640257746, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 157, train_loss = 2.570869918912649, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 158, train_loss = 2.5611304230988026, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 159, train_loss = 2.5512430667877197, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 160, train_loss = 2.5431901938281953, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 161, train_loss = 2.5348108634352684, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 162, train_loss = 2.5250244648195803, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 163, train_loss = 2.517401073127985, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 164, train_loss = 2.507621093187481, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 165, train_loss = 2.5008565671741962, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 166, train_loss = 2.4923289730213583, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 167, train_loss = 2.4831888279877603, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 168, train_loss = 2.4750713906250894, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 169, train_loss = 2.467637577559799, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 170, train_loss = 2.4598384401760995, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 171, train_loss = 2.4510132051073015, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 172, train_loss = 2.444888486061245, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 173, train_loss = 2.4363919645547867, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 174, train_loss = 2.430175817105919, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 175, train_loss = 2.4200181502383202, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 176, train_loss = 2.41530475160107, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 177, train_loss = 2.4077408525627106, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 178, train_loss = 2.4005211766343564, train_acc = 0.9953423381462506\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 179, train_loss = 2.3931109085679054, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 180, train_loss = 2.387219338444993, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 181, train_loss = 2.3809965911787003, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 182, train_loss = 2.3723351422231644, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 183, train_loss = 2.365976898698136, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 184, train_loss = 2.3588234062772244, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 185, train_loss = 2.352602433413267, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 186, train_loss = 2.34546763333492, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 187, train_loss = 2.339984542457387, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 188, train_loss = 2.3333960336167365, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 189, train_loss = 2.3273667742032558, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 190, train_loss = 2.321638535708189, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 191, train_loss = 2.3168618779163808, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 192, train_loss = 2.3090823132079095, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 193, train_loss = 2.3025420494377613, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 194, train_loss = 2.2975091610569507, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 195, train_loss = 2.2921487900894135, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 196, train_loss = 2.2859573017340153, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 197, train_loss = 2.280349763808772, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 198, train_loss = 2.274951722472906, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 199, train_loss = 2.2681599173229188, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 200, train_loss = 2.2649772700387985, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 201, train_loss = 2.2575713645201176, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 202, train_loss = 2.2536298756022006, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 203, train_loss = 2.2478635523002595, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 204, train_loss = 2.242775211809203, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 205, train_loss = 2.236837765900418, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 206, train_loss = 2.2343842138070613, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 207, train_loss = 2.227713455678895, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 208, train_loss = 2.2214950148481876, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 209, train_loss = 2.2165573823731393, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 210, train_loss = 2.210741725983098, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 211, train_loss = 2.2070432044565678, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 212, train_loss = 2.202497348189354, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 213, train_loss = 2.1971187256276608, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 214, train_loss = 2.192720863968134, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 215, train_loss = 2.1889614139217883, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 216, train_loss = 2.1837534457445145, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 217, train_loss = 2.1803406837861985, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 218, train_loss = 2.1753768797498196, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 219, train_loss = 2.1697289422154427, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 220, train_loss = 2.165677646873519, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 221, train_loss = 2.16109848767519, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 222, train_loss = 2.155785870971158, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 223, train_loss = 2.1529771250206977, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 224, train_loss = 2.1481871206779033, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 225, train_loss = 2.144415399758145, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 226, train_loss = 2.139486702857539, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 227, train_loss = 2.1350241925101727, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 228, train_loss = 2.1325017164926976, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 229, train_loss = 2.1275039326865226, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 230, train_loss = 2.1239322994370013, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 231, train_loss = 2.1192790728528053, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 232, train_loss = 2.1153827372472733, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 233, train_loss = 2.1115034769754857, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 234, train_loss = 2.1075824697036296, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 235, train_loss = 2.1044730320572853, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 236, train_loss = 2.1001372772734612, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 237, train_loss = 2.098769075004384, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 238, train_loss = 2.0943340670783073, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 239, train_loss = 2.089722466887906, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 240, train_loss = 2.085370671004057, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 241, train_loss = 2.0810117684304714, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 242, train_loss = 2.0790374267380685, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 243, train_loss = 2.0736797600984573, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 244, train_loss = 2.0720285300631076, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 245, train_loss = 2.0666682422161102, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 246, train_loss = 2.063445780426264, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 247, train_loss = 2.063686403213069, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 248, train_loss = 2.0561446112114936, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 249, train_loss = 2.0536506175994873, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 250, train_loss = 2.0497033696155995, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 251, train_loss = 2.046884370269254, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 252, train_loss = 2.0427130747120827, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 253, train_loss = 2.0389742392580956, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 254, train_loss = 2.037570960819721, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 255, train_loss = 2.033177512465045, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 256, train_loss = 2.0298521865624934, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 257, train_loss = 2.027256077853963, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 258, train_loss = 2.024196717888117, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 259, train_loss = 2.0229308418929577, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 260, train_loss = 2.0168385331053287, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 261, train_loss = 2.0152075327932835, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 262, train_loss = 2.0130321581382304, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 263, train_loss = 2.008957238169387, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 264, train_loss = 2.004374115495011, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 265, train_loss = 2.0031530919950455, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 266, train_loss = 2.0012202002108097, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 267, train_loss = 1.9962237600702792, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 268, train_loss = 1.9940462138038129, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 269, train_loss = 1.990476542385295, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 270, train_loss = 1.9882167477626354, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 271, train_loss = 1.9854205287992954, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 272, train_loss = 1.984799859346822, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 273, train_loss = 1.9793635692913085, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 274, train_loss = 1.9765517984051257, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 275, train_loss = 1.9738982270937413, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 276, train_loss = 1.9708403993863612, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 277, train_loss = 1.9690858249086887, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 278, train_loss = 1.9655280646402389, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 279, train_loss = 1.9623684249818325, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 280, train_loss = 1.9622374884784222, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 281, train_loss = 1.9569421373307705, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 282, train_loss = 1.9542864102404565, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 283, train_loss = 1.9520481687504798, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 284, train_loss = 1.951448742300272, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 285, train_loss = 1.9471332281827927, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 286, train_loss = 1.9441348438849673, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 287, train_loss = 1.94116824620869, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 288, train_loss = 1.9401256876299158, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 289, train_loss = 1.9371947894105688, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 290, train_loss = 1.9345769000938162, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 291, train_loss = 1.9316845772555098, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 292, train_loss = 1.9300668066134676, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 293, train_loss = 1.9272196479141712, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 294, train_loss = 1.923717355937697, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 295, train_loss = 1.9221345596015453, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 296, train_loss = 1.9201545976102352, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 297, train_loss = 1.916237000375986, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 298, train_loss = 1.9144454872002825, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 299, train_loss = 1.9135789138963446, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 300, train_loss = 1.9110078947851434, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 301, train_loss = 1.9099828811595216, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 302, train_loss = 1.90576631820295, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 303, train_loss = 1.905583743005991, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 304, train_loss = 1.9017388907959685, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 305, train_loss = 1.8987078903010115, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 306, train_loss = 1.8977709213504568, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 307, train_loss = 1.8953329225769266, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 308, train_loss = 1.8929378911852837, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 309, train_loss = 1.8919811384985223, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 310, train_loss = 1.8890214177081361, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 311, train_loss = 1.885287338285707, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 312, train_loss = 1.8853445959975943, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 313, train_loss = 1.883846241980791, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 314, train_loss = 1.881519197137095, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 315, train_loss = 1.8776590848574415, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 316, train_loss = 1.8755576945841312, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 317, train_loss = 1.8735090555856004, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 318, train_loss = 1.87091565632727, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 319, train_loss = 1.8695810871431604, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 320, train_loss = 1.8683938173344359, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 321, train_loss = 1.8651654148707166, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 322, train_loss = 1.8649120951304212, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 323, train_loss = 1.862768828868866, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 324, train_loss = 1.8598986765136942, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 325, train_loss = 1.8579080303898081, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 326, train_loss = 1.856849161325954, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 327, train_loss = 1.8549752695253119, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 328, train_loss = 1.853325955569744, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 329, train_loss = 1.8513991931686178, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 330, train_loss = 1.85031310969498, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 331, train_loss = 1.84780838212464, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 332, train_loss = 1.8445469550788403, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 333, train_loss = 1.843876545666717, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 334, train_loss = 1.8425950655946508, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 335, train_loss = 1.841757540940307, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 336, train_loss = 1.837941606878303, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 337, train_loss = 1.8373880299041048, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 338, train_loss = 1.8358231546590105, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 339, train_loss = 1.8331104466924444, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 340, train_loss = 1.8323877876391634, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 341, train_loss = 1.8303916888544336, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 342, train_loss = 1.8271530544152483, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 343, train_loss = 1.8265567707130685, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 344, train_loss = 1.8244060985744, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 345, train_loss = 1.824967559427023, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 346, train_loss = 1.8243847215780988, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 347, train_loss = 1.819990356802009, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 348, train_loss = 1.8187229534378275, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 349, train_loss = 1.8172877033939585, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 350, train_loss = 1.81465432792902, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 351, train_loss = 1.8127174997935072, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 352, train_loss = 1.8124311566352844, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 353, train_loss = 1.8105466837296262, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 354, train_loss = 1.809015209437348, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 355, train_loss = 1.8072449503233656, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 356, train_loss = 1.805522287846543, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 357, train_loss = 1.8021467315265909, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 358, train_loss = 1.8010246505727991, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 359, train_loss = 1.8014401408145204, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 360, train_loss = 1.7989953508367762, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 361, train_loss = 1.796758377342485, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 362, train_loss = 1.7951511703431606, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 363, train_loss = 1.793822760344483, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 364, train_loss = 1.7946922878036276, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 365, train_loss = 1.7923614556202665, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 366, train_loss = 1.790866838186048, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 367, train_loss = 1.7886453109094873, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 368, train_loss = 1.786083348095417, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 369, train_loss = 1.7849656766047701, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 370, train_loss = 1.786572857410647, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 371, train_loss = 1.7821881534764543, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 372, train_loss = 1.7810183838009834, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 373, train_loss = 1.7787782003870234, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 374, train_loss = 1.7807511599967256, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 375, train_loss = 1.777418490499258, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 376, train_loss = 1.7781274890294299, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 377, train_loss = 1.7725485935807228, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 378, train_loss = 1.7734027666738257, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 379, train_loss = 1.77359025424812, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 380, train_loss = 1.769345749169588, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 381, train_loss = 1.770166739821434, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 382, train_loss = 1.7650827852776274, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 383, train_loss = 1.7677342494716868, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 384, train_loss = 1.7641648600110784, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 385, train_loss = 1.7635092859854922, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 386, train_loss = 1.763701265095733, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 387, train_loss = 1.7591826716670766, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 388, train_loss = 1.761933614849113, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 389, train_loss = 1.758002646267414, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 390, train_loss = 1.7582925260066986, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 391, train_loss = 1.756291245459579, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 392, train_loss = 1.7556986262788996, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 393, train_loss = 1.7526441043009982, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 394, train_loss = 1.7546281764516607, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 395, train_loss = 1.7509158551692963, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 396, train_loss = 1.7493834545603022, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 397, train_loss = 1.7489565139403567, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 398, train_loss = 1.7490490190684795, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 399, train_loss = 1.7449881794163957, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 400, train_loss = 1.744100378244184, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 401, train_loss = 1.7446155709913, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 402, train_loss = 1.7412246564636007, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 403, train_loss = 1.7414255775511265, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 404, train_loss = 1.7417694168398157, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 405, train_loss = 1.7379099117824808, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 406, train_loss = 1.7372743114829063, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 407, train_loss = 1.734861465753056, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 408, train_loss = 1.7351922480156645, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 409, train_loss = 1.7367918441304937, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 410, train_loss = 1.732804017723538, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 411, train_loss = 1.7308080407092348, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 412, train_loss = 1.7289191657910123, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 413, train_loss = 1.7294777942588553, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 414, train_loss = 1.727889470756054, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 415, train_loss = 1.7247083969414234, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 416, train_loss = 1.7259791158139706, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 417, train_loss = 1.7253163444111124, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 418, train_loss = 1.7243187142303213, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 419, train_loss = 1.7231813743710518, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 420, train_loss = 1.721885271370411, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 421, train_loss = 1.723083272576332, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 422, train_loss = 1.7200049409875646, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 423, train_loss = 1.719046376645565, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 424, train_loss = 1.717606502235867, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 425, train_loss = 1.7149896770715714, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 426, train_loss = 1.7151376095716842, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 427, train_loss = 1.714054497599136, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 428, train_loss = 1.713582271069754, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 429, train_loss = 1.7109200072591193, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 430, train_loss = 1.7122892054612748, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 431, train_loss = 1.7081271397764795, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 432, train_loss = 1.70951797318412, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 433, train_loss = 1.70812889438821, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 434, train_loss = 1.707852266728878, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 435, train_loss = 1.7046982484753244, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 436, train_loss = 1.705239920585882, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 437, train_loss = 1.704450053453911, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 438, train_loss = 1.7037949549849145, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 439, train_loss = 1.7024578228592873, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 440, train_loss = 1.7013854036922567, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 441, train_loss = 1.6994454401428811, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 442, train_loss = 1.69966197386384, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 443, train_loss = 1.6991896380786784, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 444, train_loss = 1.6972633649711497, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 445, train_loss = 1.695201129943598, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 446, train_loss = 1.6966169203515165, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 447, train_loss = 1.6950163133442402, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 448, train_loss = 1.6945678529446013, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 449, train_loss = 1.6937149427831173, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 450, train_loss = 1.6919883911614306, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 451, train_loss = 1.6914834107155912, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 452, train_loss = 1.6905978905851953, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 453, train_loss = 1.6894066681270488, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 454, train_loss = 1.6893437902326696, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 455, train_loss = 1.6884080196614377, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 456, train_loss = 1.686974259733688, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 457, train_loss = 1.6854782936279662, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 458, train_loss = 1.685257660865318, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 459, train_loss = 1.6832246730918996, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 460, train_loss = 1.6836457960307598, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 461, train_loss = 1.682008030533325, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 462, train_loss = 1.6811441617901437, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 463, train_loss = 1.6808467445080169, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 464, train_loss = 1.679348090023268, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 465, train_loss = 1.6788972082431428, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 466, train_loss = 1.6766603142023087, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 467, train_loss = 1.6767258768086322, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 468, train_loss = 1.6752233318984509, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 469, train_loss = 1.6766096949577332, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 470, train_loss = 1.67395430553006, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 471, train_loss = 1.6736520640552044, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 472, train_loss = 1.6732721353764646, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 473, train_loss = 1.6726449690759182, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 474, train_loss = 1.6708337652380578, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 475, train_loss = 1.668995462357998, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 476, train_loss = 1.6686240173876286, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 477, train_loss = 1.669366812973749, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 478, train_loss = 1.6660395413637161, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 479, train_loss = 1.666796827048529, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 480, train_loss = 1.6675495368544944, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 481, train_loss = 1.6638692555134185, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 482, train_loss = 1.6674112752079964, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 483, train_loss = 1.6652910560369492, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 484, train_loss = 1.6633995200390927, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 485, train_loss = 1.662353377789259, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 486, train_loss = 1.6602813713252544, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 487, train_loss = 1.6598301294143312, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 488, train_loss = 1.6596314162015915, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 489, train_loss = 1.6601792101864703, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 490, train_loss = 1.6590336474473588, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 491, train_loss = 1.6577488568727858, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 492, train_loss = 1.6563706609304063, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 493, train_loss = 1.6554067085380666, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 494, train_loss = 1.6548117796774022, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 495, train_loss = 1.654943723231554, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 496, train_loss = 1.652588193595875, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 497, train_loss = 1.6536977638606913, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 498, train_loss = 1.6529213289613836, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 499, train_loss = 1.6521970654721372, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████            | 25/30 [3:46:18<45:15, 543.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "26th- epoch: 0, train_loss = 119.70763616263866, train_acc = 0.7822543083372148\n",
      "test Acc 0.8943202979515829:\n",
      "26th- epoch: 1, train_loss = 41.11606873571873, train_acc = 0.9130181648812297\n",
      "test Acc 0.9269087523277467:\n",
      "26th- epoch: 2, train_loss = 31.312080889940262, train_acc = 0.9350256171401956\n",
      "test Acc 0.9390130353817505:\n",
      "26th- epoch: 3, train_loss = 26.31152194365859, train_acc = 0.9459711224965067\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 4, train_loss = 23.13976438343525, train_acc = 0.9544713553795995\n",
      "test Acc 0.9473929236499069:\n",
      "26th- epoch: 5, train_loss = 20.88550717383623, train_acc = 0.9591290172333489\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 6, train_loss = 19.129208501428366, train_acc = 0.9615742897065673\n",
      "test Acc 0.9529795158286778:\n",
      "26th- epoch: 7, train_loss = 17.72316701337695, train_acc = 0.9644853283651607\n",
      "test Acc 0.9543761638733705:\n",
      "26th- epoch: 8, train_loss = 16.53446301445365, train_acc = 0.9662319515603167\n",
      "test Acc 0.9557728119180633:\n",
      "26th- epoch: 9, train_loss = 15.52297092601657, train_acc = 0.9678621332091291\n",
      "test Acc 0.9567039106145251:\n",
      "26th- epoch: 10, train_loss = 14.637652769684792, train_acc = 0.969608756404285\n",
      "test Acc 0.9567039106145251:\n",
      "26th- epoch: 11, train_loss = 13.859891664236784, train_acc = 0.9717047042384723\n",
      "test Acc 0.9581005586592178:\n",
      "26th- epoch: 12, train_loss = 13.183994069695473, train_acc = 0.9732184443409408\n",
      "test Acc 0.9599627560521415:\n",
      "26th- epoch: 13, train_loss = 12.587370615452528, train_acc = 0.9739170936190032\n",
      "test Acc 0.9613594040968343:\n",
      "26th- epoch: 14, train_loss = 12.057004299014807, train_acc = 0.975780158360503\n",
      "test Acc 0.9613594040968343:\n",
      "26th- epoch: 15, train_loss = 11.578109696507454, train_acc = 0.9770610153702841\n",
      "test Acc 0.9622905027932961:\n",
      "26th- epoch: 16, train_loss = 11.150174036622047, train_acc = 0.9775267815556591\n",
      "test Acc 0.962756052141527:\n",
      "26th- epoch: 17, train_loss = 10.758577968925238, train_acc = 0.9784583139264089\n",
      "test Acc 0.9636871508379888:\n",
      "26th- epoch: 18, train_loss = 10.389777572825551, train_acc = 0.9790405216581276\n",
      "test Acc 0.9632216014897579:\n",
      "26th- epoch: 19, train_loss = 10.051816292107105, train_acc = 0.9798556124825337\n",
      "test Acc 0.9646182495344506:\n",
      "26th- epoch: 20, train_loss = 9.735968606546521, train_acc = 0.9804378202142524\n",
      "test Acc 0.9650837988826816:\n",
      "26th- epoch: 21, train_loss = 9.445427196100354, train_acc = 0.98067070330694\n",
      "test Acc 0.9660148975791434:\n",
      "26th- epoch: 22, train_loss = 9.173946004360914, train_acc = 0.9812529110386586\n",
      "test Acc 0.9674115456238361:\n",
      "26th- epoch: 23, train_loss = 8.912191115319729, train_acc = 0.9818351187703773\n",
      "test Acc 0.9674115456238361:\n",
      "26th- epoch: 24, train_loss = 8.671792183071375, train_acc = 0.9826502095947834\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 25, train_loss = 8.448247287422419, train_acc = 0.9831159757801584\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 26, train_loss = 8.237318458035588, train_acc = 0.9834653004191896\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 27, train_loss = 8.036631766706705, train_acc = 0.983698183511877\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 28, train_loss = 7.8481764793396, train_acc = 0.9846297158826269\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 29, train_loss = 7.666158981621265, train_acc = 0.9852119236143456\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 30, train_loss = 7.49385729059577, train_acc = 0.985444806707033\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 31, train_loss = 7.332647856324911, train_acc = 0.985444806707033\n",
      "test Acc 0.9688081936685289:\n",
      "26th- epoch: 32, train_loss = 7.182064600288868, train_acc = 0.985910572892408\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 33, train_loss = 7.037772851064801, train_acc = 0.9862598975314392\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 34, train_loss = 6.901937061920762, train_acc = 0.9864927806241267\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 35, train_loss = 6.7726030591875315, train_acc = 0.9875407545412203\n",
      "test Acc 0.9697392923649907:\n",
      "26th- epoch: 36, train_loss = 6.648966107517481, train_acc = 0.9878900791802515\n",
      "test Acc 0.9697392923649907:\n",
      "26th- epoch: 37, train_loss = 6.532533777877688, train_acc = 0.9882394038192828\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 38, train_loss = 6.418939501047134, train_acc = 0.9887051700046576\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 39, train_loss = 6.31119279935956, train_acc = 0.9890544946436889\n",
      "test Acc 0.9706703910614525:\n",
      "26th- epoch: 40, train_loss = 6.207589464262128, train_acc = 0.9890544946436889\n",
      "test Acc 0.9706703910614525:\n",
      "26th- epoch: 41, train_loss = 6.111744288355112, train_acc = 0.9891709361900326\n",
      "test Acc 0.9706703910614525:\n",
      "26th- epoch: 42, train_loss = 6.013193216174841, train_acc = 0.9892873777363763\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 43, train_loss = 5.921750709414482, train_acc = 0.98940381928272\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 44, train_loss = 5.83458212390542, train_acc = 0.9896367023754076\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 45, train_loss = 5.7495930176228285, train_acc = 0.9896367023754076\n",
      "test Acc 0.9706703910614525:\n",
      "26th- epoch: 46, train_loss = 5.665215637534857, train_acc = 0.9896367023754076\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 47, train_loss = 5.586397083476186, train_acc = 0.9897531439217513\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 48, train_loss = 5.510839195922017, train_acc = 0.9899860270144387\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 49, train_loss = 5.437026932835579, train_acc = 0.9899860270144387\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 50, train_loss = 5.364754345268011, train_acc = 0.9902189101071263\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 51, train_loss = 5.294075917452574, train_acc = 0.9904517931998137\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 52, train_loss = 5.22786826454103, train_acc = 0.9904517931998137\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 53, train_loss = 5.1627531331032515, train_acc = 0.9906846762925011\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 54, train_loss = 5.0983355939388275, train_acc = 0.9911504424778761\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 55, train_loss = 5.0393769685178995, train_acc = 0.9911504424778761\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 56, train_loss = 4.978985911235213, train_acc = 0.9912668840242198\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 57, train_loss = 4.922017203643918, train_acc = 0.9911504424778761\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 58, train_loss = 4.867962718009949, train_acc = 0.9913833255705635\n",
      "test Acc 0.9720670391061452:\n",
      "26th- epoch: 59, train_loss = 4.810828188434243, train_acc = 0.9914997671169073\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 60, train_loss = 4.76052276045084, train_acc = 0.9914997671169073\n",
      "test Acc 0.9720670391061452:\n",
      "26th- epoch: 61, train_loss = 4.706394474953413, train_acc = 0.9917326502095948\n",
      "test Acc 0.9720670391061452:\n",
      "26th- epoch: 62, train_loss = 4.657572723925114, train_acc = 0.9917326502095948\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 63, train_loss = 4.608303563669324, train_acc = 0.9919655333022822\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 64, train_loss = 4.559839654713869, train_acc = 0.9919655333022822\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 65, train_loss = 4.514152085408568, train_acc = 0.9919655333022822\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 66, train_loss = 4.468345878645778, train_acc = 0.9919655333022822\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 67, train_loss = 4.424248145893216, train_acc = 0.9919655333022822\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 68, train_loss = 4.378738846629858, train_acc = 0.9919655333022822\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 69, train_loss = 4.3366662953048944, train_acc = 0.9921984163949698\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 70, train_loss = 4.29769466817379, train_acc = 0.9923148579413135\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 71, train_loss = 4.256660506129265, train_acc = 0.9923148579413135\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 72, train_loss = 4.216452399268746, train_acc = 0.9923148579413135\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 73, train_loss = 4.178926071152091, train_acc = 0.9923148579413135\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 74, train_loss = 4.142745729535818, train_acc = 0.9923148579413135\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 75, train_loss = 4.106178100220859, train_acc = 0.9923148579413135\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 76, train_loss = 4.071542411111295, train_acc = 0.9923148579413135\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 77, train_loss = 4.035816379822791, train_acc = 0.9924312994876572\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 78, train_loss = 4.000919762067497, train_acc = 0.9924312994876572\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 79, train_loss = 3.9691106462851167, train_acc = 0.9925477410340009\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 80, train_loss = 3.934836688451469, train_acc = 0.9927806241266884\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 81, train_loss = 3.907279876060784, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 82, train_loss = 3.874253767542541, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 83, train_loss = 3.843389641493559, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 84, train_loss = 3.814576313830912, train_acc = 0.9928970656730322\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 85, train_loss = 3.7847664412111044, train_acc = 0.9928970656730322\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 86, train_loss = 3.756943273358047, train_acc = 0.9930135072193759\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 87, train_loss = 3.7295599160715938, train_acc = 0.9930135072193759\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 88, train_loss = 3.702042213641107, train_acc = 0.9930135072193759\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 89, train_loss = 3.6758881360292435, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 90, train_loss = 3.6479593394324183, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 91, train_loss = 3.622745256870985, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 92, train_loss = 3.596160582266748, train_acc = 0.9930135072193759\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 93, train_loss = 3.573588944040239, train_acc = 0.9930135072193759\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 94, train_loss = 3.549038667231798, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 95, train_loss = 3.5243294406682253, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 96, train_loss = 3.500973922200501, train_acc = 0.9930135072193759\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 97, train_loss = 3.477779214270413, train_acc = 0.9931299487657196\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 98, train_loss = 3.455276792868972, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 99, train_loss = 3.4322982346639037, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 100, train_loss = 3.4112063413485885, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 101, train_loss = 3.3888511918485165, train_acc = 0.9931299487657196\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 102, train_loss = 3.3706623231992126, train_acc = 0.9931299487657196\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 103, train_loss = 3.349166519008577, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 104, train_loss = 3.328431555069983, train_acc = 0.9932463903120633\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 105, train_loss = 3.307869801297784, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 106, train_loss = 3.288724994286895, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 107, train_loss = 3.2709586285054684, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 108, train_loss = 3.2508046785369515, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 109, train_loss = 3.233166412450373, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 110, train_loss = 3.214916761033237, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 111, train_loss = 3.1969400830566883, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 112, train_loss = 3.1786235878244042, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 113, train_loss = 3.161271443590522, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 114, train_loss = 3.144970622844994, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 115, train_loss = 3.128863706253469, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 116, train_loss = 3.1108056670054793, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 117, train_loss = 3.095567850396037, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 118, train_loss = 3.0801716344431043, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 119, train_loss = 3.0633033076301217, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 120, train_loss = 3.047275047749281, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 121, train_loss = 3.032079947181046, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 122, train_loss = 3.016383239068091, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 123, train_loss = 3.00302398391068, train_acc = 0.9934792734047508\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 124, train_loss = 2.987023371271789, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 125, train_loss = 2.9734533252194524, train_acc = 0.9935957149510946\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 126, train_loss = 2.959199788980186, train_acc = 0.9937121564974383\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 127, train_loss = 2.9444407038390636, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 128, train_loss = 2.931440274231136, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 129, train_loss = 2.9168100003153086, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 130, train_loss = 2.9033068157732487, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 131, train_loss = 2.8905109548941255, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 132, train_loss = 2.875731570646167, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 133, train_loss = 2.864285179413855, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 134, train_loss = 2.8503913590684533, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 135, train_loss = 2.8366579236462712, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 136, train_loss = 2.8251210236921906, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 137, train_loss = 2.8107941644266248, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 138, train_loss = 2.7973536886274815, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 139, train_loss = 2.7876131841912866, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 140, train_loss = 2.7752343183383346, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 141, train_loss = 2.763532797805965, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 142, train_loss = 2.752177066169679, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 143, train_loss = 2.7421060455963016, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 144, train_loss = 2.7310397420078516, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 145, train_loss = 2.7193733705207705, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 146, train_loss = 2.708770605735481, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 147, train_loss = 2.6975754532031715, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 148, train_loss = 2.686595858540386, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 149, train_loss = 2.6781536391936243, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 150, train_loss = 2.667184815276414, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 151, train_loss = 2.6581034823320806, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 152, train_loss = 2.647219069302082, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 153, train_loss = 2.6374504901468754, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 154, train_loss = 2.6279850411228836, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 155, train_loss = 2.6181142646819353, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 156, train_loss = 2.610421522986144, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 157, train_loss = 2.599402470048517, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 158, train_loss = 2.5913194152526557, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 159, train_loss = 2.5821640589274466, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 160, train_loss = 2.573711795732379, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 161, train_loss = 2.564167119562626, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 162, train_loss = 2.5539067089557648, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 163, train_loss = 2.5467202491126955, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 164, train_loss = 2.536980951204896, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 165, train_loss = 2.528637662064284, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 166, train_loss = 2.520756429526955, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 167, train_loss = 2.510125104803592, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 168, train_loss = 2.5046241390518844, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 169, train_loss = 2.4975240998901427, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 170, train_loss = 2.4878612626343966, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 171, train_loss = 2.481880855280906, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 172, train_loss = 2.4730058815330267, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 173, train_loss = 2.4648838038556278, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 174, train_loss = 2.458189034368843, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 175, train_loss = 2.4506841357797384, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 176, train_loss = 2.4431440685875714, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 177, train_loss = 2.434582972433418, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 178, train_loss = 2.428343810606748, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 179, train_loss = 2.4203232540749013, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 180, train_loss = 2.4149952176958323, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 181, train_loss = 2.407757771667093, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 182, train_loss = 2.400506529957056, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 183, train_loss = 2.3940035682171583, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 184, train_loss = 2.3862154255621135, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 185, train_loss = 2.3801549202762544, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 186, train_loss = 2.3733641896396875, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 187, train_loss = 2.3656370788812637, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 188, train_loss = 2.3589445832185447, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 189, train_loss = 2.3510613590478897, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 190, train_loss = 2.3457531542517245, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 191, train_loss = 2.3387484196573496, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 192, train_loss = 2.3342250622808933, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 193, train_loss = 2.3263302873820066, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 194, train_loss = 2.3205232941545546, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 195, train_loss = 2.3142294865101576, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 196, train_loss = 2.307644205633551, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 197, train_loss = 2.3015413880348206, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 198, train_loss = 2.295979270711541, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 199, train_loss = 2.290354711469263, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 200, train_loss = 2.2846783702261746, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 201, train_loss = 2.2795943706296384, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 202, train_loss = 2.2742311637848616, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 203, train_loss = 2.2672908012755215, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 204, train_loss = 2.262343443930149, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 205, train_loss = 2.257397010922432, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 206, train_loss = 2.251451655756682, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 207, train_loss = 2.2463711705058813, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 208, train_loss = 2.242015720810741, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 209, train_loss = 2.2361526396125555, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 210, train_loss = 2.231652611400932, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 211, train_loss = 2.225912081543356, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 212, train_loss = 2.2197305378504097, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 213, train_loss = 2.2170143486000597, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 214, train_loss = 2.2117384583689272, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 215, train_loss = 2.2065865485928953, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 216, train_loss = 2.2023595571517944, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 217, train_loss = 2.1972094937227666, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 218, train_loss = 2.192631707061082, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 219, train_loss = 2.187911508604884, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 220, train_loss = 2.1829547565430403, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 221, train_loss = 2.178982216399163, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 222, train_loss = 2.174896862823516, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 223, train_loss = 2.169365128967911, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 224, train_loss = 2.164491292554885, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 225, train_loss = 2.1616332693956792, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 226, train_loss = 2.1573637048713863, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 227, train_loss = 2.1512915468774736, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 228, train_loss = 2.147716598585248, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 229, train_loss = 2.1438454589806497, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 230, train_loss = 2.138902742881328, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 231, train_loss = 2.1349868257530034, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 232, train_loss = 2.128996539860964, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 233, train_loss = 2.127094406168908, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 234, train_loss = 2.1223050635308027, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 235, train_loss = 2.1186326113529503, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 236, train_loss = 2.1140596196055412, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 237, train_loss = 2.110335108358413, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 238, train_loss = 2.107213378418237, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 239, train_loss = 2.102061271201819, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 240, train_loss = 2.0986046460457146, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 241, train_loss = 2.0954575049690902, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 242, train_loss = 2.0907389116473496, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 243, train_loss = 2.086379418615252, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 244, train_loss = 2.0830515096895397, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 245, train_loss = 2.0791837978176773, train_acc = 0.9956916627852818\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 246, train_loss = 2.0757537255994976, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 247, train_loss = 2.0717213954776525, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 248, train_loss = 2.069521349389106, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 249, train_loss = 2.065861120354384, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 250, train_loss = 2.0628532455302775, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 251, train_loss = 2.0574795049615204, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 252, train_loss = 2.054350341204554, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 253, train_loss = 2.0512134390883148, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 254, train_loss = 2.048239754512906, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 255, train_loss = 2.0442605172283947, train_acc = 0.9953423381462506\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 256, train_loss = 2.0401995605789125, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 257, train_loss = 2.037971407175064, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 258, train_loss = 2.034218853805214, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 259, train_loss = 2.031068666372448, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 260, train_loss = 2.0270464203786105, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 261, train_loss = 2.02476674830541, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 262, train_loss = 2.0207486681174487, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 263, train_loss = 2.017229404998943, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 264, train_loss = 2.0149444807320833, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 265, train_loss = 2.0119548719376326, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 266, train_loss = 2.0078767475206405, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 267, train_loss = 2.004960347665474, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 268, train_loss = 2.003016982926056, train_acc = 0.9953423381462506\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 269, train_loss = 2.0001384548377246, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 270, train_loss = 1.9964315358083695, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 271, train_loss = 1.9934664729516953, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 272, train_loss = 1.991240297211334, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 273, train_loss = 1.9884686314035207, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 274, train_loss = 1.9841481980402023, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 275, train_loss = 1.9824701168108732, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 276, train_loss = 1.979081368772313, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 277, train_loss = 1.9759674482047558, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 278, train_loss = 1.9743489809334278, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 279, train_loss = 1.9717876818031073, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 280, train_loss = 1.9687742919195443, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 281, train_loss = 1.9649039644282311, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 282, train_loss = 1.9620933793485165, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 283, train_loss = 1.9584953866433352, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 284, train_loss = 1.956869435729459, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 285, train_loss = 1.9534043483436108, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 286, train_loss = 1.950590506196022, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 287, train_loss = 1.9484099734108895, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 288, train_loss = 1.9470006588380784, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 289, train_loss = 1.9433905947953463, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 290, train_loss = 1.9422616239171475, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 291, train_loss = 1.9398767612874508, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 292, train_loss = 1.9376469894777983, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 293, train_loss = 1.9327801417093724, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 294, train_loss = 1.9327155041974038, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 295, train_loss = 1.9299868121743202, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 296, train_loss = 1.9257904954720289, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 297, train_loss = 1.9220994014758617, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 298, train_loss = 1.9219695150386542, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 299, train_loss = 1.9180691551882774, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 300, train_loss = 1.9171248581260443, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 301, train_loss = 1.914406333817169, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 302, train_loss = 1.912570035085082, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 303, train_loss = 1.909093452617526, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 304, train_loss = 1.908715646713972, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 305, train_loss = 1.9062608752865344, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 306, train_loss = 1.9037536636460572, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 307, train_loss = 1.8997212250251323, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 308, train_loss = 1.899544055806473, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 309, train_loss = 1.8966548785101622, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 310, train_loss = 1.8948256454896182, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 311, train_loss = 1.891139467479661, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 312, train_loss = 1.8909492257516831, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 313, train_loss = 1.887019072426483, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 314, train_loss = 1.8855091270525008, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 315, train_loss = 1.8817154231946915, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 316, train_loss = 1.8810409985017031, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 317, train_loss = 1.878781168954447, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 318, train_loss = 1.8761156897526234, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 319, train_loss = 1.8765005574095994, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 320, train_loss = 1.8723899964243174, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 321, train_loss = 1.8710193957667798, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 322, train_loss = 1.8676027308683842, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 323, train_loss = 1.8675572015345097, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 324, train_loss = 1.8648151860106736, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 325, train_loss = 1.863002960337326, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 326, train_loss = 1.8614563543815166, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 327, train_loss = 1.8572790313046426, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 328, train_loss = 1.8576939918566495, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 329, train_loss = 1.8535019773989916, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 330, train_loss = 1.8529524977784604, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 331, train_loss = 1.8499027031939477, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 332, train_loss = 1.8485427245032042, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 333, train_loss = 1.8473851245362312, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 334, train_loss = 1.846428691642359, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 335, train_loss = 1.8453991387505084, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 336, train_loss = 1.8398098808247596, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 337, train_loss = 1.8405571281909943, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 338, train_loss = 1.83778929640539, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 339, train_loss = 1.8367531839758158, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 340, train_loss = 1.8344589688349515, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 341, train_loss = 1.8311025265138596, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 342, train_loss = 1.831439632223919, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 343, train_loss = 1.828446914209053, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 344, train_loss = 1.8259185117203742, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 345, train_loss = 1.8262463386636227, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 346, train_loss = 1.822864993242547, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 347, train_loss = 1.822578312130645, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 348, train_loss = 1.821915650041774, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 349, train_loss = 1.817899276735261, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 350, train_loss = 1.8171710707247257, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 351, train_loss = 1.8146787211298943, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 352, train_loss = 1.813394159078598, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 353, train_loss = 1.8114373062271625, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 354, train_loss = 1.8104872207622975, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 355, train_loss = 1.807960917474702, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 356, train_loss = 1.8074678268749267, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 357, train_loss = 1.805830215336755, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 358, train_loss = 1.8035011303145438, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 359, train_loss = 1.8023491452913731, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 360, train_loss = 1.8006418060977012, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 361, train_loss = 1.7988505139946938, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 362, train_loss = 1.79817312839441, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 363, train_loss = 1.7954611096065491, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 364, train_loss = 1.7942422416526824, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 365, train_loss = 1.7922717779874802, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 366, train_loss = 1.7919533450622112, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 367, train_loss = 1.7883056662976742, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 368, train_loss = 1.7883837099652737, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 369, train_loss = 1.7866344701033086, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 370, train_loss = 1.785305405734107, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 371, train_loss = 1.783868646947667, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 372, train_loss = 1.7820455469191074, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 373, train_loss = 1.7802752417046577, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 374, train_loss = 1.7804157945793122, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 375, train_loss = 1.7781160299200565, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 376, train_loss = 1.7767661027610302, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 377, train_loss = 1.775184728205204, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 378, train_loss = 1.7745573606807739, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 379, train_loss = 1.7717787250876427, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 380, train_loss = 1.7717696477193385, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 381, train_loss = 1.7693731177132577, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 382, train_loss = 1.7685024205129594, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 383, train_loss = 1.768388492288068, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 384, train_loss = 1.7660593565087765, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 385, train_loss = 1.7641005653422326, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 386, train_loss = 1.7618284709751606, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 387, train_loss = 1.7622140001039952, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 388, train_loss = 1.7593772038817406, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 389, train_loss = 1.7595889705698937, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 390, train_loss = 1.7573698100168258, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 391, train_loss = 1.7560813773889095, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 392, train_loss = 1.7537419546861202, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 393, train_loss = 1.7536596134305, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 394, train_loss = 1.7522711344063282, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 395, train_loss = 1.7506900827866048, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 396, train_loss = 1.7488694314379245, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 397, train_loss = 1.748143331380561, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 398, train_loss = 1.7468384529929608, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 399, train_loss = 1.7457970876712352, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 400, train_loss = 1.7449627071619034, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 401, train_loss = 1.7437238816637546, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 402, train_loss = 1.7420506600756198, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 403, train_loss = 1.7416255362331867, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 404, train_loss = 1.7402269269805402, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 405, train_loss = 1.7391486775595695, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 406, train_loss = 1.7374517917633057, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 407, train_loss = 1.7357805743813515, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 408, train_loss = 1.7359434142708778, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 409, train_loss = 1.733792271465063, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 410, train_loss = 1.7337443169672042, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 411, train_loss = 1.7315151307266206, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 412, train_loss = 1.7307816843967885, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 413, train_loss = 1.7289245177526027, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 414, train_loss = 1.7289551806170493, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 415, train_loss = 1.7266539495903999, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 416, train_loss = 1.7262230564374477, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 417, train_loss = 1.7254778544884175, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 418, train_loss = 1.724689156981185, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 419, train_loss = 1.7224999342579395, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 420, train_loss = 1.7207876530010253, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 421, train_loss = 1.7207381937187165, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 422, train_loss = 1.719561732141301, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 423, train_loss = 1.7192095380742103, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 424, train_loss = 1.7178194236475974, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 425, train_loss = 1.7169459238648415, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 426, train_loss = 1.7150633012643084, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 427, train_loss = 1.7132951829116791, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 428, train_loss = 1.7133923148503527, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 429, train_loss = 1.7129747904837132, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 430, train_loss = 1.7105857096612453, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 431, train_loss = 1.7097887707641348, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 432, train_loss = 1.7081438252935186, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 433, train_loss = 1.7072553659090772, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 434, train_loss = 1.707919014035724, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 435, train_loss = 1.7064585549524054, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 436, train_loss = 1.7054777555167675, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 437, train_loss = 1.704021766781807, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 438, train_loss = 1.7026964040705934, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 439, train_loss = 1.7019949220120907, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 440, train_loss = 1.7006333880126476, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 441, train_loss = 1.700152076780796, train_acc = 0.9956916627852818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 442, train_loss = 1.6993495660135522, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 443, train_loss = 1.6976574026048183, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 444, train_loss = 1.6972728198161349, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 445, train_loss = 1.696209855377674, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 446, train_loss = 1.6953512094914913, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 447, train_loss = 1.6942934915423393, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 448, train_loss = 1.6928709720959887, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 449, train_loss = 1.691748229204677, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 450, train_loss = 1.691184226423502, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 451, train_loss = 1.6904209976783022, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 452, train_loss = 1.6888325810432434, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 453, train_loss = 1.6897661747643724, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 454, train_loss = 1.6863536076853052, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 455, train_loss = 1.6866837330162525, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 456, train_loss = 1.685942088603042, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 457, train_loss = 1.6846137816319242, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 458, train_loss = 1.6847692927112803, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 459, train_loss = 1.6824298910796642, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 460, train_loss = 1.6807023286819458, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 461, train_loss = 1.6802658587694168, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 462, train_loss = 1.6795240541687235, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 463, train_loss = 1.6798043051967397, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 464, train_loss = 1.6778163276612759, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 465, train_loss = 1.6773828206351027, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 466, train_loss = 1.6767999654402956, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 467, train_loss = 1.6767883785068989, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 468, train_loss = 1.6754499016096815, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 469, train_loss = 1.674450290738605, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 470, train_loss = 1.6729886258253828, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 471, train_loss = 1.672241279273294, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 472, train_loss = 1.6717446061084047, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 473, train_loss = 1.6703501070151106, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 474, train_loss = 1.6692068303236738, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 475, train_loss = 1.669481035321951, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 476, train_loss = 1.668081541894935, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 477, train_loss = 1.6675341142108664, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 478, train_loss = 1.6661941459169611, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 479, train_loss = 1.6651432948419824, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 480, train_loss = 1.6648930571973324, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 481, train_loss = 1.6643340861191973, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 482, train_loss = 1.6641631001839414, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 483, train_loss = 1.6618937104940414, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 484, train_loss = 1.6617569588124752, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 485, train_loss = 1.661289987503551, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 486, train_loss = 1.6593544408679008, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 487, train_loss = 1.6601183587918058, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 488, train_loss = 1.6582072004675865, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 489, train_loss = 1.6581365106394514, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 490, train_loss = 1.65760698413942, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 491, train_loss = 1.6569520396878943, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 492, train_loss = 1.6549240946769714, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 493, train_loss = 1.655432735919021, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 494, train_loss = 1.6539382822811604, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 495, train_loss = 1.6537670145044103, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 496, train_loss = 1.6525177732110023, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 497, train_loss = 1.6517742486903444, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 498, train_loss = 1.6511752493679523, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 499, train_loss = 1.6505643129348755, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|██████████████████████████████████████████████████████████████▍         | 26/30 [3:55:21<36:12, 543.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "27th- epoch: 0, train_loss = 107.20833261311054, train_acc = 0.7902887750349324\n",
      "test Acc 0.8603351955307262:\n",
      "27th- epoch: 1, train_loss = 40.97393673658371, train_acc = 0.9146483465300419\n",
      "test Acc 0.8952513966480447:\n",
      "27th- epoch: 2, train_loss = 31.856340371072292, train_acc = 0.9338612016767582\n",
      "test Acc 0.9236499068901304:\n",
      "27th- epoch: 3, train_loss = 26.915815882384777, train_acc = 0.944108057755007\n",
      "test Acc 0.9376163873370578:\n",
      "27th- epoch: 4, train_loss = 23.58322962373495, train_acc = 0.9519096413600373\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 5, train_loss = 21.180729515850544, train_acc = 0.9568001863064741\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 6, train_loss = 19.340812880545855, train_acc = 0.9593619003260363\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 7, train_loss = 17.868444357067347, train_acc = 0.9622729389846297\n",
      "test Acc 0.952048417132216:\n",
      "27th- epoch: 8, train_loss = 16.65554114803672, train_acc = 0.9654168607359106\n",
      "test Acc 0.9529795158286778:\n",
      "27th- epoch: 9, train_loss = 15.632691837847233, train_acc = 0.9677456916627852\n",
      "test Acc 0.9543761638733705:\n",
      "27th- epoch: 10, train_loss = 14.747520636767149, train_acc = 0.9697251979506288\n",
      "test Acc 0.9548417132216015:\n",
      "27th- epoch: 11, train_loss = 13.976634703576565, train_acc = 0.9710060549604099\n",
      "test Acc 0.9548417132216015:\n",
      "27th- epoch: 12, train_loss = 13.309114638715982, train_acc = 0.9729855612482534\n",
      "test Acc 0.9557728119180633:\n",
      "27th- epoch: 13, train_loss = 12.710325557738543, train_acc = 0.9736842105263158\n",
      "test Acc 0.957635009310987:\n",
      "27th- epoch: 14, train_loss = 12.179896103218198, train_acc = 0.975780158360503\n",
      "test Acc 0.9594972067039106:\n",
      "27th- epoch: 15, train_loss = 11.706954998895526, train_acc = 0.9765952491849091\n",
      "test Acc 0.9604283054003724:\n",
      "27th- epoch: 16, train_loss = 11.275580672547221, train_acc = 0.9776432231020028\n",
      "test Acc 0.9608938547486033:\n",
      "27th- epoch: 17, train_loss = 10.881322916597128, train_acc = 0.9784583139264089\n",
      "test Acc 0.9618249534450651:\n",
      "27th- epoch: 18, train_loss = 10.515646426007152, train_acc = 0.9791569632044713\n",
      "test Acc 0.9636871508379888:\n",
      "27th- epoch: 19, train_loss = 10.180152079090476, train_acc = 0.9800884955752213\n",
      "test Acc 0.9636871508379888:\n",
      "27th- epoch: 20, train_loss = 9.874670865014195, train_acc = 0.9803213786679087\n",
      "test Acc 0.9636871508379888:\n",
      "27th- epoch: 21, train_loss = 9.587420547381043, train_acc = 0.9807871448532837\n",
      "test Acc 0.9636871508379888:\n",
      "27th- epoch: 22, train_loss = 9.314332677051425, train_acc = 0.9814857941313461\n",
      "test Acc 0.9646182495344506:\n",
      "27th- epoch: 23, train_loss = 9.061625696718693, train_acc = 0.9823008849557522\n",
      "test Acc 0.9655493482309124:\n",
      "27th- epoch: 24, train_loss = 8.82520991936326, train_acc = 0.9832324173265021\n",
      "test Acc 0.9655493482309124:\n",
      "27th- epoch: 25, train_loss = 8.60749451443553, train_acc = 0.9839310666045645\n",
      "test Acc 0.9660148975791434:\n",
      "27th- epoch: 26, train_loss = 8.39636741951108, train_acc = 0.984163949697252\n",
      "test Acc 0.9660148975791434:\n",
      "27th- epoch: 27, train_loss = 8.201500052586198, train_acc = 0.9843968327899395\n",
      "test Acc 0.9660148975791434:\n",
      "27th- epoch: 28, train_loss = 8.014349350705743, train_acc = 0.9847461574289706\n",
      "test Acc 0.9655493482309124:\n",
      "27th- epoch: 29, train_loss = 7.83944739215076, train_acc = 0.9849790405216581\n",
      "test Acc 0.9660148975791434:\n",
      "27th- epoch: 30, train_loss = 7.673695432022214, train_acc = 0.9848625989753144\n",
      "test Acc 0.9664804469273743:\n",
      "27th- epoch: 31, train_loss = 7.519022712484002, train_acc = 0.9849790405216581\n",
      "test Acc 0.9664804469273743:\n",
      "27th- epoch: 32, train_loss = 7.366276925429702, train_acc = 0.9853283651606893\n",
      "test Acc 0.9664804469273743:\n",
      "27th- epoch: 33, train_loss = 7.223593363538384, train_acc = 0.985910572892408\n",
      "test Acc 0.9678770949720671:\n",
      "27th- epoch: 34, train_loss = 7.086227711290121, train_acc = 0.986376339077783\n",
      "test Acc 0.9678770949720671:\n",
      "27th- epoch: 35, train_loss = 6.952113902196288, train_acc = 0.9866092221704704\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 36, train_loss = 6.824034815654159, train_acc = 0.9869585468095017\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 37, train_loss = 6.70406705327332, train_acc = 0.9870749883558454\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 38, train_loss = 6.589310022071004, train_acc = 0.9874243129948765\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 39, train_loss = 6.477642006240785, train_acc = 0.9874243129948765\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 40, train_loss = 6.373039864003658, train_acc = 0.9874243129948765\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 41, train_loss = 6.268260876648128, train_acc = 0.9876571960875641\n",
      "test Acc 0.9688081936685289:\n",
      "27th- epoch: 42, train_loss = 6.170940954238176, train_acc = 0.9878900791802515\n",
      "test Acc 0.9688081936685289:\n",
      "27th- epoch: 43, train_loss = 6.0757039384916425, train_acc = 0.9881229622729389\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 44, train_loss = 5.986142155714333, train_acc = 0.9881229622729389\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 45, train_loss = 5.898463263176382, train_acc = 0.9881229622729389\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 46, train_loss = 5.813307388685644, train_acc = 0.9883558453656265\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 47, train_loss = 5.732444872148335, train_acc = 0.9885887284583139\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 48, train_loss = 5.652639336884022, train_acc = 0.9885887284583139\n",
      "test Acc 0.9702048417132216:\n",
      "27th- epoch: 49, train_loss = 5.5767030864953995, train_acc = 0.9887051700046576\n",
      "test Acc 0.9702048417132216:\n",
      "27th- epoch: 50, train_loss = 5.504142834804952, train_acc = 0.9888216115510013\n",
      "test Acc 0.9702048417132216:\n",
      "27th- epoch: 51, train_loss = 5.43182385340333, train_acc = 0.9889380530973452\n",
      "test Acc 0.9702048417132216:\n",
      "27th- epoch: 52, train_loss = 5.3646121034398675, train_acc = 0.9891709361900326\n",
      "test Acc 0.9702048417132216:\n",
      "27th- epoch: 53, train_loss = 5.298521409742534, train_acc = 0.9891709361900326\n",
      "test Acc 0.9702048417132216:\n",
      "27th- epoch: 54, train_loss = 5.233899187296629, train_acc = 0.9895202608290639\n",
      "test Acc 0.9702048417132216:\n",
      "27th- epoch: 55, train_loss = 5.171156688593328, train_acc = 0.9895202608290639\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 56, train_loss = 5.108403202146292, train_acc = 0.9897531439217513\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 57, train_loss = 5.0498945424333215, train_acc = 0.9897531439217513\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 58, train_loss = 4.9914137898013, train_acc = 0.9897531439217513\n",
      "test Acc 0.9702048417132216:\n",
      "27th- epoch: 59, train_loss = 4.934018296189606, train_acc = 0.989869585468095\n",
      "test Acc 0.9706703910614525:\n",
      "27th- epoch: 60, train_loss = 4.880318998359144, train_acc = 0.9899860270144387\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 61, train_loss = 4.822950511239469, train_acc = 0.9899860270144387\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 62, train_loss = 4.772951547987759, train_acc = 0.9901024685607824\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 63, train_loss = 4.7216675309464335, train_acc = 0.99033535165347\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 64, train_loss = 4.672438272275031, train_acc = 0.9906846762925011\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 65, train_loss = 4.625969219952822, train_acc = 0.9906846762925011\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 66, train_loss = 4.581084051169455, train_acc = 0.990801117838845\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 67, train_loss = 4.535338920541108, train_acc = 0.9909175593851887\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 68, train_loss = 4.488910383544862, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 69, train_loss = 4.446781113743782, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 70, train_loss = 4.403650130145252, train_acc = 0.9912668840242198\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 71, train_loss = 4.362293706275523, train_acc = 0.9913833255705635\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 72, train_loss = 4.321336307562888, train_acc = 0.9913833255705635\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 73, train_loss = 4.283829345367849, train_acc = 0.9913833255705635\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 74, train_loss = 4.244599063880742, train_acc = 0.9918490917559385\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 75, train_loss = 4.205376830883324, train_acc = 0.9918490917559385\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 76, train_loss = 4.166532479226589, train_acc = 0.9918490917559385\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 77, train_loss = 4.127433565445244, train_acc = 0.9918490917559385\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 78, train_loss = 4.092171764932573, train_acc = 0.9918490917559385\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 79, train_loss = 4.057243952527642, train_acc = 0.9919655333022822\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 80, train_loss = 4.023889824748039, train_acc = 0.9919655333022822\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 81, train_loss = 3.991066093556583, train_acc = 0.9919655333022822\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 82, train_loss = 3.957850850187242, train_acc = 0.992081974848626\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 83, train_loss = 3.9264310486614704, train_acc = 0.9919655333022822\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 84, train_loss = 3.8947943416424096, train_acc = 0.992081974848626\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 85, train_loss = 3.8659464702941477, train_acc = 0.992081974848626\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 86, train_loss = 3.835047259926796, train_acc = 0.992081974848626\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 87, train_loss = 3.8050349722616374, train_acc = 0.992081974848626\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 88, train_loss = 3.776953167747706, train_acc = 0.992081974848626\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 89, train_loss = 3.7493931599892676, train_acc = 0.992081974848626\n",
      "test Acc 0.9720670391061452:\n",
      "27th- epoch: 90, train_loss = 3.7220453061163425, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "27th- epoch: 91, train_loss = 3.693970948457718, train_acc = 0.9921984163949698\n",
      "test Acc 0.9720670391061452:\n",
      "27th- epoch: 92, train_loss = 3.6682528820820153, train_acc = 0.9923148579413135\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 93, train_loss = 3.6424429048784077, train_acc = 0.9924312994876572\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 94, train_loss = 3.617659155279398, train_acc = 0.9924312994876572\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 95, train_loss = 3.5915204524062574, train_acc = 0.9924312994876572\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 96, train_loss = 3.566030688583851, train_acc = 0.9925477410340009\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 97, train_loss = 3.542896377388388, train_acc = 0.9926641825803446\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 98, train_loss = 3.518124828580767, train_acc = 0.9926641825803446\n",
      "test Acc 0.973463687150838:\n",
      "27th- epoch: 99, train_loss = 3.49592105159536, train_acc = 0.9926641825803446\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 100, train_loss = 3.472182413097471, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 101, train_loss = 3.448847947176546, train_acc = 0.9926641825803446\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 102, train_loss = 3.4284064793027937, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 103, train_loss = 3.4057703255675733, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 104, train_loss = 3.38514706492424, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 105, train_loss = 3.362684285733849, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 106, train_loss = 3.3436182378791273, train_acc = 0.9930135072193759\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 107, train_loss = 3.321902467403561, train_acc = 0.9930135072193759\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 108, train_loss = 3.3023883141577244, train_acc = 0.9930135072193759\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 109, train_loss = 3.2819270663894713, train_acc = 0.9930135072193759\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 110, train_loss = 3.263800512999296, train_acc = 0.9930135072193759\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 111, train_loss = 3.2430840670131147, train_acc = 0.9930135072193759\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 112, train_loss = 3.224458646029234, train_acc = 0.9931299487657196\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 113, train_loss = 3.2069657049141824, train_acc = 0.9931299487657196\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 114, train_loss = 3.1889506988227367, train_acc = 0.9931299487657196\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 115, train_loss = 3.169258326292038, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 116, train_loss = 3.1528719612397254, train_acc = 0.9933628318584071\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 117, train_loss = 3.1358295581303537, train_acc = 0.9933628318584071\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 118, train_loss = 3.1163385226391256, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 119, train_loss = 3.1016109785996377, train_acc = 0.9932463903120633\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 120, train_loss = 3.083385122474283, train_acc = 0.9933628318584071\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 121, train_loss = 3.0663501494564116, train_acc = 0.9933628318584071\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 122, train_loss = 3.052566887345165, train_acc = 0.9933628318584071\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 123, train_loss = 3.0348462513647974, train_acc = 0.993828598043782\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 124, train_loss = 3.0201735817827284, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 125, train_loss = 3.0038122883997858, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 126, train_loss = 2.989116864744574, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 127, train_loss = 2.973984818905592, train_acc = 0.9939450395901258\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 128, train_loss = 2.9574606493115425, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 129, train_loss = 2.9440546818077564, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 130, train_loss = 2.9293035590089858, train_acc = 0.9939450395901258\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 131, train_loss = 2.9142777360975742, train_acc = 0.9939450395901258\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 132, train_loss = 2.901157559361309, train_acc = 0.9939450395901258\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 133, train_loss = 2.8862758302129805, train_acc = 0.9939450395901258\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 134, train_loss = 2.873319944832474, train_acc = 0.9939450395901258\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 135, train_loss = 2.8597036958672106, train_acc = 0.9939450395901258\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 136, train_loss = 2.8466551154851913, train_acc = 0.9939450395901258\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 137, train_loss = 2.8340198225341737, train_acc = 0.9939450395901258\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 138, train_loss = 2.820445982273668, train_acc = 0.9939450395901258\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 139, train_loss = 2.8080298877321184, train_acc = 0.9940614811364695\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 140, train_loss = 2.7961163916625082, train_acc = 0.9941779226828132\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 141, train_loss = 2.783648447599262, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 142, train_loss = 2.7705894485116005, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 143, train_loss = 2.7596327923238277, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 144, train_loss = 2.747609557118267, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 145, train_loss = 2.7355077392421663, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 146, train_loss = 2.7238217652775347, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 147, train_loss = 2.712434289511293, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 148, train_loss = 2.7020048201084137, train_acc = 0.9941779226828132\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 149, train_loss = 2.6904376335442066, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 150, train_loss = 2.680219101253897, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 151, train_loss = 2.669344112277031, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 152, train_loss = 2.6589065841399133, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 153, train_loss = 2.6485886748414487, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 154, train_loss = 2.6388599935453385, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 155, train_loss = 2.6286560520529747, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 156, train_loss = 2.6186917796730995, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 157, train_loss = 2.6088580414652824, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 158, train_loss = 2.598711345344782, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 159, train_loss = 2.5899560500402004, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 160, train_loss = 2.580094775883481, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 161, train_loss = 2.570132616907358, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 162, train_loss = 2.5613260455429554, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 163, train_loss = 2.5529738639015704, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 164, train_loss = 2.543055657297373, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 165, train_loss = 2.5354834895115346, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 166, train_loss = 2.5256737049203366, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 167, train_loss = 2.5175717312376946, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 168, train_loss = 2.5099606823641807, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 169, train_loss = 2.500205960124731, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 170, train_loss = 2.4918812699615955, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 171, train_loss = 2.483971582027152, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 172, train_loss = 2.4768154236953706, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 173, train_loss = 2.4674089688342065, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 174, train_loss = 2.460981858195737, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 175, train_loss = 2.4524682376068085, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 176, train_loss = 2.444389156997204, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 177, train_loss = 2.4373594236094505, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 178, train_loss = 2.430516575695947, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 179, train_loss = 2.420932261971757, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 180, train_loss = 2.414886811049655, train_acc = 0.9945272473218444\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 181, train_loss = 2.40740201738663, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 182, train_loss = 2.4011498962063342, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 183, train_loss = 2.392335745273158, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 184, train_loss = 2.385984171181917, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 185, train_loss = 2.3805763099808246, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 186, train_loss = 2.372328373370692, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 187, train_loss = 2.3655029211658984, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 188, train_loss = 2.359884649515152, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 189, train_loss = 2.3533853366971016, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 190, train_loss = 2.345658128382638, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 191, train_loss = 2.340087056159973, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 192, train_loss = 2.333754900842905, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 193, train_loss = 2.3275842878501862, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 194, train_loss = 2.321762355742976, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 195, train_loss = 2.3147766266483814, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 196, train_loss = 2.309374847682193, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 197, train_loss = 2.303110383450985, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 198, train_loss = 2.29710790514946, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 199, train_loss = 2.2915018920321018, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 200, train_loss = 2.2859990422148257, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 201, train_loss = 2.280279563041404, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 202, train_loss = 2.274347507627681, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 203, train_loss = 2.2691123101394624, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 204, train_loss = 2.263052609981969, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 205, train_loss = 2.2576742644887418, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 206, train_loss = 2.252284351736307, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 207, train_loss = 2.2460751347243786, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 208, train_loss = 2.240421262802556, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 209, train_loss = 2.2358404647093266, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 210, train_loss = 2.230434379307553, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 211, train_loss = 2.2257388543803245, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 212, train_loss = 2.220286390511319, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 213, train_loss = 2.214754005195573, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 214, train_loss = 2.211131951538846, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 215, train_loss = 2.205730934860185, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 216, train_loss = 2.199527982622385, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 217, train_loss = 2.194911640137434, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 218, train_loss = 2.19063513353467, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 219, train_loss = 2.1857578195631504, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 220, train_loss = 2.1818882699590176, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 221, train_loss = 2.176809997530654, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 222, train_loss = 2.1717439491767436, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 223, train_loss = 2.1678574681282043, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 224, train_loss = 2.162654958665371, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 225, train_loss = 2.1574748170096427, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 226, train_loss = 2.154202352045104, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 227, train_loss = 2.1495084315538406, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 228, train_loss = 2.1446314118802547, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 229, train_loss = 2.1401327252388, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 230, train_loss = 2.1358639548998326, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 231, train_loss = 2.13208569586277, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 232, train_loss = 2.1273534309584647, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 233, train_loss = 2.122658108593896, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 234, train_loss = 2.1186960216145962, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 235, train_loss = 2.1152365568559617, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 236, train_loss = 2.1107554074842483, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 237, train_loss = 2.106965158134699, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 238, train_loss = 2.1039952374994755, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 239, train_loss = 2.0986753802280873, train_acc = 0.9948765719608756\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 240, train_loss = 2.0949558143038303, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 241, train_loss = 2.0908685128670186, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 242, train_loss = 2.087832074612379, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 243, train_loss = 2.0826832975726575, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 244, train_loss = 2.08027246594429, train_acc = 0.9949930135072194\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 245, train_loss = 2.0759310859721154, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 246, train_loss = 2.0719239253085107, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 247, train_loss = 2.068406586884521, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 248, train_loss = 2.065209121792577, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 249, train_loss = 2.0617115758359432, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 250, train_loss = 2.0581291703274474, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 251, train_loss = 2.0544845486292616, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 252, train_loss = 2.0503552965819836, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 253, train_loss = 2.047548251808621, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 254, train_loss = 2.043409482925199, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 255, train_loss = 2.0400718189775944, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 256, train_loss = 2.0362722562858835, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 257, train_loss = 2.0329873947193846, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 258, train_loss = 2.030013491748832, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 259, train_loss = 2.0269713239977136, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 260, train_loss = 2.0231193639338017, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 261, train_loss = 2.0199019549181685, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 262, train_loss = 2.0161502981791273, train_acc = 0.9951094550535631\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 263, train_loss = 2.0133769623935223, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 264, train_loss = 2.0099813044071198, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 265, train_loss = 2.007105747819878, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 266, train_loss = 2.004629479139112, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 267, train_loss = 2.0005313120782375, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 268, train_loss = 1.9976125893881544, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 269, train_loss = 1.9944028556346893, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 270, train_loss = 1.9917117208242416, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 271, train_loss = 1.989143089740537, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 272, train_loss = 1.9852595193078741, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 273, train_loss = 1.9819664222886786, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 274, train_loss = 1.9798544185468927, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 275, train_loss = 1.9768880779156461, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 276, train_loss = 1.9732945176074281, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 277, train_loss = 1.9705725783715025, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 278, train_loss = 1.9679082743823528, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 279, train_loss = 1.965035201399587, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 280, train_loss = 1.9627338337013498, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 281, train_loss = 1.9593921886989847, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 282, train_loss = 1.9567985149333254, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 283, train_loss = 1.953686741529964, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 284, train_loss = 1.9512447826564312, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 285, train_loss = 1.9492830348899588, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 286, train_loss = 1.946089755743742, train_acc = 0.9952258965999069\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 287, train_loss = 1.9438731881091371, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 288, train_loss = 1.940520204603672, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 289, train_loss = 1.9381650686264038, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 290, train_loss = 1.9358157751848921, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 291, train_loss = 1.9332601502537727, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 292, train_loss = 1.930596967577003, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 293, train_loss = 1.927121177315712, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 294, train_loss = 1.9263576393714175, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 295, train_loss = 1.9222658202052116, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 296, train_loss = 1.9206569083034992, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 297, train_loss = 1.9179661398520693, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 298, train_loss = 1.9162435246398672, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 299, train_loss = 1.9133015660336241, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 300, train_loss = 1.910936220199801, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 301, train_loss = 1.9092831885209307, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 302, train_loss = 1.9061135525116697, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 303, train_loss = 1.9049343144288287, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 304, train_loss = 1.9010996632277966, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 305, train_loss = 1.898692037910223, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 306, train_loss = 1.8961931429803371, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 307, train_loss = 1.8936628563096747, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 308, train_loss = 1.891166371642612, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 309, train_loss = 1.888434505672194, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 310, train_loss = 1.886208575218916, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 311, train_loss = 1.88351869082544, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 312, train_loss = 1.881307777017355, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 313, train_loss = 1.8794363749912009, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 314, train_loss = 1.877552356570959, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 315, train_loss = 1.8747907740762457, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 316, train_loss = 1.8729117686161771, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 317, train_loss = 1.8708926849067211, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 318, train_loss = 1.8683607975253835, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 319, train_loss = 1.8661496440181509, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 320, train_loss = 1.8634134009480476, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 321, train_loss = 1.8632504058768973, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 322, train_loss = 1.859929621219635, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 323, train_loss = 1.8578956263372675, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 324, train_loss = 1.855937677086331, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 325, train_loss = 1.8539717234671116, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 326, train_loss = 1.8527032943675295, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 327, train_loss = 1.8496494354913011, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 328, train_loss = 1.8480512388050556, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 329, train_loss = 1.8456446094205603, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 330, train_loss = 1.8441694974899292, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 331, train_loss = 1.8427257438888773, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 332, train_loss = 1.8402402276406065, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 333, train_loss = 1.8378631310770288, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 334, train_loss = 1.8372940855333582, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 335, train_loss = 1.834907129406929, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 336, train_loss = 1.8322731418302283, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 337, train_loss = 1.831555531709455, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 338, train_loss = 1.8288344765314832, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 339, train_loss = 1.8271990418434143, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 340, train_loss = 1.8254340129205957, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 341, train_loss = 1.8241299390792847, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 342, train_loss = 1.8216372517636046, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 343, train_loss = 1.8193778904387727, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 344, train_loss = 1.8191397711634636, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 345, train_loss = 1.8166642835130915, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 346, train_loss = 1.8149428156903014, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 347, train_loss = 1.81267721822951, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 348, train_loss = 1.8117881926009431, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 349, train_loss = 1.8102474896004423, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 350, train_loss = 1.808527068584226, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 351, train_loss = 1.8060234176227823, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 352, train_loss = 1.8048134036362171, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 353, train_loss = 1.8032525777816772, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 354, train_loss = 1.8018241511890665, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 355, train_loss = 1.7996186738600954, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 356, train_loss = 1.798359659849666, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 357, train_loss = 1.7971255630254745, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 358, train_loss = 1.7952191146323457, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 359, train_loss = 1.7930178506067023, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 360, train_loss = 1.7915920851519331, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 361, train_loss = 1.7903710914542899, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 362, train_loss = 1.7892952933907509, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 363, train_loss = 1.7870245389640331, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 364, train_loss = 1.7851563891163096, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 365, train_loss = 1.7852450521895662, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 366, train_loss = 1.7830570811638609, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 367, train_loss = 1.78144244721625, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 368, train_loss = 1.779647889197804, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 369, train_loss = 1.7779228774597868, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 370, train_loss = 1.7762401787331328, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 371, train_loss = 1.7753512896597385, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 372, train_loss = 1.7742324024438858, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 373, train_loss = 1.7732331231236458, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 374, train_loss = 1.7707951193442568, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 375, train_loss = 1.769650430767797, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 376, train_loss = 1.7669740902492777, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 377, train_loss = 1.7668817477533594, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 378, train_loss = 1.7657130993902683, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 379, train_loss = 1.7638761376729235, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 380, train_loss = 1.7625297295162454, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 381, train_loss = 1.7615551700582728, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 382, train_loss = 1.760322599322535, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 383, train_loss = 1.7584440521895885, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 384, train_loss = 1.7568781102309003, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 385, train_loss = 1.7556120144436136, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 386, train_loss = 1.7541484100511298, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 387, train_loss = 1.7530697969486937, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 388, train_loss = 1.7513816753635183, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 389, train_loss = 1.7500920481979847, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 390, train_loss = 1.749189260066487, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 391, train_loss = 1.7469506511697546, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 392, train_loss = 1.7464504726231098, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 393, train_loss = 1.7455457150936127, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 394, train_loss = 1.743271427869331, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 395, train_loss = 1.742361096024979, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 396, train_loss = 1.740907120227348, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 397, train_loss = 1.7403636748786084, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 398, train_loss = 1.7384195812046528, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 399, train_loss = 1.736676813394297, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 400, train_loss = 1.7361865229904652, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 401, train_loss = 1.7351430070702918, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 402, train_loss = 1.7341662285034545, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 403, train_loss = 1.7319559032912366, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 404, train_loss = 1.7312061848933809, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 405, train_loss = 1.7293666377663612, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 406, train_loss = 1.7292595927719958, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 407, train_loss = 1.7276626924867742, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 408, train_loss = 1.7269001168315299, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 409, train_loss = 1.725336832285393, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 410, train_loss = 1.7238815799355507, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 411, train_loss = 1.722860123962164, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 412, train_loss = 1.721885462582577, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 413, train_loss = 1.7213033574516885, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 414, train_loss = 1.7194057839806192, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 415, train_loss = 1.7185054371948354, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 416, train_loss = 1.7178620311315171, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 417, train_loss = 1.7160121177439578, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 418, train_loss = 1.7143452639575116, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 419, train_loss = 1.7146786761586554, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 420, train_loss = 1.7128263339400291, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 421, train_loss = 1.7116691805422306, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 422, train_loss = 1.7114017394487746, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 423, train_loss = 1.7105006066267379, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 424, train_loss = 1.708468762517441, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 425, train_loss = 1.707311065227259, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 426, train_loss = 1.7070729385013692, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 427, train_loss = 1.705516867339611, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 428, train_loss = 1.7034152634441853, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 429, train_loss = 1.7028836359386332, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 430, train_loss = 1.702726534276735, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 431, train_loss = 1.7012791757588275, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 432, train_loss = 1.7005348379607312, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 433, train_loss = 1.6993065290153027, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 434, train_loss = 1.6976399309933186, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 435, train_loss = 1.6975234771962278, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 436, train_loss = 1.6964975993032567, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 437, train_loss = 1.6952077982132323, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 438, train_loss = 1.6939610727131367, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 439, train_loss = 1.6937586751882918, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 440, train_loss = 1.692229013890028, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 441, train_loss = 1.6915498289163224, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 442, train_loss = 1.6906888373196125, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 443, train_loss = 1.6895108471508138, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 444, train_loss = 1.6884255793993361, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 445, train_loss = 1.6883440564270131, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 446, train_loss = 1.6865346257691272, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 447, train_loss = 1.6853536342387088, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 448, train_loss = 1.685012357949745, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 449, train_loss = 1.6840335341985337, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 450, train_loss = 1.683171834796667, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 451, train_loss = 1.6817222746904008, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 452, train_loss = 1.6809256672859192, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 453, train_loss = 1.6797964821453206, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 454, train_loss = 1.6793146915733814, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 455, train_loss = 1.6793652710621245, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 456, train_loss = 1.6771920720930211, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 457, train_loss = 1.6771401924197562, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 458, train_loss = 1.6757857166230679, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 459, train_loss = 1.6751732851262204, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 460, train_loss = 1.6741380542516708, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 461, train_loss = 1.6733233642880805, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 462, train_loss = 1.671913271129597, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 463, train_loss = 1.67177663493203, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 464, train_loss = 1.670610858767759, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 465, train_loss = 1.6686514702741988, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 466, train_loss = 1.6691394771332853, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 467, train_loss = 1.6673144822125323, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 468, train_loss = 1.6663170494139194, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 469, train_loss = 1.6666139587759972, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 470, train_loss = 1.6651868559420109, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 471, train_loss = 1.6641950358753093, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 472, train_loss = 1.6624257825314999, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 473, train_loss = 1.6631842516362667, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 474, train_loss = 1.6613740275497548, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 475, train_loss = 1.6613407296244986, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 476, train_loss = 1.660435692698229, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 477, train_loss = 1.6597222052514553, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 478, train_loss = 1.6588858415489085, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 479, train_loss = 1.6577494405210018, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 480, train_loss = 1.6563899777829647, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 481, train_loss = 1.6565577338333242, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 482, train_loss = 1.6563234615023248, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 483, train_loss = 1.654390184849035, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 484, train_loss = 1.6537141961161979, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 485, train_loss = 1.6527238811249845, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 486, train_loss = 1.653361540287733, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 487, train_loss = 1.6522896600072272, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 488, train_loss = 1.6508802634780295, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 489, train_loss = 1.6502759829163551, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 490, train_loss = 1.6485545945470221, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 491, train_loss = 1.6485500037670135, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 492, train_loss = 1.6476535275578499, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 493, train_loss = 1.6468685679137707, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 494, train_loss = 1.6460389730636962, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 495, train_loss = 1.6459632143378258, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 496, train_loss = 1.6448047757148743, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 497, train_loss = 1.6443428086931817, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 498, train_loss = 1.6432084788684733, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 499, train_loss = 1.6428258903324604, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████▊       | 27/30 [4:04:25<27:09, 543.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "28th- epoch: 0, train_loss = 106.18086077272892, train_acc = 0.7968095016301816\n",
      "test Acc 0.888733705772812:\n",
      "28th- epoch: 1, train_loss = 41.29218380898237, train_acc = 0.9161620866325105\n",
      "test Acc 0.9269087523277467:\n",
      "28th- epoch: 2, train_loss = 31.784854017198086, train_acc = 0.936655798789008\n",
      "test Acc 0.9413407821229051:\n",
      "28th- epoch: 3, train_loss = 26.97260106354952, train_acc = 0.945854680950163\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 4, train_loss = 23.717313654720783, train_acc = 0.9534233814625058\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 5, train_loss = 21.29383822903037, train_acc = 0.9572659524918491\n",
      "test Acc 0.9511173184357542:\n",
      "28th- epoch: 6, train_loss = 19.371428068727255, train_acc = 0.9607591988821611\n",
      "test Acc 0.9543761638733705:\n",
      "28th- epoch: 7, train_loss = 17.829610127955675, train_acc = 0.9640195621797858\n",
      "test Acc 0.9557728119180633:\n",
      "28th- epoch: 8, train_loss = 16.553671777248383, train_acc = 0.966115510013973\n",
      "test Acc 0.9585661080074488:\n",
      "28th- epoch: 9, train_loss = 15.48107448592782, train_acc = 0.9686772240335352\n",
      "test Acc 0.9599627560521415:\n",
      "28th- epoch: 10, train_loss = 14.56953327730298, train_acc = 0.9710060549604099\n",
      "test Acc 0.9604283054003724:\n",
      "28th- epoch: 11, train_loss = 13.786601454019547, train_acc = 0.9724033535165347\n",
      "test Acc 0.9613594040968343:\n",
      "28th- epoch: 12, train_loss = 13.108009438961744, train_acc = 0.9739170936190032\n",
      "test Acc 0.9618249534450651:\n",
      "28th- epoch: 13, train_loss = 12.514502255246043, train_acc = 0.9750815090824406\n",
      "test Acc 0.9622905027932961:\n",
      "28th- epoch: 14, train_loss = 11.987886575981975, train_acc = 0.9764788076385654\n",
      "test Acc 0.962756052141527:\n",
      "28th- epoch: 15, train_loss = 11.511352811008692, train_acc = 0.9777596646483465\n",
      "test Acc 0.9641527001862198:\n",
      "28th- epoch: 16, train_loss = 11.083604108542204, train_acc = 0.9790405216581276\n",
      "test Acc 0.9655493482309124:\n",
      "28th- epoch: 17, train_loss = 10.691365733742714, train_acc = 0.9796227293898463\n",
      "test Acc 0.9655493482309124:\n",
      "28th- epoch: 18, train_loss = 10.326040055602789, train_acc = 0.9803213786679087\n",
      "test Acc 0.9664804469273743:\n",
      "28th- epoch: 19, train_loss = 9.993324413895607, train_acc = 0.9810200279459711\n",
      "test Acc 0.9674115456238361:\n",
      "28th- epoch: 20, train_loss = 9.684600479900837, train_acc = 0.9817186772240335\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 21, train_loss = 9.398946786299348, train_acc = 0.9823008849557522\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 22, train_loss = 9.133469074964523, train_acc = 0.9827666511411272\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 23, train_loss = 8.889254046604037, train_acc = 0.9831159757801584\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 24, train_loss = 8.656928332522511, train_acc = 0.9834653004191896\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 25, train_loss = 8.438780412077904, train_acc = 0.9839310666045645\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 26, train_loss = 8.228506160899997, train_acc = 0.9843968327899395\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 27, train_loss = 8.031492915004492, train_acc = 0.9846297158826269\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 28, train_loss = 7.843191962689161, train_acc = 0.9852119236143456\n",
      "test Acc 0.9697392923649907:\n",
      "28th- epoch: 29, train_loss = 7.666122768074274, train_acc = 0.9852119236143456\n",
      "test Acc 0.9702048417132216:\n",
      "28th- epoch: 30, train_loss = 7.4959626123309135, train_acc = 0.9860270144387517\n",
      "test Acc 0.9702048417132216:\n",
      "28th- epoch: 31, train_loss = 7.333186884410679, train_acc = 0.9861434559850955\n",
      "test Acc 0.9702048417132216:\n",
      "28th- epoch: 32, train_loss = 7.178380001336336, train_acc = 0.986376339077783\n",
      "test Acc 0.9706703910614525:\n",
      "28th- epoch: 33, train_loss = 7.031585842370987, train_acc = 0.9866092221704704\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 34, train_loss = 6.889626827090979, train_acc = 0.9867256637168141\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 35, train_loss = 6.751174800097942, train_acc = 0.9869585468095017\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 36, train_loss = 6.620122321881354, train_acc = 0.9869585468095017\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 37, train_loss = 6.493730855174363, train_acc = 0.9873078714485328\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 38, train_loss = 6.372142367064953, train_acc = 0.9873078714485328\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 39, train_loss = 6.25646626483649, train_acc = 0.9880065207265952\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 40, train_loss = 6.144644116051495, train_acc = 0.9880065207265952\n",
      "test Acc 0.9706703910614525:\n",
      "28th- epoch: 41, train_loss = 6.036713544279337, train_acc = 0.9882394038192828\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 42, train_loss = 5.930513643659651, train_acc = 0.9882394038192828\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 43, train_loss = 5.828280217945576, train_acc = 0.9883558453656265\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 44, train_loss = 5.73147398699075, train_acc = 0.9884722869119702\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 45, train_loss = 5.63691050093621, train_acc = 0.9887051700046576\n",
      "test Acc 0.9716014897579144:\n",
      "28th- epoch: 46, train_loss = 5.548168794251978, train_acc = 0.9888216115510013\n",
      "test Acc 0.9716014897579144:\n",
      "28th- epoch: 47, train_loss = 5.4616385055705905, train_acc = 0.9889380530973452\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 48, train_loss = 5.377483904361725, train_acc = 0.9890544946436889\n",
      "test Acc 0.9725325884543762:\n",
      "28th- epoch: 49, train_loss = 5.295603637583554, train_acc = 0.9891709361900326\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 50, train_loss = 5.215428316034377, train_acc = 0.9891709361900326\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 51, train_loss = 5.137980100698769, train_acc = 0.9891709361900326\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 52, train_loss = 5.063124291598797, train_acc = 0.98940381928272\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 53, train_loss = 4.991339053958654, train_acc = 0.9895202608290639\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 54, train_loss = 4.921733456663787, train_acc = 0.9895202608290639\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 55, train_loss = 4.853025422431529, train_acc = 0.989869585468095\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 56, train_loss = 4.7896130355075, train_acc = 0.9901024685607824\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 57, train_loss = 4.724524185061455, train_acc = 0.9901024685607824\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 58, train_loss = 4.663574821315706, train_acc = 0.9904517931998137\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 59, train_loss = 4.603108790703118, train_acc = 0.9910340009315324\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 60, train_loss = 4.545093995518982, train_acc = 0.9910340009315324\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 61, train_loss = 4.488558477722108, train_acc = 0.9910340009315324\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 62, train_loss = 4.433592827059329, train_acc = 0.9912668840242198\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 63, train_loss = 4.38144086766988, train_acc = 0.9914997671169073\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 64, train_loss = 4.327426265925169, train_acc = 0.9914997671169073\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 65, train_loss = 4.279910195618868, train_acc = 0.9916162086632511\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 66, train_loss = 4.230490489862859, train_acc = 0.9916162086632511\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 67, train_loss = 4.1829268001019955, train_acc = 0.9917326502095948\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 68, train_loss = 4.138961475342512, train_acc = 0.9917326502095948\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 69, train_loss = 4.094752795994282, train_acc = 0.9919655333022822\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 70, train_loss = 4.051339082419872, train_acc = 0.9919655333022822\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 71, train_loss = 4.010183928068727, train_acc = 0.9919655333022822\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 72, train_loss = 3.967965750489384, train_acc = 0.992081974848626\n",
      "test Acc 0.9739292364990689:\n",
      "28th- epoch: 73, train_loss = 3.928875608369708, train_acc = 0.9921984163949698\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 74, train_loss = 3.8904754780232906, train_acc = 0.9923148579413135\n",
      "test Acc 0.9739292364990689:\n",
      "28th- epoch: 75, train_loss = 3.852974556386471, train_acc = 0.9923148579413135\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 76, train_loss = 3.8147872085683048, train_acc = 0.9923148579413135\n",
      "test Acc 0.9739292364990689:\n",
      "28th- epoch: 77, train_loss = 3.780384859070182, train_acc = 0.9923148579413135\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 78, train_loss = 3.745138056576252, train_acc = 0.9924312994876572\n",
      "test Acc 0.9739292364990689:\n",
      "28th- epoch: 79, train_loss = 3.712088495492935, train_acc = 0.9921984163949698\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 80, train_loss = 3.677444309461862, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 81, train_loss = 3.6455035801045597, train_acc = 0.9925477410340009\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 82, train_loss = 3.6141469017602503, train_acc = 0.9925477410340009\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 83, train_loss = 3.5844311439432204, train_acc = 0.9925477410340009\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 84, train_loss = 3.5549921528436244, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 85, train_loss = 3.5260430672205985, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 86, train_loss = 3.495622757356614, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 87, train_loss = 3.470780754927546, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 88, train_loss = 3.442238053306937, train_acc = 0.9925477410340009\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 89, train_loss = 3.4146689013577998, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 90, train_loss = 3.3895128802396357, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 91, train_loss = 3.364146532025188, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 92, train_loss = 3.339302446693182, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 93, train_loss = 3.312374154571444, train_acc = 0.9930135072193759\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 94, train_loss = 3.29297950072214, train_acc = 0.9930135072193759\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 95, train_loss = 3.2673231712542474, train_acc = 0.9931299487657196\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 96, train_loss = 3.24473974108696, train_acc = 0.9931299487657196\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 97, train_loss = 3.2228495688177645, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 98, train_loss = 3.200842435937375, train_acc = 0.9934792734047508\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 99, train_loss = 3.1805684720166028, train_acc = 0.9934792734047508\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 100, train_loss = 3.1593282260000706, train_acc = 0.9935957149510946\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 101, train_loss = 3.1399022289551795, train_acc = 0.9937121564974383\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 102, train_loss = 3.117224978748709, train_acc = 0.9937121564974383\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 103, train_loss = 3.0994184934534132, train_acc = 0.9937121564974383\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 104, train_loss = 3.080381464213133, train_acc = 0.9937121564974383\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 105, train_loss = 3.0619056499563158, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 106, train_loss = 3.042794825974852, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 107, train_loss = 3.0263881548307836, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 108, train_loss = 3.0069321752525866, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 109, train_loss = 2.989829717669636, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 110, train_loss = 2.9728433615528047, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 111, train_loss = 2.9565425403416157, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 112, train_loss = 2.939227456692606, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 113, train_loss = 2.9251553029753268, train_acc = 0.9940614811364695\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 114, train_loss = 2.9073282754980028, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 115, train_loss = 2.893944801297039, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 116, train_loss = 2.8780791498720646, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 117, train_loss = 2.8627246669493616, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 118, train_loss = 2.84681456675753, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 119, train_loss = 2.8331190585158765, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 120, train_loss = 2.817853331565857, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 121, train_loss = 2.8051169677637517, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 122, train_loss = 2.7895082742907107, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 123, train_loss = 2.7775877341628075, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 124, train_loss = 2.7625796608626842, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 125, train_loss = 2.7509112656116486, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 126, train_loss = 2.7369718975387514, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 127, train_loss = 2.725443534553051, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 128, train_loss = 2.711560634430498, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 129, train_loss = 2.70144821703434, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 130, train_loss = 2.6881227283738554, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 131, train_loss = 2.67628156254068, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 132, train_loss = 2.6642237827181816, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 133, train_loss = 2.6543636112473905, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 134, train_loss = 2.6399181559681892, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 135, train_loss = 2.6315085501410067, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 136, train_loss = 2.619814561214298, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 137, train_loss = 2.608751537743956, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 138, train_loss = 2.5994209214113653, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 139, train_loss = 2.587841509375721, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 140, train_loss = 2.577893613371998, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 141, train_loss = 2.5687111518345773, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 142, train_loss = 2.5567507459782064, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 143, train_loss = 2.5489768176339567, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 144, train_loss = 2.537416855338961, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 145, train_loss = 2.528800930827856, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 146, train_loss = 2.51853974792175, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 147, train_loss = 2.5089298498351127, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 148, train_loss = 2.5013766835909337, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 149, train_loss = 2.4907740615308285, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 150, train_loss = 2.4835911605041474, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 151, train_loss = 2.47420393046923, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 152, train_loss = 2.4661111894529313, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 153, train_loss = 2.4570846781134605, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 154, train_loss = 2.4480806414503604, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 155, train_loss = 2.4413435098249465, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 156, train_loss = 2.4319945860188454, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 157, train_loss = 2.4244366113562137, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 158, train_loss = 2.4156414556782693, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 159, train_loss = 2.4087920251768082, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 160, train_loss = 2.3996239143889397, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 161, train_loss = 2.3919682018458843, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 162, train_loss = 2.3840491014998406, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 163, train_loss = 2.3774494517128915, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 164, train_loss = 2.3690404258668423, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 165, train_loss = 2.3617001038510352, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 166, train_loss = 2.3545997191686183, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 167, train_loss = 2.3466518595814705, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 168, train_loss = 2.340735438046977, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 169, train_loss = 2.3341193795204163, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 170, train_loss = 2.3280962358694524, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 171, train_loss = 2.320409916341305, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 172, train_loss = 2.3144689749460667, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 173, train_loss = 2.3094801008701324, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 174, train_loss = 2.3019062143284827, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 175, train_loss = 2.295674802036956, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 176, train_loss = 2.289139714092016, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 177, train_loss = 2.2835492331068963, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 178, train_loss = 2.27678066608496, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 179, train_loss = 2.2703906521201134, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 180, train_loss = 2.265003252774477, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 181, train_loss = 2.2582233634311706, train_acc = 0.9951094550535631\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 182, train_loss = 2.251829609274864, train_acc = 0.9951094550535631\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 183, train_loss = 2.2475891560316086, train_acc = 0.9951094550535631\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 184, train_loss = 2.2412913080770522, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 185, train_loss = 2.234818874625489, train_acc = 0.9951094550535631\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 186, train_loss = 2.2299159828107804, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 187, train_loss = 2.2243412274401635, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 188, train_loss = 2.218985928921029, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 189, train_loss = 2.2132081885356456, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 190, train_loss = 2.2081309508066624, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 191, train_loss = 2.202989401994273, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 192, train_loss = 2.1980322562158108, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 193, train_loss = 2.1926975685637444, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 194, train_loss = 2.187404381809756, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 195, train_loss = 2.182077430188656, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 196, train_loss = 2.1773811392486095, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 197, train_loss = 2.172456182539463, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 198, train_loss = 2.167077012360096, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 199, train_loss = 2.161621527047828, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 200, train_loss = 2.158240931807086, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 201, train_loss = 2.1529890422243625, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 202, train_loss = 2.1480803277809173, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 203, train_loss = 2.144500559894368, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 204, train_loss = 2.1395326431374997, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 205, train_loss = 2.1341618448495865, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 206, train_loss = 2.1303510155994445, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 207, train_loss = 2.126077798428014, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 208, train_loss = 2.1215356264729053, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 209, train_loss = 2.117114618420601, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 210, train_loss = 2.112236524699256, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 211, train_loss = 2.1078618243336678, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 212, train_loss = 2.103412131546065, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 213, train_loss = 2.1001572508830577, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 214, train_loss = 2.0954576793592423, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 215, train_loss = 2.091296187369153, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 216, train_loss = 2.086738233687356, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 217, train_loss = 2.0823834005277604, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 218, train_loss = 2.0801770475227386, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 219, train_loss = 2.074623105349019, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 220, train_loss = 2.071380153298378, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 221, train_loss = 2.0676963466685265, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 222, train_loss = 2.064450408099219, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 223, train_loss = 2.059679852100089, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 224, train_loss = 2.0557563330512494, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 225, train_loss = 2.0523995608091354, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 226, train_loss = 2.0487529274541885, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 227, train_loss = 2.045730549842119, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 228, train_loss = 2.041585038183257, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 229, train_loss = 2.0378358985763043, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 230, train_loss = 2.033695126650855, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 231, train_loss = 2.0311938028316945, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 232, train_loss = 2.0269804697018117, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 233, train_loss = 2.0233003746252507, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 234, train_loss = 2.020440347492695, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 235, train_loss = 2.0167979288380593, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 236, train_loss = 2.0129010379314423, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 237, train_loss = 2.010989257367328, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 238, train_loss = 2.0064181834459305, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 239, train_loss = 2.0039911903440952, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 240, train_loss = 2.0006102807819843, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 241, train_loss = 1.9969296816270798, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 242, train_loss = 1.9942994613666087, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 243, train_loss = 1.9905151911079884, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 244, train_loss = 1.9871802430134267, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 245, train_loss = 1.9849350068252534, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 246, train_loss = 1.9817247577011585, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 247, train_loss = 1.9773932956159115, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 248, train_loss = 1.975220199674368, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 249, train_loss = 1.972288156626746, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 250, train_loss = 1.9692909133154899, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 251, train_loss = 1.9668419894296676, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 252, train_loss = 1.9645674352068454, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 253, train_loss = 1.9610337428748608, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 254, train_loss = 1.959114796249196, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 255, train_loss = 1.9546465936582536, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 256, train_loss = 1.9535502206999809, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 257, train_loss = 1.9490536313969642, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 258, train_loss = 1.9469832517206669, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 259, train_loss = 1.9448867104947567, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 260, train_loss = 1.941034352988936, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 261, train_loss = 1.939117061556317, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 262, train_loss = 1.936947114765644, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 263, train_loss = 1.933249581605196, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 264, train_loss = 1.9296749159693718, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 265, train_loss = 1.9288127645850182, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 266, train_loss = 1.9251125901937485, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 267, train_loss = 1.923461589962244, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 268, train_loss = 1.9205555593362078, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 269, train_loss = 1.918073239387013, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 270, train_loss = 1.9163172816624865, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 271, train_loss = 1.9128349522361532, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 272, train_loss = 1.9105941839516163, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 273, train_loss = 1.9074970682850108, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 274, train_loss = 1.906355487764813, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 275, train_loss = 1.9029773386428133, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 276, train_loss = 1.9010253535816446, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 277, train_loss = 1.8989649327704683, train_acc = 0.9952258965999069\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 278, train_loss = 1.8960025757551193, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 279, train_loss = 1.894729383289814, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 280, train_loss = 1.8917427969863638, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 281, train_loss = 1.8893892305204645, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 282, train_loss = 1.887795609771274, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 283, train_loss = 1.8851984416833147, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 284, train_loss = 1.8831455943873152, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 285, train_loss = 1.8812823990592733, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 286, train_loss = 1.879095159471035, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 287, train_loss = 1.8767548836767673, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 288, train_loss = 1.8740481411805376, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 289, train_loss = 1.8721877919742838, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 290, train_loss = 1.8705503729870543, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 291, train_loss = 1.867510994314216, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 292, train_loss = 1.8648408701410517, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 293, train_loss = 1.8633342956891283, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 294, train_loss = 1.8612580312183127, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 295, train_loss = 1.8594742255518213, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 296, train_loss = 1.8577966938028112, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 297, train_loss = 1.8555823663482442, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 298, train_loss = 1.8528243725886568, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 299, train_loss = 1.8519376242766157, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 300, train_loss = 1.8491554781794548, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 301, train_loss = 1.8477118586888537, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 302, train_loss = 1.845226133824326, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 303, train_loss = 1.8438246535370126, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 304, train_loss = 1.8412797264754772, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 305, train_loss = 1.8392351331422105, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 306, train_loss = 1.8379230834543705, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 307, train_loss = 1.8366400798549876, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 308, train_loss = 1.8345931047806516, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 309, train_loss = 1.8315556248417124, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 310, train_loss = 1.8307170793414116, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 311, train_loss = 1.8283136524260044, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 312, train_loss = 1.826028537005186, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 313, train_loss = 1.8247254453599453, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 314, train_loss = 1.823323279619217, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 315, train_loss = 1.8209582617273554, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 316, train_loss = 1.8193113505840302, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 317, train_loss = 1.8168599990895018, train_acc = 0.9953423381462506\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 318, train_loss = 1.816145877004601, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 319, train_loss = 1.814259022474289, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 320, train_loss = 1.8129387088119984, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 321, train_loss = 1.8103256920585409, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 322, train_loss = 1.8088439045241103, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 323, train_loss = 1.806887278915383, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 324, train_loss = 1.8063017962267622, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 325, train_loss = 1.8040999384829774, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 326, train_loss = 1.8026495017111301, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 327, train_loss = 1.8006225737044588, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 328, train_loss = 1.7988937832415104, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 329, train_loss = 1.7971726022660732, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 330, train_loss = 1.7962733196327463, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 331, train_loss = 1.7951601980021223, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 332, train_loss = 1.791344808996655, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 333, train_loss = 1.7897560695419088, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 334, train_loss = 1.7891456572106108, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 335, train_loss = 1.7873411724576727, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 336, train_loss = 1.7864483458688483, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 337, train_loss = 1.7851544929435477, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 338, train_loss = 1.7832387847593054, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 339, train_loss = 1.7819392507662997, train_acc = 0.9954587796925943\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 340, train_loss = 1.7798039130866528, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 341, train_loss = 1.7770393515238538, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 342, train_loss = 1.7764878123998642, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 343, train_loss = 1.7749627406010404, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 344, train_loss = 1.7726897709071636, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 345, train_loss = 1.7728054138133302, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 346, train_loss = 1.7710005094995722, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 347, train_loss = 1.7702350305626169, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 348, train_loss = 1.7676770463585854, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 349, train_loss = 1.7661978030810133, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 350, train_loss = 1.7653208201518282, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 351, train_loss = 1.762803740799427, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 352, train_loss = 1.7619004435837269, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 353, train_loss = 1.7611454589059576, train_acc = 0.9954587796925943\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 354, train_loss = 1.7589808230986819, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 355, train_loss = 1.7576403642306104, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 356, train_loss = 1.7560967281460762, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 357, train_loss = 1.7561109587550163, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 358, train_loss = 1.754773641587235, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 359, train_loss = 1.7524632178246975, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 360, train_loss = 1.7517523592105135, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 361, train_loss = 1.749799152254127, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 362, train_loss = 1.74815731740091, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 363, train_loss = 1.7478574961423874, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 364, train_loss = 1.7449119748780504, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 365, train_loss = 1.7454179301857948, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 366, train_loss = 1.7425561547279358, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 367, train_loss = 1.7430252680787817, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 368, train_loss = 1.741812257678248, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 369, train_loss = 1.739658247679472, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 370, train_loss = 1.739181482582353, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 371, train_loss = 1.7370906472206116, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 372, train_loss = 1.7348891273140907, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 373, train_loss = 1.73523550236132, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 374, train_loss = 1.7334725484251976, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 375, train_loss = 1.7307734253117815, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 376, train_loss = 1.7310228236019611, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 377, train_loss = 1.7298406325280666, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 378, train_loss = 1.728289327234961, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 379, train_loss = 1.7275709795067087, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 380, train_loss = 1.7264818511903286, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 381, train_loss = 1.7256245376775041, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 382, train_loss = 1.723765934468247, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 383, train_loss = 1.7234332114458084, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 384, train_loss = 1.7219916619360447, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 385, train_loss = 1.7205316188046709, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 386, train_loss = 1.7195807248353958, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 387, train_loss = 1.7186262843897566, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 388, train_loss = 1.7162284068763256, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 389, train_loss = 1.715801291167736, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 390, train_loss = 1.7143636420369148, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 391, train_loss = 1.7152437008917332, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 392, train_loss = 1.7127334773540497, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 393, train_loss = 1.7128729782998562, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 394, train_loss = 1.71136102208402, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 395, train_loss = 1.7094870917499065, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 396, train_loss = 1.7084003140917048, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 397, train_loss = 1.7072985408594832, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 398, train_loss = 1.7059743130812421, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 399, train_loss = 1.7056629285216331, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 400, train_loss = 1.7036575438687578, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 401, train_loss = 1.7032527724513784, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 402, train_loss = 1.7025468362262473, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 403, train_loss = 1.7020209828624502, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 404, train_loss = 1.7010096050798893, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 405, train_loss = 1.6992079690098763, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 406, train_loss = 1.6985277583589777, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 407, train_loss = 1.6970382755389437, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 408, train_loss = 1.6969754211604595, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 409, train_loss = 1.6954557709395885, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 410, train_loss = 1.6948736272752285, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 411, train_loss = 1.6942387049784884, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 412, train_loss = 1.6925913455197588, train_acc = 0.9954587796925943\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 413, train_loss = 1.6904918774962425, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 414, train_loss = 1.6925094425678253, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 415, train_loss = 1.689245205372572, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 416, train_loss = 1.6888011110713705, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 417, train_loss = 1.68766011914704, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 418, train_loss = 1.6877962177386507, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 419, train_loss = 1.6852479676599614, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 420, train_loss = 1.6837625515763648, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 421, train_loss = 1.685003203630913, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 422, train_loss = 1.6828221243922599, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 423, train_loss = 1.6811882841284387, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 424, train_loss = 1.680671837180853, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 425, train_loss = 1.6799819879233837, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 426, train_loss = 1.6797919049859047, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 427, train_loss = 1.6786159251932986, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 428, train_loss = 1.6774979308247566, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 429, train_loss = 1.676386418461334, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 430, train_loss = 1.675237646966707, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 431, train_loss = 1.675432452291716, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 432, train_loss = 1.673777615011204, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 433, train_loss = 1.6732734727556817, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 434, train_loss = 1.67313938960433, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 435, train_loss = 1.6711468833382241, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 436, train_loss = 1.6717327783699147, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 437, train_loss = 1.669225753576029, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 438, train_loss = 1.6695436078007333, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 439, train_loss = 1.6680889812414534, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 440, train_loss = 1.666914393485058, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 441, train_loss = 1.6666516463155858, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 442, train_loss = 1.6653900097007863, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 443, train_loss = 1.663850113749504, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 444, train_loss = 1.66463241976453, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 445, train_loss = 1.6629958960111253, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 446, train_loss = 1.6617522339220159, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 447, train_loss = 1.6623459818656556, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 448, train_loss = 1.6605131861870177, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 449, train_loss = 1.6596393560175784, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 450, train_loss = 1.6587027522618882, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 451, train_loss = 1.657501507550478, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 452, train_loss = 1.6576862173969857, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 453, train_loss = 1.6572867520153522, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 454, train_loss = 1.6556189966504462, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 455, train_loss = 1.654900388151873, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 456, train_loss = 1.653420855582226, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 457, train_loss = 1.654803216457367, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 458, train_loss = 1.6526547484099865, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 459, train_loss = 1.652697333425749, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 460, train_loss = 1.6501486487686634, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 461, train_loss = 1.650328187912237, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 462, train_loss = 1.6495330768520944, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 463, train_loss = 1.6486575205926783, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 464, train_loss = 1.6494303432409652, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 465, train_loss = 1.6468821155722253, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 466, train_loss = 1.6475065921549685, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 467, train_loss = 1.6458876393735409, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 468, train_loss = 1.6454316240851767, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 469, train_loss = 1.6439421859686263, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 470, train_loss = 1.6438540394301526, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 471, train_loss = 1.6440302319824696, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 472, train_loss = 1.6419395518605597, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 473, train_loss = 1.6414638087153435, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 474, train_loss = 1.64177605509758, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 475, train_loss = 1.64009303227067, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 476, train_loss = 1.639774565875996, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 477, train_loss = 1.639874156564474, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 478, train_loss = 1.6380021956865676, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 479, train_loss = 1.6367019824683666, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 480, train_loss = 1.6369497403502464, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 481, train_loss = 1.6363796554505825, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 482, train_loss = 1.6350628485088237, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 483, train_loss = 1.6347774502937682, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 484, train_loss = 1.6349010691046715, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 485, train_loss = 1.633080446452368, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 486, train_loss = 1.6331553583149798, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 487, train_loss = 1.6314004845917225, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 488, train_loss = 1.631225075572729, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 489, train_loss = 1.6298955231904984, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 490, train_loss = 1.6300626397132874, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 491, train_loss = 1.6292318838532083, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 492, train_loss = 1.6285889794235118, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 493, train_loss = 1.6278711197082885, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 494, train_loss = 1.6273572693462484, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 495, train_loss = 1.6266942408983596, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 496, train_loss = 1.6253014293615706, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 497, train_loss = 1.6258189392392524, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 498, train_loss = 1.62493620935129, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 499, train_loss = 1.6233973850612529, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████▏    | 28/30 [4:13:28<18:06, 543.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "29th- epoch: 0, train_loss = 96.53166696429253, train_acc = 0.8082207731718677\n",
      "test Acc 0.8687150837988827:\n",
      "29th- epoch: 1, train_loss = 41.03782796859741, train_acc = 0.9136003726129484\n",
      "test Acc 0.9199255121042831:\n",
      "29th- epoch: 2, train_loss = 31.385571397840977, train_acc = 0.9330461108523521\n",
      "test Acc 0.9329608938547486:\n",
      "29th- epoch: 3, train_loss = 26.17290173470974, train_acc = 0.944108057755007\n",
      "test Acc 0.9441340782122905:\n",
      "29th- epoch: 4, train_loss = 22.803202502429485, train_acc = 0.9505123428039124\n",
      "test Acc 0.9506517690875232:\n",
      "29th- epoch: 5, train_loss = 20.47078873217106, train_acc = 0.9552864462040056\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 6, train_loss = 18.721892047673464, train_acc = 0.9592454587796926\n",
      "test Acc 0.9553072625698324:\n",
      "29th- epoch: 7, train_loss = 17.345317974686623, train_acc = 0.9626222636236609\n",
      "test Acc 0.9585661080074488:\n",
      "29th- epoch: 8, train_loss = 16.213955160230398, train_acc = 0.9654168607359106\n",
      "test Acc 0.9581005586592178:\n",
      "29th- epoch: 9, train_loss = 15.238172434270382, train_acc = 0.9672799254774104\n",
      "test Acc 0.9585661080074488:\n",
      "29th- epoch: 10, train_loss = 14.406781509518623, train_acc = 0.9710060549604099\n",
      "test Acc 0.9599627560521415:\n",
      "29th- epoch: 11, train_loss = 13.684132995083928, train_acc = 0.9731020027945971\n",
      "test Acc 0.9618249534450651:\n",
      "29th- epoch: 12, train_loss = 13.049789153039455, train_acc = 0.9743828598043782\n",
      "test Acc 0.962756052141527:\n",
      "29th- epoch: 13, train_loss = 12.481772381812334, train_acc = 0.9758965999068467\n",
      "test Acc 0.9632216014897579:\n",
      "29th- epoch: 14, train_loss = 11.973273243755102, train_acc = 0.9765952491849091\n",
      "test Acc 0.9636871508379888:\n",
      "29th- epoch: 15, train_loss = 11.51465410925448, train_acc = 0.9770610153702841\n",
      "test Acc 0.9636871508379888:\n",
      "29th- epoch: 16, train_loss = 11.098482834175229, train_acc = 0.9777596646483465\n",
      "test Acc 0.9646182495344506:\n",
      "29th- epoch: 17, train_loss = 10.713869020342827, train_acc = 0.9784583139264089\n",
      "test Acc 0.9650837988826816:\n",
      "29th- epoch: 18, train_loss = 10.35223850980401, train_acc = 0.9796227293898463\n",
      "test Acc 0.9655493482309124:\n",
      "29th- epoch: 19, train_loss = 10.02755025587976, train_acc = 0.98067070330694\n",
      "test Acc 0.9655493482309124:\n",
      "29th- epoch: 20, train_loss = 9.715631252154708, train_acc = 0.9811364694923148\n",
      "test Acc 0.9655493482309124:\n",
      "29th- epoch: 21, train_loss = 9.430332526564598, train_acc = 0.9814857941313461\n",
      "test Acc 0.9660148975791434:\n",
      "29th- epoch: 22, train_loss = 9.158162221312523, train_acc = 0.9824173265020959\n",
      "test Acc 0.9664804469273743:\n",
      "29th- epoch: 23, train_loss = 8.907691285014153, train_acc = 0.9827666511411272\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 24, train_loss = 8.666498254984617, train_acc = 0.9832324173265021\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 25, train_loss = 8.435372622683644, train_acc = 0.9834653004191896\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 26, train_loss = 8.2218316514045, train_acc = 0.9839310666045645\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 27, train_loss = 8.020644837990403, train_acc = 0.984163949697252\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 28, train_loss = 7.831295043230057, train_acc = 0.9845132743362832\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 29, train_loss = 7.655357467010617, train_acc = 0.9848625989753144\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 30, train_loss = 7.484830493107438, train_acc = 0.9852119236143456\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 31, train_loss = 7.325415745377541, train_acc = 0.9855612482533768\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 32, train_loss = 7.173116436228156, train_acc = 0.9857941313460643\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 33, train_loss = 7.026732541620731, train_acc = 0.985910572892408\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 34, train_loss = 6.888085482642055, train_acc = 0.9864927806241267\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 35, train_loss = 6.75368794798851, train_acc = 0.9867256637168141\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 36, train_loss = 6.6207508239895105, train_acc = 0.9870749883558454\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 37, train_loss = 6.500908376649022, train_acc = 0.9871914299021891\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 38, train_loss = 6.386930434033275, train_acc = 0.9876571960875641\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 39, train_loss = 6.275482626631856, train_acc = 0.9880065207265952\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 40, train_loss = 6.170152874663472, train_acc = 0.9883558453656265\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 41, train_loss = 6.068442678079009, train_acc = 0.9888216115510013\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 42, train_loss = 5.974525462836027, train_acc = 0.9891709361900326\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 43, train_loss = 5.879158018156886, train_acc = 0.9892873777363763\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 44, train_loss = 5.7877346109598875, train_acc = 0.9895202608290639\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 45, train_loss = 5.699647044762969, train_acc = 0.9899860270144387\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 46, train_loss = 5.617231918498874, train_acc = 0.9899860270144387\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 47, train_loss = 5.538017847575247, train_acc = 0.9901024685607824\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 48, train_loss = 5.460651050321758, train_acc = 0.9909175593851887\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 49, train_loss = 5.386826409958303, train_acc = 0.9909175593851887\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 50, train_loss = 5.313431388698518, train_acc = 0.9911504424778761\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 51, train_loss = 5.243868968449533, train_acc = 0.9913833255705635\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 52, train_loss = 5.178286728449166, train_acc = 0.9914997671169073\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 53, train_loss = 5.110492926090956, train_acc = 0.9914997671169073\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 54, train_loss = 5.049160496331751, train_acc = 0.9914997671169073\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 55, train_loss = 4.988167786039412, train_acc = 0.9914997671169073\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 56, train_loss = 4.9285181649029255, train_acc = 0.9914997671169073\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 57, train_loss = 4.871955751441419, train_acc = 0.9916162086632511\n",
      "test Acc 0.9725325884543762:\n",
      "29th- epoch: 58, train_loss = 4.816077072173357, train_acc = 0.9916162086632511\n",
      "test Acc 0.9725325884543762:\n",
      "29th- epoch: 59, train_loss = 4.760187532752752, train_acc = 0.9916162086632511\n",
      "test Acc 0.9725325884543762:\n",
      "29th- epoch: 60, train_loss = 4.704987522214651, train_acc = 0.9916162086632511\n",
      "test Acc 0.9725325884543762:\n",
      "29th- epoch: 61, train_loss = 4.653518606908619, train_acc = 0.9917326502095948\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 62, train_loss = 4.603630650788546, train_acc = 0.9917326502095948\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 63, train_loss = 4.555612213909626, train_acc = 0.9919655333022822\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 64, train_loss = 4.507418190129101, train_acc = 0.9919655333022822\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 65, train_loss = 4.461866617202759, train_acc = 0.992081974848626\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 66, train_loss = 4.414801862090826, train_acc = 0.992081974848626\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 67, train_loss = 4.371525746770203, train_acc = 0.9921984163949698\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 68, train_loss = 4.328584534116089, train_acc = 0.9923148579413135\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 69, train_loss = 4.285828001797199, train_acc = 0.9923148579413135\n",
      "test Acc 0.9743947858472998:\n",
      "29th- epoch: 70, train_loss = 4.24572245683521, train_acc = 0.9923148579413135\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 71, train_loss = 4.20706435944885, train_acc = 0.9924312994876572\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 72, train_loss = 4.166438761167228, train_acc = 0.9924312994876572\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 73, train_loss = 4.129873410798609, train_acc = 0.9925477410340009\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 74, train_loss = 4.092208489775658, train_acc = 0.9925477410340009\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 75, train_loss = 4.058036680333316, train_acc = 0.9925477410340009\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 76, train_loss = 4.022706185467541, train_acc = 0.9927806241266884\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 77, train_loss = 3.9880991810932755, train_acc = 0.9927806241266884\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 78, train_loss = 3.954744723625481, train_acc = 0.9927806241266884\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 79, train_loss = 3.920970570296049, train_acc = 0.9927806241266884\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 80, train_loss = 3.890640016645193, train_acc = 0.9930135072193759\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 81, train_loss = 3.8587442003190517, train_acc = 0.9930135072193759\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 82, train_loss = 3.82771163713187, train_acc = 0.9930135072193759\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 83, train_loss = 3.795723147690296, train_acc = 0.9930135072193759\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 84, train_loss = 3.7648031301796436, train_acc = 0.9930135072193759\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 85, train_loss = 3.739960419945419, train_acc = 0.9930135072193759\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 86, train_loss = 3.7104174830019474, train_acc = 0.9930135072193759\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 87, train_loss = 3.6815254241228104, train_acc = 0.9930135072193759\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 88, train_loss = 3.6543471850454807, train_acc = 0.9930135072193759\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 89, train_loss = 3.6286073587834835, train_acc = 0.9930135072193759\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 90, train_loss = 3.601976878941059, train_acc = 0.9930135072193759\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 91, train_loss = 3.5772183323279023, train_acc = 0.9931299487657196\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 92, train_loss = 3.551929126493633, train_acc = 0.9932463903120633\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 93, train_loss = 3.526828565634787, train_acc = 0.9932463903120633\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 94, train_loss = 3.501798316836357, train_acc = 0.9932463903120633\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 95, train_loss = 3.478545732796192, train_acc = 0.9932463903120633\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 96, train_loss = 3.4548005210235715, train_acc = 0.9932463903120633\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 97, train_loss = 3.4301183484494686, train_acc = 0.9932463903120633\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 98, train_loss = 3.4080809680745006, train_acc = 0.9932463903120633\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 99, train_loss = 3.3845673389732838, train_acc = 0.9932463903120633\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 100, train_loss = 3.3608125848695636, train_acc = 0.9932463903120633\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 101, train_loss = 3.337053614668548, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 102, train_loss = 3.315834133885801, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 103, train_loss = 3.29556505382061, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 104, train_loss = 3.275428412016481, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 105, train_loss = 3.2540775290690362, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 106, train_loss = 3.2346990131773055, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 107, train_loss = 3.2152700535953045, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 108, train_loss = 3.197121975477785, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 109, train_loss = 3.1770803690887988, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 110, train_loss = 3.1589913913048804, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 111, train_loss = 3.1405210830271244, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 112, train_loss = 3.1234488300979137, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 113, train_loss = 3.105063444469124, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 114, train_loss = 3.0894736065529287, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 115, train_loss = 3.0726025686599314, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 116, train_loss = 3.0557242087088525, train_acc = 0.9933628318584071\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 117, train_loss = 3.038612940814346, train_acc = 0.9933628318584071\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 118, train_loss = 3.0222648209892213, train_acc = 0.9933628318584071\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 119, train_loss = 3.007159650325775, train_acc = 0.9933628318584071\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 120, train_loss = 2.9912426248192787, train_acc = 0.9933628318584071\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 121, train_loss = 2.975841850042343, train_acc = 0.9933628318584071\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 122, train_loss = 2.9596290453337133, train_acc = 0.9933628318584071\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 123, train_loss = 2.945316722150892, train_acc = 0.9934792734047508\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 124, train_loss = 2.930937824305147, train_acc = 0.9934792734047508\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 125, train_loss = 2.916140654589981, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 126, train_loss = 2.902575049549341, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 127, train_loss = 2.8880063160322607, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 128, train_loss = 2.8747787005268037, train_acc = 0.9935957149510946\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 129, train_loss = 2.8605494773946702, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 130, train_loss = 2.847182093653828, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 131, train_loss = 2.834327721502632, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 132, train_loss = 2.8213603259064257, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 133, train_loss = 2.8089755475521088, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 134, train_loss = 2.7957319119013846, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 135, train_loss = 2.7837333255447447, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 136, train_loss = 2.771850405726582, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 137, train_loss = 2.759463449474424, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 138, train_loss = 2.7479347004555166, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 139, train_loss = 2.7362687862478197, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 140, train_loss = 2.7240712554194033, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 141, train_loss = 2.7125286259688437, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 142, train_loss = 2.7010343647561967, train_acc = 0.9939450395901258\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 143, train_loss = 2.6906433985568583, train_acc = 0.9940614811364695\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 144, train_loss = 2.6794035397469997, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 145, train_loss = 2.668809612747282, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 146, train_loss = 2.658899346832186, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 147, train_loss = 2.64705423777923, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 148, train_loss = 2.6375191435217857, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 149, train_loss = 2.6275884001515806, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 150, train_loss = 2.6177622848190367, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 151, train_loss = 2.6063288375735283, train_acc = 0.9941779226828132\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 152, train_loss = 2.597336603794247, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 153, train_loss = 2.5878924690186977, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 154, train_loss = 2.5787370554171503, train_acc = 0.9941779226828132\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 155, train_loss = 2.5679268739186227, train_acc = 0.9941779226828132\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 156, train_loss = 2.559310941491276, train_acc = 0.994294364229157\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 157, train_loss = 2.5518269636668265, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 158, train_loss = 2.5408008159138262, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 159, train_loss = 2.5323837152682245, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 160, train_loss = 2.5235002152621746, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 161, train_loss = 2.5142799778841436, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 162, train_loss = 2.5073623755015433, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 163, train_loss = 2.4979757056571543, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 164, train_loss = 2.489513272885233, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 165, train_loss = 2.481039961334318, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 166, train_loss = 2.4738977043889463, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 167, train_loss = 2.4639737433753908, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 168, train_loss = 2.4577521295286715, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 169, train_loss = 2.448608005885035, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 170, train_loss = 2.442089850548655, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 171, train_loss = 2.4340696088038385, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 172, train_loss = 2.425997129175812, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 173, train_loss = 2.4192736125551164, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 174, train_loss = 2.4113478413783014, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 175, train_loss = 2.403983374591917, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 176, train_loss = 2.396438048686832, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 177, train_loss = 2.3899224498309195, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 178, train_loss = 2.382242562714964, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 179, train_loss = 2.3756905049085617, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 180, train_loss = 2.36843957612291, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 181, train_loss = 2.361922685056925, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 182, train_loss = 2.3544859886169434, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 183, train_loss = 2.3485738821327686, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 184, train_loss = 2.341321235988289, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 185, train_loss = 2.33537712180987, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 186, train_loss = 2.327938017901033, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 187, train_loss = 2.322223272174597, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 188, train_loss = 2.3152011781930923, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 189, train_loss = 2.3100556805729866, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 190, train_loss = 2.303105933126062, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 191, train_loss = 2.2975482656620443, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 192, train_loss = 2.29120060428977, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 193, train_loss = 2.28482303628698, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 194, train_loss = 2.278521303087473, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 195, train_loss = 2.273335701553151, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 196, train_loss = 2.2673825409729034, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 197, train_loss = 2.2618289552628994, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 198, train_loss = 2.2561718225479126, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 199, train_loss = 2.2510903391521424, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 200, train_loss = 2.243825013516471, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 201, train_loss = 2.2394241963047534, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 202, train_loss = 2.2336099620442837, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 203, train_loss = 2.228728972375393, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 204, train_loss = 2.2231104981619865, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 205, train_loss = 2.218493616906926, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 206, train_loss = 2.212226218311116, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 207, train_loss = 2.207829138962552, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 208, train_loss = 2.2018843789119273, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 209, train_loss = 2.196945421397686, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 210, train_loss = 2.1925324238836765, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 211, train_loss = 2.1872246377170086, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 212, train_loss = 2.18199456599541, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 213, train_loss = 2.1779556286055595, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 214, train_loss = 2.171989716589451, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 215, train_loss = 2.1681088767945766, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 216, train_loss = 2.162643087329343, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 217, train_loss = 2.158932889578864, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 218, train_loss = 2.1533331349492073, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 219, train_loss = 2.1490122240502387, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 220, train_loss = 2.1443101316690445, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 221, train_loss = 2.1408786315005273, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 222, train_loss = 2.1354833964724094, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 223, train_loss = 2.1315580382943153, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 224, train_loss = 2.1265186816453934, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 225, train_loss = 2.123215199680999, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 226, train_loss = 2.117773858131841, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 227, train_loss = 2.114150643348694, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 228, train_loss = 2.1098774287384003, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 229, train_loss = 2.1054570886772126, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 230, train_loss = 2.102041666628793, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 231, train_loss = 2.097938881488517, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 232, train_loss = 2.0937367093283683, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 233, train_loss = 2.089767426252365, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 234, train_loss = 2.085309397429228, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 235, train_loss = 2.0821987066883594, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 236, train_loss = 2.0776356284040958, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 237, train_loss = 2.074345054803416, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 238, train_loss = 2.069693734170869, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 239, train_loss = 2.0673179004807025, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 240, train_loss = 2.0622118290048093, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 241, train_loss = 2.0589590941090137, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 242, train_loss = 2.0549337193369865, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 243, train_loss = 2.0517053056973964, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 244, train_loss = 2.0485040184576064, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 245, train_loss = 2.044470974477008, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 246, train_loss = 2.0413065515458584, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 247, train_loss = 2.0369953352492303, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 248, train_loss = 2.034186604199931, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 249, train_loss = 2.0309669363778085, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 250, train_loss = 2.0259608663618565, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 251, train_loss = 2.0238815795164555, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 252, train_loss = 2.0194894298911095, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 253, train_loss = 2.0172539216000587, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 254, train_loss = 2.013653711648658, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 255, train_loss = 2.0107995234429836, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 256, train_loss = 2.0057994090020657, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 257, train_loss = 2.00365558010526, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 258, train_loss = 2.000246013281867, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 259, train_loss = 1.9973651382606477, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 260, train_loss = 1.9940440740901977, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 261, train_loss = 1.9910406593699008, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 262, train_loss = 1.9876549032051116, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 263, train_loss = 1.9848376896698028, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 264, train_loss = 1.981817901134491, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 265, train_loss = 1.977859475882724, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 266, train_loss = 1.976454668911174, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 267, train_loss = 1.9726427209097892, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 268, train_loss = 1.9697783042211086, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 269, train_loss = 1.966466239420697, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 270, train_loss = 1.9642847862560302, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 271, train_loss = 1.9606174353975803, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 272, train_loss = 1.95821850374341, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 273, train_loss = 1.954777890117839, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 274, train_loss = 1.952196619240567, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 275, train_loss = 1.9495598189532757, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 276, train_loss = 1.946929782629013, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 277, train_loss = 1.944650586694479, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 278, train_loss = 1.9417791415471584, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 279, train_loss = 1.9380717005115002, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 280, train_loss = 1.9365757368505, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 281, train_loss = 1.9336775329429656, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 282, train_loss = 1.932125199586153, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 283, train_loss = 1.9281653736252338, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 284, train_loss = 1.9267233945429325, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 285, train_loss = 1.9229001838248223, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 286, train_loss = 1.9211717669386417, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 287, train_loss = 1.9178185735363513, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 288, train_loss = 1.9163929659407586, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 289, train_loss = 1.913536975858733, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 290, train_loss = 1.9115157152991742, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 291, train_loss = 1.9086938835680485, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 292, train_loss = 1.9055273111443967, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 293, train_loss = 1.9043047453742474, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 294, train_loss = 1.9012917603831738, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 295, train_loss = 1.8992707047145814, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 296, train_loss = 1.8968013997655362, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 297, train_loss = 1.8950994934421033, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 298, train_loss = 1.892082504928112, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 299, train_loss = 1.8901670041959733, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 300, train_loss = 1.8869699637871236, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 301, train_loss = 1.8852044518571347, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 302, train_loss = 1.8836664259433746, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 303, train_loss = 1.8808013361413032, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 304, train_loss = 1.878546169726178, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 305, train_loss = 1.8762488190550357, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 306, train_loss = 1.8739518262445927, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 307, train_loss = 1.8716843638103455, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 308, train_loss = 1.8691726215183735, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 309, train_loss = 1.8679762929677963, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 310, train_loss = 1.865891209570691, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 311, train_loss = 1.8630194291472435, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 312, train_loss = 1.8613269675988704, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 313, train_loss = 1.8591398771386594, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 314, train_loss = 1.8568907976150513, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 315, train_loss = 1.855123357148841, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 316, train_loss = 1.8537178710103035, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 317, train_loss = 1.851627414347604, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 318, train_loss = 1.8494584511499852, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 319, train_loss = 1.84739047777839, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 320, train_loss = 1.8452881500124931, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 321, train_loss = 1.8433385367970914, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 322, train_loss = 1.8409994181711227, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 323, train_loss = 1.839193470776081, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 324, train_loss = 1.8371863178908825, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 325, train_loss = 1.8355663504917175, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 326, train_loss = 1.8337800216395408, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 327, train_loss = 1.8312688010046259, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 328, train_loss = 1.8304875455796719, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 329, train_loss = 1.8278379800030962, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 330, train_loss = 1.825895876972936, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 331, train_loss = 1.8241980796447024, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 332, train_loss = 1.8218708088388667, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 333, train_loss = 1.8212959108641371, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 334, train_loss = 1.8192970752716064, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 335, train_loss = 1.8173036450752988, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 336, train_loss = 1.8157394950976595, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 337, train_loss = 1.8138986924896017, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 338, train_loss = 1.8116107247769833, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 339, train_loss = 1.8103091344237328, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 340, train_loss = 1.8085948141524568, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 341, train_loss = 1.8062401860952377, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 342, train_loss = 1.8046352192759514, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 343, train_loss = 1.8029711084673181, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 344, train_loss = 1.8019068017601967, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 345, train_loss = 1.7994550628354773, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 346, train_loss = 1.7990512698888779, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 347, train_loss = 1.7970963642001152, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 348, train_loss = 1.7956393646309152, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 349, train_loss = 1.7938096299767494, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 350, train_loss = 1.7920605950057507, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 351, train_loss = 1.7903074026107788, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 352, train_loss = 1.78864010295365, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 353, train_loss = 1.7875798804452643, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 354, train_loss = 1.785654096514918, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 355, train_loss = 1.78483260050416, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 356, train_loss = 1.7821948304772377, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 357, train_loss = 1.781197956413962, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 358, train_loss = 1.7790128389606252, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 359, train_loss = 1.778234681696631, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 360, train_loss = 1.7765875036129728, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 361, train_loss = 1.7756449207663536, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 362, train_loss = 1.7736540274927393, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 363, train_loss = 1.7718761004507542, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 364, train_loss = 1.7710174582898617, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 365, train_loss = 1.769287321716547, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 366, train_loss = 1.7677115401020274, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 367, train_loss = 1.7663976413896307, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 368, train_loss = 1.7647239590296522, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 369, train_loss = 1.7635144653031603, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 370, train_loss = 1.7620046077063307, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 371, train_loss = 1.7607813738286495, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 372, train_loss = 1.7598595594754443, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 373, train_loss = 1.7578011192381382, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 374, train_loss = 1.7575939446687698, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 375, train_loss = 1.7547789314994588, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 376, train_loss = 1.7539721293142065, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 377, train_loss = 1.7522442489862442, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 378, train_loss = 1.7508504390716553, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 379, train_loss = 1.7496197310974821, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 380, train_loss = 1.7488596042385325, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 381, train_loss = 1.747259603231214, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 382, train_loss = 1.746073524118401, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 383, train_loss = 1.7447279231855646, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 384, train_loss = 1.7429222402861342, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 385, train_loss = 1.7420831756899133, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 386, train_loss = 1.7407202497124672, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 387, train_loss = 1.7399622090160847, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 388, train_loss = 1.7379022054374218, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 389, train_loss = 1.7370045445859432, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 390, train_loss = 1.7354710176587105, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 391, train_loss = 1.7340090846410021, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 392, train_loss = 1.7329619663069025, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 393, train_loss = 1.7325141429901123, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 394, train_loss = 1.730327021330595, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 395, train_loss = 1.729996876209043, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 396, train_loss = 1.7285403795540333, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 397, train_loss = 1.7268383899936453, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 398, train_loss = 1.7258158512413502, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 399, train_loss = 1.724940919666551, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 400, train_loss = 1.7240998694906011, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 401, train_loss = 1.7225631661713123, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 402, train_loss = 1.7217354079475626, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 403, train_loss = 1.7202935082605109, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 404, train_loss = 1.7194811602821574, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 405, train_loss = 1.716859089792706, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 406, train_loss = 1.7152336476137862, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 407, train_loss = 1.7149777946760878, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 408, train_loss = 1.714162049232982, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 409, train_loss = 1.7122979859123006, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 410, train_loss = 1.7115103006362915, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 411, train_loss = 1.710147281526588, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 412, train_loss = 1.7091977732488886, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 413, train_loss = 1.7084119817009196, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 414, train_loss = 1.707468985230662, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 415, train_loss = 1.7064906731247902, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 416, train_loss = 1.7055797154316679, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 417, train_loss = 1.7032794952392578, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 418, train_loss = 1.7026017246535048, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 419, train_loss = 1.7015259949257597, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 420, train_loss = 1.7001121627399698, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 421, train_loss = 1.699500598013401, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 422, train_loss = 1.698255218565464, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 423, train_loss = 1.6979063911130652, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 424, train_loss = 1.6957713005831465, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 425, train_loss = 1.6957295959582552, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 426, train_loss = 1.6949508227407932, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 427, train_loss = 1.6939047612249851, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 428, train_loss = 1.6926442695548758, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 429, train_loss = 1.6910030506551266, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 430, train_loss = 1.690266971825622, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 431, train_loss = 1.688985388725996, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 432, train_loss = 1.6885704199085012, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 433, train_loss = 1.6878411521902308, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 434, train_loss = 1.6865599118173122, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 435, train_loss = 1.6860041916370392, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 436, train_loss = 1.6840278605232015, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 437, train_loss = 1.6829620525240898, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 438, train_loss = 1.6825959844281897, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 439, train_loss = 1.681479430408217, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 440, train_loss = 1.6808924414217472, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 441, train_loss = 1.6799785742769018, train_acc = 0.9958081043316255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 442, train_loss = 1.6786278076469898, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 443, train_loss = 1.6775043284287676, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 444, train_loss = 1.6774528907844797, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 445, train_loss = 1.675861074239947, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 446, train_loss = 1.6757360001793131, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 447, train_loss = 1.6739940667757764, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 448, train_loss = 1.6727443374693394, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 449, train_loss = 1.67263299098704, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 450, train_loss = 1.6714618764817715, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 451, train_loss = 1.6704935729503632, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 452, train_loss = 1.6701895172009245, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 453, train_loss = 1.6688785975566134, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 454, train_loss = 1.6679598713526502, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 455, train_loss = 1.6666246876120567, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 456, train_loss = 1.6666537696728483, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 457, train_loss = 1.6654243568191305, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 458, train_loss = 1.6645579921314493, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 459, train_loss = 1.663646244793199, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 460, train_loss = 1.6630020327866077, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 461, train_loss = 1.662286159931682, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 462, train_loss = 1.6612260565161705, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 463, train_loss = 1.6600163727998734, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 464, train_loss = 1.6596711004385725, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 465, train_loss = 1.6585887348046526, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 466, train_loss = 1.657605835585855, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 467, train_loss = 1.656381136388518, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 468, train_loss = 1.6561235574772581, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 469, train_loss = 1.6545916883042082, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 470, train_loss = 1.6542698914417997, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 471, train_loss = 1.653249683440663, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 472, train_loss = 1.6528899011900648, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 473, train_loss = 1.6522187715163454, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 474, train_loss = 1.6509021669626236, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 475, train_loss = 1.6504729824373499, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 476, train_loss = 1.648892962723039, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 477, train_loss = 1.6487295851111412, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 478, train_loss = 1.648048193543218, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 479, train_loss = 1.6468080518534407, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 480, train_loss = 1.646413321257569, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 481, train_loss = 1.6461688429117203, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 482, train_loss = 1.6449959439923987, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 483, train_loss = 1.6439748369157314, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 484, train_loss = 1.6435752784600481, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 485, train_loss = 1.6423910520970821, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 486, train_loss = 1.6416005367645994, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 487, train_loss = 1.640701094060205, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 488, train_loss = 1.6404228148749098, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 489, train_loss = 1.6396095728268847, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 490, train_loss = 1.6386140137910843, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 491, train_loss = 1.6380682388553396, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 492, train_loss = 1.6371167860925198, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 493, train_loss = 1.6362797915935516, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 494, train_loss = 1.636095336289145, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 495, train_loss = 1.6346486372640356, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 496, train_loss = 1.634735712199472, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 497, train_loss = 1.6342589618870988, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 498, train_loss = 1.6330257641384378, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 499, train_loss = 1.6322314478456974, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████▌  | 29/30 [4:22:31<09:03, 543.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "30th- epoch: 0, train_loss = 106.08653329312801, train_acc = 0.7812063344201211\n",
      "test Acc 0.8626629422718808:\n",
      "30th- epoch: 1, train_loss = 42.843772023916245, train_acc = 0.9137168141592921\n",
      "test Acc 0.914804469273743:\n",
      "30th- epoch: 2, train_loss = 32.90244650095701, train_acc = 0.9356078248719143\n",
      "test Acc 0.9324953445065177:\n",
      "30th- epoch: 3, train_loss = 27.909543372690678, train_acc = 0.9462040055891943\n",
      "test Acc 0.9427374301675978:\n",
      "30th- epoch: 4, train_loss = 24.643171593546867, train_acc = 0.9510945505356311\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 5, train_loss = 22.226665269583464, train_acc = 0.9550535631113182\n",
      "test Acc 0.9492551210428305:\n",
      "30th- epoch: 6, train_loss = 20.320121996104717, train_acc = 0.9586632510479739\n",
      "test Acc 0.9515828677839852:\n",
      "30th- epoch: 7, train_loss = 18.76566231250763, train_acc = 0.9609920819748486\n",
      "test Acc 0.9543761638733705:\n",
      "30th- epoch: 8, train_loss = 17.468633346259594, train_acc = 0.9632044713553796\n",
      "test Acc 0.9581005586592178:\n",
      "30th- epoch: 9, train_loss = 16.35835598409176, train_acc = 0.9648346530041919\n",
      "test Acc 0.9590316573556797:\n",
      "30th- epoch: 10, train_loss = 15.410277165472507, train_acc = 0.9670470423847228\n",
      "test Acc 0.9604283054003724:\n",
      "30th- epoch: 11, train_loss = 14.577697098255157, train_acc = 0.9687936655798789\n",
      "test Acc 0.9608938547486033:\n",
      "30th- epoch: 12, train_loss = 13.848721656948328, train_acc = 0.9703074056823474\n",
      "test Acc 0.9613594040968343:\n",
      "30th- epoch: 13, train_loss = 13.200624100863934, train_acc = 0.972286911970191\n",
      "test Acc 0.9618249534450651:\n",
      "30th- epoch: 14, train_loss = 12.625669997185469, train_acc = 0.9735677689799721\n",
      "test Acc 0.9622905027932961:\n",
      "30th- epoch: 15, train_loss = 12.106083113700151, train_acc = 0.9750815090824406\n",
      "test Acc 0.9622905027932961:\n",
      "30th- epoch: 16, train_loss = 11.633268840610981, train_acc = 0.9760130414531905\n",
      "test Acc 0.9622905027932961:\n",
      "30th- epoch: 17, train_loss = 11.199759889394045, train_acc = 0.9772938984629715\n",
      "test Acc 0.9622905027932961:\n",
      "30th- epoch: 18, train_loss = 10.808624986559153, train_acc = 0.9783418723800652\n",
      "test Acc 0.962756052141527:\n",
      "30th- epoch: 19, train_loss = 10.450374536216259, train_acc = 0.9789240801117839\n",
      "test Acc 0.962756052141527:\n",
      "30th- epoch: 20, train_loss = 10.119647148996592, train_acc = 0.9795062878435026\n",
      "test Acc 0.9632216014897579:\n",
      "30th- epoch: 21, train_loss = 9.812290154397488, train_acc = 0.9800884955752213\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 22, train_loss = 9.522084703668952, train_acc = 0.980204937121565\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 23, train_loss = 9.253153691068292, train_acc = 0.9807871448532837\n",
      "test Acc 0.9646182495344506:\n",
      "30th- epoch: 24, train_loss = 9.002940200269222, train_acc = 0.9816022356776898\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 25, train_loss = 8.76281495951116, train_acc = 0.9818351187703773\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 26, train_loss = 8.53792098723352, train_acc = 0.9824173265020959\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 27, train_loss = 8.330242009833455, train_acc = 0.9825337680484397\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 28, train_loss = 8.127824367955327, train_acc = 0.9827666511411272\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 29, train_loss = 7.938932567834854, train_acc = 0.9832324173265021\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 30, train_loss = 7.759816015139222, train_acc = 0.9838146250582208\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 31, train_loss = 7.591259049251676, train_acc = 0.9842803912435957\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 32, train_loss = 7.426038894802332, train_acc = 0.9850954820680019\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 33, train_loss = 7.2751861941069365, train_acc = 0.9855612482533768\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 34, train_loss = 7.126015529036522, train_acc = 0.9856776897997206\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 35, train_loss = 6.9868841804564, train_acc = 0.9860270144387517\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 36, train_loss = 6.854304311797023, train_acc = 0.986376339077783\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 37, train_loss = 6.726658836007118, train_acc = 0.9869585468095017\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 38, train_loss = 6.605490542948246, train_acc = 0.9874243129948765\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 39, train_loss = 6.489386063069105, train_acc = 0.9874243129948765\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 40, train_loss = 6.378428963944316, train_acc = 0.9875407545412203\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 41, train_loss = 6.2731035724282265, train_acc = 0.9876571960875641\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 42, train_loss = 6.169823763892055, train_acc = 0.9878900791802515\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 43, train_loss = 6.073317427188158, train_acc = 0.9883558453656265\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 44, train_loss = 5.977033723145723, train_acc = 0.9884722869119702\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 45, train_loss = 5.889429586008191, train_acc = 0.9887051700046576\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 46, train_loss = 5.798904260620475, train_acc = 0.9887051700046576\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 47, train_loss = 5.71601571701467, train_acc = 0.9888216115510013\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 48, train_loss = 5.635739326477051, train_acc = 0.9888216115510013\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 49, train_loss = 5.5567273031920195, train_acc = 0.9890544946436889\n",
      "test Acc 0.9706703910614525:\n",
      "30th- epoch: 50, train_loss = 5.482906561344862, train_acc = 0.9892873777363763\n",
      "test Acc 0.9706703910614525:\n",
      "30th- epoch: 51, train_loss = 5.410480787977576, train_acc = 0.9892873777363763\n",
      "test Acc 0.9706703910614525:\n",
      "30th- epoch: 52, train_loss = 5.341580776497722, train_acc = 0.9895202608290639\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 53, train_loss = 5.2725195698440075, train_acc = 0.9896367023754076\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 54, train_loss = 5.207065995782614, train_acc = 0.9896367023754076\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 55, train_loss = 5.142112601548433, train_acc = 0.989869585468095\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 56, train_loss = 5.081384586170316, train_acc = 0.9899860270144387\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 57, train_loss = 5.022527320310473, train_acc = 0.9899860270144387\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 58, train_loss = 4.962907204404473, train_acc = 0.99033535165347\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 59, train_loss = 4.907352549955249, train_acc = 0.99033535165347\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 60, train_loss = 4.850800281390548, train_acc = 0.99033535165347\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 61, train_loss = 4.79768636263907, train_acc = 0.99033535165347\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 62, train_loss = 4.745090013369918, train_acc = 0.9904517931998137\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 63, train_loss = 4.694810228422284, train_acc = 0.9904517931998137\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 64, train_loss = 4.644008623436093, train_acc = 0.9904517931998137\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 65, train_loss = 4.595755122601986, train_acc = 0.9905682347461574\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 66, train_loss = 4.551118375733495, train_acc = 0.9906846762925011\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 67, train_loss = 4.503607327118516, train_acc = 0.990801117838845\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 68, train_loss = 4.459266539663076, train_acc = 0.9910340009315324\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 69, train_loss = 4.416364097036421, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 70, train_loss = 4.372156233526766, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 71, train_loss = 4.331927127204835, train_acc = 0.9911504424778761\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 72, train_loss = 4.2911513186991215, train_acc = 0.9912668840242198\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 73, train_loss = 4.252466323785484, train_acc = 0.9913833255705635\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 74, train_loss = 4.213729462586343, train_acc = 0.9913833255705635\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 75, train_loss = 4.175177581608295, train_acc = 0.9913833255705635\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 76, train_loss = 4.141077290289104, train_acc = 0.9914997671169073\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 77, train_loss = 4.103232574649155, train_acc = 0.9914997671169073\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 78, train_loss = 4.069599017500877, train_acc = 0.9916162086632511\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 79, train_loss = 4.033999118022621, train_acc = 0.9917326502095948\n",
      "test Acc 0.9725325884543762:\n",
      "30th- epoch: 80, train_loss = 4.000122486613691, train_acc = 0.9917326502095948\n",
      "test Acc 0.9725325884543762:\n",
      "30th- epoch: 81, train_loss = 3.967149411328137, train_acc = 0.9917326502095948\n",
      "test Acc 0.9725325884543762:\n",
      "30th- epoch: 82, train_loss = 3.9353208048269153, train_acc = 0.9918490917559385\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 83, train_loss = 3.9037921661511064, train_acc = 0.9918490917559385\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 84, train_loss = 3.8729199217632413, train_acc = 0.992081974848626\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 85, train_loss = 3.842108336277306, train_acc = 0.992081974848626\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 86, train_loss = 3.8130631810054183, train_acc = 0.9921984163949698\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 87, train_loss = 3.7823543632403016, train_acc = 0.992081974848626\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 88, train_loss = 3.7548399223014712, train_acc = 0.992081974848626\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 89, train_loss = 3.725460617803037, train_acc = 0.992081974848626\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 90, train_loss = 3.6984808882698417, train_acc = 0.992081974848626\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 91, train_loss = 3.6707982243970037, train_acc = 0.9921984163949698\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 92, train_loss = 3.6445436254143715, train_acc = 0.9923148579413135\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 93, train_loss = 3.620021273382008, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 94, train_loss = 3.5938045466318727, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 95, train_loss = 3.5701012536883354, train_acc = 0.9924312994876572\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 96, train_loss = 3.5435717748478055, train_acc = 0.9925477410340009\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 97, train_loss = 3.5208214996382594, train_acc = 0.9925477410340009\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 98, train_loss = 3.4958848729729652, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 99, train_loss = 3.472339540719986, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 100, train_loss = 3.4507221756502986, train_acc = 0.9927806241266884\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 101, train_loss = 3.4285618169233203, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 102, train_loss = 3.4052313221618533, train_acc = 0.9928970656730322\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 103, train_loss = 3.3849820867180824, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 104, train_loss = 3.362783090211451, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 105, train_loss = 3.3429528484120965, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 106, train_loss = 3.3218895765021443, train_acc = 0.9931299487657196\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 107, train_loss = 3.3011017134413123, train_acc = 0.9932463903120633\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 108, train_loss = 3.281168577261269, train_acc = 0.9933628318584071\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 109, train_loss = 3.2615179559215903, train_acc = 0.9933628318584071\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 110, train_loss = 3.242820872925222, train_acc = 0.9933628318584071\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 111, train_loss = 3.2224499210715294, train_acc = 0.9934792734047508\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 112, train_loss = 3.2048839814960957, train_acc = 0.9934792734047508\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 113, train_loss = 3.1854186514392495, train_acc = 0.9937121564974383\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 114, train_loss = 3.16738058719784, train_acc = 0.9937121564974383\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 115, train_loss = 3.149981312453747, train_acc = 0.9937121564974383\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 116, train_loss = 3.1328492490574718, train_acc = 0.9937121564974383\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 117, train_loss = 3.115670391358435, train_acc = 0.9937121564974383\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 118, train_loss = 3.099690943956375, train_acc = 0.9937121564974383\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 119, train_loss = 3.0840002233162522, train_acc = 0.993828598043782\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 120, train_loss = 3.0666387155652046, train_acc = 0.993828598043782\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 121, train_loss = 3.05086767161265, train_acc = 0.993828598043782\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 122, train_loss = 3.0351557196117938, train_acc = 0.993828598043782\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 123, train_loss = 3.0191313163377345, train_acc = 0.993828598043782\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 124, train_loss = 3.004977807402611, train_acc = 0.993828598043782\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 125, train_loss = 2.9884519814513624, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 126, train_loss = 2.9737408556975424, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 127, train_loss = 2.9598288075067103, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 128, train_loss = 2.9453159919939935, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 129, train_loss = 2.9316033734939992, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 130, train_loss = 2.917399851139635, train_acc = 0.994294364229157\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 131, train_loss = 2.9041747748851776, train_acc = 0.9939450395901258\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 132, train_loss = 2.8903207019902766, train_acc = 0.9939450395901258\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 133, train_loss = 2.877696687821299, train_acc = 0.994294364229157\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 134, train_loss = 2.863596936222166, train_acc = 0.994294364229157\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 135, train_loss = 2.851023899856955, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 136, train_loss = 2.8380411132238805, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 137, train_loss = 2.8261671364307404, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 138, train_loss = 2.813875467982143, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 139, train_loss = 2.802259972784668, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 140, train_loss = 2.7889243587851524, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 141, train_loss = 2.777231853455305, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 142, train_loss = 2.7650058157742023, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 143, train_loss = 2.7538529322482646, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 144, train_loss = 2.7416250109672546, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 145, train_loss = 2.7315764077939093, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 146, train_loss = 2.71965586906299, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 147, train_loss = 2.7077079652808607, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 148, train_loss = 2.697655662894249, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 149, train_loss = 2.686784863471985, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 150, train_loss = 2.6760612479411066, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 151, train_loss = 2.6664390019141138, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 152, train_loss = 2.654739574994892, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 153, train_loss = 2.6449082284234464, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 154, train_loss = 2.634452771395445, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 155, train_loss = 2.6264717928133905, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 156, train_loss = 2.6155872978270054, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 157, train_loss = 2.6052488535642624, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 158, train_loss = 2.5957393795251846, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 159, train_loss = 2.5852800249122083, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 160, train_loss = 2.5764975040219724, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 161, train_loss = 2.5670061619021, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 162, train_loss = 2.557175552006811, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 163, train_loss = 2.5491271116770804, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 164, train_loss = 2.539558867458254, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 165, train_loss = 2.5324786663986742, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 166, train_loss = 2.522308725863695, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 167, train_loss = 2.5133804478682578, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 168, train_loss = 2.5042754956521094, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 169, train_loss = 2.4965019202791154, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 170, train_loss = 2.487688569817692, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 171, train_loss = 2.4801315926015377, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 172, train_loss = 2.4710978134535253, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 173, train_loss = 2.4626155071891844, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 174, train_loss = 2.455408296082169, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 175, train_loss = 2.4459136836230755, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 176, train_loss = 2.439385382924229, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 177, train_loss = 2.43165040621534, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 178, train_loss = 2.4238384501077235, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 179, train_loss = 2.417340195272118, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 180, train_loss = 2.4086950882337987, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 181, train_loss = 2.4025908135809004, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 182, train_loss = 2.3949591666460037, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 183, train_loss = 2.3882059827446938, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 184, train_loss = 2.3808012404479086, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 185, train_loss = 2.373931066598743, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 186, train_loss = 2.367342287208885, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 187, train_loss = 2.3619021461345255, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 188, train_loss = 2.3554437845014036, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 189, train_loss = 2.347891591489315, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 190, train_loss = 2.342634826898575, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 191, train_loss = 2.3354562842287123, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 192, train_loss = 2.3292905748821795, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 193, train_loss = 2.323005789425224, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 194, train_loss = 2.3170663663186133, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 195, train_loss = 2.3103239671327174, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 196, train_loss = 2.304937524255365, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 197, train_loss = 2.2995298616588116, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 198, train_loss = 2.2922544120810926, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 199, train_loss = 2.2872813418507576, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 200, train_loss = 2.280415819492191, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 201, train_loss = 2.2750978097319603, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 202, train_loss = 2.2695982195436954, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 203, train_loss = 2.265010205563158, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 204, train_loss = 2.2591834515333176, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 205, train_loss = 2.25417376938276, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 206, train_loss = 2.2478174169082195, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 207, train_loss = 2.2426656882744282, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 208, train_loss = 2.237592204241082, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 209, train_loss = 2.232526541920379, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 210, train_loss = 2.2267167617101222, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 211, train_loss = 2.221870319219306, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 212, train_loss = 2.2178818446118385, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 213, train_loss = 2.2110414642374963, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 214, train_loss = 2.207970616640523, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 215, train_loss = 2.2017073172610253, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 216, train_loss = 2.1973508931696415, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 217, train_loss = 2.192198608070612, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 218, train_loss = 2.1879179377574474, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 219, train_loss = 2.183020706055686, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 220, train_loss = 2.1784893486183137, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 221, train_loss = 2.1737800389528275, train_acc = 0.9951094550535631\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 222, train_loss = 2.1698074750602245, train_acc = 0.9951094550535631\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 223, train_loss = 2.1635263848584145, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 224, train_loss = 2.1601781498175114, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 225, train_loss = 2.1545834864955395, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 226, train_loss = 2.150322460802272, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 227, train_loss = 2.1457971793133765, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 228, train_loss = 2.142428879858926, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 229, train_loss = 2.1378003966528922, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 230, train_loss = 2.1334794238209724, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 231, train_loss = 2.129399175522849, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 232, train_loss = 2.1240844305139035, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 233, train_loss = 2.1219579242169857, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 234, train_loss = 2.1166784912347794, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 235, train_loss = 2.112657852470875, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 236, train_loss = 2.108857962070033, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 237, train_loss = 2.1042424726765603, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 238, train_loss = 2.10075107216835, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 239, train_loss = 2.097565470961854, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 240, train_loss = 2.0924957680981606, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 241, train_loss = 2.0893961649853736, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 242, train_loss = 2.0848392609041184, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 243, train_loss = 2.082393564283848, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 244, train_loss = 2.0778891183435917, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 245, train_loss = 2.0739311650395393, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 246, train_loss = 2.071140732616186, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 247, train_loss = 2.067961507709697, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 248, train_loss = 2.063115277560428, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 249, train_loss = 2.0612824086565524, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 250, train_loss = 2.0561809029895812, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 251, train_loss = 2.0532135106623173, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 252, train_loss = 2.0483700570184737, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 253, train_loss = 2.046351083787158, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 254, train_loss = 2.043633305700496, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 255, train_loss = 2.0383295852225274, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 256, train_loss = 2.03654986503534, train_acc = 0.9954587796925943\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 257, train_loss = 2.0326145465951413, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 258, train_loss = 2.02897518617101, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 259, train_loss = 2.025958641199395, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 260, train_loss = 2.0225524704437703, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 261, train_loss = 2.019299165578559, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 262, train_loss = 2.0163821715395898, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 263, train_loss = 2.0128673054277897, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 264, train_loss = 2.00895240646787, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 265, train_loss = 2.0063368938863277, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 266, train_loss = 2.0034983444493264, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 267, train_loss = 2.0004295259714127, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 268, train_loss = 1.9977750617545098, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 269, train_loss = 1.9948149237316102, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 270, train_loss = 1.9917001861613244, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 271, train_loss = 1.9889108885545284, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 272, train_loss = 1.9857456746976823, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 273, train_loss = 1.9829656246583909, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 274, train_loss = 1.9799904872197658, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 275, train_loss = 1.976656824350357, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 276, train_loss = 1.9740844976622611, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 277, train_loss = 1.9705646336078644, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 278, train_loss = 1.9687152728438377, train_acc = 0.9954587796925943\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 279, train_loss = 1.9656810972373933, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 280, train_loss = 1.9627189997117966, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 281, train_loss = 1.9599728409666568, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 282, train_loss = 1.9583447102922946, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 283, train_loss = 1.9539561185520142, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 284, train_loss = 1.9526936772745103, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 285, train_loss = 1.9487553734797984, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 286, train_loss = 1.9470077976584435, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 287, train_loss = 1.9431428362149745, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 288, train_loss = 1.9405363015830517, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 289, train_loss = 1.93739207345061, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 290, train_loss = 1.9357562388759106, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 291, train_loss = 1.9335334934294224, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 292, train_loss = 1.9317006815690547, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 293, train_loss = 1.928858297644183, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 294, train_loss = 1.9257286179345101, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 295, train_loss = 1.9232720732688904, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 296, train_loss = 1.9211627766489983, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 297, train_loss = 1.91900834441185, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 298, train_loss = 1.9143013209104538, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 299, train_loss = 1.911855700192973, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 300, train_loss = 1.9100323889870197, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 301, train_loss = 1.9066225301939994, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 302, train_loss = 1.9053964987397194, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 303, train_loss = 1.9027107257861644, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 304, train_loss = 1.8994210723321885, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 305, train_loss = 1.8980280000250787, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 306, train_loss = 1.8948351468425244, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 307, train_loss = 1.8941561430692673, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 308, train_loss = 1.8909546980867162, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 309, train_loss = 1.8895803466439247, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 310, train_loss = 1.8870318531990051, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 311, train_loss = 1.8851532625267282, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 312, train_loss = 1.883209822117351, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 313, train_loss = 1.8797076741466299, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 314, train_loss = 1.8790025474736467, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 315, train_loss = 1.8750946646323428, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 316, train_loss = 1.8735792934894562, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 317, train_loss = 1.8726509660482407, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 318, train_loss = 1.869864715845324, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 319, train_loss = 1.8685960955917835, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 320, train_loss = 1.8660905808210373, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 321, train_loss = 1.8624084381153807, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 322, train_loss = 1.8615864577004686, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 323, train_loss = 1.8589715970447287, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 324, train_loss = 1.8578090543160215, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 325, train_loss = 1.8555835783481598, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 326, train_loss = 1.8540427101543173, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 327, train_loss = 1.8516758134355769, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 328, train_loss = 1.8494609458139166, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 329, train_loss = 1.8487802557647228, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 330, train_loss = 1.844749666750431, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 331, train_loss = 1.8444543046643957, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 332, train_loss = 1.8428071662783623, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 333, train_loss = 1.840139520703815, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 334, train_loss = 1.8378732167184353, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 335, train_loss = 1.836250795633532, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 336, train_loss = 1.834494782029651, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 337, train_loss = 1.8332516178488731, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 338, train_loss = 1.831255546421744, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 339, train_loss = 1.829502941458486, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 340, train_loss = 1.8274099752306938, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 341, train_loss = 1.8264157474040985, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 342, train_loss = 1.824559636414051, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 343, train_loss = 1.8214871337404475, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 344, train_loss = 1.8195614131400362, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 345, train_loss = 1.8188044019043446, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 346, train_loss = 1.8177125478396192, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 347, train_loss = 1.8158385554561391, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 348, train_loss = 1.81425864121411, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 349, train_loss = 1.8116001585731283, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 350, train_loss = 1.8101087361574173, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 351, train_loss = 1.8091369668254629, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 352, train_loss = 1.8065376927843317, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 353, train_loss = 1.8056960726389661, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 354, train_loss = 1.8042431300273165, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 355, train_loss = 1.8018247397849336, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 356, train_loss = 1.800899332971312, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 357, train_loss = 1.7990702986717224, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 358, train_loss = 1.7983863552799448, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 359, train_loss = 1.7960620200028643, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 360, train_loss = 1.7948517637560144, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 361, train_loss = 1.7928698249161243, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 362, train_loss = 1.7908213548362255, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 363, train_loss = 1.7900351943681017, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 364, train_loss = 1.7878293929388747, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 365, train_loss = 1.7869785452494398, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 366, train_loss = 1.7846046462655067, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 367, train_loss = 1.7836233613779768, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 368, train_loss = 1.7831201603403315, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 369, train_loss = 1.781329732388258, train_acc = 0.9956916627852818\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 370, train_loss = 1.7788787757745013, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 371, train_loss = 1.7790508369216695, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 372, train_loss = 1.7775946395704523, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 373, train_loss = 1.775124100386165, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 374, train_loss = 1.7739237869391218, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 375, train_loss = 1.7729874340584502, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 376, train_loss = 1.7711272574961185, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 377, train_loss = 1.7701744263758883, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 378, train_loss = 1.7679735558340326, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 379, train_loss = 1.767313800752163, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 380, train_loss = 1.7665195228764787, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 381, train_loss = 1.763089923770167, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 382, train_loss = 1.7626550024142489, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 383, train_loss = 1.76185169944074, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 384, train_loss = 1.7606940964469686, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 385, train_loss = 1.7580482152989134, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 386, train_loss = 1.757849564193748, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 387, train_loss = 1.7565091947326437, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 388, train_loss = 1.7553072100272402, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 389, train_loss = 1.752692062407732, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 390, train_loss = 1.7526479152729735, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 391, train_loss = 1.7516795521369204, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 392, train_loss = 1.7502946419408545, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 393, train_loss = 1.7487593591213226, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 394, train_loss = 1.7482602646341547, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 395, train_loss = 1.7460835924139246, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 396, train_loss = 1.7452914640307426, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 397, train_loss = 1.7436550060519949, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 398, train_loss = 1.7413514045765623, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 399, train_loss = 1.741345596848987, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 400, train_loss = 1.739977459073998, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 401, train_loss = 1.7387725872686133, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 402, train_loss = 1.7373620085418224, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 403, train_loss = 1.736694530933164, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 404, train_loss = 1.7355122765293345, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 405, train_loss = 1.7330359952757135, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 406, train_loss = 1.7319233877351508, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 407, train_loss = 1.732242301106453, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 408, train_loss = 1.7298787770560011, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 409, train_loss = 1.7293425450334325, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 410, train_loss = 1.728174727410078, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 411, train_loss = 1.7277881316840649, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 412, train_loss = 1.7258392932126299, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 413, train_loss = 1.7237162118544802, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 414, train_loss = 1.72385038563516, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 415, train_loss = 1.7233868576586246, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 416, train_loss = 1.7218897925922647, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 417, train_loss = 1.7192063318798319, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 418, train_loss = 1.7187962954631075, train_acc = 0.995575221238938\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 419, train_loss = 1.7182251922786236, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 420, train_loss = 1.717205839813687, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 421, train_loss = 1.7166286520659924, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 422, train_loss = 1.713731893687509, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 423, train_loss = 1.7138934234390035, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 424, train_loss = 1.7130911661079153, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 425, train_loss = 1.7120874052634463, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 426, train_loss = 1.709786020219326, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 427, train_loss = 1.709401094703935, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 428, train_loss = 1.708667683065869, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 429, train_loss = 1.7071628458797932, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 430, train_loss = 1.706322162062861, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 431, train_loss = 1.7057641968131065, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 432, train_loss = 1.7044754723319784, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 433, train_loss = 1.7038544155657291, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 434, train_loss = 1.7023924427339807, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 435, train_loss = 1.7013401513686404, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 436, train_loss = 1.7001813600072637, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 437, train_loss = 1.6990519799292088, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 438, train_loss = 1.6979369608452544, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 439, train_loss = 1.697494207532145, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 440, train_loss = 1.6951390305766836, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 441, train_loss = 1.6961844265460968, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 442, train_loss = 1.6950750686228275, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 443, train_loss = 1.6927770165493712, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 444, train_loss = 1.6926163248717785, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 445, train_loss = 1.6908323926618323, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 446, train_loss = 1.69041231891606, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 447, train_loss = 1.6891694279620424, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 448, train_loss = 1.6876070561120287, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 449, train_loss = 1.6874075817177072, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 450, train_loss = 1.6880283914506435, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 451, train_loss = 1.6856044493615627, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 452, train_loss = 1.6851523233344778, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 453, train_loss = 1.6835187872638926, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 454, train_loss = 1.6840938193490729, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 455, train_loss = 1.683119791210629, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 456, train_loss = 1.680910779745318, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 457, train_loss = 1.6811861569294706, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 458, train_loss = 1.6802568808197975, train_acc = 0.995575221238938\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 459, train_loss = 1.678008514107205, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 460, train_loss = 1.6788151897490025, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 461, train_loss = 1.6772980516543612, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 462, train_loss = 1.6757612526416779, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 463, train_loss = 1.675564595789183, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 464, train_loss = 1.674516998231411, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 465, train_loss = 1.673344788432587, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 466, train_loss = 1.6728999453480355, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 467, train_loss = 1.6726970312302, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 468, train_loss = 1.669836015731562, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 469, train_loss = 1.6703752974863164, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 470, train_loss = 1.668116744607687, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 471, train_loss = 1.6686946998233907, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 472, train_loss = 1.6670433320105076, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 473, train_loss = 1.666659664362669, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 474, train_loss = 1.6655757427215576, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 475, train_loss = 1.6652230334584601, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 476, train_loss = 1.6635029378230684, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 477, train_loss = 1.6645392130012624, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 478, train_loss = 1.6627536304295063, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 479, train_loss = 1.6615866981446743, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 480, train_loss = 1.6609219523961656, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 481, train_loss = 1.6600725017488003, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 482, train_loss = 1.6599152038688771, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 483, train_loss = 1.6583071897621267, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 484, train_loss = 1.658075111627113, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 485, train_loss = 1.6570657305419445, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 486, train_loss = 1.6574445702135563, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 487, train_loss = 1.6549543875153176, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 488, train_loss = 1.6549887495930307, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 489, train_loss = 1.6536835879087448, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 490, train_loss = 1.652803398668766, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 491, train_loss = 1.6528349121217616, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 492, train_loss = 1.651822557032574, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 493, train_loss = 1.650273232429754, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 494, train_loss = 1.6496554054319859, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 495, train_loss = 1.649096089124214, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 496, train_loss = 1.6489556469023228, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 497, train_loss = 1.6481071996386163, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 498, train_loss = 1.6470818097586744, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 499, train_loss = 1.6468195232446305, train_acc = 0.995575221238938\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 30/30 [4:31:34<00:00, 543.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4h 31min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    read_path = 'D:virus/image/2gram_768/'\n",
    "    \n",
    "    temp = [[],[]]\n",
    "    \n",
    "    Loader = D.File_loader()\n",
    "    data_a, label_a = Loader.read_files(read_path, interp = False)\n",
    "    \n",
    "    idx = np.argsort(label_a)\n",
    "    \n",
    "    sorted_data = data_a[idx].reshape(10736, -1)\n",
    "    sorted_label = sorted(label_a)\n",
    "        \n",
    "    BATCH_SIZE = 64\n",
    "    TOTAL = 30\n",
    "    EPOCH =500\n",
    "    NUM_CLASS = 9\n",
    "    LR = 0.0001\n",
    "    SEED = [s for s in range(TOTAL)]\n",
    "    Num_Nodes = 768\n",
    "    \n",
    "    CUDA_N = 'cuda:0'\n",
    "    \n",
    "    # creating data indices for spliting\n",
    "    full_dataset = CustomDataset(sorted_data, sorted_label)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # spliting\n",
    "    torch.manual_seed(10)\n",
    "    train_dataset, test_dataset = data.random_split(full_dataset, [train_size, test_size])\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    loss_total = []\n",
    "    acc_total = []\n",
    "    pred_total = []\n",
    "    true_total = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(TOTAL)):\n",
    "        \n",
    "        \n",
    "        device = torch.device(CUDA_N if torch.cuda.is_available() else 'cpu')\n",
    "        torch.manual_seed(SEED[i])\n",
    "        net = Mcslt(Num_Nodes, NUM_CLASS)\n",
    "        net.to(device)\n",
    "        print(net)\n",
    "        \n",
    "        softmax = nn.Softmax()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=LR, momentum = 0.1)\n",
    "        \n",
    "        loss_list = []\n",
    "        train_acc_list = []\n",
    "        test_acc_list = []\n",
    "        \n",
    "        pred_temp = []\n",
    "        true_temp = []\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            net.train()\n",
    "            running_loss = 0\n",
    "            total = train_size\n",
    "            correct = 0 \n",
    "            \n",
    "            for step, images_labels in enumerate(train_loader):\n",
    "                inputs, labels = images_labels\n",
    "                inputs, labels = inputs.type(torch.FloatTensor).to(device), labels.type(torch.LongTensor).to(device)\n",
    "                \n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, pred = torch.max(outputs, dim=1)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            train_acc = correct/total\n",
    "            loss_list.append(running_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "            print('{}th- epoch: {}, train_loss = {}, train_acc = {}'.format(i+1, epoch, running_loss, train_acc))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                correct = 0\n",
    "                total = test_size\n",
    "                pt, tt = [], []\n",
    "                \n",
    "                for step_t, images_labels_t in enumerate(test_loader):\n",
    "                    inputs_t, labels_t = images_labels_t\n",
    "                    inputs_t, labels_t = inputs_t.type(torch.FloatTensor).to(device), labels_t.type(torch.LongTensor).to(device)\n",
    "                    \n",
    "                    outputs_t = net(inputs_t)\n",
    "                    outputs_t = softmax(outputs_t)\n",
    "                    \n",
    "                    # test accuracy\n",
    "                    _, pred_t = torch.max(outputs_t, dim = 1)\n",
    "                    \n",
    "                    pt.append(pred_t)\n",
    "                    tt.append(labels_t)\n",
    "                    \n",
    "                    correct += (pred_t == labels_t).sum().item()\n",
    "                    \n",
    "                pred_temp.append(torch.cat(pt))\n",
    "                true_temp.append(torch.cat(tt))\n",
    "                \n",
    "                test_acc = correct/total\n",
    "                test_acc_list.append(test_acc)\n",
    "                \n",
    "                print('test Acc {}:'.format(test_acc))\n",
    "                \n",
    "        best_result_index = np.argmax(np.array(test_acc_list))\n",
    "        loss_total.append(loss_list[best_result_index])\n",
    "        acc_total.append(test_acc_list[best_result_index])\n",
    "        pred_total.append(pred_temp[best_result_index].tolist())\n",
    "        true_total.append(true_temp[best_result_index].tolist())\n",
    "        \n",
    "    file_name = 'res/Mcslt_2gram'\n",
    "    torch.save(net.state_dict(), file_name +'.pth')\n",
    "    \n",
    "    loss_DF = pd.DataFrame(loss_total)\n",
    "    loss_DF.to_csv(file_name+\" loss.csv\")\n",
    "    \n",
    "    acc_DF = pd.DataFrame(acc_total)\n",
    "    acc_DF.to_csv(file_name +\" acc.csv\")\n",
    "    \n",
    "    pred_DF = pd.DataFrame(pred_total)\n",
    "    pred_DF.to_csv(file_name +\" pred.csv\")\n",
    "    \n",
    "    true_DF = pd.DataFrame(true_total)\n",
    "    true_DF.to_csv(file_name +\" true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
