{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import utility.Data_loader as D\n",
    "from utility.Model import MCSP\n",
    "from utility.Custom import CustomDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "1th- epoch: 0, train_loss = 271.2672520875931, train_acc = 0.41825803446669774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DTools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.4883612662942272:\n",
      "1th- epoch: 1, train_loss = 214.01694536209106, train_acc = 0.49580810433162553\n",
      "test Acc 0.4995344506517691:\n",
      "1th- epoch: 2, train_loss = 182.19874835014343, train_acc = 0.5046576618537494\n",
      "test Acc 0.5088454376163873:\n",
      "1th- epoch: 3, train_loss = 166.00276082754135, train_acc = 0.5244527247321844\n",
      "test Acc 0.5451582867783985:\n",
      "1th- epoch: 4, train_loss = 153.8338621854782, train_acc = 0.569981369352585\n",
      "test Acc 0.6019553072625698:\n",
      "1th- epoch: 5, train_loss = 142.8161992430687, train_acc = 0.6151606893339544\n",
      "test Acc 0.6359404096834265:\n",
      "1th- epoch: 6, train_loss = 132.31497937440872, train_acc = 0.6376339077782953\n",
      "test Acc 0.6499068901303539:\n",
      "1th- epoch: 7, train_loss = 122.23918217420578, train_acc = 0.6701210992081975\n",
      "test Acc 0.681098696461825:\n",
      "1th- epoch: 8, train_loss = 112.69693922996521, train_acc = 0.7111085235211924\n",
      "test Acc 0.7653631284916201:\n",
      "1th- epoch: 9, train_loss = 103.86176759004593, train_acc = 0.778178854215184\n",
      "test Acc 0.7886405959031657:\n",
      "1th- epoch: 10, train_loss = 95.87765175104141, train_acc = 0.805891942244993\n",
      "test Acc 0.8133147113594041:\n",
      "1th- epoch: 11, train_loss = 88.77799594402313, train_acc = 0.8209129017233349\n",
      "test Acc 0.8282122905027933:\n",
      "1th- epoch: 12, train_loss = 82.5495753288269, train_acc = 0.8302282254308337\n",
      "test Acc 0.8379888268156425:\n",
      "1th- epoch: 13, train_loss = 77.12100604176521, train_acc = 0.8404750815090825\n",
      "test Acc 0.8575418994413407:\n",
      "1th- epoch: 14, train_loss = 72.39102989435196, train_acc = 0.8539823008849557\n",
      "test Acc 0.861266294227188:\n",
      "1th- epoch: 15, train_loss = 68.26106771826744, train_acc = 0.8624825337680484\n",
      "test Acc 0.8691806331471136:\n",
      "1th- epoch: 16, train_loss = 64.64892518520355, train_acc = 0.8686539357242664\n",
      "test Acc 0.87243947858473:\n",
      "1th- epoch: 17, train_loss = 61.47719594836235, train_acc = 0.872380065207266\n",
      "test Acc 0.8766294227188082:\n",
      "1th- epoch: 18, train_loss = 58.68905720114708, train_acc = 0.8768048439683279\n",
      "test Acc 0.8812849162011173:\n",
      "1th- epoch: 19, train_loss = 56.23664806783199, train_acc = 0.8827433628318584\n",
      "test Acc 0.888733705772812:\n",
      "1th- epoch: 20, train_loss = 54.073801174759865, train_acc = 0.8879832324173265\n",
      "test Acc 0.8952513966480447:\n",
      "1th- epoch: 21, train_loss = 52.164852261543274, train_acc = 0.893921751280857\n",
      "test Acc 0.8975791433891993:\n",
      "1th- epoch: 22, train_loss = 50.472004637122154, train_acc = 0.8959012575687005\n",
      "test Acc 0.898975791433892:\n",
      "1th- epoch: 23, train_loss = 48.96311040222645, train_acc = 0.8977643223102003\n",
      "test Acc 0.9017690875232774:\n",
      "1th- epoch: 24, train_loss = 47.61166813969612, train_acc = 0.8982300884955752\n",
      "test Acc 0.904562383612663:\n",
      "1th- epoch: 25, train_loss = 46.3953797519207, train_acc = 0.9004424778761062\n",
      "test Acc 0.9054934823091247:\n",
      "1th- epoch: 26, train_loss = 45.29362826049328, train_acc = 0.9019562179785747\n",
      "test Acc 0.9054934823091247:\n",
      "1th- epoch: 27, train_loss = 44.28963638842106, train_acc = 0.9034699580810434\n",
      "test Acc 0.9082867783985102:\n",
      "1th- epoch: 28, train_loss = 43.36835287511349, train_acc = 0.9055659059152306\n",
      "test Acc 0.9106145251396648:\n",
      "1th- epoch: 29, train_loss = 42.51699806749821, train_acc = 0.9071960875640428\n",
      "test Acc 0.9110800744878957:\n",
      "1th- epoch: 30, train_loss = 41.727783158421516, train_acc = 0.9082440614811365\n",
      "test Acc 0.9115456238361266:\n",
      "1th- epoch: 31, train_loss = 40.99403718113899, train_acc = 0.9088262692128551\n",
      "test Acc 0.9124767225325885:\n",
      "1th- epoch: 32, train_loss = 40.30776698887348, train_acc = 0.9110386585933862\n",
      "test Acc 0.9134078212290503:\n",
      "1th- epoch: 33, train_loss = 39.66524565219879, train_acc = 0.9123195156031673\n",
      "test Acc 0.9134078212290503:\n",
      "1th- epoch: 34, train_loss = 39.06030520796776, train_acc = 0.9138332557056358\n",
      "test Acc 0.914804469273743:\n",
      "1th- epoch: 35, train_loss = 38.48896339535713, train_acc = 0.9156963204471356\n",
      "test Acc 0.9166666666666666:\n",
      "1th- epoch: 36, train_loss = 37.946754425764084, train_acc = 0.9175593851886353\n",
      "test Acc 0.9175977653631285:\n",
      "1th- epoch: 37, train_loss = 37.432326301932335, train_acc = 0.9189566837447601\n",
      "test Acc 0.9180633147113594:\n",
      "1th- epoch: 38, train_loss = 36.94338694214821, train_acc = 0.9203539823008849\n",
      "test Acc 0.9189944134078212:\n",
      "1th- epoch: 39, train_loss = 36.47674924135208, train_acc = 0.9219841639496973\n",
      "test Acc 0.9194599627560521:\n",
      "1th- epoch: 40, train_loss = 36.03120828419924, train_acc = 0.9231485794131346\n",
      "test Acc 0.9199255121042831:\n",
      "1th- epoch: 41, train_loss = 35.604983918368816, train_acc = 0.9241965533302282\n",
      "test Acc 0.9203910614525139:\n",
      "1th- epoch: 42, train_loss = 35.196621119976044, train_acc = 0.9257102934326968\n",
      "test Acc 0.9208566108007449:\n",
      "1th- epoch: 43, train_loss = 34.80449068546295, train_acc = 0.9262925011644154\n",
      "test Acc 0.9217877094972067:\n",
      "1th- epoch: 44, train_loss = 34.42792496085167, train_acc = 0.9272240335351654\n",
      "test Acc 0.9241154562383612:\n",
      "1th- epoch: 45, train_loss = 34.06635305285454, train_acc = 0.9275733581741965\n",
      "test Acc 0.9241154562383612:\n",
      "1th- epoch: 46, train_loss = 33.718541510403156, train_acc = 0.9280391243595715\n",
      "test Acc 0.9245810055865922:\n",
      "1th- epoch: 47, train_loss = 33.38360487669706, train_acc = 0.9288542151839776\n",
      "test Acc 0.9245810055865922:\n",
      "1th- epoch: 48, train_loss = 33.060968555510044, train_acc = 0.9293199813693526\n",
      "test Acc 0.9245810055865922:\n",
      "1th- epoch: 49, train_loss = 32.74987640231848, train_acc = 0.9294364229156963\n",
      "test Acc 0.9250465549348231:\n",
      "1th- epoch: 50, train_loss = 32.44897695630789, train_acc = 0.930018630647415\n",
      "test Acc 0.925512104283054:\n",
      "1th- epoch: 51, train_loss = 32.157382756471634, train_acc = 0.9306008383791337\n",
      "test Acc 0.9259776536312849:\n",
      "1th- epoch: 52, train_loss = 31.87543223053217, train_acc = 0.9310666045645086\n",
      "test Acc 0.9259776536312849:\n",
      "1th- epoch: 53, train_loss = 31.60246802866459, train_acc = 0.9315323707498836\n",
      "test Acc 0.9264432029795159:\n",
      "1th- epoch: 54, train_loss = 31.33762137591839, train_acc = 0.9315323707498836\n",
      "test Acc 0.9264432029795159:\n",
      "1th- epoch: 55, train_loss = 31.080282516777515, train_acc = 0.932231020027946\n",
      "test Acc 0.9264432029795159:\n",
      "1th- epoch: 56, train_loss = 30.829762779176235, train_acc = 0.9325803446669771\n",
      "test Acc 0.9264432029795159:\n",
      "1th- epoch: 57, train_loss = 30.586120270192623, train_acc = 0.9328132277596647\n",
      "test Acc 0.9264432029795159:\n",
      "1th- epoch: 58, train_loss = 30.34812431037426, train_acc = 0.9331625523986958\n",
      "test Acc 0.9264432029795159:\n",
      "1th- epoch: 59, train_loss = 30.116841822862625, train_acc = 0.9335118770377271\n",
      "test Acc 0.9264432029795159:\n",
      "1th- epoch: 60, train_loss = 29.891346141695976, train_acc = 0.9338612016767582\n",
      "test Acc 0.9273743016759777:\n",
      "1th- epoch: 61, train_loss = 29.671921387314796, train_acc = 0.9344434094084769\n",
      "test Acc 0.9273743016759777:\n",
      "1th- epoch: 62, train_loss = 29.458426512777805, train_acc = 0.9346762925011645\n",
      "test Acc 0.9278398510242085:\n",
      "1th- epoch: 63, train_loss = 29.249663785099983, train_acc = 0.9349091755938519\n",
      "test Acc 0.9283054003724395:\n",
      "1th- epoch: 64, train_loss = 29.046326965093613, train_acc = 0.9353749417792269\n",
      "test Acc 0.9283054003724395:\n",
      "1th- epoch: 65, train_loss = 28.848372295498848, train_acc = 0.935724266418258\n",
      "test Acc 0.9283054003724395:\n",
      "1th- epoch: 66, train_loss = 28.654911875724792, train_acc = 0.9360735910572893\n",
      "test Acc 0.9283054003724395:\n",
      "1th- epoch: 67, train_loss = 28.46532092988491, train_acc = 0.936190032603633\n",
      "test Acc 0.9283054003724395:\n",
      "1th- epoch: 68, train_loss = 28.27973924577236, train_acc = 0.9367722403353517\n",
      "test Acc 0.9283054003724395:\n",
      "1th- epoch: 69, train_loss = 28.099021926522255, train_acc = 0.9375873311597578\n",
      "test Acc 0.9292364990689013:\n",
      "1th- epoch: 70, train_loss = 27.921234399080276, train_acc = 0.9377037727061015\n",
      "test Acc 0.9292364990689013:\n",
      "1th- epoch: 71, train_loss = 27.747342959046364, train_acc = 0.937936655798789\n",
      "test Acc 0.9297020484171322:\n",
      "1th- epoch: 72, train_loss = 27.57747931778431, train_acc = 0.9388681881695389\n",
      "test Acc 0.9297020484171322:\n",
      "1th- epoch: 73, train_loss = 27.41088491678238, train_acc = 0.9395668374476013\n",
      "test Acc 0.9301675977653632:\n",
      "1th- epoch: 74, train_loss = 27.247624572366476, train_acc = 0.9397997205402888\n",
      "test Acc 0.931098696461825:\n",
      "1th- epoch: 75, train_loss = 27.08669351041317, train_acc = 0.9400326036329762\n",
      "test Acc 0.9315642458100558:\n",
      "1th- epoch: 76, train_loss = 26.92831216007471, train_acc = 0.94014904517932\n",
      "test Acc 0.9315642458100558:\n",
      "1th- epoch: 77, train_loss = 26.773252200335264, train_acc = 0.9402654867256637\n",
      "test Acc 0.9315642458100558:\n",
      "1th- epoch: 78, train_loss = 26.621287178248167, train_acc = 0.9404983698183512\n",
      "test Acc 0.9320297951582868:\n",
      "1th- epoch: 79, train_loss = 26.472527142614126, train_acc = 0.9410805775500699\n",
      "test Acc 0.9320297951582868:\n",
      "1th- epoch: 80, train_loss = 26.326822079718113, train_acc = 0.941429902189101\n",
      "test Acc 0.9320297951582868:\n",
      "1th- epoch: 81, train_loss = 26.183881416916847, train_acc = 0.9416627852817886\n",
      "test Acc 0.9320297951582868:\n",
      "1th- epoch: 82, train_loss = 26.043019082397223, train_acc = 0.941895668374476\n",
      "test Acc 0.9320297951582868:\n",
      "1th- epoch: 83, train_loss = 25.905559953302145, train_acc = 0.9420121099208197\n",
      "test Acc 0.9324953445065177:\n",
      "1th- epoch: 84, train_loss = 25.77062239870429, train_acc = 0.9421285514671635\n",
      "test Acc 0.9324953445065177:\n",
      "1th- epoch: 85, train_loss = 25.637900196015835, train_acc = 0.9425943176525384\n",
      "test Acc 0.9329608938547486:\n",
      "1th- epoch: 86, train_loss = 25.508060306310654, train_acc = 0.9429436422915697\n",
      "test Acc 0.9329608938547486:\n",
      "1th- epoch: 87, train_loss = 25.380926299840212, train_acc = 0.9432929669306008\n",
      "test Acc 0.9329608938547486:\n",
      "1th- epoch: 88, train_loss = 25.25575463473797, train_acc = 0.9434094084769445\n",
      "test Acc 0.9329608938547486:\n",
      "1th- epoch: 89, train_loss = 25.133298490196466, train_acc = 0.9439916162086632\n",
      "test Acc 0.9329608938547486:\n",
      "1th- epoch: 90, train_loss = 25.01297676190734, train_acc = 0.9438751746623195\n",
      "test Acc 0.9329608938547486:\n",
      "1th- epoch: 91, train_loss = 24.89470386877656, train_acc = 0.944108057755007\n",
      "test Acc 0.9329608938547486:\n",
      "1th- epoch: 92, train_loss = 24.77876202762127, train_acc = 0.9442244993013508\n",
      "test Acc 0.9329608938547486:\n",
      "1th- epoch: 93, train_loss = 24.664932008832693, train_acc = 0.9444573823940382\n",
      "test Acc 0.9334264432029795:\n",
      "1th- epoch: 94, train_loss = 24.553004942834377, train_acc = 0.9445738239403819\n",
      "test Acc 0.9338919925512105:\n",
      "1th- epoch: 95, train_loss = 24.443118035793304, train_acc = 0.9450395901257569\n",
      "test Acc 0.9343575418994413:\n",
      "1th- epoch: 96, train_loss = 24.334761451929808, train_acc = 0.9452724732184443\n",
      "test Acc 0.9343575418994413:\n",
      "1th- epoch: 97, train_loss = 24.228928931057453, train_acc = 0.9455053563111319\n",
      "test Acc 0.9348230912476723:\n",
      "1th- epoch: 98, train_loss = 24.124806713312864, train_acc = 0.9457382394038193\n",
      "test Acc 0.9348230912476723:\n",
      "1th- epoch: 99, train_loss = 24.02222530171275, train_acc = 0.9459711224965067\n",
      "test Acc 0.9348230912476723:\n",
      "1th- epoch: 100, train_loss = 23.921377509832382, train_acc = 0.946320447135538\n",
      "test Acc 0.9348230912476723:\n",
      "1th- epoch: 101, train_loss = 23.822078820317984, train_acc = 0.9465533302282254\n",
      "test Acc 0.9348230912476723:\n",
      "1th- epoch: 102, train_loss = 23.724446840584278, train_acc = 0.946786213320913\n",
      "test Acc 0.9348230912476723:\n",
      "1th- epoch: 103, train_loss = 23.62868256866932, train_acc = 0.9470190964136004\n",
      "test Acc 0.9352886405959032:\n",
      "1th- epoch: 104, train_loss = 23.534315038472414, train_acc = 0.9472519795062878\n",
      "test Acc 0.9352886405959032:\n",
      "1th- epoch: 105, train_loss = 23.44140176102519, train_acc = 0.9474848625989754\n",
      "test Acc 0.9357541899441341:\n",
      "1th- epoch: 106, train_loss = 23.350161492824554, train_acc = 0.9478341872380065\n",
      "test Acc 0.9357541899441341:\n",
      "1th- epoch: 107, train_loss = 23.259880881756544, train_acc = 0.948067070330694\n",
      "test Acc 0.9357541899441341:\n",
      "1th- epoch: 108, train_loss = 23.171104561537504, train_acc = 0.9484163949697252\n",
      "test Acc 0.9357541899441341:\n",
      "1th- epoch: 109, train_loss = 23.08385442942381, train_acc = 0.9485328365160689\n",
      "test Acc 0.936219739292365:\n",
      "1th- epoch: 110, train_loss = 22.99840931966901, train_acc = 0.9487657196087564\n",
      "test Acc 0.9366852886405959:\n",
      "1th- epoch: 111, train_loss = 22.914382629096508, train_acc = 0.9488821611551002\n",
      "test Acc 0.9366852886405959:\n",
      "1th- epoch: 112, train_loss = 22.83150266483426, train_acc = 0.9488821611551002\n",
      "test Acc 0.9366852886405959:\n",
      "1th- epoch: 113, train_loss = 22.750151693820953, train_acc = 0.9489986027014439\n",
      "test Acc 0.9366852886405959:\n",
      "1th- epoch: 114, train_loss = 22.669669207185507, train_acc = 0.9491150442477876\n",
      "test Acc 0.9376163873370578:\n",
      "1th- epoch: 115, train_loss = 22.590198297053576, train_acc = 0.9492314857941313\n",
      "test Acc 0.9376163873370578:\n",
      "1th- epoch: 116, train_loss = 22.511819187551737, train_acc = 0.9496972519795063\n",
      "test Acc 0.9380819366852886:\n",
      "1th- epoch: 117, train_loss = 22.434445165097713, train_acc = 0.94981369352585\n",
      "test Acc 0.9380819366852886:\n",
      "1th- epoch: 118, train_loss = 22.358287822455168, train_acc = 0.9499301350721937\n",
      "test Acc 0.9385474860335196:\n",
      "1th- epoch: 119, train_loss = 22.282905284315348, train_acc = 0.9501630181648812\n",
      "test Acc 0.9385474860335196:\n",
      "1th- epoch: 120, train_loss = 22.209051579236984, train_acc = 0.9501630181648812\n",
      "test Acc 0.9385474860335196:\n",
      "1th- epoch: 121, train_loss = 22.135632503777742, train_acc = 0.950279459711225\n",
      "test Acc 0.9385474860335196:\n",
      "1th- epoch: 122, train_loss = 22.063593946397305, train_acc = 0.950279459711225\n",
      "test Acc 0.9385474860335196:\n",
      "1th- epoch: 123, train_loss = 21.992350969463587, train_acc = 0.950279459711225\n",
      "test Acc 0.9380819366852886:\n",
      "1th- epoch: 124, train_loss = 21.922046270221472, train_acc = 0.950279459711225\n",
      "test Acc 0.9380819366852886:\n",
      "1th- epoch: 125, train_loss = 21.852675560861826, train_acc = 0.9505123428039124\n",
      "test Acc 0.9385474860335196:\n",
      "1th- epoch: 126, train_loss = 21.783955398947, train_acc = 0.9506287843502562\n",
      "test Acc 0.9385474860335196:\n",
      "1th- epoch: 127, train_loss = 21.716348256915808, train_acc = 0.9508616674429436\n",
      "test Acc 0.9385474860335196:\n",
      "1th- epoch: 128, train_loss = 21.649712167680264, train_acc = 0.9512109920819748\n",
      "test Acc 0.9385474860335196:\n",
      "1th- epoch: 129, train_loss = 21.583408996462822, train_acc = 0.9513274336283186\n",
      "test Acc 0.9385474860335196:\n",
      "1th- epoch: 130, train_loss = 21.51866888254881, train_acc = 0.951560316721006\n",
      "test Acc 0.9385474860335196:\n",
      "1th- epoch: 131, train_loss = 21.45379961282015, train_acc = 0.951560316721006\n",
      "test Acc 0.9390130353817505:\n",
      "1th- epoch: 132, train_loss = 21.39068979769945, train_acc = 0.9519096413600373\n",
      "test Acc 0.9394785847299814:\n",
      "1th- epoch: 133, train_loss = 21.32793816551566, train_acc = 0.9519096413600373\n",
      "test Acc 0.9394785847299814:\n",
      "1th- epoch: 134, train_loss = 21.265878651291132, train_acc = 0.9519096413600373\n",
      "test Acc 0.9394785847299814:\n",
      "1th- epoch: 135, train_loss = 21.204876381903887, train_acc = 0.9521425244527247\n",
      "test Acc 0.9399441340782123:\n",
      "1th- epoch: 136, train_loss = 21.144539039582014, train_acc = 0.9523754075454122\n",
      "test Acc 0.9399441340782123:\n",
      "1th- epoch: 137, train_loss = 21.08497040718794, train_acc = 0.9523754075454122\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 138, train_loss = 21.026222333312035, train_acc = 0.9526082906380997\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 139, train_loss = 20.96806215122342, train_acc = 0.9527247321844434\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 140, train_loss = 20.910195257514715, train_acc = 0.9529576152771309\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 141, train_loss = 20.85282900556922, train_acc = 0.9531904983698184\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 142, train_loss = 20.797331262379885, train_acc = 0.9531904983698184\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 143, train_loss = 20.74146707355976, train_acc = 0.9531904983698184\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 144, train_loss = 20.685506403446198, train_acc = 0.9531904983698184\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 145, train_loss = 20.631331734359264, train_acc = 0.9534233814625058\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 146, train_loss = 20.577371070161462, train_acc = 0.9535398230088495\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 147, train_loss = 20.523728132247925, train_acc = 0.9535398230088495\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 148, train_loss = 20.47060096077621, train_acc = 0.9535398230088495\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 149, train_loss = 20.418142249807715, train_acc = 0.9536562645551933\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 150, train_loss = 20.367018604651093, train_acc = 0.9538891476478808\n",
      "test Acc 0.9408752327746741:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 151, train_loss = 20.31556594185531, train_acc = 0.9542384722869119\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 152, train_loss = 20.26522314734757, train_acc = 0.9542384722869119\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 153, train_loss = 20.213884880766273, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 154, train_loss = 20.16530113480985, train_acc = 0.9544713553795995\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 155, train_loss = 20.115578582510352, train_acc = 0.9544713553795995\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 156, train_loss = 20.066991152241826, train_acc = 0.9545877969259432\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 157, train_loss = 20.01737269759178, train_acc = 0.9548206800186306\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 158, train_loss = 19.969882497563958, train_acc = 0.9548206800186306\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 159, train_loss = 19.92299798130989, train_acc = 0.9548206800186306\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 160, train_loss = 19.87636031396687, train_acc = 0.9548206800186306\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 161, train_loss = 19.829958708956838, train_acc = 0.9549371215649743\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 162, train_loss = 19.78366300277412, train_acc = 0.9548206800186306\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 163, train_loss = 19.738736677914858, train_acc = 0.9549371215649743\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 164, train_loss = 19.693106217309833, train_acc = 0.9551700046576619\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 165, train_loss = 19.64752455241978, train_acc = 0.9554028877503493\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 166, train_loss = 19.60341096110642, train_acc = 0.955519329296693\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 167, train_loss = 19.56073864363134, train_acc = 0.9558686539357243\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 168, train_loss = 19.51596068777144, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "1th- epoch: 169, train_loss = 19.474018059670925, train_acc = 0.9561015370284117\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 170, train_loss = 19.429727263748646, train_acc = 0.9563344201210993\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 171, train_loss = 19.38745723478496, train_acc = 0.956450861667443\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 172, train_loss = 19.345588168129325, train_acc = 0.956450861667443\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 173, train_loss = 19.304623192176223, train_acc = 0.9568001863064741\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 174, train_loss = 19.26304049603641, train_acc = 0.9570330693991617\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 175, train_loss = 19.2212135810405, train_acc = 0.9570330693991617\n",
      "test Acc 0.9418063314711359:\n",
      "1th- epoch: 176, train_loss = 19.181565515697002, train_acc = 0.9570330693991617\n",
      "test Acc 0.9418063314711359:\n",
      "1th- epoch: 177, train_loss = 19.141014086082578, train_acc = 0.9571495109455054\n",
      "test Acc 0.9422718808193669:\n",
      "1th- epoch: 178, train_loss = 19.100867116823792, train_acc = 0.9570330693991617\n",
      "test Acc 0.9427374301675978:\n",
      "1th- epoch: 179, train_loss = 19.06068598665297, train_acc = 0.9571495109455054\n",
      "test Acc 0.9427374301675978:\n",
      "1th- epoch: 180, train_loss = 19.02159775607288, train_acc = 0.9571495109455054\n",
      "test Acc 0.9427374301675978:\n",
      "1th- epoch: 181, train_loss = 18.98264446295798, train_acc = 0.9572659524918491\n",
      "test Acc 0.9427374301675978:\n",
      "1th- epoch: 182, train_loss = 18.94338578172028, train_acc = 0.9572659524918491\n",
      "test Acc 0.9427374301675978:\n",
      "1th- epoch: 183, train_loss = 18.90643692947924, train_acc = 0.9572659524918491\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 184, train_loss = 18.867981689050794, train_acc = 0.9574988355845365\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 185, train_loss = 18.83172946423292, train_acc = 0.9574988355845365\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 186, train_loss = 18.794079920277, train_acc = 0.9577317186772241\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 187, train_loss = 18.756686283275485, train_acc = 0.9579646017699115\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 188, train_loss = 18.72070183046162, train_acc = 0.9579646017699115\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 189, train_loss = 18.68401639908552, train_acc = 0.9580810433162552\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 190, train_loss = 18.647927401587367, train_acc = 0.9580810433162552\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 191, train_loss = 18.61156884394586, train_acc = 0.9581974848625989\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 192, train_loss = 18.57617243938148, train_acc = 0.9581974848625989\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 193, train_loss = 18.541430786252022, train_acc = 0.9584303679552865\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 194, train_loss = 18.506898880004883, train_acc = 0.9586632510479739\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 195, train_loss = 18.470657816156745, train_acc = 0.9586632510479739\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 196, train_loss = 18.43838400952518, train_acc = 0.9587796925943176\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 197, train_loss = 18.403212320059538, train_acc = 0.9587796925943176\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 198, train_loss = 18.370257426053286, train_acc = 0.9587796925943176\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 199, train_loss = 18.336679078638554, train_acc = 0.9587796925943176\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 200, train_loss = 18.304271060973406, train_acc = 0.9587796925943176\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 201, train_loss = 18.27036214992404, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 202, train_loss = 18.239409578964114, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 203, train_loss = 18.20573678985238, train_acc = 0.9590125756870052\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 204, train_loss = 18.175289526581764, train_acc = 0.9590125756870052\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 205, train_loss = 18.14221635647118, train_acc = 0.9591290172333489\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 206, train_loss = 18.11113023944199, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 207, train_loss = 18.07984935492277, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 208, train_loss = 18.04862172342837, train_acc = 0.9593619003260363\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 209, train_loss = 18.018262961879373, train_acc = 0.9593619003260363\n",
      "test Acc 0.9455307262569832:\n",
      "1th- epoch: 210, train_loss = 17.986909341067076, train_acc = 0.9593619003260363\n",
      "test Acc 0.9455307262569832:\n",
      "1th- epoch: 211, train_loss = 17.956415148451924, train_acc = 0.9593619003260363\n",
      "test Acc 0.9455307262569832:\n",
      "1th- epoch: 212, train_loss = 17.927369499579072, train_acc = 0.9593619003260363\n",
      "test Acc 0.9455307262569832:\n",
      "1th- epoch: 213, train_loss = 17.89750849083066, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 214, train_loss = 17.86828705854714, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 215, train_loss = 17.838971393182874, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 216, train_loss = 17.80974950455129, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 217, train_loss = 17.78228429146111, train_acc = 0.95947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 218, train_loss = 17.753064127638936, train_acc = 0.95947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 219, train_loss = 17.725073581561446, train_acc = 0.9595947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 220, train_loss = 17.69718018732965, train_acc = 0.9595947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 221, train_loss = 17.668720297515392, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 222, train_loss = 17.640876131132245, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 223, train_loss = 17.614218251779675, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 224, train_loss = 17.58784024603665, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 225, train_loss = 17.559962218627334, train_acc = 0.959944108057755\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 226, train_loss = 17.533563151955605, train_acc = 0.9601769911504425\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 227, train_loss = 17.507038719952106, train_acc = 0.96040987424313\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 228, train_loss = 17.48172820918262, train_acc = 0.96040987424313\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 229, train_loss = 17.455296205356717, train_acc = 0.96040987424313\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 230, train_loss = 17.429749140515924, train_acc = 0.96040987424313\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 231, train_loss = 17.40462512522936, train_acc = 0.96040987424313\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 232, train_loss = 17.378877149894834, train_acc = 0.96040987424313\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 233, train_loss = 17.35382147692144, train_acc = 0.9607591988821611\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 234, train_loss = 17.329136857762933, train_acc = 0.9608756404285049\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 235, train_loss = 17.30494554899633, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 236, train_loss = 17.280469436198473, train_acc = 0.9611085235211924\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 237, train_loss = 17.256493153050542, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 238, train_loss = 17.231816137209535, train_acc = 0.9614578481602236\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 239, train_loss = 17.207997674122453, train_acc = 0.9614578481602236\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 240, train_loss = 17.184159215539694, train_acc = 0.9614578481602236\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 241, train_loss = 17.160932559520006, train_acc = 0.9614578481602236\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 242, train_loss = 17.136712537147105, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 243, train_loss = 17.114010642282665, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 244, train_loss = 17.091644286178052, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 245, train_loss = 17.068882492370903, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 246, train_loss = 17.04661179613322, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 247, train_loss = 17.02337791863829, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 248, train_loss = 17.002210441045463, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 249, train_loss = 16.979036387987435, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 250, train_loss = 16.956993277184665, train_acc = 0.9615742897065673\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 251, train_loss = 16.935431393794715, train_acc = 0.9615742897065673\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 252, train_loss = 16.914838198572397, train_acc = 0.961690731252911\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 253, train_loss = 16.89195451606065, train_acc = 0.961690731252911\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 254, train_loss = 16.870681811124086, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 255, train_loss = 16.849259763024747, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 256, train_loss = 16.828957185149193, train_acc = 0.9620400558919422\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 257, train_loss = 16.80911546573043, train_acc = 0.9620400558919422\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 258, train_loss = 16.787578356452286, train_acc = 0.9620400558919422\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 259, train_loss = 16.768638393841684, train_acc = 0.962156497438286\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 260, train_loss = 16.74676550924778, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 261, train_loss = 16.72767172008753, train_acc = 0.9625058220773172\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 262, train_loss = 16.706176708452404, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 263, train_loss = 16.68634695187211, train_acc = 0.9628551467163484\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 264, train_loss = 16.668057277798653, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 265, train_loss = 16.647237233817577, train_acc = 0.9628551467163484\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 266, train_loss = 16.62851864937693, train_acc = 0.9630880298090359\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 267, train_loss = 16.608943548984826, train_acc = 0.9632044713553796\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 268, train_loss = 16.589089646935463, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 269, train_loss = 16.571264941245317, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 270, train_loss = 16.551194452680647, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 271, train_loss = 16.533170147798955, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 272, train_loss = 16.51408440526575, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 273, train_loss = 16.494948119856417, train_acc = 0.9634373544480671\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 274, train_loss = 16.475436219014227, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 275, train_loss = 16.457455831579864, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 276, train_loss = 16.438676458783448, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 277, train_loss = 16.42146000545472, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 278, train_loss = 16.403381414711475, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 279, train_loss = 16.38486551400274, train_acc = 0.9634373544480671\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 280, train_loss = 16.367639034986496, train_acc = 0.9634373544480671\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 281, train_loss = 16.350070510990918, train_acc = 0.9634373544480671\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 282, train_loss = 16.332942756824195, train_acc = 0.9634373544480671\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 283, train_loss = 16.314833521842957, train_acc = 0.9634373544480671\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 284, train_loss = 16.298385326750576, train_acc = 0.9634373544480671\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 285, train_loss = 16.28208641242236, train_acc = 0.9634373544480671\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 286, train_loss = 16.263846294023097, train_acc = 0.9636702375407545\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 287, train_loss = 16.24787037447095, train_acc = 0.9637866790870983\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 288, train_loss = 16.23007547110319, train_acc = 0.9637866790870983\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 289, train_loss = 16.215490244328976, train_acc = 0.963903120633442\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 290, train_loss = 16.198090709745884, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 291, train_loss = 16.182256128638983, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 292, train_loss = 16.16560976859182, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 293, train_loss = 16.150396867655218, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 294, train_loss = 16.13383641000837, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 295, train_loss = 16.11610797047615, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 296, train_loss = 16.1011753519997, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 297, train_loss = 16.086083103902638, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 298, train_loss = 16.06968350801617, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 299, train_loss = 16.055102348327637, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 300, train_loss = 16.040284052491188, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 301, train_loss = 16.024240251630545, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 302, train_loss = 16.00871830433607, train_acc = 0.9640195621797858\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 303, train_loss = 15.99330114852637, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 304, train_loss = 15.976489018648863, train_acc = 0.9640195621797858\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 305, train_loss = 15.963604263961315, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 306, train_loss = 15.948566883802414, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 307, train_loss = 15.933951030485332, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 308, train_loss = 15.918092358857393, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 309, train_loss = 15.903884906321764, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 310, train_loss = 15.890143225900829, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 311, train_loss = 15.875597304664552, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 312, train_loss = 15.861309832893312, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 313, train_loss = 15.8469722783193, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 314, train_loss = 15.832111399620771, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 315, train_loss = 15.818863646127284, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 316, train_loss = 15.804716053418815, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 317, train_loss = 15.790833893232048, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 318, train_loss = 15.776331004686654, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 319, train_loss = 15.76300194952637, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 320, train_loss = 15.749279080890119, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 321, train_loss = 15.736025770194829, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 322, train_loss = 15.722954399883747, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 323, train_loss = 15.709376752376556, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 324, train_loss = 15.694850948639214, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 325, train_loss = 15.682066301815212, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 326, train_loss = 15.669681089930236, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 327, train_loss = 15.65535816643387, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 328, train_loss = 15.64305239636451, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 329, train_loss = 15.630001220852137, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 330, train_loss = 15.616285238415003, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 331, train_loss = 15.603900621645153, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 332, train_loss = 15.589972499758005, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 333, train_loss = 15.578457272611558, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 334, train_loss = 15.56642984971404, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 335, train_loss = 15.553387339226902, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 336, train_loss = 15.540325530804694, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 337, train_loss = 15.528816816397011, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 338, train_loss = 15.517332940362394, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 339, train_loss = 15.502876444719732, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 340, train_loss = 15.49264718964696, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 341, train_loss = 15.480446404777467, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 342, train_loss = 15.467804104089737, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 343, train_loss = 15.456315563060343, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 344, train_loss = 15.44402237702161, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 345, train_loss = 15.431871094740927, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 346, train_loss = 15.421905315481126, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 347, train_loss = 15.40902271028608, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 348, train_loss = 15.3981718942523, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 349, train_loss = 15.385853820480406, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 350, train_loss = 15.37569670099765, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 351, train_loss = 15.362552177160978, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 352, train_loss = 15.353375299833715, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 353, train_loss = 15.340970609337091, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 354, train_loss = 15.328958224505186, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 355, train_loss = 15.317842577584088, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 356, train_loss = 15.307550867088139, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 357, train_loss = 15.295936218462884, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 358, train_loss = 15.28654884826392, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 359, train_loss = 15.274067033082247, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 360, train_loss = 15.263403628952801, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 361, train_loss = 15.252353940159082, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 362, train_loss = 15.240896053612232, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 363, train_loss = 15.230925928801298, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 364, train_loss = 15.219889263622463, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 365, train_loss = 15.209391094744205, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 366, train_loss = 15.198600251227617, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 367, train_loss = 15.187041021883488, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 368, train_loss = 15.176463264971972, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 369, train_loss = 15.167517225258052, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 370, train_loss = 15.156555466353893, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 371, train_loss = 15.14762921165675, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 372, train_loss = 15.136406558565795, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 373, train_loss = 15.12674015108496, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 374, train_loss = 15.1166026359424, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 375, train_loss = 15.106828509829938, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 376, train_loss = 15.096452915109694, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 377, train_loss = 15.086189166642725, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 378, train_loss = 15.076599667780101, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 379, train_loss = 15.066113990731537, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 380, train_loss = 15.05535272974521, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 381, train_loss = 15.046918478794396, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 382, train_loss = 15.036634302698076, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 383, train_loss = 15.028254996053874, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 384, train_loss = 15.018207849003375, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 385, train_loss = 15.00950309727341, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 386, train_loss = 14.998894379474223, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 387, train_loss = 14.991161693818867, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 388, train_loss = 14.979566189460456, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 389, train_loss = 14.970687626861036, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 390, train_loss = 14.960221686400473, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 391, train_loss = 14.952414111234248, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 392, train_loss = 14.943550641648471, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 393, train_loss = 14.932251136749983, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 394, train_loss = 14.924648962914944, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 395, train_loss = 14.9141017338261, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 396, train_loss = 14.906320481561124, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 397, train_loss = 14.897740707732737, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 398, train_loss = 14.88724632654339, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 399, train_loss = 14.879292368888855, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 400, train_loss = 14.871358337812126, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 401, train_loss = 14.859682421199977, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 402, train_loss = 14.852498612366617, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 403, train_loss = 14.844869535416365, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 404, train_loss = 14.834528181701899, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 405, train_loss = 14.826109937392175, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 406, train_loss = 14.81652136426419, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 407, train_loss = 14.80991640035063, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 408, train_loss = 14.798859533853829, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 409, train_loss = 14.79309552628547, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 410, train_loss = 14.781329329125583, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 411, train_loss = 14.775389317423105, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 412, train_loss = 14.76523788785562, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 413, train_loss = 14.757941477932036, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 414, train_loss = 14.749683776404709, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 415, train_loss = 14.742340280208737, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 416, train_loss = 14.73376214131713, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 417, train_loss = 14.727183185517788, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 418, train_loss = 14.715395454317331, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 419, train_loss = 14.710328977555037, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 420, train_loss = 14.699459699448198, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 421, train_loss = 14.692589968442917, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 422, train_loss = 14.684618366416544, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 423, train_loss = 14.674970021937042, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 424, train_loss = 14.668371304869652, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 425, train_loss = 14.658657853957266, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 426, train_loss = 14.651220238301903, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 427, train_loss = 14.644337809178978, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 428, train_loss = 14.638440723065287, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 429, train_loss = 14.628935599233955, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 430, train_loss = 14.621374871581793, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 431, train_loss = 14.613836345728487, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 432, train_loss = 14.606004234403372, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 433, train_loss = 14.599468249827623, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 434, train_loss = 14.59175089141354, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 435, train_loss = 14.583983371499926, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 436, train_loss = 14.57641160255298, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 437, train_loss = 14.56948914239183, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 438, train_loss = 14.56004631659016, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 439, train_loss = 14.553740378469229, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 440, train_loss = 14.546490663196892, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 441, train_loss = 14.539952961262316, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 442, train_loss = 14.53207697859034, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 443, train_loss = 14.525687143206596, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 444, train_loss = 14.518084419425577, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 445, train_loss = 14.510425621178001, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 446, train_loss = 14.50370234111324, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 447, train_loss = 14.496224882546812, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 448, train_loss = 14.488609896507114, train_acc = 0.9675128085700978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 449, train_loss = 14.481323149055243, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 450, train_loss = 14.4752606167458, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 451, train_loss = 14.467322764452547, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 452, train_loss = 14.461147697176784, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 453, train_loss = 14.454042656812817, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 454, train_loss = 14.44718243042007, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 455, train_loss = 14.441452404018492, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 456, train_loss = 14.433553086128086, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 457, train_loss = 14.426092151552439, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 458, train_loss = 14.419980520848185, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 459, train_loss = 14.413346631918103, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 460, train_loss = 14.40737435594201, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 461, train_loss = 14.399405763950199, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 462, train_loss = 14.393019007053226, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 463, train_loss = 14.388692321721464, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 464, train_loss = 14.379515375941992, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 465, train_loss = 14.373746232595295, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 466, train_loss = 14.366071242839098, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 467, train_loss = 14.360213682055473, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 468, train_loss = 14.353560949210078, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 469, train_loss = 14.345319821033627, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 470, train_loss = 14.340060432907194, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 471, train_loss = 14.334747099783272, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 472, train_loss = 14.327329160179943, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 473, train_loss = 14.323228232562542, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 474, train_loss = 14.314817695412785, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 475, train_loss = 14.309277900960296, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 476, train_loss = 14.30208379542455, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 477, train_loss = 14.296384908258915, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 478, train_loss = 14.289949709083885, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 479, train_loss = 14.28442303976044, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 480, train_loss = 14.277057374361902, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 481, train_loss = 14.271701502148062, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 482, train_loss = 14.266072187572718, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 483, train_loss = 14.258960995823145, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 484, train_loss = 14.254519818816334, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 485, train_loss = 14.248098400887102, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 486, train_loss = 14.24058994045481, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 487, train_loss = 14.235224070493132, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 488, train_loss = 14.229331681970507, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 489, train_loss = 14.223733566701412, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 490, train_loss = 14.217632030602545, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 491, train_loss = 14.210632335394621, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 492, train_loss = 14.205694068223238, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 493, train_loss = 14.20090770861134, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 494, train_loss = 14.19495352357626, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 495, train_loss = 14.187880387995392, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 496, train_loss = 14.183697450906038, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 497, train_loss = 14.178747240453959, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 498, train_loss = 14.171556727495044, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "1th- epoch: 499, train_loss = 14.165843307971954, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                      | 1/30 [06:38<3:12:35, 398.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "2th- epoch: 0, train_loss = 275.24771463871, train_acc = 0.475780158360503\n",
      "test Acc 0.4958100558659218:\n",
      "2th- epoch: 1, train_loss = 216.2361055612564, train_acc = 0.4989520260829064\n",
      "test Acc 0.4995344506517691:\n",
      "2th- epoch: 2, train_loss = 180.2244988679886, train_acc = 0.5065207265952492\n",
      "test Acc 0.5153631284916201:\n",
      "2th- epoch: 3, train_loss = 163.04333424568176, train_acc = 0.5353982300884956\n",
      "test Acc 0.5702979515828678:\n",
      "2th- epoch: 4, train_loss = 150.30342203378677, train_acc = 0.5916394969725198\n",
      "test Acc 0.6243016759776536:\n",
      "2th- epoch: 5, train_loss = 138.8890375494957, train_acc = 0.6305309734513275\n",
      "test Acc 0.6466480446927374:\n",
      "2th- epoch: 6, train_loss = 128.24254459142685, train_acc = 0.6492780624126688\n",
      "test Acc 0.6573556797020484:\n",
      "2th- epoch: 7, train_loss = 118.3969509601593, train_acc = 0.6956217978574756\n",
      "test Acc 0.75512104283054:\n",
      "2th- epoch: 8, train_loss = 109.35061049461365, train_acc = 0.7700279459711225\n",
      "test Acc 0.787243947858473:\n",
      "2th- epoch: 9, train_loss = 101.1271265745163, train_acc = 0.79052165812762\n",
      "test Acc 0.7988826815642458:\n",
      "2th- epoch: 10, train_loss = 93.7462849020958, train_acc = 0.8118304611085235\n",
      "test Acc 0.813780260707635:\n",
      "2th- epoch: 11, train_loss = 87.2397088110447, train_acc = 0.8214951094550536\n",
      "test Acc 0.824487895716946:\n",
      "2th- epoch: 12, train_loss = 81.55146688222885, train_acc = 0.83011178388449\n",
      "test Acc 0.8347299813780261:\n",
      "2th- epoch: 13, train_loss = 76.5840060710907, train_acc = 0.8372147182114579\n",
      "test Acc 0.8412476722532588:\n",
      "2th- epoch: 14, train_loss = 72.21844863891602, train_acc = 0.8436190032603633\n",
      "test Acc 0.8491620111731844:\n",
      "2th- epoch: 15, train_loss = 68.33972632884979, train_acc = 0.8518863530507685\n",
      "test Acc 0.8631284916201117:\n",
      "2th- epoch: 16, train_loss = 64.87618950009346, train_acc = 0.8629482999534234\n",
      "test Acc 0.8715083798882681:\n",
      "2th- epoch: 17, train_loss = 61.77188524603844, train_acc = 0.8713320912901723\n",
      "test Acc 0.8794227188081937:\n",
      "2th- epoch: 18, train_loss = 58.98846593499184, train_acc = 0.8754075454122031\n",
      "test Acc 0.8836126629422719:\n",
      "2th- epoch: 19, train_loss = 56.50353741645813, train_acc = 0.8790172333488588\n",
      "test Acc 0.8910614525139665:\n",
      "2th- epoch: 20, train_loss = 54.28961595892906, train_acc = 0.8869352585002329\n",
      "test Acc 0.8947858472998138:\n",
      "2th- epoch: 21, train_loss = 52.31643804907799, train_acc = 0.8922915696320447\n",
      "test Acc 0.8999068901303539:\n",
      "2th- epoch: 22, train_loss = 50.55705027282238, train_acc = 0.896134140661388\n",
      "test Acc 0.9022346368715084:\n",
      "2th- epoch: 23, train_loss = 48.98740141093731, train_acc = 0.8986958546809501\n",
      "test Acc 0.9027001862197392:\n",
      "2th- epoch: 24, train_loss = 47.583515390753746, train_acc = 0.9003260363297625\n",
      "test Acc 0.9031657355679702:\n",
      "2th- epoch: 25, train_loss = 46.32113890349865, train_acc = 0.902771308802981\n",
      "test Acc 0.9059590316573557:\n",
      "2th- epoch: 26, train_loss = 45.17947120964527, train_acc = 0.9039357242664182\n",
      "test Acc 0.9068901303538175:\n",
      "2th- epoch: 27, train_loss = 44.14431653916836, train_acc = 0.9055659059152306\n",
      "test Acc 0.9082867783985102:\n",
      "2th- epoch: 28, train_loss = 43.20077806711197, train_acc = 0.9067303213786679\n",
      "test Acc 0.909683426443203:\n",
      "2th- epoch: 29, train_loss = 42.3359305113554, train_acc = 0.907545412203074\n",
      "test Acc 0.9110800744878957:\n",
      "2th- epoch: 30, train_loss = 41.53865168988705, train_acc = 0.9101071262226362\n",
      "test Acc 0.9110800744878957:\n",
      "2th- epoch: 31, train_loss = 40.801338225603104, train_acc = 0.9118537494177923\n",
      "test Acc 0.9115456238361266:\n",
      "2th- epoch: 32, train_loss = 40.1155311614275, train_acc = 0.9133674895202608\n",
      "test Acc 0.9129422718808193:\n",
      "2th- epoch: 33, train_loss = 39.474770084023476, train_acc = 0.9158127619934793\n",
      "test Acc 0.9152700186219739:\n",
      "2th- epoch: 34, train_loss = 38.874853417277336, train_acc = 0.917675826734979\n",
      "test Acc 0.9157355679702048:\n",
      "2th- epoch: 35, train_loss = 38.311701223254204, train_acc = 0.9182580344666977\n",
      "test Acc 0.9171322160148976:\n",
      "2th- epoch: 36, train_loss = 37.78007270395756, train_acc = 0.9189566837447601\n",
      "test Acc 0.9185288640595903:\n",
      "2th- epoch: 37, train_loss = 37.27742424607277, train_acc = 0.9197717745691663\n",
      "test Acc 0.9194599627560521:\n",
      "2th- epoch: 38, train_loss = 36.80022406578064, train_acc = 0.9211690731252911\n",
      "test Acc 0.9194599627560521:\n",
      "2th- epoch: 39, train_loss = 36.3457386046648, train_acc = 0.921634839310666\n",
      "test Acc 0.9194599627560521:\n",
      "2th- epoch: 40, train_loss = 35.91153858602047, train_acc = 0.9224499301350721\n",
      "test Acc 0.9199255121042831:\n",
      "2th- epoch: 41, train_loss = 35.495786532759666, train_acc = 0.9229156963204471\n",
      "test Acc 0.9208566108007449:\n",
      "2th- epoch: 42, train_loss = 35.0983260050416, train_acc = 0.9234979040521658\n",
      "test Acc 0.9217877094972067:\n",
      "2th- epoch: 43, train_loss = 34.71775062382221, train_acc = 0.9240801117838845\n",
      "test Acc 0.9222532588454376:\n",
      "2th- epoch: 44, train_loss = 34.35257738083601, train_acc = 0.9254774103400093\n",
      "test Acc 0.9241154562383612:\n",
      "2th- epoch: 45, train_loss = 34.00143441557884, train_acc = 0.926059618071728\n",
      "test Acc 0.9245810055865922:\n",
      "2th- epoch: 46, train_loss = 33.66347674280405, train_acc = 0.9271075919888216\n",
      "test Acc 0.9245810055865922:\n",
      "2th- epoch: 47, train_loss = 33.336442939937115, train_acc = 0.9279226828132278\n",
      "test Acc 0.925512104283054:\n",
      "2th- epoch: 48, train_loss = 33.02118667215109, train_acc = 0.9286213320912902\n",
      "test Acc 0.9259776536312849:\n",
      "2th- epoch: 49, train_loss = 32.71703866869211, train_acc = 0.9295528644620401\n",
      "test Acc 0.9264432029795159:\n",
      "2th- epoch: 50, train_loss = 32.42347860336304, train_acc = 0.9299021891010713\n",
      "test Acc 0.9269087523277467:\n",
      "2th- epoch: 51, train_loss = 32.13920371234417, train_acc = 0.9301350721937587\n",
      "test Acc 0.9273743016759777:\n",
      "2th- epoch: 52, train_loss = 31.863839134573936, train_acc = 0.9308337214718212\n",
      "test Acc 0.9278398510242085:\n",
      "2th- epoch: 53, train_loss = 31.597242809832096, train_acc = 0.9308337214718212\n",
      "test Acc 0.9273743016759777:\n",
      "2th- epoch: 54, train_loss = 31.33811953663826, train_acc = 0.9311830461108523\n",
      "test Acc 0.9273743016759777:\n",
      "2th- epoch: 55, train_loss = 31.085824258625507, train_acc = 0.9312994876571961\n",
      "test Acc 0.9273743016759777:\n",
      "2th- epoch: 56, train_loss = 30.84061350673437, train_acc = 0.9315323707498836\n",
      "test Acc 0.9273743016759777:\n",
      "2th- epoch: 57, train_loss = 30.601116366684437, train_acc = 0.9319981369352585\n",
      "test Acc 0.9273743016759777:\n",
      "2th- epoch: 58, train_loss = 30.367850683629513, train_acc = 0.9325803446669771\n",
      "test Acc 0.9273743016759777:\n",
      "2th- epoch: 59, train_loss = 30.139569707214832, train_acc = 0.9329296693060084\n",
      "test Acc 0.9273743016759777:\n",
      "2th- epoch: 60, train_loss = 29.916874766349792, train_acc = 0.9332789939450395\n",
      "test Acc 0.9273743016759777:\n",
      "2th- epoch: 61, train_loss = 29.699906215071678, train_acc = 0.9337447601304145\n",
      "test Acc 0.9273743016759777:\n",
      "2th- epoch: 62, train_loss = 29.488038301467896, train_acc = 0.9340940847694458\n",
      "test Acc 0.9273743016759777:\n",
      "2th- epoch: 63, train_loss = 29.28122929483652, train_acc = 0.9346762925011645\n",
      "test Acc 0.9273743016759777:\n",
      "2th- epoch: 64, train_loss = 29.07853688299656, train_acc = 0.9350256171401956\n",
      "test Acc 0.9283054003724395:\n",
      "2th- epoch: 65, train_loss = 28.8809704631567, train_acc = 0.935258500232883\n",
      "test Acc 0.9283054003724395:\n",
      "2th- epoch: 66, train_loss = 28.687011495232582, train_acc = 0.9354913833255706\n",
      "test Acc 0.9283054003724395:\n",
      "2th- epoch: 67, train_loss = 28.497416973114014, train_acc = 0.9354913833255706\n",
      "test Acc 0.9287709497206704:\n",
      "2th- epoch: 68, train_loss = 28.31159646064043, train_acc = 0.9354913833255706\n",
      "test Acc 0.9287709497206704:\n",
      "2th- epoch: 69, train_loss = 28.128961086273193, train_acc = 0.935724266418258\n",
      "test Acc 0.9287709497206704:\n",
      "2th- epoch: 70, train_loss = 27.950330510735512, train_acc = 0.936190032603633\n",
      "test Acc 0.9292364990689013:\n",
      "2th- epoch: 71, train_loss = 27.77524396777153, train_acc = 0.936190032603633\n",
      "test Acc 0.9297020484171322:\n",
      "2th- epoch: 72, train_loss = 27.603385500609875, train_acc = 0.936655798789008\n",
      "test Acc 0.9297020484171322:\n",
      "2th- epoch: 73, train_loss = 27.435102067887783, train_acc = 0.9368886818816954\n",
      "test Acc 0.9297020484171322:\n",
      "2th- epoch: 74, train_loss = 27.271037839353085, train_acc = 0.9375873311597578\n",
      "test Acc 0.9297020484171322:\n",
      "2th- epoch: 75, train_loss = 27.10984394699335, train_acc = 0.9377037727061015\n",
      "test Acc 0.9301675977653632:\n",
      "2th- epoch: 76, train_loss = 26.952003575861454, train_acc = 0.9382859804378202\n",
      "test Acc 0.9301675977653632:\n",
      "2th- epoch: 77, train_loss = 26.797145143151283, train_acc = 0.9381695388914765\n",
      "test Acc 0.9301675977653632:\n",
      "2th- epoch: 78, train_loss = 26.645434968173504, train_acc = 0.9385188635305077\n",
      "test Acc 0.9301675977653632:\n",
      "2th- epoch: 79, train_loss = 26.496755465865135, train_acc = 0.9385188635305077\n",
      "test Acc 0.930633147113594:\n",
      "2th- epoch: 80, train_loss = 26.350580409169197, train_acc = 0.9388681881695389\n",
      "test Acc 0.931098696461825:\n",
      "2th- epoch: 81, train_loss = 26.207194693386555, train_acc = 0.939683278993945\n",
      "test Acc 0.9315642458100558:\n",
      "2th- epoch: 82, train_loss = 26.066932775080204, train_acc = 0.9399161620866325\n",
      "test Acc 0.9315642458100558:\n",
      "2th- epoch: 83, train_loss = 25.928943436592817, train_acc = 0.9403819282720075\n",
      "test Acc 0.9324953445065177:\n",
      "2th- epoch: 84, train_loss = 25.79369567707181, train_acc = 0.9409641360037261\n",
      "test Acc 0.9324953445065177:\n",
      "2th- epoch: 85, train_loss = 25.661103393882513, train_acc = 0.941895668374476\n",
      "test Acc 0.9324953445065177:\n",
      "2th- epoch: 86, train_loss = 25.5301705673337, train_acc = 0.942361434559851\n",
      "test Acc 0.9329608938547486:\n",
      "2th- epoch: 87, train_loss = 25.40233151242137, train_acc = 0.9427107591988821\n",
      "test Acc 0.9329608938547486:\n",
      "2th- epoch: 88, train_loss = 25.27692873030901, train_acc = 0.9437587331159758\n",
      "test Acc 0.9329608938547486:\n",
      "2th- epoch: 89, train_loss = 25.153504323214293, train_acc = 0.944108057755007\n",
      "test Acc 0.9329608938547486:\n",
      "2th- epoch: 90, train_loss = 25.0316895917058, train_acc = 0.9446902654867256\n",
      "test Acc 0.9338919925512105:\n",
      "2th- epoch: 91, train_loss = 24.912557411938906, train_acc = 0.9449231485794132\n",
      "test Acc 0.9338919925512105:\n",
      "2th- epoch: 92, train_loss = 24.794884208589792, train_acc = 0.945388914764788\n",
      "test Acc 0.9338919925512105:\n",
      "2th- epoch: 93, train_loss = 24.679042924195528, train_acc = 0.945388914764788\n",
      "test Acc 0.9338919925512105:\n",
      "2th- epoch: 94, train_loss = 24.565332550555468, train_acc = 0.945388914764788\n",
      "test Acc 0.9338919925512105:\n",
      "2th- epoch: 95, train_loss = 24.453331388533115, train_acc = 0.945388914764788\n",
      "test Acc 0.9338919925512105:\n",
      "2th- epoch: 96, train_loss = 24.342907033860683, train_acc = 0.9456217978574756\n",
      "test Acc 0.9343575418994413:\n",
      "2th- epoch: 97, train_loss = 24.235208854079247, train_acc = 0.945854680950163\n",
      "test Acc 0.9343575418994413:\n",
      "2th- epoch: 98, train_loss = 24.12889800593257, train_acc = 0.9459711224965067\n",
      "test Acc 0.9343575418994413:\n",
      "2th- epoch: 99, train_loss = 24.024963937699795, train_acc = 0.9460875640428504\n",
      "test Acc 0.9343575418994413:\n",
      "2th- epoch: 100, train_loss = 23.92283582687378, train_acc = 0.9464368886818817\n",
      "test Acc 0.9348230912476723:\n",
      "2th- epoch: 101, train_loss = 23.822315212339163, train_acc = 0.9466697717745691\n",
      "test Acc 0.9352886405959032:\n",
      "2th- epoch: 102, train_loss = 23.723611790686846, train_acc = 0.9466697717745691\n",
      "test Acc 0.9352886405959032:\n",
      "2th- epoch: 103, train_loss = 23.625920075923204, train_acc = 0.9466697717745691\n",
      "test Acc 0.9352886405959032:\n",
      "2th- epoch: 104, train_loss = 23.530485447496176, train_acc = 0.9466697717745691\n",
      "test Acc 0.9352886405959032:\n",
      "2th- epoch: 105, train_loss = 23.436347737908363, train_acc = 0.946786213320913\n",
      "test Acc 0.9352886405959032:\n",
      "2th- epoch: 106, train_loss = 23.343491561710835, train_acc = 0.9471355379599441\n",
      "test Acc 0.9352886405959032:\n",
      "2th- epoch: 107, train_loss = 23.252320535480976, train_acc = 0.9474848625989754\n",
      "test Acc 0.9352886405959032:\n",
      "2th- epoch: 108, train_loss = 23.162299435585737, train_acc = 0.9476013041453191\n",
      "test Acc 0.936219739292365:\n",
      "2th- epoch: 109, train_loss = 23.073987193405628, train_acc = 0.9476013041453191\n",
      "test Acc 0.9371508379888268:\n",
      "2th- epoch: 110, train_loss = 22.986394345760345, train_acc = 0.9479506287843502\n",
      "test Acc 0.9371508379888268:\n",
      "2th- epoch: 111, train_loss = 22.90060545504093, train_acc = 0.9482999534233815\n",
      "test Acc 0.9376163873370578:\n",
      "2th- epoch: 112, train_loss = 22.815856494009495, train_acc = 0.9485328365160689\n",
      "test Acc 0.9380819366852886:\n",
      "2th- epoch: 113, train_loss = 22.732378020882607, train_acc = 0.9486492780624126\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 114, train_loss = 22.650278620421886, train_acc = 0.9491150442477876\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 115, train_loss = 22.56897385418415, train_acc = 0.9495808104331626\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 116, train_loss = 22.488942347466946, train_acc = 0.9499301350721937\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 117, train_loss = 22.409907579421997, train_acc = 0.9503959012575687\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 118, train_loss = 22.332150980830193, train_acc = 0.9506287843502562\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 119, train_loss = 22.25495044514537, train_acc = 0.9508616674429436\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 120, train_loss = 22.178470488637686, train_acc = 0.9510945505356311\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 121, train_loss = 22.10369760543108, train_acc = 0.9512109920819748\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 122, train_loss = 22.03011292591691, train_acc = 0.9513274336283186\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 123, train_loss = 21.957147032022476, train_acc = 0.9513274336283186\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 124, train_loss = 21.885430734604597, train_acc = 0.951560316721006\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 125, train_loss = 21.814213454723358, train_acc = 0.9516767582673498\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 126, train_loss = 21.744995146989822, train_acc = 0.9516767582673498\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 127, train_loss = 21.675446566194296, train_acc = 0.9517931998136935\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 128, train_loss = 21.607223752886057, train_acc = 0.9519096413600373\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 129, train_loss = 21.540130488574505, train_acc = 0.9519096413600373\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 130, train_loss = 21.47412696108222, train_acc = 0.9519096413600373\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 131, train_loss = 21.40793576836586, train_acc = 0.9522589659990685\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 132, train_loss = 21.342976555228233, train_acc = 0.9521425244527247\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 133, train_loss = 21.27870887517929, train_acc = 0.9522589659990685\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 134, train_loss = 21.215615425258875, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 135, train_loss = 21.153305172920227, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 136, train_loss = 21.092198725789785, train_acc = 0.9529576152771309\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 137, train_loss = 21.03155479207635, train_acc = 0.9531904983698184\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 138, train_loss = 20.970731809735298, train_acc = 0.9533069399161621\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 139, train_loss = 20.911972176283598, train_acc = 0.9534233814625058\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 140, train_loss = 20.85344123095274, train_acc = 0.9535398230088495\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 141, train_loss = 20.795920230448246, train_acc = 0.9536562645551933\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 142, train_loss = 20.738713886588812, train_acc = 0.9536562645551933\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 143, train_loss = 20.68162178620696, train_acc = 0.9536562645551933\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 144, train_loss = 20.625607177615166, train_acc = 0.9538891476478808\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 145, train_loss = 20.56985877454281, train_acc = 0.9537727061015371\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 146, train_loss = 20.516026843339205, train_acc = 0.9540055891942245\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 147, train_loss = 20.462098229676485, train_acc = 0.9540055891942245\n",
      "test Acc 0.9399441340782123:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 148, train_loss = 20.408636696636677, train_acc = 0.9540055891942245\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 149, train_loss = 20.355853132903576, train_acc = 0.9540055891942245\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 150, train_loss = 20.30357151851058, train_acc = 0.9541220307405682\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 151, train_loss = 20.2524044662714, train_acc = 0.9542384722869119\n",
      "test Acc 0.9404096834264432:\n",
      "2th- epoch: 152, train_loss = 20.20157014206052, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 153, train_loss = 20.150760654360056, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 154, train_loss = 20.100580608472228, train_acc = 0.9545877969259432\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 155, train_loss = 20.051460318267345, train_acc = 0.9545877969259432\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 156, train_loss = 20.001188537105918, train_acc = 0.9547042384722869\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 157, train_loss = 19.95260962843895, train_acc = 0.9548206800186306\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 158, train_loss = 19.904435764998198, train_acc = 0.9549371215649743\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 159, train_loss = 19.85746866837144, train_acc = 0.9550535631113182\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 160, train_loss = 19.81030061468482, train_acc = 0.9551700046576619\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 161, train_loss = 19.764188090339303, train_acc = 0.9554028877503493\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 162, train_loss = 19.71800014562905, train_acc = 0.9554028877503493\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 163, train_loss = 19.673064466565847, train_acc = 0.9556357708430367\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 164, train_loss = 19.627790378406644, train_acc = 0.9556357708430367\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 165, train_loss = 19.58329874649644, train_acc = 0.9558686539357243\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 166, train_loss = 19.539472380653024, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 167, train_loss = 19.495196970179677, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 168, train_loss = 19.45229052565992, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 169, train_loss = 19.409516451880336, train_acc = 0.9561015370284117\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 170, train_loss = 19.367121597751975, train_acc = 0.9561015370284117\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 171, train_loss = 19.324622569605708, train_acc = 0.9561015370284117\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 172, train_loss = 19.283040203154087, train_acc = 0.9561015370284117\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 173, train_loss = 19.242310946807265, train_acc = 0.9563344201210993\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 174, train_loss = 19.201349265873432, train_acc = 0.9563344201210993\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 175, train_loss = 19.16089403629303, train_acc = 0.956450861667443\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 176, train_loss = 19.120473252609372, train_acc = 0.9566837447601304\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 177, train_loss = 19.080622071400285, train_acc = 0.9569166278528178\n",
      "test Acc 0.9418063314711359:\n",
      "2th- epoch: 178, train_loss = 19.04160507582128, train_acc = 0.9570330693991617\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 179, train_loss = 19.00313293375075, train_acc = 0.9570330693991617\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 180, train_loss = 18.963752014562488, train_acc = 0.9571495109455054\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 181, train_loss = 18.926290206611156, train_acc = 0.9571495109455054\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 182, train_loss = 18.88759102486074, train_acc = 0.9572659524918491\n",
      "test Acc 0.9432029795158287:\n",
      "2th- epoch: 183, train_loss = 18.849933944642544, train_acc = 0.9572659524918491\n",
      "test Acc 0.9432029795158287:\n",
      "2th- epoch: 184, train_loss = 18.81322916597128, train_acc = 0.9574988355845365\n",
      "test Acc 0.9432029795158287:\n",
      "2th- epoch: 185, train_loss = 18.77710314653814, train_acc = 0.9576152771308803\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 186, train_loss = 18.74006081931293, train_acc = 0.9577317186772241\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 187, train_loss = 18.70413208566606, train_acc = 0.9579646017699115\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 188, train_loss = 18.667903469875455, train_acc = 0.9580810433162552\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 189, train_loss = 18.633642937988043, train_acc = 0.9580810433162552\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 190, train_loss = 18.59786944463849, train_acc = 0.9581974848625989\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 191, train_loss = 18.562947623431683, train_acc = 0.9581974848625989\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 192, train_loss = 18.52806498669088, train_acc = 0.9583139264089428\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 193, train_loss = 18.493307320401073, train_acc = 0.9583139264089428\n",
      "test Acc 0.9441340782122905:\n",
      "2th- epoch: 194, train_loss = 18.458926057443023, train_acc = 0.9584303679552865\n",
      "test Acc 0.9441340782122905:\n",
      "2th- epoch: 195, train_loss = 18.42495014704764, train_acc = 0.9585468095016302\n",
      "test Acc 0.9441340782122905:\n",
      "2th- epoch: 196, train_loss = 18.393037436529994, train_acc = 0.9586632510479739\n",
      "test Acc 0.9441340782122905:\n",
      "2th- epoch: 197, train_loss = 18.357939852401614, train_acc = 0.9586632510479739\n",
      "test Acc 0.9441340782122905:\n",
      "2th- epoch: 198, train_loss = 18.326203612610698, train_acc = 0.9586632510479739\n",
      "test Acc 0.9441340782122905:\n",
      "2th- epoch: 199, train_loss = 18.294349057599902, train_acc = 0.9587796925943176\n",
      "test Acc 0.9445996275605214:\n",
      "2th- epoch: 200, train_loss = 18.261967046186328, train_acc = 0.9588961341406614\n",
      "test Acc 0.9445996275605214:\n",
      "2th- epoch: 201, train_loss = 18.231469033285975, train_acc = 0.9588961341406614\n",
      "test Acc 0.9445996275605214:\n",
      "2th- epoch: 202, train_loss = 18.19872268475592, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 203, train_loss = 18.167532978579402, train_acc = 0.9590125756870052\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 204, train_loss = 18.136050989851356, train_acc = 0.9590125756870052\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 205, train_loss = 18.104033283889294, train_acc = 0.9590125756870052\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 206, train_loss = 18.074948573485017, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 207, train_loss = 18.041938116773963, train_acc = 0.9592454587796926\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 208, train_loss = 18.0127887558192, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "2th- epoch: 209, train_loss = 17.98416704311967, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "2th- epoch: 210, train_loss = 17.952994028106332, train_acc = 0.95947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "2th- epoch: 211, train_loss = 17.926695263013244, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "2th- epoch: 212, train_loss = 17.89562533982098, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "2th- epoch: 213, train_loss = 17.867753377184272, train_acc = 0.9597112249650676\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 214, train_loss = 17.838520200923085, train_acc = 0.9595947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 215, train_loss = 17.810318935662508, train_acc = 0.9598276665114113\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 216, train_loss = 17.783183854073286, train_acc = 0.959944108057755\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 217, train_loss = 17.754063177853823, train_acc = 0.959944108057755\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 218, train_loss = 17.726034758612514, train_acc = 0.959944108057755\n",
      "test Acc 0.9459962756052142:\n",
      "2th- epoch: 219, train_loss = 17.69934925623238, train_acc = 0.9600605496040987\n",
      "test Acc 0.9459962756052142:\n",
      "2th- epoch: 220, train_loss = 17.671866489574313, train_acc = 0.9602934326967862\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 221, train_loss = 17.644465915858746, train_acc = 0.9601769911504425\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 222, train_loss = 17.61813135817647, train_acc = 0.9601769911504425\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 223, train_loss = 17.59250200353563, train_acc = 0.9605263157894737\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 224, train_loss = 17.566066762432456, train_acc = 0.9606427573358174\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 225, train_loss = 17.53939445875585, train_acc = 0.9606427573358174\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 226, train_loss = 17.512955885380507, train_acc = 0.9607591988821611\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 227, train_loss = 17.487961238250136, train_acc = 0.9606427573358174\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 228, train_loss = 17.46199290268123, train_acc = 0.9606427573358174\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 229, train_loss = 17.43732169829309, train_acc = 0.9606427573358174\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 230, train_loss = 17.412250937893987, train_acc = 0.9606427573358174\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 231, train_loss = 17.38757630623877, train_acc = 0.9607591988821611\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 232, train_loss = 17.36222840473056, train_acc = 0.9609920819748486\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 233, train_loss = 17.337997952476144, train_acc = 0.9609920819748486\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 234, train_loss = 17.31413442082703, train_acc = 0.9609920819748486\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 235, train_loss = 17.290327604860067, train_acc = 0.9609920819748486\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 236, train_loss = 17.266056952998042, train_acc = 0.9611085235211924\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 237, train_loss = 17.24200066924095, train_acc = 0.9608756404285049\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 238, train_loss = 17.21990205347538, train_acc = 0.9609920819748486\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 239, train_loss = 17.19562034495175, train_acc = 0.9609920819748486\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 240, train_loss = 17.172565173357725, train_acc = 0.9609920819748486\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 241, train_loss = 17.150202096439898, train_acc = 0.9609920819748486\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 242, train_loss = 17.126483988948166, train_acc = 0.9612249650675361\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 243, train_loss = 17.104752633720636, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 244, train_loss = 17.081073752604425, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 245, train_loss = 17.059425964020193, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 246, train_loss = 17.03752422425896, train_acc = 0.961690731252911\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 247, train_loss = 17.015237647108734, train_acc = 0.961690731252911\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 248, train_loss = 16.993898066692054, train_acc = 0.961690731252911\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 249, train_loss = 16.972638115286827, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 250, train_loss = 16.950507912784815, train_acc = 0.9619236143455985\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 251, train_loss = 16.929936840198934, train_acc = 0.9620400558919422\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 252, train_loss = 16.90835485700518, train_acc = 0.962156497438286\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 253, train_loss = 16.88745626527816, train_acc = 0.9622729389846297\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 254, train_loss = 16.86656016111374, train_acc = 0.9622729389846297\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 255, train_loss = 16.845619215629995, train_acc = 0.9625058220773172\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 256, train_loss = 16.82556985411793, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 257, train_loss = 16.80571525078267, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 258, train_loss = 16.784156288020313, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 259, train_loss = 16.764402627944946, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 260, train_loss = 16.744877487421036, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 261, train_loss = 16.724828184582293, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 262, train_loss = 16.70624481793493, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 263, train_loss = 16.686718337237835, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 264, train_loss = 16.666349712759256, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 265, train_loss = 16.648054339922965, train_acc = 0.9630880298090359\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 266, train_loss = 16.628690258599818, train_acc = 0.9632044713553796\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 267, train_loss = 16.60966692492366, train_acc = 0.9632044713553796\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 268, train_loss = 16.5910326205194, train_acc = 0.9633209129017233\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 269, train_loss = 16.572804079391062, train_acc = 0.9633209129017233\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 270, train_loss = 16.553834763355553, train_acc = 0.9633209129017233\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 271, train_loss = 16.534986813552678, train_acc = 0.9634373544480671\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 272, train_loss = 16.517627344466746, train_acc = 0.9634373544480671\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 273, train_loss = 16.498857378028333, train_acc = 0.9634373544480671\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 274, train_loss = 16.48119366262108, train_acc = 0.9634373544480671\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 275, train_loss = 16.46329103782773, train_acc = 0.9635537959944108\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 276, train_loss = 16.445451474748552, train_acc = 0.9636702375407545\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 277, train_loss = 16.42823639139533, train_acc = 0.9636702375407545\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 278, train_loss = 16.40957069862634, train_acc = 0.9636702375407545\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 279, train_loss = 16.392928942106664, train_acc = 0.9636702375407545\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 280, train_loss = 16.375454395078123, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 281, train_loss = 16.358744761906564, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 282, train_loss = 16.340910867787898, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 283, train_loss = 16.32216126844287, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 284, train_loss = 16.305770717561245, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 285, train_loss = 16.289152037352324, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 286, train_loss = 16.272595928050578, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 287, train_loss = 16.255958263762295, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 288, train_loss = 16.239539082162082, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 289, train_loss = 16.222371731884778, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 290, train_loss = 16.207368411123753, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 291, train_loss = 16.190640188753605, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 292, train_loss = 16.175467637367547, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 293, train_loss = 16.158323383890092, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 294, train_loss = 16.142133306711912, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 295, train_loss = 16.126869392581284, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 296, train_loss = 16.111686505377293, train_acc = 0.9641360037261295\n",
      "test Acc 0.9483240223463687:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 297, train_loss = 16.095071859657764, train_acc = 0.9641360037261295\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 298, train_loss = 16.080826823599637, train_acc = 0.9641360037261295\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 299, train_loss = 16.06511064618826, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 300, train_loss = 16.04986176174134, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 301, train_loss = 16.03362430166453, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 302, train_loss = 16.019259714521468, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 303, train_loss = 16.00452418718487, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 304, train_loss = 15.99016373977065, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 305, train_loss = 15.974832438863814, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 306, train_loss = 15.959646194241941, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 307, train_loss = 15.944542493671179, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 308, train_loss = 15.92983886692673, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 309, train_loss = 15.916460566222668, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 310, train_loss = 15.900799040682614, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 311, train_loss = 15.887032152153552, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 312, train_loss = 15.873024332337081, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 313, train_loss = 15.857429876923561, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 314, train_loss = 15.844460774213076, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 315, train_loss = 15.830587630160153, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 316, train_loss = 15.816417728550732, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 317, train_loss = 15.802621222101152, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 318, train_loss = 15.789553996175528, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 319, train_loss = 15.77510294970125, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 320, train_loss = 15.762258431874216, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 321, train_loss = 15.749926775693893, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 322, train_loss = 15.734651970677078, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 323, train_loss = 15.722949724644423, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 324, train_loss = 15.708729349076748, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 325, train_loss = 15.69538176804781, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 326, train_loss = 15.682100680656731, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 327, train_loss = 15.66932441946119, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 328, train_loss = 15.655988745391369, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 329, train_loss = 15.643888567574322, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 330, train_loss = 15.63008130621165, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "2th- epoch: 331, train_loss = 15.616982203908265, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 332, train_loss = 15.60426340252161, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 333, train_loss = 15.591108314692974, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 334, train_loss = 15.57823304925114, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 335, train_loss = 15.565504615195096, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 336, train_loss = 15.553052846342325, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 337, train_loss = 15.5413265414536, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 338, train_loss = 15.529251103289425, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 339, train_loss = 15.517610188573599, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 340, train_loss = 15.505593343637884, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 341, train_loss = 15.493769043125212, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 342, train_loss = 15.480017446912825, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 343, train_loss = 15.469043011777103, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 344, train_loss = 15.456716656684875, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 345, train_loss = 15.444559502415359, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 346, train_loss = 15.433762095868587, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 347, train_loss = 15.421991924755275, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 348, train_loss = 15.409831203520298, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 349, train_loss = 15.398902419023216, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 350, train_loss = 15.386057213880122, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 351, train_loss = 15.374658446758986, train_acc = 0.9654168607359106\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 352, train_loss = 15.364003342576325, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 353, train_loss = 15.352253946475685, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 354, train_loss = 15.340642579831183, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 355, train_loss = 15.33058897126466, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 356, train_loss = 15.31869896594435, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 357, train_loss = 15.307771044783294, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 358, train_loss = 15.29688959941268, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 359, train_loss = 15.28635208774358, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 360, train_loss = 15.276146440766752, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 361, train_loss = 15.264998857863247, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 362, train_loss = 15.253459374420345, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 363, train_loss = 15.243880649097264, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 364, train_loss = 15.232522307895124, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 365, train_loss = 15.22363369166851, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 366, train_loss = 15.212104969657958, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 367, train_loss = 15.201670043170452, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 368, train_loss = 15.191997666843235, train_acc = 0.9659990684676293\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 369, train_loss = 15.18074802774936, train_acc = 0.9659990684676293\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 370, train_loss = 15.170758440159261, train_acc = 0.966115510013973\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 371, train_loss = 15.159533741883934, train_acc = 0.966115510013973\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 372, train_loss = 15.149770576506853, train_acc = 0.966115510013973\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 373, train_loss = 15.138485510833561, train_acc = 0.966115510013973\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 374, train_loss = 15.127722359262407, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 375, train_loss = 15.117094577290118, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 376, train_loss = 15.1071617314592, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 377, train_loss = 15.096808695234358, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 378, train_loss = 15.088256007991731, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 379, train_loss = 15.077163356356323, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 380, train_loss = 15.06741222832352, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 381, train_loss = 15.058373923413455, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 382, train_loss = 15.048109433613718, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 383, train_loss = 15.039217269979417, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 384, train_loss = 15.028155603446066, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 385, train_loss = 15.020894050598145, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 386, train_loss = 15.009610429406166, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 387, train_loss = 15.000185520388186, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 388, train_loss = 14.99103673454374, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 389, train_loss = 14.982257462106645, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 390, train_loss = 14.972736600786448, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 391, train_loss = 14.962069598026574, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 392, train_loss = 14.953172122128308, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 393, train_loss = 14.944775272160769, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 394, train_loss = 14.934719474054873, train_acc = 0.9662319515603167\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 395, train_loss = 14.926445592194796, train_acc = 0.9662319515603167\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 396, train_loss = 14.917079259641469, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 397, train_loss = 14.908551150001585, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 398, train_loss = 14.8994864160195, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 399, train_loss = 14.890029746107757, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 400, train_loss = 14.880979406647384, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 401, train_loss = 14.871806097216904, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 402, train_loss = 14.863499689847231, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 403, train_loss = 14.855232201516628, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 404, train_loss = 14.846017527393997, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 405, train_loss = 14.837024153210223, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 406, train_loss = 14.829544343985617, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 407, train_loss = 14.820581628941, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 408, train_loss = 14.811795857734978, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 409, train_loss = 14.8044996522367, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 410, train_loss = 14.794587618671358, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 411, train_loss = 14.786499448120594, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 412, train_loss = 14.778149168007076, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 413, train_loss = 14.768818017095327, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 414, train_loss = 14.761470161378384, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 415, train_loss = 14.753223653882742, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 416, train_loss = 14.745107656810433, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 417, train_loss = 14.736391045153141, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 418, train_loss = 14.728811567183584, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 419, train_loss = 14.719920974224806, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 420, train_loss = 14.71229786798358, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 421, train_loss = 14.704113561660051, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 422, train_loss = 14.696608060505241, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 423, train_loss = 14.687957840505987, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 424, train_loss = 14.681118757929653, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 425, train_loss = 14.67210760479793, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 426, train_loss = 14.664231257047504, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 427, train_loss = 14.656579818576574, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 428, train_loss = 14.649286022875458, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 429, train_loss = 14.641603015363216, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 430, train_loss = 14.633499673102051, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 431, train_loss = 14.625460462179035, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 432, train_loss = 14.61856509372592, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 433, train_loss = 14.610535772051662, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 434, train_loss = 14.601039247121662, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 435, train_loss = 14.595432044472545, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 436, train_loss = 14.58696716511622, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 437, train_loss = 14.579199142754078, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 438, train_loss = 14.573373342398554, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 439, train_loss = 14.565190496388823, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 440, train_loss = 14.557415250688791, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 441, train_loss = 14.551134473178536, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 442, train_loss = 14.543624447192997, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 443, train_loss = 14.536023081745952, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 444, train_loss = 14.52982226619497, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 445, train_loss = 14.52098266268149, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 446, train_loss = 14.514634804334491, train_acc = 0.9669306008383791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.952048417132216:\n",
      "2th- epoch: 447, train_loss = 14.506382524967194, train_acc = 0.9669306008383791\n",
      "test Acc 0.952048417132216:\n",
      "2th- epoch: 448, train_loss = 14.501448461320251, train_acc = 0.9669306008383791\n",
      "test Acc 0.952048417132216:\n",
      "2th- epoch: 449, train_loss = 14.49306563520804, train_acc = 0.9669306008383791\n",
      "test Acc 0.952048417132216:\n",
      "2th- epoch: 450, train_loss = 14.488213755190372, train_acc = 0.9669306008383791\n",
      "test Acc 0.952048417132216:\n",
      "2th- epoch: 451, train_loss = 14.479358475655317, train_acc = 0.9669306008383791\n",
      "test Acc 0.952048417132216:\n",
      "2th- epoch: 452, train_loss = 14.472795577254146, train_acc = 0.9670470423847228\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 453, train_loss = 14.465746937785298, train_acc = 0.9671634839310667\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 454, train_loss = 14.458684181328863, train_acc = 0.9672799254774104\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 455, train_loss = 14.450950773898512, train_acc = 0.9672799254774104\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 456, train_loss = 14.445322144776583, train_acc = 0.9671634839310667\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 457, train_loss = 14.43965678429231, train_acc = 0.9672799254774104\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 458, train_loss = 14.430883592460304, train_acc = 0.9673963670237541\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 459, train_loss = 14.424769753124565, train_acc = 0.9673963670237541\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 460, train_loss = 14.418706709053367, train_acc = 0.9675128085700978\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 461, train_loss = 14.412187723908573, train_acc = 0.9675128085700978\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 462, train_loss = 14.404901830013841, train_acc = 0.9675128085700978\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 463, train_loss = 14.399145467672497, train_acc = 0.9675128085700978\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 464, train_loss = 14.391816271003336, train_acc = 0.9675128085700978\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 465, train_loss = 14.385014675557613, train_acc = 0.9675128085700978\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 466, train_loss = 14.37854959955439, train_acc = 0.9675128085700978\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 467, train_loss = 14.372222205158323, train_acc = 0.9675128085700978\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 468, train_loss = 14.366200233343989, train_acc = 0.9675128085700978\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 469, train_loss = 14.35868719452992, train_acc = 0.9675128085700978\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 470, train_loss = 14.352545557077974, train_acc = 0.9675128085700978\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 471, train_loss = 14.34574549132958, train_acc = 0.9676292501164415\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 472, train_loss = 14.340118180960417, train_acc = 0.9676292501164415\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 473, train_loss = 14.333090294152498, train_acc = 0.9677456916627852\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 474, train_loss = 14.328474114183336, train_acc = 0.9677456916627852\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 475, train_loss = 14.321960164699703, train_acc = 0.9677456916627852\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 476, train_loss = 14.315419418271631, train_acc = 0.9677456916627852\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 477, train_loss = 14.309963916894048, train_acc = 0.9677456916627852\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 478, train_loss = 14.302489808294922, train_acc = 0.9677456916627852\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 479, train_loss = 14.295878574252129, train_acc = 0.9677456916627852\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 480, train_loss = 14.290666298475116, train_acc = 0.9677456916627852\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 481, train_loss = 14.284677103161812, train_acc = 0.9677456916627852\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 482, train_loss = 14.277940975036472, train_acc = 0.9677456916627852\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 483, train_loss = 14.273005654569715, train_acc = 0.9678621332091291\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 484, train_loss = 14.266620560083538, train_acc = 0.9677456916627852\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 485, train_loss = 14.260876517742872, train_acc = 0.9678621332091291\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 486, train_loss = 14.254546468611807, train_acc = 0.9678621332091291\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 487, train_loss = 14.24801791086793, train_acc = 0.9678621332091291\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 488, train_loss = 14.24260495742783, train_acc = 0.9678621332091291\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 489, train_loss = 14.236091332975775, train_acc = 0.9678621332091291\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 490, train_loss = 14.231566356029361, train_acc = 0.9679785747554728\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 491, train_loss = 14.225361892487854, train_acc = 0.9679785747554728\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 492, train_loss = 14.21845430508256, train_acc = 0.9680950163018165\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 493, train_loss = 14.21267087617889, train_acc = 0.9680950163018165\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 494, train_loss = 14.206791996955872, train_acc = 0.9680950163018165\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 495, train_loss = 14.20177418505773, train_acc = 0.9680950163018165\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 496, train_loss = 14.196159732993692, train_acc = 0.9680950163018165\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 497, train_loss = 14.18972592940554, train_acc = 0.9682114578481602\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 498, train_loss = 14.184887843672186, train_acc = 0.9682114578481602\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 499, train_loss = 14.17979058995843, train_acc = 0.9682114578481602\n",
      "test Acc 0.952513966480447:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████▊                                                                    | 2/30 [13:18<3:06:10, 398.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "3th- epoch: 0, train_loss = 276.2034921646118, train_acc = 0.4118537494177923\n",
      "test Acc 0.4934823091247672:\n",
      "3th- epoch: 1, train_loss = 221.20825564861298, train_acc = 0.4970889613414066\n",
      "test Acc 0.49906890130353815:\n",
      "3th- epoch: 2, train_loss = 185.0362446308136, train_acc = 0.5027945971122496\n",
      "test Acc 0.5079143389199255:\n",
      "3th- epoch: 3, train_loss = 164.36495280265808, train_acc = 0.5295761527713088\n",
      "test Acc 0.5605214152700186:\n",
      "3th- epoch: 4, train_loss = 150.17652881145477, train_acc = 0.5865160689333955\n",
      "test Acc 0.6154562383612663:\n",
      "3th- epoch: 5, train_loss = 137.98855394124985, train_acc = 0.6256404285048905\n",
      "test Acc 0.6433891992551211:\n",
      "3th- epoch: 6, train_loss = 126.79091918468475, train_acc = 0.6612715416860736\n",
      "test Acc 0.6685288640595903:\n",
      "3th- epoch: 7, train_loss = 116.51499634981155, train_acc = 0.6928272007452259\n",
      "test Acc 0.7630353817504656:\n",
      "3th- epoch: 8, train_loss = 107.18992477655411, train_acc = 0.7657196087564043\n",
      "test Acc 0.7895716945996276:\n",
      "3th- epoch: 9, train_loss = 98.81350213289261, train_acc = 0.8018164881229622\n",
      "test Acc 0.8054003724394786:\n",
      "3th- epoch: 10, train_loss = 91.36836105585098, train_acc = 0.8105496040987424\n",
      "test Acc 0.8109869646182495:\n",
      "3th- epoch: 11, train_loss = 84.87694630026817, train_acc = 0.8225430833721472\n",
      "test Acc 0.8300744878957169:\n",
      "3th- epoch: 12, train_loss = 79.25132298469543, train_acc = 0.8309268747088961\n",
      "test Acc 0.8370577281191807:\n",
      "3th- epoch: 13, train_loss = 74.36280006170273, train_acc = 0.8401257568700512\n",
      "test Acc 0.8561452513966481:\n",
      "3th- epoch: 14, train_loss = 70.0978267788887, train_acc = 0.852119236143456\n",
      "test Acc 0.8635940409683427:\n",
      "3th- epoch: 15, train_loss = 66.3527777493, train_acc = 0.8625989753143922\n",
      "test Acc 0.8696461824953445:\n",
      "3th- epoch: 16, train_loss = 63.06414085626602, train_acc = 0.8688868188169538\n",
      "test Acc 0.8733705772811918:\n",
      "3th- epoch: 17, train_loss = 60.16272422671318, train_acc = 0.8721471821145785\n",
      "test Acc 0.8784916201117319:\n",
      "3th- epoch: 18, train_loss = 57.60346294939518, train_acc = 0.8765719608756404\n",
      "test Acc 0.8850093109869647:\n",
      "3th- epoch: 19, train_loss = 55.335990741848946, train_acc = 0.8812296227293899\n",
      "test Acc 0.8924581005586593:\n",
      "3th- epoch: 20, train_loss = 53.32984758913517, train_acc = 0.8887983232417327\n",
      "test Acc 0.8943202979515829:\n",
      "3th- epoch: 21, train_loss = 51.54651565849781, train_acc = 0.8919422449930136\n",
      "test Acc 0.8957169459962756:\n",
      "3th- epoch: 22, train_loss = 49.95280994474888, train_acc = 0.8940381928272008\n",
      "test Acc 0.8975791433891993:\n",
      "3th- epoch: 23, train_loss = 48.522739097476006, train_acc = 0.8957848160223568\n",
      "test Acc 0.8999068901303539:\n",
      "3th- epoch: 24, train_loss = 47.23180803656578, train_acc = 0.8974149976711691\n",
      "test Acc 0.9017690875232774:\n",
      "3th- epoch: 25, train_loss = 46.05980880558491, train_acc = 0.8986958546809501\n",
      "test Acc 0.9022346368715084:\n",
      "3th- epoch: 26, train_loss = 44.99081094563007, train_acc = 0.9004424778761062\n",
      "test Acc 0.9036312849162011:\n",
      "3th- epoch: 27, train_loss = 44.01194719970226, train_acc = 0.902305542617606\n",
      "test Acc 0.9054934823091247:\n",
      "3th- epoch: 28, train_loss = 43.10815179347992, train_acc = 0.9042850489054495\n",
      "test Acc 0.9054934823091247:\n",
      "3th- epoch: 29, train_loss = 42.27083298563957, train_acc = 0.9056823474615743\n",
      "test Acc 0.9064245810055865:\n",
      "3th- epoch: 30, train_loss = 41.49338908493519, train_acc = 0.9074289706567303\n",
      "test Acc 0.9082867783985102:\n",
      "3th- epoch: 31, train_loss = 40.76645585894585, train_acc = 0.9098742431299488\n",
      "test Acc 0.909683426443203:\n",
      "3th- epoch: 32, train_loss = 40.08524179458618, train_acc = 0.9116208663251048\n",
      "test Acc 0.909683426443203:\n",
      "3th- epoch: 33, train_loss = 39.4449762403965, train_acc = 0.9134839310666045\n",
      "test Acc 0.9110800744878957:\n",
      "3th- epoch: 34, train_loss = 38.84136474132538, train_acc = 0.9153469958081043\n",
      "test Acc 0.9129422718808193:\n",
      "3th- epoch: 35, train_loss = 38.269612684845924, train_acc = 0.9170936190032604\n",
      "test Acc 0.9138733705772812:\n",
      "3th- epoch: 36, train_loss = 37.72788795828819, train_acc = 0.9186073591057289\n",
      "test Acc 0.9152700186219739:\n",
      "3th- epoch: 37, train_loss = 37.21313267946243, train_acc = 0.9189566837447601\n",
      "test Acc 0.9171322160148976:\n",
      "3th- epoch: 38, train_loss = 36.72305856645107, train_acc = 0.9203539823008849\n",
      "test Acc 0.9171322160148976:\n",
      "3th- epoch: 39, train_loss = 36.25578582286835, train_acc = 0.921634839310666\n",
      "test Acc 0.9180633147113594:\n",
      "3th- epoch: 40, train_loss = 35.81075032055378, train_acc = 0.9222170470423847\n",
      "test Acc 0.9189944134078212:\n",
      "3th- epoch: 41, train_loss = 35.3850354924798, train_acc = 0.9229156963204471\n",
      "test Acc 0.9199255121042831:\n",
      "3th- epoch: 42, train_loss = 34.976998060941696, train_acc = 0.9237307871448532\n",
      "test Acc 0.9203910614525139:\n",
      "3th- epoch: 43, train_loss = 34.58569344878197, train_acc = 0.9244294364229158\n",
      "test Acc 0.9203910614525139:\n",
      "3th- epoch: 44, train_loss = 34.210358150303364, train_acc = 0.9250116441546343\n",
      "test Acc 0.9213221601489758:\n",
      "3th- epoch: 45, train_loss = 33.849585592746735, train_acc = 0.9262925011644154\n",
      "test Acc 0.9217877094972067:\n",
      "3th- epoch: 46, train_loss = 33.50278924405575, train_acc = 0.9274569166278528\n",
      "test Acc 0.9236499068901304:\n",
      "3th- epoch: 47, train_loss = 33.16775194555521, train_acc = 0.928272007452259\n",
      "test Acc 0.9241154562383612:\n",
      "3th- epoch: 48, train_loss = 32.84438172727823, train_acc = 0.9289706567303214\n",
      "test Acc 0.9245810055865922:\n",
      "3th- epoch: 49, train_loss = 32.532131895422935, train_acc = 0.9293199813693526\n",
      "test Acc 0.9250465549348231:\n",
      "3th- epoch: 50, train_loss = 32.23080676048994, train_acc = 0.9296693060083838\n",
      "test Acc 0.9250465549348231:\n",
      "3th- epoch: 51, train_loss = 31.939807802438736, train_acc = 0.9299021891010713\n",
      "test Acc 0.9250465549348231:\n",
      "3th- epoch: 52, train_loss = 31.657220356166363, train_acc = 0.9303679552864462\n",
      "test Acc 0.925512104283054:\n",
      "3th- epoch: 53, train_loss = 31.38397329300642, train_acc = 0.9310666045645086\n",
      "test Acc 0.925512104283054:\n",
      "3th- epoch: 54, train_loss = 31.118353851139545, train_acc = 0.9316488122962273\n",
      "test Acc 0.9264432029795159:\n",
      "3th- epoch: 55, train_loss = 30.860255904495716, train_acc = 0.9319981369352585\n",
      "test Acc 0.9264432029795159:\n",
      "3th- epoch: 56, train_loss = 30.609859734773636, train_acc = 0.9325803446669771\n",
      "test Acc 0.9269087523277467:\n",
      "3th- epoch: 57, train_loss = 30.36655694246292, train_acc = 0.9328132277596647\n",
      "test Acc 0.9273743016759777:\n",
      "3th- epoch: 58, train_loss = 30.12941436469555, train_acc = 0.9332789939450395\n",
      "test Acc 0.9278398510242085:\n",
      "3th- epoch: 59, train_loss = 29.898249804973602, train_acc = 0.9333954354913834\n",
      "test Acc 0.9278398510242085:\n",
      "3th- epoch: 60, train_loss = 29.672714948654175, train_acc = 0.9337447601304145\n",
      "test Acc 0.9273743016759777:\n",
      "3th- epoch: 61, train_loss = 29.453311540186405, train_acc = 0.933977643223102\n",
      "test Acc 0.9273743016759777:\n",
      "3th- epoch: 62, train_loss = 29.23816805332899, train_acc = 0.9345598509548206\n",
      "test Acc 0.9273743016759777:\n",
      "3th- epoch: 63, train_loss = 29.027984708547592, train_acc = 0.9347927340475082\n",
      "test Acc 0.9273743016759777:\n",
      "3th- epoch: 64, train_loss = 28.821788229048252, train_acc = 0.9354913833255706\n",
      "test Acc 0.9269087523277467:\n",
      "3th- epoch: 65, train_loss = 28.62038615345955, train_acc = 0.935724266418258\n",
      "test Acc 0.9269087523277467:\n",
      "3th- epoch: 66, train_loss = 28.42412654310465, train_acc = 0.9359571495109456\n",
      "test Acc 0.9278398510242085:\n",
      "3th- epoch: 67, train_loss = 28.232360139489174, train_acc = 0.9365393572426641\n",
      "test Acc 0.9287709497206704:\n",
      "3th- epoch: 68, train_loss = 28.0448532178998, train_acc = 0.9367722403353517\n",
      "test Acc 0.9287709497206704:\n",
      "3th- epoch: 69, train_loss = 27.86196956038475, train_acc = 0.9373544480670704\n",
      "test Acc 0.9287709497206704:\n",
      "3th- epoch: 70, train_loss = 27.682499535381794, train_acc = 0.9378202142524453\n",
      "test Acc 0.9297020484171322:\n",
      "3th- epoch: 71, train_loss = 27.506989143788815, train_acc = 0.937936655798789\n",
      "test Acc 0.931098696461825:\n",
      "3th- epoch: 72, train_loss = 27.335250973701477, train_acc = 0.9387517466231952\n",
      "test Acc 0.9315642458100558:\n",
      "3th- epoch: 73, train_loss = 27.166601337492466, train_acc = 0.9392175128085701\n",
      "test Acc 0.9320297951582868:\n",
      "3th- epoch: 74, train_loss = 27.001866437494755, train_acc = 0.9393339543549138\n",
      "test Acc 0.9320297951582868:\n",
      "3th- epoch: 75, train_loss = 26.841838374733925, train_acc = 0.9397997205402888\n",
      "test Acc 0.9320297951582868:\n",
      "3th- epoch: 76, train_loss = 26.6838533654809, train_acc = 0.9404983698183512\n",
      "test Acc 0.9320297951582868:\n",
      "3th- epoch: 77, train_loss = 26.5303289629519, train_acc = 0.9408476944573824\n",
      "test Acc 0.9320297951582868:\n",
      "3th- epoch: 78, train_loss = 26.37967338040471, train_acc = 0.9410805775500699\n",
      "test Acc 0.9324953445065177:\n",
      "3th- epoch: 79, train_loss = 26.232392475008965, train_acc = 0.941429902189101\n",
      "test Acc 0.9324953445065177:\n",
      "3th- epoch: 80, train_loss = 26.08789848536253, train_acc = 0.9420121099208197\n",
      "test Acc 0.9329608938547486:\n",
      "3th- epoch: 81, train_loss = 25.946291603147984, train_acc = 0.942361434559851\n",
      "test Acc 0.9329608938547486:\n",
      "3th- epoch: 82, train_loss = 25.807945907115936, train_acc = 0.9429436422915697\n",
      "test Acc 0.9329608938547486:\n",
      "3th- epoch: 83, train_loss = 25.672000467777252, train_acc = 0.9432929669306008\n",
      "test Acc 0.9338919925512105:\n",
      "3th- epoch: 84, train_loss = 25.53899345546961, train_acc = 0.9436422915696321\n",
      "test Acc 0.9343575418994413:\n",
      "3th- epoch: 85, train_loss = 25.408269878476858, train_acc = 0.9438751746623195\n",
      "test Acc 0.9348230912476723:\n",
      "3th- epoch: 86, train_loss = 25.280251797288656, train_acc = 0.944108057755007\n",
      "test Acc 0.9352886405959032:\n",
      "3th- epoch: 87, train_loss = 25.154725026339293, train_acc = 0.9448067070330693\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 88, train_loss = 25.03198379278183, train_acc = 0.9450395901257569\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 89, train_loss = 24.911291003227234, train_acc = 0.945388914764788\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 90, train_loss = 24.792833670973778, train_acc = 0.9457382394038193\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 91, train_loss = 24.676306299865246, train_acc = 0.9460875640428504\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 92, train_loss = 24.56244896352291, train_acc = 0.9460875640428504\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 93, train_loss = 24.450056228786707, train_acc = 0.9462040055891943\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 94, train_loss = 24.340421944856644, train_acc = 0.9462040055891943\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 95, train_loss = 24.233089458197355, train_acc = 0.9464368886818817\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 96, train_loss = 24.126795902848244, train_acc = 0.9465533302282254\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 97, train_loss = 24.022430550307035, train_acc = 0.9466697717745691\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 98, train_loss = 23.919615425169468, train_acc = 0.9469026548672567\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 99, train_loss = 23.81909377872944, train_acc = 0.9472519795062878\n",
      "test Acc 0.936219739292365:\n",
      "3th- epoch: 100, train_loss = 23.71995983272791, train_acc = 0.9472519795062878\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 101, train_loss = 23.623014014214277, train_acc = 0.9476013041453191\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 102, train_loss = 23.527464143931866, train_acc = 0.9479506287843502\n",
      "test Acc 0.9357541899441341:\n",
      "3th- epoch: 103, train_loss = 23.43320442736149, train_acc = 0.9479506287843502\n",
      "test Acc 0.936219739292365:\n",
      "3th- epoch: 104, train_loss = 23.340938221663237, train_acc = 0.9479506287843502\n",
      "test Acc 0.9371508379888268:\n",
      "3th- epoch: 105, train_loss = 23.248864997178316, train_acc = 0.9482999534233815\n",
      "test Acc 0.9371508379888268:\n",
      "3th- epoch: 106, train_loss = 23.159213062375784, train_acc = 0.9482999534233815\n",
      "test Acc 0.9376163873370578:\n",
      "3th- epoch: 107, train_loss = 23.07164576649666, train_acc = 0.9484163949697252\n",
      "test Acc 0.9376163873370578:\n",
      "3th- epoch: 108, train_loss = 22.98409567028284, train_acc = 0.9484163949697252\n",
      "test Acc 0.9380819366852886:\n",
      "3th- epoch: 109, train_loss = 22.898014403879642, train_acc = 0.9485328365160689\n",
      "test Acc 0.9385474860335196:\n",
      "3th- epoch: 110, train_loss = 22.814057901501656, train_acc = 0.9487657196087564\n",
      "test Acc 0.9385474860335196:\n",
      "3th- epoch: 111, train_loss = 22.729574590921402, train_acc = 0.9489986027014439\n",
      "test Acc 0.9385474860335196:\n",
      "3th- epoch: 112, train_loss = 22.647293467074633, train_acc = 0.9493479273404751\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 113, train_loss = 22.566210810095072, train_acc = 0.9495808104331626\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 114, train_loss = 22.48731094971299, train_acc = 0.9496972519795063\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 115, train_loss = 22.40979014709592, train_acc = 0.9496972519795063\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 116, train_loss = 22.332240983843803, train_acc = 0.94981369352585\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 117, train_loss = 22.257006663829088, train_acc = 0.9500465766185375\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 118, train_loss = 22.18094453588128, train_acc = 0.9500465766185375\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 119, train_loss = 22.106549348682165, train_acc = 0.950279459711225\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 120, train_loss = 22.03368015959859, train_acc = 0.9505123428039124\n",
      "test Acc 0.9394785847299814:\n",
      "3th- epoch: 121, train_loss = 21.961362194269896, train_acc = 0.9506287843502562\n",
      "test Acc 0.9394785847299814:\n",
      "3th- epoch: 122, train_loss = 21.89064021408558, train_acc = 0.9507452258965999\n",
      "test Acc 0.9394785847299814:\n",
      "3th- epoch: 123, train_loss = 21.820614702999592, train_acc = 0.9507452258965999\n",
      "test Acc 0.9394785847299814:\n",
      "3th- epoch: 124, train_loss = 21.750878017395735, train_acc = 0.9510945505356311\n",
      "test Acc 0.9394785847299814:\n",
      "3th- epoch: 125, train_loss = 21.682697121053934, train_acc = 0.9514438751746623\n",
      "test Acc 0.9394785847299814:\n",
      "3th- epoch: 126, train_loss = 21.615150291472673, train_acc = 0.9514438751746623\n",
      "test Acc 0.9399441340782123:\n",
      "3th- epoch: 127, train_loss = 21.54832200333476, train_acc = 0.951560316721006\n",
      "test Acc 0.9399441340782123:\n",
      "3th- epoch: 128, train_loss = 21.48158197849989, train_acc = 0.9516767582673498\n",
      "test Acc 0.9399441340782123:\n",
      "3th- epoch: 129, train_loss = 21.416440188884735, train_acc = 0.9519096413600373\n",
      "test Acc 0.9399441340782123:\n",
      "3th- epoch: 130, train_loss = 21.352496095001698, train_acc = 0.952026082906381\n",
      "test Acc 0.9399441340782123:\n",
      "3th- epoch: 131, train_loss = 21.288846913725138, train_acc = 0.9523754075454122\n",
      "test Acc 0.9399441340782123:\n",
      "3th- epoch: 132, train_loss = 21.226621586829424, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "3th- epoch: 133, train_loss = 21.16464725136757, train_acc = 0.9529576152771309\n",
      "test Acc 0.9399441340782123:\n",
      "3th- epoch: 134, train_loss = 21.10338657721877, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n",
      "3th- epoch: 135, train_loss = 21.042745903134346, train_acc = 0.9534233814625058\n",
      "test Acc 0.9399441340782123:\n",
      "3th- epoch: 136, train_loss = 20.982778575271368, train_acc = 0.9534233814625058\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 137, train_loss = 20.92399276793003, train_acc = 0.9535398230088495\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 138, train_loss = 20.86575175449252, train_acc = 0.9536562645551933\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 139, train_loss = 20.808013796806335, train_acc = 0.9537727061015371\n",
      "test Acc 0.9408752327746741:\n",
      "3th- epoch: 140, train_loss = 20.751056432724, train_acc = 0.9538891476478808\n",
      "test Acc 0.9408752327746741:\n",
      "3th- epoch: 141, train_loss = 20.694225694984198, train_acc = 0.9538891476478808\n",
      "test Acc 0.9408752327746741:\n",
      "3th- epoch: 142, train_loss = 20.637240320444107, train_acc = 0.9540055891942245\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 143, train_loss = 20.581828493624926, train_acc = 0.9541220307405682\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 144, train_loss = 20.527270391583443, train_acc = 0.9542384722869119\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 145, train_loss = 20.472854238003492, train_acc = 0.9543549138332557\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 146, train_loss = 20.419334644451737, train_acc = 0.9544713553795995\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 147, train_loss = 20.365173682570457, train_acc = 0.9544713553795995\n",
      "test Acc 0.9404096834264432:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 148, train_loss = 20.313264625146985, train_acc = 0.9545877969259432\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 149, train_loss = 20.26043264195323, train_acc = 0.9547042384722869\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 150, train_loss = 20.209364579990506, train_acc = 0.9547042384722869\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 151, train_loss = 20.159387396648526, train_acc = 0.9549371215649743\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 152, train_loss = 20.109563106670976, train_acc = 0.9552864462040056\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 153, train_loss = 20.060316180810332, train_acc = 0.955519329296693\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 154, train_loss = 20.010577272623777, train_acc = 0.955519329296693\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 155, train_loss = 19.961899051442742, train_acc = 0.9556357708430367\n",
      "test Acc 0.9408752327746741:\n",
      "3th- epoch: 156, train_loss = 19.913328766822815, train_acc = 0.9557522123893806\n",
      "test Acc 0.9408752327746741:\n",
      "3th- epoch: 157, train_loss = 19.865281900390983, train_acc = 0.9558686539357243\n",
      "test Acc 0.9408752327746741:\n",
      "3th- epoch: 158, train_loss = 19.81839014030993, train_acc = 0.9558686539357243\n",
      "test Acc 0.9408752327746741:\n",
      "3th- epoch: 159, train_loss = 19.770782524719834, train_acc = 0.9558686539357243\n",
      "test Acc 0.9413407821229051:\n",
      "3th- epoch: 160, train_loss = 19.724596794694662, train_acc = 0.9558686539357243\n",
      "test Acc 0.9418063314711359:\n",
      "3th- epoch: 161, train_loss = 19.67896461300552, train_acc = 0.9558686539357243\n",
      "test Acc 0.9418063314711359:\n",
      "3th- epoch: 162, train_loss = 19.632908906787634, train_acc = 0.9558686539357243\n",
      "test Acc 0.9422718808193669:\n",
      "3th- epoch: 163, train_loss = 19.58847081847489, train_acc = 0.9561015370284117\n",
      "test Acc 0.9422718808193669:\n",
      "3th- epoch: 164, train_loss = 19.544069530442357, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 165, train_loss = 19.499765744432807, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 166, train_loss = 19.45615898631513, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 167, train_loss = 19.413259418681264, train_acc = 0.9563344201210993\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 168, train_loss = 19.370306650176644, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 169, train_loss = 19.32853121124208, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 170, train_loss = 19.285875106230378, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 171, train_loss = 19.243574945256114, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 172, train_loss = 19.202155167236924, train_acc = 0.956450861667443\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 173, train_loss = 19.16218089684844, train_acc = 0.956450861667443\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 174, train_loss = 19.12083826214075, train_acc = 0.9566837447601304\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 175, train_loss = 19.0809215195477, train_acc = 0.9568001863064741\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 176, train_loss = 19.04158184491098, train_acc = 0.9569166278528178\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 177, train_loss = 19.001648819074035, train_acc = 0.9569166278528178\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 178, train_loss = 18.96315706335008, train_acc = 0.9572659524918491\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 179, train_loss = 18.924119846895337, train_acc = 0.9572659524918491\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 180, train_loss = 18.886461364105344, train_acc = 0.9574988355845365\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 181, train_loss = 18.84821611456573, train_acc = 0.9574988355845365\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 182, train_loss = 18.809615010395646, train_acc = 0.9576152771308803\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 183, train_loss = 18.773367369547486, train_acc = 0.9577317186772241\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 184, train_loss = 18.734954316169024, train_acc = 0.9578481602235678\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 185, train_loss = 18.698628483340144, train_acc = 0.9579646017699115\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 186, train_loss = 18.661895101889968, train_acc = 0.9580810433162552\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 187, train_loss = 18.625658767297864, train_acc = 0.9580810433162552\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 188, train_loss = 18.590908586978912, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 189, train_loss = 18.55522727034986, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 190, train_loss = 18.520504077896476, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 191, train_loss = 18.486091068014503, train_acc = 0.9584303679552865\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 192, train_loss = 18.45168429799378, train_acc = 0.9585468095016302\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 193, train_loss = 18.41790620237589, train_acc = 0.9585468095016302\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 194, train_loss = 18.383694967254996, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 195, train_loss = 18.351016940549016, train_acc = 0.9587796925943176\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 196, train_loss = 18.316240556538105, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 197, train_loss = 18.282884031534195, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 198, train_loss = 18.25093417428434, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 199, train_loss = 18.218579947948456, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 200, train_loss = 18.187256522476673, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 201, train_loss = 18.155150843784213, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 202, train_loss = 18.123442392796278, train_acc = 0.9587796925943176\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 203, train_loss = 18.09262895397842, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 204, train_loss = 18.061560003086925, train_acc = 0.9592454587796926\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 205, train_loss = 18.03121447376907, train_acc = 0.9592454587796926\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 206, train_loss = 18.00060186162591, train_acc = 0.95947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 207, train_loss = 17.971514524891973, train_acc = 0.95947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 208, train_loss = 17.9412045981735, train_acc = 0.95947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 209, train_loss = 17.911463361233473, train_acc = 0.9595947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 210, train_loss = 17.882221151143312, train_acc = 0.9595947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 211, train_loss = 17.85390430316329, train_acc = 0.9595947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 212, train_loss = 17.82439747452736, train_acc = 0.9595947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 213, train_loss = 17.795998848974705, train_acc = 0.9595947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 214, train_loss = 17.76770832762122, train_acc = 0.9595947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 215, train_loss = 17.739997224882245, train_acc = 0.9595947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 216, train_loss = 17.71166150458157, train_acc = 0.9595947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 217, train_loss = 17.68499968573451, train_acc = 0.9597112249650676\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 218, train_loss = 17.657324690371752, train_acc = 0.9597112249650676\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 219, train_loss = 17.63026541657746, train_acc = 0.9598276665114113\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 220, train_loss = 17.60390955209732, train_acc = 0.9598276665114113\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 221, train_loss = 17.577354231849313, train_acc = 0.959944108057755\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 222, train_loss = 17.550226328894496, train_acc = 0.9598276665114113\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 223, train_loss = 17.525475326925516, train_acc = 0.9598276665114113\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 224, train_loss = 17.49865104444325, train_acc = 0.9598276665114113\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 225, train_loss = 17.473160883411765, train_acc = 0.959944108057755\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 226, train_loss = 17.44759047590196, train_acc = 0.9600605496040987\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 227, train_loss = 17.42272018454969, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 228, train_loss = 17.3968291785568, train_acc = 0.9606427573358174\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 229, train_loss = 17.37242789566517, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 230, train_loss = 17.346926467493176, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 231, train_loss = 17.323429241776466, train_acc = 0.9607591988821611\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 232, train_loss = 17.29928125999868, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 233, train_loss = 17.27437410876155, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 234, train_loss = 17.250498078763485, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 235, train_loss = 17.2268138024956, train_acc = 0.9611085235211924\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 236, train_loss = 17.20343674905598, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 237, train_loss = 17.179749896749854, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 238, train_loss = 17.156433545053005, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 239, train_loss = 17.13323182798922, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 240, train_loss = 17.11053102836013, train_acc = 0.9615742897065673\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 241, train_loss = 17.088016523979604, train_acc = 0.961690731252911\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 242, train_loss = 17.0655213361606, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 243, train_loss = 17.0428047478199, train_acc = 0.9620400558919422\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 244, train_loss = 17.020362682640553, train_acc = 0.9619236143455985\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 245, train_loss = 16.99912814516574, train_acc = 0.962156497438286\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 246, train_loss = 16.976447279565036, train_acc = 0.962156497438286\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 247, train_loss = 16.95528131723404, train_acc = 0.9620400558919422\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 248, train_loss = 16.932662383653224, train_acc = 0.9620400558919422\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 249, train_loss = 16.912564773112535, train_acc = 0.9623893805309734\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 250, train_loss = 16.891187623143196, train_acc = 0.9623893805309734\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 251, train_loss = 16.86895937565714, train_acc = 0.9623893805309734\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 252, train_loss = 16.84916682448238, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 253, train_loss = 16.82786498684436, train_acc = 0.9625058220773172\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 254, train_loss = 16.8079706793651, train_acc = 0.9625058220773172\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 255, train_loss = 16.787775977514684, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 256, train_loss = 16.767018822021782, train_acc = 0.9627387051700047\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 257, train_loss = 16.746974389068782, train_acc = 0.9628551467163484\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 258, train_loss = 16.7267941897735, train_acc = 0.9628551467163484\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 259, train_loss = 16.707638676278293, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 260, train_loss = 16.687730153091252, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 261, train_loss = 16.667862988077104, train_acc = 0.9629715882626921\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 262, train_loss = 16.648166273720562, train_acc = 0.9629715882626921\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 263, train_loss = 16.62961793318391, train_acc = 0.9629715882626921\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 264, train_loss = 16.6105425208807, train_acc = 0.9629715882626921\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 265, train_loss = 16.59165546670556, train_acc = 0.9629715882626921\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 266, train_loss = 16.572588360868394, train_acc = 0.9629715882626921\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 267, train_loss = 16.554632917046547, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 268, train_loss = 16.536583566106856, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 269, train_loss = 16.51703717559576, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 270, train_loss = 16.499344013631344, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 271, train_loss = 16.48007455840707, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 272, train_loss = 16.463675350882113, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 273, train_loss = 16.444711718708277, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 274, train_loss = 16.42730509210378, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 275, train_loss = 16.410062678158283, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 276, train_loss = 16.391791122965515, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 277, train_loss = 16.3753036884591, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 278, train_loss = 16.35771958064288, train_acc = 0.9635537959944108\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 279, train_loss = 16.339764333330095, train_acc = 0.9635537959944108\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 280, train_loss = 16.322618261910975, train_acc = 0.9635537959944108\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 281, train_loss = 16.306323987431824, train_acc = 0.9635537959944108\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 282, train_loss = 16.289703744463623, train_acc = 0.9636702375407545\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 283, train_loss = 16.272613584063947, train_acc = 0.9636702375407545\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 284, train_loss = 16.25650333147496, train_acc = 0.9637866790870983\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 285, train_loss = 16.240003664046526, train_acc = 0.9637866790870983\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 286, train_loss = 16.223564020358026, train_acc = 0.9637866790870983\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 287, train_loss = 16.20800043735653, train_acc = 0.9637866790870983\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 288, train_loss = 16.19001895096153, train_acc = 0.9637866790870983\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 289, train_loss = 16.174470364116132, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 290, train_loss = 16.158834416419268, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 291, train_loss = 16.142823052592576, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 292, train_loss = 16.12683266494423, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 293, train_loss = 16.111583557911217, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 294, train_loss = 16.096432170830667, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 295, train_loss = 16.079293239861727, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 296, train_loss = 16.06363578233868, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 297, train_loss = 16.048351044766605, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 298, train_loss = 16.03406561538577, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 299, train_loss = 16.0185460858047, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 300, train_loss = 16.003661083988845, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 301, train_loss = 15.989133776165545, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 302, train_loss = 15.973547253757715, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 303, train_loss = 15.959140942431986, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 304, train_loss = 15.944149394519627, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 305, train_loss = 15.929464891552925, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 306, train_loss = 15.915284329093993, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 307, train_loss = 15.900686522014439, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 308, train_loss = 15.886541825719178, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 309, train_loss = 15.87219048757106, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 310, train_loss = 15.858849151991308, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 311, train_loss = 15.84406000841409, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 312, train_loss = 15.83045781031251, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 313, train_loss = 15.815781603567302, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 314, train_loss = 15.80311317089945, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 315, train_loss = 15.788713722489774, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 316, train_loss = 15.77543396409601, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 317, train_loss = 15.761865721084177, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 318, train_loss = 15.747984333895147, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 319, train_loss = 15.734805937856436, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 320, train_loss = 15.721888854168355, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 321, train_loss = 15.708921659737825, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 322, train_loss = 15.69522999227047, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 323, train_loss = 15.683192235417664, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 324, train_loss = 15.669686328619719, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 325, train_loss = 15.656069534830749, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 326, train_loss = 15.642782376147807, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 327, train_loss = 15.630799534730613, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 328, train_loss = 15.617587853223085, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 329, train_loss = 15.605601045303047, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 330, train_loss = 15.592373826541007, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 331, train_loss = 15.57913575321436, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 332, train_loss = 15.56794864591211, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 333, train_loss = 15.55510040000081, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 334, train_loss = 15.541880171746016, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 335, train_loss = 15.531137163750827, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 336, train_loss = 15.51845084130764, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 337, train_loss = 15.506341180764139, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 338, train_loss = 15.495688893832266, train_acc = 0.9654168607359106\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 339, train_loss = 15.482045362703502, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 340, train_loss = 15.470145646482706, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 341, train_loss = 15.4590545007959, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 342, train_loss = 15.447014883160591, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 343, train_loss = 15.434552622027695, train_acc = 0.965649743828598\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 344, train_loss = 15.424297370016575, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 345, train_loss = 15.41211299970746, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 346, train_loss = 15.400059240870178, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 347, train_loss = 15.389261457137764, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 348, train_loss = 15.378125711344182, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 349, train_loss = 15.367045246064663, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 350, train_loss = 15.355131763964891, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 351, train_loss = 15.342896026559174, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 352, train_loss = 15.333324217237532, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 353, train_loss = 15.321839758194983, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 354, train_loss = 15.310712467879057, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 355, train_loss = 15.300121787004173, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 356, train_loss = 15.28903191536665, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 357, train_loss = 15.277989360503852, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 358, train_loss = 15.26677652541548, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 359, train_loss = 15.257801310159266, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 360, train_loss = 15.246110897511244, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 361, train_loss = 15.235788476653397, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 362, train_loss = 15.225226665847003, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 363, train_loss = 15.214580801315606, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 364, train_loss = 15.203991533257067, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 365, train_loss = 15.193501197732985, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 366, train_loss = 15.182704164646566, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 367, train_loss = 15.173591003753245, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 368, train_loss = 15.16143446136266, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 369, train_loss = 15.152869894169271, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 370, train_loss = 15.142516105435789, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 371, train_loss = 15.133734223432839, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 372, train_loss = 15.123153686523438, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 373, train_loss = 15.112675405107439, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 374, train_loss = 15.103401160798967, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 375, train_loss = 15.093030146323144, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 376, train_loss = 15.08452048432082, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 377, train_loss = 15.073216286487877, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 378, train_loss = 15.062215606682003, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 379, train_loss = 15.053679297678173, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 380, train_loss = 15.044123403728008, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 381, train_loss = 15.034626034088433, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 382, train_loss = 15.026580087840557, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 383, train_loss = 15.01613438501954, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 384, train_loss = 15.007077775895596, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 385, train_loss = 14.99869329109788, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 386, train_loss = 14.988383434712887, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 387, train_loss = 14.97758071217686, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 388, train_loss = 14.968711380846798, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 389, train_loss = 14.960779978893697, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 390, train_loss = 14.949761771596968, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 391, train_loss = 14.943073466420174, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 392, train_loss = 14.932759393006563, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 393, train_loss = 14.921220738440752, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 394, train_loss = 14.914683909155428, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 395, train_loss = 14.904233884066343, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 396, train_loss = 14.895053506828845, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 397, train_loss = 14.885579545982182, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 398, train_loss = 14.877376862801611, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 399, train_loss = 14.869445617310703, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 400, train_loss = 14.858670637011528, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 401, train_loss = 14.852521187625825, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 402, train_loss = 14.84332722146064, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 403, train_loss = 14.833589143119752, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 404, train_loss = 14.82692996878177, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 405, train_loss = 14.816688104532659, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 406, train_loss = 14.808409913443029, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 407, train_loss = 14.799566787667572, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 408, train_loss = 14.79062316287309, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 409, train_loss = 14.782499960623682, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 410, train_loss = 14.77446633670479, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 411, train_loss = 14.766472022049129, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 412, train_loss = 14.758193276822567, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 413, train_loss = 14.750321929343045, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 414, train_loss = 14.743091572076082, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 415, train_loss = 14.73396307695657, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 416, train_loss = 14.72634135838598, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 417, train_loss = 14.71838145982474, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 418, train_loss = 14.711720549501479, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 419, train_loss = 14.700794306583703, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 420, train_loss = 14.6938795754686, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 421, train_loss = 14.685197380371392, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 422, train_loss = 14.678589654155076, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 423, train_loss = 14.671002400107682, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 424, train_loss = 14.663703831844032, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 425, train_loss = 14.654274199157953, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 426, train_loss = 14.647057203110307, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 427, train_loss = 14.638742005918175, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 428, train_loss = 14.63240621611476, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 429, train_loss = 14.625192472245544, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 430, train_loss = 14.61715662991628, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 431, train_loss = 14.60984405875206, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 432, train_loss = 14.60102185094729, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 433, train_loss = 14.594046156853437, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 434, train_loss = 14.588633307721466, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 435, train_loss = 14.579289557877928, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 436, train_loss = 14.572713533882052, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 437, train_loss = 14.56467529013753, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 438, train_loss = 14.559370125178248, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 439, train_loss = 14.550161801278591, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 440, train_loss = 14.543756613042206, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 441, train_loss = 14.536644021514803, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 442, train_loss = 14.529658149927855, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 443, train_loss = 14.522808693349361, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 444, train_loss = 14.51529394974932, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 445, train_loss = 14.509092602878809, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 446, train_loss = 14.501909223850816, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 447, train_loss = 14.49413886666298, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 448, train_loss = 14.487086153123528, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 449, train_loss = 14.480277211870998, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 450, train_loss = 14.474615565035492, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 451, train_loss = 14.464928886387497, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 452, train_loss = 14.458031728863716, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 453, train_loss = 14.453509746585041, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 454, train_loss = 14.445351312402636, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 455, train_loss = 14.437080989126116, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 456, train_loss = 14.431152728851885, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 457, train_loss = 14.424927864223719, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 458, train_loss = 14.416581330355257, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "3th- epoch: 459, train_loss = 14.411080622579902, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 460, train_loss = 14.405179854482412, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 461, train_loss = 14.397641065064818, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 462, train_loss = 14.3945317924954, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 463, train_loss = 14.384007137268782, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 464, train_loss = 14.380105402320623, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 465, train_loss = 14.373058214783669, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 466, train_loss = 14.365813333541155, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 467, train_loss = 14.361776372883469, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 468, train_loss = 14.351121339946985, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 469, train_loss = 14.347658639308065, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 470, train_loss = 14.342036129441112, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 471, train_loss = 14.33453825255856, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 472, train_loss = 14.328182344790548, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 473, train_loss = 14.320748233702034, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 474, train_loss = 14.316103619989008, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 475, train_loss = 14.309610688593239, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 476, train_loss = 14.302896256092936, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 477, train_loss = 14.298454193864018, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 478, train_loss = 14.292629081755877, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 479, train_loss = 14.286385568324476, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 480, train_loss = 14.28015930717811, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 481, train_loss = 14.272590532898903, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 482, train_loss = 14.268205471336842, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 483, train_loss = 14.260669884737581, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 484, train_loss = 14.254855980630964, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 485, train_loss = 14.249945264309645, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 486, train_loss = 14.243029376957566, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 487, train_loss = 14.23576419427991, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 488, train_loss = 14.229316460434347, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 489, train_loss = 14.22378663579002, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 490, train_loss = 14.22058812296018, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 491, train_loss = 14.21266575763002, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 492, train_loss = 14.207298258785158, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 493, train_loss = 14.203195920679718, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 494, train_loss = 14.196061523165554, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 495, train_loss = 14.188760449644178, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 496, train_loss = 14.184073518961668, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 497, train_loss = 14.17854917049408, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 498, train_loss = 14.17474770406261, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 499, train_loss = 14.171031651552767, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▎                                                                 | 3/30 [19:57<2:59:32, 398.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "4th- epoch: 0, train_loss = 272.8078705072403, train_acc = 0.4411970190964136\n",
      "test Acc 0.49534450651769085:\n",
      "4th- epoch: 1, train_loss = 213.61059081554413, train_acc = 0.5001164415463437\n",
      "test Acc 0.5:\n",
      "4th- epoch: 2, train_loss = 178.82091164588928, train_acc = 0.5058220773171868\n",
      "test Acc 0.5200186219739292:\n",
      "4th- epoch: 3, train_loss = 162.20025157928467, train_acc = 0.5434326967862133\n",
      "test Acc 0.585195530726257:\n",
      "4th- epoch: 4, train_loss = 149.47734540700912, train_acc = 0.5944340940847694\n",
      "test Acc 0.6140595903165735:\n",
      "4th- epoch: 5, train_loss = 138.23628962039948, train_acc = 0.6202841173730788\n",
      "test Acc 0.63268156424581:\n",
      "4th- epoch: 6, train_loss = 127.94197601079941, train_acc = 0.6378667908709827\n",
      "test Acc 0.6610800744878957:\n",
      "4th- epoch: 7, train_loss = 118.52841037511826, train_acc = 0.6662785281788542\n",
      "test Acc 0.6666666666666666:\n",
      "4th- epoch: 8, train_loss = 109.86026513576508, train_acc = 0.7072659524918491\n",
      "test Acc 0.7690875232774674:\n",
      "4th- epoch: 9, train_loss = 101.88350659608841, train_acc = 0.7921518397764322\n",
      "test Acc 0.803072625698324:\n",
      "4th- epoch: 10, train_loss = 94.62689125537872, train_acc = 0.8079878900791803\n",
      "test Acc 0.8105214152700186:\n",
      "4th- epoch: 11, train_loss = 88.12952280044556, train_acc = 0.8205635770843037\n",
      "test Acc 0.8277467411545624:\n",
      "4th- epoch: 12, train_loss = 82.3688705265522, train_acc = 0.8316255239869585\n",
      "test Acc 0.8333333333333334:\n",
      "4th- epoch: 13, train_loss = 77.2809809744358, train_acc = 0.8402421984163949\n",
      "test Acc 0.851024208566108:\n",
      "4th- epoch: 14, train_loss = 72.78475278615952, train_acc = 0.8523521192361434\n",
      "test Acc 0.8580074487895717:\n",
      "4th- epoch: 15, train_loss = 68.80753630399704, train_acc = 0.8606194690265486\n",
      "test Acc 0.8626629422718808:\n",
      "4th- epoch: 16, train_loss = 65.28439608216286, train_acc = 0.8664415463437355\n",
      "test Acc 0.8682495344506518:\n",
      "4th- epoch: 17, train_loss = 62.15716364979744, train_acc = 0.8699347927340475\n",
      "test Acc 0.8743016759776536:\n",
      "4th- epoch: 18, train_loss = 59.386198341846466, train_acc = 0.875873311597578\n",
      "test Acc 0.8817504655493482:\n",
      "4th- epoch: 19, train_loss = 56.92947241663933, train_acc = 0.8811131811830462\n",
      "test Acc 0.8873370577281192:\n",
      "4th- epoch: 20, train_loss = 54.752489387989044, train_acc = 0.8857708430367955\n",
      "test Acc 0.8896648044692738:\n",
      "4th- epoch: 21, train_loss = 52.81564711034298, train_acc = 0.8885654401490451\n",
      "test Acc 0.8938547486033519:\n",
      "4th- epoch: 22, train_loss = 51.086103558540344, train_acc = 0.891243595714951\n",
      "test Acc 0.8966480446927374:\n",
      "4th- epoch: 23, train_loss = 49.54117327928543, train_acc = 0.8938053097345132\n",
      "test Acc 0.8999068901303539:\n",
      "4th- epoch: 24, train_loss = 48.1534758657217, train_acc = 0.8971821145784816\n",
      "test Acc 0.9003724394785847:\n",
      "4th- epoch: 25, train_loss = 46.90331915020943, train_acc = 0.8991616208663251\n",
      "test Acc 0.9022346368715084:\n",
      "4th- epoch: 26, train_loss = 45.76921866834164, train_acc = 0.8999767116907312\n",
      "test Acc 0.9027001862197392:\n",
      "4th- epoch: 27, train_loss = 44.739369973540306, train_acc = 0.9019562179785747\n",
      "test Acc 0.9036312849162011:\n",
      "4th- epoch: 28, train_loss = 43.79701787233353, train_acc = 0.9035863996273871\n",
      "test Acc 0.9068901303538175:\n",
      "4th- epoch: 29, train_loss = 42.931374192237854, train_acc = 0.9054494643688868\n",
      "test Acc 0.909217877094972:\n",
      "4th- epoch: 30, train_loss = 42.13189077377319, train_acc = 0.9073125291103866\n",
      "test Acc 0.910148975791434:\n",
      "4th- epoch: 31, train_loss = 41.39081208407879, train_acc = 0.9090591523055426\n",
      "test Acc 0.9110800744878957:\n",
      "4th- epoch: 32, train_loss = 40.70113064348698, train_acc = 0.9108057755006986\n",
      "test Acc 0.9110800744878957:\n",
      "4th- epoch: 33, train_loss = 40.05542643368244, train_acc = 0.9136003726129484\n",
      "test Acc 0.9106145251396648:\n",
      "4th- epoch: 34, train_loss = 39.44794315099716, train_acc = 0.9144154634373545\n",
      "test Acc 0.9120111731843575:\n",
      "4th- epoch: 35, train_loss = 38.87542161345482, train_acc = 0.9158127619934793\n",
      "test Acc 0.9124767225325885:\n",
      "4th- epoch: 36, train_loss = 38.33367021381855, train_acc = 0.9168607359105729\n",
      "test Acc 0.9152700186219739:\n",
      "4th- epoch: 37, train_loss = 37.819377675652504, train_acc = 0.9180251513740102\n",
      "test Acc 0.9157355679702048:\n",
      "4th- epoch: 38, train_loss = 37.330133855342865, train_acc = 0.9191895668374476\n",
      "test Acc 0.9157355679702048:\n",
      "4th- epoch: 39, train_loss = 36.86420926451683, train_acc = 0.9202375407545412\n",
      "test Acc 0.9166666666666666:\n",
      "4th- epoch: 40, train_loss = 36.41963800787926, train_acc = 0.9214019562179786\n",
      "test Acc 0.9185288640595903:\n",
      "4th- epoch: 41, train_loss = 35.995275020599365, train_acc = 0.9215183977643223\n",
      "test Acc 0.9189944134078212:\n",
      "4th- epoch: 42, train_loss = 35.5893152654171, train_acc = 0.922100605496041\n",
      "test Acc 0.9203910614525139:\n",
      "4th- epoch: 43, train_loss = 35.199787348508835, train_acc = 0.922566371681416\n",
      "test Acc 0.9217877094972067:\n",
      "4th- epoch: 44, train_loss = 34.82593750953674, train_acc = 0.9230321378667908\n",
      "test Acc 0.9227188081936686:\n",
      "4th- epoch: 45, train_loss = 34.4653759598732, train_acc = 0.9241965533302282\n",
      "test Acc 0.9241154562383612:\n",
      "4th- epoch: 46, train_loss = 34.11777167022228, train_acc = 0.9247787610619469\n",
      "test Acc 0.9250465549348231:\n",
      "4th- epoch: 47, train_loss = 33.78334350138903, train_acc = 0.925593851886353\n",
      "test Acc 0.9250465549348231:\n",
      "4th- epoch: 48, train_loss = 33.46060912311077, train_acc = 0.926059618071728\n",
      "test Acc 0.925512104283054:\n",
      "4th- epoch: 49, train_loss = 33.14868067204952, train_acc = 0.9267582673497904\n",
      "test Acc 0.9259776536312849:\n",
      "4th- epoch: 50, train_loss = 32.84673109650612, train_acc = 0.9276897997205403\n",
      "test Acc 0.9264432029795159:\n",
      "4th- epoch: 51, train_loss = 32.555014938116074, train_acc = 0.9286213320912902\n",
      "test Acc 0.9269087523277467:\n",
      "4th- epoch: 52, train_loss = 32.27236967533827, train_acc = 0.9289706567303214\n",
      "test Acc 0.9278398510242085:\n",
      "4th- epoch: 53, train_loss = 31.998172990977764, train_acc = 0.9293199813693526\n",
      "test Acc 0.9278398510242085:\n",
      "4th- epoch: 54, train_loss = 31.7325973585248, train_acc = 0.9296693060083838\n",
      "test Acc 0.9278398510242085:\n",
      "4th- epoch: 55, train_loss = 31.47485375404358, train_acc = 0.9302515137401025\n",
      "test Acc 0.9278398510242085:\n",
      "4th- epoch: 56, train_loss = 31.224758982658386, train_acc = 0.9306008383791337\n",
      "test Acc 0.9278398510242085:\n",
      "4th- epoch: 57, train_loss = 30.981263250112534, train_acc = 0.9311830461108523\n",
      "test Acc 0.9278398510242085:\n",
      "4th- epoch: 58, train_loss = 30.74402718245983, train_acc = 0.9316488122962273\n",
      "test Acc 0.9278398510242085:\n",
      "4th- epoch: 59, train_loss = 30.512564703822136, train_acc = 0.9321145784816023\n",
      "test Acc 0.9278398510242085:\n",
      "4th- epoch: 60, train_loss = 30.286483012139797, train_acc = 0.9321145784816023\n",
      "test Acc 0.9283054003724395:\n",
      "4th- epoch: 61, train_loss = 30.06590510904789, train_acc = 0.9326967862133209\n",
      "test Acc 0.9283054003724395:\n",
      "4th- epoch: 62, train_loss = 29.849652133882046, train_acc = 0.9331625523986958\n",
      "test Acc 0.9283054003724395:\n",
      "4th- epoch: 63, train_loss = 29.637985572218895, train_acc = 0.9338612016767582\n",
      "test Acc 0.9283054003724395:\n",
      "4th- epoch: 64, train_loss = 29.43113426119089, train_acc = 0.9340940847694458\n",
      "test Acc 0.9292364990689013:\n",
      "4th- epoch: 65, train_loss = 29.229143232107162, train_acc = 0.9345598509548206\n",
      "test Acc 0.9297020484171322:\n",
      "4th- epoch: 66, train_loss = 29.031947672367096, train_acc = 0.9347927340475082\n",
      "test Acc 0.9301675977653632:\n",
      "4th- epoch: 67, train_loss = 28.838625632226467, train_acc = 0.9351420586865393\n",
      "test Acc 0.9301675977653632:\n",
      "4th- epoch: 68, train_loss = 28.64967029541731, train_acc = 0.935258500232883\n",
      "test Acc 0.9301675977653632:\n",
      "4th- epoch: 69, train_loss = 28.464461088180542, train_acc = 0.935724266418258\n",
      "test Acc 0.9301675977653632:\n",
      "4th- epoch: 70, train_loss = 28.282994210720062, train_acc = 0.9359571495109456\n",
      "test Acc 0.9301675977653632:\n",
      "4th- epoch: 71, train_loss = 28.104616574943066, train_acc = 0.9359571495109456\n",
      "test Acc 0.9301675977653632:\n",
      "4th- epoch: 72, train_loss = 27.930215664207935, train_acc = 0.9360735910572893\n",
      "test Acc 0.930633147113594:\n",
      "4th- epoch: 73, train_loss = 27.759015530347824, train_acc = 0.9363064741499767\n",
      "test Acc 0.930633147113594:\n",
      "4th- epoch: 74, train_loss = 27.59111738204956, train_acc = 0.936655798789008\n",
      "test Acc 0.930633147113594:\n",
      "4th- epoch: 75, train_loss = 27.426085218787193, train_acc = 0.9374708896134141\n",
      "test Acc 0.9315642458100558:\n",
      "4th- epoch: 76, train_loss = 27.264427803456783, train_acc = 0.9382859804378202\n",
      "test Acc 0.9315642458100558:\n",
      "4th- epoch: 77, train_loss = 27.105701245367527, train_acc = 0.9382859804378202\n",
      "test Acc 0.9320297951582868:\n",
      "4th- epoch: 78, train_loss = 26.950386188924313, train_acc = 0.9387517466231952\n",
      "test Acc 0.9320297951582868:\n",
      "4th- epoch: 79, train_loss = 26.79672022163868, train_acc = 0.9389846297158826\n",
      "test Acc 0.9320297951582868:\n",
      "4th- epoch: 80, train_loss = 26.645477958023548, train_acc = 0.9394503959012576\n",
      "test Acc 0.9320297951582868:\n",
      "4th- epoch: 81, train_loss = 26.498368054628372, train_acc = 0.9400326036329762\n",
      "test Acc 0.9320297951582868:\n",
      "4th- epoch: 82, train_loss = 26.353632129728794, train_acc = 0.9406148113646949\n",
      "test Acc 0.9324953445065177:\n",
      "4th- epoch: 83, train_loss = 26.211752515286207, train_acc = 0.9407312529110387\n",
      "test Acc 0.9324953445065177:\n",
      "4th- epoch: 84, train_loss = 26.072607848793268, train_acc = 0.9413134606427573\n",
      "test Acc 0.9324953445065177:\n",
      "4th- epoch: 85, train_loss = 25.935834974050522, train_acc = 0.9417792268281323\n",
      "test Acc 0.9329608938547486:\n",
      "4th- epoch: 86, train_loss = 25.80149056389928, train_acc = 0.9421285514671635\n",
      "test Acc 0.9329608938547486:\n",
      "4th- epoch: 87, train_loss = 25.669094067066908, train_acc = 0.9422449930135072\n",
      "test Acc 0.9329608938547486:\n",
      "4th- epoch: 88, train_loss = 25.539884839206934, train_acc = 0.9425943176525384\n",
      "test Acc 0.9329608938547486:\n",
      "4th- epoch: 89, train_loss = 25.41227177530527, train_acc = 0.9427107591988821\n",
      "test Acc 0.9329608938547486:\n",
      "4th- epoch: 90, train_loss = 25.28757819160819, train_acc = 0.9428272007452259\n",
      "test Acc 0.9329608938547486:\n",
      "4th- epoch: 91, train_loss = 25.164907351136208, train_acc = 0.9430600838379134\n",
      "test Acc 0.9329608938547486:\n",
      "4th- epoch: 92, train_loss = 25.0446732416749, train_acc = 0.9434094084769445\n",
      "test Acc 0.9334264432029795:\n",
      "4th- epoch: 93, train_loss = 24.925760865211487, train_acc = 0.9434094084769445\n",
      "test Acc 0.9334264432029795:\n",
      "4th- epoch: 94, train_loss = 24.809568598866463, train_acc = 0.9439916162086632\n",
      "test Acc 0.9334264432029795:\n",
      "4th- epoch: 95, train_loss = 24.694795303046703, train_acc = 0.9442244993013508\n",
      "test Acc 0.9334264432029795:\n",
      "4th- epoch: 96, train_loss = 24.581784918904305, train_acc = 0.9444573823940382\n",
      "test Acc 0.9334264432029795:\n",
      "4th- epoch: 97, train_loss = 24.47071098536253, train_acc = 0.9451560316721006\n",
      "test Acc 0.9334264432029795:\n",
      "4th- epoch: 98, train_loss = 24.361101508140564, train_acc = 0.9452724732184443\n",
      "test Acc 0.9334264432029795:\n",
      "4th- epoch: 99, train_loss = 24.253913015127182, train_acc = 0.945388914764788\n",
      "test Acc 0.9334264432029795:\n",
      "4th- epoch: 100, train_loss = 24.148204416036606, train_acc = 0.945854680950163\n",
      "test Acc 0.9343575418994413:\n",
      "4th- epoch: 101, train_loss = 24.04469497874379, train_acc = 0.9459711224965067\n",
      "test Acc 0.9343575418994413:\n",
      "4th- epoch: 102, train_loss = 23.9432510137558, train_acc = 0.946320447135538\n",
      "test Acc 0.9343575418994413:\n",
      "4th- epoch: 103, train_loss = 23.84305026754737, train_acc = 0.9469026548672567\n",
      "test Acc 0.9343575418994413:\n",
      "4th- epoch: 104, train_loss = 23.745130352675915, train_acc = 0.9469026548672567\n",
      "test Acc 0.9343575418994413:\n",
      "4th- epoch: 105, train_loss = 23.647640105336905, train_acc = 0.9469026548672567\n",
      "test Acc 0.9348230912476723:\n",
      "4th- epoch: 106, train_loss = 23.552660446614027, train_acc = 0.9470190964136004\n",
      "test Acc 0.9348230912476723:\n",
      "4th- epoch: 107, train_loss = 23.459065787494183, train_acc = 0.9472519795062878\n",
      "test Acc 0.9348230912476723:\n",
      "4th- epoch: 108, train_loss = 23.36678746715188, train_acc = 0.9473684210526315\n",
      "test Acc 0.9348230912476723:\n",
      "4th- epoch: 109, train_loss = 23.27520300447941, train_acc = 0.9474848625989754\n",
      "test Acc 0.9348230912476723:\n",
      "4th- epoch: 110, train_loss = 23.185416985303164, train_acc = 0.9476013041453191\n",
      "test Acc 0.9352886405959032:\n",
      "4th- epoch: 111, train_loss = 23.09661715477705, train_acc = 0.9476013041453191\n",
      "test Acc 0.9352886405959032:\n",
      "4th- epoch: 112, train_loss = 23.010050874203444, train_acc = 0.9479506287843502\n",
      "test Acc 0.9357541899441341:\n",
      "4th- epoch: 113, train_loss = 22.92394820228219, train_acc = 0.9481835118770378\n",
      "test Acc 0.936219739292365:\n",
      "4th- epoch: 114, train_loss = 22.839944012463093, train_acc = 0.9481835118770378\n",
      "test Acc 0.936219739292365:\n",
      "4th- epoch: 115, train_loss = 22.75690197572112, train_acc = 0.9481835118770378\n",
      "test Acc 0.936219739292365:\n",
      "4th- epoch: 116, train_loss = 22.674472827464342, train_acc = 0.9482999534233815\n",
      "test Acc 0.9366852886405959:\n",
      "4th- epoch: 117, train_loss = 22.59337455779314, train_acc = 0.9485328365160689\n",
      "test Acc 0.9366852886405959:\n",
      "4th- epoch: 118, train_loss = 22.51358213275671, train_acc = 0.9485328365160689\n",
      "test Acc 0.9376163873370578:\n",
      "4th- epoch: 119, train_loss = 22.435157850384712, train_acc = 0.9487657196087564\n",
      "test Acc 0.9376163873370578:\n",
      "4th- epoch: 120, train_loss = 22.357195530086756, train_acc = 0.9489986027014439\n",
      "test Acc 0.9376163873370578:\n",
      "4th- epoch: 121, train_loss = 22.280526742339134, train_acc = 0.9489986027014439\n",
      "test Acc 0.9376163873370578:\n",
      "4th- epoch: 122, train_loss = 22.205041892826557, train_acc = 0.9494643688868188\n",
      "test Acc 0.9376163873370578:\n",
      "4th- epoch: 123, train_loss = 22.130603104829788, train_acc = 0.9496972519795063\n",
      "test Acc 0.9376163873370578:\n",
      "4th- epoch: 124, train_loss = 22.05779143795371, train_acc = 0.9496972519795063\n",
      "test Acc 0.9376163873370578:\n",
      "4th- epoch: 125, train_loss = 21.984533570706844, train_acc = 0.9501630181648812\n",
      "test Acc 0.9376163873370578:\n",
      "4th- epoch: 126, train_loss = 21.9128633774817, train_acc = 0.9501630181648812\n",
      "test Acc 0.9380819366852886:\n",
      "4th- epoch: 127, train_loss = 21.842174883931875, train_acc = 0.9503959012575687\n",
      "test Acc 0.9390130353817505:\n",
      "4th- epoch: 128, train_loss = 21.77141897380352, train_acc = 0.9503959012575687\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 129, train_loss = 21.70272485911846, train_acc = 0.9506287843502562\n",
      "test Acc 0.9399441340782123:\n",
      "4th- epoch: 130, train_loss = 21.634424105286598, train_acc = 0.9506287843502562\n",
      "test Acc 0.9404096834264432:\n",
      "4th- epoch: 131, train_loss = 21.567649342119694, train_acc = 0.9507452258965999\n",
      "test Acc 0.9408752327746741:\n",
      "4th- epoch: 132, train_loss = 21.50082554668188, train_acc = 0.9508616674429436\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 133, train_loss = 21.43582735210657, train_acc = 0.9508616674429436\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 134, train_loss = 21.370812699198723, train_acc = 0.9510945505356311\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 135, train_loss = 21.30647174268961, train_acc = 0.9512109920819748\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 136, train_loss = 21.244265247136354, train_acc = 0.9513274336283186\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 137, train_loss = 21.18131783232093, train_acc = 0.9514438751746623\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 138, train_loss = 21.11886700615287, train_acc = 0.9513274336283186\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 139, train_loss = 21.05861223489046, train_acc = 0.951560316721006\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 140, train_loss = 20.998277500271797, train_acc = 0.9517931998136935\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 141, train_loss = 20.938510235399008, train_acc = 0.9516767582673498\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 142, train_loss = 20.87981653213501, train_acc = 0.9521425244527247\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 143, train_loss = 20.821297988295555, train_acc = 0.9522589659990685\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 144, train_loss = 20.764046102762222, train_acc = 0.9523754075454122\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 145, train_loss = 20.707127895206213, train_acc = 0.9527247321844434\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 146, train_loss = 20.651244200766087, train_acc = 0.9527247321844434\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 147, train_loss = 20.595140364021063, train_acc = 0.9527247321844434\n",
      "test Acc 0.9418063314711359:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 148, train_loss = 20.539544235914946, train_acc = 0.9528411737307871\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 149, train_loss = 20.485472090542316, train_acc = 0.9533069399161621\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 150, train_loss = 20.431449059396982, train_acc = 0.9535398230088495\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 151, train_loss = 20.378593150526285, train_acc = 0.9537727061015371\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 152, train_loss = 20.32557801529765, train_acc = 0.9538891476478808\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 153, train_loss = 20.272476479411125, train_acc = 0.9541220307405682\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 154, train_loss = 20.221302699297667, train_acc = 0.9543549138332557\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 155, train_loss = 20.170306142419577, train_acc = 0.9545877969259432\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 156, train_loss = 20.11895350366831, train_acc = 0.9547042384722869\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 157, train_loss = 20.06883543357253, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 158, train_loss = 20.018460258841515, train_acc = 0.9550535631113182\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 159, train_loss = 19.96972919255495, train_acc = 0.9550535631113182\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 160, train_loss = 19.920812286436558, train_acc = 0.9551700046576619\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 161, train_loss = 19.873404271900654, train_acc = 0.9551700046576619\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 162, train_loss = 19.825379870831966, train_acc = 0.9554028877503493\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 163, train_loss = 19.777822414413095, train_acc = 0.955519329296693\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 164, train_loss = 19.731714947149158, train_acc = 0.9557522123893806\n",
      "test Acc 0.9422718808193669:\n",
      "4th- epoch: 165, train_loss = 19.6843987647444, train_acc = 0.9558686539357243\n",
      "test Acc 0.9422718808193669:\n",
      "4th- epoch: 166, train_loss = 19.638668606057763, train_acc = 0.9558686539357243\n",
      "test Acc 0.9422718808193669:\n",
      "4th- epoch: 167, train_loss = 19.59302464686334, train_acc = 0.955985095482068\n",
      "test Acc 0.9422718808193669:\n",
      "4th- epoch: 168, train_loss = 19.548801546916366, train_acc = 0.955985095482068\n",
      "test Acc 0.9422718808193669:\n",
      "4th- epoch: 169, train_loss = 19.502604307606816, train_acc = 0.956450861667443\n",
      "test Acc 0.9422718808193669:\n",
      "4th- epoch: 170, train_loss = 19.45842026732862, train_acc = 0.956450861667443\n",
      "test Acc 0.9422718808193669:\n",
      "4th- epoch: 171, train_loss = 19.413924926891923, train_acc = 0.9566837447601304\n",
      "test Acc 0.9422718808193669:\n",
      "4th- epoch: 172, train_loss = 19.37147799320519, train_acc = 0.9566837447601304\n",
      "test Acc 0.9422718808193669:\n",
      "4th- epoch: 173, train_loss = 19.328502034768462, train_acc = 0.9566837447601304\n",
      "test Acc 0.9422718808193669:\n",
      "4th- epoch: 174, train_loss = 19.28344964981079, train_acc = 0.9566837447601304\n",
      "test Acc 0.9422718808193669:\n",
      "4th- epoch: 175, train_loss = 19.24099120311439, train_acc = 0.9566837447601304\n",
      "test Acc 0.9427374301675978:\n",
      "4th- epoch: 176, train_loss = 19.197004230692983, train_acc = 0.9566837447601304\n",
      "test Acc 0.9427374301675978:\n",
      "4th- epoch: 177, train_loss = 19.155797062441707, train_acc = 0.9568001863064741\n",
      "test Acc 0.9427374301675978:\n",
      "4th- epoch: 178, train_loss = 19.114864002913237, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 179, train_loss = 19.074738891795278, train_acc = 0.9570330693991617\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 180, train_loss = 19.034994075074792, train_acc = 0.9570330693991617\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 181, train_loss = 18.995479943230748, train_acc = 0.9571495109455054\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 182, train_loss = 18.955192310735583, train_acc = 0.9571495109455054\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 183, train_loss = 18.91620867140591, train_acc = 0.9571495109455054\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 184, train_loss = 18.877562809735537, train_acc = 0.9571495109455054\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 185, train_loss = 18.838951153680682, train_acc = 0.9574988355845365\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 186, train_loss = 18.801025938242674, train_acc = 0.9574988355845365\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 187, train_loss = 18.763240640982985, train_acc = 0.9576152771308803\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 188, train_loss = 18.72627951949835, train_acc = 0.9578481602235678\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 189, train_loss = 18.68741828761995, train_acc = 0.9581974848625989\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 190, train_loss = 18.65075952373445, train_acc = 0.9581974848625989\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 191, train_loss = 18.61373934522271, train_acc = 0.9583139264089428\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 192, train_loss = 18.577573446556926, train_acc = 0.9584303679552865\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 193, train_loss = 18.54299225844443, train_acc = 0.9583139264089428\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 194, train_loss = 18.50607585720718, train_acc = 0.9583139264089428\n",
      "test Acc 0.9445996275605214:\n",
      "4th- epoch: 195, train_loss = 18.471768498420715, train_acc = 0.9584303679552865\n",
      "test Acc 0.9445996275605214:\n",
      "4th- epoch: 196, train_loss = 18.438040263950825, train_acc = 0.9586632510479739\n",
      "test Acc 0.9445996275605214:\n",
      "4th- epoch: 197, train_loss = 18.403847075998783, train_acc = 0.9587796925943176\n",
      "test Acc 0.9450651769087524:\n",
      "4th- epoch: 198, train_loss = 18.368850762024522, train_acc = 0.9588961341406614\n",
      "test Acc 0.9455307262569832:\n",
      "4th- epoch: 199, train_loss = 18.33613832294941, train_acc = 0.9588961341406614\n",
      "test Acc 0.9455307262569832:\n",
      "4th- epoch: 200, train_loss = 18.302587727084756, train_acc = 0.9588961341406614\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 201, train_loss = 18.26924773491919, train_acc = 0.9588961341406614\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 202, train_loss = 18.235809337347746, train_acc = 0.9590125756870052\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 203, train_loss = 18.203832732513547, train_acc = 0.9591290172333489\n",
      "test Acc 0.9455307262569832:\n",
      "4th- epoch: 204, train_loss = 18.171403754502535, train_acc = 0.9591290172333489\n",
      "test Acc 0.9455307262569832:\n",
      "4th- epoch: 205, train_loss = 18.139351850375533, train_acc = 0.9591290172333489\n",
      "test Acc 0.9455307262569832:\n",
      "4th- epoch: 206, train_loss = 18.10725096054375, train_acc = 0.9591290172333489\n",
      "test Acc 0.9455307262569832:\n",
      "4th- epoch: 207, train_loss = 18.077175399288535, train_acc = 0.9591290172333489\n",
      "test Acc 0.9455307262569832:\n",
      "4th- epoch: 208, train_loss = 18.04398795031011, train_acc = 0.9591290172333489\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 209, train_loss = 18.015104850754142, train_acc = 0.9592454587796926\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 210, train_loss = 17.98310999572277, train_acc = 0.9592454587796926\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 211, train_loss = 17.95435907691717, train_acc = 0.9593619003260363\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 212, train_loss = 17.92328390479088, train_acc = 0.9593619003260363\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 213, train_loss = 17.893621498718858, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 214, train_loss = 17.863044016063213, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 215, train_loss = 17.83375179208815, train_acc = 0.9597112249650676\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 216, train_loss = 17.80561577156186, train_acc = 0.9597112249650676\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 217, train_loss = 17.77678521350026, train_acc = 0.9597112249650676\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 218, train_loss = 17.749603183940053, train_acc = 0.9597112249650676\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 219, train_loss = 17.720204358920455, train_acc = 0.959944108057755\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 220, train_loss = 17.69264999218285, train_acc = 0.9600605496040987\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 221, train_loss = 17.66321425512433, train_acc = 0.9602934326967862\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 222, train_loss = 17.63645183108747, train_acc = 0.9602934326967862\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 223, train_loss = 17.609408527612686, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 224, train_loss = 17.582288267090917, train_acc = 0.9605263157894737\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 225, train_loss = 17.554878374561667, train_acc = 0.9605263157894737\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 226, train_loss = 17.52860234491527, train_acc = 0.9605263157894737\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 227, train_loss = 17.500860719010234, train_acc = 0.9605263157894737\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 228, train_loss = 17.473922753706574, train_acc = 0.9605263157894737\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 229, train_loss = 17.448886206373572, train_acc = 0.9607591988821611\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 230, train_loss = 17.42293794825673, train_acc = 0.9607591988821611\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 231, train_loss = 17.396335646510124, train_acc = 0.9609920819748486\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 232, train_loss = 17.370698800310493, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 233, train_loss = 17.34669749252498, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 234, train_loss = 17.320997012779117, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 235, train_loss = 17.296054942533374, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 236, train_loss = 17.271771328523755, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 237, train_loss = 17.247497802600265, train_acc = 0.9609920819748486\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 238, train_loss = 17.22443892247975, train_acc = 0.9612249650675361\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 239, train_loss = 17.198082325980067, train_acc = 0.9611085235211924\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 240, train_loss = 17.174264654517174, train_acc = 0.9612249650675361\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 241, train_loss = 17.151246136054397, train_acc = 0.9612249650675361\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 242, train_loss = 17.127357037737966, train_acc = 0.9611085235211924\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 243, train_loss = 17.105201112106442, train_acc = 0.9612249650675361\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 244, train_loss = 17.080772437155247, train_acc = 0.9612249650675361\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 245, train_loss = 17.05625886283815, train_acc = 0.9613414066138798\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 246, train_loss = 17.034311400726438, train_acc = 0.9614578481602236\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 247, train_loss = 17.011078543961048, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 248, train_loss = 16.988075356930494, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 249, train_loss = 16.967550897970796, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 250, train_loss = 16.94338553212583, train_acc = 0.9618071727992548\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 251, train_loss = 16.922732086852193, train_acc = 0.9618071727992548\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 252, train_loss = 16.90146521665156, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 253, train_loss = 16.878611216321588, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 254, train_loss = 16.857649818062782, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 255, train_loss = 16.836949069984257, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 256, train_loss = 16.81546629872173, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 257, train_loss = 16.79233159404248, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 258, train_loss = 16.77506808191538, train_acc = 0.9625058220773172\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 259, train_loss = 16.751559689641, train_acc = 0.9625058220773172\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 260, train_loss = 16.731287916190922, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 261, train_loss = 16.71318635623902, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 262, train_loss = 16.690326812677085, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 263, train_loss = 16.671448305249214, train_acc = 0.9628551467163484\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 264, train_loss = 16.64987243246287, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 265, train_loss = 16.632914933376014, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 266, train_loss = 16.61188457533717, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 267, train_loss = 16.59221736341715, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 268, train_loss = 16.57421732414514, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 269, train_loss = 16.555060238577425, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 270, train_loss = 16.53588713426143, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 271, train_loss = 16.516678464598954, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 272, train_loss = 16.498005208559334, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 273, train_loss = 16.47908437345177, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 274, train_loss = 16.461588283069432, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 275, train_loss = 16.442286585457623, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 276, train_loss = 16.424431855790317, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 277, train_loss = 16.40791045036167, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 278, train_loss = 16.389555383473635, train_acc = 0.9636702375407545\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 279, train_loss = 16.372562624514103, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 280, train_loss = 16.352150272578, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 281, train_loss = 16.335849951952696, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 282, train_loss = 16.31933335121721, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 283, train_loss = 16.29957066476345, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 284, train_loss = 16.28552521392703, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 285, train_loss = 16.26714677270502, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 286, train_loss = 16.24922406580299, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 287, train_loss = 16.231126400642097, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 288, train_loss = 16.216246749274433, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 289, train_loss = 16.197579216212034, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 290, train_loss = 16.18295658379793, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 291, train_loss = 16.166231871582568, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 292, train_loss = 16.149560503661633, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 293, train_loss = 16.132809941656888, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 294, train_loss = 16.117481301538646, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 295, train_loss = 16.101802797056735, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 296, train_loss = 16.08641917910427, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 297, train_loss = 16.068228781223297, train_acc = 0.9641360037261295\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 298, train_loss = 16.05313660670072, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 299, train_loss = 16.03794176876545, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 300, train_loss = 16.023205344565213, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 301, train_loss = 16.007857809774578, train_acc = 0.9641360037261295\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 302, train_loss = 15.991688915528357, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 303, train_loss = 15.977347382344306, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 304, train_loss = 15.96165369823575, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 305, train_loss = 15.946905393153429, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 306, train_loss = 15.932400897145271, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 307, train_loss = 15.917273444123566, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 308, train_loss = 15.90236718673259, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 309, train_loss = 15.88920562993735, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 310, train_loss = 15.87552369106561, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 311, train_loss = 15.858376146294177, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 312, train_loss = 15.843834602274, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 313, train_loss = 15.83208308648318, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 314, train_loss = 15.815405392087996, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 315, train_loss = 15.803336583077908, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 316, train_loss = 15.78750854358077, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 317, train_loss = 15.775637239217758, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 318, train_loss = 15.761448554694653, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 319, train_loss = 15.7477693753317, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 320, train_loss = 15.733977172523737, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 321, train_loss = 15.719195444136858, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 322, train_loss = 15.70572108309716, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 323, train_loss = 15.693294350989163, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 324, train_loss = 15.680199276655912, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 325, train_loss = 15.666089958511293, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 326, train_loss = 15.653995480388403, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 327, train_loss = 15.638999935239553, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 328, train_loss = 15.627193777821958, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 329, train_loss = 15.61486917361617, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 330, train_loss = 15.601319093257189, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 331, train_loss = 15.586836889386177, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 332, train_loss = 15.575981986708939, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 333, train_loss = 15.56053413450718, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 334, train_loss = 15.549957245588303, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 335, train_loss = 15.536104812286794, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 336, train_loss = 15.522849727421999, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 337, train_loss = 15.511499375104904, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 338, train_loss = 15.498908289708197, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 339, train_loss = 15.486164721660316, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 340, train_loss = 15.473526791669428, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 341, train_loss = 15.461463179439306, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 342, train_loss = 15.449383190833032, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 343, train_loss = 15.438436317257583, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 344, train_loss = 15.425136592239141, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 345, train_loss = 15.41366883739829, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 346, train_loss = 15.401169266551733, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 347, train_loss = 15.388855685479939, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 348, train_loss = 15.376447036862373, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 349, train_loss = 15.365221084095538, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 350, train_loss = 15.353659222833812, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 351, train_loss = 15.343452043831348, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 352, train_loss = 15.331171539612114, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 353, train_loss = 15.320109411142766, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 354, train_loss = 15.307305292226374, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 355, train_loss = 15.296442173421383, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 356, train_loss = 15.285068743862212, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 357, train_loss = 15.274635400623083, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 358, train_loss = 15.262688561342657, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 359, train_loss = 15.252267112024128, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 360, train_loss = 15.240988769568503, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 361, train_loss = 15.229837503284216, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 362, train_loss = 15.219551789574325, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 363, train_loss = 15.207825382240117, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 364, train_loss = 15.198195186443627, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 365, train_loss = 15.18737863842398, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 366, train_loss = 15.177497427910566, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 367, train_loss = 15.165667193941772, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 368, train_loss = 15.15522991400212, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 369, train_loss = 15.146688931621611, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 370, train_loss = 15.1347128553316, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 371, train_loss = 15.12497466430068, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 372, train_loss = 15.113417063839734, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 373, train_loss = 15.103553153574467, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 374, train_loss = 15.093490743078291, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 375, train_loss = 15.083125771023333, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 376, train_loss = 15.071749742142856, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 377, train_loss = 15.061437322758138, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 378, train_loss = 15.051146228797734, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 379, train_loss = 15.042525422759354, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 380, train_loss = 15.033758358098567, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 381, train_loss = 15.02270045876503, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 382, train_loss = 15.011113001964986, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 383, train_loss = 15.002185410819948, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 384, train_loss = 14.992496103048325, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 385, train_loss = 14.982429242692888, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 386, train_loss = 14.975329924374819, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 387, train_loss = 14.963957608677447, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 388, train_loss = 14.953885227441788, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 389, train_loss = 14.944041666574776, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 390, train_loss = 14.934476796537638, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 391, train_loss = 14.924956100992858, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 392, train_loss = 14.915931660681963, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 393, train_loss = 14.907238078303635, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 394, train_loss = 14.898625609464943, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 395, train_loss = 14.888466657139361, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 396, train_loss = 14.8778157196939, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 397, train_loss = 14.87047468405217, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 398, train_loss = 14.861445208080113, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 399, train_loss = 14.852157342247665, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 400, train_loss = 14.84441687259823, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 401, train_loss = 14.83350404072553, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 402, train_loss = 14.82452931907028, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 403, train_loss = 14.81536502763629, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 404, train_loss = 14.806819665245712, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 405, train_loss = 14.798876312561333, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 406, train_loss = 14.788144093938172, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 407, train_loss = 14.77978886757046, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 408, train_loss = 14.77189798746258, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 409, train_loss = 14.762705731205642, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 410, train_loss = 14.754884057678282, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 411, train_loss = 14.745375079102814, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 412, train_loss = 14.738232900388539, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 413, train_loss = 14.727684768848121, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 414, train_loss = 14.71860961895436, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 415, train_loss = 14.71029004920274, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 416, train_loss = 14.702345964498818, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 417, train_loss = 14.693299478851259, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 418, train_loss = 14.685676828958094, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 419, train_loss = 14.677034226246178, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 420, train_loss = 14.66921788919717, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 421, train_loss = 14.660938270390034, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 422, train_loss = 14.651522307656705, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 423, train_loss = 14.644124194048345, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 424, train_loss = 14.635690152645111, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 425, train_loss = 14.62788376584649, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 426, train_loss = 14.620352488942444, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 427, train_loss = 14.613207868300378, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 428, train_loss = 14.604658878408372, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 429, train_loss = 14.595698069781065, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 430, train_loss = 14.589462856762111, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 431, train_loss = 14.579572352580726, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 432, train_loss = 14.571892601437867, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 433, train_loss = 14.564874715171754, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 434, train_loss = 14.558592983521521, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 435, train_loss = 14.55047335010022, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 436, train_loss = 14.542035098187625, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 437, train_loss = 14.532983776181936, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 438, train_loss = 14.526647803373635, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 439, train_loss = 14.51802622526884, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 440, train_loss = 14.510900733061135, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 441, train_loss = 14.503656526561826, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 442, train_loss = 14.498191403690726, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 443, train_loss = 14.489396899938583, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 444, train_loss = 14.48317235475406, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 445, train_loss = 14.473606477025896, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 446, train_loss = 14.46583412354812, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 447, train_loss = 14.460158391389996, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 448, train_loss = 14.452430956065655, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 449, train_loss = 14.445954460650682, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 450, train_loss = 14.43947010859847, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 451, train_loss = 14.430873869452626, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 452, train_loss = 14.422933280467987, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 453, train_loss = 14.416581686586142, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 454, train_loss = 14.409754250198603, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 455, train_loss = 14.400995736476034, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 456, train_loss = 14.396162737160921, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 457, train_loss = 14.387955639511347, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 458, train_loss = 14.379303018096834, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 459, train_loss = 14.37367436895147, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 460, train_loss = 14.367054861038923, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 461, train_loss = 14.359982136636972, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 462, train_loss = 14.354672806803137, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 463, train_loss = 14.346290737390518, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 464, train_loss = 14.33837640285492, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 465, train_loss = 14.332424455787987, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 466, train_loss = 14.325709514319897, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 467, train_loss = 14.321041710674763, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 468, train_loss = 14.312289802823216, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 469, train_loss = 14.305245564784855, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 470, train_loss = 14.300056904554367, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 471, train_loss = 14.292178323026747, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 472, train_loss = 14.285170141607523, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 473, train_loss = 14.27920218417421, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 474, train_loss = 14.273520404007286, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 475, train_loss = 14.265057054813951, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 476, train_loss = 14.260012781713158, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 477, train_loss = 14.252996012568474, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 478, train_loss = 14.24748550215736, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 479, train_loss = 14.23982892325148, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 480, train_loss = 14.233828837517649, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 481, train_loss = 14.2276859767735, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 482, train_loss = 14.222091103438288, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 483, train_loss = 14.215560477226973, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 484, train_loss = 14.208080609794706, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 485, train_loss = 14.20146711403504, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 486, train_loss = 14.195311028510332, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 487, train_loss = 14.188581152353436, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 488, train_loss = 14.183605682104826, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 489, train_loss = 14.176857850048691, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 490, train_loss = 14.171563609037548, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 491, train_loss = 14.165170045103878, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 492, train_loss = 14.158709432929754, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 493, train_loss = 14.151535586919636, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 494, train_loss = 14.147358351852745, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 495, train_loss = 14.141756533179432, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 496, train_loss = 14.138730425387621, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 497, train_loss = 14.129256095737219, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 498, train_loss = 14.121538708452135, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 499, train_loss = 14.11998258670792, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████▋                                                               | 4/30 [26:36<2:52:53, 399.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "5th- epoch: 0, train_loss = 273.12359035015106, train_acc = 0.46262226362366093\n",
      "test Acc 0.50512104283054:\n",
      "5th- epoch: 1, train_loss = 211.5753232240677, train_acc = 0.5012808570097811\n",
      "test Acc 0.5037243947858473:\n",
      "5th- epoch: 2, train_loss = 178.47317802906036, train_acc = 0.5170004657661854\n",
      "test Acc 0.5335195530726257:\n",
      "5th- epoch: 3, train_loss = 161.8494484424591, train_acc = 0.5476245924545878\n",
      "test Acc 0.5782122905027933:\n",
      "5th- epoch: 4, train_loss = 149.1482640504837, train_acc = 0.5860503027480205\n",
      "test Acc 0.6187150837988827:\n",
      "5th- epoch: 5, train_loss = 137.84246575832367, train_acc = 0.6275034932463903\n",
      "test Acc 0.6433891992551211:\n",
      "5th- epoch: 6, train_loss = 127.38623982667923, train_acc = 0.6448532836516069\n",
      "test Acc 0.6536312849162011:\n",
      "5th- epoch: 7, train_loss = 117.75730991363525, train_acc = 0.6917792268281323\n",
      "test Acc 0.7513966480446927:\n",
      "5th- epoch: 8, train_loss = 108.8482146859169, train_acc = 0.7519795062878435\n",
      "test Acc 0.7672253258845437:\n",
      "5th- epoch: 9, train_loss = 100.63339561223984, train_acc = 0.7806241266884024\n",
      "test Acc 0.8002793296089385:\n",
      "5th- epoch: 10, train_loss = 93.113091558218, train_acc = 0.8099673963670238\n",
      "test Acc 0.824487895716946:\n",
      "5th- epoch: 11, train_loss = 86.34707674384117, train_acc = 0.8277829529576153\n",
      "test Acc 0.8379888268156425:\n",
      "5th- epoch: 12, train_loss = 80.3459852039814, train_acc = 0.8387284583139264\n",
      "test Acc 0.8533519553072626:\n",
      "5th- epoch: 13, train_loss = 75.06511160731316, train_acc = 0.8506054960409875\n",
      "test Acc 0.8608007448789572:\n",
      "5th- epoch: 14, train_loss = 70.45855087041855, train_acc = 0.8591057289240801\n",
      "test Acc 0.8687150837988827:\n",
      "5th- epoch: 15, train_loss = 66.46144413948059, train_acc = 0.8643455985095482\n",
      "test Acc 0.8747672253258846:\n",
      "5th- epoch: 16, train_loss = 62.99353262782097, train_acc = 0.8687703772706101\n",
      "test Acc 0.8780260707635009:\n",
      "5th- epoch: 17, train_loss = 59.97884628176689, train_acc = 0.871448532836516\n",
      "test Acc 0.8803538175046555:\n",
      "5th- epoch: 18, train_loss = 57.34408186376095, train_acc = 0.875873311597578\n",
      "test Acc 0.8845437616387337:\n",
      "5th- epoch: 19, train_loss = 55.036992594599724, train_acc = 0.8812296227293899\n",
      "test Acc 0.8919925512104283:\n",
      "5th- epoch: 20, train_loss = 53.008058309555054, train_acc = 0.8864694923148579\n",
      "test Acc 0.8943202979515829:\n",
      "5th- epoch: 21, train_loss = 51.21216717362404, train_acc = 0.8920586865393573\n",
      "test Acc 0.8994413407821229:\n",
      "5th- epoch: 22, train_loss = 49.61504262685776, train_acc = 0.8955519329296693\n",
      "test Acc 0.8994413407821229:\n",
      "5th- epoch: 23, train_loss = 48.188174188137054, train_acc = 0.8964834653004192\n",
      "test Acc 0.9017690875232774:\n",
      "5th- epoch: 24, train_loss = 46.907288640737534, train_acc = 0.8985794131346064\n",
      "test Acc 0.9031657355679702:\n",
      "5th- epoch: 25, train_loss = 45.74954940378666, train_acc = 0.8997438285980438\n",
      "test Acc 0.9050279329608939:\n",
      "5th- epoch: 26, train_loss = 44.6970085054636, train_acc = 0.9019562179785747\n",
      "test Acc 0.9073556797020484:\n",
      "5th- epoch: 27, train_loss = 43.73453612625599, train_acc = 0.9038192827200745\n",
      "test Acc 0.9087523277467412:\n",
      "5th- epoch: 28, train_loss = 42.848487213253975, train_acc = 0.9059152305542617\n",
      "test Acc 0.910148975791434:\n",
      "5th- epoch: 29, train_loss = 42.0300377458334, train_acc = 0.9076618537494178\n",
      "test Acc 0.909683426443203:\n",
      "5th- epoch: 30, train_loss = 41.26941300928593, train_acc = 0.9089427107591989\n",
      "test Acc 0.9106145251396648:\n",
      "5th- epoch: 31, train_loss = 40.560050293803215, train_acc = 0.9109222170470423\n",
      "test Acc 0.9115456238361266:\n",
      "5th- epoch: 32, train_loss = 39.896773025393486, train_acc = 0.9131346064275734\n",
      "test Acc 0.9120111731843575:\n",
      "5th- epoch: 33, train_loss = 39.27420338988304, train_acc = 0.9152305542617606\n",
      "test Acc 0.9138733705772812:\n",
      "5th- epoch: 34, train_loss = 38.68783150613308, train_acc = 0.9168607359105729\n",
      "test Acc 0.9152700186219739:\n",
      "5th- epoch: 35, train_loss = 38.13322342932224, train_acc = 0.9177922682813228\n",
      "test Acc 0.9162011173184358:\n",
      "5th- epoch: 36, train_loss = 37.606617987155914, train_acc = 0.9184909175593852\n",
      "test Acc 0.9162011173184358:\n",
      "5th- epoch: 37, train_loss = 37.107316598296165, train_acc = 0.9195388914764788\n",
      "test Acc 0.9175977653631285:\n",
      "5th- epoch: 38, train_loss = 36.63350574672222, train_acc = 0.91988821611551\n",
      "test Acc 0.9194599627560521:\n",
      "5th- epoch: 39, train_loss = 36.182060584425926, train_acc = 0.9208197484862599\n",
      "test Acc 0.9185288640595903:\n",
      "5th- epoch: 40, train_loss = 35.75038155913353, train_acc = 0.9215183977643223\n",
      "test Acc 0.9185288640595903:\n",
      "5th- epoch: 41, train_loss = 35.33711691945791, train_acc = 0.922100605496041\n",
      "test Acc 0.9194599627560521:\n",
      "5th- epoch: 42, train_loss = 34.94023308157921, train_acc = 0.9233814625058221\n",
      "test Acc 0.9213221601489758:\n",
      "5th- epoch: 43, train_loss = 34.561262741684914, train_acc = 0.9243129948765719\n",
      "test Acc 0.9222532588454376:\n",
      "5th- epoch: 44, train_loss = 34.19726151227951, train_acc = 0.9248952026082906\n",
      "test Acc 0.9227188081936686:\n",
      "5th- epoch: 45, train_loss = 33.847311303019524, train_acc = 0.9259431765253843\n",
      "test Acc 0.9241154562383612:\n",
      "5th- epoch: 46, train_loss = 33.50934825837612, train_acc = 0.9262925011644154\n",
      "test Acc 0.9241154562383612:\n",
      "5th- epoch: 47, train_loss = 33.18362508714199, train_acc = 0.9269911504424779\n",
      "test Acc 0.9250465549348231:\n",
      "5th- epoch: 48, train_loss = 32.86927140504122, train_acc = 0.9275733581741965\n",
      "test Acc 0.9250465549348231:\n",
      "5th- epoch: 49, train_loss = 32.565430879592896, train_acc = 0.9281555659059152\n",
      "test Acc 0.9264432029795159:\n",
      "5th- epoch: 50, train_loss = 32.271461710333824, train_acc = 0.9287377736376339\n",
      "test Acc 0.9273743016759777:\n",
      "5th- epoch: 51, train_loss = 31.985461093485355, train_acc = 0.9292035398230089\n",
      "test Acc 0.9278398510242085:\n",
      "5th- epoch: 52, train_loss = 31.709367282688618, train_acc = 0.9294364229156963\n",
      "test Acc 0.9278398510242085:\n",
      "5th- epoch: 53, train_loss = 31.440447315573692, train_acc = 0.9296693060083838\n",
      "test Acc 0.9283054003724395:\n",
      "5th- epoch: 54, train_loss = 31.179055228829384, train_acc = 0.9299021891010713\n",
      "test Acc 0.9287709497206704:\n",
      "5th- epoch: 55, train_loss = 30.924607180058956, train_acc = 0.9302515137401025\n",
      "test Acc 0.9292364990689013:\n",
      "5th- epoch: 56, train_loss = 30.676922313869, train_acc = 0.9308337214718212\n",
      "test Acc 0.9292364990689013:\n",
      "5th- epoch: 57, train_loss = 30.43655826896429, train_acc = 0.9312994876571961\n",
      "test Acc 0.9292364990689013:\n",
      "5th- epoch: 58, train_loss = 30.2022857144475, train_acc = 0.9318816953889147\n",
      "test Acc 0.9292364990689013:\n",
      "5th- epoch: 59, train_loss = 29.974515475332737, train_acc = 0.9324639031206334\n",
      "test Acc 0.9292364990689013:\n",
      "5th- epoch: 60, train_loss = 29.751818381249905, train_acc = 0.9331625523986958\n",
      "test Acc 0.9297020484171322:\n",
      "5th- epoch: 61, train_loss = 29.535016767680645, train_acc = 0.9337447601304145\n",
      "test Acc 0.9297020484171322:\n",
      "5th- epoch: 62, train_loss = 29.32434555143118, train_acc = 0.9338612016767582\n",
      "test Acc 0.9297020484171322:\n",
      "5th- epoch: 63, train_loss = 29.1187414675951, train_acc = 0.9347927340475082\n",
      "test Acc 0.9297020484171322:\n",
      "5th- epoch: 64, train_loss = 28.918379582464695, train_acc = 0.9350256171401956\n",
      "test Acc 0.9292364990689013:\n",
      "5th- epoch: 65, train_loss = 28.722809500992298, train_acc = 0.935258500232883\n",
      "test Acc 0.9292364990689013:\n",
      "5th- epoch: 66, train_loss = 28.531457990407944, train_acc = 0.935258500232883\n",
      "test Acc 0.9292364990689013:\n",
      "5th- epoch: 67, train_loss = 28.343851268291473, train_acc = 0.935724266418258\n",
      "test Acc 0.9297020484171322:\n",
      "5th- epoch: 68, train_loss = 28.159964449703693, train_acc = 0.9359571495109456\n",
      "test Acc 0.930633147113594:\n",
      "5th- epoch: 69, train_loss = 27.980014383792877, train_acc = 0.9363064741499767\n",
      "test Acc 0.930633147113594:\n",
      "5th- epoch: 70, train_loss = 27.803831174969673, train_acc = 0.9364229156963204\n",
      "test Acc 0.930633147113594:\n",
      "5th- epoch: 71, train_loss = 27.632359601557255, train_acc = 0.9368886818816954\n",
      "test Acc 0.930633147113594:\n",
      "5th- epoch: 72, train_loss = 27.463897138834, train_acc = 0.9372380065207266\n",
      "test Acc 0.930633147113594:\n",
      "5th- epoch: 73, train_loss = 27.29870718717575, train_acc = 0.9375873311597578\n",
      "test Acc 0.931098696461825:\n",
      "5th- epoch: 74, train_loss = 27.137109212577343, train_acc = 0.9374708896134141\n",
      "test Acc 0.931098696461825:\n",
      "5th- epoch: 75, train_loss = 26.978539370000362, train_acc = 0.9378202142524453\n",
      "test Acc 0.931098696461825:\n",
      "5th- epoch: 76, train_loss = 26.823225438594818, train_acc = 0.9381695388914765\n",
      "test Acc 0.9315642458100558:\n",
      "5th- epoch: 77, train_loss = 26.670820597559214, train_acc = 0.9384024219841639\n",
      "test Acc 0.9315642458100558:\n",
      "5th- epoch: 78, train_loss = 26.521501425653696, train_acc = 0.9393339543549138\n",
      "test Acc 0.9320297951582868:\n",
      "5th- epoch: 79, train_loss = 26.375262930989265, train_acc = 0.9397997205402888\n",
      "test Acc 0.9320297951582868:\n",
      "5th- epoch: 80, train_loss = 26.23155251890421, train_acc = 0.9399161620866325\n",
      "test Acc 0.9320297951582868:\n",
      "5th- epoch: 81, train_loss = 26.09044972062111, train_acc = 0.9404983698183512\n",
      "test Acc 0.9324953445065177:\n",
      "5th- epoch: 82, train_loss = 25.952143743634224, train_acc = 0.9411970190964136\n",
      "test Acc 0.9334264432029795:\n",
      "5th- epoch: 83, train_loss = 25.81631964445114, train_acc = 0.9420121099208197\n",
      "test Acc 0.9334264432029795:\n",
      "5th- epoch: 84, train_loss = 25.682837318629026, train_acc = 0.9429436422915697\n",
      "test Acc 0.9334264432029795:\n",
      "5th- epoch: 85, train_loss = 25.55263438075781, train_acc = 0.9432929669306008\n",
      "test Acc 0.9338919925512105:\n",
      "5th- epoch: 86, train_loss = 25.424793489277363, train_acc = 0.9434094084769445\n",
      "test Acc 0.9338919925512105:\n",
      "5th- epoch: 87, train_loss = 25.29898414760828, train_acc = 0.9438751746623195\n",
      "test Acc 0.9338919925512105:\n",
      "5th- epoch: 88, train_loss = 25.175623681396246, train_acc = 0.9443409408476945\n",
      "test Acc 0.9338919925512105:\n",
      "5th- epoch: 89, train_loss = 25.054400511085987, train_acc = 0.9448067070330693\n",
      "test Acc 0.9338919925512105:\n",
      "5th- epoch: 90, train_loss = 24.935246657580137, train_acc = 0.9451560316721006\n",
      "test Acc 0.9338919925512105:\n",
      "5th- epoch: 91, train_loss = 24.818263720721006, train_acc = 0.945388914764788\n",
      "test Acc 0.9338919925512105:\n",
      "5th- epoch: 92, train_loss = 24.70364759862423, train_acc = 0.9455053563111319\n",
      "test Acc 0.9338919925512105:\n",
      "5th- epoch: 93, train_loss = 24.590411223471165, train_acc = 0.9455053563111319\n",
      "test Acc 0.9338919925512105:\n",
      "5th- epoch: 94, train_loss = 24.479780722409487, train_acc = 0.945854680950163\n",
      "test Acc 0.9338919925512105:\n",
      "5th- epoch: 95, train_loss = 24.370874624699354, train_acc = 0.9460875640428504\n",
      "test Acc 0.9343575418994413:\n",
      "5th- epoch: 96, train_loss = 24.26431790366769, train_acc = 0.946320447135538\n",
      "test Acc 0.9348230912476723:\n",
      "5th- epoch: 97, train_loss = 24.15933533385396, train_acc = 0.9465533302282254\n",
      "test Acc 0.9348230912476723:\n",
      "5th- epoch: 98, train_loss = 24.05612999200821, train_acc = 0.9466697717745691\n",
      "test Acc 0.9348230912476723:\n",
      "5th- epoch: 99, train_loss = 23.95442111045122, train_acc = 0.9466697717745691\n",
      "test Acc 0.9352886405959032:\n",
      "5th- epoch: 100, train_loss = 23.85487785190344, train_acc = 0.946786213320913\n",
      "test Acc 0.9357541899441341:\n",
      "5th- epoch: 101, train_loss = 23.75759582221508, train_acc = 0.946786213320913\n",
      "test Acc 0.9357541899441341:\n",
      "5th- epoch: 102, train_loss = 23.660958476364613, train_acc = 0.9470190964136004\n",
      "test Acc 0.9357541899441341:\n",
      "5th- epoch: 103, train_loss = 23.565934378653765, train_acc = 0.9471355379599441\n",
      "test Acc 0.936219739292365:\n",
      "5th- epoch: 104, train_loss = 23.47277196869254, train_acc = 0.9477177456916628\n",
      "test Acc 0.9366852886405959:\n",
      "5th- epoch: 105, train_loss = 23.38066280260682, train_acc = 0.9478341872380065\n",
      "test Acc 0.9366852886405959:\n",
      "5th- epoch: 106, train_loss = 23.290159538388252, train_acc = 0.9477177456916628\n",
      "test Acc 0.9376163873370578:\n",
      "5th- epoch: 107, train_loss = 23.20137095451355, train_acc = 0.9479506287843502\n",
      "test Acc 0.9376163873370578:\n",
      "5th- epoch: 108, train_loss = 23.11367430910468, train_acc = 0.9481835118770378\n",
      "test Acc 0.9376163873370578:\n",
      "5th- epoch: 109, train_loss = 23.027434777468443, train_acc = 0.9482999534233815\n",
      "test Acc 0.9380819366852886:\n",
      "5th- epoch: 110, train_loss = 22.942547786980867, train_acc = 0.9484163949697252\n",
      "test Acc 0.9380819366852886:\n",
      "5th- epoch: 111, train_loss = 22.8586964905262, train_acc = 0.9484163949697252\n",
      "test Acc 0.9385474860335196:\n",
      "5th- epoch: 112, train_loss = 22.775789942592382, train_acc = 0.9486492780624126\n",
      "test Acc 0.9385474860335196:\n",
      "5th- epoch: 113, train_loss = 22.695851251482964, train_acc = 0.9487657196087564\n",
      "test Acc 0.9385474860335196:\n",
      "5th- epoch: 114, train_loss = 22.616009920835495, train_acc = 0.9491150442477876\n",
      "test Acc 0.9390130353817505:\n",
      "5th- epoch: 115, train_loss = 22.536724880337715, train_acc = 0.9491150442477876\n",
      "test Acc 0.9390130353817505:\n",
      "5th- epoch: 116, train_loss = 22.458775497972965, train_acc = 0.9491150442477876\n",
      "test Acc 0.9390130353817505:\n",
      "5th- epoch: 117, train_loss = 22.38266647234559, train_acc = 0.9493479273404751\n",
      "test Acc 0.9390130353817505:\n",
      "5th- epoch: 118, train_loss = 22.306817963719368, train_acc = 0.9493479273404751\n",
      "test Acc 0.9390130353817505:\n",
      "5th- epoch: 119, train_loss = 22.232369150966406, train_acc = 0.9493479273404751\n",
      "test Acc 0.9394785847299814:\n",
      "5th- epoch: 120, train_loss = 22.158930130302906, train_acc = 0.9495808104331626\n",
      "test Acc 0.9394785847299814:\n",
      "5th- epoch: 121, train_loss = 22.086312849074602, train_acc = 0.9495808104331626\n",
      "test Acc 0.9399441340782123:\n",
      "5th- epoch: 122, train_loss = 22.01449477672577, train_acc = 0.9496972519795063\n",
      "test Acc 0.9399441340782123:\n",
      "5th- epoch: 123, train_loss = 21.943409528583288, train_acc = 0.9496972519795063\n",
      "test Acc 0.9404096834264432:\n",
      "5th- epoch: 124, train_loss = 21.873366970568895, train_acc = 0.94981369352585\n",
      "test Acc 0.9408752327746741:\n",
      "5th- epoch: 125, train_loss = 21.80400337278843, train_acc = 0.94981369352585\n",
      "test Acc 0.9408752327746741:\n",
      "5th- epoch: 126, train_loss = 21.735658816993237, train_acc = 0.9499301350721937\n",
      "test Acc 0.9408752327746741:\n",
      "5th- epoch: 127, train_loss = 21.668677266687155, train_acc = 0.9500465766185375\n",
      "test Acc 0.9408752327746741:\n",
      "5th- epoch: 128, train_loss = 21.60150546580553, train_acc = 0.9501630181648812\n",
      "test Acc 0.9408752327746741:\n",
      "5th- epoch: 129, train_loss = 21.535281591117382, train_acc = 0.950279459711225\n",
      "test Acc 0.9413407821229051:\n",
      "5th- epoch: 130, train_loss = 21.469842452555895, train_acc = 0.950279459711225\n",
      "test Acc 0.9413407821229051:\n",
      "5th- epoch: 131, train_loss = 21.404870752245188, train_acc = 0.9505123428039124\n",
      "test Acc 0.9413407821229051:\n",
      "5th- epoch: 132, train_loss = 21.340608842670918, train_acc = 0.9507452258965999\n",
      "test Acc 0.9413407821229051:\n",
      "5th- epoch: 133, train_loss = 21.277627483010292, train_acc = 0.9512109920819748\n",
      "test Acc 0.9413407821229051:\n",
      "5th- epoch: 134, train_loss = 21.21533017605543, train_acc = 0.951560316721006\n",
      "test Acc 0.9408752327746741:\n",
      "5th- epoch: 135, train_loss = 21.153754353523254, train_acc = 0.9516767582673498\n",
      "test Acc 0.9408752327746741:\n",
      "5th- epoch: 136, train_loss = 21.09276931360364, train_acc = 0.9517931998136935\n",
      "test Acc 0.9408752327746741:\n",
      "5th- epoch: 137, train_loss = 21.032859452068806, train_acc = 0.9519096413600373\n",
      "test Acc 0.9413407821229051:\n",
      "5th- epoch: 138, train_loss = 20.97365054115653, train_acc = 0.9522589659990685\n",
      "test Acc 0.9413407821229051:\n",
      "5th- epoch: 139, train_loss = 20.914840571582317, train_acc = 0.9522589659990685\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 140, train_loss = 20.856873806566, train_acc = 0.9523754075454122\n",
      "test Acc 0.9422718808193669:\n",
      "5th- epoch: 141, train_loss = 20.79911996424198, train_acc = 0.9522589659990685\n",
      "test Acc 0.9422718808193669:\n",
      "5th- epoch: 142, train_loss = 20.742069132626057, train_acc = 0.952491849091756\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 143, train_loss = 20.685871969908476, train_acc = 0.9523754075454122\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 144, train_loss = 20.63020931184292, train_acc = 0.9527247321844434\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 145, train_loss = 20.5750779658556, train_acc = 0.9529576152771309\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 146, train_loss = 20.519835997372866, train_acc = 0.9530740568234746\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 147, train_loss = 20.466104742139578, train_acc = 0.9531904983698184\n",
      "test Acc 0.9418063314711359:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 148, train_loss = 20.412738859653473, train_acc = 0.9537727061015371\n",
      "test Acc 0.9422718808193669:\n",
      "5th- epoch: 149, train_loss = 20.360474260523915, train_acc = 0.9540055891942245\n",
      "test Acc 0.9422718808193669:\n",
      "5th- epoch: 150, train_loss = 20.307407232001424, train_acc = 0.9541220307405682\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 151, train_loss = 20.256470745429397, train_acc = 0.9541220307405682\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 152, train_loss = 20.204591795802116, train_acc = 0.9542384722869119\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 153, train_loss = 20.15384010411799, train_acc = 0.9542384722869119\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 154, train_loss = 20.103699443861842, train_acc = 0.9542384722869119\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 155, train_loss = 20.053100883960724, train_acc = 0.9541220307405682\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 156, train_loss = 20.003915958106518, train_acc = 0.9544713553795995\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 157, train_loss = 19.9548572730273, train_acc = 0.9544713553795995\n",
      "test Acc 0.9422718808193669:\n",
      "5th- epoch: 158, train_loss = 19.905902449041605, train_acc = 0.9544713553795995\n",
      "test Acc 0.9422718808193669:\n",
      "5th- epoch: 159, train_loss = 19.8579766061157, train_acc = 0.9544713553795995\n",
      "test Acc 0.9422718808193669:\n",
      "5th- epoch: 160, train_loss = 19.810273138806224, train_acc = 0.9544713553795995\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 161, train_loss = 19.762784915044904, train_acc = 0.9545877969259432\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 162, train_loss = 19.716298235580325, train_acc = 0.9548206800186306\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 163, train_loss = 19.669669285416603, train_acc = 0.9549371215649743\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 164, train_loss = 19.62404134683311, train_acc = 0.9549371215649743\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 165, train_loss = 19.578814156353474, train_acc = 0.9549371215649743\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 166, train_loss = 19.533593056723475, train_acc = 0.9550535631113182\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 167, train_loss = 19.488800110295415, train_acc = 0.9550535631113182\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 168, train_loss = 19.443736417219043, train_acc = 0.9550535631113182\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 169, train_loss = 19.399995509535074, train_acc = 0.9552864462040056\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 170, train_loss = 19.35612964257598, train_acc = 0.9554028877503493\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 171, train_loss = 19.313152050599456, train_acc = 0.9557522123893806\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 172, train_loss = 19.2704510204494, train_acc = 0.9558686539357243\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 173, train_loss = 19.228432208299637, train_acc = 0.9558686539357243\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 174, train_loss = 19.18605592288077, train_acc = 0.9561015370284117\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 175, train_loss = 19.14508743584156, train_acc = 0.9562179785747554\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 176, train_loss = 19.103380160406232, train_acc = 0.9562179785747554\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 177, train_loss = 19.06276660040021, train_acc = 0.9562179785747554\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 178, train_loss = 19.022624311968684, train_acc = 0.956450861667443\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 179, train_loss = 18.982271065935493, train_acc = 0.9565673032137867\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 180, train_loss = 18.942368170246482, train_acc = 0.9566837447601304\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 181, train_loss = 18.90330577082932, train_acc = 0.9566837447601304\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 182, train_loss = 18.86484649963677, train_acc = 0.9570330693991617\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 183, train_loss = 18.82668880932033, train_acc = 0.9570330693991617\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 184, train_loss = 18.787685861811042, train_acc = 0.9570330693991617\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 185, train_loss = 18.749152975156903, train_acc = 0.9570330693991617\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 186, train_loss = 18.711743550375104, train_acc = 0.9571495109455054\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 187, train_loss = 18.672684160992503, train_acc = 0.9574988355845365\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 188, train_loss = 18.635057911276817, train_acc = 0.9573823940381928\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 189, train_loss = 18.59843405149877, train_acc = 0.9574988355845365\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 190, train_loss = 18.561425622552633, train_acc = 0.9576152771308803\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 191, train_loss = 18.5260367449373, train_acc = 0.9578481602235678\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 192, train_loss = 18.490719044581056, train_acc = 0.9578481602235678\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 193, train_loss = 18.454138407483697, train_acc = 0.9579646017699115\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 194, train_loss = 18.419778011739254, train_acc = 0.9580810433162552\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 195, train_loss = 18.38424721919, train_acc = 0.9579646017699115\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 196, train_loss = 18.35027888044715, train_acc = 0.9579646017699115\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 197, train_loss = 18.315719360485673, train_acc = 0.9580810433162552\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 198, train_loss = 18.28215161897242, train_acc = 0.9580810433162552\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 199, train_loss = 18.247554879635572, train_acc = 0.9581974848625989\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 200, train_loss = 18.214052649214864, train_acc = 0.9581974848625989\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 201, train_loss = 18.180791152641177, train_acc = 0.9584303679552865\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 202, train_loss = 18.14726566709578, train_acc = 0.9587796925943176\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 203, train_loss = 18.115153850987554, train_acc = 0.9587796925943176\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 204, train_loss = 18.08192076906562, train_acc = 0.9587796925943176\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 205, train_loss = 18.050760162994266, train_acc = 0.9588961341406614\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 206, train_loss = 18.018590634688735, train_acc = 0.9590125756870052\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 207, train_loss = 17.987750463187695, train_acc = 0.9590125756870052\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 208, train_loss = 17.955571653321385, train_acc = 0.9591290172333489\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 209, train_loss = 17.9246032461524, train_acc = 0.9591290172333489\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 210, train_loss = 17.89455697312951, train_acc = 0.9592454587796926\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 211, train_loss = 17.864432523027062, train_acc = 0.9591290172333489\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 212, train_loss = 17.833563366904855, train_acc = 0.9592454587796926\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 213, train_loss = 17.80409910902381, train_acc = 0.9592454587796926\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 214, train_loss = 17.774423135444522, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 215, train_loss = 17.744831742718816, train_acc = 0.9595947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 216, train_loss = 17.715452942997217, train_acc = 0.959944108057755\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 217, train_loss = 17.686727246269584, train_acc = 0.9600605496040987\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 218, train_loss = 17.658629592508078, train_acc = 0.9600605496040987\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 219, train_loss = 17.630499381572008, train_acc = 0.9600605496040987\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 220, train_loss = 17.602099511772394, train_acc = 0.9600605496040987\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 221, train_loss = 17.574557580053806, train_acc = 0.9600605496040987\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 222, train_loss = 17.546338176354766, train_acc = 0.959944108057755\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 223, train_loss = 17.519661026075482, train_acc = 0.9601769911504425\n",
      "test Acc 0.946927374301676:\n",
      "5th- epoch: 224, train_loss = 17.492664074525237, train_acc = 0.9601769911504425\n",
      "test Acc 0.946927374301676:\n",
      "5th- epoch: 225, train_loss = 17.46532621793449, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 226, train_loss = 17.438516907393932, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 227, train_loss = 17.411979719996452, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 228, train_loss = 17.385402530431747, train_acc = 0.9605263157894737\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 229, train_loss = 17.358331022784114, train_acc = 0.9605263157894737\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 230, train_loss = 17.332901371642947, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 231, train_loss = 17.307606944814324, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 232, train_loss = 17.281959487125278, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 233, train_loss = 17.256813131272793, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 234, train_loss = 17.233252489939332, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 235, train_loss = 17.208073610439897, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 236, train_loss = 17.183409059420228, train_acc = 0.9609920819748486\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 237, train_loss = 17.15966160222888, train_acc = 0.9611085235211924\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 238, train_loss = 17.135226540267467, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 239, train_loss = 17.110816713422537, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 240, train_loss = 17.08793976623565, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 241, train_loss = 17.063852350227535, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 242, train_loss = 17.04103444609791, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 243, train_loss = 17.01789936516434, train_acc = 0.9615742897065673\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 244, train_loss = 16.9947159467265, train_acc = 0.9615742897065673\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 245, train_loss = 16.972005661576986, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 246, train_loss = 16.94982407707721, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 247, train_loss = 16.92685902491212, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 248, train_loss = 16.904102127067745, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 249, train_loss = 16.880852931179106, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 250, train_loss = 16.86023855302483, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 251, train_loss = 16.838966235518456, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 252, train_loss = 16.81660990882665, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 253, train_loss = 16.794770400971174, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 254, train_loss = 16.774258516728878, train_acc = 0.9625058220773172\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 255, train_loss = 16.75316983833909, train_acc = 0.9627387051700047\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 256, train_loss = 16.732396594248712, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 257, train_loss = 16.712352506816387, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 258, train_loss = 16.69117980916053, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 259, train_loss = 16.6708627268672, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 260, train_loss = 16.65063801407814, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 261, train_loss = 16.62951447069645, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 262, train_loss = 16.60913510248065, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 263, train_loss = 16.589906624518335, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 264, train_loss = 16.569812790490687, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 265, train_loss = 16.551153258420527, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 266, train_loss = 16.530194739811122, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 267, train_loss = 16.511894623748958, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 268, train_loss = 16.492740594781935, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 269, train_loss = 16.47437177132815, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 270, train_loss = 16.454865150153637, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 271, train_loss = 16.4351344704628, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 272, train_loss = 16.418353197164834, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 273, train_loss = 16.399038120172918, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 274, train_loss = 16.381024550646544, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 275, train_loss = 16.36217165272683, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 276, train_loss = 16.34454099368304, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 277, train_loss = 16.32616908568889, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 278, train_loss = 16.307995884679258, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 279, train_loss = 16.290591931901872, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 280, train_loss = 16.272711846977472, train_acc = 0.9636702375407545\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 281, train_loss = 16.25552940648049, train_acc = 0.9637866790870983\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 282, train_loss = 16.238436926156282, train_acc = 0.963903120633442\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 283, train_loss = 16.220654748380184, train_acc = 0.963903120633442\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 284, train_loss = 16.20387923810631, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 285, train_loss = 16.186834383755922, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 286, train_loss = 16.170366071164608, train_acc = 0.9641360037261295\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 287, train_loss = 16.153381306678057, train_acc = 0.9641360037261295\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 288, train_loss = 16.13725208491087, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 289, train_loss = 16.120318801142275, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 290, train_loss = 16.1037622326985, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 291, train_loss = 16.087297689169645, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 292, train_loss = 16.07152434438467, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 293, train_loss = 16.055387678556144, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 294, train_loss = 16.039783435873687, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 295, train_loss = 16.02316661644727, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 296, train_loss = 16.006108357571065, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 297, train_loss = 15.990069519728422, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 298, train_loss = 15.974083206616342, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 299, train_loss = 15.95823648199439, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 300, train_loss = 15.943249489180744, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 301, train_loss = 15.928236433304846, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 302, train_loss = 15.911893639713526, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 303, train_loss = 15.896426410414279, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 304, train_loss = 15.88186254631728, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 305, train_loss = 15.86707231681794, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 306, train_loss = 15.852063356898725, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 307, train_loss = 15.83820952102542, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 308, train_loss = 15.823947266675532, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 309, train_loss = 15.808444399386644, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 310, train_loss = 15.795259173028171, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 311, train_loss = 15.781035728752613, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 312, train_loss = 15.767195015214384, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 313, train_loss = 15.75143341999501, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 314, train_loss = 15.73831382766366, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 315, train_loss = 15.723598471842706, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 316, train_loss = 15.709968462586403, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 317, train_loss = 15.696656328625977, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 318, train_loss = 15.681886189617217, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 319, train_loss = 15.668291423469782, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 320, train_loss = 15.65491971373558, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 321, train_loss = 15.64169683586806, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 322, train_loss = 15.629023398272693, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 323, train_loss = 15.614797758869827, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 324, train_loss = 15.601644612848759, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 325, train_loss = 15.588001576252282, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 326, train_loss = 15.575936750508845, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 327, train_loss = 15.562974291853607, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 328, train_loss = 15.549849818460643, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 329, train_loss = 15.53651902358979, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 330, train_loss = 15.52433059643954, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 331, train_loss = 15.512384316883981, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 332, train_loss = 15.49969353992492, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 333, train_loss = 15.484627599827945, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 334, train_loss = 15.473923646844923, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 335, train_loss = 15.461197982542217, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 336, train_loss = 15.449961961247027, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 337, train_loss = 15.438270832411945, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 338, train_loss = 15.423406790010631, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 339, train_loss = 15.412865119986236, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 340, train_loss = 15.40007258206606, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 341, train_loss = 15.388720891438425, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 342, train_loss = 15.376435422338545, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 343, train_loss = 15.364319329150021, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 344, train_loss = 15.352193914353848, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 345, train_loss = 15.342333347536623, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 346, train_loss = 15.329966962337494, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 347, train_loss = 15.318857601843774, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 348, train_loss = 15.307213204912841, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 349, train_loss = 15.295048939995468, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 350, train_loss = 15.284337341785431, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 351, train_loss = 15.27290656697005, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 352, train_loss = 15.263006769120693, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 353, train_loss = 15.251430016011, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 354, train_loss = 15.23840457573533, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 355, train_loss = 15.228414340876043, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 356, train_loss = 15.217883188277483, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 357, train_loss = 15.206527627073228, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 358, train_loss = 15.196294675581157, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 359, train_loss = 15.186583469621837, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 360, train_loss = 15.175236728042364, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 361, train_loss = 15.16296211630106, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 362, train_loss = 15.153783614747226, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 363, train_loss = 15.142153359949589, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 364, train_loss = 15.132319861091673, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 365, train_loss = 15.121511031873524, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 366, train_loss = 15.11321975570172, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 367, train_loss = 15.09843095112592, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 368, train_loss = 15.090491863898933, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 369, train_loss = 15.080769226886332, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 370, train_loss = 15.07078676391393, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 371, train_loss = 15.061362468637526, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 372, train_loss = 15.050836235284805, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 373, train_loss = 15.037881380878389, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 374, train_loss = 15.031522148288786, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 375, train_loss = 15.02005331683904, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 376, train_loss = 15.009705108590424, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 377, train_loss = 15.000783436000347, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 378, train_loss = 14.989704575389624, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 379, train_loss = 14.982336382381618, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 380, train_loss = 14.969447641633451, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 381, train_loss = 14.961756126023829, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 382, train_loss = 14.95178159326315, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 383, train_loss = 14.94220710080117, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 384, train_loss = 14.932344649918377, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 385, train_loss = 14.922514907084405, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 386, train_loss = 14.913821305148304, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 387, train_loss = 14.904001821763813, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 388, train_loss = 14.895502517931163, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 389, train_loss = 14.885843737982213, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 390, train_loss = 14.876181895844638, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 391, train_loss = 14.868436213582754, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 392, train_loss = 14.858120821416378, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 393, train_loss = 14.8497562892735, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 394, train_loss = 14.83942195866257, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 395, train_loss = 14.830682098865509, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 396, train_loss = 14.823097839020193, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 397, train_loss = 14.814616591669619, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 398, train_loss = 14.806717227213085, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 399, train_loss = 14.798443018458784, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 400, train_loss = 14.78672780841589, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 401, train_loss = 14.777713497169316, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 402, train_loss = 14.771532073616982, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 403, train_loss = 14.762858636677265, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 404, train_loss = 14.755114957690239, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 405, train_loss = 14.74704359471798, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 406, train_loss = 14.738048773258924, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 407, train_loss = 14.730347365140915, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 408, train_loss = 14.72040794417262, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 409, train_loss = 14.711840230971575, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 410, train_loss = 14.702707610093057, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 411, train_loss = 14.692871977575123, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 412, train_loss = 14.6878523780033, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 413, train_loss = 14.67798388004303, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 414, train_loss = 14.670393347740173, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 415, train_loss = 14.660918342880905, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 416, train_loss = 14.653800726868212, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 417, train_loss = 14.645751972682774, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 418, train_loss = 14.636089933104813, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 419, train_loss = 14.629926147405058, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 420, train_loss = 14.617873392999172, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 421, train_loss = 14.610898975282907, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 422, train_loss = 14.605936954263598, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 423, train_loss = 14.599617736879736, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 424, train_loss = 14.59142334992066, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 425, train_loss = 14.585312353912741, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 426, train_loss = 14.574357853736728, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 427, train_loss = 14.566009553615004, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 428, train_loss = 14.557174844201654, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 429, train_loss = 14.550393482204527, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 430, train_loss = 14.542065820191056, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 431, train_loss = 14.535706461872905, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 432, train_loss = 14.52987722819671, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 433, train_loss = 14.522525849286467, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 434, train_loss = 14.514736098702997, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 435, train_loss = 14.506333829369396, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 436, train_loss = 14.501935742795467, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 437, train_loss = 14.491737876087427, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 438, train_loss = 14.48353755986318, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 439, train_loss = 14.475931806955487, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 440, train_loss = 14.471377568785101, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 441, train_loss = 14.462950490415096, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 442, train_loss = 14.456724098417908, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 443, train_loss = 14.44824248785153, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 444, train_loss = 14.444626338779926, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 445, train_loss = 14.435277885291725, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 446, train_loss = 14.426289342343807, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 447, train_loss = 14.421268084552139, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 448, train_loss = 14.411986152175814, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 449, train_loss = 14.406001932919025, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 450, train_loss = 14.400497747119516, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 451, train_loss = 14.39273705938831, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 452, train_loss = 14.388493556529284, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 453, train_loss = 14.377132584806532, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 454, train_loss = 14.3713019923307, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 455, train_loss = 14.365471290890127, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 456, train_loss = 14.358430533204228, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 457, train_loss = 14.351972935255617, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 458, train_loss = 14.345593269914389, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 459, train_loss = 14.339241733308882, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 460, train_loss = 14.33138977130875, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 461, train_loss = 14.32539608469233, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 462, train_loss = 14.318964796606451, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 463, train_loss = 14.312954901251942, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 464, train_loss = 14.304131595883518, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 465, train_loss = 14.299480224493891, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 466, train_loss = 14.290113950613886, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 467, train_loss = 14.287644090596586, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 468, train_loss = 14.280111821833998, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 469, train_loss = 14.271484275814146, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 470, train_loss = 14.266578676644713, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 471, train_loss = 14.260861923452467, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 472, train_loss = 14.256529673933983, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 473, train_loss = 14.250333033502102, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 474, train_loss = 14.243712992873043, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 475, train_loss = 14.238387511577457, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 476, train_loss = 14.230134131852537, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 477, train_loss = 14.225324548780918, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 478, train_loss = 14.216425271239132, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 479, train_loss = 14.213369311299175, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 480, train_loss = 14.20709370309487, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 481, train_loss = 14.200328465551138, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 482, train_loss = 14.194490191992372, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 483, train_loss = 14.186404645442963, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 484, train_loss = 14.181340493261814, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 485, train_loss = 14.176775604486465, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 486, train_loss = 14.16928538447246, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 487, train_loss = 14.163896857295185, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 488, train_loss = 14.158521970268339, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 489, train_loss = 14.15409435192123, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 490, train_loss = 14.145162960980088, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 491, train_loss = 14.141712851822376, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 492, train_loss = 14.134768477175385, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 493, train_loss = 14.130727043841034, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 494, train_loss = 14.123697720468044, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 495, train_loss = 14.117334876209497, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 496, train_loss = 14.111284008715302, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 497, train_loss = 14.107631313148886, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 498, train_loss = 14.100953586399555, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 499, train_loss = 14.097304596100003, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████▏                                                            | 5/30 [33:14<2:46:08, 398.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "6th- epoch: 0, train_loss = 277.17784881591797, train_acc = 0.38448998602701445\n",
      "test Acc 0.49394785847299816:\n",
      "6th- epoch: 1, train_loss = 220.1851544380188, train_acc = 0.49592454587796925\n",
      "test Acc 0.49906890130353815:\n",
      "6th- epoch: 2, train_loss = 185.94705522060394, train_acc = 0.5027945971122496\n",
      "test Acc 0.5079143389199255:\n",
      "6th- epoch: 3, train_loss = 168.50449633598328, train_acc = 0.5236376339077783\n",
      "test Acc 0.5456238361266295:\n",
      "6th- epoch: 4, train_loss = 155.61861062049866, train_acc = 0.5659059152305542\n",
      "test Acc 0.5935754189944135:\n",
      "6th- epoch: 5, train_loss = 144.29900020360947, train_acc = 0.6046809501630181\n",
      "test Acc 0.62243947858473:\n",
      "6th- epoch: 6, train_loss = 133.63801646232605, train_acc = 0.6321611551001397\n",
      "test Acc 0.6480446927374302:\n",
      "6th- epoch: 7, train_loss = 123.61302047967911, train_acc = 0.6786213320912902\n",
      "test Acc 0.7416201117318436:\n",
      "6th- epoch: 8, train_loss = 114.33587503433228, train_acc = 0.7431299487657196\n",
      "test Acc 0.7672253258845437:\n",
      "6th- epoch: 9, train_loss = 105.83269327878952, train_acc = 0.7817885421518398\n",
      "test Acc 0.7984171322160148:\n",
      "6th- epoch: 10, train_loss = 98.10084456205368, train_acc = 0.8035631113181183\n",
      "test Acc 0.8091247672253259:\n",
      "6th- epoch: 11, train_loss = 91.1408783197403, train_acc = 0.8112482533768048\n",
      "test Acc 0.8179702048417132:\n",
      "6th- epoch: 12, train_loss = 84.90627267956734, train_acc = 0.8245225896599907\n",
      "test Acc 0.8337988826815642:\n",
      "6th- epoch: 13, train_loss = 79.38901776075363, train_acc = 0.837564042850489\n",
      "test Acc 0.8421787709497207:\n",
      "6th- epoch: 14, train_loss = 74.54770231246948, train_acc = 0.8452491849091756\n",
      "test Acc 0.8575418994413407:\n",
      "6th- epoch: 15, train_loss = 70.29701760411263, train_acc = 0.8542151839776432\n",
      "test Acc 0.8640595903165735:\n",
      "6th- epoch: 16, train_loss = 66.55224612355232, train_acc = 0.8627154168607359\n",
      "test Acc 0.8696461824953445:\n",
      "6th- epoch: 17, train_loss = 63.24588856101036, train_acc = 0.8687703772706101\n",
      "test Acc 0.8784916201117319:\n",
      "6th- epoch: 18, train_loss = 60.328654766082764, train_acc = 0.8731951560316721\n",
      "test Acc 0.883147113594041:\n",
      "6th- epoch: 19, train_loss = 57.74653625488281, train_acc = 0.878551467163484\n",
      "test Acc 0.8878026070763501:\n",
      "6th- epoch: 20, train_loss = 55.460362896323204, train_acc = 0.8821611551001397\n",
      "test Acc 0.8901303538175046:\n",
      "6th- epoch: 21, train_loss = 53.43276736140251, train_acc = 0.8843735444806707\n",
      "test Acc 0.8919925512104283:\n",
      "6th- epoch: 22, train_loss = 51.630814388394356, train_acc = 0.8872845831392641\n",
      "test Acc 0.8961824953445066:\n",
      "6th- epoch: 23, train_loss = 50.023000195622444, train_acc = 0.8900791802515138\n",
      "test Acc 0.8966480446927374:\n",
      "6th- epoch: 24, train_loss = 48.5841578990221, train_acc = 0.892640894271076\n",
      "test Acc 0.9008379888268156:\n",
      "6th- epoch: 25, train_loss = 47.29021491110325, train_acc = 0.8975314392175128\n",
      "test Acc 0.9027001862197392:\n",
      "6th- epoch: 26, train_loss = 46.12058529257774, train_acc = 0.8997438285980438\n",
      "test Acc 0.9031657355679702:\n",
      "6th- epoch: 27, train_loss = 45.058691158890724, train_acc = 0.9012575687005123\n",
      "test Acc 0.9054934823091247:\n",
      "6th- epoch: 28, train_loss = 44.08984878659248, train_acc = 0.9041686073591058\n",
      "test Acc 0.9068901303538175:\n",
      "6th- epoch: 29, train_loss = 43.19933247566223, train_acc = 0.905798789007918\n",
      "test Acc 0.9087523277467412:\n",
      "6th- epoch: 30, train_loss = 42.37677189707756, train_acc = 0.9074289706567303\n",
      "test Acc 0.910148975791434:\n",
      "6th- epoch: 31, train_loss = 41.612268909811974, train_acc = 0.9081276199347927\n",
      "test Acc 0.9110800744878957:\n",
      "6th- epoch: 32, train_loss = 40.89814308285713, train_acc = 0.9091755938518864\n",
      "test Acc 0.9110800744878957:\n",
      "6th- epoch: 33, train_loss = 40.22886800765991, train_acc = 0.9103400093153237\n",
      "test Acc 0.9110800744878957:\n",
      "6th- epoch: 34, train_loss = 39.59842091798782, train_acc = 0.9125523986958547\n",
      "test Acc 0.9124767225325885:\n",
      "6th- epoch: 35, train_loss = 39.00355318188667, train_acc = 0.9144154634373545\n",
      "test Acc 0.9138733705772812:\n",
      "6th- epoch: 36, train_loss = 38.440685749053955, train_acc = 0.9167442943642291\n",
      "test Acc 0.914804469273743:\n",
      "6th- epoch: 37, train_loss = 37.90630066394806, train_acc = 0.917675826734979\n",
      "test Acc 0.914804469273743:\n",
      "6th- epoch: 38, train_loss = 37.398415595293045, train_acc = 0.9188402421984164\n",
      "test Acc 0.9157355679702048:\n",
      "6th- epoch: 39, train_loss = 36.91527360677719, train_acc = 0.9201210992081975\n",
      "test Acc 0.9175977653631285:\n",
      "6th- epoch: 40, train_loss = 36.45321597158909, train_acc = 0.9217512808570097\n",
      "test Acc 0.9189944134078212:\n",
      "6th- epoch: 41, train_loss = 36.012951120734215, train_acc = 0.9222170470423847\n",
      "test Acc 0.9194599627560521:\n",
      "6th- epoch: 42, train_loss = 35.591373950242996, train_acc = 0.9237307871448532\n",
      "test Acc 0.9208566108007449:\n",
      "6th- epoch: 43, train_loss = 35.187781900167465, train_acc = 0.9246623195156032\n",
      "test Acc 0.9208566108007449:\n",
      "6th- epoch: 44, train_loss = 34.80117213726044, train_acc = 0.9247787610619469\n",
      "test Acc 0.9213221601489758:\n",
      "6th- epoch: 45, train_loss = 34.429087318480015, train_acc = 0.926059618071728\n",
      "test Acc 0.9231843575418994:\n",
      "6th- epoch: 46, train_loss = 34.070835657417774, train_acc = 0.9271075919888216\n",
      "test Acc 0.9241154562383612:\n",
      "6th- epoch: 47, train_loss = 33.72554770112038, train_acc = 0.927806241266884\n",
      "test Acc 0.9241154562383612:\n",
      "6th- epoch: 48, train_loss = 33.39383265376091, train_acc = 0.9279226828132278\n",
      "test Acc 0.9245810055865922:\n",
      "6th- epoch: 49, train_loss = 33.073711074888706, train_acc = 0.9283884489986027\n",
      "test Acc 0.9245810055865922:\n",
      "6th- epoch: 50, train_loss = 32.76540293544531, train_acc = 0.9286213320912902\n",
      "test Acc 0.9250465549348231:\n",
      "6th- epoch: 51, train_loss = 32.46658855676651, train_acc = 0.9289706567303214\n",
      "test Acc 0.9259776536312849:\n",
      "6th- epoch: 52, train_loss = 32.17674045264721, train_acc = 0.9295528644620401\n",
      "test Acc 0.9264432029795159:\n",
      "6th- epoch: 53, train_loss = 31.897066816687584, train_acc = 0.930018630647415\n",
      "test Acc 0.9264432029795159:\n",
      "6th- epoch: 54, train_loss = 31.625978626310825, train_acc = 0.9299021891010713\n",
      "test Acc 0.9273743016759777:\n",
      "6th- epoch: 55, train_loss = 31.363211579620838, train_acc = 0.9304843968327899\n",
      "test Acc 0.9273743016759777:\n",
      "6th- epoch: 56, train_loss = 31.1079833060503, train_acc = 0.9309501630181649\n",
      "test Acc 0.9273743016759777:\n",
      "6th- epoch: 57, train_loss = 30.860405161976814, train_acc = 0.9311830461108523\n",
      "test Acc 0.9273743016759777:\n",
      "6th- epoch: 58, train_loss = 30.619784079492092, train_acc = 0.9315323707498836\n",
      "test Acc 0.9278398510242085:\n",
      "6th- epoch: 59, train_loss = 30.385613821446896, train_acc = 0.932231020027946\n",
      "test Acc 0.9278398510242085:\n",
      "6th- epoch: 60, train_loss = 30.15735075622797, train_acc = 0.9326967862133209\n",
      "test Acc 0.9278398510242085:\n",
      "6th- epoch: 61, train_loss = 29.935067735612392, train_acc = 0.9326967862133209\n",
      "test Acc 0.9278398510242085:\n",
      "6th- epoch: 62, train_loss = 29.71876549720764, train_acc = 0.9331625523986958\n",
      "test Acc 0.9287709497206704:\n",
      "6th- epoch: 63, train_loss = 29.507300533354282, train_acc = 0.9333954354913834\n",
      "test Acc 0.9287709497206704:\n",
      "6th- epoch: 64, train_loss = 29.300417758524418, train_acc = 0.9337447601304145\n",
      "test Acc 0.9287709497206704:\n",
      "6th- epoch: 65, train_loss = 29.09820793569088, train_acc = 0.9340940847694458\n",
      "test Acc 0.9287709497206704:\n",
      "6th- epoch: 66, train_loss = 28.900888353586197, train_acc = 0.9345598509548206\n",
      "test Acc 0.9287709497206704:\n",
      "6th- epoch: 67, train_loss = 28.707455039024353, train_acc = 0.9349091755938519\n",
      "test Acc 0.9287709497206704:\n",
      "6th- epoch: 68, train_loss = 28.518721714615822, train_acc = 0.9350256171401956\n",
      "test Acc 0.9287709497206704:\n",
      "6th- epoch: 69, train_loss = 28.33360018581152, train_acc = 0.9356078248719143\n",
      "test Acc 0.9292364990689013:\n",
      "6th- epoch: 70, train_loss = 28.15282193571329, train_acc = 0.9360735910572893\n",
      "test Acc 0.9297020484171322:\n",
      "6th- epoch: 71, train_loss = 27.974961914122105, train_acc = 0.9363064741499767\n",
      "test Acc 0.9297020484171322:\n",
      "6th- epoch: 72, train_loss = 27.801150605082512, train_acc = 0.9364229156963204\n",
      "test Acc 0.9297020484171322:\n",
      "6th- epoch: 73, train_loss = 27.631213694810867, train_acc = 0.9368886818816954\n",
      "test Acc 0.9297020484171322:\n",
      "6th- epoch: 74, train_loss = 27.46432114392519, train_acc = 0.9372380065207266\n",
      "test Acc 0.9297020484171322:\n",
      "6th- epoch: 75, train_loss = 27.301155745983124, train_acc = 0.9378202142524453\n",
      "test Acc 0.9297020484171322:\n",
      "6th- epoch: 76, train_loss = 27.141152173280716, train_acc = 0.9381695388914765\n",
      "test Acc 0.9297020484171322:\n",
      "6th- epoch: 77, train_loss = 26.98439084738493, train_acc = 0.9386353050768514\n",
      "test Acc 0.9297020484171322:\n",
      "6th- epoch: 78, train_loss = 26.830497235059738, train_acc = 0.9388681881695389\n",
      "test Acc 0.9301675977653632:\n",
      "6th- epoch: 79, train_loss = 26.6795691549778, train_acc = 0.9394503959012576\n",
      "test Acc 0.9301675977653632:\n",
      "6th- epoch: 80, train_loss = 26.5313223823905, train_acc = 0.9400326036329762\n",
      "test Acc 0.931098696461825:\n",
      "6th- epoch: 81, train_loss = 26.38576139509678, train_acc = 0.9402654867256637\n",
      "test Acc 0.931098696461825:\n",
      "6th- epoch: 82, train_loss = 26.24276341497898, train_acc = 0.9406148113646949\n",
      "test Acc 0.931098696461825:\n",
      "6th- epoch: 83, train_loss = 26.10219980031252, train_acc = 0.9409641360037261\n",
      "test Acc 0.9320297951582868:\n",
      "6th- epoch: 84, train_loss = 25.96477497369051, train_acc = 0.9411970190964136\n",
      "test Acc 0.9320297951582868:\n",
      "6th- epoch: 85, train_loss = 25.829662457108498, train_acc = 0.9411970190964136\n",
      "test Acc 0.9320297951582868:\n",
      "6th- epoch: 86, train_loss = 25.696940004825592, train_acc = 0.9413134606427573\n",
      "test Acc 0.9324953445065177:\n",
      "6th- epoch: 87, train_loss = 25.567400198429823, train_acc = 0.9420121099208197\n",
      "test Acc 0.9329608938547486:\n",
      "6th- epoch: 88, train_loss = 25.439858078956604, train_acc = 0.942361434559851\n",
      "test Acc 0.9329608938547486:\n",
      "6th- epoch: 89, train_loss = 25.315081767737865, train_acc = 0.9431765253842571\n",
      "test Acc 0.9320297951582868:\n",
      "6th- epoch: 90, train_loss = 25.192188646644354, train_acc = 0.9432929669306008\n",
      "test Acc 0.9320297951582868:\n",
      "6th- epoch: 91, train_loss = 25.07169357687235, train_acc = 0.9438751746623195\n",
      "test Acc 0.9324953445065177:\n",
      "6th- epoch: 92, train_loss = 24.953760970383883, train_acc = 0.9443409408476945\n",
      "test Acc 0.9324953445065177:\n",
      "6th- epoch: 93, train_loss = 24.83746885880828, train_acc = 0.9448067070330693\n",
      "test Acc 0.9329608938547486:\n",
      "6th- epoch: 94, train_loss = 24.72272528707981, train_acc = 0.9450395901257569\n",
      "test Acc 0.9334264432029795:\n",
      "6th- epoch: 95, train_loss = 24.610908653587103, train_acc = 0.945388914764788\n",
      "test Acc 0.9343575418994413:\n",
      "6th- epoch: 96, train_loss = 24.500137101858854, train_acc = 0.9455053563111319\n",
      "test Acc 0.9348230912476723:\n",
      "6th- epoch: 97, train_loss = 24.39170479774475, train_acc = 0.9457382394038193\n",
      "test Acc 0.9348230912476723:\n",
      "6th- epoch: 98, train_loss = 24.284194607287645, train_acc = 0.9459711224965067\n",
      "test Acc 0.9352886405959032:\n",
      "6th- epoch: 99, train_loss = 24.178689379245043, train_acc = 0.9462040055891943\n",
      "test Acc 0.9352886405959032:\n",
      "6th- epoch: 100, train_loss = 24.074831530451775, train_acc = 0.946320447135538\n",
      "test Acc 0.9352886405959032:\n",
      "6th- epoch: 101, train_loss = 23.97220680490136, train_acc = 0.9464368886818817\n",
      "test Acc 0.9352886405959032:\n",
      "6th- epoch: 102, train_loss = 23.872934605926275, train_acc = 0.9465533302282254\n",
      "test Acc 0.9352886405959032:\n",
      "6th- epoch: 103, train_loss = 23.77275075018406, train_acc = 0.9469026548672567\n",
      "test Acc 0.9352886405959032:\n",
      "6th- epoch: 104, train_loss = 23.675734251737595, train_acc = 0.9472519795062878\n",
      "test Acc 0.9357541899441341:\n",
      "6th- epoch: 105, train_loss = 23.579776756465435, train_acc = 0.9476013041453191\n",
      "test Acc 0.9352886405959032:\n",
      "6th- epoch: 106, train_loss = 23.485702730715275, train_acc = 0.9478341872380065\n",
      "test Acc 0.9357541899441341:\n",
      "6th- epoch: 107, train_loss = 23.392978724092245, train_acc = 0.948067070330694\n",
      "test Acc 0.936219739292365:\n",
      "6th- epoch: 108, train_loss = 23.301574282348156, train_acc = 0.9484163949697252\n",
      "test Acc 0.936219739292365:\n",
      "6th- epoch: 109, train_loss = 23.212257876992226, train_acc = 0.9484163949697252\n",
      "test Acc 0.9366852886405959:\n",
      "6th- epoch: 110, train_loss = 23.12445567175746, train_acc = 0.9484163949697252\n",
      "test Acc 0.9366852886405959:\n",
      "6th- epoch: 111, train_loss = 23.036213386803865, train_acc = 0.9484163949697252\n",
      "test Acc 0.9366852886405959:\n",
      "6th- epoch: 112, train_loss = 22.950890455394983, train_acc = 0.9486492780624126\n",
      "test Acc 0.9380819366852886:\n",
      "6th- epoch: 113, train_loss = 22.866963271051645, train_acc = 0.9488821611551002\n",
      "test Acc 0.9376163873370578:\n",
      "6th- epoch: 114, train_loss = 22.783150378614664, train_acc = 0.9493479273404751\n",
      "test Acc 0.9385474860335196:\n",
      "6th- epoch: 115, train_loss = 22.700929518789053, train_acc = 0.9495808104331626\n",
      "test Acc 0.9380819366852886:\n",
      "6th- epoch: 116, train_loss = 22.620731234550476, train_acc = 0.9495808104331626\n",
      "test Acc 0.9390130353817505:\n",
      "6th- epoch: 117, train_loss = 22.54093912988901, train_acc = 0.9499301350721937\n",
      "test Acc 0.9394785847299814:\n",
      "6th- epoch: 118, train_loss = 22.46171672642231, train_acc = 0.9500465766185375\n",
      "test Acc 0.9399441340782123:\n",
      "6th- epoch: 119, train_loss = 22.384270824491978, train_acc = 0.950279459711225\n",
      "test Acc 0.9394785847299814:\n",
      "6th- epoch: 120, train_loss = 22.307145468890667, train_acc = 0.9505123428039124\n",
      "test Acc 0.9399441340782123:\n",
      "6th- epoch: 121, train_loss = 22.233500104397535, train_acc = 0.9503959012575687\n",
      "test Acc 0.9404096834264432:\n",
      "6th- epoch: 122, train_loss = 22.15863000229001, train_acc = 0.9506287843502562\n",
      "test Acc 0.9404096834264432:\n",
      "6th- epoch: 123, train_loss = 22.084495309740305, train_acc = 0.9506287843502562\n",
      "test Acc 0.9404096834264432:\n",
      "6th- epoch: 124, train_loss = 22.012257400900126, train_acc = 0.9506287843502562\n",
      "test Acc 0.9404096834264432:\n",
      "6th- epoch: 125, train_loss = 21.940233547240496, train_acc = 0.9507452258965999\n",
      "test Acc 0.9404096834264432:\n",
      "6th- epoch: 126, train_loss = 21.86930764466524, train_acc = 0.9509781089892874\n",
      "test Acc 0.9404096834264432:\n",
      "6th- epoch: 127, train_loss = 21.799344900995493, train_acc = 0.9512109920819748\n",
      "test Acc 0.9404096834264432:\n",
      "6th- epoch: 128, train_loss = 21.730972588062286, train_acc = 0.9513274336283186\n",
      "test Acc 0.9404096834264432:\n",
      "6th- epoch: 129, train_loss = 21.66152684763074, train_acc = 0.9512109920819748\n",
      "test Acc 0.9404096834264432:\n",
      "6th- epoch: 130, train_loss = 21.593863360583782, train_acc = 0.9513274336283186\n",
      "test Acc 0.9408752327746741:\n",
      "6th- epoch: 131, train_loss = 21.527483504265547, train_acc = 0.9512109920819748\n",
      "test Acc 0.9408752327746741:\n",
      "6th- epoch: 132, train_loss = 21.462298456579447, train_acc = 0.9514438751746623\n",
      "test Acc 0.9413407821229051:\n",
      "6th- epoch: 133, train_loss = 21.396874099969864, train_acc = 0.9516767582673498\n",
      "test Acc 0.9413407821229051:\n",
      "6th- epoch: 134, train_loss = 21.332379534840584, train_acc = 0.9516767582673498\n",
      "test Acc 0.9413407821229051:\n",
      "6th- epoch: 135, train_loss = 21.269392289221287, train_acc = 0.9519096413600373\n",
      "test Acc 0.9413407821229051:\n",
      "6th- epoch: 136, train_loss = 21.205971885472536, train_acc = 0.9519096413600373\n",
      "test Acc 0.9413407821229051:\n",
      "6th- epoch: 137, train_loss = 21.143221016973257, train_acc = 0.952026082906381\n",
      "test Acc 0.9413407821229051:\n",
      "6th- epoch: 138, train_loss = 21.082781981676817, train_acc = 0.9521425244527247\n",
      "test Acc 0.9413407821229051:\n",
      "6th- epoch: 139, train_loss = 21.022421061992645, train_acc = 0.9521425244527247\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 140, train_loss = 20.961808539927006, train_acc = 0.9522589659990685\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 141, train_loss = 20.902557883411646, train_acc = 0.9526082906380997\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 142, train_loss = 20.843673061579466, train_acc = 0.9529576152771309\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 143, train_loss = 20.785575348883867, train_acc = 0.9530740568234746\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 144, train_loss = 20.72866264358163, train_acc = 0.9533069399161621\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 145, train_loss = 20.672233019024134, train_acc = 0.9534233814625058\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 146, train_loss = 20.615544751286507, train_acc = 0.9535398230088495\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 147, train_loss = 20.558711800724268, train_acc = 0.9536562645551933\n",
      "test Acc 0.9418063314711359:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 148, train_loss = 20.50361431762576, train_acc = 0.9538891476478808\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 149, train_loss = 20.45055366307497, train_acc = 0.9540055891942245\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 150, train_loss = 20.396430749446154, train_acc = 0.9541220307405682\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 151, train_loss = 20.342847514897585, train_acc = 0.9542384722869119\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 152, train_loss = 20.29087210819125, train_acc = 0.9544713553795995\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 153, train_loss = 20.23754943162203, train_acc = 0.9544713553795995\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 154, train_loss = 20.18651570379734, train_acc = 0.9544713553795995\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 155, train_loss = 20.135010417550802, train_acc = 0.9544713553795995\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 156, train_loss = 20.085269609466195, train_acc = 0.9549371215649743\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 157, train_loss = 20.034741066396236, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 158, train_loss = 19.98567185923457, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 159, train_loss = 19.937357895076275, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 160, train_loss = 19.888347320258617, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 161, train_loss = 19.840712608769536, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 162, train_loss = 19.792688578367233, train_acc = 0.9554028877503493\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 163, train_loss = 19.74549824371934, train_acc = 0.9554028877503493\n",
      "test Acc 0.9427374301675978:\n",
      "6th- epoch: 164, train_loss = 19.698605567216873, train_acc = 0.9554028877503493\n",
      "test Acc 0.9427374301675978:\n",
      "6th- epoch: 165, train_loss = 19.651886386796832, train_acc = 0.9556357708430367\n",
      "test Acc 0.9427374301675978:\n",
      "6th- epoch: 166, train_loss = 19.607245406135917, train_acc = 0.9561015370284117\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 167, train_loss = 19.562067318707705, train_acc = 0.9561015370284117\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 168, train_loss = 19.516564259305596, train_acc = 0.955985095482068\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 169, train_loss = 19.47241298109293, train_acc = 0.9561015370284117\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 170, train_loss = 19.427960770204663, train_acc = 0.9561015370284117\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 171, train_loss = 19.384110528975725, train_acc = 0.9562179785747554\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 172, train_loss = 19.34108359180391, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 173, train_loss = 19.29919067211449, train_acc = 0.9565673032137867\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 174, train_loss = 19.25709448195994, train_acc = 0.9565673032137867\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 175, train_loss = 19.214748091995716, train_acc = 0.9568001863064741\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 176, train_loss = 19.173829723149538, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 177, train_loss = 19.133583892136812, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 178, train_loss = 19.09152969904244, train_acc = 0.9569166278528178\n",
      "test Acc 0.9441340782122905:\n",
      "6th- epoch: 179, train_loss = 19.05100833810866, train_acc = 0.9570330693991617\n",
      "test Acc 0.9441340782122905:\n",
      "6th- epoch: 180, train_loss = 19.01101889461279, train_acc = 0.9570330693991617\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 181, train_loss = 18.972614476457238, train_acc = 0.9570330693991617\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 182, train_loss = 18.932332070544362, train_acc = 0.9570330693991617\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 183, train_loss = 18.891766726970673, train_acc = 0.9571495109455054\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 184, train_loss = 18.853259390220046, train_acc = 0.9572659524918491\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 185, train_loss = 18.81483456492424, train_acc = 0.9572659524918491\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 186, train_loss = 18.77812114916742, train_acc = 0.9573823940381928\n",
      "test Acc 0.9455307262569832:\n",
      "6th- epoch: 187, train_loss = 18.74040249362588, train_acc = 0.9574988355845365\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 188, train_loss = 18.70332915894687, train_acc = 0.9576152771308803\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 189, train_loss = 18.66712604276836, train_acc = 0.9579646017699115\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 190, train_loss = 18.63061829097569, train_acc = 0.9581974848625989\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 191, train_loss = 18.5938309635967, train_acc = 0.9583139264089428\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 192, train_loss = 18.558917807415128, train_acc = 0.9584303679552865\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 193, train_loss = 18.52389614470303, train_acc = 0.9584303679552865\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 194, train_loss = 18.48853313177824, train_acc = 0.9585468095016302\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 195, train_loss = 18.451993921771646, train_acc = 0.9587796925943176\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 196, train_loss = 18.41972029581666, train_acc = 0.9590125756870052\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 197, train_loss = 18.38476449996233, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 198, train_loss = 18.352463522925973, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 199, train_loss = 18.318552929908037, train_acc = 0.9592454587796926\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 200, train_loss = 18.28620251081884, train_acc = 0.9591290172333489\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 201, train_loss = 18.25165688432753, train_acc = 0.9593619003260363\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 202, train_loss = 18.220923462882638, train_acc = 0.9593619003260363\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 203, train_loss = 18.187889870256186, train_acc = 0.9593619003260363\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 204, train_loss = 18.154708532616496, train_acc = 0.95947834187238\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 205, train_loss = 18.124024933204055, train_acc = 0.9595947834187238\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 206, train_loss = 18.092405781149864, train_acc = 0.9597112249650676\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 207, train_loss = 18.062028631567955, train_acc = 0.9597112249650676\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 208, train_loss = 18.031464502215385, train_acc = 0.9597112249650676\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 209, train_loss = 18.0001068264246, train_acc = 0.9598276665114113\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 210, train_loss = 17.96948293223977, train_acc = 0.959944108057755\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 211, train_loss = 17.94059200771153, train_acc = 0.9600605496040987\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 212, train_loss = 17.910212395712733, train_acc = 0.959944108057755\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 213, train_loss = 17.882278760895133, train_acc = 0.959944108057755\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 214, train_loss = 17.85133949480951, train_acc = 0.959944108057755\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 215, train_loss = 17.82214716821909, train_acc = 0.9600605496040987\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 216, train_loss = 17.79374144040048, train_acc = 0.9600605496040987\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 217, train_loss = 17.766212418675423, train_acc = 0.9600605496040987\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 218, train_loss = 17.73720378987491, train_acc = 0.9601769911504425\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 219, train_loss = 17.708407340571284, train_acc = 0.9601769911504425\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 220, train_loss = 17.68235259875655, train_acc = 0.9601769911504425\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 221, train_loss = 17.654158735647798, train_acc = 0.9601769911504425\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 222, train_loss = 17.628879500553012, train_acc = 0.9601769911504425\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 223, train_loss = 17.60146059282124, train_acc = 0.9602934326967862\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 224, train_loss = 17.573184376582503, train_acc = 0.9602934326967862\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 225, train_loss = 17.546245561912656, train_acc = 0.9602934326967862\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 226, train_loss = 17.521084932610393, train_acc = 0.96040987424313\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 227, train_loss = 17.4947244618088, train_acc = 0.96040987424313\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 228, train_loss = 17.467700593173504, train_acc = 0.96040987424313\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 229, train_loss = 17.442996172234416, train_acc = 0.96040987424313\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 230, train_loss = 17.416737504303455, train_acc = 0.96040987424313\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 231, train_loss = 17.39056347683072, train_acc = 0.9606427573358174\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 232, train_loss = 17.365370109677315, train_acc = 0.9606427573358174\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 233, train_loss = 17.342036738991737, train_acc = 0.9607591988821611\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 234, train_loss = 17.315289048478007, train_acc = 0.9607591988821611\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 235, train_loss = 17.289911160245538, train_acc = 0.9609920819748486\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 236, train_loss = 17.264133671298623, train_acc = 0.9609920819748486\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 237, train_loss = 17.241513369604945, train_acc = 0.9609920819748486\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 238, train_loss = 17.21603691391647, train_acc = 0.9609920819748486\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 239, train_loss = 17.193707648664713, train_acc = 0.9609920819748486\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 240, train_loss = 17.168653888627887, train_acc = 0.9611085235211924\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 241, train_loss = 17.145596591755748, train_acc = 0.9612249650675361\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 242, train_loss = 17.124151178635657, train_acc = 0.9612249650675361\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 243, train_loss = 17.09928761702031, train_acc = 0.9612249650675361\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 244, train_loss = 17.076021970249712, train_acc = 0.9612249650675361\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 245, train_loss = 17.053603344596922, train_acc = 0.9614578481602236\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 246, train_loss = 17.032244499772787, train_acc = 0.9614578481602236\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 247, train_loss = 17.00882165785879, train_acc = 0.9614578481602236\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 248, train_loss = 16.987595141865313, train_acc = 0.9615742897065673\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 249, train_loss = 16.9655634900555, train_acc = 0.9615742897065673\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 250, train_loss = 16.942348041571677, train_acc = 0.9618071727992548\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 251, train_loss = 16.92162613477558, train_acc = 0.9619236143455985\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 252, train_loss = 16.899828024208546, train_acc = 0.9619236143455985\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 253, train_loss = 16.878422804176807, train_acc = 0.9620400558919422\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 254, train_loss = 16.855826325714588, train_acc = 0.9620400558919422\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 255, train_loss = 16.83549236599356, train_acc = 0.9620400558919422\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 256, train_loss = 16.814601455815136, train_acc = 0.9622729389846297\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 257, train_loss = 16.794586825184524, train_acc = 0.9622729389846297\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 258, train_loss = 16.774954677559435, train_acc = 0.9625058220773172\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 259, train_loss = 16.751294404268265, train_acc = 0.9625058220773172\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 260, train_loss = 16.732972416095436, train_acc = 0.9625058220773172\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 261, train_loss = 16.712440351955593, train_acc = 0.9626222636236609\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 262, train_loss = 16.691949773579836, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 263, train_loss = 16.67178785894066, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 264, train_loss = 16.65246948506683, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 265, train_loss = 16.631601342000067, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 266, train_loss = 16.612414840608835, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 267, train_loss = 16.594329298473895, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 268, train_loss = 16.574858360923827, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 269, train_loss = 16.55487424042076, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 270, train_loss = 16.53582980763167, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 271, train_loss = 16.516221477650106, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 272, train_loss = 16.49801481515169, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 273, train_loss = 16.47910922486335, train_acc = 0.9629715882626921\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 274, train_loss = 16.460539943538606, train_acc = 0.9629715882626921\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 275, train_loss = 16.443069086410105, train_acc = 0.9630880298090359\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 276, train_loss = 16.424552525393665, train_acc = 0.9630880298090359\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 277, train_loss = 16.40524396393448, train_acc = 0.9632044713553796\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 278, train_loss = 16.38743370771408, train_acc = 0.9632044713553796\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 279, train_loss = 16.36898386757821, train_acc = 0.9632044713553796\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 280, train_loss = 16.35104499477893, train_acc = 0.9632044713553796\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 281, train_loss = 16.33273529727012, train_acc = 0.9632044713553796\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 282, train_loss = 16.316034321673214, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 283, train_loss = 16.297580416314304, train_acc = 0.9634373544480671\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 284, train_loss = 16.28042940888554, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 285, train_loss = 16.262550030834973, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 286, train_loss = 16.246747818775475, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 287, train_loss = 16.229389534331858, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 288, train_loss = 16.212850724346936, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 289, train_loss = 16.197463236749172, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 290, train_loss = 16.1792214512825, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 291, train_loss = 16.162476557306945, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 292, train_loss = 16.1468199333176, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 293, train_loss = 16.128923311829567, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 294, train_loss = 16.112940498627722, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 295, train_loss = 16.097151930443943, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 296, train_loss = 16.08203403931111, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 297, train_loss = 16.065605383366346, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 298, train_loss = 16.050170689821243, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 299, train_loss = 16.034463603049517, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 300, train_loss = 16.018944893963635, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 301, train_loss = 16.002034991048276, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 302, train_loss = 15.988488645292819, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 303, train_loss = 15.971110648475587, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 304, train_loss = 15.956392168998718, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 305, train_loss = 15.940015862695873, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 306, train_loss = 15.926204129122198, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 307, train_loss = 15.910891517996788, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 308, train_loss = 15.898070015013218, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 309, train_loss = 15.881135293282568, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 310, train_loss = 15.867072344757617, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 311, train_loss = 15.852650061249733, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 312, train_loss = 15.838060840032995, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 313, train_loss = 15.822540304623544, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 314, train_loss = 15.808321391232312, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 315, train_loss = 15.795580175705254, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 316, train_loss = 15.779680249281228, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 317, train_loss = 15.766484281979501, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 318, train_loss = 15.751211661845446, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 319, train_loss = 15.737486599944532, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 320, train_loss = 15.72285742405802, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 321, train_loss = 15.710684171877801, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 322, train_loss = 15.6976488372311, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 323, train_loss = 15.684160084463656, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 324, train_loss = 15.66697586979717, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 325, train_loss = 15.655313546769321, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 326, train_loss = 15.64121130015701, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 327, train_loss = 15.627675951458514, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 328, train_loss = 15.614390469156206, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 329, train_loss = 15.600663252174854, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 330, train_loss = 15.588872886262834, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 331, train_loss = 15.57340782508254, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 332, train_loss = 15.56024292577058, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 333, train_loss = 15.548460331745446, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 334, train_loss = 15.534500990994275, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 335, train_loss = 15.521697822958231, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 336, train_loss = 15.508638124912977, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 337, train_loss = 15.49652025103569, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 338, train_loss = 15.484223724342883, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 339, train_loss = 15.471707223914564, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 340, train_loss = 15.460387733764946, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 341, train_loss = 15.44832827616483, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 342, train_loss = 15.434344444423914, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 343, train_loss = 15.422468570061028, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 344, train_loss = 15.410846878774464, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 345, train_loss = 15.398654703982174, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 346, train_loss = 15.387482106685638, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 347, train_loss = 15.37189830467105, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 348, train_loss = 15.361872050911188, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 349, train_loss = 15.351307858712971, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 350, train_loss = 15.338037553243339, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 351, train_loss = 15.327305752784014, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 352, train_loss = 15.315992574207485, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 353, train_loss = 15.302823697216809, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 354, train_loss = 15.291894274763763, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 355, train_loss = 15.282761382870376, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 356, train_loss = 15.269160032272339, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 357, train_loss = 15.259274714626372, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 358, train_loss = 15.247696313075721, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 359, train_loss = 15.23545642849058, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 360, train_loss = 15.2232745885849, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 361, train_loss = 15.211208775639534, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 362, train_loss = 15.199131935834885, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 363, train_loss = 15.189641624689102, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 364, train_loss = 15.178458880633116, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 365, train_loss = 15.16801614034921, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 366, train_loss = 15.15723228175193, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 367, train_loss = 15.1432267120108, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 368, train_loss = 15.13499125186354, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 369, train_loss = 15.1247145133093, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 370, train_loss = 15.112681386061013, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 371, train_loss = 15.103175359778106, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 372, train_loss = 15.093022957444191, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 373, train_loss = 15.082121695391834, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 374, train_loss = 15.069500648416579, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 375, train_loss = 15.061381757259369, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 376, train_loss = 15.051091290079057, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 377, train_loss = 15.039129097014666, train_acc = 0.965649743828598\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 378, train_loss = 15.03049664478749, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 379, train_loss = 15.02114246506244, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 380, train_loss = 15.00902570411563, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 381, train_loss = 15.000272977165878, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 382, train_loss = 14.99022249225527, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 383, train_loss = 14.979149837046862, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 384, train_loss = 14.970339018851519, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 385, train_loss = 14.960775333456695, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 386, train_loss = 14.95174611452967, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 387, train_loss = 14.940303046256304, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 388, train_loss = 14.930675049312413, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 389, train_loss = 14.921264305710793, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 390, train_loss = 14.911967050284147, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 391, train_loss = 14.900642205029726, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 392, train_loss = 14.892090704292059, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 393, train_loss = 14.881916038691998, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 394, train_loss = 14.873257301747799, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 395, train_loss = 14.863278113305569, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 396, train_loss = 14.854016960598528, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 397, train_loss = 14.844244736246765, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 398, train_loss = 14.836058107670397, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 399, train_loss = 14.824959509074688, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 400, train_loss = 14.81593818962574, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 401, train_loss = 14.80835889885202, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 402, train_loss = 14.798736218363047, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 403, train_loss = 14.788019049912691, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 404, train_loss = 14.780954846646637, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 405, train_loss = 14.77141240844503, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 406, train_loss = 14.762644097208977, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 407, train_loss = 14.753350716084242, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 408, train_loss = 14.74551547691226, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 409, train_loss = 14.73550627892837, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 410, train_loss = 14.72752862656489, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 411, train_loss = 14.718736612703651, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 412, train_loss = 14.709902860224247, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 413, train_loss = 14.702715394552797, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 414, train_loss = 14.69096160819754, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 415, train_loss = 14.683690423611552, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 416, train_loss = 14.675120489206165, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 417, train_loss = 14.666350053157657, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "6th- epoch: 418, train_loss = 14.658299788832664, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "6th- epoch: 419, train_loss = 14.651011552661657, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 420, train_loss = 14.640327870845795, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "6th- epoch: 421, train_loss = 14.633491080254316, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "6th- epoch: 422, train_loss = 14.625487613026053, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "6th- epoch: 423, train_loss = 14.615707521792501, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 424, train_loss = 14.61116468673572, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 425, train_loss = 14.602310980204493, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 426, train_loss = 14.593768091406673, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 427, train_loss = 14.585893581155688, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 428, train_loss = 14.578632660210133, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 429, train_loss = 14.567426023539156, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 430, train_loss = 14.560748605523258, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 431, train_loss = 14.552292883396149, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 432, train_loss = 14.545580487698317, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 433, train_loss = 14.535788852721453, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 434, train_loss = 14.528489130083472, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 435, train_loss = 14.520670790225267, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 436, train_loss = 14.514862224459648, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 437, train_loss = 14.50380021193996, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 438, train_loss = 14.49737236648798, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 439, train_loss = 14.490479495376348, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 440, train_loss = 14.48195448005572, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 441, train_loss = 14.475181834306568, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 442, train_loss = 14.468984936829656, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 443, train_loss = 14.460053314920515, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 444, train_loss = 14.451249534729868, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 445, train_loss = 14.445022155996412, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 446, train_loss = 14.437550749629736, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 447, train_loss = 14.429339500609785, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 448, train_loss = 14.423349395394325, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 449, train_loss = 14.413362609688193, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 450, train_loss = 14.407786765601486, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 451, train_loss = 14.399596823845059, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 452, train_loss = 14.392717823386192, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 453, train_loss = 14.383409181144089, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 454, train_loss = 14.376702112611383, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 455, train_loss = 14.368737041950226, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 456, train_loss = 14.362490547355264, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 457, train_loss = 14.354698166251183, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 458, train_loss = 14.347671829164028, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 459, train_loss = 14.340548101812601, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 460, train_loss = 14.33592822169885, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 461, train_loss = 14.326855791267008, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 462, train_loss = 14.323375348001719, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 463, train_loss = 14.312684198375791, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 464, train_loss = 14.304561714176089, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 465, train_loss = 14.299766349140555, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 466, train_loss = 14.29177071666345, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 467, train_loss = 14.284482043236494, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 468, train_loss = 14.278879191726446, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 469, train_loss = 14.274349145591259, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 470, train_loss = 14.266939298715442, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 471, train_loss = 14.260975278913975, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 472, train_loss = 14.252877596765757, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 473, train_loss = 14.246887224260718, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 474, train_loss = 14.240780506283045, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 475, train_loss = 14.235953143332154, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 476, train_loss = 14.228033673018217, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 477, train_loss = 14.222725978586823, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 478, train_loss = 14.213759756181389, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 479, train_loss = 14.209916461259127, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 480, train_loss = 14.203518801834434, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 481, train_loss = 14.194737246725708, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 482, train_loss = 14.191636926028877, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 483, train_loss = 14.182250868529081, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 484, train_loss = 14.175267754588276, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 485, train_loss = 14.169356970582157, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 486, train_loss = 14.16764161735773, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 487, train_loss = 14.157882694154978, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 488, train_loss = 14.150587202515453, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 489, train_loss = 14.147620230913162, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 490, train_loss = 14.140732274856418, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 491, train_loss = 14.135837706271559, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 492, train_loss = 14.128334580454975, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 493, train_loss = 14.12213816260919, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 494, train_loss = 14.11842044070363, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 495, train_loss = 14.10850731516257, train_acc = 0.9684443409408477\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 496, train_loss = 14.104378672782332, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 497, train_loss = 14.097743371967226, train_acc = 0.9684443409408477\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 498, train_loss = 14.089942345861346, train_acc = 0.9684443409408477\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 499, train_loss = 14.08721482520923, train_acc = 0.9684443409408477\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████▌                                                          | 6/30 [39:53<2:39:29, 398.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "7th- epoch: 0, train_loss = 271.8913948535919, train_acc = 0.44201210992081974\n",
      "test Acc 0.49441340782122906:\n",
      "7th- epoch: 1, train_loss = 211.9687738418579, train_acc = 0.4991849091755938\n",
      "test Acc 0.4995344506517691:\n",
      "7th- epoch: 2, train_loss = 179.19372045993805, train_acc = 0.5088495575221239\n",
      "test Acc 0.5246741154562383:\n",
      "7th- epoch: 3, train_loss = 162.9555351138115, train_acc = 0.547508150908244\n",
      "test Acc 0.5824022346368715:\n",
      "7th- epoch: 4, train_loss = 150.47131192684174, train_acc = 0.5996739636702375\n",
      "test Acc 0.61731843575419:\n",
      "7th- epoch: 5, train_loss = 139.2513312101364, train_acc = 0.627619934792734\n",
      "test Acc 0.6419925512104283:\n",
      "7th- epoch: 6, train_loss = 128.7450186610222, train_acc = 0.6406613879832325\n",
      "test Acc 0.6508379888268156:\n",
      "7th- epoch: 7, train_loss = 118.96887016296387, train_acc = 0.6667442943642291\n",
      "test Acc 0.675512104283054:\n",
      "7th- epoch: 8, train_loss = 109.91028743982315, train_acc = 0.7057522123893806\n",
      "test Acc 0.7630353817504656:\n",
      "7th- epoch: 9, train_loss = 101.59801936149597, train_acc = 0.7814392175128085\n",
      "test Acc 0.8012104283054003:\n",
      "7th- epoch: 10, train_loss = 94.07667940855026, train_acc = 0.8108989287377736\n",
      "test Acc 0.8175046554934823:\n",
      "7th- epoch: 11, train_loss = 87.3865410387516, train_acc = 0.8231252911038659\n",
      "test Acc 0.8305400372439479:\n",
      "7th- epoch: 12, train_loss = 81.52807861566544, train_acc = 0.8312761993479273\n",
      "test Acc 0.8384543761638734:\n",
      "7th- epoch: 13, train_loss = 76.38641646504402, train_acc = 0.8400093153237075\n",
      "test Acc 0.8486964618249534:\n",
      "7th- epoch: 14, train_loss = 71.89213573932648, train_acc = 0.8509548206800186\n",
      "test Acc 0.8575418994413407:\n",
      "7th- epoch: 15, train_loss = 67.95038282871246, train_acc = 0.8602701443875175\n",
      "test Acc 0.8640595903165735:\n",
      "7th- epoch: 16, train_loss = 64.46964603662491, train_acc = 0.8671401956217979\n",
      "test Acc 0.8729050279329609:\n",
      "7th- epoch: 17, train_loss = 61.38894194364548, train_acc = 0.8721471821145785\n",
      "test Acc 0.8789571694599627:\n",
      "7th- epoch: 18, train_loss = 58.65570765733719, train_acc = 0.8752911038658593\n",
      "test Acc 0.8817504655493482:\n",
      "7th- epoch: 19, train_loss = 56.23254869878292, train_acc = 0.8806474149976712\n",
      "test Acc 0.8859404096834265:\n",
      "7th- epoch: 20, train_loss = 54.08680482208729, train_acc = 0.8846064275733582\n",
      "test Acc 0.8919925512104283:\n",
      "7th- epoch: 21, train_loss = 52.18130220472813, train_acc = 0.8903120633442012\n",
      "test Acc 0.8943202979515829:\n",
      "7th- epoch: 22, train_loss = 50.48569458723068, train_acc = 0.892175128085701\n",
      "test Acc 0.9003724394785847:\n",
      "7th- epoch: 23, train_loss = 48.971546337008476, train_acc = 0.8981136469492315\n",
      "test Acc 0.9008379888268156:\n",
      "7th- epoch: 24, train_loss = 47.613531827926636, train_acc = 0.8993945039590125\n",
      "test Acc 0.9022346368715084:\n",
      "7th- epoch: 25, train_loss = 46.390713065862656, train_acc = 0.9010246856078249\n",
      "test Acc 0.9027001862197392:\n",
      "7th- epoch: 26, train_loss = 45.28634463250637, train_acc = 0.9025384257102934\n",
      "test Acc 0.9050279329608939:\n",
      "7th- epoch: 27, train_loss = 44.28155644237995, train_acc = 0.9034699580810434\n",
      "test Acc 0.9064245810055865:\n",
      "7th- epoch: 28, train_loss = 43.36314335465431, train_acc = 0.9053330228225431\n",
      "test Acc 0.9064245810055865:\n",
      "7th- epoch: 29, train_loss = 42.51956947147846, train_acc = 0.9063809967396367\n",
      "test Acc 0.9068901303538175:\n",
      "7th- epoch: 30, train_loss = 41.739627316594124, train_acc = 0.9077782952957615\n",
      "test Acc 0.909217877094972:\n",
      "7th- epoch: 31, train_loss = 41.01521521806717, train_acc = 0.9089427107591989\n",
      "test Acc 0.909217877094972:\n",
      "7th- epoch: 32, train_loss = 40.336936354637146, train_acc = 0.9111551001397299\n",
      "test Acc 0.909683426443203:\n",
      "7th- epoch: 33, train_loss = 39.69994083046913, train_acc = 0.9131346064275734\n",
      "test Acc 0.9106145251396648:\n",
      "7th- epoch: 34, train_loss = 39.10030932724476, train_acc = 0.9148812296227294\n",
      "test Acc 0.9124767225325885:\n",
      "7th- epoch: 35, train_loss = 38.53624086081982, train_acc = 0.9166278528178854\n",
      "test Acc 0.9143389199255121:\n",
      "7th- epoch: 36, train_loss = 38.0035063624382, train_acc = 0.9180251513740102\n",
      "test Acc 0.9152700186219739:\n",
      "7th- epoch: 37, train_loss = 37.4994970113039, train_acc = 0.9200046576618538\n",
      "test Acc 0.9162011173184358:\n",
      "7th- epoch: 38, train_loss = 37.02039059996605, train_acc = 0.9209361900326036\n",
      "test Acc 0.9162011173184358:\n",
      "7th- epoch: 39, train_loss = 36.563999325037, train_acc = 0.9218677224033535\n",
      "test Acc 0.9166666666666666:\n",
      "7th- epoch: 40, train_loss = 36.12772952020168, train_acc = 0.9229156963204471\n",
      "test Acc 0.9185288640595903:\n",
      "7th- epoch: 41, train_loss = 35.71066589653492, train_acc = 0.9232650209594784\n",
      "test Acc 0.9194599627560521:\n",
      "7th- epoch: 42, train_loss = 35.311649434268475, train_acc = 0.9238472286911971\n",
      "test Acc 0.9203910614525139:\n",
      "7th- epoch: 43, train_loss = 34.928574711084366, train_acc = 0.9251280857009782\n",
      "test Acc 0.9217877094972067:\n",
      "7th- epoch: 44, train_loss = 34.56062765419483, train_acc = 0.9257102934326968\n",
      "test Acc 0.9231843575418994:\n",
      "7th- epoch: 45, train_loss = 34.20534244179726, train_acc = 0.9262925011644154\n",
      "test Acc 0.9231843575418994:\n",
      "7th- epoch: 46, train_loss = 33.86243926733732, train_acc = 0.9271075919888216\n",
      "test Acc 0.9231843575418994:\n",
      "7th- epoch: 47, train_loss = 33.53171696513891, train_acc = 0.9280391243595715\n",
      "test Acc 0.9236499068901304:\n",
      "7th- epoch: 48, train_loss = 33.212530083954334, train_acc = 0.9283884489986027\n",
      "test Acc 0.9236499068901304:\n",
      "7th- epoch: 49, train_loss = 32.903972864151, train_acc = 0.9287377736376339\n",
      "test Acc 0.9245810055865922:\n",
      "7th- epoch: 50, train_loss = 32.60429662466049, train_acc = 0.9289706567303214\n",
      "test Acc 0.9245810055865922:\n",
      "7th- epoch: 51, train_loss = 32.313629508018494, train_acc = 0.9290870982766651\n",
      "test Acc 0.9250465549348231:\n",
      "7th- epoch: 52, train_loss = 32.03166621923447, train_acc = 0.9294364229156963\n",
      "test Acc 0.9259776536312849:\n",
      "7th- epoch: 53, train_loss = 31.757501006126404, train_acc = 0.9299021891010713\n",
      "test Acc 0.9259776536312849:\n",
      "7th- epoch: 54, train_loss = 31.491495855152607, train_acc = 0.9306008383791337\n",
      "test Acc 0.9259776536312849:\n",
      "7th- epoch: 55, train_loss = 31.23272043466568, train_acc = 0.9307172799254774\n",
      "test Acc 0.9259776536312849:\n",
      "7th- epoch: 56, train_loss = 30.981582760810852, train_acc = 0.9307172799254774\n",
      "test Acc 0.9259776536312849:\n",
      "7th- epoch: 57, train_loss = 30.737389124929905, train_acc = 0.9311830461108523\n",
      "test Acc 0.9259776536312849:\n",
      "7th- epoch: 58, train_loss = 30.499401286244392, train_acc = 0.9316488122962273\n",
      "test Acc 0.9264432029795159:\n",
      "7th- epoch: 59, train_loss = 30.267520643770695, train_acc = 0.9324639031206334\n",
      "test Acc 0.9264432029795159:\n",
      "7th- epoch: 60, train_loss = 30.04089231044054, train_acc = 0.9330461108523521\n",
      "test Acc 0.9264432029795159:\n",
      "7th- epoch: 61, train_loss = 29.819992437958717, train_acc = 0.9335118770377271\n",
      "test Acc 0.9264432029795159:\n",
      "7th- epoch: 62, train_loss = 29.603418044745922, train_acc = 0.9337447601304145\n",
      "test Acc 0.9269087523277467:\n",
      "7th- epoch: 63, train_loss = 29.39181450009346, train_acc = 0.9342105263157895\n",
      "test Acc 0.9273743016759777:\n",
      "7th- epoch: 64, train_loss = 29.18464744091034, train_acc = 0.9343269678621332\n",
      "test Acc 0.9278398510242085:\n",
      "7th- epoch: 65, train_loss = 28.982659488916397, train_acc = 0.9350256171401956\n",
      "test Acc 0.9283054003724395:\n",
      "7th- epoch: 66, train_loss = 28.784834034740925, train_acc = 0.935258500232883\n",
      "test Acc 0.9283054003724395:\n",
      "7th- epoch: 67, train_loss = 28.59163550287485, train_acc = 0.9353749417792269\n",
      "test Acc 0.9287709497206704:\n",
      "7th- epoch: 68, train_loss = 28.4021303281188, train_acc = 0.935724266418258\n",
      "test Acc 0.9292364990689013:\n",
      "7th- epoch: 69, train_loss = 28.216229133307934, train_acc = 0.9360735910572893\n",
      "test Acc 0.9292364990689013:\n",
      "7th- epoch: 70, train_loss = 28.03402678668499, train_acc = 0.9368886818816954\n",
      "test Acc 0.9292364990689013:\n",
      "7th- epoch: 71, train_loss = 27.85567207634449, train_acc = 0.9370051234280391\n",
      "test Acc 0.9287709497206704:\n",
      "7th- epoch: 72, train_loss = 27.680944174528122, train_acc = 0.9371215649743828\n",
      "test Acc 0.9287709497206704:\n",
      "7th- epoch: 73, train_loss = 27.509273268282413, train_acc = 0.9378202142524453\n",
      "test Acc 0.9287709497206704:\n",
      "7th- epoch: 74, train_loss = 27.340901263058186, train_acc = 0.9384024219841639\n",
      "test Acc 0.9287709497206704:\n",
      "7th- epoch: 75, train_loss = 27.175385877490044, train_acc = 0.9387517466231952\n",
      "test Acc 0.9287709497206704:\n",
      "7th- epoch: 76, train_loss = 27.012832544744015, train_acc = 0.9388681881695389\n",
      "test Acc 0.9292364990689013:\n",
      "7th- epoch: 77, train_loss = 26.853684674948454, train_acc = 0.9392175128085701\n",
      "test Acc 0.9292364990689013:\n",
      "7th- epoch: 78, train_loss = 26.69763596355915, train_acc = 0.9393339543549138\n",
      "test Acc 0.9301675977653632:\n",
      "7th- epoch: 79, train_loss = 26.544280629605055, train_acc = 0.9399161620866325\n",
      "test Acc 0.931098696461825:\n",
      "7th- epoch: 80, train_loss = 26.394154507666826, train_acc = 0.94014904517932\n",
      "test Acc 0.9315642458100558:\n",
      "7th- epoch: 81, train_loss = 26.24648854881525, train_acc = 0.9402654867256637\n",
      "test Acc 0.9315642458100558:\n",
      "7th- epoch: 82, train_loss = 26.102374099195004, train_acc = 0.9408476944573824\n",
      "test Acc 0.9320297951582868:\n",
      "7th- epoch: 83, train_loss = 25.961095619946718, train_acc = 0.9413134606427573\n",
      "test Acc 0.9329608938547486:\n",
      "7th- epoch: 84, train_loss = 25.822787504643202, train_acc = 0.9415463437354448\n",
      "test Acc 0.9329608938547486:\n",
      "7th- epoch: 85, train_loss = 25.68671602010727, train_acc = 0.9420121099208197\n",
      "test Acc 0.9329608938547486:\n",
      "7th- epoch: 86, train_loss = 25.55328629910946, train_acc = 0.942361434559851\n",
      "test Acc 0.9329608938547486:\n",
      "7th- epoch: 87, train_loss = 25.422916144132614, train_acc = 0.9431765253842571\n",
      "test Acc 0.9329608938547486:\n",
      "7th- epoch: 88, train_loss = 25.294493317604065, train_acc = 0.9437587331159758\n",
      "test Acc 0.9334264432029795:\n",
      "7th- epoch: 89, train_loss = 25.168663386255503, train_acc = 0.9442244993013508\n",
      "test Acc 0.9343575418994413:\n",
      "7th- epoch: 90, train_loss = 25.046006739139557, train_acc = 0.9445738239403819\n",
      "test Acc 0.9348230912476723:\n",
      "7th- epoch: 91, train_loss = 24.925058230757713, train_acc = 0.9451560316721006\n",
      "test Acc 0.9348230912476723:\n",
      "7th- epoch: 92, train_loss = 24.806646525859833, train_acc = 0.9457382394038193\n",
      "test Acc 0.9352886405959032:\n",
      "7th- epoch: 93, train_loss = 24.689920857548714, train_acc = 0.9460875640428504\n",
      "test Acc 0.9352886405959032:\n",
      "7th- epoch: 94, train_loss = 24.576204296201468, train_acc = 0.9460875640428504\n",
      "test Acc 0.9352886405959032:\n",
      "7th- epoch: 95, train_loss = 24.464787762612104, train_acc = 0.946320447135538\n",
      "test Acc 0.9352886405959032:\n",
      "7th- epoch: 96, train_loss = 24.354770813137293, train_acc = 0.9464368886818817\n",
      "test Acc 0.9357541899441341:\n",
      "7th- epoch: 97, train_loss = 24.247040197253227, train_acc = 0.9464368886818817\n",
      "test Acc 0.9357541899441341:\n",
      "7th- epoch: 98, train_loss = 24.14050655439496, train_acc = 0.9466697717745691\n",
      "test Acc 0.936219739292365:\n",
      "7th- epoch: 99, train_loss = 24.037063363939524, train_acc = 0.9466697717745691\n",
      "test Acc 0.936219739292365:\n",
      "7th- epoch: 100, train_loss = 23.93400541320443, train_acc = 0.9466697717745691\n",
      "test Acc 0.936219739292365:\n",
      "7th- epoch: 101, train_loss = 23.832874823361635, train_acc = 0.9469026548672567\n",
      "test Acc 0.9366852886405959:\n",
      "7th- epoch: 102, train_loss = 23.733978856354952, train_acc = 0.9469026548672567\n",
      "test Acc 0.9366852886405959:\n",
      "7th- epoch: 103, train_loss = 23.636514347046614, train_acc = 0.9470190964136004\n",
      "test Acc 0.9366852886405959:\n",
      "7th- epoch: 104, train_loss = 23.54099316895008, train_acc = 0.9472519795062878\n",
      "test Acc 0.9366852886405959:\n",
      "7th- epoch: 105, train_loss = 23.446794535964727, train_acc = 0.9472519795062878\n",
      "test Acc 0.9366852886405959:\n",
      "7th- epoch: 106, train_loss = 23.35437400639057, train_acc = 0.9473684210526315\n",
      "test Acc 0.9376163873370578:\n",
      "7th- epoch: 107, train_loss = 23.263527125120163, train_acc = 0.9477177456916628\n",
      "test Acc 0.9376163873370578:\n",
      "7th- epoch: 108, train_loss = 23.173954963684082, train_acc = 0.9477177456916628\n",
      "test Acc 0.9380819366852886:\n",
      "7th- epoch: 109, train_loss = 23.085376780480146, train_acc = 0.9479506287843502\n",
      "test Acc 0.9380819366852886:\n",
      "7th- epoch: 110, train_loss = 22.998539049178362, train_acc = 0.9479506287843502\n",
      "test Acc 0.9380819366852886:\n",
      "7th- epoch: 111, train_loss = 22.912949662655592, train_acc = 0.9486492780624126\n",
      "test Acc 0.9380819366852886:\n",
      "7th- epoch: 112, train_loss = 22.828869327902794, train_acc = 0.9488821611551002\n",
      "test Acc 0.9380819366852886:\n",
      "7th- epoch: 113, train_loss = 22.74567501246929, train_acc = 0.9488821611551002\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 114, train_loss = 22.663955464959145, train_acc = 0.9489986027014439\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 115, train_loss = 22.583602093160152, train_acc = 0.9491150442477876\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 116, train_loss = 22.504439759999514, train_acc = 0.9494643688868188\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 117, train_loss = 22.426277551800013, train_acc = 0.9499301350721937\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 118, train_loss = 22.349485028535128, train_acc = 0.9500465766185375\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 119, train_loss = 22.273415382951498, train_acc = 0.9501630181648812\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 120, train_loss = 22.198280069977045, train_acc = 0.9501630181648812\n",
      "test Acc 0.9390130353817505:\n",
      "7th- epoch: 121, train_loss = 22.124334953725338, train_acc = 0.950279459711225\n",
      "test Acc 0.9390130353817505:\n",
      "7th- epoch: 122, train_loss = 22.051473297178745, train_acc = 0.9503959012575687\n",
      "test Acc 0.9394785847299814:\n",
      "7th- epoch: 123, train_loss = 21.97983518615365, train_acc = 0.9503959012575687\n",
      "test Acc 0.9394785847299814:\n",
      "7th- epoch: 124, train_loss = 21.908419847488403, train_acc = 0.9503959012575687\n",
      "test Acc 0.9399441340782123:\n",
      "7th- epoch: 125, train_loss = 21.838575795292854, train_acc = 0.9505123428039124\n",
      "test Acc 0.9404096834264432:\n",
      "7th- epoch: 126, train_loss = 21.77008969336748, train_acc = 0.9505123428039124\n",
      "test Acc 0.9404096834264432:\n",
      "7th- epoch: 127, train_loss = 21.701519533991814, train_acc = 0.9506287843502562\n",
      "test Acc 0.9404096834264432:\n",
      "7th- epoch: 128, train_loss = 21.634049125015736, train_acc = 0.9507452258965999\n",
      "test Acc 0.9404096834264432:\n",
      "7th- epoch: 129, train_loss = 21.56770247593522, train_acc = 0.9509781089892874\n",
      "test Acc 0.9404096834264432:\n",
      "7th- epoch: 130, train_loss = 21.50118400901556, train_acc = 0.9513274336283186\n",
      "test Acc 0.9404096834264432:\n",
      "7th- epoch: 131, train_loss = 21.43594155088067, train_acc = 0.951560316721006\n",
      "test Acc 0.9404096834264432:\n",
      "7th- epoch: 132, train_loss = 21.371691800653934, train_acc = 0.951560316721006\n",
      "test Acc 0.9404096834264432:\n",
      "7th- epoch: 133, train_loss = 21.307856775820255, train_acc = 0.9519096413600373\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 134, train_loss = 21.245308827608824, train_acc = 0.9519096413600373\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 135, train_loss = 21.182819176465273, train_acc = 0.9523754075454122\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 136, train_loss = 21.12070496752858, train_acc = 0.9527247321844434\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 137, train_loss = 21.060356460511684, train_acc = 0.9529576152771309\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 138, train_loss = 20.99952831491828, train_acc = 0.9533069399161621\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 139, train_loss = 20.940727774053812, train_acc = 0.9534233814625058\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 140, train_loss = 20.881921362131834, train_acc = 0.9536562645551933\n",
      "test Acc 0.9413407821229051:\n",
      "7th- epoch: 141, train_loss = 20.823521710932255, train_acc = 0.9536562645551933\n",
      "test Acc 0.9413407821229051:\n",
      "7th- epoch: 142, train_loss = 20.766286686062813, train_acc = 0.9536562645551933\n",
      "test Acc 0.9413407821229051:\n",
      "7th- epoch: 143, train_loss = 20.709214199334383, train_acc = 0.9535398230088495\n",
      "test Acc 0.9413407821229051:\n",
      "7th- epoch: 144, train_loss = 20.653243098407984, train_acc = 0.9535398230088495\n",
      "test Acc 0.9413407821229051:\n",
      "7th- epoch: 145, train_loss = 20.597075425088406, train_acc = 0.9535398230088495\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 146, train_loss = 20.54215443506837, train_acc = 0.9535398230088495\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 147, train_loss = 20.487675692886114, train_acc = 0.9537727061015371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 148, train_loss = 20.434560725465417, train_acc = 0.9537727061015371\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 149, train_loss = 20.381162548437715, train_acc = 0.9541220307405682\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 150, train_loss = 20.32907802052796, train_acc = 0.9541220307405682\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 151, train_loss = 20.277589274570346, train_acc = 0.9541220307405682\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 152, train_loss = 20.22601450420916, train_acc = 0.9543549138332557\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 153, train_loss = 20.17534578219056, train_acc = 0.9547042384722869\n",
      "test Acc 0.9422718808193669:\n",
      "7th- epoch: 154, train_loss = 20.125143943354487, train_acc = 0.9547042384722869\n",
      "test Acc 0.9422718808193669:\n",
      "7th- epoch: 155, train_loss = 20.074849285185337, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 156, train_loss = 20.025239335373044, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 157, train_loss = 19.97658330388367, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 158, train_loss = 19.92767839692533, train_acc = 0.9550535631113182\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 159, train_loss = 19.879984168335795, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 160, train_loss = 19.83199241757393, train_acc = 0.9551700046576619\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 161, train_loss = 19.784876942634583, train_acc = 0.9552864462040056\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 162, train_loss = 19.738620100542903, train_acc = 0.9552864462040056\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 163, train_loss = 19.69281479343772, train_acc = 0.9552864462040056\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 164, train_loss = 19.646795166656375, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "7th- epoch: 165, train_loss = 19.602023785933852, train_acc = 0.9554028877503493\n",
      "test Acc 0.9422718808193669:\n",
      "7th- epoch: 166, train_loss = 19.55626479163766, train_acc = 0.9554028877503493\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 167, train_loss = 19.51178333349526, train_acc = 0.9554028877503493\n",
      "test Acc 0.9427374301675978:\n",
      "7th- epoch: 168, train_loss = 19.467205261811614, train_acc = 0.955519329296693\n",
      "test Acc 0.9427374301675978:\n",
      "7th- epoch: 169, train_loss = 19.42433595843613, train_acc = 0.955519329296693\n",
      "test Acc 0.9432029795158287:\n",
      "7th- epoch: 170, train_loss = 19.38056485541165, train_acc = 0.9556357708430367\n",
      "test Acc 0.9432029795158287:\n",
      "7th- epoch: 171, train_loss = 19.33728945069015, train_acc = 0.9557522123893806\n",
      "test Acc 0.9432029795158287:\n",
      "7th- epoch: 172, train_loss = 19.294845774769783, train_acc = 0.955985095482068\n",
      "test Acc 0.9432029795158287:\n",
      "7th- epoch: 173, train_loss = 19.253734078258276, train_acc = 0.956450861667443\n",
      "test Acc 0.9436685288640596:\n",
      "7th- epoch: 174, train_loss = 19.21168371103704, train_acc = 0.9566837447601304\n",
      "test Acc 0.9436685288640596:\n",
      "7th- epoch: 175, train_loss = 19.170852806419134, train_acc = 0.9571495109455054\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 176, train_loss = 19.130254378542304, train_acc = 0.9570330693991617\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 177, train_loss = 19.089795781299472, train_acc = 0.9571495109455054\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 178, train_loss = 19.048804169520736, train_acc = 0.9572659524918491\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 179, train_loss = 19.009383587166667, train_acc = 0.9573823940381928\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 180, train_loss = 18.969114737585187, train_acc = 0.9574988355845365\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 181, train_loss = 18.929507290944457, train_acc = 0.9578481602235678\n",
      "test Acc 0.9450651769087524:\n",
      "7th- epoch: 182, train_loss = 18.891063230112195, train_acc = 0.9578481602235678\n",
      "test Acc 0.9450651769087524:\n",
      "7th- epoch: 183, train_loss = 18.853069158270955, train_acc = 0.9579646017699115\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 184, train_loss = 18.8136644680053, train_acc = 0.9579646017699115\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 185, train_loss = 18.776731172576547, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 186, train_loss = 18.739552116021514, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 187, train_loss = 18.701950918883085, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 188, train_loss = 18.664836833253503, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 189, train_loss = 18.628847567364573, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 190, train_loss = 18.592247733846307, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 191, train_loss = 18.55680400878191, train_acc = 0.9584303679552865\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 192, train_loss = 18.52089818753302, train_acc = 0.9584303679552865\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 193, train_loss = 18.48694198206067, train_acc = 0.9584303679552865\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 194, train_loss = 18.452699091285467, train_acc = 0.9585468095016302\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 195, train_loss = 18.417631221935153, train_acc = 0.9585468095016302\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 196, train_loss = 18.384204018861055, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 197, train_loss = 18.35011707060039, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 198, train_loss = 18.31650790013373, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 199, train_loss = 18.28342873416841, train_acc = 0.9586632510479739\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 200, train_loss = 18.249856187030673, train_acc = 0.9587796925943176\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 201, train_loss = 18.218098994344473, train_acc = 0.9586632510479739\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 202, train_loss = 18.185366237536073, train_acc = 0.9587796925943176\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 203, train_loss = 18.153280524536967, train_acc = 0.9591290172333489\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 204, train_loss = 18.12080958671868, train_acc = 0.9591290172333489\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 205, train_loss = 18.089679708704352, train_acc = 0.9591290172333489\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 206, train_loss = 18.057387368753552, train_acc = 0.9593619003260363\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 207, train_loss = 18.026931397616863, train_acc = 0.9593619003260363\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 208, train_loss = 17.996147993952036, train_acc = 0.9593619003260363\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 209, train_loss = 17.966122617945075, train_acc = 0.9593619003260363\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 210, train_loss = 17.93519632704556, train_acc = 0.9593619003260363\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 211, train_loss = 17.905203053727746, train_acc = 0.9593619003260363\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 212, train_loss = 17.875173039734364, train_acc = 0.9593619003260363\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 213, train_loss = 17.845678569748998, train_acc = 0.9593619003260363\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 214, train_loss = 17.816646864637733, train_acc = 0.9595947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 215, train_loss = 17.78842682391405, train_acc = 0.9595947834187238\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 216, train_loss = 17.759084559977055, train_acc = 0.9595947834187238\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 217, train_loss = 17.73096865415573, train_acc = 0.9595947834187238\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 218, train_loss = 17.702365508303046, train_acc = 0.9595947834187238\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 219, train_loss = 17.674882961437106, train_acc = 0.9595947834187238\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 220, train_loss = 17.64700816012919, train_acc = 0.9598276665114113\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 221, train_loss = 17.619358256459236, train_acc = 0.9598276665114113\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 222, train_loss = 17.591474561020732, train_acc = 0.9597112249650676\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 223, train_loss = 17.564867563545704, train_acc = 0.9597112249650676\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 224, train_loss = 17.53794215619564, train_acc = 0.9598276665114113\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 225, train_loss = 17.512181429192424, train_acc = 0.9601769911504425\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 226, train_loss = 17.48506917245686, train_acc = 0.9601769911504425\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 227, train_loss = 17.458790281787515, train_acc = 0.9602934326967862\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 228, train_loss = 17.432820696383715, train_acc = 0.96040987424313\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 229, train_loss = 17.407515766099095, train_acc = 0.9605263157894737\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 230, train_loss = 17.380732972174883, train_acc = 0.9605263157894737\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 231, train_loss = 17.355477267876267, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 232, train_loss = 17.3308972325176, train_acc = 0.9607591988821611\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 233, train_loss = 17.30640510842204, train_acc = 0.9608756404285049\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 234, train_loss = 17.281165713444352, train_acc = 0.9608756404285049\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 235, train_loss = 17.25700791925192, train_acc = 0.9608756404285049\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 236, train_loss = 17.23265246115625, train_acc = 0.9608756404285049\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 237, train_loss = 17.207759592682123, train_acc = 0.9609920819748486\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 238, train_loss = 17.18437573965639, train_acc = 0.9611085235211924\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 239, train_loss = 17.160566672682762, train_acc = 0.9611085235211924\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 240, train_loss = 17.1374845886603, train_acc = 0.9612249650675361\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 241, train_loss = 17.11408591363579, train_acc = 0.9612249650675361\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 242, train_loss = 17.09075566008687, train_acc = 0.9615742897065673\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 243, train_loss = 17.067068125121295, train_acc = 0.961690731252911\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 244, train_loss = 17.044607038609684, train_acc = 0.961690731252911\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 245, train_loss = 17.022354297339916, train_acc = 0.9618071727992548\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 246, train_loss = 16.99949308950454, train_acc = 0.9618071727992548\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 247, train_loss = 16.978288638405502, train_acc = 0.9619236143455985\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 248, train_loss = 16.955615407787263, train_acc = 0.962156497438286\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 249, train_loss = 16.933996260166168, train_acc = 0.9622729389846297\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 250, train_loss = 16.912119151093066, train_acc = 0.9622729389846297\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 251, train_loss = 16.890657515265048, train_acc = 0.9622729389846297\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 252, train_loss = 16.869474592618644, train_acc = 0.9622729389846297\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 253, train_loss = 16.848654192872345, train_acc = 0.9622729389846297\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 254, train_loss = 16.828460921533406, train_acc = 0.9622729389846297\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 255, train_loss = 16.806859673000872, train_acc = 0.9622729389846297\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 256, train_loss = 16.785695145837963, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 257, train_loss = 16.76475706975907, train_acc = 0.9625058220773172\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 258, train_loss = 16.744142063893378, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 259, train_loss = 16.722031413577497, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 260, train_loss = 16.70396598894149, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 261, train_loss = 16.684114321134984, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 262, train_loss = 16.66446367185563, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 263, train_loss = 16.642895028926432, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 264, train_loss = 16.6247291630134, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 265, train_loss = 16.604654665105045, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 266, train_loss = 16.58563383948058, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 267, train_loss = 16.566221803426743, train_acc = 0.9628551467163484\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 268, train_loss = 16.547037079930305, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 269, train_loss = 16.527858342044055, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 270, train_loss = 16.50918845552951, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 271, train_loss = 16.490240239538252, train_acc = 0.9632044713553796\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 272, train_loss = 16.471258968114853, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 273, train_loss = 16.453254281543195, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 274, train_loss = 16.435064469464123, train_acc = 0.9634373544480671\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 275, train_loss = 16.416319333016872, train_acc = 0.9634373544480671\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 276, train_loss = 16.39852795843035, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 277, train_loss = 16.38080842513591, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 278, train_loss = 16.36315044760704, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 279, train_loss = 16.346130657941103, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 280, train_loss = 16.32805168721825, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 281, train_loss = 16.31064451020211, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 282, train_loss = 16.29295014962554, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 283, train_loss = 16.27600231859833, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 284, train_loss = 16.258268910460174, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 285, train_loss = 16.24287298321724, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 286, train_loss = 16.22588847205043, train_acc = 0.9640195621797858\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 287, train_loss = 16.208438211120665, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 288, train_loss = 16.190434829331934, train_acc = 0.9641360037261295\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 289, train_loss = 16.174931560643017, train_acc = 0.9641360037261295\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 290, train_loss = 16.158898521214724, train_acc = 0.9641360037261295\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 291, train_loss = 16.141114256344736, train_acc = 0.9641360037261295\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 292, train_loss = 16.12547545786947, train_acc = 0.9642524452724732\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 293, train_loss = 16.109744804911315, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 294, train_loss = 16.095075367949903, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 295, train_loss = 16.07764736842364, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 296, train_loss = 16.06183349248022, train_acc = 0.9644853283651607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 297, train_loss = 16.046894636005163, train_acc = 0.9644853283651607\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 298, train_loss = 16.029894437640905, train_acc = 0.9644853283651607\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 299, train_loss = 16.015070998109877, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 300, train_loss = 15.999884907156229, train_acc = 0.9644853283651607\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 301, train_loss = 15.984096066094935, train_acc = 0.9644853283651607\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 302, train_loss = 15.968377941288054, train_acc = 0.9644853283651607\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 303, train_loss = 15.955188003368676, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 304, train_loss = 15.938509927131236, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 305, train_loss = 15.925583843141794, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 306, train_loss = 15.910107150673866, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 307, train_loss = 15.894911669194698, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 308, train_loss = 15.879018147476017, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 309, train_loss = 15.866650961339474, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 310, train_loss = 15.851966577582061, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 311, train_loss = 15.837155311368406, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 312, train_loss = 15.823261771351099, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 313, train_loss = 15.808857618831098, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 314, train_loss = 15.795337877236307, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 315, train_loss = 15.780597694218159, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 316, train_loss = 15.76671573985368, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 317, train_loss = 15.752373494207859, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 318, train_loss = 15.739324375987053, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 319, train_loss = 15.7265699012205, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 320, train_loss = 15.712856978178024, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 321, train_loss = 15.699005925096571, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 322, train_loss = 15.685960963368416, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 323, train_loss = 15.671653370372951, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 324, train_loss = 15.65845237672329, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 325, train_loss = 15.645472685806453, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 326, train_loss = 15.633437119424343, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 327, train_loss = 15.619028311222792, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 328, train_loss = 15.606601141393185, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 329, train_loss = 15.594309438951313, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 330, train_loss = 15.580808219499886, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 331, train_loss = 15.568307581357658, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 332, train_loss = 15.555063483305275, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 333, train_loss = 15.543021998368204, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 334, train_loss = 15.529589691199362, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 335, train_loss = 15.51677227485925, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 336, train_loss = 15.504806153476238, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 337, train_loss = 15.493334334343672, train_acc = 0.9654168607359106\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 338, train_loss = 15.479737660847604, train_acc = 0.9654168607359106\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 339, train_loss = 15.468637040816247, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 340, train_loss = 15.455511048436165, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 341, train_loss = 15.445065173320472, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 342, train_loss = 15.430163372308016, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 343, train_loss = 15.42013529036194, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 344, train_loss = 15.408898245543242, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 345, train_loss = 15.395270521752536, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 346, train_loss = 15.383742497302592, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 347, train_loss = 15.373212628997862, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 348, train_loss = 15.360298857092857, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 349, train_loss = 15.347446121275425, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 350, train_loss = 15.337840122170746, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 351, train_loss = 15.325788979418576, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 352, train_loss = 15.314871960319579, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 353, train_loss = 15.301811572164297, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 354, train_loss = 15.293353392742574, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 355, train_loss = 15.279356428422034, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 356, train_loss = 15.270218767225742, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 357, train_loss = 15.259259171783924, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 358, train_loss = 15.248598542064428, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 359, train_loss = 15.23697504401207, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 360, train_loss = 15.22665371466428, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 361, train_loss = 15.213727675378323, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 362, train_loss = 15.206051718443632, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 363, train_loss = 15.192511252127588, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 364, train_loss = 15.182742157019675, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 365, train_loss = 15.17248197644949, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 366, train_loss = 15.161762207746506, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 367, train_loss = 15.151256646029651, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 368, train_loss = 15.141740128397942, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 369, train_loss = 15.130755290389061, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 370, train_loss = 15.119996477849782, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 371, train_loss = 15.112829052843153, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 372, train_loss = 15.101805196143687, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 373, train_loss = 15.090413268655539, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 374, train_loss = 15.079635806381702, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 375, train_loss = 15.069377592764795, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 376, train_loss = 15.062754046171904, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 377, train_loss = 15.049675765447319, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 378, train_loss = 15.041176470927894, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 379, train_loss = 15.031435971148312, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 380, train_loss = 15.021410793066025, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 381, train_loss = 15.011316022835672, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 382, train_loss = 15.00195364933461, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 383, train_loss = 14.99040425941348, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 384, train_loss = 14.982368583790958, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 385, train_loss = 14.970930594950914, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 386, train_loss = 14.962787743657827, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 387, train_loss = 14.952775792218745, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 388, train_loss = 14.944535217247903, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 389, train_loss = 14.934500306844711, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 390, train_loss = 14.92447858210653, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 391, train_loss = 14.917899358086288, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 392, train_loss = 14.90914731938392, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 393, train_loss = 14.89903362095356, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 394, train_loss = 14.889817069284618, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 395, train_loss = 14.881341020576656, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 396, train_loss = 14.871931981295347, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 397, train_loss = 14.863018084317446, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 398, train_loss = 14.853393790312111, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 399, train_loss = 14.844180670566857, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 400, train_loss = 14.834486602805555, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 401, train_loss = 14.826120355166495, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 402, train_loss = 14.818703778088093, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 403, train_loss = 14.809441513381898, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 404, train_loss = 14.799466078169644, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 405, train_loss = 14.79247451480478, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 406, train_loss = 14.7836245149374, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 407, train_loss = 14.775392555631697, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 408, train_loss = 14.767754253931344, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 409, train_loss = 14.758668090216815, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 410, train_loss = 14.749905196018517, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 411, train_loss = 14.741309496574104, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 412, train_loss = 14.734014511108398, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 413, train_loss = 14.725503132678568, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 414, train_loss = 14.71603012830019, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 415, train_loss = 14.709897029213607, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 416, train_loss = 14.700939062982798, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 417, train_loss = 14.692415539175272, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 418, train_loss = 14.686215019784868, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 419, train_loss = 14.675428022630513, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 420, train_loss = 14.670421137474477, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 421, train_loss = 14.660143689252436, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 422, train_loss = 14.653421685099602, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 423, train_loss = 14.646628133021295, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 424, train_loss = 14.636929020285606, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 425, train_loss = 14.630036019720137, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 426, train_loss = 14.621528666466475, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 427, train_loss = 14.615091610699892, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 428, train_loss = 14.607896690256894, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 429, train_loss = 14.59895555023104, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 430, train_loss = 14.592306070961058, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 431, train_loss = 14.582081321626902, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 432, train_loss = 14.577739834785461, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 433, train_loss = 14.56998807284981, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 434, train_loss = 14.558078653179109, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 435, train_loss = 14.5539382211864, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 436, train_loss = 14.546260438859463, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 437, train_loss = 14.53845192026347, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 438, train_loss = 14.530826069414616, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 439, train_loss = 14.524579742457718, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 440, train_loss = 14.518094271421432, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 441, train_loss = 14.511403732001781, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 442, train_loss = 14.504399965051562, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 443, train_loss = 14.494219599757344, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 444, train_loss = 14.487083790358156, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 445, train_loss = 14.480480263475329, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 446, train_loss = 14.474241515155882, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 447, train_loss = 14.467055073473603, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 448, train_loss = 14.458874457981437, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 449, train_loss = 14.453694183379412, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 450, train_loss = 14.445668570697308, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 451, train_loss = 14.439767856150866, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 452, train_loss = 14.434272281825542, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 453, train_loss = 14.423974046949297, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 454, train_loss = 14.419569405261427, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 455, train_loss = 14.41593649983406, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 456, train_loss = 14.40529319876805, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 457, train_loss = 14.398158399853855, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 458, train_loss = 14.393861352000386, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 459, train_loss = 14.386074371635914, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 460, train_loss = 14.378805108368397, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 461, train_loss = 14.37293802946806, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 462, train_loss = 14.365603379905224, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 463, train_loss = 14.361673726234585, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 464, train_loss = 14.353423775639385, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 465, train_loss = 14.346502921078354, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 466, train_loss = 14.340289200190455, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 467, train_loss = 14.33528230106458, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 468, train_loss = 14.326468223240227, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 469, train_loss = 14.321616865694523, train_acc = 0.9684443409408477\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 470, train_loss = 14.316379415336996, train_acc = 0.9684443409408477\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 471, train_loss = 14.310340204741806, train_acc = 0.9684443409408477\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 472, train_loss = 14.301324438303709, train_acc = 0.9684443409408477\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 473, train_loss = 14.297352375928313, train_acc = 0.9685607824871915\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 474, train_loss = 14.29065167158842, train_acc = 0.9685607824871915\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 475, train_loss = 14.285686405841261, train_acc = 0.9686772240335352\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 476, train_loss = 14.27689248463139, train_acc = 0.9686772240335352\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 477, train_loss = 14.271762121468782, train_acc = 0.9686772240335352\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 478, train_loss = 14.26459609111771, train_acc = 0.9686772240335352\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 479, train_loss = 14.260572008788586, train_acc = 0.9686772240335352\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 480, train_loss = 14.2549366527237, train_acc = 0.9686772240335352\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 481, train_loss = 14.248673306312412, train_acc = 0.9686772240335352\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 482, train_loss = 14.242189798504114, train_acc = 0.9686772240335352\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 483, train_loss = 14.23623060574755, train_acc = 0.9686772240335352\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 484, train_loss = 14.231464425567538, train_acc = 0.9686772240335352\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 485, train_loss = 14.224572891835123, train_acc = 0.9687936655798789\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 486, train_loss = 14.21782119339332, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 487, train_loss = 14.214552387595177, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 488, train_loss = 14.207450525369495, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 489, train_loss = 14.204109476413578, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 490, train_loss = 14.193661192897707, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 491, train_loss = 14.189910081680864, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 492, train_loss = 14.185355998575687, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 493, train_loss = 14.178859380539507, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 494, train_loss = 14.175981646869332, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 495, train_loss = 14.165928275790066, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 496, train_loss = 14.164250335190445, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 497, train_loss = 14.155738566070795, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 498, train_loss = 14.15241602808237, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n",
      "7th- epoch: 499, train_loss = 14.145109947770834, train_acc = 0.9687936655798789\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████████████                                                        | 7/30 [46:32<2:32:52, 398.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "8th- epoch: 0, train_loss = 270.7080445289612, train_acc = 0.4642524452724732\n",
      "test Acc 0.49534450651769085:\n",
      "8th- epoch: 1, train_loss = 212.58421969413757, train_acc = 0.4995342338146251\n",
      "test Acc 0.4995344506517691:\n",
      "8th- epoch: 2, train_loss = 180.38537406921387, train_acc = 0.5040754541220307\n",
      "test Acc 0.5088454376163873:\n",
      "8th- epoch: 3, train_loss = 163.1363070011139, train_acc = 0.534350256171402\n",
      "test Acc 0.5661080074487895:\n",
      "8th- epoch: 4, train_loss = 150.2402604818344, train_acc = 0.5887284583139264\n",
      "test Acc 0.6094040968342644:\n",
      "8th- epoch: 5, train_loss = 138.8298562169075, train_acc = 0.6190032603632977\n",
      "test Acc 0.6322160148975792:\n",
      "8th- epoch: 6, train_loss = 128.32935893535614, train_acc = 0.6390312063344201\n",
      "test Acc 0.648975791433892:\n",
      "8th- epoch: 7, train_loss = 118.65627962350845, train_acc = 0.6811830461108523\n",
      "test Acc 0.755586592178771:\n",
      "8th- epoch: 8, train_loss = 109.75516349077225, train_acc = 0.7649045179319981\n",
      "test Acc 0.7760707635009311:\n",
      "8th- epoch: 9, train_loss = 101.6150364279747, train_acc = 0.7812063344201211\n",
      "test Acc 0.7900372439478585:\n",
      "8th- epoch: 10, train_loss = 94.25513815879822, train_acc = 0.8053097345132744\n",
      "test Acc 0.8175046554934823:\n",
      "8th- epoch: 11, train_loss = 87.67499938607216, train_acc = 0.8206800186306474\n",
      "test Acc 0.8240223463687151:\n",
      "8th- epoch: 12, train_loss = 81.84892955422401, train_acc = 0.8287144853283651\n",
      "test Acc 0.8393854748603352:\n",
      "8th- epoch: 13, train_loss = 76.74111345410347, train_acc = 0.8401257568700512\n",
      "test Acc 0.8477653631284916:\n",
      "8th- epoch: 14, train_loss = 72.2774230837822, train_acc = 0.8488588728458314\n",
      "test Acc 0.8547486033519553:\n",
      "8th- epoch: 15, train_loss = 68.36818248033524, train_acc = 0.8564275733581742\n",
      "test Acc 0.8608007448789572:\n",
      "8th- epoch: 16, train_loss = 64.92366781830788, train_acc = 0.8636469492314858\n",
      "test Acc 0.86731843575419:\n",
      "8th- epoch: 17, train_loss = 61.87100675702095, train_acc = 0.8678388448998603\n",
      "test Acc 0.87243947858473:\n",
      "8th- epoch: 18, train_loss = 59.1504080593586, train_acc = 0.8712156497438286\n",
      "test Acc 0.8770949720670391:\n",
      "8th- epoch: 19, train_loss = 56.71962931752205, train_acc = 0.8755239869585468\n",
      "test Acc 0.8836126629422719:\n",
      "8th- epoch: 20, train_loss = 54.53987881541252, train_acc = 0.8794829995342338\n",
      "test Acc 0.8868715083798883:\n",
      "8th- epoch: 21, train_loss = 52.58458103239536, train_acc = 0.8855379599441081\n",
      "test Acc 0.8929236499068901:\n",
      "8th- epoch: 22, train_loss = 50.828015178442, train_acc = 0.8910107126222636\n",
      "test Acc 0.8985102420856611:\n",
      "8th- epoch: 23, train_loss = 49.246883541345596, train_acc = 0.8974149976711691\n",
      "test Acc 0.8994413407821229:\n",
      "8th- epoch: 24, train_loss = 47.81850554049015, train_acc = 0.9003260363297625\n",
      "test Acc 0.9013035381750466:\n",
      "8th- epoch: 25, train_loss = 46.525512516498566, train_acc = 0.901839776432231\n",
      "test Acc 0.904096834264432:\n",
      "8th- epoch: 26, train_loss = 45.351878583431244, train_acc = 0.9031206334420121\n",
      "test Acc 0.9059590316573557:\n",
      "8th- epoch: 27, train_loss = 44.28398843109608, train_acc = 0.9060316721006055\n",
      "test Acc 0.9064245810055865:\n",
      "8th- epoch: 28, train_loss = 43.3087202757597, train_acc = 0.9074289706567303\n",
      "test Acc 0.9068901303538175:\n",
      "8th- epoch: 29, train_loss = 42.41419434547424, train_acc = 0.9094084769445738\n",
      "test Acc 0.9068901303538175:\n",
      "8th- epoch: 30, train_loss = 41.589921072125435, train_acc = 0.9103400093153237\n",
      "test Acc 0.9087523277467412:\n",
      "8th- epoch: 31, train_loss = 40.82721698284149, train_acc = 0.912435957149511\n",
      "test Acc 0.909217877094972:\n",
      "8th- epoch: 32, train_loss = 40.11877819895744, train_acc = 0.9136003726129484\n",
      "test Acc 0.9106145251396648:\n",
      "8th- epoch: 33, train_loss = 39.45898498594761, train_acc = 0.9149976711690732\n",
      "test Acc 0.9106145251396648:\n",
      "8th- epoch: 34, train_loss = 38.841505631804466, train_acc = 0.9170936190032604\n",
      "test Acc 0.9120111731843575:\n",
      "8th- epoch: 35, train_loss = 38.26232363283634, train_acc = 0.9182580344666977\n",
      "test Acc 0.9134078212290503:\n",
      "8th- epoch: 36, train_loss = 37.71673661470413, train_acc = 0.9191895668374476\n",
      "test Acc 0.9138733705772812:\n",
      "8th- epoch: 37, train_loss = 37.20059661567211, train_acc = 0.9201210992081975\n",
      "test Acc 0.914804469273743:\n",
      "8th- epoch: 38, train_loss = 36.71146176755428, train_acc = 0.9214019562179786\n",
      "test Acc 0.9166666666666666:\n",
      "8th- epoch: 39, train_loss = 36.24616412818432, train_acc = 0.9230321378667908\n",
      "test Acc 0.9171322160148976:\n",
      "8th- epoch: 40, train_loss = 35.80221779644489, train_acc = 0.9239636702375408\n",
      "test Acc 0.9175977653631285:\n",
      "8th- epoch: 41, train_loss = 35.37811414897442, train_acc = 0.9244294364229158\n",
      "test Acc 0.9185288640595903:\n",
      "8th- epoch: 42, train_loss = 34.97328479588032, train_acc = 0.9251280857009782\n",
      "test Acc 0.9194599627560521:\n",
      "8th- epoch: 43, train_loss = 34.58499036729336, train_acc = 0.9254774103400093\n",
      "test Acc 0.9213221601489758:\n",
      "8th- epoch: 44, train_loss = 34.213556192815304, train_acc = 0.9266418258034467\n",
      "test Acc 0.9213221601489758:\n",
      "8th- epoch: 45, train_loss = 33.85721778124571, train_acc = 0.9273404750815091\n",
      "test Acc 0.9227188081936686:\n",
      "8th- epoch: 46, train_loss = 33.51401910930872, train_acc = 0.9279226828132278\n",
      "test Acc 0.9241154562383612:\n",
      "8th- epoch: 47, train_loss = 33.18355467915535, train_acc = 0.9285048905449464\n",
      "test Acc 0.9245810055865922:\n",
      "8th- epoch: 48, train_loss = 32.86571545153856, train_acc = 0.9293199813693526\n",
      "test Acc 0.9250465549348231:\n",
      "8th- epoch: 49, train_loss = 32.55924388766289, train_acc = 0.9299021891010713\n",
      "test Acc 0.925512104283054:\n",
      "8th- epoch: 50, train_loss = 32.26326770335436, train_acc = 0.9301350721937587\n",
      "test Acc 0.925512104283054:\n",
      "8th- epoch: 51, train_loss = 31.976886324584484, train_acc = 0.9303679552864462\n",
      "test Acc 0.925512104283054:\n",
      "8th- epoch: 52, train_loss = 31.699726842343807, train_acc = 0.9308337214718212\n",
      "test Acc 0.925512104283054:\n",
      "8th- epoch: 53, train_loss = 31.43010911345482, train_acc = 0.9314159292035398\n",
      "test Acc 0.9259776536312849:\n",
      "8th- epoch: 54, train_loss = 31.16878490895033, train_acc = 0.9318816953889147\n",
      "test Acc 0.9259776536312849:\n",
      "8th- epoch: 55, train_loss = 30.91514766216278, train_acc = 0.9324639031206334\n",
      "test Acc 0.9264432029795159:\n",
      "8th- epoch: 56, train_loss = 30.66952123492956, train_acc = 0.9326967862133209\n",
      "test Acc 0.9269087523277467:\n",
      "8th- epoch: 57, train_loss = 30.430396735668182, train_acc = 0.9331625523986958\n",
      "test Acc 0.9269087523277467:\n",
      "8th- epoch: 58, train_loss = 30.19731444865465, train_acc = 0.9335118770377271\n",
      "test Acc 0.9269087523277467:\n",
      "8th- epoch: 59, train_loss = 29.970544405281544, train_acc = 0.933977643223102\n",
      "test Acc 0.9269087523277467:\n",
      "8th- epoch: 60, train_loss = 29.748540610074997, train_acc = 0.9344434094084769\n",
      "test Acc 0.9273743016759777:\n",
      "8th- epoch: 61, train_loss = 29.53187482059002, train_acc = 0.9346762925011645\n",
      "test Acc 0.9273743016759777:\n",
      "8th- epoch: 62, train_loss = 29.31949406862259, train_acc = 0.9349091755938519\n",
      "test Acc 0.9273743016759777:\n",
      "8th- epoch: 63, train_loss = 29.11160434037447, train_acc = 0.9354913833255706\n",
      "test Acc 0.9273743016759777:\n",
      "8th- epoch: 64, train_loss = 28.90855396538973, train_acc = 0.9356078248719143\n",
      "test Acc 0.9278398510242085:\n",
      "8th- epoch: 65, train_loss = 28.71006029099226, train_acc = 0.9358407079646017\n",
      "test Acc 0.9292364990689013:\n",
      "8th- epoch: 66, train_loss = 28.515462443232536, train_acc = 0.9358407079646017\n",
      "test Acc 0.9297020484171322:\n",
      "8th- epoch: 67, train_loss = 28.325082011520863, train_acc = 0.936190032603633\n",
      "test Acc 0.9301675977653632:\n",
      "8th- epoch: 68, train_loss = 28.13895419239998, train_acc = 0.9367722403353517\n",
      "test Acc 0.9301675977653632:\n",
      "8th- epoch: 69, train_loss = 27.95669411867857, train_acc = 0.9370051234280391\n",
      "test Acc 0.9301675977653632:\n",
      "8th- epoch: 70, train_loss = 27.778186298906803, train_acc = 0.9372380065207266\n",
      "test Acc 0.9301675977653632:\n",
      "8th- epoch: 71, train_loss = 27.60343062132597, train_acc = 0.9377037727061015\n",
      "test Acc 0.9297020484171322:\n",
      "8th- epoch: 72, train_loss = 27.43067755550146, train_acc = 0.9381695388914765\n",
      "test Acc 0.9297020484171322:\n",
      "8th- epoch: 73, train_loss = 27.261727958917618, train_acc = 0.9382859804378202\n",
      "test Acc 0.9301675977653632:\n",
      "8th- epoch: 74, train_loss = 27.094504967331886, train_acc = 0.9389846297158826\n",
      "test Acc 0.9301675977653632:\n",
      "8th- epoch: 75, train_loss = 26.931570164859295, train_acc = 0.9394503959012576\n",
      "test Acc 0.9301675977653632:\n",
      "8th- epoch: 76, train_loss = 26.770881965756416, train_acc = 0.939683278993945\n",
      "test Acc 0.930633147113594:\n",
      "8th- epoch: 77, train_loss = 26.61456485837698, train_acc = 0.9402654867256637\n",
      "test Acc 0.931098696461825:\n",
      "8th- epoch: 78, train_loss = 26.45945478975773, train_acc = 0.9406148113646949\n",
      "test Acc 0.9315642458100558:\n",
      "8th- epoch: 79, train_loss = 26.308585945516825, train_acc = 0.9408476944573824\n",
      "test Acc 0.9320297951582868:\n",
      "8th- epoch: 80, train_loss = 26.15937402099371, train_acc = 0.9411970190964136\n",
      "test Acc 0.9320297951582868:\n",
      "8th- epoch: 81, train_loss = 26.014015324413776, train_acc = 0.941429902189101\n",
      "test Acc 0.9320297951582868:\n",
      "8th- epoch: 82, train_loss = 25.871875267475843, train_acc = 0.9416627852817886\n",
      "test Acc 0.9320297951582868:\n",
      "8th- epoch: 83, train_loss = 25.731540888547897, train_acc = 0.9417792268281323\n",
      "test Acc 0.9324953445065177:\n",
      "8th- epoch: 84, train_loss = 25.594015184789896, train_acc = 0.942361434559851\n",
      "test Acc 0.9329608938547486:\n",
      "8th- epoch: 85, train_loss = 25.459096506237984, train_acc = 0.9427107591988821\n",
      "test Acc 0.9329608938547486:\n",
      "8th- epoch: 86, train_loss = 25.32661932334304, train_acc = 0.9425943176525384\n",
      "test Acc 0.9329608938547486:\n",
      "8th- epoch: 87, train_loss = 25.197289619594812, train_acc = 0.9429436422915697\n",
      "test Acc 0.9334264432029795:\n",
      "8th- epoch: 88, train_loss = 25.070239514112473, train_acc = 0.9431765253842571\n",
      "test Acc 0.9334264432029795:\n",
      "8th- epoch: 89, train_loss = 24.945085756480694, train_acc = 0.9431765253842571\n",
      "test Acc 0.9334264432029795:\n",
      "8th- epoch: 90, train_loss = 24.822132863104343, train_acc = 0.9431765253842571\n",
      "test Acc 0.9334264432029795:\n",
      "8th- epoch: 91, train_loss = 24.702170755714178, train_acc = 0.9432929669306008\n",
      "test Acc 0.9334264432029795:\n",
      "8th- epoch: 92, train_loss = 24.584110729396343, train_acc = 0.9437587331159758\n",
      "test Acc 0.9334264432029795:\n",
      "8th- epoch: 93, train_loss = 24.46852082759142, train_acc = 0.944108057755007\n",
      "test Acc 0.9334264432029795:\n",
      "8th- epoch: 94, train_loss = 24.355468351393938, train_acc = 0.9443409408476945\n",
      "test Acc 0.9334264432029795:\n",
      "8th- epoch: 95, train_loss = 24.244153298437595, train_acc = 0.9449231485794132\n",
      "test Acc 0.9338919925512105:\n",
      "8th- epoch: 96, train_loss = 24.134521458297968, train_acc = 0.9451560316721006\n",
      "test Acc 0.9343575418994413:\n",
      "8th- epoch: 97, train_loss = 24.0274715423584, train_acc = 0.945388914764788\n",
      "test Acc 0.9343575418994413:\n",
      "8th- epoch: 98, train_loss = 23.92203640937805, train_acc = 0.9457382394038193\n",
      "test Acc 0.9348230912476723:\n",
      "8th- epoch: 99, train_loss = 23.81813232973218, train_acc = 0.9459711224965067\n",
      "test Acc 0.9348230912476723:\n",
      "8th- epoch: 100, train_loss = 23.716698564589024, train_acc = 0.945854680950163\n",
      "test Acc 0.9352886405959032:\n",
      "8th- epoch: 101, train_loss = 23.615854859352112, train_acc = 0.9459711224965067\n",
      "test Acc 0.9352886405959032:\n",
      "8th- epoch: 102, train_loss = 23.518568322062492, train_acc = 0.9462040055891943\n",
      "test Acc 0.9352886405959032:\n",
      "8th- epoch: 103, train_loss = 23.419874608516693, train_acc = 0.9462040055891943\n",
      "test Acc 0.9352886405959032:\n",
      "8th- epoch: 104, train_loss = 23.32590765878558, train_acc = 0.9464368886818817\n",
      "test Acc 0.9352886405959032:\n",
      "8th- epoch: 105, train_loss = 23.231995671987534, train_acc = 0.9470190964136004\n",
      "test Acc 0.936219739292365:\n",
      "8th- epoch: 106, train_loss = 23.138710986822844, train_acc = 0.9473684210526315\n",
      "test Acc 0.936219739292365:\n",
      "8th- epoch: 107, train_loss = 23.0485725030303, train_acc = 0.9474848625989754\n",
      "test Acc 0.936219739292365:\n",
      "8th- epoch: 108, train_loss = 22.96022503823042, train_acc = 0.9478341872380065\n",
      "test Acc 0.9366852886405959:\n",
      "8th- epoch: 109, train_loss = 22.8714815415442, train_acc = 0.9478341872380065\n",
      "test Acc 0.9366852886405959:\n",
      "8th- epoch: 110, train_loss = 22.785690508782864, train_acc = 0.9479506287843502\n",
      "test Acc 0.9371508379888268:\n",
      "8th- epoch: 111, train_loss = 22.700742062181234, train_acc = 0.9482999534233815\n",
      "test Acc 0.9380819366852886:\n",
      "8th- epoch: 112, train_loss = 22.616811979562044, train_acc = 0.9486492780624126\n",
      "test Acc 0.9380819366852886:\n",
      "8th- epoch: 113, train_loss = 22.534448459744453, train_acc = 0.9492314857941313\n",
      "test Acc 0.9390130353817505:\n",
      "8th- epoch: 114, train_loss = 22.45314598828554, train_acc = 0.9492314857941313\n",
      "test Acc 0.9390130353817505:\n",
      "8th- epoch: 115, train_loss = 22.37316257879138, train_acc = 0.9492314857941313\n",
      "test Acc 0.9390130353817505:\n",
      "8th- epoch: 116, train_loss = 22.295640040189028, train_acc = 0.9494643688868188\n",
      "test Acc 0.9390130353817505:\n",
      "8th- epoch: 117, train_loss = 22.217885192483664, train_acc = 0.9496972519795063\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 118, train_loss = 22.142922267317772, train_acc = 0.9496972519795063\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 119, train_loss = 22.065635349601507, train_acc = 0.94981369352585\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 120, train_loss = 21.993268352001905, train_acc = 0.9499301350721937\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 121, train_loss = 21.919931903481483, train_acc = 0.9500465766185375\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 122, train_loss = 21.849154956638813, train_acc = 0.9501630181648812\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 123, train_loss = 21.777511723339558, train_acc = 0.9505123428039124\n",
      "test Acc 0.9399441340782123:\n",
      "8th- epoch: 124, train_loss = 21.70696058496833, train_acc = 0.9506287843502562\n",
      "test Acc 0.9399441340782123:\n",
      "8th- epoch: 125, train_loss = 21.637989599257708, train_acc = 0.9508616674429436\n",
      "test Acc 0.9399441340782123:\n",
      "8th- epoch: 126, train_loss = 21.57044519856572, train_acc = 0.9510945505356311\n",
      "test Acc 0.9399441340782123:\n",
      "8th- epoch: 127, train_loss = 21.502577867358923, train_acc = 0.9512109920819748\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 128, train_loss = 21.436475940048695, train_acc = 0.9513274336283186\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 129, train_loss = 21.370901130139828, train_acc = 0.9514438751746623\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 130, train_loss = 21.306510914117098, train_acc = 0.9514438751746623\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 131, train_loss = 21.24272021651268, train_acc = 0.9514438751746623\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 132, train_loss = 21.17893286049366, train_acc = 0.951560316721006\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 133, train_loss = 21.116342205554247, train_acc = 0.9514438751746623\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 134, train_loss = 21.05497469007969, train_acc = 0.951560316721006\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 135, train_loss = 20.994012519717216, train_acc = 0.9517931998136935\n",
      "test Acc 0.9413407821229051:\n",
      "8th- epoch: 136, train_loss = 20.93427486717701, train_acc = 0.9522589659990685\n",
      "test Acc 0.9413407821229051:\n",
      "8th- epoch: 137, train_loss = 20.873987581580877, train_acc = 0.952491849091756\n",
      "test Acc 0.9418063314711359:\n",
      "8th- epoch: 138, train_loss = 20.81573574244976, train_acc = 0.952491849091756\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 139, train_loss = 20.757611751556396, train_acc = 0.952491849091756\n",
      "test Acc 0.9418063314711359:\n",
      "8th- epoch: 140, train_loss = 20.70049350708723, train_acc = 0.9527247321844434\n",
      "test Acc 0.9418063314711359:\n",
      "8th- epoch: 141, train_loss = 20.643516946583986, train_acc = 0.9527247321844434\n",
      "test Acc 0.9413407821229051:\n",
      "8th- epoch: 142, train_loss = 20.58779976516962, train_acc = 0.9529576152771309\n",
      "test Acc 0.9413407821229051:\n",
      "8th- epoch: 143, train_loss = 20.53300941735506, train_acc = 0.9530740568234746\n",
      "test Acc 0.9413407821229051:\n",
      "8th- epoch: 144, train_loss = 20.477576784789562, train_acc = 0.9534233814625058\n",
      "test Acc 0.9413407821229051:\n",
      "8th- epoch: 145, train_loss = 20.423326138406992, train_acc = 0.9535398230088495\n",
      "test Acc 0.9413407821229051:\n",
      "8th- epoch: 146, train_loss = 20.370110616087914, train_acc = 0.9535398230088495\n",
      "test Acc 0.9413407821229051:\n",
      "8th- epoch: 147, train_loss = 20.316539905965328, train_acc = 0.9536562645551933\n",
      "test Acc 0.9408752327746741:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 148, train_loss = 20.2649206481874, train_acc = 0.9538891476478808\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 149, train_loss = 20.212747376412153, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 150, train_loss = 20.1619132719934, train_acc = 0.9542384722869119\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 151, train_loss = 20.11017064191401, train_acc = 0.9542384722869119\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 152, train_loss = 20.060357293114066, train_acc = 0.9542384722869119\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 153, train_loss = 20.00885068066418, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 154, train_loss = 19.959929360076785, train_acc = 0.9544713553795995\n",
      "test Acc 0.9418063314711359:\n",
      "8th- epoch: 155, train_loss = 19.910931259393692, train_acc = 0.9545877969259432\n",
      "test Acc 0.9418063314711359:\n",
      "8th- epoch: 156, train_loss = 19.862437015399337, train_acc = 0.9547042384722869\n",
      "test Acc 0.9418063314711359:\n",
      "8th- epoch: 157, train_loss = 19.815275890752673, train_acc = 0.9547042384722869\n",
      "test Acc 0.9418063314711359:\n",
      "8th- epoch: 158, train_loss = 19.767989525571465, train_acc = 0.9547042384722869\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 159, train_loss = 19.72168129682541, train_acc = 0.9548206800186306\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 160, train_loss = 19.675319558009505, train_acc = 0.9548206800186306\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 161, train_loss = 19.629470957443118, train_acc = 0.9549371215649743\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 162, train_loss = 19.58461743965745, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 163, train_loss = 19.539888460189104, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 164, train_loss = 19.494996825233102, train_acc = 0.9554028877503493\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 165, train_loss = 19.451110603287816, train_acc = 0.955519329296693\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 166, train_loss = 19.4080895408988, train_acc = 0.955519329296693\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 167, train_loss = 19.363837430253625, train_acc = 0.9556357708430367\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 168, train_loss = 19.32127663306892, train_acc = 0.9556357708430367\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 169, train_loss = 19.279625311493874, train_acc = 0.9557522123893806\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 170, train_loss = 19.23823986388743, train_acc = 0.9557522123893806\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 171, train_loss = 19.196146542206407, train_acc = 0.9558686539357243\n",
      "test Acc 0.9427374301675978:\n",
      "8th- epoch: 172, train_loss = 19.15488749742508, train_acc = 0.9561015370284117\n",
      "test Acc 0.9427374301675978:\n",
      "8th- epoch: 173, train_loss = 19.114902244880795, train_acc = 0.9561015370284117\n",
      "test Acc 0.9427374301675978:\n",
      "8th- epoch: 174, train_loss = 19.074284015223384, train_acc = 0.956450861667443\n",
      "test Acc 0.9427374301675978:\n",
      "8th- epoch: 175, train_loss = 19.03421509079635, train_acc = 0.9565673032137867\n",
      "test Acc 0.9427374301675978:\n",
      "8th- epoch: 176, train_loss = 18.9951981715858, train_acc = 0.9565673032137867\n",
      "test Acc 0.9427374301675978:\n",
      "8th- epoch: 177, train_loss = 18.955339320003986, train_acc = 0.9568001863064741\n",
      "test Acc 0.9427374301675978:\n",
      "8th- epoch: 178, train_loss = 18.91663086041808, train_acc = 0.9570330693991617\n",
      "test Acc 0.9432029795158287:\n",
      "8th- epoch: 179, train_loss = 18.87818550504744, train_acc = 0.9572659524918491\n",
      "test Acc 0.9436685288640596:\n",
      "8th- epoch: 180, train_loss = 18.840481778606772, train_acc = 0.9573823940381928\n",
      "test Acc 0.9436685288640596:\n",
      "8th- epoch: 181, train_loss = 18.802896121516824, train_acc = 0.9573823940381928\n",
      "test Acc 0.9436685288640596:\n",
      "8th- epoch: 182, train_loss = 18.765664679929614, train_acc = 0.9574988355845365\n",
      "test Acc 0.9436685288640596:\n",
      "8th- epoch: 183, train_loss = 18.728955322876573, train_acc = 0.9578481602235678\n",
      "test Acc 0.9436685288640596:\n",
      "8th- epoch: 184, train_loss = 18.692666495218873, train_acc = 0.9578481602235678\n",
      "test Acc 0.9445996275605214:\n",
      "8th- epoch: 185, train_loss = 18.656451677903533, train_acc = 0.9579646017699115\n",
      "test Acc 0.9445996275605214:\n",
      "8th- epoch: 186, train_loss = 18.62009024620056, train_acc = 0.9579646017699115\n",
      "test Acc 0.9445996275605214:\n",
      "8th- epoch: 187, train_loss = 18.58465992100537, train_acc = 0.9580810433162552\n",
      "test Acc 0.9445996275605214:\n",
      "8th- epoch: 188, train_loss = 18.54814583621919, train_acc = 0.9584303679552865\n",
      "test Acc 0.9445996275605214:\n",
      "8th- epoch: 189, train_loss = 18.512494875118136, train_acc = 0.9584303679552865\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 190, train_loss = 18.478603657335043, train_acc = 0.9585468095016302\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 191, train_loss = 18.44462542794645, train_acc = 0.9585468095016302\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 192, train_loss = 18.411008035764098, train_acc = 0.9585468095016302\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 193, train_loss = 18.376420037820935, train_acc = 0.9586632510479739\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 194, train_loss = 18.34388537891209, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 195, train_loss = 18.310932429507375, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 196, train_loss = 18.2782328594476, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 197, train_loss = 18.246220951899886, train_acc = 0.9587796925943176\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 198, train_loss = 18.214624734595418, train_acc = 0.9587796925943176\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 199, train_loss = 18.1827973742038, train_acc = 0.9587796925943176\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 200, train_loss = 18.150194061920047, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 201, train_loss = 18.11945310048759, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 202, train_loss = 18.088705660775304, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 203, train_loss = 18.05729646421969, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 204, train_loss = 18.02713406831026, train_acc = 0.9590125756870052\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 205, train_loss = 17.997155575081706, train_acc = 0.9592454587796926\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 206, train_loss = 17.967944126576185, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 207, train_loss = 17.938031876459718, train_acc = 0.9592454587796926\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 208, train_loss = 17.90942951105535, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 209, train_loss = 17.87970868125558, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 210, train_loss = 17.850886112079024, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 211, train_loss = 17.822154941037297, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 212, train_loss = 17.794276168569922, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 213, train_loss = 17.76705859787762, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 214, train_loss = 17.739862816408277, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 215, train_loss = 17.711650896817446, train_acc = 0.9592454587796926\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 216, train_loss = 17.683948699384928, train_acc = 0.9593619003260363\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 217, train_loss = 17.656523125246167, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 218, train_loss = 17.629359344020486, train_acc = 0.9598276665114113\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 219, train_loss = 17.603765876963735, train_acc = 0.9598276665114113\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 220, train_loss = 17.576452815905213, train_acc = 0.9598276665114113\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 221, train_loss = 17.549926981329918, train_acc = 0.9600605496040987\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 222, train_loss = 17.525443201884627, train_acc = 0.96040987424313\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 223, train_loss = 17.499658193439245, train_acc = 0.9605263157894737\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 224, train_loss = 17.472872054204345, train_acc = 0.9606427573358174\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 225, train_loss = 17.44682147167623, train_acc = 0.9606427573358174\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 226, train_loss = 17.42169743962586, train_acc = 0.9606427573358174\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 227, train_loss = 17.396487461403012, train_acc = 0.9606427573358174\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 228, train_loss = 17.372384740039706, train_acc = 0.9606427573358174\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 229, train_loss = 17.34769093617797, train_acc = 0.9606427573358174\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 230, train_loss = 17.322619481012225, train_acc = 0.9607591988821611\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 231, train_loss = 17.299033479765058, train_acc = 0.9607591988821611\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 232, train_loss = 17.27501893788576, train_acc = 0.9608756404285049\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 233, train_loss = 17.2515316773206, train_acc = 0.9609920819748486\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 234, train_loss = 17.22759653441608, train_acc = 0.9609920819748486\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 235, train_loss = 17.204433543607593, train_acc = 0.9611085235211924\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 236, train_loss = 17.181877395138144, train_acc = 0.9611085235211924\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 237, train_loss = 17.158579520881176, train_acc = 0.9611085235211924\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 238, train_loss = 17.135988349094987, train_acc = 0.9611085235211924\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 239, train_loss = 17.113971831277013, train_acc = 0.9611085235211924\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 240, train_loss = 17.09135663509369, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 241, train_loss = 17.06881358101964, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 242, train_loss = 17.04695658851415, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 243, train_loss = 17.024664919823408, train_acc = 0.9614578481602236\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 244, train_loss = 17.00420916825533, train_acc = 0.9614578481602236\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 245, train_loss = 16.982133298180997, train_acc = 0.9614578481602236\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 246, train_loss = 16.960782434791327, train_acc = 0.9615742897065673\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 247, train_loss = 16.939164362847805, train_acc = 0.9615742897065673\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 248, train_loss = 16.918184072710574, train_acc = 0.9618071727992548\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 249, train_loss = 16.89677580446005, train_acc = 0.9619236143455985\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 250, train_loss = 16.876506499014795, train_acc = 0.9619236143455985\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 251, train_loss = 16.856100898236036, train_acc = 0.9620400558919422\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 252, train_loss = 16.83523207437247, train_acc = 0.9620400558919422\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 253, train_loss = 16.815094406716526, train_acc = 0.9620400558919422\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 254, train_loss = 16.795624382793903, train_acc = 0.9620400558919422\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 255, train_loss = 16.77592769358307, train_acc = 0.9622729389846297\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 256, train_loss = 16.755794967524707, train_acc = 0.9623893805309734\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 257, train_loss = 16.73633289244026, train_acc = 0.9627387051700047\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 258, train_loss = 16.716187397949398, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 259, train_loss = 16.696770428679883, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 260, train_loss = 16.67640363331884, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 261, train_loss = 16.658134409226477, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 262, train_loss = 16.64063262939453, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 263, train_loss = 16.62039328739047, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 264, train_loss = 16.60219556093216, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 265, train_loss = 16.584206548519433, train_acc = 0.9629715882626921\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 266, train_loss = 16.565382671542466, train_acc = 0.9630880298090359\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 267, train_loss = 16.547502239234746, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 268, train_loss = 16.529574677348137, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 269, train_loss = 16.511205699294806, train_acc = 0.9630880298090359\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 270, train_loss = 16.493830353952944, train_acc = 0.9629715882626921\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 271, train_loss = 16.4757706457749, train_acc = 0.9630880298090359\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 272, train_loss = 16.4582010358572, train_acc = 0.9630880298090359\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 273, train_loss = 16.44050887133926, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 274, train_loss = 16.422171820886433, train_acc = 0.9634373544480671\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 275, train_loss = 16.405516263097525, train_acc = 0.9635537959944108\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 276, train_loss = 16.388579537160695, train_acc = 0.9635537959944108\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 277, train_loss = 16.371496030129492, train_acc = 0.9635537959944108\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 278, train_loss = 16.353989644907415, train_acc = 0.9636702375407545\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 279, train_loss = 16.337175610475242, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 280, train_loss = 16.32053539995104, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 281, train_loss = 16.30310791824013, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 282, train_loss = 16.286147616803646, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 283, train_loss = 16.270424994640052, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 284, train_loss = 16.255612652748823, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 285, train_loss = 16.23830896988511, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 286, train_loss = 16.221759761683643, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 287, train_loss = 16.20548235345632, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 288, train_loss = 16.190249347127974, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 289, train_loss = 16.17434886097908, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 290, train_loss = 16.15976892411709, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 291, train_loss = 16.144649752415717, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 292, train_loss = 16.13024166878313, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 293, train_loss = 16.11421717237681, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 294, train_loss = 16.09907393436879, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 295, train_loss = 16.08432569820434, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 296, train_loss = 16.068245951086283, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 297, train_loss = 16.052971575409174, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 298, train_loss = 16.03670934867114, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 299, train_loss = 16.022493514232337, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 300, train_loss = 16.006972044706345, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 301, train_loss = 15.990957498550415, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 302, train_loss = 15.978307426907122, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 303, train_loss = 15.963429640978575, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 304, train_loss = 15.948655933141708, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 305, train_loss = 15.934861343353987, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 306, train_loss = 15.920803860761225, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 307, train_loss = 15.906411887146533, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 308, train_loss = 15.892709121108055, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 309, train_loss = 15.87997826281935, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 310, train_loss = 15.866455131210387, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 311, train_loss = 15.850972346030176, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 312, train_loss = 15.835885520093143, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 313, train_loss = 15.821609775535762, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 314, train_loss = 15.808362911455333, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 315, train_loss = 15.794252902269363, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 316, train_loss = 15.78176665585488, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 317, train_loss = 15.7690594131127, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 318, train_loss = 15.75692444294691, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 319, train_loss = 15.744215867482126, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 320, train_loss = 15.731705192476511, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 321, train_loss = 15.716992859728634, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 322, train_loss = 15.705456278286874, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 323, train_loss = 15.69303288590163, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 324, train_loss = 15.67945069540292, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 325, train_loss = 15.66731194127351, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 326, train_loss = 15.652350266464055, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 327, train_loss = 15.640773660503328, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 328, train_loss = 15.629802984185517, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "8th- epoch: 329, train_loss = 15.615899271331728, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 330, train_loss = 15.60280828550458, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 331, train_loss = 15.590803630650043, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 332, train_loss = 15.578105176799, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 333, train_loss = 15.5660010734573, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 334, train_loss = 15.555502501316369, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 335, train_loss = 15.544165566563606, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 336, train_loss = 15.532990946434438, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "8th- epoch: 337, train_loss = 15.51956831663847, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "8th- epoch: 338, train_loss = 15.506617820821702, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "8th- epoch: 339, train_loss = 15.495189864188433, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 340, train_loss = 15.484113493002951, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 341, train_loss = 15.474053181707859, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 342, train_loss = 15.46378864441067, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 343, train_loss = 15.451117490418255, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 344, train_loss = 15.439584583975375, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 345, train_loss = 15.425837167538702, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 346, train_loss = 15.414268325082958, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 347, train_loss = 15.403839106671512, train_acc = 0.965649743828598\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 348, train_loss = 15.393391344696283, train_acc = 0.965649743828598\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 349, train_loss = 15.38010797649622, train_acc = 0.965649743828598\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 350, train_loss = 15.369907189160585, train_acc = 0.965649743828598\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 351, train_loss = 15.359659794718027, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 352, train_loss = 15.347791478037834, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 353, train_loss = 15.336952456273139, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 354, train_loss = 15.326341848820448, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 355, train_loss = 15.31545352190733, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 356, train_loss = 15.3057646676898, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 357, train_loss = 15.293684978038073, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 358, train_loss = 15.28332491312176, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 359, train_loss = 15.273002992384136, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 360, train_loss = 15.260930926539004, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 361, train_loss = 15.251789565198123, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 362, train_loss = 15.241502118296921, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 363, train_loss = 15.230803433805704, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 364, train_loss = 15.220532449893653, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 365, train_loss = 15.211176524870098, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 366, train_loss = 15.199255310930312, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 367, train_loss = 15.190400482155383, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 368, train_loss = 15.17946329060942, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 369, train_loss = 15.16954946052283, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 370, train_loss = 15.159230812452734, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 371, train_loss = 15.149287473410368, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 372, train_loss = 15.14002428855747, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 373, train_loss = 15.130336848087609, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 374, train_loss = 15.120327609591186, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 375, train_loss = 15.110835232771933, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 376, train_loss = 15.100699108093977, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 377, train_loss = 15.090665806084871, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 378, train_loss = 15.080626008100808, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 379, train_loss = 15.071182155050337, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "8th- epoch: 380, train_loss = 15.062803112901747, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 381, train_loss = 15.052468746900558, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 382, train_loss = 15.043227990157902, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 383, train_loss = 15.034397809766233, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 384, train_loss = 15.024116854183376, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 385, train_loss = 15.015657193027437, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 386, train_loss = 15.006746319122612, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 387, train_loss = 14.996064436621964, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 388, train_loss = 14.98725779633969, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 389, train_loss = 14.978889324702322, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 390, train_loss = 14.970408029854298, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 391, train_loss = 14.960566095076501, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 392, train_loss = 14.950258028693497, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 393, train_loss = 14.941980152390897, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 394, train_loss = 14.932863417081535, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 395, train_loss = 14.924324753694236, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 396, train_loss = 14.91446812171489, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 397, train_loss = 14.907914906740189, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 398, train_loss = 14.89800088852644, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 399, train_loss = 14.888356611132622, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 400, train_loss = 14.88137125223875, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 401, train_loss = 14.87273518834263, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 402, train_loss = 14.864131120033562, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 403, train_loss = 14.853739987127483, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 404, train_loss = 14.846624709665775, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 405, train_loss = 14.83755216281861, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 406, train_loss = 14.829706442542374, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 407, train_loss = 14.82231479883194, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 408, train_loss = 14.813404314219952, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 409, train_loss = 14.803120800293982, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 410, train_loss = 14.795869745314121, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 411, train_loss = 14.78812162578106, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 412, train_loss = 14.780104209668934, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 413, train_loss = 14.772784654982388, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 414, train_loss = 14.763749876059592, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 415, train_loss = 14.755869249813259, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 416, train_loss = 14.748084605671465, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 417, train_loss = 14.739470217376947, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 418, train_loss = 14.731413935311139, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 419, train_loss = 14.723228217102587, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 420, train_loss = 14.716622244566679, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 421, train_loss = 14.70664373692125, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 422, train_loss = 14.699367047287524, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 423, train_loss = 14.692220229655504, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 424, train_loss = 14.685229070484638, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 425, train_loss = 14.67725008353591, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 426, train_loss = 14.670195533894002, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 427, train_loss = 14.6613887893036, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 428, train_loss = 14.65412066783756, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 429, train_loss = 14.6465123295784, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 430, train_loss = 14.639818739145994, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 431, train_loss = 14.630111766513437, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 432, train_loss = 14.62414429569617, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 433, train_loss = 14.615505291614681, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 434, train_loss = 14.610071138944477, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 435, train_loss = 14.601119935512543, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 436, train_loss = 14.594855287577957, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 437, train_loss = 14.586259722709656, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 438, train_loss = 14.57959164539352, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 439, train_loss = 14.572355883661658, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 440, train_loss = 14.565352035220712, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 441, train_loss = 14.557639679405838, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 442, train_loss = 14.550981773529202, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 443, train_loss = 14.54253892833367, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 444, train_loss = 14.536745626479387, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 445, train_loss = 14.52949370071292, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 446, train_loss = 14.521568335592747, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 447, train_loss = 14.515956919640303, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 448, train_loss = 14.507528027053922, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 449, train_loss = 14.502392879221588, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 450, train_loss = 14.493081618100405, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 451, train_loss = 14.488592248409986, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 452, train_loss = 14.480891061481088, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 453, train_loss = 14.475514702498913, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 454, train_loss = 14.469244123902172, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 455, train_loss = 14.462778636720031, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 456, train_loss = 14.453236628323793, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "8th- epoch: 457, train_loss = 14.446950429584831, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 458, train_loss = 14.440676162485033, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 459, train_loss = 14.436085620429367, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 460, train_loss = 14.428421440068632, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 461, train_loss = 14.420848652720451, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 462, train_loss = 14.414939197245985, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 463, train_loss = 14.407443554606289, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 464, train_loss = 14.402566328644753, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 465, train_loss = 14.394597914069891, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 466, train_loss = 14.389855878893286, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 467, train_loss = 14.383121270686388, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 468, train_loss = 14.376732832286507, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 469, train_loss = 14.369689483195543, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 470, train_loss = 14.36459526931867, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 471, train_loss = 14.356919975485653, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 472, train_loss = 14.352952593471855, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 473, train_loss = 14.34385850885883, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 474, train_loss = 14.339235806372017, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 475, train_loss = 14.33341463143006, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 476, train_loss = 14.328246109187603, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 477, train_loss = 14.320516604930162, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 478, train_loss = 14.312048631254584, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 479, train_loss = 14.308792915195227, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 480, train_loss = 14.303300525993109, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 481, train_loss = 14.296661420259625, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 482, train_loss = 14.289704157505184, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 483, train_loss = 14.2831213013269, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 484, train_loss = 14.280189041048288, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 485, train_loss = 14.2741889343597, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 486, train_loss = 14.266087333206087, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 487, train_loss = 14.261126339435577, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 488, train_loss = 14.25647929823026, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 489, train_loss = 14.25054024765268, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 490, train_loss = 14.243952116463333, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 491, train_loss = 14.236705718096346, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 492, train_loss = 14.23375832149759, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 493, train_loss = 14.225665314588696, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 494, train_loss = 14.219628208782524, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 495, train_loss = 14.214235416147858, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 496, train_loss = 14.209234587848186, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 497, train_loss = 14.204554165247828, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 498, train_loss = 14.195767294615507, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "8th- epoch: 499, train_loss = 14.190983308944851, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|███████████████████▍                                                     | 8/30 [53:12<2:26:20, 399.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "9th- epoch: 0, train_loss = 270.2029436826706, train_acc = 0.4786911970190964\n",
      "test Acc 0.4958100558659218:\n",
      "9th- epoch: 1, train_loss = 210.06985223293304, train_acc = 0.4995342338146251\n",
      "test Acc 0.49906890130353815:\n",
      "9th- epoch: 2, train_loss = 179.86472284793854, train_acc = 0.5088495575221239\n",
      "test Acc 0.5228119180633147:\n",
      "9th- epoch: 3, train_loss = 164.5068392753601, train_acc = 0.5330693991616209\n",
      "test Acc 0.5563314711359404:\n",
      "9th- epoch: 4, train_loss = 152.4598005414009, train_acc = 0.568234746157429\n",
      "test Acc 0.6000931098696461:\n",
      "9th- epoch: 5, train_loss = 141.38466954231262, train_acc = 0.6070097810898929\n",
      "test Acc 0.6261638733705773:\n",
      "9th- epoch: 6, train_loss = 130.71189135313034, train_acc = 0.6334420121099208\n",
      "test Acc 0.6447858472998138:\n",
      "9th- epoch: 7, train_loss = 120.57752841711044, train_acc = 0.6836283185840708\n",
      "test Acc 0.7458100558659218:\n",
      "9th- epoch: 8, train_loss = 111.1502748131752, train_acc = 0.75\n",
      "test Acc 0.7588454376163873:\n",
      "9th- epoch: 9, train_loss = 102.50589108467102, train_acc = 0.7745691662785282\n",
      "test Acc 0.7877094972067039:\n",
      "9th- epoch: 10, train_loss = 94.73021417856216, train_acc = 0.8012342803912436\n",
      "test Acc 0.8063314711359404:\n",
      "9th- epoch: 11, train_loss = 87.79592451453209, train_acc = 0.8180018630647415\n",
      "test Acc 0.8342644320297952:\n",
      "9th- epoch: 12, train_loss = 81.67009317874908, train_acc = 0.8387284583139264\n",
      "test Acc 0.8528864059590316:\n",
      "9th- epoch: 13, train_loss = 76.31245476007462, train_acc = 0.8520027945971123\n",
      "test Acc 0.8635940409683427:\n",
      "9th- epoch: 14, train_loss = 71.64860633015633, train_acc = 0.862249650675361\n",
      "test Acc 0.8677839851024208:\n",
      "9th- epoch: 15, train_loss = 67.5955835878849, train_acc = 0.8698183511877038\n",
      "test Acc 0.8756983240223464:\n",
      "9th- epoch: 16, train_loss = 64.06569391489029, train_acc = 0.8756404285048905\n",
      "test Acc 0.8817504655493482:\n",
      "9th- epoch: 17, train_loss = 60.97945100069046, train_acc = 0.8808802980903586\n",
      "test Acc 0.8840782122905028:\n",
      "9th- epoch: 18, train_loss = 58.28145605325699, train_acc = 0.8828598043782021\n",
      "test Acc 0.888733705772812:\n",
      "9th- epoch: 19, train_loss = 55.90722842514515, train_acc = 0.8844899860270145\n",
      "test Acc 0.8905959031657356:\n",
      "9th- epoch: 20, train_loss = 53.80952559411526, train_acc = 0.8884489986027014\n",
      "test Acc 0.8966480446927374:\n",
      "9th- epoch: 21, train_loss = 51.9499591588974, train_acc = 0.8911271541686073\n",
      "test Acc 0.8975791433891993:\n",
      "9th- epoch: 22, train_loss = 50.297552689909935, train_acc = 0.8933395435491384\n",
      "test Acc 0.8980446927374302:\n",
      "9th- epoch: 23, train_loss = 48.8212019354105, train_acc = 0.8970656730321379\n",
      "test Acc 0.9022346368715084:\n",
      "9th- epoch: 24, train_loss = 47.49703520536423, train_acc = 0.8995109455053563\n",
      "test Acc 0.9036312849162011:\n",
      "9th- epoch: 25, train_loss = 46.30036278069019, train_acc = 0.9006753609687936\n",
      "test Acc 0.9054934823091247:\n",
      "9th- epoch: 26, train_loss = 45.21561802923679, train_acc = 0.9025384257102934\n",
      "test Acc 0.9064245810055865:\n",
      "9th- epoch: 27, train_loss = 44.225025817751884, train_acc = 0.9033535165346995\n",
      "test Acc 0.9064245810055865:\n",
      "9th- epoch: 28, train_loss = 43.31356705725193, train_acc = 0.9053330228225431\n",
      "test Acc 0.9068901303538175:\n",
      "9th- epoch: 29, train_loss = 42.47400192916393, train_acc = 0.9070796460176991\n",
      "test Acc 0.9087523277467412:\n",
      "9th- epoch: 30, train_loss = 41.69581364095211, train_acc = 0.9096413600372613\n",
      "test Acc 0.910148975791434:\n",
      "9th- epoch: 31, train_loss = 40.97141978144646, train_acc = 0.9109222170470423\n",
      "test Acc 0.9110800744878957:\n",
      "9th- epoch: 32, train_loss = 40.294033482670784, train_acc = 0.9137168141592921\n",
      "test Acc 0.9124767225325885:\n",
      "9th- epoch: 33, train_loss = 39.659234553575516, train_acc = 0.9146483465300419\n",
      "test Acc 0.9129422718808193:\n",
      "9th- epoch: 34, train_loss = 39.06168952584267, train_acc = 0.916394969725198\n",
      "test Acc 0.9143389199255121:\n",
      "9th- epoch: 35, train_loss = 38.49849897623062, train_acc = 0.9169771774569166\n",
      "test Acc 0.9152700186219739:\n",
      "9th- epoch: 36, train_loss = 37.96654160320759, train_acc = 0.9175593851886353\n",
      "test Acc 0.9157355679702048:\n",
      "9th- epoch: 37, train_loss = 37.46262167394161, train_acc = 0.9183744760130415\n",
      "test Acc 0.9166666666666666:\n",
      "9th- epoch: 38, train_loss = 36.98370312154293, train_acc = 0.91988821611551\n",
      "test Acc 0.9166666666666666:\n",
      "9th- epoch: 39, train_loss = 36.528818577528, train_acc = 0.9208197484862599\n",
      "test Acc 0.9175977653631285:\n",
      "9th- epoch: 40, train_loss = 36.09584765136242, train_acc = 0.921634839310666\n",
      "test Acc 0.9185288640595903:\n",
      "9th- epoch: 41, train_loss = 35.6824501901865, train_acc = 0.9230321378667908\n",
      "test Acc 0.9189944134078212:\n",
      "9th- epoch: 42, train_loss = 35.287802785634995, train_acc = 0.9238472286911971\n",
      "test Acc 0.9199255121042831:\n",
      "9th- epoch: 43, train_loss = 34.90973524004221, train_acc = 0.9245458779692595\n",
      "test Acc 0.9208566108007449:\n",
      "9th- epoch: 44, train_loss = 34.5468155965209, train_acc = 0.9257102934326968\n",
      "test Acc 0.9222532588454376:\n",
      "9th- epoch: 45, train_loss = 34.19799812883139, train_acc = 0.926059618071728\n",
      "test Acc 0.9227188081936686:\n",
      "9th- epoch: 46, train_loss = 33.863084368407726, train_acc = 0.926525384257103\n",
      "test Acc 0.9236499068901304:\n",
      "9th- epoch: 47, train_loss = 33.53987842053175, train_acc = 0.9268747088961341\n",
      "test Acc 0.9236499068901304:\n",
      "9th- epoch: 48, train_loss = 33.229281686246395, train_acc = 0.9272240335351654\n",
      "test Acc 0.9245810055865922:\n",
      "9th- epoch: 49, train_loss = 32.92951325327158, train_acc = 0.9279226828132278\n",
      "test Acc 0.9250465549348231:\n",
      "9th- epoch: 50, train_loss = 32.63977073132992, train_acc = 0.9281555659059152\n",
      "test Acc 0.9250465549348231:\n",
      "9th- epoch: 51, train_loss = 32.35959444195032, train_acc = 0.9288542151839776\n",
      "test Acc 0.9250465549348231:\n",
      "9th- epoch: 52, train_loss = 32.08881752192974, train_acc = 0.9289706567303214\n",
      "test Acc 0.925512104283054:\n",
      "9th- epoch: 53, train_loss = 31.82589877396822, train_acc = 0.9293199813693526\n",
      "test Acc 0.925512104283054:\n",
      "9th- epoch: 54, train_loss = 31.571002431213856, train_acc = 0.9296693060083838\n",
      "test Acc 0.9259776536312849:\n",
      "9th- epoch: 55, train_loss = 31.323655374348164, train_acc = 0.9306008383791337\n",
      "test Acc 0.9259776536312849:\n",
      "9th- epoch: 56, train_loss = 31.083079420030117, train_acc = 0.9307172799254774\n",
      "test Acc 0.9259776536312849:\n",
      "9th- epoch: 57, train_loss = 30.848189011216164, train_acc = 0.9314159292035398\n",
      "test Acc 0.9259776536312849:\n",
      "9th- epoch: 58, train_loss = 30.61939188838005, train_acc = 0.931765253842571\n",
      "test Acc 0.9264432029795159:\n",
      "9th- epoch: 59, train_loss = 30.396335244178772, train_acc = 0.9318816953889147\n",
      "test Acc 0.9269087523277467:\n",
      "9th- epoch: 60, train_loss = 30.178361795842648, train_acc = 0.9321145784816023\n",
      "test Acc 0.9269087523277467:\n",
      "9th- epoch: 61, train_loss = 29.965018689632416, train_acc = 0.9329296693060084\n",
      "test Acc 0.9273743016759777:\n",
      "9th- epoch: 62, train_loss = 29.757620252668858, train_acc = 0.9336283185840708\n",
      "test Acc 0.9273743016759777:\n",
      "9th- epoch: 63, train_loss = 29.5540424361825, train_acc = 0.9338612016767582\n",
      "test Acc 0.9269087523277467:\n",
      "9th- epoch: 64, train_loss = 29.35620004683733, train_acc = 0.9344434094084769\n",
      "test Acc 0.9269087523277467:\n",
      "9th- epoch: 65, train_loss = 29.162777177989483, train_acc = 0.9350256171401956\n",
      "test Acc 0.9273743016759777:\n",
      "9th- epoch: 66, train_loss = 28.97394149750471, train_acc = 0.935258500232883\n",
      "test Acc 0.9278398510242085:\n",
      "9th- epoch: 67, train_loss = 28.78867933154106, train_acc = 0.9354913833255706\n",
      "test Acc 0.9283054003724395:\n",
      "9th- epoch: 68, train_loss = 28.608044050633907, train_acc = 0.9358407079646017\n",
      "test Acc 0.9287709497206704:\n",
      "9th- epoch: 69, train_loss = 28.43065905570984, train_acc = 0.936190032603633\n",
      "test Acc 0.9287709497206704:\n",
      "9th- epoch: 70, train_loss = 28.25722672045231, train_acc = 0.9368886818816954\n",
      "test Acc 0.9287709497206704:\n",
      "9th- epoch: 71, train_loss = 28.087035082280636, train_acc = 0.9372380065207266\n",
      "test Acc 0.9287709497206704:\n",
      "9th- epoch: 72, train_loss = 27.919820457696915, train_acc = 0.9374708896134141\n",
      "test Acc 0.9297020484171322:\n",
      "9th- epoch: 73, train_loss = 27.755833469331264, train_acc = 0.9378202142524453\n",
      "test Acc 0.9297020484171322:\n",
      "9th- epoch: 74, train_loss = 27.595700435340405, train_acc = 0.937936655798789\n",
      "test Acc 0.9297020484171322:\n",
      "9th- epoch: 75, train_loss = 27.438722878694534, train_acc = 0.9384024219841639\n",
      "test Acc 0.9297020484171322:\n",
      "9th- epoch: 76, train_loss = 27.28404152393341, train_acc = 0.9386353050768514\n",
      "test Acc 0.9297020484171322:\n",
      "9th- epoch: 77, train_loss = 27.13248211890459, train_acc = 0.9386353050768514\n",
      "test Acc 0.9301675977653632:\n",
      "9th- epoch: 78, train_loss = 26.984916262328625, train_acc = 0.9389846297158826\n",
      "test Acc 0.9301675977653632:\n",
      "9th- epoch: 79, train_loss = 26.838451705873013, train_acc = 0.9393339543549138\n",
      "test Acc 0.9301675977653632:\n",
      "9th- epoch: 80, train_loss = 26.69628183543682, train_acc = 0.9393339543549138\n",
      "test Acc 0.931098696461825:\n",
      "9th- epoch: 81, train_loss = 26.555548794567585, train_acc = 0.9393339543549138\n",
      "test Acc 0.931098696461825:\n",
      "9th- epoch: 82, train_loss = 26.41735504567623, train_acc = 0.9394503959012576\n",
      "test Acc 0.9315642458100558:\n",
      "9th- epoch: 83, train_loss = 26.28123952448368, train_acc = 0.94014904517932\n",
      "test Acc 0.9320297951582868:\n",
      "9th- epoch: 84, train_loss = 26.147749736905098, train_acc = 0.9406148113646949\n",
      "test Acc 0.9320297951582868:\n",
      "9th- epoch: 85, train_loss = 26.015489544719458, train_acc = 0.9410805775500699\n",
      "test Acc 0.9320297951582868:\n",
      "9th- epoch: 86, train_loss = 25.88643303140998, train_acc = 0.941429902189101\n",
      "test Acc 0.9320297951582868:\n",
      "9th- epoch: 87, train_loss = 25.75962934270501, train_acc = 0.9417792268281323\n",
      "test Acc 0.9320297951582868:\n",
      "9th- epoch: 88, train_loss = 25.63317735865712, train_acc = 0.941895668374476\n",
      "test Acc 0.9320297951582868:\n",
      "9th- epoch: 89, train_loss = 25.509412486106157, train_acc = 0.9420121099208197\n",
      "test Acc 0.9320297951582868:\n",
      "9th- epoch: 90, train_loss = 25.38835134729743, train_acc = 0.942361434559851\n",
      "test Acc 0.9320297951582868:\n",
      "9th- epoch: 91, train_loss = 25.269017592072487, train_acc = 0.9425943176525384\n",
      "test Acc 0.9320297951582868:\n",
      "9th- epoch: 92, train_loss = 25.15139677748084, train_acc = 0.9428272007452259\n",
      "test Acc 0.9320297951582868:\n",
      "9th- epoch: 93, train_loss = 25.035078182816505, train_acc = 0.9429436422915697\n",
      "test Acc 0.9324953445065177:\n",
      "9th- epoch: 94, train_loss = 24.921839859336615, train_acc = 0.9431765253842571\n",
      "test Acc 0.9334264432029795:\n",
      "9th- epoch: 95, train_loss = 24.810334511101246, train_acc = 0.9434094084769445\n",
      "test Acc 0.9343575418994413:\n",
      "9th- epoch: 96, train_loss = 24.70070081576705, train_acc = 0.9438751746623195\n",
      "test Acc 0.9343575418994413:\n",
      "9th- epoch: 97, train_loss = 24.593096122145653, train_acc = 0.9442244993013508\n",
      "test Acc 0.9343575418994413:\n",
      "9th- epoch: 98, train_loss = 24.48693523183465, train_acc = 0.9450395901257569\n",
      "test Acc 0.9348230912476723:\n",
      "9th- epoch: 99, train_loss = 24.383108519017696, train_acc = 0.9452724732184443\n",
      "test Acc 0.9348230912476723:\n",
      "9th- epoch: 100, train_loss = 24.28011206910014, train_acc = 0.9456217978574756\n",
      "test Acc 0.9357541899441341:\n",
      "9th- epoch: 101, train_loss = 24.17956155911088, train_acc = 0.9460875640428504\n",
      "test Acc 0.936219739292365:\n",
      "9th- epoch: 102, train_loss = 24.080177940428257, train_acc = 0.946786213320913\n",
      "test Acc 0.936219739292365:\n",
      "9th- epoch: 103, train_loss = 23.982437755912542, train_acc = 0.946786213320913\n",
      "test Acc 0.9366852886405959:\n",
      "9th- epoch: 104, train_loss = 23.886005397886038, train_acc = 0.9470190964136004\n",
      "test Acc 0.9366852886405959:\n",
      "9th- epoch: 105, train_loss = 23.789882604032755, train_acc = 0.9469026548672567\n",
      "test Acc 0.9371508379888268:\n",
      "9th- epoch: 106, train_loss = 23.69909716024995, train_acc = 0.9473684210526315\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 107, train_loss = 23.607648205012083, train_acc = 0.9473684210526315\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 108, train_loss = 23.51792072877288, train_acc = 0.9474848625989754\n",
      "test Acc 0.9380819366852886:\n",
      "9th- epoch: 109, train_loss = 23.428102966398, train_acc = 0.9476013041453191\n",
      "test Acc 0.9380819366852886:\n",
      "9th- epoch: 110, train_loss = 23.34011321142316, train_acc = 0.9478341872380065\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 111, train_loss = 23.253909461200237, train_acc = 0.9479506287843502\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 112, train_loss = 23.1688573025167, train_acc = 0.9482999534233815\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 113, train_loss = 23.08482324331999, train_acc = 0.9482999534233815\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 114, train_loss = 23.002958822995424, train_acc = 0.9485328365160689\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 115, train_loss = 22.920254848897457, train_acc = 0.9487657196087564\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 116, train_loss = 22.840174224227667, train_acc = 0.9487657196087564\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 117, train_loss = 22.762331169098616, train_acc = 0.9488821611551002\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 118, train_loss = 22.682235538959503, train_acc = 0.9489986027014439\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 119, train_loss = 22.605312444269657, train_acc = 0.9489986027014439\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 120, train_loss = 22.530111126601696, train_acc = 0.9493479273404751\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 121, train_loss = 22.456004038453102, train_acc = 0.9495808104331626\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 122, train_loss = 22.381697207689285, train_acc = 0.9496972519795063\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 123, train_loss = 22.308531414717436, train_acc = 0.94981369352585\n",
      "test Acc 0.9385474860335196:\n",
      "9th- epoch: 124, train_loss = 22.23610159382224, train_acc = 0.94981369352585\n",
      "test Acc 0.9390130353817505:\n",
      "9th- epoch: 125, train_loss = 22.165005918592215, train_acc = 0.9500465766185375\n",
      "test Acc 0.9390130353817505:\n",
      "9th- epoch: 126, train_loss = 22.094862669706345, train_acc = 0.9501630181648812\n",
      "test Acc 0.9394785847299814:\n",
      "9th- epoch: 127, train_loss = 22.024653907865286, train_acc = 0.9503959012575687\n",
      "test Acc 0.9394785847299814:\n",
      "9th- epoch: 128, train_loss = 21.955982588231564, train_acc = 0.9506287843502562\n",
      "test Acc 0.9394785847299814:\n",
      "9th- epoch: 129, train_loss = 21.887994397431612, train_acc = 0.9506287843502562\n",
      "test Acc 0.9394785847299814:\n",
      "9th- epoch: 130, train_loss = 21.820064213126898, train_acc = 0.9507452258965999\n",
      "test Acc 0.9394785847299814:\n",
      "9th- epoch: 131, train_loss = 21.75422263890505, train_acc = 0.9508616674429436\n",
      "test Acc 0.9394785847299814:\n",
      "9th- epoch: 132, train_loss = 21.689307525753975, train_acc = 0.9508616674429436\n",
      "test Acc 0.9394785847299814:\n",
      "9th- epoch: 133, train_loss = 21.624542366713285, train_acc = 0.9509781089892874\n",
      "test Acc 0.9390130353817505:\n",
      "9th- epoch: 134, train_loss = 21.56076304987073, train_acc = 0.951560316721006\n",
      "test Acc 0.9390130353817505:\n",
      "9th- epoch: 135, train_loss = 21.497745145112276, train_acc = 0.951560316721006\n",
      "test Acc 0.9390130353817505:\n",
      "9th- epoch: 136, train_loss = 21.435380056500435, train_acc = 0.9516767582673498\n",
      "test Acc 0.9390130353817505:\n",
      "9th- epoch: 137, train_loss = 21.37342370301485, train_acc = 0.9516767582673498\n",
      "test Acc 0.9394785847299814:\n",
      "9th- epoch: 138, train_loss = 21.314326375722885, train_acc = 0.9517931998136935\n",
      "test Acc 0.9399441340782123:\n",
      "9th- epoch: 139, train_loss = 21.252585124224424, train_acc = 0.952026082906381\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 140, train_loss = 21.19280545786023, train_acc = 0.9523754075454122\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 141, train_loss = 21.13276854902506, train_acc = 0.952491849091756\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 142, train_loss = 21.0747395940125, train_acc = 0.9526082906380997\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 143, train_loss = 21.01784060522914, train_acc = 0.9526082906380997\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 144, train_loss = 20.959426555782557, train_acc = 0.9528411737307871\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 145, train_loss = 20.903145488351583, train_acc = 0.9530740568234746\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 146, train_loss = 20.845327243208885, train_acc = 0.9530740568234746\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 147, train_loss = 20.790162686258554, train_acc = 0.9529576152771309\n",
      "test Acc 0.9404096834264432:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 148, train_loss = 20.735736690461636, train_acc = 0.9530740568234746\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 149, train_loss = 20.68056233599782, train_acc = 0.9531904983698184\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 150, train_loss = 20.62735750898719, train_acc = 0.9536562645551933\n",
      "test Acc 0.9408752327746741:\n",
      "9th- epoch: 151, train_loss = 20.57356970384717, train_acc = 0.9536562645551933\n",
      "test Acc 0.9408752327746741:\n",
      "9th- epoch: 152, train_loss = 20.519749162718654, train_acc = 0.9538891476478808\n",
      "test Acc 0.9408752327746741:\n",
      "9th- epoch: 153, train_loss = 20.468556294217706, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "9th- epoch: 154, train_loss = 20.415730448439717, train_acc = 0.9542384722869119\n",
      "test Acc 0.9408752327746741:\n",
      "9th- epoch: 155, train_loss = 20.363517854362726, train_acc = 0.9542384722869119\n",
      "test Acc 0.9408752327746741:\n",
      "9th- epoch: 156, train_loss = 20.31246112473309, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "9th- epoch: 157, train_loss = 20.26209337450564, train_acc = 0.9544713553795995\n",
      "test Acc 0.9408752327746741:\n",
      "9th- epoch: 158, train_loss = 20.21223482489586, train_acc = 0.9545877969259432\n",
      "test Acc 0.9413407821229051:\n",
      "9th- epoch: 159, train_loss = 20.1625087428838, train_acc = 0.9545877969259432\n",
      "test Acc 0.9413407821229051:\n",
      "9th- epoch: 160, train_loss = 20.1139222253114, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "9th- epoch: 161, train_loss = 20.065798303112388, train_acc = 0.9550535631113182\n",
      "test Acc 0.9418063314711359:\n",
      "9th- epoch: 162, train_loss = 20.016909746453166, train_acc = 0.9550535631113182\n",
      "test Acc 0.9418063314711359:\n",
      "9th- epoch: 163, train_loss = 19.96934031881392, train_acc = 0.9550535631113182\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 164, train_loss = 19.921487344428897, train_acc = 0.9550535631113182\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 165, train_loss = 19.875261940062046, train_acc = 0.9550535631113182\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 166, train_loss = 19.82881952635944, train_acc = 0.9549371215649743\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 167, train_loss = 19.782811926677823, train_acc = 0.9550535631113182\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 168, train_loss = 19.737323163077235, train_acc = 0.9551700046576619\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 169, train_loss = 19.69188734702766, train_acc = 0.9552864462040056\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 170, train_loss = 19.647903399541974, train_acc = 0.9554028877503493\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 171, train_loss = 19.602475034072995, train_acc = 0.955519329296693\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 172, train_loss = 19.557883873581886, train_acc = 0.955519329296693\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 173, train_loss = 19.514724178239703, train_acc = 0.9556357708430367\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 174, train_loss = 19.471407748758793, train_acc = 0.9557522123893806\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 175, train_loss = 19.427372274920344, train_acc = 0.9558686539357243\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 176, train_loss = 19.385718032717705, train_acc = 0.955985095482068\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 177, train_loss = 19.343849113211036, train_acc = 0.9561015370284117\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 178, train_loss = 19.303224740549922, train_acc = 0.9562179785747554\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 179, train_loss = 19.261791525408626, train_acc = 0.956450861667443\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 180, train_loss = 19.220120714977384, train_acc = 0.956450861667443\n",
      "test Acc 0.9436685288640596:\n",
      "9th- epoch: 181, train_loss = 19.18013045564294, train_acc = 0.9565673032137867\n",
      "test Acc 0.9441340782122905:\n",
      "9th- epoch: 182, train_loss = 19.140562100335956, train_acc = 0.9568001863064741\n",
      "test Acc 0.9441340782122905:\n",
      "9th- epoch: 183, train_loss = 19.101154759526253, train_acc = 0.9568001863064741\n",
      "test Acc 0.9441340782122905:\n",
      "9th- epoch: 184, train_loss = 19.06191306747496, train_acc = 0.9570330693991617\n",
      "test Acc 0.9441340782122905:\n",
      "9th- epoch: 185, train_loss = 19.02243977971375, train_acc = 0.9570330693991617\n",
      "test Acc 0.9441340782122905:\n",
      "9th- epoch: 186, train_loss = 18.982700554654002, train_acc = 0.9571495109455054\n",
      "test Acc 0.9441340782122905:\n",
      "9th- epoch: 187, train_loss = 18.94468709640205, train_acc = 0.9572659524918491\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 188, train_loss = 18.90663486160338, train_acc = 0.9573823940381928\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 189, train_loss = 18.868168072775006, train_acc = 0.9573823940381928\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 190, train_loss = 18.83169093541801, train_acc = 0.9574988355845365\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 191, train_loss = 18.79533009044826, train_acc = 0.9574988355845365\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 192, train_loss = 18.757988700643182, train_acc = 0.9574988355845365\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 193, train_loss = 18.7220103982836, train_acc = 0.9576152771308803\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 194, train_loss = 18.68603060208261, train_acc = 0.9577317186772241\n",
      "test Acc 0.9450651769087524:\n",
      "9th- epoch: 195, train_loss = 18.650432428345084, train_acc = 0.9577317186772241\n",
      "test Acc 0.9450651769087524:\n",
      "9th- epoch: 196, train_loss = 18.614495219662786, train_acc = 0.9578481602235678\n",
      "test Acc 0.9450651769087524:\n",
      "9th- epoch: 197, train_loss = 18.579573426395655, train_acc = 0.9578481602235678\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 198, train_loss = 18.544714238494635, train_acc = 0.9579646017699115\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 199, train_loss = 18.51067023165524, train_acc = 0.9580810433162552\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 200, train_loss = 18.476485515013337, train_acc = 0.9580810433162552\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 201, train_loss = 18.44282249175012, train_acc = 0.9580810433162552\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 202, train_loss = 18.409628411754966, train_acc = 0.9585468095016302\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 203, train_loss = 18.376651598140597, train_acc = 0.9585468095016302\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 204, train_loss = 18.343415092676878, train_acc = 0.9585468095016302\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 205, train_loss = 18.309307290241122, train_acc = 0.9586632510479739\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 206, train_loss = 18.277288280427456, train_acc = 0.9587796925943176\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 207, train_loss = 18.245601816102862, train_acc = 0.9586632510479739\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 208, train_loss = 18.213653111830354, train_acc = 0.9586632510479739\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 209, train_loss = 18.182876605540514, train_acc = 0.9587796925943176\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 210, train_loss = 18.150710374116898, train_acc = 0.9590125756870052\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 211, train_loss = 18.120601827278733, train_acc = 0.9590125756870052\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 212, train_loss = 18.088732853531837, train_acc = 0.9592454587796926\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 213, train_loss = 18.058646347373724, train_acc = 0.9592454587796926\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 214, train_loss = 18.028713716194034, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 215, train_loss = 17.999834114685655, train_acc = 0.95947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 216, train_loss = 17.96906680241227, train_acc = 0.95947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 217, train_loss = 17.94111673347652, train_acc = 0.9598276665114113\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 218, train_loss = 17.91187526844442, train_acc = 0.959944108057755\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 219, train_loss = 17.882681528106332, train_acc = 0.959944108057755\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 220, train_loss = 17.854442035779357, train_acc = 0.9601769911504425\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 221, train_loss = 17.825747299939394, train_acc = 0.9602934326967862\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 222, train_loss = 17.79770495556295, train_acc = 0.9602934326967862\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 223, train_loss = 17.771349092945457, train_acc = 0.9602934326967862\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 224, train_loss = 17.742182044312358, train_acc = 0.96040987424313\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 225, train_loss = 17.715511351823807, train_acc = 0.96040987424313\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 226, train_loss = 17.687112361192703, train_acc = 0.96040987424313\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 227, train_loss = 17.661571078002453, train_acc = 0.96040987424313\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 228, train_loss = 17.6356256660074, train_acc = 0.96040987424313\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 229, train_loss = 17.609606688842177, train_acc = 0.9605263157894737\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 230, train_loss = 17.582894317805767, train_acc = 0.9606427573358174\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 231, train_loss = 17.55627758987248, train_acc = 0.9607591988821611\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 232, train_loss = 17.528300939127803, train_acc = 0.9607591988821611\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 233, train_loss = 17.503220034763217, train_acc = 0.9607591988821611\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 234, train_loss = 17.47793784737587, train_acc = 0.9607591988821611\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 235, train_loss = 17.45355394296348, train_acc = 0.9608756404285049\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 236, train_loss = 17.428847670555115, train_acc = 0.9608756404285049\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 237, train_loss = 17.404017569497228, train_acc = 0.9609920819748486\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 238, train_loss = 17.378962324932218, train_acc = 0.9609920819748486\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 239, train_loss = 17.354765282943845, train_acc = 0.9609920819748486\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 240, train_loss = 17.330848375335336, train_acc = 0.9609920819748486\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 241, train_loss = 17.307012913748622, train_acc = 0.9611085235211924\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 242, train_loss = 17.282954316586256, train_acc = 0.9611085235211924\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 243, train_loss = 17.259785128757358, train_acc = 0.9611085235211924\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 244, train_loss = 17.23649825528264, train_acc = 0.9611085235211924\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 245, train_loss = 17.214761861599982, train_acc = 0.9612249650675361\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 246, train_loss = 17.18964060395956, train_acc = 0.9611085235211924\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 247, train_loss = 17.16647734772414, train_acc = 0.9611085235211924\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 248, train_loss = 17.1451338455081, train_acc = 0.9613414066138798\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 249, train_loss = 17.12218588218093, train_acc = 0.9615742897065673\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 250, train_loss = 17.100006606429815, train_acc = 0.9615742897065673\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 251, train_loss = 17.078012543730438, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 252, train_loss = 17.05535639822483, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 253, train_loss = 17.03375395294279, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 254, train_loss = 17.01181282196194, train_acc = 0.9618071727992548\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 255, train_loss = 16.99071462173015, train_acc = 0.9618071727992548\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 256, train_loss = 16.969550211913884, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 257, train_loss = 16.948494791053236, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 258, train_loss = 16.926674891263247, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 259, train_loss = 16.906381625682116, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 260, train_loss = 16.885720648802817, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 261, train_loss = 16.865763415582478, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 262, train_loss = 16.844092070125043, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 263, train_loss = 16.82479092106223, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 264, train_loss = 16.80500086490065, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 265, train_loss = 16.784306538291276, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 266, train_loss = 16.7651123739779, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 267, train_loss = 16.744617893360555, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 268, train_loss = 16.72579691465944, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 269, train_loss = 16.705837258137763, train_acc = 0.9622729389846297\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 270, train_loss = 16.68648528587073, train_acc = 0.9622729389846297\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 271, train_loss = 16.66732116509229, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 272, train_loss = 16.648754916153848, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 273, train_loss = 16.62962470203638, train_acc = 0.9625058220773172\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 274, train_loss = 16.611624781042337, train_acc = 0.9628551467163484\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 275, train_loss = 16.592837150208652, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 276, train_loss = 16.574979479424655, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 277, train_loss = 16.555365002714097, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 278, train_loss = 16.536555907689035, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 279, train_loss = 16.51892910990864, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 280, train_loss = 16.50076308567077, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 281, train_loss = 16.482911157421768, train_acc = 0.9634373544480671\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 282, train_loss = 16.46401780191809, train_acc = 0.9635537959944108\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 283, train_loss = 16.44788068998605, train_acc = 0.9635537959944108\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 284, train_loss = 16.429856988601387, train_acc = 0.9636702375407545\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 285, train_loss = 16.41203507129103, train_acc = 0.9636702375407545\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 286, train_loss = 16.39467070158571, train_acc = 0.9635537959944108\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 287, train_loss = 16.37770999222994, train_acc = 0.9635537959944108\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 288, train_loss = 16.3607294857502, train_acc = 0.9635537959944108\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 289, train_loss = 16.343935473822057, train_acc = 0.9635537959944108\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 290, train_loss = 16.328477648086846, train_acc = 0.9635537959944108\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 291, train_loss = 16.310767523944378, train_acc = 0.9636702375407545\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 292, train_loss = 16.293333873152733, train_acc = 0.9637866790870983\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 293, train_loss = 16.277081950567663, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 294, train_loss = 16.261158137582242, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 295, train_loss = 16.244759866036475, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 296, train_loss = 16.2287581525743, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 297, train_loss = 16.21406179945916, train_acc = 0.9642524452724732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 298, train_loss = 16.19707679376006, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 299, train_loss = 16.179960299283266, train_acc = 0.9643688868188169\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 300, train_loss = 16.165329571813345, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 301, train_loss = 16.149973939172924, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 302, train_loss = 16.13276239577681, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 303, train_loss = 16.117290121503174, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 304, train_loss = 16.102610270492733, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 305, train_loss = 16.087169650010765, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 306, train_loss = 16.071969679556787, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 307, train_loss = 16.056557051837444, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 308, train_loss = 16.04242143407464, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 309, train_loss = 16.027613434009254, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 310, train_loss = 16.011779055930674, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 311, train_loss = 15.99775443971157, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 312, train_loss = 15.98353948444128, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 313, train_loss = 15.967740222811699, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 314, train_loss = 15.954879720695317, train_acc = 0.9648346530041919\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 315, train_loss = 15.939259889535606, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 316, train_loss = 15.92564097698778, train_acc = 0.9648346530041919\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 317, train_loss = 15.91214066836983, train_acc = 0.9648346530041919\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 318, train_loss = 15.896885213442147, train_acc = 0.9649510945505356\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 319, train_loss = 15.882103378884494, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 320, train_loss = 15.86901830509305, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 321, train_loss = 15.854684241116047, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 322, train_loss = 15.840851263143122, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 323, train_loss = 15.828394559212029, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 324, train_loss = 15.81406035181135, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 325, train_loss = 15.800187618471682, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 326, train_loss = 15.787157188169658, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 327, train_loss = 15.772282421588898, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 328, train_loss = 15.75979866553098, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 329, train_loss = 15.74682016018778, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 330, train_loss = 15.73278496786952, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 331, train_loss = 15.718834832310677, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 332, train_loss = 15.70627690013498, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 333, train_loss = 15.693384568206966, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 334, train_loss = 15.681162050925195, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 335, train_loss = 15.667958623729646, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 336, train_loss = 15.655159193091094, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 337, train_loss = 15.642223168164492, train_acc = 0.9649510945505356\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 338, train_loss = 15.628959734924138, train_acc = 0.9649510945505356\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 339, train_loss = 15.616065368056297, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 340, train_loss = 15.603049187920988, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 341, train_loss = 15.59002086520195, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 342, train_loss = 15.578684739768505, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 343, train_loss = 15.566429015249014, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 344, train_loss = 15.553756062872708, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 345, train_loss = 15.543638157658279, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 346, train_loss = 15.53080177679658, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 347, train_loss = 15.517885942012072, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 348, train_loss = 15.50628883112222, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 349, train_loss = 15.493713580071926, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 350, train_loss = 15.481154189445078, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 351, train_loss = 15.472337233833969, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 352, train_loss = 15.459545063786209, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 353, train_loss = 15.44793422613293, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 354, train_loss = 15.437286195345223, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 355, train_loss = 15.425987648777664, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 356, train_loss = 15.412450719624758, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 357, train_loss = 15.40270135551691, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 358, train_loss = 15.391378704458475, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 359, train_loss = 15.380636704154313, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 360, train_loss = 15.367633499205112, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 361, train_loss = 15.358121883124113, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 362, train_loss = 15.34671773482114, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 363, train_loss = 15.335002637468278, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 364, train_loss = 15.325554906390607, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 365, train_loss = 15.312483835965395, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 366, train_loss = 15.3023785604164, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 367, train_loss = 15.290831151418388, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 368, train_loss = 15.279548790305853, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 369, train_loss = 15.26943810749799, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 370, train_loss = 15.259497459046543, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 371, train_loss = 15.247946459800005, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 372, train_loss = 15.2378167854622, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 373, train_loss = 15.228352464735508, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 374, train_loss = 15.216535546816885, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 375, train_loss = 15.205641522072256, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 376, train_loss = 15.194604742340744, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 377, train_loss = 15.185305529274046, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 378, train_loss = 15.174560737796128, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 379, train_loss = 15.165103319101036, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 380, train_loss = 15.154903291724622, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 381, train_loss = 15.145256344228983, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 382, train_loss = 15.134533107280731, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 383, train_loss = 15.126559242606163, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 384, train_loss = 15.114509395323694, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 385, train_loss = 15.105701074935496, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 386, train_loss = 15.094041003845632, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 387, train_loss = 15.08606472145766, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 388, train_loss = 15.075966182164848, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 389, train_loss = 15.066863469779491, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 390, train_loss = 15.055278201587498, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 391, train_loss = 15.047762495465577, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 392, train_loss = 15.03687905240804, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 393, train_loss = 15.028583948500454, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 394, train_loss = 15.018490456975996, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 395, train_loss = 15.008418455719948, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 396, train_loss = 14.999736522324383, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 397, train_loss = 14.991209290921688, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 398, train_loss = 14.981459797360003, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 399, train_loss = 14.97187428176403, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 400, train_loss = 14.963053417392075, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 401, train_loss = 14.953477002680302, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 402, train_loss = 14.944324307143688, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 403, train_loss = 14.935523652471602, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 404, train_loss = 14.927518792450428, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 405, train_loss = 14.917901548556983, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 406, train_loss = 14.907648082822561, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 407, train_loss = 14.900211920030415, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 408, train_loss = 14.891462299972773, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 409, train_loss = 14.882795866578817, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 410, train_loss = 14.872806400991976, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 411, train_loss = 14.864786479622126, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 412, train_loss = 14.856359734199941, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 413, train_loss = 14.847319488413632, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 414, train_loss = 14.839244629256427, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 415, train_loss = 14.830463808961213, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 416, train_loss = 14.821975025348365, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 417, train_loss = 14.81327201705426, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 418, train_loss = 14.806604706682265, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 419, train_loss = 14.798954204656184, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 420, train_loss = 14.788544616661966, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 421, train_loss = 14.780399017035961, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 422, train_loss = 14.77166451048106, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 423, train_loss = 14.764222255907953, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 424, train_loss = 14.75606491882354, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 425, train_loss = 14.748412269167602, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 426, train_loss = 14.740399221889675, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 427, train_loss = 14.733454089611769, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 428, train_loss = 14.724362845532596, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 429, train_loss = 14.717932323925197, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 430, train_loss = 14.709018918685615, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 431, train_loss = 14.701566540636122, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 432, train_loss = 14.693225589580834, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 433, train_loss = 14.687328689731658, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 434, train_loss = 14.67788225132972, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 435, train_loss = 14.670177858322859, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 436, train_loss = 14.662764335982502, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 437, train_loss = 14.654327616095543, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 438, train_loss = 14.6475287117064, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 439, train_loss = 14.638170402497053, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 440, train_loss = 14.63377076992765, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 441, train_loss = 14.624702545348555, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 442, train_loss = 14.617655159439892, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 443, train_loss = 14.609904402401298, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 444, train_loss = 14.602200417313725, train_acc = 0.9672799254774104\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 445, train_loss = 14.594470927957445, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 446, train_loss = 14.587341765407473, train_acc = 0.9673963670237541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 447, train_loss = 14.580204661935568, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 448, train_loss = 14.57207045191899, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 449, train_loss = 14.56553727015853, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 450, train_loss = 14.558614874724299, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 451, train_loss = 14.55202400078997, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 452, train_loss = 14.544648515526205, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 453, train_loss = 14.536532861646265, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 454, train_loss = 14.529765753541142, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 455, train_loss = 14.523650503251702, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 456, train_loss = 14.516379871871322, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 457, train_loss = 14.508599034044892, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 458, train_loss = 14.501587002072483, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 459, train_loss = 14.494509109761566, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 460, train_loss = 14.487067496869713, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 461, train_loss = 14.481474285479635, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 462, train_loss = 14.473125285003334, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 463, train_loss = 14.467283209320158, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 464, train_loss = 14.459490716457367, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 465, train_loss = 14.45423607667908, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 466, train_loss = 14.44571648305282, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 467, train_loss = 14.439384145196527, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 468, train_loss = 14.43453941354528, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 469, train_loss = 14.425667451228946, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 470, train_loss = 14.422827824950218, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 471, train_loss = 14.413802677299827, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 472, train_loss = 14.4075065725483, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 473, train_loss = 14.400902369525284, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 474, train_loss = 14.393393730279058, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "9th- epoch: 475, train_loss = 14.38765654573217, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 476, train_loss = 14.382090745028108, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 477, train_loss = 14.373873175587505, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 478, train_loss = 14.367033336311579, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 479, train_loss = 14.363089086022228, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "9th- epoch: 480, train_loss = 14.35455418145284, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "9th- epoch: 481, train_loss = 14.34837881103158, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 482, train_loss = 14.342464378569275, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "9th- epoch: 483, train_loss = 14.33702601864934, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "9th- epoch: 484, train_loss = 14.329536797944456, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "9th- epoch: 485, train_loss = 14.324461597949266, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "9th- epoch: 486, train_loss = 14.31703870370984, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "9th- epoch: 487, train_loss = 14.311318470630795, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "9th- epoch: 488, train_loss = 14.305805134121329, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "9th- epoch: 489, train_loss = 14.298197641968727, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "9th- epoch: 490, train_loss = 14.294290045741946, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "9th- epoch: 491, train_loss = 14.285665158182383, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "9th- epoch: 492, train_loss = 14.281370082404464, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "9th- epoch: 493, train_loss = 14.278707257006317, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "9th- epoch: 494, train_loss = 14.2684336588718, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "9th- epoch: 495, train_loss = 14.262819883879274, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "9th- epoch: 496, train_loss = 14.261026042047888, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "9th- epoch: 497, train_loss = 14.254622081760317, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "9th- epoch: 498, train_loss = 14.244305131491274, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "9th- epoch: 499, train_loss = 14.239794434513897, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████████████▉                                                   | 9/30 [59:51<2:19:44, 399.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "10th- epoch: 0, train_loss = 276.93775272369385, train_acc = 0.38670237540754543\n",
      "test Acc 0.4925512104283054:\n",
      "10th- epoch: 1, train_loss = 217.7094842195511, train_acc = 0.4980204937121565\n",
      "test Acc 0.4995344506517691:\n",
      "10th- epoch: 2, train_loss = 181.1441216468811, train_acc = 0.504424778761062\n",
      "test Acc 0.5097765363128491:\n",
      "10th- epoch: 3, train_loss = 163.37178510427475, train_acc = 0.5380763856544015\n",
      "test Acc 0.5763500931098696:\n",
      "10th- epoch: 4, train_loss = 149.90887773036957, train_acc = 0.5954820680018631\n",
      "test Acc 0.6182495344506518:\n",
      "10th- epoch: 5, train_loss = 138.18388736248016, train_acc = 0.6238938053097345\n",
      "test Acc 0.638268156424581:\n",
      "10th- epoch: 6, train_loss = 127.77747744321823, train_acc = 0.6394969725197951\n",
      "test Acc 0.6494413407821229:\n",
      "10th- epoch: 7, train_loss = 118.45061767101288, train_acc = 0.6844434094084769\n",
      "test Acc 0.744413407821229:\n",
      "10th- epoch: 8, train_loss = 109.93933868408203, train_acc = 0.757918025151374\n",
      "test Acc 0.7742085661080075:\n",
      "10th- epoch: 9, train_loss = 102.07068890333176, train_acc = 0.7873777363763391\n",
      "test Acc 0.8012104283054003:\n",
      "10th- epoch: 10, train_loss = 94.7535443007946, train_acc = 0.80985095482068\n",
      "test Acc 0.8212290502793296:\n",
      "10th- epoch: 11, train_loss = 88.04479059576988, train_acc = 0.8247554727526781\n",
      "test Acc 0.8356610800744879:\n",
      "10th- epoch: 12, train_loss = 81.99115666747093, train_acc = 0.838029809035864\n",
      "test Acc 0.8519553072625698:\n",
      "10th- epoch: 13, train_loss = 76.59922003746033, train_acc = 0.8485095482068001\n",
      "test Acc 0.8575418994413407:\n",
      "10th- epoch: 14, train_loss = 71.84175327420235, train_acc = 0.8571262226362366\n",
      "test Acc 0.8621973929236499:\n",
      "10th- epoch: 15, train_loss = 67.68037432432175, train_acc = 0.8629482999534234\n",
      "test Acc 0.8677839851024208:\n",
      "10th- epoch: 16, train_loss = 64.04748991131783, train_acc = 0.8677224033535166\n",
      "test Acc 0.8747672253258846:\n",
      "10th- epoch: 17, train_loss = 60.87004417181015, train_acc = 0.871914299021891\n",
      "test Acc 0.8789571694599627:\n",
      "10th- epoch: 18, train_loss = 58.086925595998764, train_acc = 0.8762226362366092\n",
      "test Acc 0.8836126629422719:\n",
      "10th- epoch: 19, train_loss = 55.64286734163761, train_acc = 0.8809967396367023\n",
      "test Acc 0.8878026070763501:\n",
      "10th- epoch: 20, train_loss = 53.489250645041466, train_acc = 0.8858872845831393\n",
      "test Acc 0.8952513966480447:\n",
      "10th- epoch: 21, train_loss = 51.5826268941164, train_acc = 0.8931066604564508\n",
      "test Acc 0.8980446927374302:\n",
      "10th- epoch: 22, train_loss = 49.88579639792442, train_acc = 0.8955519329296693\n",
      "test Acc 0.8999068901303539:\n",
      "10th- epoch: 23, train_loss = 48.370090782642365, train_acc = 0.8972985561248253\n",
      "test Acc 0.9017690875232774:\n",
      "10th- epoch: 24, train_loss = 47.011122703552246, train_acc = 0.8990451793199814\n",
      "test Acc 0.904562383612663:\n",
      "10th- epoch: 25, train_loss = 45.787062615156174, train_acc = 0.9012575687005123\n",
      "test Acc 0.9068901303538175:\n",
      "10th- epoch: 26, train_loss = 44.678875774145126, train_acc = 0.9035863996273871\n",
      "test Acc 0.9082867783985102:\n",
      "10th- epoch: 27, train_loss = 43.671526342630386, train_acc = 0.905798789007918\n",
      "test Acc 0.910148975791434:\n",
      "10th- epoch: 28, train_loss = 42.74857139587402, train_acc = 0.9073125291103866\n",
      "test Acc 0.9106145251396648:\n",
      "10th- epoch: 29, train_loss = 41.89890560507774, train_acc = 0.9083605030274802\n",
      "test Acc 0.9110800744878957:\n",
      "10th- epoch: 30, train_loss = 41.11248937249184, train_acc = 0.9095249184909175\n",
      "test Acc 0.9124767225325885:\n",
      "10th- epoch: 31, train_loss = 40.38263896107674, train_acc = 0.911970190964136\n",
      "test Acc 0.9124767225325885:\n",
      "10th- epoch: 32, train_loss = 39.70321646332741, train_acc = 0.9142990218910108\n",
      "test Acc 0.9134078212290503:\n",
      "10th- epoch: 33, train_loss = 39.0678980499506, train_acc = 0.9158127619934793\n",
      "test Acc 0.9166666666666666:\n",
      "10th- epoch: 34, train_loss = 38.4699734300375, train_acc = 0.9169771774569166\n",
      "test Acc 0.9162011173184358:\n",
      "10th- epoch: 35, train_loss = 37.90726675093174, train_acc = 0.918141592920354\n",
      "test Acc 0.9166666666666666:\n",
      "10th- epoch: 36, train_loss = 37.37760649621487, train_acc = 0.9191895668374476\n",
      "test Acc 0.9171322160148976:\n",
      "10th- epoch: 37, train_loss = 36.87632651627064, train_acc = 0.9201210992081975\n",
      "test Acc 0.9180633147113594:\n",
      "10th- epoch: 38, train_loss = 36.39992681145668, train_acc = 0.9209361900326036\n",
      "test Acc 0.9180633147113594:\n",
      "10th- epoch: 39, train_loss = 35.946345657110214, train_acc = 0.9218677224033535\n",
      "test Acc 0.9194599627560521:\n",
      "10th- epoch: 40, train_loss = 35.515190839767456, train_acc = 0.922566371681416\n",
      "test Acc 0.9203910614525139:\n",
      "10th- epoch: 41, train_loss = 35.104467146098614, train_acc = 0.9231485794131346\n",
      "test Acc 0.9213221601489758:\n",
      "10th- epoch: 42, train_loss = 34.71223494410515, train_acc = 0.9244294364229158\n",
      "test Acc 0.9241154562383612:\n",
      "10th- epoch: 43, train_loss = 34.33721794933081, train_acc = 0.9247787610619469\n",
      "test Acc 0.9250465549348231:\n",
      "10th- epoch: 44, train_loss = 33.97742857038975, train_acc = 0.9254774103400093\n",
      "test Acc 0.925512104283054:\n",
      "10th- epoch: 45, train_loss = 33.63253717124462, train_acc = 0.9264089427107592\n",
      "test Acc 0.9259776536312849:\n",
      "10th- epoch: 46, train_loss = 33.300525940954685, train_acc = 0.9275733581741965\n",
      "test Acc 0.9264432029795159:\n",
      "10th- epoch: 47, train_loss = 32.98143194615841, train_acc = 0.9280391243595715\n",
      "test Acc 0.9264432029795159:\n",
      "10th- epoch: 48, train_loss = 32.67391259968281, train_acc = 0.9288542151839776\n",
      "test Acc 0.9269087523277467:\n",
      "10th- epoch: 49, train_loss = 32.3768043294549, train_acc = 0.9295528644620401\n",
      "test Acc 0.9269087523277467:\n",
      "10th- epoch: 50, train_loss = 32.08962274342775, train_acc = 0.9301350721937587\n",
      "test Acc 0.9273743016759777:\n",
      "10th- epoch: 51, train_loss = 31.811863735318184, train_acc = 0.9304843968327899\n",
      "test Acc 0.9273743016759777:\n",
      "10th- epoch: 52, train_loss = 31.54259019345045, train_acc = 0.9306008383791337\n",
      "test Acc 0.9278398510242085:\n",
      "10th- epoch: 53, train_loss = 31.280861660838127, train_acc = 0.9307172799254774\n",
      "test Acc 0.9278398510242085:\n",
      "10th- epoch: 54, train_loss = 31.027561597526073, train_acc = 0.9311830461108523\n",
      "test Acc 0.9278398510242085:\n",
      "10th- epoch: 55, train_loss = 30.78040501475334, train_acc = 0.9316488122962273\n",
      "test Acc 0.9278398510242085:\n",
      "10th- epoch: 56, train_loss = 30.539523027837276, train_acc = 0.9321145784816023\n",
      "test Acc 0.9287709497206704:\n",
      "10th- epoch: 57, train_loss = 30.305736683309078, train_acc = 0.9325803446669771\n",
      "test Acc 0.9287709497206704:\n",
      "10th- epoch: 58, train_loss = 30.07803189754486, train_acc = 0.9335118770377271\n",
      "test Acc 0.9287709497206704:\n",
      "10th- epoch: 59, train_loss = 29.85578364878893, train_acc = 0.9336283185840708\n",
      "test Acc 0.9292364990689013:\n",
      "10th- epoch: 60, train_loss = 29.639382503926754, train_acc = 0.9342105263157895\n",
      "test Acc 0.9292364990689013:\n",
      "10th- epoch: 61, train_loss = 29.42755452543497, train_acc = 0.9347927340475082\n",
      "test Acc 0.9292364990689013:\n",
      "10th- epoch: 62, train_loss = 29.22088986635208, train_acc = 0.9347927340475082\n",
      "test Acc 0.9292364990689013:\n",
      "10th- epoch: 63, train_loss = 29.019073516130447, train_acc = 0.9349091755938519\n",
      "test Acc 0.9297020484171322:\n",
      "10th- epoch: 64, train_loss = 28.821209639310837, train_acc = 0.9351420586865393\n",
      "test Acc 0.9297020484171322:\n",
      "10th- epoch: 65, train_loss = 28.626929953694344, train_acc = 0.9353749417792269\n",
      "test Acc 0.9297020484171322:\n",
      "10th- epoch: 66, train_loss = 28.436412043869495, train_acc = 0.935724266418258\n",
      "test Acc 0.9297020484171322:\n",
      "10th- epoch: 67, train_loss = 28.249467507004738, train_acc = 0.9363064741499767\n",
      "test Acc 0.9297020484171322:\n",
      "10th- epoch: 68, train_loss = 28.06707525998354, train_acc = 0.936655798789008\n",
      "test Acc 0.9297020484171322:\n",
      "10th- epoch: 69, train_loss = 27.888698160648346, train_acc = 0.9368886818816954\n",
      "test Acc 0.9292364990689013:\n",
      "10th- epoch: 70, train_loss = 27.713849000632763, train_acc = 0.9372380065207266\n",
      "test Acc 0.9297020484171322:\n",
      "10th- epoch: 71, train_loss = 27.542679898440838, train_acc = 0.9372380065207266\n",
      "test Acc 0.9297020484171322:\n",
      "10th- epoch: 72, train_loss = 27.374438360333443, train_acc = 0.9372380065207266\n",
      "test Acc 0.9301675977653632:\n",
      "10th- epoch: 73, train_loss = 27.209902249276638, train_acc = 0.937936655798789\n",
      "test Acc 0.930633147113594:\n",
      "10th- epoch: 74, train_loss = 27.04809983074665, train_acc = 0.9381695388914765\n",
      "test Acc 0.930633147113594:\n",
      "10th- epoch: 75, train_loss = 26.88986050710082, train_acc = 0.9386353050768514\n",
      "test Acc 0.930633147113594:\n",
      "10th- epoch: 76, train_loss = 26.73464708402753, train_acc = 0.9388681881695389\n",
      "test Acc 0.930633147113594:\n",
      "10th- epoch: 77, train_loss = 26.582552671432495, train_acc = 0.939683278993945\n",
      "test Acc 0.930633147113594:\n",
      "10th- epoch: 78, train_loss = 26.434036392718554, train_acc = 0.9402654867256637\n",
      "test Acc 0.931098696461825:\n",
      "10th- epoch: 79, train_loss = 26.286691423505545, train_acc = 0.9407312529110387\n",
      "test Acc 0.931098696461825:\n",
      "10th- epoch: 80, train_loss = 26.143196385353804, train_acc = 0.9409641360037261\n",
      "test Acc 0.931098696461825:\n",
      "10th- epoch: 81, train_loss = 26.00279114022851, train_acc = 0.941429902189101\n",
      "test Acc 0.930633147113594:\n",
      "10th- epoch: 82, train_loss = 25.86500507220626, train_acc = 0.941895668374476\n",
      "test Acc 0.931098696461825:\n",
      "10th- epoch: 83, train_loss = 25.729488223791122, train_acc = 0.9420121099208197\n",
      "test Acc 0.931098696461825:\n",
      "10th- epoch: 84, train_loss = 25.596766985952854, train_acc = 0.9422449930135072\n",
      "test Acc 0.931098696461825:\n",
      "10th- epoch: 85, train_loss = 25.46668641269207, train_acc = 0.9425943176525384\n",
      "test Acc 0.931098696461825:\n",
      "10th- epoch: 86, train_loss = 25.339445881545544, train_acc = 0.9428272007452259\n",
      "test Acc 0.9315642458100558:\n",
      "10th- epoch: 87, train_loss = 25.21393048763275, train_acc = 0.9434094084769445\n",
      "test Acc 0.9315642458100558:\n",
      "10th- epoch: 88, train_loss = 25.08989753946662, train_acc = 0.9434094084769445\n",
      "test Acc 0.9324953445065177:\n",
      "10th- epoch: 89, train_loss = 24.9699024297297, train_acc = 0.9436422915696321\n",
      "test Acc 0.9324953445065177:\n",
      "10th- epoch: 90, train_loss = 24.85186492279172, train_acc = 0.9436422915696321\n",
      "test Acc 0.9324953445065177:\n",
      "10th- epoch: 91, train_loss = 24.735265530645847, train_acc = 0.9437587331159758\n",
      "test Acc 0.9324953445065177:\n",
      "10th- epoch: 92, train_loss = 24.621925685554743, train_acc = 0.9442244993013508\n",
      "test Acc 0.9329608938547486:\n",
      "10th- epoch: 93, train_loss = 24.510622523725033, train_acc = 0.9445738239403819\n",
      "test Acc 0.9329608938547486:\n",
      "10th- epoch: 94, train_loss = 24.400655817240477, train_acc = 0.9450395901257569\n",
      "test Acc 0.9338919925512105:\n",
      "10th- epoch: 95, train_loss = 24.29321550950408, train_acc = 0.945388914764788\n",
      "test Acc 0.9343575418994413:\n",
      "10th- epoch: 96, train_loss = 24.18674786016345, train_acc = 0.9456217978574756\n",
      "test Acc 0.9348230912476723:\n",
      "10th- epoch: 97, train_loss = 24.084052242338657, train_acc = 0.945854680950163\n",
      "test Acc 0.9348230912476723:\n",
      "10th- epoch: 98, train_loss = 23.98095442727208, train_acc = 0.9460875640428504\n",
      "test Acc 0.9348230912476723:\n",
      "10th- epoch: 99, train_loss = 23.88099806010723, train_acc = 0.9462040055891943\n",
      "test Acc 0.9352886405959032:\n",
      "10th- epoch: 100, train_loss = 23.78270236775279, train_acc = 0.9465533302282254\n",
      "test Acc 0.9352886405959032:\n",
      "10th- epoch: 101, train_loss = 23.685788363218307, train_acc = 0.9464368886818817\n",
      "test Acc 0.9352886405959032:\n",
      "10th- epoch: 102, train_loss = 23.58965713530779, train_acc = 0.9466697717745691\n",
      "test Acc 0.9352886405959032:\n",
      "10th- epoch: 103, train_loss = 23.495767831802368, train_acc = 0.9469026548672567\n",
      "test Acc 0.9352886405959032:\n",
      "10th- epoch: 104, train_loss = 23.404630176723003, train_acc = 0.9472519795062878\n",
      "test Acc 0.9357541899441341:\n",
      "10th- epoch: 105, train_loss = 23.313626367598772, train_acc = 0.9477177456916628\n",
      "test Acc 0.936219739292365:\n",
      "10th- epoch: 106, train_loss = 23.224541265517473, train_acc = 0.948067070330694\n",
      "test Acc 0.9366852886405959:\n",
      "10th- epoch: 107, train_loss = 23.13589321821928, train_acc = 0.9481835118770378\n",
      "test Acc 0.9371508379888268:\n",
      "10th- epoch: 108, train_loss = 23.049339409917593, train_acc = 0.9481835118770378\n",
      "test Acc 0.9371508379888268:\n",
      "10th- epoch: 109, train_loss = 22.964816447347403, train_acc = 0.9481835118770378\n",
      "test Acc 0.9366852886405959:\n",
      "10th- epoch: 110, train_loss = 22.8804181702435, train_acc = 0.9485328365160689\n",
      "test Acc 0.9371508379888268:\n",
      "10th- epoch: 111, train_loss = 22.79819020628929, train_acc = 0.9485328365160689\n",
      "test Acc 0.9371508379888268:\n",
      "10th- epoch: 112, train_loss = 22.717036116868258, train_acc = 0.9487657196087564\n",
      "test Acc 0.9371508379888268:\n",
      "10th- epoch: 113, train_loss = 22.635583341121674, train_acc = 0.9491150442477876\n",
      "test Acc 0.9371508379888268:\n",
      "10th- epoch: 114, train_loss = 22.55753878131509, train_acc = 0.9491150442477876\n",
      "test Acc 0.9371508379888268:\n",
      "10th- epoch: 115, train_loss = 22.478365123271942, train_acc = 0.9494643688868188\n",
      "test Acc 0.9376163873370578:\n",
      "10th- epoch: 116, train_loss = 22.402243096381426, train_acc = 0.9496972519795063\n",
      "test Acc 0.9380819366852886:\n",
      "10th- epoch: 117, train_loss = 22.326587446033955, train_acc = 0.94981369352585\n",
      "test Acc 0.9380819366852886:\n",
      "10th- epoch: 118, train_loss = 22.253133311867714, train_acc = 0.9499301350721937\n",
      "test Acc 0.9380819366852886:\n",
      "10th- epoch: 119, train_loss = 22.1780455224216, train_acc = 0.9501630181648812\n",
      "test Acc 0.9380819366852886:\n",
      "10th- epoch: 120, train_loss = 22.106618713587523, train_acc = 0.9505123428039124\n",
      "test Acc 0.9380819366852886:\n",
      "10th- epoch: 121, train_loss = 22.03486041352153, train_acc = 0.9507452258965999\n",
      "test Acc 0.9380819366852886:\n",
      "10th- epoch: 122, train_loss = 21.96565217524767, train_acc = 0.9508616674429436\n",
      "test Acc 0.9385474860335196:\n",
      "10th- epoch: 123, train_loss = 21.894862420856953, train_acc = 0.9513274336283186\n",
      "test Acc 0.9385474860335196:\n",
      "10th- epoch: 124, train_loss = 21.826665066182613, train_acc = 0.9513274336283186\n",
      "test Acc 0.9385474860335196:\n",
      "10th- epoch: 125, train_loss = 21.759264890104532, train_acc = 0.951560316721006\n",
      "test Acc 0.9385474860335196:\n",
      "10th- epoch: 126, train_loss = 21.6914731413126, train_acc = 0.9516767582673498\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 127, train_loss = 21.625570073723793, train_acc = 0.951560316721006\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 128, train_loss = 21.56084955483675, train_acc = 0.951560316721006\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 129, train_loss = 21.496115144342184, train_acc = 0.9519096413600373\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 130, train_loss = 21.434583146125078, train_acc = 0.9521425244527247\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 131, train_loss = 21.37208202853799, train_acc = 0.9522589659990685\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 132, train_loss = 21.31046722829342, train_acc = 0.952491849091756\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 133, train_loss = 21.248615939170122, train_acc = 0.9526082906380997\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 134, train_loss = 21.18872807174921, train_acc = 0.9528411737307871\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 135, train_loss = 21.129261381924152, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 136, train_loss = 21.0698135048151, train_acc = 0.9528411737307871\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 137, train_loss = 21.01173596456647, train_acc = 0.9528411737307871\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 138, train_loss = 20.954836800694466, train_acc = 0.9530740568234746\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 139, train_loss = 20.89804381504655, train_acc = 0.9531904983698184\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 140, train_loss = 20.84180500358343, train_acc = 0.9534233814625058\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 141, train_loss = 20.78586110845208, train_acc = 0.9535398230088495\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 142, train_loss = 20.730884544551373, train_acc = 0.9537727061015371\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 143, train_loss = 20.676595129072666, train_acc = 0.9537727061015371\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 144, train_loss = 20.62278580479324, train_acc = 0.9538891476478808\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 145, train_loss = 20.568942369893193, train_acc = 0.9538891476478808\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 146, train_loss = 20.515694998204708, train_acc = 0.9540055891942245\n",
      "test Acc 0.9399441340782123:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 147, train_loss = 20.46458270587027, train_acc = 0.9540055891942245\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 148, train_loss = 20.412695771083236, train_acc = 0.9541220307405682\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 149, train_loss = 20.36306113936007, train_acc = 0.9542384722869119\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 150, train_loss = 20.311897004023194, train_acc = 0.9542384722869119\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 151, train_loss = 20.262148259207606, train_acc = 0.9543549138332557\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 152, train_loss = 20.212612261995673, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 153, train_loss = 20.163597121834755, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 154, train_loss = 20.112916151061654, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 155, train_loss = 20.066819263622165, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 156, train_loss = 20.01780709810555, train_acc = 0.9545877969259432\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 157, train_loss = 19.97174620628357, train_acc = 0.9545877969259432\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 158, train_loss = 19.923164067789912, train_acc = 0.9547042384722869\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 159, train_loss = 19.877298444509506, train_acc = 0.9547042384722869\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 160, train_loss = 19.831563347950578, train_acc = 0.9548206800186306\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 161, train_loss = 19.785285148769617, train_acc = 0.9551700046576619\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 162, train_loss = 19.739443277940154, train_acc = 0.9551700046576619\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 163, train_loss = 19.695794278755784, train_acc = 0.9551700046576619\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 164, train_loss = 19.650748247280717, train_acc = 0.9552864462040056\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 165, train_loss = 19.60645955055952, train_acc = 0.9552864462040056\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 166, train_loss = 19.564507784321904, train_acc = 0.9554028877503493\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 167, train_loss = 19.521350253373384, train_acc = 0.955519329296693\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 168, train_loss = 19.478811990469694, train_acc = 0.9556357708430367\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 169, train_loss = 19.43825226277113, train_acc = 0.9556357708430367\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 170, train_loss = 19.394896138459444, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 171, train_loss = 19.35419343598187, train_acc = 0.955985095482068\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 172, train_loss = 19.311107078567147, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 173, train_loss = 19.272927530109882, train_acc = 0.9562179785747554\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 174, train_loss = 19.23193389363587, train_acc = 0.9563344201210993\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 175, train_loss = 19.192297691479325, train_acc = 0.9563344201210993\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 176, train_loss = 19.153261059895158, train_acc = 0.9563344201210993\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 177, train_loss = 19.113880744203925, train_acc = 0.956450861667443\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 178, train_loss = 19.074366023764014, train_acc = 0.956450861667443\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 179, train_loss = 19.036633100360632, train_acc = 0.9565673032137867\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 180, train_loss = 18.998339680954814, train_acc = 0.9566837447601304\n",
      "test Acc 0.9422718808193669:\n",
      "10th- epoch: 181, train_loss = 18.96088202111423, train_acc = 0.9568001863064741\n",
      "test Acc 0.9422718808193669:\n",
      "10th- epoch: 182, train_loss = 18.92388224415481, train_acc = 0.9570330693991617\n",
      "test Acc 0.9422718808193669:\n",
      "10th- epoch: 183, train_loss = 18.885399652644992, train_acc = 0.9572659524918491\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 184, train_loss = 18.84976065903902, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 185, train_loss = 18.811792220920324, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 186, train_loss = 18.777783032506704, train_acc = 0.9574988355845365\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 187, train_loss = 18.740145886316895, train_acc = 0.9574988355845365\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 188, train_loss = 18.70680576004088, train_acc = 0.9576152771308803\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 189, train_loss = 18.671735048294067, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 190, train_loss = 18.636119497939944, train_acc = 0.9578481602235678\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 191, train_loss = 18.600851668044925, train_acc = 0.9579646017699115\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 192, train_loss = 18.567700946703553, train_acc = 0.9580810433162552\n",
      "test Acc 0.9436685288640596:\n",
      "10th- epoch: 193, train_loss = 18.532974638044834, train_acc = 0.9581974848625989\n",
      "test Acc 0.9436685288640596:\n",
      "10th- epoch: 194, train_loss = 18.500264208763838, train_acc = 0.9581974848625989\n",
      "test Acc 0.9436685288640596:\n",
      "10th- epoch: 195, train_loss = 18.46710597164929, train_acc = 0.9583139264089428\n",
      "test Acc 0.9436685288640596:\n",
      "10th- epoch: 196, train_loss = 18.43447650410235, train_acc = 0.9584303679552865\n",
      "test Acc 0.9436685288640596:\n",
      "10th- epoch: 197, train_loss = 18.401455828920007, train_acc = 0.9585468095016302\n",
      "test Acc 0.9441340782122905:\n",
      "10th- epoch: 198, train_loss = 18.368477802723646, train_acc = 0.9585468095016302\n",
      "test Acc 0.9441340782122905:\n",
      "10th- epoch: 199, train_loss = 18.336637975648046, train_acc = 0.9586632510479739\n",
      "test Acc 0.9441340782122905:\n",
      "10th- epoch: 200, train_loss = 18.305746300145984, train_acc = 0.9586632510479739\n",
      "test Acc 0.9445996275605214:\n",
      "10th- epoch: 201, train_loss = 18.273207837715745, train_acc = 0.9587796925943176\n",
      "test Acc 0.9445996275605214:\n",
      "10th- epoch: 202, train_loss = 18.241711670532823, train_acc = 0.9587796925943176\n",
      "test Acc 0.9445996275605214:\n",
      "10th- epoch: 203, train_loss = 18.210209365934134, train_acc = 0.9587796925943176\n",
      "test Acc 0.9445996275605214:\n",
      "10th- epoch: 204, train_loss = 18.17815311998129, train_acc = 0.9587796925943176\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 205, train_loss = 18.146054031327367, train_acc = 0.9587796925943176\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 206, train_loss = 18.11729739792645, train_acc = 0.9587796925943176\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 207, train_loss = 18.088089542463422, train_acc = 0.9588961341406614\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 208, train_loss = 18.057084122672677, train_acc = 0.9591290172333489\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 209, train_loss = 18.028140472248197, train_acc = 0.9591290172333489\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 210, train_loss = 17.998696679249406, train_acc = 0.9592454587796926\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 211, train_loss = 17.97095595858991, train_acc = 0.9592454587796926\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 212, train_loss = 17.94087346084416, train_acc = 0.9591290172333489\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 213, train_loss = 17.91298566199839, train_acc = 0.9592454587796926\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 214, train_loss = 17.884819701313972, train_acc = 0.9592454587796926\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 215, train_loss = 17.856486592441797, train_acc = 0.9593619003260363\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 216, train_loss = 17.828746870160103, train_acc = 0.9593619003260363\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 217, train_loss = 17.800281167030334, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 218, train_loss = 17.774528263136744, train_acc = 0.95947834187238\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 219, train_loss = 17.746678033843637, train_acc = 0.95947834187238\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 220, train_loss = 17.71954151056707, train_acc = 0.95947834187238\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 221, train_loss = 17.693224234506488, train_acc = 0.9595947834187238\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 222, train_loss = 17.66660842113197, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 223, train_loss = 17.640966434031725, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 224, train_loss = 17.614665960893035, train_acc = 0.9600605496040987\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 225, train_loss = 17.590120078995824, train_acc = 0.9601769911504425\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 226, train_loss = 17.561003979295492, train_acc = 0.9602934326967862\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 227, train_loss = 17.539489466696978, train_acc = 0.9602934326967862\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 228, train_loss = 17.51139031164348, train_acc = 0.9605263157894737\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 229, train_loss = 17.487873638048768, train_acc = 0.9605263157894737\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 230, train_loss = 17.461460886523128, train_acc = 0.9605263157894737\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 231, train_loss = 17.439140746369958, train_acc = 0.9605263157894737\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 232, train_loss = 17.41345659457147, train_acc = 0.9605263157894737\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 233, train_loss = 17.390355175361037, train_acc = 0.9605263157894737\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 234, train_loss = 17.365493731573224, train_acc = 0.9606427573358174\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 235, train_loss = 17.343385186046362, train_acc = 0.9607591988821611\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 236, train_loss = 17.320325069129467, train_acc = 0.9607591988821611\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 237, train_loss = 17.294598264619708, train_acc = 0.9608756404285049\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 238, train_loss = 17.27276768349111, train_acc = 0.9612249650675361\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 239, train_loss = 17.247453339397907, train_acc = 0.9612249650675361\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 240, train_loss = 17.22679732553661, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 241, train_loss = 17.204769445583224, train_acc = 0.9614578481602236\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 242, train_loss = 17.181225411593914, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 243, train_loss = 17.15838195104152, train_acc = 0.961690731252911\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 244, train_loss = 17.13812008406967, train_acc = 0.9619236143455985\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 245, train_loss = 17.11600756365806, train_acc = 0.9619236143455985\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 246, train_loss = 17.09256889205426, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 247, train_loss = 17.069664489477873, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 248, train_loss = 17.04696160275489, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 249, train_loss = 17.027040727436543, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 250, train_loss = 17.005661990493536, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 251, train_loss = 16.98564495611936, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 252, train_loss = 16.964329057373106, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 253, train_loss = 16.944497633725405, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 254, train_loss = 16.92547730822116, train_acc = 0.9622729389846297\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 255, train_loss = 16.900502453558147, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 256, train_loss = 16.881958191283047, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 257, train_loss = 16.861461106687784, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 258, train_loss = 16.841685901395977, train_acc = 0.9625058220773172\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 259, train_loss = 16.82197322230786, train_acc = 0.9625058220773172\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 260, train_loss = 16.803671408444643, train_acc = 0.9625058220773172\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 261, train_loss = 16.783113655634224, train_acc = 0.9625058220773172\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 262, train_loss = 16.764057368971407, train_acc = 0.9625058220773172\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 263, train_loss = 16.742689325474203, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 264, train_loss = 16.724667735397816, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 265, train_loss = 16.705144389532506, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 266, train_loss = 16.68800513073802, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 267, train_loss = 16.668156332336366, train_acc = 0.9628551467163484\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 268, train_loss = 16.650916922837496, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 269, train_loss = 16.631695142947137, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 270, train_loss = 16.611611598171294, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 271, train_loss = 16.59332689922303, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 272, train_loss = 16.575131100602448, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 273, train_loss = 16.557515968568623, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 274, train_loss = 16.539484820328653, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 275, train_loss = 16.523982328362763, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 276, train_loss = 16.503924909047782, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 277, train_loss = 16.48567469511181, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 278, train_loss = 16.470260568894446, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 279, train_loss = 16.453406646847725, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 280, train_loss = 16.43508933763951, train_acc = 0.9636702375407545\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 281, train_loss = 16.41990373749286, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 282, train_loss = 16.400011933408678, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 283, train_loss = 16.38539311196655, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 284, train_loss = 16.367439343594015, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 285, train_loss = 16.350150670856237, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 286, train_loss = 16.33324498217553, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 287, train_loss = 16.318387132138014, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 288, train_loss = 16.302184015512466, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 289, train_loss = 16.283685374073684, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 290, train_loss = 16.27108884602785, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 291, train_loss = 16.25323298573494, train_acc = 0.9641360037261295\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 292, train_loss = 16.23700963612646, train_acc = 0.9641360037261295\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 293, train_loss = 16.220422475598752, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 294, train_loss = 16.205395862460136, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 295, train_loss = 16.190022743307054, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 296, train_loss = 16.172158849425614, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 297, train_loss = 16.159002970904112, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 298, train_loss = 16.142639856785536, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 299, train_loss = 16.12823635339737, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 300, train_loss = 16.113845785148442, train_acc = 0.9642524452724732\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 301, train_loss = 16.09789585787803, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 302, train_loss = 16.083124205470085, train_acc = 0.9642524452724732\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 303, train_loss = 16.066540971398354, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 304, train_loss = 16.05392435286194, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 305, train_loss = 16.0390257043764, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 306, train_loss = 16.025596380233765, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 307, train_loss = 16.00788914691657, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 308, train_loss = 15.9958560699597, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 309, train_loss = 15.980771627277136, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 310, train_loss = 15.966832135803998, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 311, train_loss = 15.953133127652109, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 312, train_loss = 15.93772175628692, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 313, train_loss = 15.925001996569335, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 314, train_loss = 15.910327825695276, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 315, train_loss = 15.89615364279598, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 316, train_loss = 15.883192750625312, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 317, train_loss = 15.86898987274617, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 318, train_loss = 15.853329319506884, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 319, train_loss = 15.84063517022878, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 320, train_loss = 15.826945236884058, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 321, train_loss = 15.811996407806873, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 322, train_loss = 15.800420564599335, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 323, train_loss = 15.788316611200571, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 324, train_loss = 15.77265702188015, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 325, train_loss = 15.758562250994146, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 326, train_loss = 15.74682671111077, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 327, train_loss = 15.733109037391841, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 328, train_loss = 15.719765561632812, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "10th- epoch: 329, train_loss = 15.704991416074336, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 330, train_loss = 15.694303452968597, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 331, train_loss = 15.6809267019853, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 332, train_loss = 15.670589468441904, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 333, train_loss = 15.655733495019376, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 334, train_loss = 15.642916899174452, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 335, train_loss = 15.631720739416778, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 336, train_loss = 15.617899801582098, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 337, train_loss = 15.604360385797918, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 338, train_loss = 15.594983670860529, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 339, train_loss = 15.58231822680682, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 340, train_loss = 15.568034336902201, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 341, train_loss = 15.557494970969856, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 342, train_loss = 15.543443883769214, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 343, train_loss = 15.53330069128424, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 344, train_loss = 15.520831526257098, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 345, train_loss = 15.512059953063726, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 346, train_loss = 15.49880746472627, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 347, train_loss = 15.485963062383235, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 348, train_loss = 15.472783621400595, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 349, train_loss = 15.462497227825224, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 350, train_loss = 15.451866528950632, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 351, train_loss = 15.438877220265567, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 352, train_loss = 15.426356893964112, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 353, train_loss = 15.416846576146781, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 354, train_loss = 15.409318990074098, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 355, train_loss = 15.395954310894012, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 356, train_loss = 15.384650819003582, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 357, train_loss = 15.371869914233685, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 358, train_loss = 15.360342029482126, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "10th- epoch: 359, train_loss = 15.351016237400472, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "10th- epoch: 360, train_loss = 15.341463188640773, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "10th- epoch: 361, train_loss = 15.326494961045682, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "10th- epoch: 362, train_loss = 15.317883539944887, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "10th- epoch: 363, train_loss = 15.305932226590812, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "10th- epoch: 364, train_loss = 15.295700698159635, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "10th- epoch: 365, train_loss = 15.285605292767286, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 366, train_loss = 15.275963730178773, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 367, train_loss = 15.26522208377719, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 368, train_loss = 15.25425460934639, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 369, train_loss = 15.24246884137392, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 370, train_loss = 15.232275946997106, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 371, train_loss = 15.222048359923065, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 372, train_loss = 15.209926494397223, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 373, train_loss = 15.20242475438863, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 374, train_loss = 15.191304485313594, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 375, train_loss = 15.180787220597267, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 376, train_loss = 15.172348751686513, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 377, train_loss = 15.159419470466673, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 378, train_loss = 15.149664009921253, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 379, train_loss = 15.138334322720766, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 380, train_loss = 15.130857297219336, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 381, train_loss = 15.122053109109402, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 382, train_loss = 15.110198908485472, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 383, train_loss = 15.1019082153216, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 384, train_loss = 15.089550985954702, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 385, train_loss = 15.082791400142014, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 386, train_loss = 15.074202553369105, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 387, train_loss = 15.061057883314788, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 388, train_loss = 15.054885786958039, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 389, train_loss = 15.044489494524896, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 390, train_loss = 15.033028601668775, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 391, train_loss = 15.02432455867529, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "10th- epoch: 392, train_loss = 15.017311662435532, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 393, train_loss = 15.004285395145416, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "10th- epoch: 394, train_loss = 14.999306246638298, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 395, train_loss = 14.98747771140188, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "10th- epoch: 396, train_loss = 14.979511100798845, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "10th- epoch: 397, train_loss = 14.970084951259196, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "10th- epoch: 398, train_loss = 14.961248363368213, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 399, train_loss = 14.950663392432034, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 400, train_loss = 14.940256454050541, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 401, train_loss = 14.932899344712496, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 402, train_loss = 14.924984823912382, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 403, train_loss = 14.915968508459628, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 404, train_loss = 14.90823716390878, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 405, train_loss = 14.898473571054637, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 406, train_loss = 14.88990397658199, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 407, train_loss = 14.88061810657382, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 408, train_loss = 14.87279608566314, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 409, train_loss = 14.862392630428076, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 410, train_loss = 14.853914081119001, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 411, train_loss = 14.844915598630905, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 412, train_loss = 14.837272715754807, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 413, train_loss = 14.829033591784537, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 414, train_loss = 14.821158700622618, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 415, train_loss = 14.811539524234831, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 416, train_loss = 14.803725466132164, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 417, train_loss = 14.794038038700819, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 418, train_loss = 14.786921395920217, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 419, train_loss = 14.779557933099568, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 420, train_loss = 14.77118495106697, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 421, train_loss = 14.761874545365572, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 422, train_loss = 14.756007126532495, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 423, train_loss = 14.74579332768917, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 424, train_loss = 14.740429021418095, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 425, train_loss = 14.728445309214294, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 426, train_loss = 14.72491078544408, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 427, train_loss = 14.713553762994707, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 428, train_loss = 14.70867021009326, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 429, train_loss = 14.69664849434048, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 430, train_loss = 14.691689785569906, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 431, train_loss = 14.685507508926094, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 432, train_loss = 14.674327995628119, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 433, train_loss = 14.668947231024504, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 434, train_loss = 14.65915681514889, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 435, train_loss = 14.653763727284968, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 436, train_loss = 14.643832418136299, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 437, train_loss = 14.635874565690756, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 438, train_loss = 14.627349846996367, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 439, train_loss = 14.620547332800925, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 440, train_loss = 14.61069234739989, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 441, train_loss = 14.60527867730707, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 442, train_loss = 14.595878931693733, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 443, train_loss = 14.589947675354779, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 444, train_loss = 14.58238036185503, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 445, train_loss = 14.574544602073729, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 446, train_loss = 14.56963414978236, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 447, train_loss = 14.562011502683163, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 448, train_loss = 14.555582301225513, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 449, train_loss = 14.548132552299649, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "10th- epoch: 450, train_loss = 14.538489618804306, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "10th- epoch: 451, train_loss = 14.530745891388506, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "10th- epoch: 452, train_loss = 14.526392512023449, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "10th- epoch: 453, train_loss = 14.515450944658369, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "10th- epoch: 454, train_loss = 14.509228184819221, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 455, train_loss = 14.505138871725649, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 456, train_loss = 14.494779117405415, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 457, train_loss = 14.492924311663955, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 458, train_loss = 14.481880673673004, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 459, train_loss = 14.47505851695314, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 460, train_loss = 14.469010230153799, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 461, train_loss = 14.46342154359445, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 462, train_loss = 14.455867843236774, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 463, train_loss = 14.449136840645224, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 464, train_loss = 14.439432763960212, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 465, train_loss = 14.435168467462063, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 466, train_loss = 14.428499665111303, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 467, train_loss = 14.421174362301826, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 468, train_loss = 14.414904264267534, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 469, train_loss = 14.40819893265143, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 470, train_loss = 14.400903610046953, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 471, train_loss = 14.39562096586451, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 472, train_loss = 14.387718775775284, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 473, train_loss = 14.381744537502527, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 474, train_loss = 14.375616745557636, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 475, train_loss = 14.36876187985763, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 476, train_loss = 14.362862007226795, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 477, train_loss = 14.355374120175838, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 478, train_loss = 14.349428912159055, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 479, train_loss = 14.341550143901259, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 480, train_loss = 14.336744448635727, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 481, train_loss = 14.330537722911686, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 482, train_loss = 14.324751583393663, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 483, train_loss = 14.318357852753252, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 484, train_loss = 14.311889266129583, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 485, train_loss = 14.30377276847139, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 486, train_loss = 14.299964883830398, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 487, train_loss = 14.291737370193005, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 488, train_loss = 14.287483242806047, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 489, train_loss = 14.280616408679634, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 490, train_loss = 14.274125733878464, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 491, train_loss = 14.267128644045442, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 492, train_loss = 14.262740541249514, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 493, train_loss = 14.255785550922155, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 494, train_loss = 14.25005841255188, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 495, train_loss = 14.245815420057625, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 496, train_loss = 14.238048198167235, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 497, train_loss = 14.232622568961233, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 498, train_loss = 14.226679073181003, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 499, train_loss = 14.222338145133108, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████▎                                              | 10/30 [1:06:32<2:13:14, 399.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "11th- epoch: 0, train_loss = 273.631268620491, train_acc = 0.4139496972519795\n",
      "test Acc 0.49115456238361266:\n",
      "11th- epoch: 1, train_loss = 213.32915663719177, train_acc = 0.4969725197950629\n",
      "test Acc 0.5:\n",
      "11th- epoch: 2, train_loss = 180.1446361541748, train_acc = 0.5058220773171868\n",
      "test Acc 0.5167597765363129:\n",
      "11th- epoch: 3, train_loss = 163.47185266017914, train_acc = 0.5388914764788076\n",
      "test Acc 0.5702979515828678:\n",
      "11th- epoch: 4, train_loss = 150.82424837350845, train_acc = 0.5889613414066138\n",
      "test Acc 0.6121973929236499:\n",
      "11th- epoch: 5, train_loss = 139.63873076438904, train_acc = 0.6197019096413601\n",
      "test Acc 0.6359404096834265:\n",
      "11th- epoch: 6, train_loss = 129.3656097650528, train_acc = 0.6479972054028877\n",
      "test Acc 0.6624767225325885:\n",
      "11th- epoch: 7, train_loss = 119.9883680343628, train_acc = 0.6697717745691663\n",
      "test Acc 0.7430167597765364:\n",
      "11th- epoch: 8, train_loss = 111.44989675283432, train_acc = 0.7136702375407545\n",
      "test Acc 0.7667597765363129:\n",
      "11th- epoch: 9, train_loss = 103.56908416748047, train_acc = 0.7904052165812762\n",
      "test Acc 0.8002793296089385:\n",
      "11th- epoch: 10, train_loss = 96.2485214471817, train_acc = 0.8102002794597112\n",
      "test Acc 0.8156424581005587:\n",
      "11th- epoch: 11, train_loss = 89.4970038831234, train_acc = 0.8230088495575221\n",
      "test Acc 0.8347299813780261:\n",
      "11th- epoch: 12, train_loss = 83.37398186326027, train_acc = 0.8346530041918957\n",
      "test Acc 0.8505586592178771:\n",
      "11th- epoch: 13, train_loss = 77.8927812576294, train_acc = 0.8429203539823009\n",
      "test Acc 0.8584729981378026:\n",
      "11th- epoch: 14, train_loss = 73.06080847978592, train_acc = 0.8513041453190499\n",
      "test Acc 0.8626629422718808:\n",
      "11th- epoch: 15, train_loss = 68.83587059378624, train_acc = 0.8598043782021425\n",
      "test Acc 0.8687150837988827:\n",
      "11th- epoch: 16, train_loss = 65.14240422844887, train_acc = 0.865742897065673\n",
      "test Acc 0.87243947858473:\n",
      "11th- epoch: 17, train_loss = 61.91179195046425, train_acc = 0.8694690265486725\n",
      "test Acc 0.8780260707635009:\n",
      "11th- epoch: 18, train_loss = 59.08128809928894, train_acc = 0.8755239869585468\n",
      "test Acc 0.8812849162011173:\n",
      "11th- epoch: 19, train_loss = 56.59815213084221, train_acc = 0.8808802980903586\n",
      "test Acc 0.8891992551210428:\n",
      "11th- epoch: 20, train_loss = 54.41155178844929, train_acc = 0.8864694923148579\n",
      "test Acc 0.8905959031657356:\n",
      "11th- epoch: 21, train_loss = 52.480145424604416, train_acc = 0.8893805309734514\n",
      "test Acc 0.8924581005586593:\n",
      "11th- epoch: 22, train_loss = 50.768346190452576, train_acc = 0.8907778295295762\n",
      "test Acc 0.8947858472998138:\n",
      "11th- epoch: 23, train_loss = 49.24137422442436, train_acc = 0.8924080111783884\n",
      "test Acc 0.8980446927374302:\n",
      "11th- epoch: 24, train_loss = 47.870649963617325, train_acc = 0.8942710759198882\n",
      "test Acc 0.9013035381750466:\n",
      "11th- epoch: 25, train_loss = 46.639136135578156, train_acc = 0.8982300884955752\n",
      "test Acc 0.9022346368715084:\n",
      "11th- epoch: 26, train_loss = 45.5258174687624, train_acc = 0.8997438285980438\n",
      "test Acc 0.9031657355679702:\n",
      "11th- epoch: 27, train_loss = 44.512501895427704, train_acc = 0.9017233348858873\n",
      "test Acc 0.904096834264432:\n",
      "11th- epoch: 28, train_loss = 43.5859916806221, train_acc = 0.9031206334420121\n",
      "test Acc 0.9064245810055865:\n",
      "11th- epoch: 29, train_loss = 42.73266592621803, train_acc = 0.9052165812761993\n",
      "test Acc 0.9073556797020484:\n",
      "11th- epoch: 30, train_loss = 41.94390028715134, train_acc = 0.9068467629250117\n",
      "test Acc 0.9082867783985102:\n",
      "11th- epoch: 31, train_loss = 41.20972681045532, train_acc = 0.9082440614811365\n",
      "test Acc 0.9087523277467412:\n",
      "11th- epoch: 32, train_loss = 40.5243484377861, train_acc = 0.9097578015836051\n",
      "test Acc 0.910148975791434:\n",
      "11th- epoch: 33, train_loss = 39.8827228397131, train_acc = 0.9116208663251048\n",
      "test Acc 0.9110800744878957:\n",
      "11th- epoch: 34, train_loss = 39.27878347039223, train_acc = 0.9129017233348858\n",
      "test Acc 0.9120111731843575:\n",
      "11th- epoch: 35, train_loss = 38.70749895274639, train_acc = 0.915463437354448\n",
      "test Acc 0.9124767225325885:\n",
      "11th- epoch: 36, train_loss = 38.16537569463253, train_acc = 0.9168607359105729\n",
      "test Acc 0.9138733705772812:\n",
      "11th- epoch: 37, train_loss = 37.650971472263336, train_acc = 0.9180251513740102\n",
      "test Acc 0.9143389199255121:\n",
      "11th- epoch: 38, train_loss = 37.16258090734482, train_acc = 0.9189566837447601\n",
      "test Acc 0.9152700186219739:\n",
      "11th- epoch: 39, train_loss = 36.697481989860535, train_acc = 0.9201210992081975\n",
      "test Acc 0.9162011173184358:\n",
      "11th- epoch: 40, train_loss = 36.25302994251251, train_acc = 0.9212855146716349\n",
      "test Acc 0.9171322160148976:\n",
      "11th- epoch: 41, train_loss = 35.82734817266464, train_acc = 0.9223334885887284\n",
      "test Acc 0.9175977653631285:\n",
      "11th- epoch: 42, train_loss = 35.419690281152725, train_acc = 0.9234979040521658\n",
      "test Acc 0.9194599627560521:\n",
      "11th- epoch: 43, train_loss = 35.028566636145115, train_acc = 0.9240801117838845\n",
      "test Acc 0.9208566108007449:\n",
      "11th- epoch: 44, train_loss = 34.65324718505144, train_acc = 0.9244294364229158\n",
      "test Acc 0.9208566108007449:\n",
      "11th- epoch: 45, train_loss = 34.291220515966415, train_acc = 0.925593851886353\n",
      "test Acc 0.9213221601489758:\n",
      "11th- epoch: 46, train_loss = 33.943084709346294, train_acc = 0.926525384257103\n",
      "test Acc 0.9217877094972067:\n",
      "11th- epoch: 47, train_loss = 33.60712344199419, train_acc = 0.9273404750815091\n",
      "test Acc 0.9227188081936686:\n",
      "11th- epoch: 48, train_loss = 33.282531917095184, train_acc = 0.9279226828132278\n",
      "test Acc 0.9231843575418994:\n",
      "11th- epoch: 49, train_loss = 32.96924927830696, train_acc = 0.9283884489986027\n",
      "test Acc 0.9236499068901304:\n",
      "11th- epoch: 50, train_loss = 32.665975496172905, train_acc = 0.9294364229156963\n",
      "test Acc 0.9236499068901304:\n",
      "11th- epoch: 51, train_loss = 32.370983585715294, train_acc = 0.9295528644620401\n",
      "test Acc 0.9250465549348231:\n",
      "11th- epoch: 52, train_loss = 32.08590940386057, train_acc = 0.9303679552864462\n",
      "test Acc 0.9250465549348231:\n",
      "11th- epoch: 53, train_loss = 31.80945562571287, train_acc = 0.9307172799254774\n",
      "test Acc 0.925512104283054:\n",
      "11th- epoch: 54, train_loss = 31.54061232507229, train_acc = 0.9312994876571961\n",
      "test Acc 0.9259776536312849:\n",
      "11th- epoch: 55, train_loss = 31.279927246272564, train_acc = 0.9314159292035398\n",
      "test Acc 0.9259776536312849:\n",
      "11th- epoch: 56, train_loss = 31.02652456611395, train_acc = 0.9319981369352585\n",
      "test Acc 0.9259776536312849:\n",
      "11th- epoch: 57, train_loss = 30.7801373898983, train_acc = 0.9328132277596647\n",
      "test Acc 0.9259776536312849:\n",
      "11th- epoch: 58, train_loss = 30.540416702628136, train_acc = 0.9330461108523521\n",
      "test Acc 0.9259776536312849:\n",
      "11th- epoch: 59, train_loss = 30.30625957995653, train_acc = 0.9333954354913834\n",
      "test Acc 0.9259776536312849:\n",
      "11th- epoch: 60, train_loss = 30.078486762940884, train_acc = 0.9337447601304145\n",
      "test Acc 0.9264432029795159:\n",
      "11th- epoch: 61, train_loss = 29.85649097710848, train_acc = 0.933977643223102\n",
      "test Acc 0.9264432029795159:\n",
      "11th- epoch: 62, train_loss = 29.6395034044981, train_acc = 0.9342105263157895\n",
      "test Acc 0.9264432029795159:\n",
      "11th- epoch: 63, train_loss = 29.427447997033596, train_acc = 0.9346762925011645\n",
      "test Acc 0.9269087523277467:\n",
      "11th- epoch: 64, train_loss = 29.22055544704199, train_acc = 0.9347927340475082\n",
      "test Acc 0.9273743016759777:\n",
      "11th- epoch: 65, train_loss = 29.01749237626791, train_acc = 0.9353749417792269\n",
      "test Acc 0.9278398510242085:\n",
      "11th- epoch: 66, train_loss = 28.82023384422064, train_acc = 0.9360735910572893\n",
      "test Acc 0.9278398510242085:\n",
      "11th- epoch: 67, train_loss = 28.626488082110882, train_acc = 0.9363064741499767\n",
      "test Acc 0.9283054003724395:\n",
      "11th- epoch: 68, train_loss = 28.438184425234795, train_acc = 0.9363064741499767\n",
      "test Acc 0.9283054003724395:\n",
      "11th- epoch: 69, train_loss = 28.2534367069602, train_acc = 0.9365393572426641\n",
      "test Acc 0.9283054003724395:\n",
      "11th- epoch: 70, train_loss = 28.072169445455074, train_acc = 0.9367722403353517\n",
      "test Acc 0.9283054003724395:\n",
      "11th- epoch: 71, train_loss = 27.895730040967464, train_acc = 0.9374708896134141\n",
      "test Acc 0.9283054003724395:\n",
      "11th- epoch: 72, train_loss = 27.722182616591454, train_acc = 0.937936655798789\n",
      "test Acc 0.9283054003724395:\n",
      "11th- epoch: 73, train_loss = 27.55319242924452, train_acc = 0.9381695388914765\n",
      "test Acc 0.9283054003724395:\n",
      "11th- epoch: 74, train_loss = 27.386763036251068, train_acc = 0.9384024219841639\n",
      "test Acc 0.9283054003724395:\n",
      "11th- epoch: 75, train_loss = 27.2242945805192, train_acc = 0.9387517466231952\n",
      "test Acc 0.9287709497206704:\n",
      "11th- epoch: 76, train_loss = 27.064609207212925, train_acc = 0.9392175128085701\n",
      "test Acc 0.9292364990689013:\n",
      "11th- epoch: 77, train_loss = 26.908060152083635, train_acc = 0.9394503959012576\n",
      "test Acc 0.9292364990689013:\n",
      "11th- epoch: 78, train_loss = 26.754921685904264, train_acc = 0.9397997205402888\n",
      "test Acc 0.9292364990689013:\n",
      "11th- epoch: 79, train_loss = 26.604456175118685, train_acc = 0.9399161620866325\n",
      "test Acc 0.9292364990689013:\n",
      "11th- epoch: 80, train_loss = 26.456622634083033, train_acc = 0.9403819282720075\n",
      "test Acc 0.9301675977653632:\n",
      "11th- epoch: 81, train_loss = 26.312285117805004, train_acc = 0.9404983698183512\n",
      "test Acc 0.9301675977653632:\n",
      "11th- epoch: 82, train_loss = 26.169758524745703, train_acc = 0.9410805775500699\n",
      "test Acc 0.930633147113594:\n",
      "11th- epoch: 83, train_loss = 26.030725233256817, train_acc = 0.9416627852817886\n",
      "test Acc 0.931098696461825:\n",
      "11th- epoch: 84, train_loss = 25.894865203648806, train_acc = 0.9421285514671635\n",
      "test Acc 0.931098696461825:\n",
      "11th- epoch: 85, train_loss = 25.761450473219156, train_acc = 0.9424778761061947\n",
      "test Acc 0.9315642458100558:\n",
      "11th- epoch: 86, train_loss = 25.630155220627785, train_acc = 0.9429436422915697\n",
      "test Acc 0.9315642458100558:\n",
      "11th- epoch: 87, train_loss = 25.501729629933834, train_acc = 0.9437587331159758\n",
      "test Acc 0.9315642458100558:\n",
      "11th- epoch: 88, train_loss = 25.37566701695323, train_acc = 0.9438751746623195\n",
      "test Acc 0.9315642458100558:\n",
      "11th- epoch: 89, train_loss = 25.25128698348999, train_acc = 0.9442244993013508\n",
      "test Acc 0.9315642458100558:\n",
      "11th- epoch: 90, train_loss = 25.129892833530903, train_acc = 0.9446902654867256\n",
      "test Acc 0.9324953445065177:\n",
      "11th- epoch: 91, train_loss = 25.010316602885723, train_acc = 0.9450395901257569\n",
      "test Acc 0.9324953445065177:\n",
      "11th- epoch: 92, train_loss = 24.891497280448675, train_acc = 0.9455053563111319\n",
      "test Acc 0.9334264432029795:\n",
      "11th- epoch: 93, train_loss = 24.776494447141886, train_acc = 0.9455053563111319\n",
      "test Acc 0.9334264432029795:\n",
      "11th- epoch: 94, train_loss = 24.663642410188913, train_acc = 0.9456217978574756\n",
      "test Acc 0.9334264432029795:\n",
      "11th- epoch: 95, train_loss = 24.552520118653774, train_acc = 0.945854680950163\n",
      "test Acc 0.9343575418994413:\n",
      "11th- epoch: 96, train_loss = 24.4435518309474, train_acc = 0.945854680950163\n",
      "test Acc 0.936219739292365:\n",
      "11th- epoch: 97, train_loss = 24.337022073566914, train_acc = 0.9459711224965067\n",
      "test Acc 0.936219739292365:\n",
      "11th- epoch: 98, train_loss = 24.231795497238636, train_acc = 0.9464368886818817\n",
      "test Acc 0.9357541899441341:\n",
      "11th- epoch: 99, train_loss = 24.128353841602802, train_acc = 0.9465533302282254\n",
      "test Acc 0.9357541899441341:\n",
      "11th- epoch: 100, train_loss = 24.02692499756813, train_acc = 0.9471355379599441\n",
      "test Acc 0.9357541899441341:\n",
      "11th- epoch: 101, train_loss = 23.926814667880535, train_acc = 0.9472519795062878\n",
      "test Acc 0.9357541899441341:\n",
      "11th- epoch: 102, train_loss = 23.82773170620203, train_acc = 0.9472519795062878\n",
      "test Acc 0.936219739292365:\n",
      "11th- epoch: 103, train_loss = 23.730467446148396, train_acc = 0.9472519795062878\n",
      "test Acc 0.9366852886405959:\n",
      "11th- epoch: 104, train_loss = 23.634865902364254, train_acc = 0.9474848625989754\n",
      "test Acc 0.9366852886405959:\n",
      "11th- epoch: 105, train_loss = 23.540753554552794, train_acc = 0.9473684210526315\n",
      "test Acc 0.9366852886405959:\n",
      "11th- epoch: 106, train_loss = 23.448881965130568, train_acc = 0.9474848625989754\n",
      "test Acc 0.9366852886405959:\n",
      "11th- epoch: 107, train_loss = 23.35764615610242, train_acc = 0.9476013041453191\n",
      "test Acc 0.9371508379888268:\n",
      "11th- epoch: 108, train_loss = 23.268535688519478, train_acc = 0.9478341872380065\n",
      "test Acc 0.9371508379888268:\n",
      "11th- epoch: 109, train_loss = 23.17984189465642, train_acc = 0.9479506287843502\n",
      "test Acc 0.9371508379888268:\n",
      "11th- epoch: 110, train_loss = 23.094112779945135, train_acc = 0.948067070330694\n",
      "test Acc 0.9371508379888268:\n",
      "11th- epoch: 111, train_loss = 23.008481044322252, train_acc = 0.9484163949697252\n",
      "test Acc 0.9371508379888268:\n",
      "11th- epoch: 112, train_loss = 22.923758406192064, train_acc = 0.9486492780624126\n",
      "test Acc 0.9371508379888268:\n",
      "11th- epoch: 113, train_loss = 22.840859681367874, train_acc = 0.9487657196087564\n",
      "test Acc 0.9371508379888268:\n",
      "11th- epoch: 114, train_loss = 22.75950800254941, train_acc = 0.9487657196087564\n",
      "test Acc 0.9376163873370578:\n",
      "11th- epoch: 115, train_loss = 22.678585540503263, train_acc = 0.9487657196087564\n",
      "test Acc 0.9376163873370578:\n",
      "11th- epoch: 116, train_loss = 22.599247738718987, train_acc = 0.9491150442477876\n",
      "test Acc 0.9380819366852886:\n",
      "11th- epoch: 117, train_loss = 22.520176824182272, train_acc = 0.9491150442477876\n",
      "test Acc 0.9380819366852886:\n",
      "11th- epoch: 118, train_loss = 22.442727740854025, train_acc = 0.9492314857941313\n",
      "test Acc 0.9380819366852886:\n",
      "11th- epoch: 119, train_loss = 22.366753216832876, train_acc = 0.9492314857941313\n",
      "test Acc 0.9390130353817505:\n",
      "11th- epoch: 120, train_loss = 22.291195057332516, train_acc = 0.9495808104331626\n",
      "test Acc 0.9390130353817505:\n",
      "11th- epoch: 121, train_loss = 22.217261910438538, train_acc = 0.94981369352585\n",
      "test Acc 0.9390130353817505:\n",
      "11th- epoch: 122, train_loss = 22.143700275570154, train_acc = 0.9500465766185375\n",
      "test Acc 0.9394785847299814:\n",
      "11th- epoch: 123, train_loss = 22.07193350791931, train_acc = 0.9509781089892874\n",
      "test Acc 0.9399441340782123:\n",
      "11th- epoch: 124, train_loss = 22.00049005076289, train_acc = 0.9509781089892874\n",
      "test Acc 0.9399441340782123:\n",
      "11th- epoch: 125, train_loss = 21.93046695739031, train_acc = 0.9512109920819748\n",
      "test Acc 0.9399441340782123:\n",
      "11th- epoch: 126, train_loss = 21.860735796391964, train_acc = 0.9512109920819748\n",
      "test Acc 0.9399441340782123:\n",
      "11th- epoch: 127, train_loss = 21.79255361109972, train_acc = 0.9512109920819748\n",
      "test Acc 0.9399441340782123:\n",
      "11th- epoch: 128, train_loss = 21.724783405661583, train_acc = 0.9514438751746623\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 129, train_loss = 21.657753750681877, train_acc = 0.9514438751746623\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 130, train_loss = 21.59181560575962, train_acc = 0.9513274336283186\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 131, train_loss = 21.526672296226025, train_acc = 0.9513274336283186\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 132, train_loss = 21.46169149875641, train_acc = 0.9514438751746623\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 133, train_loss = 21.39811449125409, train_acc = 0.9514438751746623\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 134, train_loss = 21.335553035140038, train_acc = 0.951560316721006\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 135, train_loss = 21.272628862410784, train_acc = 0.9519096413600373\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 136, train_loss = 21.211425364017487, train_acc = 0.9523754075454122\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 137, train_loss = 21.150475066155195, train_acc = 0.9528411737307871\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 138, train_loss = 21.08922827243805, train_acc = 0.9529576152771309\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 139, train_loss = 21.0298961289227, train_acc = 0.9528411737307871\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 140, train_loss = 20.970607697963715, train_acc = 0.9529576152771309\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 141, train_loss = 20.913351319730282, train_acc = 0.9530740568234746\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 142, train_loss = 20.855308797210455, train_acc = 0.9531904983698184\n",
      "test Acc 0.9408752327746741:\n",
      "11th- epoch: 143, train_loss = 20.79852006584406, train_acc = 0.9533069399161621\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 144, train_loss = 20.742287300527096, train_acc = 0.9533069399161621\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 145, train_loss = 20.685751527547836, train_acc = 0.9533069399161621\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 146, train_loss = 20.630201172083616, train_acc = 0.9535398230088495\n",
      "test Acc 0.9413407821229051:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 147, train_loss = 20.5753236413002, train_acc = 0.9535398230088495\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 148, train_loss = 20.521814158186316, train_acc = 0.9536562645551933\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 149, train_loss = 20.468763450160623, train_acc = 0.9536562645551933\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 150, train_loss = 20.41514198668301, train_acc = 0.9537727061015371\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 151, train_loss = 20.363882223144174, train_acc = 0.9537727061015371\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 152, train_loss = 20.311869574710727, train_acc = 0.9542384722869119\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 153, train_loss = 20.26032037101686, train_acc = 0.9545877969259432\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 154, train_loss = 20.210004264488816, train_acc = 0.9548206800186306\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 155, train_loss = 20.159246305003762, train_acc = 0.9548206800186306\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 156, train_loss = 20.109660597518086, train_acc = 0.9549371215649743\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 157, train_loss = 20.060432393103838, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 158, train_loss = 20.011713841930032, train_acc = 0.9550535631113182\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 159, train_loss = 19.961839640513062, train_acc = 0.9551700046576619\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 160, train_loss = 19.914361814036965, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "11th- epoch: 161, train_loss = 19.866442261263728, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "11th- epoch: 162, train_loss = 19.819697881117463, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "11th- epoch: 163, train_loss = 19.77349384315312, train_acc = 0.9554028877503493\n",
      "test Acc 0.9422718808193669:\n",
      "11th- epoch: 164, train_loss = 19.726554492488503, train_acc = 0.955519329296693\n",
      "test Acc 0.9422718808193669:\n",
      "11th- epoch: 165, train_loss = 19.68019407428801, train_acc = 0.9556357708430367\n",
      "test Acc 0.9427374301675978:\n",
      "11th- epoch: 166, train_loss = 19.635497799143195, train_acc = 0.9558686539357243\n",
      "test Acc 0.9427374301675978:\n",
      "11th- epoch: 167, train_loss = 19.59092420525849, train_acc = 0.955985095482068\n",
      "test Acc 0.9427374301675978:\n",
      "11th- epoch: 168, train_loss = 19.546479733660817, train_acc = 0.955985095482068\n",
      "test Acc 0.9427374301675978:\n",
      "11th- epoch: 169, train_loss = 19.502249578014016, train_acc = 0.955985095482068\n",
      "test Acc 0.9427374301675978:\n",
      "11th- epoch: 170, train_loss = 19.458024142310023, train_acc = 0.955985095482068\n",
      "test Acc 0.9432029795158287:\n",
      "11th- epoch: 171, train_loss = 19.41513361595571, train_acc = 0.9562179785747554\n",
      "test Acc 0.9432029795158287:\n",
      "11th- epoch: 172, train_loss = 19.37119260057807, train_acc = 0.9562179785747554\n",
      "test Acc 0.9432029795158287:\n",
      "11th- epoch: 173, train_loss = 19.329808810725808, train_acc = 0.9562179785747554\n",
      "test Acc 0.9432029795158287:\n",
      "11th- epoch: 174, train_loss = 19.286550847813487, train_acc = 0.9563344201210993\n",
      "test Acc 0.9432029795158287:\n",
      "11th- epoch: 175, train_loss = 19.24625156261027, train_acc = 0.9563344201210993\n",
      "test Acc 0.9432029795158287:\n",
      "11th- epoch: 176, train_loss = 19.20424498617649, train_acc = 0.956450861667443\n",
      "test Acc 0.9432029795158287:\n",
      "11th- epoch: 177, train_loss = 19.16319726034999, train_acc = 0.9565673032137867\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 178, train_loss = 19.122647000476718, train_acc = 0.9565673032137867\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 179, train_loss = 19.083151070401073, train_acc = 0.9565673032137867\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 180, train_loss = 19.042246963828802, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 181, train_loss = 19.00319374538958, train_acc = 0.9570330693991617\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 182, train_loss = 18.964460534974933, train_acc = 0.9571495109455054\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 183, train_loss = 18.9258485250175, train_acc = 0.9572659524918491\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 184, train_loss = 18.886079385876656, train_acc = 0.9572659524918491\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 185, train_loss = 18.846950793638825, train_acc = 0.9573823940381928\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 186, train_loss = 18.80873637087643, train_acc = 0.9577317186772241\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 187, train_loss = 18.771857123821974, train_acc = 0.9580810433162552\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 188, train_loss = 18.734981326386333, train_acc = 0.9580810433162552\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 189, train_loss = 18.6979514118284, train_acc = 0.9580810433162552\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 190, train_loss = 18.66155313514173, train_acc = 0.9580810433162552\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 191, train_loss = 18.62531989067793, train_acc = 0.9580810433162552\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 192, train_loss = 18.5892315171659, train_acc = 0.9581974848625989\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 193, train_loss = 18.55325977690518, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 194, train_loss = 18.51816488802433, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 195, train_loss = 18.48371442966163, train_acc = 0.9583139264089428\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 196, train_loss = 18.449166966602206, train_acc = 0.9585468095016302\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 197, train_loss = 18.414226410910487, train_acc = 0.9586632510479739\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 198, train_loss = 18.380245558917522, train_acc = 0.9587796925943176\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 199, train_loss = 18.346859907731414, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 200, train_loss = 18.313063137233257, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 201, train_loss = 18.27969672344625, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 202, train_loss = 18.247264552861452, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 203, train_loss = 18.215000551193953, train_acc = 0.9590125756870052\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 204, train_loss = 18.18223630823195, train_acc = 0.9590125756870052\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 205, train_loss = 18.15029139816761, train_acc = 0.9590125756870052\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 206, train_loss = 18.118133509531617, train_acc = 0.9590125756870052\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 207, train_loss = 18.086671380326152, train_acc = 0.9588961341406614\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 208, train_loss = 18.055822087451816, train_acc = 0.9590125756870052\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 209, train_loss = 18.025412015616894, train_acc = 0.9592454587796926\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 210, train_loss = 17.993842577561736, train_acc = 0.9592454587796926\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 211, train_loss = 17.963520983234048, train_acc = 0.95947834187238\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 212, train_loss = 17.933211587369442, train_acc = 0.95947834187238\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 213, train_loss = 17.903573283925653, train_acc = 0.95947834187238\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 214, train_loss = 17.872618161141872, train_acc = 0.95947834187238\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 215, train_loss = 17.84371743351221, train_acc = 0.95947834187238\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 216, train_loss = 17.8137927390635, train_acc = 0.9595947834187238\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 217, train_loss = 17.78466367907822, train_acc = 0.9595947834187238\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 218, train_loss = 17.755803467705846, train_acc = 0.9595947834187238\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 219, train_loss = 17.72644636966288, train_acc = 0.9597112249650676\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 220, train_loss = 17.69800588861108, train_acc = 0.9597112249650676\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 221, train_loss = 17.671023102477193, train_acc = 0.9597112249650676\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 222, train_loss = 17.64196658320725, train_acc = 0.9597112249650676\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 223, train_loss = 17.613977424800396, train_acc = 0.9597112249650676\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 224, train_loss = 17.587278556078672, train_acc = 0.9598276665114113\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 225, train_loss = 17.560200694948435, train_acc = 0.9598276665114113\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 226, train_loss = 17.532324766740203, train_acc = 0.9598276665114113\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 227, train_loss = 17.506573291495442, train_acc = 0.959944108057755\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 228, train_loss = 17.47936058230698, train_acc = 0.959944108057755\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 229, train_loss = 17.453101363033056, train_acc = 0.9601769911504425\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 230, train_loss = 17.42762396670878, train_acc = 0.9601769911504425\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 231, train_loss = 17.40186658874154, train_acc = 0.9601769911504425\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 232, train_loss = 17.375675939023495, train_acc = 0.9605263157894737\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 233, train_loss = 17.35062713176012, train_acc = 0.9605263157894737\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 234, train_loss = 17.32624151557684, train_acc = 0.9605263157894737\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 235, train_loss = 17.299445973709226, train_acc = 0.9605263157894737\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 236, train_loss = 17.275353736244142, train_acc = 0.9605263157894737\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 237, train_loss = 17.250785159878433, train_acc = 0.9605263157894737\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 238, train_loss = 17.225624475628138, train_acc = 0.9605263157894737\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 239, train_loss = 17.20202238857746, train_acc = 0.9606427573358174\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 240, train_loss = 17.17783854622394, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 241, train_loss = 17.15368979331106, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 242, train_loss = 17.13001937326044, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 243, train_loss = 17.10725858528167, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 244, train_loss = 17.083024258725345, train_acc = 0.9611085235211924\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 245, train_loss = 17.06083407625556, train_acc = 0.9611085235211924\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 246, train_loss = 17.036598537117243, train_acc = 0.9612249650675361\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 247, train_loss = 17.01550656929612, train_acc = 0.9612249650675361\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 248, train_loss = 16.992432203143835, train_acc = 0.9612249650675361\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 249, train_loss = 16.97009874973446, train_acc = 0.9614578481602236\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 250, train_loss = 16.946907363831997, train_acc = 0.9615742897065673\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 251, train_loss = 16.925687044858932, train_acc = 0.9614578481602236\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 252, train_loss = 16.902907623909414, train_acc = 0.9615742897065673\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 253, train_loss = 16.882712026126683, train_acc = 0.961690731252911\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 254, train_loss = 16.86132401973009, train_acc = 0.9620400558919422\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 255, train_loss = 16.839588273316622, train_acc = 0.962156497438286\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 256, train_loss = 16.81964500527829, train_acc = 0.962156497438286\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 257, train_loss = 16.79752095695585, train_acc = 0.9622729389846297\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 258, train_loss = 16.776902155019343, train_acc = 0.9622729389846297\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 259, train_loss = 16.756402615457773, train_acc = 0.9625058220773172\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 260, train_loss = 16.73565888684243, train_acc = 0.9625058220773172\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 261, train_loss = 16.714886241592467, train_acc = 0.9625058220773172\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 262, train_loss = 16.695605505257845, train_acc = 0.9625058220773172\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 263, train_loss = 16.675687237642705, train_acc = 0.9625058220773172\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 264, train_loss = 16.654860977083445, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 265, train_loss = 16.635916586965322, train_acc = 0.9627387051700047\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 266, train_loss = 16.615680714137852, train_acc = 0.9628551467163484\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 267, train_loss = 16.595741868019104, train_acc = 0.9628551467163484\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 268, train_loss = 16.57965838909149, train_acc = 0.9629715882626921\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 269, train_loss = 16.558392014354467, train_acc = 0.9629715882626921\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 270, train_loss = 16.540091601200402, train_acc = 0.9629715882626921\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 271, train_loss = 16.519458814524114, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 272, train_loss = 16.502067894674838, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 273, train_loss = 16.48218884691596, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 274, train_loss = 16.464086148887873, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 275, train_loss = 16.445033286698163, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 276, train_loss = 16.42718084063381, train_acc = 0.9632044713553796\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 277, train_loss = 16.40845928248018, train_acc = 0.9634373544480671\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 278, train_loss = 16.389628939330578, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 279, train_loss = 16.372270796447992, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 280, train_loss = 16.356571093201637, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 281, train_loss = 16.337552040815353, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 282, train_loss = 16.321218161843717, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 283, train_loss = 16.30640105623752, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 284, train_loss = 16.28541846666485, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 285, train_loss = 16.26839900854975, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 286, train_loss = 16.251473397016525, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 287, train_loss = 16.23648572061211, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 288, train_loss = 16.217526487074792, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 289, train_loss = 16.199750683270395, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 290, train_loss = 16.182286293245852, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 291, train_loss = 16.167119794525206, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 292, train_loss = 16.151147466152906, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 293, train_loss = 16.13475129008293, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 294, train_loss = 16.11881155986339, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 295, train_loss = 16.10213415324688, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 296, train_loss = 16.085586563684046, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 297, train_loss = 16.068491470068693, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "11th- epoch: 298, train_loss = 16.054401396773756, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "11th- epoch: 299, train_loss = 16.038042951375246, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "11th- epoch: 300, train_loss = 16.024504250846803, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "11th- epoch: 301, train_loss = 16.007252142764628, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "11th- epoch: 302, train_loss = 15.991676057688892, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "11th- epoch: 303, train_loss = 15.977827561087906, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "11th- epoch: 304, train_loss = 15.961436483077705, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "11th- epoch: 305, train_loss = 15.944808550179005, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 306, train_loss = 15.93282635230571, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 307, train_loss = 15.915609530173242, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 308, train_loss = 15.901940234005451, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 309, train_loss = 15.886103335767984, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 310, train_loss = 15.872334282845259, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 311, train_loss = 15.85960887465626, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 312, train_loss = 15.844013745896518, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 313, train_loss = 15.829113089479506, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 314, train_loss = 15.81542878691107, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 315, train_loss = 15.800493457354605, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 316, train_loss = 15.788326715119183, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 317, train_loss = 15.771797314286232, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 318, train_loss = 15.759670299477875, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 319, train_loss = 15.74474995676428, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 320, train_loss = 15.731574520468712, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 321, train_loss = 15.717474643141031, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 322, train_loss = 15.704207594506443, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 323, train_loss = 15.69118516985327, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 324, train_loss = 15.676582779735327, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 325, train_loss = 15.662628774531186, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 326, train_loss = 15.650341390632093, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 327, train_loss = 15.637669943273067, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 328, train_loss = 15.623476904816926, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 329, train_loss = 15.610748088918626, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 330, train_loss = 15.597482845187187, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 331, train_loss = 15.584829226136208, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 332, train_loss = 15.572742654941976, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 333, train_loss = 15.559376635588706, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 334, train_loss = 15.547332565300167, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 335, train_loss = 15.534393808804452, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 336, train_loss = 15.52169185411185, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 337, train_loss = 15.50917223840952, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 338, train_loss = 15.497067618183792, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 339, train_loss = 15.485922592692077, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 340, train_loss = 15.472007335163653, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 341, train_loss = 15.461357743479311, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 342, train_loss = 15.44982320163399, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 343, train_loss = 15.436613497324288, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 344, train_loss = 15.424002583138645, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 345, train_loss = 15.412212029099464, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 346, train_loss = 15.400579282082617, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 347, train_loss = 15.390620306134224, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 348, train_loss = 15.377219918183982, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 349, train_loss = 15.367732290178537, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 350, train_loss = 15.352893670089543, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 351, train_loss = 15.34197847172618, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 352, train_loss = 15.332069943659008, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 353, train_loss = 15.319988588802516, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 354, train_loss = 15.308673028834164, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 355, train_loss = 15.296048643998802, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 356, train_loss = 15.285447048954666, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 357, train_loss = 15.273956424556673, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 358, train_loss = 15.264046507887542, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 359, train_loss = 15.252403282560408, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 360, train_loss = 15.240917466580868, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 361, train_loss = 15.23090308625251, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 362, train_loss = 15.220617611892521, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 363, train_loss = 15.209877077490091, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 364, train_loss = 15.197745185345411, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 365, train_loss = 15.18739377334714, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 366, train_loss = 15.178007342852652, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 367, train_loss = 15.16511981934309, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 368, train_loss = 15.155723557807505, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 369, train_loss = 15.146018821746111, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 370, train_loss = 15.135664685629308, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 371, train_loss = 15.126531261950731, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 372, train_loss = 15.115324057638645, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 373, train_loss = 15.105207960121334, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 374, train_loss = 15.095084273256361, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 375, train_loss = 15.085552400909364, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 376, train_loss = 15.073575410991907, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 377, train_loss = 15.063331135548651, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 378, train_loss = 15.05499969329685, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 379, train_loss = 15.04399961605668, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 380, train_loss = 15.034158039838076, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 381, train_loss = 15.02495679538697, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 382, train_loss = 15.015851964242756, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 383, train_loss = 15.0047476766631, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 384, train_loss = 14.995775603689253, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 385, train_loss = 14.985023010522127, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 386, train_loss = 14.976927794516087, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 387, train_loss = 14.968708860687912, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 388, train_loss = 14.958288472145796, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 389, train_loss = 14.94835874158889, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 390, train_loss = 14.939512562006712, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 391, train_loss = 14.92977974936366, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 392, train_loss = 14.91932017635554, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 393, train_loss = 14.910664399154484, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 394, train_loss = 14.90125594381243, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 395, train_loss = 14.893390505574644, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "11th- epoch: 396, train_loss = 14.883235308341682, train_acc = 0.9659990684676293\n",
      "test Acc 0.9511173184357542:\n",
      "11th- epoch: 397, train_loss = 14.87299174349755, train_acc = 0.9659990684676293\n",
      "test Acc 0.9511173184357542:\n",
      "11th- epoch: 398, train_loss = 14.865673619322479, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 399, train_loss = 14.856037250719965, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 400, train_loss = 14.847530134953558, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 401, train_loss = 14.837916345335543, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 402, train_loss = 14.830127518624067, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 403, train_loss = 14.819932151585817, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 404, train_loss = 14.811527404002845, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 405, train_loss = 14.804881997406483, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 406, train_loss = 14.794046505354345, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 407, train_loss = 14.786554802209139, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 408, train_loss = 14.7768335910514, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 409, train_loss = 14.767642304301262, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 410, train_loss = 14.761616305448115, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 411, train_loss = 14.750934139825404, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 412, train_loss = 14.744736476801336, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 413, train_loss = 14.735647725872695, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 414, train_loss = 14.72641836758703, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 415, train_loss = 14.718255396932364, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 416, train_loss = 14.70971126947552, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 417, train_loss = 14.700337883085012, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 418, train_loss = 14.692977701313794, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 419, train_loss = 14.685938931070268, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 420, train_loss = 14.677159294486046, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 421, train_loss = 14.668063702993095, train_acc = 0.9663483931066604\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 422, train_loss = 14.66188308596611, train_acc = 0.9663483931066604\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 423, train_loss = 14.653167399577796, train_acc = 0.9663483931066604\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 424, train_loss = 14.64465385209769, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 425, train_loss = 14.636448495090008, train_acc = 0.9663483931066604\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 426, train_loss = 14.629491730593145, train_acc = 0.9663483931066604\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 427, train_loss = 14.621442270465195, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 428, train_loss = 14.612363944761455, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 429, train_loss = 14.605420679785311, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 430, train_loss = 14.59783844370395, train_acc = 0.9663483931066604\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 431, train_loss = 14.590971291996539, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 432, train_loss = 14.581475402228534, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 433, train_loss = 14.575320069678128, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 434, train_loss = 14.568438618443906, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 435, train_loss = 14.560171681456268, train_acc = 0.9663483931066604\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 436, train_loss = 14.550772433169186, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 437, train_loss = 14.544697809964418, train_acc = 0.9663483931066604\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 438, train_loss = 14.53673438820988, train_acc = 0.9662319515603167\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 439, train_loss = 14.529444840736687, train_acc = 0.9666977177456917\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 440, train_loss = 14.522917159833014, train_acc = 0.966581276199348\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 441, train_loss = 14.514995265752077, train_acc = 0.9666977177456917\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 442, train_loss = 14.506806095130742, train_acc = 0.9668141592920354\n",
      "test Acc 0.952048417132216:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 443, train_loss = 14.498577599413693, train_acc = 0.9668141592920354\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 444, train_loss = 14.492979764007032, train_acc = 0.9668141592920354\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 445, train_loss = 14.486076061613858, train_acc = 0.9668141592920354\n",
      "test Acc 0.952048417132216:\n",
      "11th- epoch: 446, train_loss = 14.478131166659296, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 447, train_loss = 14.469789392314851, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 448, train_loss = 14.463964792899787, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 449, train_loss = 14.457210625521839, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 450, train_loss = 14.448810413479805, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 451, train_loss = 14.442559319548309, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 452, train_loss = 14.43426850810647, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 453, train_loss = 14.428641024045646, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 454, train_loss = 14.422398576047271, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 455, train_loss = 14.412937736604363, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 456, train_loss = 14.407925625797361, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 457, train_loss = 14.401813438627869, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 458, train_loss = 14.396107567939907, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 459, train_loss = 14.38921325514093, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 460, train_loss = 14.379846265073866, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 461, train_loss = 14.373250474687666, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 462, train_loss = 14.368008007761091, train_acc = 0.9671634839310667\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 463, train_loss = 14.35914204036817, train_acc = 0.9672799254774104\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 464, train_loss = 14.353667666669935, train_acc = 0.9672799254774104\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 465, train_loss = 14.345039968844503, train_acc = 0.9672799254774104\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 466, train_loss = 14.338154753204435, train_acc = 0.9672799254774104\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 467, train_loss = 14.335482926573604, train_acc = 0.9672799254774104\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 468, train_loss = 14.327922468539327, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 469, train_loss = 14.32017208635807, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 470, train_loss = 14.314210028853267, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 471, train_loss = 14.306110832840204, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 472, train_loss = 14.301637809723616, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 473, train_loss = 14.29421904310584, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 474, train_loss = 14.287561269011348, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 475, train_loss = 14.282161916140467, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 476, train_loss = 14.274609728250653, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 477, train_loss = 14.26882441714406, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 478, train_loss = 14.261119441594929, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 479, train_loss = 14.255388346966356, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 480, train_loss = 14.24758394062519, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 481, train_loss = 14.240778587758541, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 482, train_loss = 14.237066449131817, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 483, train_loss = 14.230156432837248, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 484, train_loss = 14.224336133804172, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 485, train_loss = 14.217490988317877, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 486, train_loss = 14.211891239043325, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 487, train_loss = 14.206076093018055, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 488, train_loss = 14.200171968434006, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 489, train_loss = 14.194142737891525, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 490, train_loss = 14.187120995018631, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 491, train_loss = 14.181702814996243, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 492, train_loss = 14.175607760902494, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 493, train_loss = 14.169616531580687, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 494, train_loss = 14.163349818438292, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 495, train_loss = 14.157417885959148, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 496, train_loss = 14.151128113269806, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 497, train_loss = 14.147086718585342, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 498, train_loss = 14.140692898537964, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 499, train_loss = 14.135565379168838, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████▋                                            | 11/30 [1:13:12<2:06:36, 399.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "12th- epoch: 0, train_loss = 274.7738287448883, train_acc = 0.4576152771308803\n",
      "test Acc 0.4995344506517691:\n",
      "12th- epoch: 1, train_loss = 216.1894828081131, train_acc = 0.5010479739170937\n",
      "test Acc 0.5:\n",
      "12th- epoch: 2, train_loss = 181.73206233978271, train_acc = 0.5038425710293433\n",
      "test Acc 0.5111731843575419:\n",
      "12th- epoch: 3, train_loss = 164.85052287578583, train_acc = 0.5330693991616209\n",
      "test Acc 0.563780260707635:\n",
      "12th- epoch: 4, train_loss = 152.13531756401062, train_acc = 0.581858407079646\n",
      "test Acc 0.6084729981378026:\n",
      "12th- epoch: 5, train_loss = 140.83005565404892, train_acc = 0.6173730787144853\n",
      "test Acc 0.6238361266294227:\n",
      "12th- epoch: 6, train_loss = 130.27494376897812, train_acc = 0.6387983232417327\n",
      "test Acc 0.6657355679702048:\n",
      "12th- epoch: 7, train_loss = 120.54935240745544, train_acc = 0.6951560316721006\n",
      "test Acc 0.75512104283054:\n",
      "12th- epoch: 8, train_loss = 111.7096796631813, train_acc = 0.7598975314392176\n",
      "test Acc 0.7690875232774674:\n",
      "12th- epoch: 9, train_loss = 103.68939852714539, train_acc = 0.7772473218444341\n",
      "test Acc 0.7900372439478585:\n",
      "12th- epoch: 10, train_loss = 96.39591133594513, train_acc = 0.8029809035863996\n",
      "test Acc 0.8114525139664804:\n",
      "12th- epoch: 11, train_loss = 89.78203499317169, train_acc = 0.8171867722403353\n",
      "test Acc 0.8212290502793296:\n",
      "12th- epoch: 12, train_loss = 83.84798243641853, train_acc = 0.8276665114112716\n",
      "test Acc 0.8379888268156425:\n",
      "12th- epoch: 13, train_loss = 78.54968720674515, train_acc = 0.8401257568700512\n",
      "test Acc 0.8524208566108007:\n",
      "12th- epoch: 14, train_loss = 73.83644568920135, train_acc = 0.8496739636702375\n",
      "test Acc 0.8584729981378026:\n",
      "12th- epoch: 15, train_loss = 69.65849727392197, train_acc = 0.857359105728924\n",
      "test Acc 0.8626629422718808:\n",
      "12th- epoch: 16, train_loss = 65.95776823163033, train_acc = 0.8637633907778295\n",
      "test Acc 0.8687150837988827:\n",
      "12th- epoch: 17, train_loss = 62.67775762081146, train_acc = 0.8692361434559851\n",
      "test Acc 0.8743016759776536:\n",
      "12th- epoch: 18, train_loss = 59.77211081981659, train_acc = 0.873660922217047\n",
      "test Acc 0.8794227188081937:\n",
      "12th- epoch: 19, train_loss = 57.19712883234024, train_acc = 0.878085700978109\n",
      "test Acc 0.8859404096834265:\n",
      "12th- epoch: 20, train_loss = 54.90917204320431, train_acc = 0.882510479739171\n",
      "test Acc 0.8915270018621974:\n",
      "12th- epoch: 21, train_loss = 52.872683465480804, train_acc = 0.8880996739636703\n",
      "test Acc 0.8980446927374302:\n",
      "12th- epoch: 22, train_loss = 51.06157010793686, train_acc = 0.8953190498369819\n",
      "test Acc 0.8980446927374302:\n",
      "12th- epoch: 23, train_loss = 49.4456112831831, train_acc = 0.8977643223102003\n",
      "test Acc 0.9003724394785847:\n",
      "12th- epoch: 24, train_loss = 47.9979233443737, train_acc = 0.8992780624126688\n",
      "test Acc 0.9013035381750466:\n",
      "12th- epoch: 25, train_loss = 46.695898815989494, train_acc = 0.9009082440614812\n",
      "test Acc 0.904562383612663:\n",
      "12th- epoch: 26, train_loss = 45.5172531157732, train_acc = 0.9030041918956684\n",
      "test Acc 0.9059590316573557:\n",
      "12th- epoch: 27, train_loss = 44.44759030640125, train_acc = 0.9051001397298556\n",
      "test Acc 0.9064245810055865:\n",
      "12th- epoch: 28, train_loss = 43.47203539311886, train_acc = 0.9060316721006055\n",
      "test Acc 0.9064245810055865:\n",
      "12th- epoch: 29, train_loss = 42.57826371490955, train_acc = 0.9081276199347927\n",
      "test Acc 0.9068901303538175:\n",
      "12th- epoch: 30, train_loss = 41.75560460984707, train_acc = 0.9092920353982301\n",
      "test Acc 0.9087523277467412:\n",
      "12th- epoch: 31, train_loss = 40.99533425271511, train_acc = 0.9108057755006986\n",
      "test Acc 0.909217877094972:\n",
      "12th- epoch: 32, train_loss = 40.29030539095402, train_acc = 0.911970190964136\n",
      "test Acc 0.9106145251396648:\n",
      "12th- epoch: 33, train_loss = 39.634415686130524, train_acc = 0.9142990218910108\n",
      "test Acc 0.9124767225325885:\n",
      "12th- epoch: 34, train_loss = 39.020149037241936, train_acc = 0.915463437354448\n",
      "test Acc 0.9129422718808193:\n",
      "12th- epoch: 35, train_loss = 38.442699521780014, train_acc = 0.9180251513740102\n",
      "test Acc 0.9152700186219739:\n",
      "12th- epoch: 36, train_loss = 37.89759981632233, train_acc = 0.9187238006520727\n",
      "test Acc 0.9157355679702048:\n",
      "12th- epoch: 37, train_loss = 37.38229565322399, train_acc = 0.9193060083837913\n",
      "test Acc 0.9162011173184358:\n",
      "12th- epoch: 38, train_loss = 36.89328871667385, train_acc = 0.9210526315789473\n",
      "test Acc 0.9157355679702048:\n",
      "12th- epoch: 39, train_loss = 36.42898999154568, train_acc = 0.9219841639496973\n",
      "test Acc 0.9162011173184358:\n",
      "12th- epoch: 40, train_loss = 35.985546082258224, train_acc = 0.9231485794131346\n",
      "test Acc 0.9180633147113594:\n",
      "12th- epoch: 41, train_loss = 35.561443880200386, train_acc = 0.9244294364229158\n",
      "test Acc 0.9185288640595903:\n",
      "12th- epoch: 42, train_loss = 35.15598884224892, train_acc = 0.9251280857009782\n",
      "test Acc 0.9203910614525139:\n",
      "12th- epoch: 43, train_loss = 34.767741307616234, train_acc = 0.9253609687936656\n",
      "test Acc 0.9208566108007449:\n",
      "12th- epoch: 44, train_loss = 34.39455822110176, train_acc = 0.9257102934326968\n",
      "test Acc 0.9217877094972067:\n",
      "12th- epoch: 45, train_loss = 34.035389833152294, train_acc = 0.9264089427107592\n",
      "test Acc 0.9227188081936686:\n",
      "12th- epoch: 46, train_loss = 33.69107247889042, train_acc = 0.9267582673497904\n",
      "test Acc 0.9231843575418994:\n",
      "12th- epoch: 47, train_loss = 33.35919860750437, train_acc = 0.9272240335351654\n",
      "test Acc 0.9231843575418994:\n",
      "12th- epoch: 48, train_loss = 33.03902640193701, train_acc = 0.9275733581741965\n",
      "test Acc 0.9241154562383612:\n",
      "12th- epoch: 49, train_loss = 32.73009257763624, train_acc = 0.9286213320912902\n",
      "test Acc 0.9241154562383612:\n",
      "12th- epoch: 50, train_loss = 32.43169565498829, train_acc = 0.9292035398230089\n",
      "test Acc 0.9241154562383612:\n",
      "12th- epoch: 51, train_loss = 32.14324917644262, train_acc = 0.9296693060083838\n",
      "test Acc 0.925512104283054:\n",
      "12th- epoch: 52, train_loss = 31.86470903456211, train_acc = 0.9299021891010713\n",
      "test Acc 0.9259776536312849:\n",
      "12th- epoch: 53, train_loss = 31.595201455056667, train_acc = 0.9307172799254774\n",
      "test Acc 0.9264432029795159:\n",
      "12th- epoch: 54, train_loss = 31.33384671062231, train_acc = 0.9309501630181649\n",
      "test Acc 0.9273743016759777:\n",
      "12th- epoch: 55, train_loss = 31.080112002789974, train_acc = 0.9311830461108523\n",
      "test Acc 0.9273743016759777:\n",
      "12th- epoch: 56, train_loss = 30.832466661930084, train_acc = 0.9315323707498836\n",
      "test Acc 0.9273743016759777:\n",
      "12th- epoch: 57, train_loss = 30.59244877099991, train_acc = 0.9319981369352585\n",
      "test Acc 0.9278398510242085:\n",
      "12th- epoch: 58, train_loss = 30.358614221215248, train_acc = 0.9324639031206334\n",
      "test Acc 0.9269087523277467:\n",
      "12th- epoch: 59, train_loss = 30.13190484046936, train_acc = 0.9326967862133209\n",
      "test Acc 0.9269087523277467:\n",
      "12th- epoch: 60, train_loss = 29.90972375869751, train_acc = 0.9332789939450395\n",
      "test Acc 0.9269087523277467:\n",
      "12th- epoch: 61, train_loss = 29.694345377385616, train_acc = 0.9337447601304145\n",
      "test Acc 0.9273743016759777:\n",
      "12th- epoch: 62, train_loss = 29.484021231532097, train_acc = 0.933977643223102\n",
      "test Acc 0.9273743016759777:\n",
      "12th- epoch: 63, train_loss = 29.279332764446735, train_acc = 0.9342105263157895\n",
      "test Acc 0.9273743016759777:\n",
      "12th- epoch: 64, train_loss = 29.078907378017902, train_acc = 0.9350256171401956\n",
      "test Acc 0.9273743016759777:\n",
      "12th- epoch: 65, train_loss = 28.882208831608295, train_acc = 0.9351420586865393\n",
      "test Acc 0.9273743016759777:\n",
      "12th- epoch: 66, train_loss = 28.690736815333366, train_acc = 0.9353749417792269\n",
      "test Acc 0.9273743016759777:\n",
      "12th- epoch: 67, train_loss = 28.503387562930584, train_acc = 0.9354913833255706\n",
      "test Acc 0.9278398510242085:\n",
      "12th- epoch: 68, train_loss = 28.319832928478718, train_acc = 0.9359571495109456\n",
      "test Acc 0.9283054003724395:\n",
      "12th- epoch: 69, train_loss = 28.140659898519516, train_acc = 0.9363064741499767\n",
      "test Acc 0.9283054003724395:\n",
      "12th- epoch: 70, train_loss = 27.965047165751457, train_acc = 0.9364229156963204\n",
      "test Acc 0.9283054003724395:\n",
      "12th- epoch: 71, train_loss = 27.793244898319244, train_acc = 0.9368886818816954\n",
      "test Acc 0.9283054003724395:\n",
      "12th- epoch: 72, train_loss = 27.62412841618061, train_acc = 0.9374708896134141\n",
      "test Acc 0.9283054003724395:\n",
      "12th- epoch: 73, train_loss = 27.45850021392107, train_acc = 0.9382859804378202\n",
      "test Acc 0.9287709497206704:\n",
      "12th- epoch: 74, train_loss = 27.29619523137808, train_acc = 0.9385188635305077\n",
      "test Acc 0.9287709497206704:\n",
      "12th- epoch: 75, train_loss = 27.136740505695343, train_acc = 0.9389846297158826\n",
      "test Acc 0.9292364990689013:\n",
      "12th- epoch: 76, train_loss = 26.98120541870594, train_acc = 0.9393339543549138\n",
      "test Acc 0.9297020484171322:\n",
      "12th- epoch: 77, train_loss = 26.82829473912716, train_acc = 0.939683278993945\n",
      "test Acc 0.9297020484171322:\n",
      "12th- epoch: 78, train_loss = 26.677980490028858, train_acc = 0.9404983698183512\n",
      "test Acc 0.9301675977653632:\n",
      "12th- epoch: 79, train_loss = 26.530388042330742, train_acc = 0.9409641360037261\n",
      "test Acc 0.9301675977653632:\n",
      "12th- epoch: 80, train_loss = 26.38575192540884, train_acc = 0.9409641360037261\n",
      "test Acc 0.9301675977653632:\n",
      "12th- epoch: 81, train_loss = 26.243665512651205, train_acc = 0.9409641360037261\n",
      "test Acc 0.930633147113594:\n",
      "12th- epoch: 82, train_loss = 26.104553923010826, train_acc = 0.941895668374476\n",
      "test Acc 0.930633147113594:\n",
      "12th- epoch: 83, train_loss = 25.967710372060537, train_acc = 0.9424778761061947\n",
      "test Acc 0.931098696461825:\n",
      "12th- epoch: 84, train_loss = 25.833216696977615, train_acc = 0.9424778761061947\n",
      "test Acc 0.9315642458100558:\n",
      "12th- epoch: 85, train_loss = 25.7016113512218, train_acc = 0.9427107591988821\n",
      "test Acc 0.9315642458100558:\n",
      "12th- epoch: 86, train_loss = 25.572014700621367, train_acc = 0.9430600838379134\n",
      "test Acc 0.9315642458100558:\n",
      "12th- epoch: 87, train_loss = 25.44467606768012, train_acc = 0.9430600838379134\n",
      "test Acc 0.9315642458100558:\n",
      "12th- epoch: 88, train_loss = 25.3188489228487, train_acc = 0.9434094084769445\n",
      "test Acc 0.9315642458100558:\n",
      "12th- epoch: 89, train_loss = 25.196523621678352, train_acc = 0.9435258500232883\n",
      "test Acc 0.9315642458100558:\n",
      "12th- epoch: 90, train_loss = 25.075535222887993, train_acc = 0.9439916162086632\n",
      "test Acc 0.9320297951582868:\n",
      "12th- epoch: 91, train_loss = 24.957120817154646, train_acc = 0.944108057755007\n",
      "test Acc 0.9324953445065177:\n",
      "12th- epoch: 92, train_loss = 24.84034203365445, train_acc = 0.9445738239403819\n",
      "test Acc 0.9324953445065177:\n",
      "12th- epoch: 93, train_loss = 24.725260093808174, train_acc = 0.9446902654867256\n",
      "test Acc 0.9324953445065177:\n",
      "12th- epoch: 94, train_loss = 24.61288994550705, train_acc = 0.9449231485794132\n",
      "test Acc 0.9329608938547486:\n",
      "12th- epoch: 95, train_loss = 24.502042416483164, train_acc = 0.945388914764788\n",
      "test Acc 0.9329608938547486:\n",
      "12th- epoch: 96, train_loss = 24.392481725662947, train_acc = 0.9455053563111319\n",
      "test Acc 0.9329608938547486:\n",
      "12th- epoch: 97, train_loss = 24.285388305783272, train_acc = 0.9457382394038193\n",
      "test Acc 0.9329608938547486:\n",
      "12th- epoch: 98, train_loss = 24.17957231402397, train_acc = 0.9460875640428504\n",
      "test Acc 0.9329608938547486:\n",
      "12th- epoch: 99, train_loss = 24.075213849544525, train_acc = 0.9466697717745691\n",
      "test Acc 0.9329608938547486:\n",
      "12th- epoch: 100, train_loss = 23.973122112452984, train_acc = 0.9466697717745691\n",
      "test Acc 0.9334264432029795:\n",
      "12th- epoch: 101, train_loss = 23.872342720627785, train_acc = 0.9466697717745691\n",
      "test Acc 0.9334264432029795:\n",
      "12th- epoch: 102, train_loss = 23.773124858736992, train_acc = 0.946786213320913\n",
      "test Acc 0.9334264432029795:\n",
      "12th- epoch: 103, train_loss = 23.67621859535575, train_acc = 0.9472519795062878\n",
      "test Acc 0.9334264432029795:\n",
      "12th- epoch: 104, train_loss = 23.579819966107607, train_acc = 0.9474848625989754\n",
      "test Acc 0.9338919925512105:\n",
      "12th- epoch: 105, train_loss = 23.485572919249535, train_acc = 0.9476013041453191\n",
      "test Acc 0.9338919925512105:\n",
      "12th- epoch: 106, train_loss = 23.39244881272316, train_acc = 0.9478341872380065\n",
      "test Acc 0.9343575418994413:\n",
      "12th- epoch: 107, train_loss = 23.300981272011995, train_acc = 0.948067070330694\n",
      "test Acc 0.9343575418994413:\n",
      "12th- epoch: 108, train_loss = 23.210702389478683, train_acc = 0.9482999534233815\n",
      "test Acc 0.9343575418994413:\n",
      "12th- epoch: 109, train_loss = 23.122441705316305, train_acc = 0.9486492780624126\n",
      "test Acc 0.9348230912476723:\n",
      "12th- epoch: 110, train_loss = 23.034273955971003, train_acc = 0.9487657196087564\n",
      "test Acc 0.9348230912476723:\n",
      "12th- epoch: 111, train_loss = 22.948558684438467, train_acc = 0.9488821611551002\n",
      "test Acc 0.9352886405959032:\n",
      "12th- epoch: 112, train_loss = 22.862445063889027, train_acc = 0.9489986027014439\n",
      "test Acc 0.9352886405959032:\n",
      "12th- epoch: 113, train_loss = 22.779759112745523, train_acc = 0.9492314857941313\n",
      "test Acc 0.9366852886405959:\n",
      "12th- epoch: 114, train_loss = 22.69751638546586, train_acc = 0.9496972519795063\n",
      "test Acc 0.9371508379888268:\n",
      "12th- epoch: 115, train_loss = 22.616244688630104, train_acc = 0.94981369352585\n",
      "test Acc 0.9376163873370578:\n",
      "12th- epoch: 116, train_loss = 22.535916656255722, train_acc = 0.9500465766185375\n",
      "test Acc 0.9376163873370578:\n",
      "12th- epoch: 117, train_loss = 22.456432912498713, train_acc = 0.9503959012575687\n",
      "test Acc 0.9380819366852886:\n",
      "12th- epoch: 118, train_loss = 22.37903393059969, train_acc = 0.9506287843502562\n",
      "test Acc 0.9385474860335196:\n",
      "12th- epoch: 119, train_loss = 22.301016874611378, train_acc = 0.9506287843502562\n",
      "test Acc 0.9385474860335196:\n",
      "12th- epoch: 120, train_loss = 22.224857106804848, train_acc = 0.9508616674429436\n",
      "test Acc 0.9385474860335196:\n",
      "12th- epoch: 121, train_loss = 22.150540743023157, train_acc = 0.9509781089892874\n",
      "test Acc 0.9390130353817505:\n",
      "12th- epoch: 122, train_loss = 22.07695295661688, train_acc = 0.9510945505356311\n",
      "test Acc 0.9394785847299814:\n",
      "12th- epoch: 123, train_loss = 22.004650678485632, train_acc = 0.9512109920819748\n",
      "test Acc 0.9394785847299814:\n",
      "12th- epoch: 124, train_loss = 21.931509900838137, train_acc = 0.9512109920819748\n",
      "test Acc 0.9394785847299814:\n",
      "12th- epoch: 125, train_loss = 21.861970607191324, train_acc = 0.9513274336283186\n",
      "test Acc 0.9394785847299814:\n",
      "12th- epoch: 126, train_loss = 21.79108403995633, train_acc = 0.9516767582673498\n",
      "test Acc 0.9394785847299814:\n",
      "12th- epoch: 127, train_loss = 21.721685368567705, train_acc = 0.9519096413600373\n",
      "test Acc 0.9394785847299814:\n",
      "12th- epoch: 128, train_loss = 21.653632007539272, train_acc = 0.952026082906381\n",
      "test Acc 0.9394785847299814:\n",
      "12th- epoch: 129, train_loss = 21.58701127767563, train_acc = 0.9521425244527247\n",
      "test Acc 0.9404096834264432:\n",
      "12th- epoch: 130, train_loss = 21.52016169950366, train_acc = 0.9522589659990685\n",
      "test Acc 0.9404096834264432:\n",
      "12th- epoch: 131, train_loss = 21.452563501894474, train_acc = 0.952491849091756\n",
      "test Acc 0.9404096834264432:\n",
      "12th- epoch: 132, train_loss = 21.38811594992876, train_acc = 0.9527247321844434\n",
      "test Acc 0.9404096834264432:\n",
      "12th- epoch: 133, train_loss = 21.324851863086224, train_acc = 0.9526082906380997\n",
      "test Acc 0.9404096834264432:\n",
      "12th- epoch: 134, train_loss = 21.260731652379036, train_acc = 0.9529576152771309\n",
      "test Acc 0.9408752327746741:\n",
      "12th- epoch: 135, train_loss = 21.197725638747215, train_acc = 0.9530740568234746\n",
      "test Acc 0.9408752327746741:\n",
      "12th- epoch: 136, train_loss = 21.135972678661346, train_acc = 0.9533069399161621\n",
      "test Acc 0.9408752327746741:\n",
      "12th- epoch: 137, train_loss = 21.074016578495502, train_acc = 0.9534233814625058\n",
      "test Acc 0.9408752327746741:\n",
      "12th- epoch: 138, train_loss = 21.013273134827614, train_acc = 0.9535398230088495\n",
      "test Acc 0.9404096834264432:\n",
      "12th- epoch: 139, train_loss = 20.953387923538685, train_acc = 0.9535398230088495\n",
      "test Acc 0.9404096834264432:\n",
      "12th- epoch: 140, train_loss = 20.893969777971506, train_acc = 0.9537727061015371\n",
      "test Acc 0.9404096834264432:\n",
      "12th- epoch: 141, train_loss = 20.835053101181984, train_acc = 0.9537727061015371\n",
      "test Acc 0.9404096834264432:\n",
      "12th- epoch: 142, train_loss = 20.777108009904623, train_acc = 0.9538891476478808\n",
      "test Acc 0.9404096834264432:\n",
      "12th- epoch: 143, train_loss = 20.71904957666993, train_acc = 0.9538891476478808\n",
      "test Acc 0.9408752327746741:\n",
      "12th- epoch: 144, train_loss = 20.661687918007374, train_acc = 0.9537727061015371\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 145, train_loss = 20.60698338598013, train_acc = 0.9538891476478808\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 146, train_loss = 20.550029270350933, train_acc = 0.9540055891942245\n",
      "test Acc 0.9413407821229051:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 147, train_loss = 20.496245205402374, train_acc = 0.9540055891942245\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 148, train_loss = 20.441682677716017, train_acc = 0.9541220307405682\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 149, train_loss = 20.387186210602522, train_acc = 0.9541220307405682\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 150, train_loss = 20.334812454879284, train_acc = 0.9541220307405682\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 151, train_loss = 20.28178722783923, train_acc = 0.9541220307405682\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 152, train_loss = 20.230928521603346, train_acc = 0.9544713553795995\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 153, train_loss = 20.179203756153584, train_acc = 0.9545877969259432\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 154, train_loss = 20.126196898519993, train_acc = 0.9545877969259432\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 155, train_loss = 20.076110053807497, train_acc = 0.9547042384722869\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 156, train_loss = 20.02743910253048, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 157, train_loss = 19.978439355269074, train_acc = 0.9547042384722869\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 158, train_loss = 19.928284445777535, train_acc = 0.9550535631113182\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 159, train_loss = 19.880640583112836, train_acc = 0.9552864462040056\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 160, train_loss = 19.83118811622262, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 161, train_loss = 19.78548894263804, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 162, train_loss = 19.736569402739406, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 163, train_loss = 19.690474605187774, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 164, train_loss = 19.643337262794375, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 165, train_loss = 19.598491983488202, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 166, train_loss = 19.553584998473525, train_acc = 0.955519329296693\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 167, train_loss = 19.50675349496305, train_acc = 0.955519329296693\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 168, train_loss = 19.462023897096515, train_acc = 0.955519329296693\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 169, train_loss = 19.417699854820967, train_acc = 0.9556357708430367\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 170, train_loss = 19.375289710238576, train_acc = 0.9557522123893806\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 171, train_loss = 19.333114251494408, train_acc = 0.955985095482068\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 172, train_loss = 19.291674146428704, train_acc = 0.9562179785747554\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 173, train_loss = 19.247472753748298, train_acc = 0.9563344201210993\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 174, train_loss = 19.205330861732364, train_acc = 0.9563344201210993\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 175, train_loss = 19.161065699532628, train_acc = 0.956450861667443\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 176, train_loss = 19.12227906100452, train_acc = 0.9568001863064741\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 177, train_loss = 19.08053714968264, train_acc = 0.9572659524918491\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 178, train_loss = 19.041599614545703, train_acc = 0.9571495109455054\n",
      "test Acc 0.9432029795158287:\n",
      "12th- epoch: 179, train_loss = 19.001378485932946, train_acc = 0.9572659524918491\n",
      "test Acc 0.9432029795158287:\n",
      "12th- epoch: 180, train_loss = 18.963289903476834, train_acc = 0.9572659524918491\n",
      "test Acc 0.9432029795158287:\n",
      "12th- epoch: 181, train_loss = 18.92171007208526, train_acc = 0.9574988355845365\n",
      "test Acc 0.9432029795158287:\n",
      "12th- epoch: 182, train_loss = 18.884284116327763, train_acc = 0.9574988355845365\n",
      "test Acc 0.9436685288640596:\n",
      "12th- epoch: 183, train_loss = 18.845362845808268, train_acc = 0.9574988355845365\n",
      "test Acc 0.9436685288640596:\n",
      "12th- epoch: 184, train_loss = 18.807082226499915, train_acc = 0.9576152771308803\n",
      "test Acc 0.9450651769087524:\n",
      "12th- epoch: 185, train_loss = 18.7673714235425, train_acc = 0.9577317186772241\n",
      "test Acc 0.9450651769087524:\n",
      "12th- epoch: 186, train_loss = 18.73037838190794, train_acc = 0.9578481602235678\n",
      "test Acc 0.9450651769087524:\n",
      "12th- epoch: 187, train_loss = 18.696619039401412, train_acc = 0.9578481602235678\n",
      "test Acc 0.9450651769087524:\n",
      "12th- epoch: 188, train_loss = 18.655986281111836, train_acc = 0.9578481602235678\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 189, train_loss = 18.621898278594017, train_acc = 0.9581974848625989\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 190, train_loss = 18.586224487051368, train_acc = 0.9583139264089428\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 191, train_loss = 18.55089613981545, train_acc = 0.9584303679552865\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 192, train_loss = 18.516128558665514, train_acc = 0.9585468095016302\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 193, train_loss = 18.48061112128198, train_acc = 0.9585468095016302\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 194, train_loss = 18.445548605173826, train_acc = 0.9585468095016302\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 195, train_loss = 18.408845249563456, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 196, train_loss = 18.376481847837567, train_acc = 0.9587796925943176\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 197, train_loss = 18.339756967499852, train_acc = 0.9587796925943176\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 198, train_loss = 18.30925819836557, train_acc = 0.9587796925943176\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 199, train_loss = 18.27601958811283, train_acc = 0.9587796925943176\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 200, train_loss = 18.243327101692557, train_acc = 0.9587796925943176\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 201, train_loss = 18.210646461695433, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 202, train_loss = 18.17557900212705, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 203, train_loss = 18.143026381731033, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 204, train_loss = 18.11198085360229, train_acc = 0.9587796925943176\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 205, train_loss = 18.080584935843945, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 206, train_loss = 18.05042708478868, train_acc = 0.9590125756870052\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 207, train_loss = 18.017186189070344, train_acc = 0.9590125756870052\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 208, train_loss = 17.9897791557014, train_acc = 0.9590125756870052\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 209, train_loss = 17.957126604393125, train_acc = 0.9591290172333489\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 210, train_loss = 17.929706575348973, train_acc = 0.9591290172333489\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 211, train_loss = 17.899548415094614, train_acc = 0.9592454587796926\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 212, train_loss = 17.867513271048665, train_acc = 0.9592454587796926\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 213, train_loss = 17.838751005008817, train_acc = 0.9593619003260363\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 214, train_loss = 17.80942096747458, train_acc = 0.9593619003260363\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 215, train_loss = 17.78032791428268, train_acc = 0.9595947834187238\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 216, train_loss = 17.751112025231123, train_acc = 0.9597112249650676\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 217, train_loss = 17.72528655640781, train_acc = 0.9597112249650676\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 218, train_loss = 17.697277637198567, train_acc = 0.9597112249650676\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 219, train_loss = 17.669395457953215, train_acc = 0.9598276665114113\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 220, train_loss = 17.64203425683081, train_acc = 0.9598276665114113\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 221, train_loss = 17.613194923847914, train_acc = 0.959944108057755\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 222, train_loss = 17.58659259043634, train_acc = 0.959944108057755\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 223, train_loss = 17.560686921700835, train_acc = 0.959944108057755\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 224, train_loss = 17.532555578276515, train_acc = 0.959944108057755\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 225, train_loss = 17.50561989285052, train_acc = 0.9600605496040987\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 226, train_loss = 17.478961085900664, train_acc = 0.9601769911504425\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 227, train_loss = 17.451005501672626, train_acc = 0.9601769911504425\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 228, train_loss = 17.424039164558053, train_acc = 0.9601769911504425\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 229, train_loss = 17.39758492074907, train_acc = 0.9601769911504425\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 230, train_loss = 17.37350519746542, train_acc = 0.9602934326967862\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 231, train_loss = 17.348053216934204, train_acc = 0.96040987424313\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 232, train_loss = 17.323062462732196, train_acc = 0.9605263157894737\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 233, train_loss = 17.29930303618312, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 234, train_loss = 17.274704109877348, train_acc = 0.9606427573358174\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 235, train_loss = 17.24989813938737, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 236, train_loss = 17.22461278550327, train_acc = 0.9608756404285049\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 237, train_loss = 17.202186891809106, train_acc = 0.9608756404285049\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 238, train_loss = 17.176229337230325, train_acc = 0.9609920819748486\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 239, train_loss = 17.15222531184554, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 240, train_loss = 17.128316771239042, train_acc = 0.9612249650675361\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 241, train_loss = 17.10528510250151, train_acc = 0.9613414066138798\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 242, train_loss = 17.079312965273857, train_acc = 0.9613414066138798\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 243, train_loss = 17.054989270865917, train_acc = 0.9613414066138798\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 244, train_loss = 17.0330590326339, train_acc = 0.9614578481602236\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 245, train_loss = 17.01056095212698, train_acc = 0.9614578481602236\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 246, train_loss = 16.987486772239208, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 247, train_loss = 16.965954722836614, train_acc = 0.9618071727992548\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 248, train_loss = 16.94434069469571, train_acc = 0.9619236143455985\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 249, train_loss = 16.92049529775977, train_acc = 0.962156497438286\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 250, train_loss = 16.899237944744527, train_acc = 0.9622729389846297\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 251, train_loss = 16.877849336713552, train_acc = 0.9623893805309734\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 252, train_loss = 16.85674958769232, train_acc = 0.9623893805309734\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 253, train_loss = 16.83498670067638, train_acc = 0.9626222636236609\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 254, train_loss = 16.81509259995073, train_acc = 0.9627387051700047\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 255, train_loss = 16.794160593301058, train_acc = 0.9627387051700047\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 256, train_loss = 16.773769583553076, train_acc = 0.9627387051700047\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 257, train_loss = 16.7524024406448, train_acc = 0.9627387051700047\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 258, train_loss = 16.7312622256577, train_acc = 0.9627387051700047\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 259, train_loss = 16.711559109389782, train_acc = 0.9627387051700047\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 260, train_loss = 16.69111756980419, train_acc = 0.9627387051700047\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 261, train_loss = 16.668569437228143, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 262, train_loss = 16.647619317285717, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 263, train_loss = 16.627389104105532, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 264, train_loss = 16.60854898765683, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 265, train_loss = 16.589425285346806, train_acc = 0.9629715882626921\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 266, train_loss = 16.57076038699597, train_acc = 0.9629715882626921\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 267, train_loss = 16.55061151832342, train_acc = 0.9629715882626921\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 268, train_loss = 16.530966374091804, train_acc = 0.9630880298090359\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 269, train_loss = 16.51151667535305, train_acc = 0.9630880298090359\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 270, train_loss = 16.491901266388595, train_acc = 0.9630880298090359\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 271, train_loss = 16.472863245755434, train_acc = 0.9632044713553796\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 272, train_loss = 16.455010761506855, train_acc = 0.9633209129017233\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 273, train_loss = 16.437517245300114, train_acc = 0.9634373544480671\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 274, train_loss = 16.418896801769733, train_acc = 0.9635537959944108\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 275, train_loss = 16.40172493085265, train_acc = 0.9635537959944108\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 276, train_loss = 16.383251289837062, train_acc = 0.9635537959944108\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 277, train_loss = 16.363099941052496, train_acc = 0.9636702375407545\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 278, train_loss = 16.346269962377846, train_acc = 0.9636702375407545\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 279, train_loss = 16.329807988367975, train_acc = 0.9636702375407545\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 280, train_loss = 16.31172593589872, train_acc = 0.9636702375407545\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 281, train_loss = 16.29273543227464, train_acc = 0.9637866790870983\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 282, train_loss = 16.277689318172634, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 283, train_loss = 16.25841864105314, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 284, train_loss = 16.24156311992556, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 285, train_loss = 16.22351571265608, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 286, train_loss = 16.20779989566654, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 287, train_loss = 16.190779118798673, train_acc = 0.9640195621797858\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 288, train_loss = 16.173557830043137, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 289, train_loss = 16.15782884415239, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 290, train_loss = 16.140790882520378, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 291, train_loss = 16.12442407477647, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 292, train_loss = 16.1089935163036, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 293, train_loss = 16.093845698051155, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 294, train_loss = 16.075450557284057, train_acc = 0.9642524452724732\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 295, train_loss = 16.060652711428702, train_acc = 0.9642524452724732\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 296, train_loss = 16.04382740240544, train_acc = 0.9642524452724732\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 297, train_loss = 16.028728912584484, train_acc = 0.9642524452724732\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 298, train_loss = 16.01270780619234, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 299, train_loss = 15.998877353034914, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 300, train_loss = 15.981967584230006, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 301, train_loss = 15.967734318226576, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 302, train_loss = 15.952188790775836, train_acc = 0.9644853283651607\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 303, train_loss = 15.937125665135682, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 304, train_loss = 15.922294880263507, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 305, train_loss = 15.907194138504565, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 306, train_loss = 15.891419630497694, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 307, train_loss = 15.877694889903069, train_acc = 0.9644853283651607\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 308, train_loss = 15.861487013287842, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 309, train_loss = 15.845520734786987, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 310, train_loss = 15.831086249090731, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 311, train_loss = 15.816348782740533, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 312, train_loss = 15.80357486475259, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 313, train_loss = 15.787642858922482, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 314, train_loss = 15.773586567491293, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 315, train_loss = 15.759046394377947, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 316, train_loss = 15.746323644183576, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 317, train_loss = 15.733785447664559, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 318, train_loss = 15.718257493339479, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 319, train_loss = 15.705447781831026, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 320, train_loss = 15.692007165402174, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 321, train_loss = 15.677009114064276, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 322, train_loss = 15.663632358424366, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 323, train_loss = 15.65087350551039, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 324, train_loss = 15.63668204843998, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 325, train_loss = 15.623144961893559, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 326, train_loss = 15.609820703975856, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 327, train_loss = 15.598351559601724, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 328, train_loss = 15.584161854349077, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 329, train_loss = 15.571169094182551, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 330, train_loss = 15.55905940104276, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 331, train_loss = 15.545648332685232, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 332, train_loss = 15.533662986010313, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 333, train_loss = 15.51915863994509, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 334, train_loss = 15.507986701093614, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 335, train_loss = 15.495020248927176, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 336, train_loss = 15.481588368304074, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 337, train_loss = 15.470418810844421, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 338, train_loss = 15.457709149457514, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 339, train_loss = 15.44465796276927, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 340, train_loss = 15.432762920856476, train_acc = 0.9655333022822543\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 341, train_loss = 15.42150195594877, train_acc = 0.965649743828598\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 342, train_loss = 15.40906373783946, train_acc = 0.965649743828598\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 343, train_loss = 15.396392740309238, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 344, train_loss = 15.383748504333198, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 345, train_loss = 15.372936823405325, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 346, train_loss = 15.361401437781751, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 347, train_loss = 15.349343046545982, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 348, train_loss = 15.338050388731062, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 349, train_loss = 15.326237949542701, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 350, train_loss = 15.314692615531385, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 351, train_loss = 15.303331955336034, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 352, train_loss = 15.290458519943058, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 353, train_loss = 15.280278570950031, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 354, train_loss = 15.268750539980829, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 355, train_loss = 15.257552310824394, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 356, train_loss = 15.246149660088122, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 357, train_loss = 15.233055573888123, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 358, train_loss = 15.222000658512115, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 359, train_loss = 15.21260379999876, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 360, train_loss = 15.20033413451165, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 361, train_loss = 15.18893825635314, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 362, train_loss = 15.179237599484622, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 363, train_loss = 15.168002319522202, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 364, train_loss = 15.157637267373502, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 365, train_loss = 15.145516614429653, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 366, train_loss = 15.135799539275467, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 367, train_loss = 15.125792509876192, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 368, train_loss = 15.115009028464556, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 369, train_loss = 15.10364697035402, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 370, train_loss = 15.094181396998465, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 371, train_loss = 15.082847175188363, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 372, train_loss = 15.073756928555667, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 373, train_loss = 15.06123410537839, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 374, train_loss = 15.050537768751383, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 375, train_loss = 15.040462486445904, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 376, train_loss = 15.029095935635269, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 377, train_loss = 15.021167836152017, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 378, train_loss = 15.009599342010915, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 379, train_loss = 15.000186118297279, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 380, train_loss = 14.991326361894608, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 381, train_loss = 14.980619949288666, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 382, train_loss = 14.97082681953907, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 383, train_loss = 14.962216072715819, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 384, train_loss = 14.950140650384128, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 385, train_loss = 14.942265518009663, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 386, train_loss = 14.93200760986656, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 387, train_loss = 14.922648967243731, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 388, train_loss = 14.913430861197412, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 389, train_loss = 14.903386391699314, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 390, train_loss = 14.893272369168699, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 391, train_loss = 14.883467301726341, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 392, train_loss = 14.874640915542841, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 393, train_loss = 14.864208572544158, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 394, train_loss = 14.855275030247867, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 395, train_loss = 14.846480697393417, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 396, train_loss = 14.835185636766255, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 397, train_loss = 14.826561928726733, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 398, train_loss = 14.818066244013608, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 399, train_loss = 14.80760073568672, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 400, train_loss = 14.799360153265297, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 401, train_loss = 14.790164257399738, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 402, train_loss = 14.780829440802336, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 403, train_loss = 14.77028642501682, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 404, train_loss = 14.763126231729984, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 405, train_loss = 14.75479753408581, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 406, train_loss = 14.745397822000086, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 407, train_loss = 14.737099568359554, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 408, train_loss = 14.727928611449897, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 409, train_loss = 14.719301369041204, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 410, train_loss = 14.709361545741558, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 411, train_loss = 14.7032653959468, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 412, train_loss = 14.693705421872437, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 413, train_loss = 14.685391411185265, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 414, train_loss = 14.676967438310385, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 415, train_loss = 14.668412036262453, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 416, train_loss = 14.659195327199996, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 417, train_loss = 14.651480390690267, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 418, train_loss = 14.644299381412566, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 419, train_loss = 14.635610225610435, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 420, train_loss = 14.62644341494888, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 421, train_loss = 14.61972741317004, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 422, train_loss = 14.610163412056863, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 423, train_loss = 14.603076808154583, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 424, train_loss = 14.593982662074268, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 425, train_loss = 14.586340050213039, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 426, train_loss = 14.576631710864604, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 427, train_loss = 14.569929488003254, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 428, train_loss = 14.562121338211, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 429, train_loss = 14.554984261281788, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 430, train_loss = 14.544976990669966, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 431, train_loss = 14.537224215455353, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 432, train_loss = 14.5287054060027, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 433, train_loss = 14.522698703221977, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 434, train_loss = 14.51394507754594, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 435, train_loss = 14.50666840095073, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 436, train_loss = 14.497961642686278, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 437, train_loss = 14.489429370965809, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 438, train_loss = 14.482484714593738, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 439, train_loss = 14.47536035394296, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 440, train_loss = 14.468648257199675, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 441, train_loss = 14.460728123784065, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 442, train_loss = 14.452847022563219, train_acc = 0.9675128085700978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 443, train_loss = 14.444300692528486, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 444, train_loss = 14.43845733627677, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 445, train_loss = 14.430300386156887, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 446, train_loss = 14.424008440226316, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 447, train_loss = 14.41722280299291, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 448, train_loss = 14.408917136490345, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 449, train_loss = 14.403192352503538, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 450, train_loss = 14.395526073873043, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 451, train_loss = 14.387022090610117, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 452, train_loss = 14.380485175643116, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 453, train_loss = 14.37263130908832, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 454, train_loss = 14.366206304635853, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 455, train_loss = 14.358055786695331, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 456, train_loss = 14.352087209466845, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 457, train_loss = 14.344332059379667, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 458, train_loss = 14.337525808718055, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 459, train_loss = 14.330498377326876, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 460, train_loss = 14.324663175735623, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 461, train_loss = 14.31684872880578, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 462, train_loss = 14.310139441397041, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 463, train_loss = 14.303158428519964, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 464, train_loss = 14.297472094651312, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 465, train_loss = 14.290126379579306, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 466, train_loss = 14.283560352865607, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 467, train_loss = 14.27744286134839, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 468, train_loss = 14.27008594200015, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 469, train_loss = 14.264371482189745, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 470, train_loss = 14.257804269436747, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 471, train_loss = 14.249145723879337, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 472, train_loss = 14.24425184726715, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 473, train_loss = 14.237206514924765, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 474, train_loss = 14.229818066116422, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 475, train_loss = 14.226258272770792, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 476, train_loss = 14.21830947836861, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 477, train_loss = 14.212386835366488, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 478, train_loss = 14.205415282398462, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 479, train_loss = 14.197861827909946, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 480, train_loss = 14.192056263331324, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 481, train_loss = 14.186131849884987, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 482, train_loss = 14.180451218038797, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 483, train_loss = 14.173308927565813, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 484, train_loss = 14.167143553495407, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 485, train_loss = 14.16045455634594, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 486, train_loss = 14.153856864664704, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 487, train_loss = 14.14811692154035, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 488, train_loss = 14.142403156962246, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 489, train_loss = 14.13713455060497, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 490, train_loss = 14.130188771989197, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 491, train_loss = 14.124459013342857, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 492, train_loss = 14.11672060424462, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 493, train_loss = 14.112145131919533, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 494, train_loss = 14.104252806399018, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 495, train_loss = 14.09873565658927, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 496, train_loss = 14.093232729937881, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 497, train_loss = 14.088181179016829, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 498, train_loss = 14.081297693308443, train_acc = 0.9686772240335352\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 499, train_loss = 14.075327216181904, train_acc = 0.9686772240335352\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████                                          | 12/30 [1:19:53<2:00:01, 400.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "13th- epoch: 0, train_loss = 272.7261302471161, train_acc = 0.4351420586865394\n",
      "test Acc 0.49813780260707635:\n",
      "13th- epoch: 1, train_loss = 211.00203347206116, train_acc = 0.5\n",
      "test Acc 0.49906890130353815:\n",
      "13th- epoch: 2, train_loss = 177.96690702438354, train_acc = 0.5073358174196554\n",
      "test Acc 0.5176908752327747:\n",
      "13th- epoch: 3, train_loss = 161.18100148439407, train_acc = 0.5384257102934327\n",
      "test Acc 0.5758845437616388:\n",
      "13th- epoch: 4, train_loss = 148.35128086805344, train_acc = 0.5874476013041453\n",
      "test Acc 0.6121973929236499:\n",
      "13th- epoch: 5, train_loss = 137.0123335123062, train_acc = 0.6240102468560782\n",
      "test Acc 0.638733705772812:\n",
      "13th- epoch: 6, train_loss = 126.75883102416992, train_acc = 0.6559152305542617\n",
      "test Acc 0.6652700186219739:\n",
      "13th- epoch: 7, train_loss = 117.48385787010193, train_acc = 0.6877037727061015\n",
      "test Acc 0.7453445065176909:\n",
      "13th- epoch: 8, train_loss = 109.02030807733536, train_acc = 0.7540754541220307\n",
      "test Acc 0.7737430167597765:\n",
      "13th- epoch: 9, train_loss = 101.16808462142944, train_acc = 0.7926176059618072\n",
      "test Acc 0.8049348230912476:\n",
      "13th- epoch: 10, train_loss = 93.88083213567734, train_acc = 0.8148579413134607\n",
      "test Acc 0.8263500931098696:\n",
      "13th- epoch: 11, train_loss = 87.22435706853867, train_acc = 0.8297624592454588\n",
      "test Acc 0.8463687150837989:\n",
      "13th- epoch: 12, train_loss = 81.22433176636696, train_acc = 0.8430367955286446\n",
      "test Acc 0.8556797020484171:\n",
      "13th- epoch: 13, train_loss = 75.88916745781898, train_acc = 0.8518863530507685\n",
      "test Acc 0.8631284916201117:\n",
      "13th- epoch: 14, train_loss = 71.20731434226036, train_acc = 0.8591057289240801\n",
      "test Acc 0.866852886405959:\n",
      "13th- epoch: 15, train_loss = 67.12221798300743, train_acc = 0.8628318584070797\n",
      "test Acc 0.8691806331471136:\n",
      "13th- epoch: 16, train_loss = 63.57499587535858, train_acc = 0.8677224033535166\n",
      "test Acc 0.8747672253258846:\n",
      "13th- epoch: 17, train_loss = 60.49510335922241, train_acc = 0.874126688402422\n",
      "test Acc 0.88268156424581:\n",
      "13th- epoch: 18, train_loss = 57.807653561234474, train_acc = 0.8790172333488588\n",
      "test Acc 0.888733705772812:\n",
      "13th- epoch: 19, train_loss = 55.44702926278114, train_acc = 0.8822775966464834\n",
      "test Acc 0.8896648044692738:\n",
      "13th- epoch: 20, train_loss = 53.360675275325775, train_acc = 0.886003726129483\n",
      "test Acc 0.8919925512104283:\n",
      "13th- epoch: 21, train_loss = 51.5137350410223, train_acc = 0.8887983232417327\n",
      "test Acc 0.8980446927374302:\n",
      "13th- epoch: 22, train_loss = 49.87590381503105, train_acc = 0.8928737773637634\n",
      "test Acc 0.9022346368715084:\n",
      "13th- epoch: 23, train_loss = 48.41674855351448, train_acc = 0.8997438285980438\n",
      "test Acc 0.904096834264432:\n",
      "13th- epoch: 24, train_loss = 47.11031664907932, train_acc = 0.901374010246856\n",
      "test Acc 0.904562383612663:\n",
      "13th- epoch: 25, train_loss = 45.93291284143925, train_acc = 0.902305542617606\n",
      "test Acc 0.9054934823091247:\n",
      "13th- epoch: 26, train_loss = 44.86540696024895, train_acc = 0.9033535165346995\n",
      "test Acc 0.9068901303538175:\n",
      "13th- epoch: 27, train_loss = 43.89040680229664, train_acc = 0.9046343735444806\n",
      "test Acc 0.9082867783985102:\n",
      "13th- epoch: 28, train_loss = 42.996957421302795, train_acc = 0.9061481136469492\n",
      "test Acc 0.9087523277467412:\n",
      "13th- epoch: 29, train_loss = 42.17384451627731, train_acc = 0.907545412203074\n",
      "test Acc 0.909683426443203:\n",
      "13th- epoch: 30, train_loss = 41.411637008190155, train_acc = 0.9084769445738239\n",
      "test Acc 0.9106145251396648:\n",
      "13th- epoch: 31, train_loss = 40.70388711988926, train_acc = 0.9105728924080112\n",
      "test Acc 0.9106145251396648:\n",
      "13th- epoch: 32, train_loss = 40.042715683579445, train_acc = 0.9126688402421984\n",
      "test Acc 0.9106145251396648:\n",
      "13th- epoch: 33, train_loss = 39.4232541769743, train_acc = 0.9140661387983232\n",
      "test Acc 0.9110800744878957:\n",
      "13th- epoch: 34, train_loss = 38.84054547548294, train_acc = 0.9153469958081043\n",
      "test Acc 0.9120111731843575:\n",
      "13th- epoch: 35, train_loss = 38.29112942516804, train_acc = 0.9169771774569166\n",
      "test Acc 0.9124767225325885:\n",
      "13th- epoch: 36, train_loss = 37.770266726613045, train_acc = 0.9177922682813228\n",
      "test Acc 0.9129422718808193:\n",
      "13th- epoch: 37, train_loss = 37.27650760114193, train_acc = 0.9188402421984164\n",
      "test Acc 0.9143389199255121:\n",
      "13th- epoch: 38, train_loss = 36.80648799240589, train_acc = 0.9193060083837913\n",
      "test Acc 0.9166666666666666:\n",
      "13th- epoch: 39, train_loss = 36.35842715203762, train_acc = 0.9203539823008849\n",
      "test Acc 0.9180633147113594:\n",
      "13th- epoch: 40, train_loss = 35.930907160043716, train_acc = 0.9211690731252911\n",
      "test Acc 0.9189944134078212:\n",
      "13th- epoch: 41, train_loss = 35.522427685558796, train_acc = 0.922566371681416\n",
      "test Acc 0.9203910614525139:\n",
      "13th- epoch: 42, train_loss = 35.13074812293053, train_acc = 0.9234979040521658\n",
      "test Acc 0.9213221601489758:\n",
      "13th- epoch: 43, train_loss = 34.75533989816904, train_acc = 0.9246623195156032\n",
      "test Acc 0.9222532588454376:\n",
      "13th- epoch: 44, train_loss = 34.393660597503185, train_acc = 0.9252445272473219\n",
      "test Acc 0.9227188081936686:\n",
      "13th- epoch: 45, train_loss = 34.04582381993532, train_acc = 0.9258267349790406\n",
      "test Acc 0.9227188081936686:\n",
      "13th- epoch: 46, train_loss = 33.7108838185668, train_acc = 0.9257102934326968\n",
      "test Acc 0.9236499068901304:\n",
      "13th- epoch: 47, train_loss = 33.38778857886791, train_acc = 0.9267582673497904\n",
      "test Acc 0.9236499068901304:\n",
      "13th- epoch: 48, train_loss = 33.07559248059988, train_acc = 0.9271075919888216\n",
      "test Acc 0.9241154562383612:\n",
      "13th- epoch: 49, train_loss = 32.77337849885225, train_acc = 0.9274569166278528\n",
      "test Acc 0.9241154562383612:\n",
      "13th- epoch: 50, train_loss = 32.48110130429268, train_acc = 0.9280391243595715\n",
      "test Acc 0.9245810055865922:\n",
      "13th- epoch: 51, train_loss = 32.197457171976566, train_acc = 0.9290870982766651\n",
      "test Acc 0.9250465549348231:\n",
      "13th- epoch: 52, train_loss = 31.923155091702938, train_acc = 0.9294364229156963\n",
      "test Acc 0.9264432029795159:\n",
      "13th- epoch: 53, train_loss = 31.657340332865715, train_acc = 0.9295528644620401\n",
      "test Acc 0.9264432029795159:\n",
      "13th- epoch: 54, train_loss = 31.399189308285713, train_acc = 0.9303679552864462\n",
      "test Acc 0.9269087523277467:\n",
      "13th- epoch: 55, train_loss = 31.149072125554085, train_acc = 0.9309501630181649\n",
      "test Acc 0.9273743016759777:\n",
      "13th- epoch: 56, train_loss = 30.90577708929777, train_acc = 0.9310666045645086\n",
      "test Acc 0.9278398510242085:\n",
      "13th- epoch: 57, train_loss = 30.66894117742777, train_acc = 0.9315323707498836\n",
      "test Acc 0.9278398510242085:\n",
      "13th- epoch: 58, train_loss = 30.43778446316719, train_acc = 0.931765253842571\n",
      "test Acc 0.9278398510242085:\n",
      "13th- epoch: 59, train_loss = 30.211988165974617, train_acc = 0.9319981369352585\n",
      "test Acc 0.9278398510242085:\n",
      "13th- epoch: 60, train_loss = 29.99194362014532, train_acc = 0.9324639031206334\n",
      "test Acc 0.9278398510242085:\n",
      "13th- epoch: 61, train_loss = 29.77613851428032, train_acc = 0.9330461108523521\n",
      "test Acc 0.9278398510242085:\n",
      "13th- epoch: 62, train_loss = 29.566369399428368, train_acc = 0.9331625523986958\n",
      "test Acc 0.9283054003724395:\n",
      "13th- epoch: 63, train_loss = 29.360259018838406, train_acc = 0.9333954354913834\n",
      "test Acc 0.9287709497206704:\n",
      "13th- epoch: 64, train_loss = 29.159294933080673, train_acc = 0.9337447601304145\n",
      "test Acc 0.9287709497206704:\n",
      "13th- epoch: 65, train_loss = 28.9618806168437, train_acc = 0.9340940847694458\n",
      "test Acc 0.9292364990689013:\n",
      "13th- epoch: 66, train_loss = 28.768317013978958, train_acc = 0.9347927340475082\n",
      "test Acc 0.9292364990689013:\n",
      "13th- epoch: 67, train_loss = 28.57895026355982, train_acc = 0.9353749417792269\n",
      "test Acc 0.9292364990689013:\n",
      "13th- epoch: 68, train_loss = 28.393799170851707, train_acc = 0.9354913833255706\n",
      "test Acc 0.9292364990689013:\n",
      "13th- epoch: 69, train_loss = 28.213636681437492, train_acc = 0.9359571495109456\n",
      "test Acc 0.9292364990689013:\n",
      "13th- epoch: 70, train_loss = 28.03643413633108, train_acc = 0.9365393572426641\n",
      "test Acc 0.9292364990689013:\n",
      "13th- epoch: 71, train_loss = 27.86307866126299, train_acc = 0.9370051234280391\n",
      "test Acc 0.9292364990689013:\n",
      "13th- epoch: 72, train_loss = 27.693491719663143, train_acc = 0.9372380065207266\n",
      "test Acc 0.9292364990689013:\n",
      "13th- epoch: 73, train_loss = 27.527300730347633, train_acc = 0.9374708896134141\n",
      "test Acc 0.9297020484171322:\n",
      "13th- epoch: 74, train_loss = 27.36409618705511, train_acc = 0.9378202142524453\n",
      "test Acc 0.9297020484171322:\n",
      "13th- epoch: 75, train_loss = 27.20333171635866, train_acc = 0.9384024219841639\n",
      "test Acc 0.9297020484171322:\n",
      "13th- epoch: 76, train_loss = 27.046116918325424, train_acc = 0.9392175128085701\n",
      "test Acc 0.9297020484171322:\n",
      "13th- epoch: 77, train_loss = 26.891727715730667, train_acc = 0.9397997205402888\n",
      "test Acc 0.9297020484171322:\n",
      "13th- epoch: 78, train_loss = 26.739994511008263, train_acc = 0.9399161620866325\n",
      "test Acc 0.9297020484171322:\n",
      "13th- epoch: 79, train_loss = 26.59119349718094, train_acc = 0.9407312529110387\n",
      "test Acc 0.930633147113594:\n",
      "13th- epoch: 80, train_loss = 26.445787210017443, train_acc = 0.9410805775500699\n",
      "test Acc 0.930633147113594:\n",
      "13th- epoch: 81, train_loss = 26.303148940205574, train_acc = 0.9415463437354448\n",
      "test Acc 0.930633147113594:\n",
      "13th- epoch: 82, train_loss = 26.162965048104525, train_acc = 0.9417792268281323\n",
      "test Acc 0.930633147113594:\n",
      "13th- epoch: 83, train_loss = 26.025547850877047, train_acc = 0.941895668374476\n",
      "test Acc 0.930633147113594:\n",
      "13th- epoch: 84, train_loss = 25.89095151424408, train_acc = 0.942361434559851\n",
      "test Acc 0.930633147113594:\n",
      "13th- epoch: 85, train_loss = 25.75870520249009, train_acc = 0.9427107591988821\n",
      "test Acc 0.930633147113594:\n",
      "13th- epoch: 86, train_loss = 25.628008127212524, train_acc = 0.9430600838379134\n",
      "test Acc 0.931098696461825:\n",
      "13th- epoch: 87, train_loss = 25.500454302877188, train_acc = 0.9434094084769445\n",
      "test Acc 0.931098696461825:\n",
      "13th- epoch: 88, train_loss = 25.37478758394718, train_acc = 0.9438751746623195\n",
      "test Acc 0.9315642458100558:\n",
      "13th- epoch: 89, train_loss = 25.252127893269062, train_acc = 0.9438751746623195\n",
      "test Acc 0.9320297951582868:\n",
      "13th- epoch: 90, train_loss = 25.131299909204245, train_acc = 0.944108057755007\n",
      "test Acc 0.9324953445065177:\n",
      "13th- epoch: 91, train_loss = 25.01242984086275, train_acc = 0.9443409408476945\n",
      "test Acc 0.9329608938547486:\n",
      "13th- epoch: 92, train_loss = 24.895463604480028, train_acc = 0.9443409408476945\n",
      "test Acc 0.9334264432029795:\n",
      "13th- epoch: 93, train_loss = 24.781363405287266, train_acc = 0.9443409408476945\n",
      "test Acc 0.9338919925512105:\n",
      "13th- epoch: 94, train_loss = 24.668686419725418, train_acc = 0.9445738239403819\n",
      "test Acc 0.9343575418994413:\n",
      "13th- epoch: 95, train_loss = 24.557341530919075, train_acc = 0.9448067070330693\n",
      "test Acc 0.9348230912476723:\n",
      "13th- epoch: 96, train_loss = 24.44842215999961, train_acc = 0.9448067070330693\n",
      "test Acc 0.9348230912476723:\n",
      "13th- epoch: 97, train_loss = 24.341393787413836, train_acc = 0.9451560316721006\n",
      "test Acc 0.9352886405959032:\n",
      "13th- epoch: 98, train_loss = 24.2363912910223, train_acc = 0.9456217978574756\n",
      "test Acc 0.936219739292365:\n",
      "13th- epoch: 99, train_loss = 24.133163895457983, train_acc = 0.9460875640428504\n",
      "test Acc 0.936219739292365:\n",
      "13th- epoch: 100, train_loss = 24.03074150159955, train_acc = 0.9464368886818817\n",
      "test Acc 0.936219739292365:\n",
      "13th- epoch: 101, train_loss = 23.930811762809753, train_acc = 0.9465533302282254\n",
      "test Acc 0.936219739292365:\n",
      "13th- epoch: 102, train_loss = 23.83193950727582, train_acc = 0.9466697717745691\n",
      "test Acc 0.936219739292365:\n",
      "13th- epoch: 103, train_loss = 23.735330410301685, train_acc = 0.9469026548672567\n",
      "test Acc 0.9366852886405959:\n",
      "13th- epoch: 104, train_loss = 23.640144776552916, train_acc = 0.9473684210526315\n",
      "test Acc 0.9366852886405959:\n",
      "13th- epoch: 105, train_loss = 23.546314533799887, train_acc = 0.9477177456916628\n",
      "test Acc 0.9366852886405959:\n",
      "13th- epoch: 106, train_loss = 23.454795211553574, train_acc = 0.9478341872380065\n",
      "test Acc 0.9366852886405959:\n",
      "13th- epoch: 107, train_loss = 23.363362438976765, train_acc = 0.9479506287843502\n",
      "test Acc 0.9371508379888268:\n",
      "13th- epoch: 108, train_loss = 23.273543767631054, train_acc = 0.9481835118770378\n",
      "test Acc 0.9371508379888268:\n",
      "13th- epoch: 109, train_loss = 23.185494609177113, train_acc = 0.9482999534233815\n",
      "test Acc 0.9371508379888268:\n",
      "13th- epoch: 110, train_loss = 23.098161570727825, train_acc = 0.9482999534233815\n",
      "test Acc 0.9376163873370578:\n",
      "13th- epoch: 111, train_loss = 23.012918401509523, train_acc = 0.9484163949697252\n",
      "test Acc 0.9376163873370578:\n",
      "13th- epoch: 112, train_loss = 22.928114116191864, train_acc = 0.9485328365160689\n",
      "test Acc 0.9376163873370578:\n",
      "13th- epoch: 113, train_loss = 22.845622532069683, train_acc = 0.9487657196087564\n",
      "test Acc 0.9380819366852886:\n",
      "13th- epoch: 114, train_loss = 22.764692541211843, train_acc = 0.9489986027014439\n",
      "test Acc 0.9380819366852886:\n",
      "13th- epoch: 115, train_loss = 22.683550745248795, train_acc = 0.9491150442477876\n",
      "test Acc 0.9380819366852886:\n",
      "13th- epoch: 116, train_loss = 22.603762306272984, train_acc = 0.9492314857941313\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 117, train_loss = 22.526090502738953, train_acc = 0.9496972519795063\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 118, train_loss = 22.44922584295273, train_acc = 0.9499301350721937\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 119, train_loss = 22.373816169798374, train_acc = 0.9499301350721937\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 120, train_loss = 22.298524640500546, train_acc = 0.9499301350721937\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 121, train_loss = 22.224215660244226, train_acc = 0.9500465766185375\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 122, train_loss = 22.151301376521587, train_acc = 0.9501630181648812\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 123, train_loss = 22.08041649311781, train_acc = 0.9500465766185375\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 124, train_loss = 22.00882015377283, train_acc = 0.9500465766185375\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 125, train_loss = 21.938610650599003, train_acc = 0.9503959012575687\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 126, train_loss = 21.869560915976763, train_acc = 0.9505123428039124\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 127, train_loss = 21.8010673224926, train_acc = 0.9507452258965999\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 128, train_loss = 21.73301713913679, train_acc = 0.9508616674429436\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 129, train_loss = 21.666174814105034, train_acc = 0.9510945505356311\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 130, train_loss = 21.599330566823483, train_acc = 0.951560316721006\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 131, train_loss = 21.53414871916175, train_acc = 0.951560316721006\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 132, train_loss = 21.47023543342948, train_acc = 0.9516767582673498\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 133, train_loss = 21.40565013885498, train_acc = 0.9516767582673498\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 134, train_loss = 21.341464821249247, train_acc = 0.9517931998136935\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 135, train_loss = 21.277933780103922, train_acc = 0.9517931998136935\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 136, train_loss = 21.214297626167536, train_acc = 0.9517931998136935\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 137, train_loss = 21.154062896966934, train_acc = 0.9519096413600373\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 138, train_loss = 21.09306637942791, train_acc = 0.9522589659990685\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 139, train_loss = 21.032516840845346, train_acc = 0.9526082906380997\n",
      "test Acc 0.9394785847299814:\n",
      "13th- epoch: 140, train_loss = 20.973294842988253, train_acc = 0.9526082906380997\n",
      "test Acc 0.9394785847299814:\n",
      "13th- epoch: 141, train_loss = 20.91550077497959, train_acc = 0.952491849091756\n",
      "test Acc 0.9394785847299814:\n",
      "13th- epoch: 142, train_loss = 20.857173416763544, train_acc = 0.9526082906380997\n",
      "test Acc 0.9399441340782123:\n",
      "13th- epoch: 143, train_loss = 20.79993522912264, train_acc = 0.9526082906380997\n",
      "test Acc 0.9399441340782123:\n",
      "13th- epoch: 144, train_loss = 20.74269276484847, train_acc = 0.9529576152771309\n",
      "test Acc 0.9399441340782123:\n",
      "13th- epoch: 145, train_loss = 20.686480708420277, train_acc = 0.9533069399161621\n",
      "test Acc 0.9399441340782123:\n",
      "13th- epoch: 146, train_loss = 20.63187136873603, train_acc = 0.9534233814625058\n",
      "test Acc 0.9399441340782123:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 147, train_loss = 20.57724417373538, train_acc = 0.9534233814625058\n",
      "test Acc 0.9404096834264432:\n",
      "13th- epoch: 148, train_loss = 20.52184085175395, train_acc = 0.9535398230088495\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 149, train_loss = 20.468800742179155, train_acc = 0.9535398230088495\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 150, train_loss = 20.415191132575274, train_acc = 0.9535398230088495\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 151, train_loss = 20.3625460639596, train_acc = 0.9537727061015371\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 152, train_loss = 20.31016020476818, train_acc = 0.9538891476478808\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 153, train_loss = 20.259089466184378, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 154, train_loss = 20.207855701446533, train_acc = 0.9541220307405682\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 155, train_loss = 20.156932059675455, train_acc = 0.9545877969259432\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 156, train_loss = 20.107696056365967, train_acc = 0.9545877969259432\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 157, train_loss = 20.057143108919263, train_acc = 0.9545877969259432\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 158, train_loss = 20.00806026160717, train_acc = 0.9545877969259432\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 159, train_loss = 19.958357261493802, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "13th- epoch: 160, train_loss = 19.912479916587472, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "13th- epoch: 161, train_loss = 19.864140471443534, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "13th- epoch: 162, train_loss = 19.81763138063252, train_acc = 0.9549371215649743\n",
      "test Acc 0.9422718808193669:\n",
      "13th- epoch: 163, train_loss = 19.770283982157707, train_acc = 0.9550535631113182\n",
      "test Acc 0.9422718808193669:\n",
      "13th- epoch: 164, train_loss = 19.72363329678774, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "13th- epoch: 165, train_loss = 19.677511101588607, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "13th- epoch: 166, train_loss = 19.632434094324708, train_acc = 0.9554028877503493\n",
      "test Acc 0.9422718808193669:\n",
      "13th- epoch: 167, train_loss = 19.587608030065894, train_acc = 0.9554028877503493\n",
      "test Acc 0.9422718808193669:\n",
      "13th- epoch: 168, train_loss = 19.542524479329586, train_acc = 0.955519329296693\n",
      "test Acc 0.9422718808193669:\n",
      "13th- epoch: 169, train_loss = 19.498718542978168, train_acc = 0.9557522123893806\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 170, train_loss = 19.454324224963784, train_acc = 0.9558686539357243\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 171, train_loss = 19.410762760788202, train_acc = 0.955985095482068\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 172, train_loss = 19.368436036631465, train_acc = 0.9562179785747554\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 173, train_loss = 19.325068155303597, train_acc = 0.9562179785747554\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 174, train_loss = 19.28146999143064, train_acc = 0.9563344201210993\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 175, train_loss = 19.239998744800687, train_acc = 0.956450861667443\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 176, train_loss = 19.19874769076705, train_acc = 0.956450861667443\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 177, train_loss = 19.156685197725892, train_acc = 0.956450861667443\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 178, train_loss = 19.116843624040484, train_acc = 0.9565673032137867\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 179, train_loss = 19.075745103880763, train_acc = 0.9565673032137867\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 180, train_loss = 19.03432676382363, train_acc = 0.9566837447601304\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 181, train_loss = 18.995916113257408, train_acc = 0.9570330693991617\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 182, train_loss = 18.955783408135176, train_acc = 0.9570330693991617\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 183, train_loss = 18.916488576680422, train_acc = 0.9571495109455054\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 184, train_loss = 18.877529554069042, train_acc = 0.9571495109455054\n",
      "test Acc 0.9436685288640596:\n",
      "13th- epoch: 185, train_loss = 18.83840654604137, train_acc = 0.9572659524918491\n",
      "test Acc 0.9436685288640596:\n",
      "13th- epoch: 186, train_loss = 18.801164977252483, train_acc = 0.9574988355845365\n",
      "test Acc 0.9445996275605214:\n",
      "13th- epoch: 187, train_loss = 18.763193672522902, train_acc = 0.9574988355845365\n",
      "test Acc 0.9450651769087524:\n",
      "13th- epoch: 188, train_loss = 18.725264068692923, train_acc = 0.9576152771308803\n",
      "test Acc 0.9450651769087524:\n",
      "13th- epoch: 189, train_loss = 18.687850311398506, train_acc = 0.9577317186772241\n",
      "test Acc 0.9450651769087524:\n",
      "13th- epoch: 190, train_loss = 18.65180521272123, train_acc = 0.9577317186772241\n",
      "test Acc 0.9455307262569832:\n",
      "13th- epoch: 191, train_loss = 18.614595882594585, train_acc = 0.9579646017699115\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 192, train_loss = 18.579705214127898, train_acc = 0.9581974848625989\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 193, train_loss = 18.543738095089793, train_acc = 0.9581974848625989\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 194, train_loss = 18.50716484710574, train_acc = 0.9583139264089428\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 195, train_loss = 18.470952905714512, train_acc = 0.9585468095016302\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 196, train_loss = 18.437297182157636, train_acc = 0.9587796925943176\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 197, train_loss = 18.40139444731176, train_acc = 0.9587796925943176\n",
      "test Acc 0.9455307262569832:\n",
      "13th- epoch: 198, train_loss = 18.367308862507343, train_acc = 0.9588961341406614\n",
      "test Acc 0.9455307262569832:\n",
      "13th- epoch: 199, train_loss = 18.334116799756885, train_acc = 0.9588961341406614\n",
      "test Acc 0.9455307262569832:\n",
      "13th- epoch: 200, train_loss = 18.29968493245542, train_acc = 0.9590125756870052\n",
      "test Acc 0.9455307262569832:\n",
      "13th- epoch: 201, train_loss = 18.26690150424838, train_acc = 0.9588961341406614\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 202, train_loss = 18.231951588764787, train_acc = 0.9588961341406614\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 203, train_loss = 18.20042066834867, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 204, train_loss = 18.166433760896325, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 205, train_loss = 18.1330257486552, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 206, train_loss = 18.101309591904283, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 207, train_loss = 18.0684695225209, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 208, train_loss = 18.03847044892609, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 209, train_loss = 18.006586968898773, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 210, train_loss = 17.975405398756266, train_acc = 0.9595947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 211, train_loss = 17.944460989907384, train_acc = 0.9595947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 212, train_loss = 17.915452226996422, train_acc = 0.9597112249650676\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 213, train_loss = 17.88336642831564, train_acc = 0.9597112249650676\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 214, train_loss = 17.854360178112984, train_acc = 0.9597112249650676\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 215, train_loss = 17.82302920334041, train_acc = 0.9598276665114113\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 216, train_loss = 17.79434491880238, train_acc = 0.9600605496040987\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 217, train_loss = 17.76478717662394, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 218, train_loss = 17.734428837895393, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 219, train_loss = 17.706690225750208, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 220, train_loss = 17.676398687064648, train_acc = 0.96040987424313\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 221, train_loss = 17.647602615877986, train_acc = 0.96040987424313\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 222, train_loss = 17.620132001116872, train_acc = 0.9605263157894737\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 223, train_loss = 17.59200920164585, train_acc = 0.9605263157894737\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 224, train_loss = 17.564545642584562, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 225, train_loss = 17.537711026147008, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 226, train_loss = 17.50998200289905, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 227, train_loss = 17.48453033529222, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 228, train_loss = 17.456352405250072, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 229, train_loss = 17.431114414706826, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 230, train_loss = 17.40419959835708, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 231, train_loss = 17.378349345177412, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 232, train_loss = 17.352646632120013, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 233, train_loss = 17.32856043614447, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 234, train_loss = 17.302750756964087, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 235, train_loss = 17.27758534066379, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 236, train_loss = 17.251737328246236, train_acc = 0.9611085235211924\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 237, train_loss = 17.228027364239097, train_acc = 0.9611085235211924\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 238, train_loss = 17.20368491485715, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 239, train_loss = 17.17813866212964, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 240, train_loss = 17.154445964843035, train_acc = 0.9614578481602236\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 241, train_loss = 17.13148088566959, train_acc = 0.9614578481602236\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 242, train_loss = 17.106995029374957, train_acc = 0.9615742897065673\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 243, train_loss = 17.08305294625461, train_acc = 0.961690731252911\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 244, train_loss = 17.05974414013326, train_acc = 0.9618071727992548\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 245, train_loss = 17.03769960999489, train_acc = 0.9618071727992548\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 246, train_loss = 17.012593261897564, train_acc = 0.961690731252911\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 247, train_loss = 16.990280551835895, train_acc = 0.9618071727992548\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 248, train_loss = 16.969247007742524, train_acc = 0.9620400558919422\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 249, train_loss = 16.946355720981956, train_acc = 0.9620400558919422\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 250, train_loss = 16.922959765419364, train_acc = 0.962156497438286\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 251, train_loss = 16.90118690393865, train_acc = 0.962156497438286\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 252, train_loss = 16.879654755815864, train_acc = 0.9622729389846297\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 253, train_loss = 16.857621697708964, train_acc = 0.9623893805309734\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 254, train_loss = 16.834972834214568, train_acc = 0.9625058220773172\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 255, train_loss = 16.815673913806677, train_acc = 0.9625058220773172\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 256, train_loss = 16.79157248698175, train_acc = 0.9625058220773172\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 257, train_loss = 16.77145910076797, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 258, train_loss = 16.752438448369503, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 259, train_loss = 16.730851009488106, train_acc = 0.9627387051700047\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 260, train_loss = 16.70994410291314, train_acc = 0.9627387051700047\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 261, train_loss = 16.68889410700649, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 262, train_loss = 16.66784023027867, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 263, train_loss = 16.64811711013317, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 264, train_loss = 16.63012874033302, train_acc = 0.9629715882626921\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 265, train_loss = 16.6090747108683, train_acc = 0.9630880298090359\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 266, train_loss = 16.589800585992634, train_acc = 0.9630880298090359\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 267, train_loss = 16.569165549241006, train_acc = 0.9630880298090359\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 268, train_loss = 16.551470138132572, train_acc = 0.9630880298090359\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 269, train_loss = 16.530223813839257, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "13th- epoch: 270, train_loss = 16.51300475001335, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "13th- epoch: 271, train_loss = 16.493332851678133, train_acc = 0.9634373544480671\n",
      "test Acc 0.9487895716945997:\n",
      "13th- epoch: 272, train_loss = 16.47559652198106, train_acc = 0.9634373544480671\n",
      "test Acc 0.9487895716945997:\n",
      "13th- epoch: 273, train_loss = 16.45483312290162, train_acc = 0.9635537959944108\n",
      "test Acc 0.9487895716945997:\n",
      "13th- epoch: 274, train_loss = 16.436335087753832, train_acc = 0.9635537959944108\n",
      "test Acc 0.9487895716945997:\n",
      "13th- epoch: 275, train_loss = 16.420071256347, train_acc = 0.9636702375407545\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 276, train_loss = 16.398956549353898, train_acc = 0.9636702375407545\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 277, train_loss = 16.383082296699286, train_acc = 0.9636702375407545\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 278, train_loss = 16.36442467197776, train_acc = 0.9636702375407545\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 279, train_loss = 16.346949958242476, train_acc = 0.9636702375407545\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 280, train_loss = 16.330529782921076, train_acc = 0.9636702375407545\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 281, train_loss = 16.31080865766853, train_acc = 0.9636702375407545\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 282, train_loss = 16.29533625487238, train_acc = 0.9636702375407545\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 283, train_loss = 16.275940633378923, train_acc = 0.9636702375407545\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 284, train_loss = 16.259199279360473, train_acc = 0.9637866790870983\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 285, train_loss = 16.242862650193274, train_acc = 0.9637866790870983\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 286, train_loss = 16.224926077760756, train_acc = 0.9640195621797858\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 287, train_loss = 16.208921171724796, train_acc = 0.9640195621797858\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 288, train_loss = 16.190484137274325, train_acc = 0.9640195621797858\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 289, train_loss = 16.175636955536902, train_acc = 0.9640195621797858\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 290, train_loss = 16.15904536470771, train_acc = 0.9640195621797858\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 291, train_loss = 16.1416155686602, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 292, train_loss = 16.125303708016872, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 293, train_loss = 16.10988976433873, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 294, train_loss = 16.09236117452383, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 295, train_loss = 16.077485607005656, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 296, train_loss = 16.062143304385245, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 297, train_loss = 16.045417048037052, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 298, train_loss = 16.030080842785537, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 299, train_loss = 16.013558658771217, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 300, train_loss = 15.997607841156423, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 301, train_loss = 15.98341787327081, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 302, train_loss = 15.96837459411472, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 303, train_loss = 15.952759440988302, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 304, train_loss = 15.93588023353368, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 305, train_loss = 15.92078047990799, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 306, train_loss = 15.908898969180882, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 307, train_loss = 15.89269593078643, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 308, train_loss = 15.874998492188752, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 309, train_loss = 15.863825809210539, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 310, train_loss = 15.847590889781713, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 311, train_loss = 15.832171362824738, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 312, train_loss = 15.820353305898607, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 313, train_loss = 15.805765074677765, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 314, train_loss = 15.792278970591724, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 315, train_loss = 15.779043299145997, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 316, train_loss = 15.765819816850126, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 317, train_loss = 15.750589690171182, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 318, train_loss = 15.73572079371661, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 319, train_loss = 15.721977737732232, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 320, train_loss = 15.708795681595802, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 321, train_loss = 15.69556811824441, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 322, train_loss = 15.683063816279173, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 323, train_loss = 15.668568287976086, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 324, train_loss = 15.655284139327705, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 325, train_loss = 15.642491467297077, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 326, train_loss = 15.629593188874424, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 327, train_loss = 15.616379640065134, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 328, train_loss = 15.604092453606427, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 329, train_loss = 15.590517792850733, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 330, train_loss = 15.577531275339425, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 331, train_loss = 15.564289726316929, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 332, train_loss = 15.554277148097754, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 333, train_loss = 15.540533418767154, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 334, train_loss = 15.5291208922863, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 335, train_loss = 15.514966775663197, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 336, train_loss = 15.502412828616798, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 337, train_loss = 15.490012659691274, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 338, train_loss = 15.478190537542105, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 339, train_loss = 15.466514683328569, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 340, train_loss = 15.454997037537396, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 341, train_loss = 15.440234529785812, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 342, train_loss = 15.431700736284256, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 343, train_loss = 15.417713849805295, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 344, train_loss = 15.406341779977083, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 345, train_loss = 15.391723208129406, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 346, train_loss = 15.383875933475792, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 347, train_loss = 15.368801298551261, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 348, train_loss = 15.358445059508085, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 349, train_loss = 15.348205924965441, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 350, train_loss = 15.336066474206746, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 351, train_loss = 15.326228092424572, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 352, train_loss = 15.311605668626726, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 353, train_loss = 15.300297223962843, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 354, train_loss = 15.290232381783426, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 355, train_loss = 15.277269286103547, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 356, train_loss = 15.26629291754216, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 357, train_loss = 15.255521528422832, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 358, train_loss = 15.245517964474857, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 359, train_loss = 15.23483459930867, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 360, train_loss = 15.224550299346447, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 361, train_loss = 15.212673749774694, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 362, train_loss = 15.20513170864433, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 363, train_loss = 15.19128851685673, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 364, train_loss = 15.18110151682049, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 365, train_loss = 15.169065956026316, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 366, train_loss = 15.160336896777153, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 367, train_loss = 15.149000043980777, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 368, train_loss = 15.139149755239487, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 369, train_loss = 15.130351063795388, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 370, train_loss = 15.117181436158717, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 371, train_loss = 15.109030607156456, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 372, train_loss = 15.097503843717277, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 373, train_loss = 15.089080661535263, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 374, train_loss = 15.077084948308766, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 375, train_loss = 15.068276222795248, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 376, train_loss = 15.056740856729448, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 377, train_loss = 15.046445650048554, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 378, train_loss = 15.037909798324108, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 379, train_loss = 15.029064659960568, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 380, train_loss = 15.018563785590231, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 381, train_loss = 15.00950240995735, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 382, train_loss = 14.999789574183524, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 383, train_loss = 14.988050509244204, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 384, train_loss = 14.978483122773468, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 385, train_loss = 14.968473251909018, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 386, train_loss = 14.95874735340476, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 387, train_loss = 14.950939019210637, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 388, train_loss = 14.943439234048128, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 389, train_loss = 14.934114802628756, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 390, train_loss = 14.923589282669127, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 391, train_loss = 14.91412541642785, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 392, train_loss = 14.90506521333009, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 393, train_loss = 14.897401523776352, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 394, train_loss = 14.886162576265633, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 395, train_loss = 14.878894335590303, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 396, train_loss = 14.865533411502838, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 397, train_loss = 14.85942006483674, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 398, train_loss = 14.847571796737611, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 399, train_loss = 14.84224038850516, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 400, train_loss = 14.833095248788595, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 401, train_loss = 14.82374160271138, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 402, train_loss = 14.8157739052549, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 403, train_loss = 14.805890049785376, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 404, train_loss = 14.795534768141806, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 405, train_loss = 14.789670799858868, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 406, train_loss = 14.779371944256127, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 407, train_loss = 14.774351074360311, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 408, train_loss = 14.765431956388056, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 409, train_loss = 14.755004334263504, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 410, train_loss = 14.748342487029731, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 411, train_loss = 14.738719865679741, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 412, train_loss = 14.729250035248697, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 413, train_loss = 14.722468957304955, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 414, train_loss = 14.716170595027506, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 415, train_loss = 14.708447474054992, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 416, train_loss = 14.697127469815314, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 417, train_loss = 14.689974096603692, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "13th- epoch: 418, train_loss = 14.682907075621188, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 419, train_loss = 14.672180644236505, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 420, train_loss = 14.667274963110685, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 421, train_loss = 14.656573913060129, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 422, train_loss = 14.650711928494275, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 423, train_loss = 14.644255124032497, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 424, train_loss = 14.63717432320118, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 425, train_loss = 14.629489802755415, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 426, train_loss = 14.621274574659765, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 427, train_loss = 14.611272416077554, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 428, train_loss = 14.60473224427551, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 429, train_loss = 14.595914685167372, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "13th- epoch: 430, train_loss = 14.589548252522945, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 431, train_loss = 14.579778737388551, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 432, train_loss = 14.573159027844667, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 433, train_loss = 14.564351395703852, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 434, train_loss = 14.555789074860513, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 435, train_loss = 14.55294529069215, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 436, train_loss = 14.543748524039984, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 437, train_loss = 14.53723445162177, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 438, train_loss = 14.531512051820755, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 439, train_loss = 14.521731819026172, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 440, train_loss = 14.515188953839242, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 441, train_loss = 14.506352100521326, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 442, train_loss = 14.49935644492507, train_acc = 0.9679785747554728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 443, train_loss = 14.490908135659993, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 444, train_loss = 14.484527461230755, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 445, train_loss = 14.479740463197231, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 446, train_loss = 14.470245104283094, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 447, train_loss = 14.463487461209297, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 448, train_loss = 14.45795650407672, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 449, train_loss = 14.449344269931316, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 450, train_loss = 14.444095232989639, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 451, train_loss = 14.43610958615318, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 452, train_loss = 14.43229902535677, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 453, train_loss = 14.42314931889996, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 454, train_loss = 14.416800680104643, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 455, train_loss = 14.410632143262774, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 456, train_loss = 14.402543097734451, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 457, train_loss = 14.397480043116957, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 458, train_loss = 14.389943797141314, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 459, train_loss = 14.383328875061125, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 460, train_loss = 14.378163958434016, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 461, train_loss = 14.37193617457524, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 462, train_loss = 14.36116627464071, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 463, train_loss = 14.356529405806214, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 464, train_loss = 14.355063063558191, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 465, train_loss = 14.345712028443813, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 466, train_loss = 14.33602356677875, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 467, train_loss = 14.331417659763247, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 468, train_loss = 14.325375848915428, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 469, train_loss = 14.31637116894126, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 470, train_loss = 14.31113767484203, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 471, train_loss = 14.307386302854866, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 472, train_loss = 14.298670571297407, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 473, train_loss = 14.291939802467823, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 474, train_loss = 14.28719191858545, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 475, train_loss = 14.282195292413235, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 476, train_loss = 14.275049835443497, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 477, train_loss = 14.272180506493896, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 478, train_loss = 14.262062458787113, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 479, train_loss = 14.25883267680183, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 480, train_loss = 14.251785302069038, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 481, train_loss = 14.244515551719815, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 482, train_loss = 14.238902768585831, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 483, train_loss = 14.233041990548372, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 484, train_loss = 14.225533841643482, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 485, train_loss = 14.222233419772238, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 486, train_loss = 14.215478765312582, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 487, train_loss = 14.207613304257393, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 488, train_loss = 14.202521104365587, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 489, train_loss = 14.196649434510618, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 490, train_loss = 14.192949888762087, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 491, train_loss = 14.187724707182497, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 492, train_loss = 14.180701322853565, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 493, train_loss = 14.181054873857647, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 494, train_loss = 14.170671346131712, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 495, train_loss = 14.163212362676859, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 496, train_loss = 14.160143362823874, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 497, train_loss = 14.154805531259626, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 498, train_loss = 14.146776153240353, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 499, train_loss = 14.139775939285755, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████▎                                       | 13/30 [1:26:32<1:53:15, 399.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "14th- epoch: 0, train_loss = 272.74533343315125, train_acc = 0.46332091290172334\n",
      "test Acc 0.4972067039106145:\n",
      "14th- epoch: 1, train_loss = 213.44214820861816, train_acc = 0.4995342338146251\n",
      "test Acc 0.4995344506517691:\n",
      "14th- epoch: 2, train_loss = 180.48098182678223, train_acc = 0.5069864927806241\n",
      "test Acc 0.5176908752327747:\n",
      "14th- epoch: 3, train_loss = 164.07619738578796, train_acc = 0.5313227759664648\n",
      "test Acc 0.5572625698324022:\n",
      "14th- epoch: 4, train_loss = 151.5756734609604, train_acc = 0.5747554727526781\n",
      "test Acc 0.6042830540037244:\n",
      "14th- epoch: 5, train_loss = 140.3252758383751, train_acc = 0.613996273870517\n",
      "test Acc 0.6284916201117319:\n",
      "14th- epoch: 6, train_loss = 129.68537604808807, train_acc = 0.6316953889147647\n",
      "test Acc 0.6466480446927374:\n",
      "14th- epoch: 7, train_loss = 119.72239357233047, train_acc = 0.6747787610619469\n",
      "test Acc 0.7462756052141527:\n",
      "14th- epoch: 8, train_loss = 110.58457964658737, train_acc = 0.7327666511411272\n",
      "test Acc 0.7569832402234636:\n",
      "14th- epoch: 9, train_loss = 102.25368142127991, train_acc = 0.7791103865859339\n",
      "test Acc 0.7942271880819367:\n",
      "14th- epoch: 10, train_loss = 94.72238045930862, train_acc = 0.8071727992547741\n",
      "test Acc 0.8095903165735568:\n",
      "14th- epoch: 11, train_loss = 87.96336868405342, train_acc = 0.8225430833721472\n",
      "test Acc 0.8319366852886406:\n",
      "14th- epoch: 12, train_loss = 81.96449011564255, train_acc = 0.8339543549138333\n",
      "test Acc 0.839851024208566:\n",
      "14th- epoch: 13, train_loss = 76.66839817166328, train_acc = 0.8435025617140196\n",
      "test Acc 0.8519553072625698:\n",
      "14th- epoch: 14, train_loss = 72.02499186992645, train_acc = 0.8550302748020494\n",
      "test Acc 0.8594040968342644:\n",
      "14th- epoch: 15, train_loss = 67.96235445141792, train_acc = 0.8624825337680484\n",
      "test Acc 0.866852886405959:\n",
      "14th- epoch: 16, train_loss = 64.40506511926651, train_acc = 0.8678388448998603\n",
      "test Acc 0.8747672253258846:\n",
      "14th- epoch: 17, train_loss = 61.28965413570404, train_acc = 0.874126688402422\n",
      "test Acc 0.88268156424581:\n",
      "14th- epoch: 18, train_loss = 58.55684146285057, train_acc = 0.8802980903586399\n",
      "test Acc 0.8850093109869647:\n",
      "14th- epoch: 19, train_loss = 56.15238282084465, train_acc = 0.8828598043782021\n",
      "test Acc 0.888733705772812:\n",
      "14th- epoch: 20, train_loss = 54.029116317629814, train_acc = 0.8855379599441081\n",
      "test Acc 0.8896648044692738:\n",
      "14th- epoch: 21, train_loss = 52.14777426421642, train_acc = 0.8871681415929203\n",
      "test Acc 0.8919925512104283:\n",
      "14th- epoch: 22, train_loss = 50.477647587656975, train_acc = 0.8903120633442012\n",
      "test Acc 0.8961824953445066:\n",
      "14th- epoch: 23, train_loss = 48.986430287361145, train_acc = 0.8959012575687005\n",
      "test Acc 0.9003724394785847:\n",
      "14th- epoch: 24, train_loss = 47.648739859461784, train_acc = 0.8988122962272939\n",
      "test Acc 0.9013035381750466:\n",
      "14th- epoch: 25, train_loss = 46.443533167243004, train_acc = 0.9006753609687936\n",
      "test Acc 0.9022346368715084:\n",
      "14th- epoch: 26, train_loss = 45.35412381589413, train_acc = 0.9017233348858873\n",
      "test Acc 0.9027001862197392:\n",
      "14th- epoch: 27, train_loss = 44.35971735417843, train_acc = 0.9030041918956684\n",
      "test Acc 0.904096834264432:\n",
      "14th- epoch: 28, train_loss = 43.446367368102074, train_acc = 0.9039357242664182\n",
      "test Acc 0.9054934823091247:\n",
      "14th- epoch: 29, train_loss = 42.60435338318348, train_acc = 0.905798789007918\n",
      "test Acc 0.9078212290502793:\n",
      "14th- epoch: 30, train_loss = 41.8265044093132, train_acc = 0.9074289706567303\n",
      "test Acc 0.9082867783985102:\n",
      "14th- epoch: 31, train_loss = 41.10500109195709, train_acc = 0.9083605030274802\n",
      "test Acc 0.9087523277467412:\n",
      "14th- epoch: 32, train_loss = 40.43239226937294, train_acc = 0.9106893339543549\n",
      "test Acc 0.9115456238361266:\n",
      "14th- epoch: 33, train_loss = 39.80269384384155, train_acc = 0.9131346064275734\n",
      "test Acc 0.9120111731843575:\n",
      "14th- epoch: 34, train_loss = 39.210165575146675, train_acc = 0.9148812296227294\n",
      "test Acc 0.9124767225325885:\n",
      "14th- epoch: 35, train_loss = 38.65056000649929, train_acc = 0.9169771774569166\n",
      "test Acc 0.9143389199255121:\n",
      "14th- epoch: 36, train_loss = 38.1219916343689, train_acc = 0.9184909175593852\n",
      "test Acc 0.9152700186219739:\n",
      "14th- epoch: 37, train_loss = 37.619533240795135, train_acc = 0.9202375407545412\n",
      "test Acc 0.914804469273743:\n",
      "14th- epoch: 38, train_loss = 37.13967505097389, train_acc = 0.9208197484862599\n",
      "test Acc 0.9166666666666666:\n",
      "14th- epoch: 39, train_loss = 36.68137268722057, train_acc = 0.9212855146716349\n",
      "test Acc 0.9175977653631285:\n",
      "14th- epoch: 40, train_loss = 36.243279695510864, train_acc = 0.9218677224033535\n",
      "test Acc 0.9180633147113594:\n",
      "14th- epoch: 41, train_loss = 35.82424369454384, train_acc = 0.9227992547741034\n",
      "test Acc 0.9189944134078212:\n",
      "14th- epoch: 42, train_loss = 35.42273876070976, train_acc = 0.9231485794131346\n",
      "test Acc 0.9194599627560521:\n",
      "14th- epoch: 43, train_loss = 35.0370751619339, train_acc = 0.9238472286911971\n",
      "test Acc 0.9203910614525139:\n",
      "14th- epoch: 44, train_loss = 34.66651628911495, train_acc = 0.9243129948765719\n",
      "test Acc 0.9208566108007449:\n",
      "14th- epoch: 45, train_loss = 34.31103937327862, train_acc = 0.9246623195156032\n",
      "test Acc 0.9217877094972067:\n",
      "14th- epoch: 46, train_loss = 33.96912717074156, train_acc = 0.925593851886353\n",
      "test Acc 0.9217877094972067:\n",
      "14th- epoch: 47, train_loss = 33.640202544629574, train_acc = 0.926059618071728\n",
      "test Acc 0.9227188081936686:\n",
      "14th- epoch: 48, train_loss = 33.321977123618126, train_acc = 0.9273404750815091\n",
      "test Acc 0.9227188081936686:\n",
      "14th- epoch: 49, train_loss = 33.01402476429939, train_acc = 0.9281555659059152\n",
      "test Acc 0.9236499068901304:\n",
      "14th- epoch: 50, train_loss = 32.71582067757845, train_acc = 0.9285048905449464\n",
      "test Acc 0.9250465549348231:\n",
      "14th- epoch: 51, train_loss = 32.426161520183086, train_acc = 0.9287377736376339\n",
      "test Acc 0.9259776536312849:\n",
      "14th- epoch: 52, train_loss = 32.1446874961257, train_acc = 0.9296693060083838\n",
      "test Acc 0.9264432029795159:\n",
      "14th- epoch: 53, train_loss = 31.87154907733202, train_acc = 0.930018630647415\n",
      "test Acc 0.9264432029795159:\n",
      "14th- epoch: 54, train_loss = 31.606235712766647, train_acc = 0.9302515137401025\n",
      "test Acc 0.9264432029795159:\n",
      "14th- epoch: 55, train_loss = 31.3490447178483, train_acc = 0.9303679552864462\n",
      "test Acc 0.9264432029795159:\n",
      "14th- epoch: 56, train_loss = 31.099355794489384, train_acc = 0.9308337214718212\n",
      "test Acc 0.9269087523277467:\n",
      "14th- epoch: 57, train_loss = 30.856785781681538, train_acc = 0.9314159292035398\n",
      "test Acc 0.9273743016759777:\n",
      "14th- epoch: 58, train_loss = 30.620392963290215, train_acc = 0.931765253842571\n",
      "test Acc 0.9278398510242085:\n",
      "14th- epoch: 59, train_loss = 30.39057520776987, train_acc = 0.9319981369352585\n",
      "test Acc 0.9283054003724395:\n",
      "14th- epoch: 60, train_loss = 30.166114903986454, train_acc = 0.932231020027946\n",
      "test Acc 0.9283054003724395:\n",
      "14th- epoch: 61, train_loss = 29.9476850181818, train_acc = 0.9325803446669771\n",
      "test Acc 0.9283054003724395:\n",
      "14th- epoch: 62, train_loss = 29.73417942970991, train_acc = 0.9330461108523521\n",
      "test Acc 0.9292364990689013:\n",
      "14th- epoch: 63, train_loss = 29.525597639381886, train_acc = 0.9332789939450395\n",
      "test Acc 0.9292364990689013:\n",
      "14th- epoch: 64, train_loss = 29.321649968624115, train_acc = 0.9336283185840708\n",
      "test Acc 0.9292364990689013:\n",
      "14th- epoch: 65, train_loss = 29.122869059443474, train_acc = 0.933977643223102\n",
      "test Acc 0.9292364990689013:\n",
      "14th- epoch: 66, train_loss = 28.928576536476612, train_acc = 0.9345598509548206\n",
      "test Acc 0.9301675977653632:\n",
      "14th- epoch: 67, train_loss = 28.738931857049465, train_acc = 0.9349091755938519\n",
      "test Acc 0.9301675977653632:\n",
      "14th- epoch: 68, train_loss = 28.553007550537586, train_acc = 0.935258500232883\n",
      "test Acc 0.9301675977653632:\n",
      "14th- epoch: 69, train_loss = 28.371255077421665, train_acc = 0.9353749417792269\n",
      "test Acc 0.9301675977653632:\n",
      "14th- epoch: 70, train_loss = 28.193311542272568, train_acc = 0.935724266418258\n",
      "test Acc 0.930633147113594:\n",
      "14th- epoch: 71, train_loss = 28.01834809780121, train_acc = 0.9360735910572893\n",
      "test Acc 0.930633147113594:\n",
      "14th- epoch: 72, train_loss = 27.847487278282642, train_acc = 0.9370051234280391\n",
      "test Acc 0.930633147113594:\n",
      "14th- epoch: 73, train_loss = 27.679576635360718, train_acc = 0.9374708896134141\n",
      "test Acc 0.930633147113594:\n",
      "14th- epoch: 74, train_loss = 27.515015497803688, train_acc = 0.937936655798789\n",
      "test Acc 0.931098696461825:\n",
      "14th- epoch: 75, train_loss = 27.354150533676147, train_acc = 0.9385188635305077\n",
      "test Acc 0.931098696461825:\n",
      "14th- epoch: 76, train_loss = 27.196122638881207, train_acc = 0.9386353050768514\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 77, train_loss = 27.040709853172302, train_acc = 0.9392175128085701\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 78, train_loss = 26.888911224901676, train_acc = 0.9392175128085701\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 79, train_loss = 26.73965536803007, train_acc = 0.9393339543549138\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 80, train_loss = 26.593107879161835, train_acc = 0.9399161620866325\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 81, train_loss = 26.44977767392993, train_acc = 0.9404983698183512\n",
      "test Acc 0.931098696461825:\n",
      "14th- epoch: 82, train_loss = 26.309524562209845, train_acc = 0.9407312529110387\n",
      "test Acc 0.931098696461825:\n",
      "14th- epoch: 83, train_loss = 26.17109325528145, train_acc = 0.9409641360037261\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 84, train_loss = 26.03531212732196, train_acc = 0.9410805775500699\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 85, train_loss = 25.901685878634453, train_acc = 0.9415463437354448\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 86, train_loss = 25.771454978734255, train_acc = 0.941895668374476\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 87, train_loss = 25.643313143402338, train_acc = 0.9421285514671635\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 88, train_loss = 25.517173275351524, train_acc = 0.9427107591988821\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 89, train_loss = 25.393799606710672, train_acc = 0.9430600838379134\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 90, train_loss = 25.272889237850904, train_acc = 0.9432929669306008\n",
      "test Acc 0.9324953445065177:\n",
      "14th- epoch: 91, train_loss = 25.153100483119488, train_acc = 0.944108057755007\n",
      "test Acc 0.9329608938547486:\n",
      "14th- epoch: 92, train_loss = 25.03618310391903, train_acc = 0.9443409408476945\n",
      "test Acc 0.9334264432029795:\n",
      "14th- epoch: 93, train_loss = 24.92155811190605, train_acc = 0.9448067070330693\n",
      "test Acc 0.9334264432029795:\n",
      "14th- epoch: 94, train_loss = 24.808890726417303, train_acc = 0.945388914764788\n",
      "test Acc 0.9334264432029795:\n",
      "14th- epoch: 95, train_loss = 24.698172722011805, train_acc = 0.9456217978574756\n",
      "test Acc 0.9343575418994413:\n",
      "14th- epoch: 96, train_loss = 24.58901184797287, train_acc = 0.9456217978574756\n",
      "test Acc 0.9352886405959032:\n",
      "14th- epoch: 97, train_loss = 24.482110146433115, train_acc = 0.9457382394038193\n",
      "test Acc 0.9352886405959032:\n",
      "14th- epoch: 98, train_loss = 24.37724144011736, train_acc = 0.9459711224965067\n",
      "test Acc 0.9352886405959032:\n",
      "14th- epoch: 99, train_loss = 24.273286938667297, train_acc = 0.9460875640428504\n",
      "test Acc 0.9352886405959032:\n",
      "14th- epoch: 100, train_loss = 24.17083704471588, train_acc = 0.9460875640428504\n",
      "test Acc 0.9352886405959032:\n",
      "14th- epoch: 101, train_loss = 24.071160312741995, train_acc = 0.9465533302282254\n",
      "test Acc 0.9352886405959032:\n",
      "14th- epoch: 102, train_loss = 23.972447998821735, train_acc = 0.946786213320913\n",
      "test Acc 0.9352886405959032:\n",
      "14th- epoch: 103, train_loss = 23.875546149909496, train_acc = 0.9471355379599441\n",
      "test Acc 0.9352886405959032:\n",
      "14th- epoch: 104, train_loss = 23.780320797115564, train_acc = 0.9474848625989754\n",
      "test Acc 0.9357541899441341:\n",
      "14th- epoch: 105, train_loss = 23.685830119997263, train_acc = 0.9476013041453191\n",
      "test Acc 0.936219739292365:\n",
      "14th- epoch: 106, train_loss = 23.59358748421073, train_acc = 0.9478341872380065\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 107, train_loss = 23.502465095371008, train_acc = 0.9478341872380065\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 108, train_loss = 23.41249806433916, train_acc = 0.9478341872380065\n",
      "test Acc 0.9371508379888268:\n",
      "14th- epoch: 109, train_loss = 23.32357334345579, train_acc = 0.9481835118770378\n",
      "test Acc 0.9371508379888268:\n",
      "14th- epoch: 110, train_loss = 23.23704858124256, train_acc = 0.9484163949697252\n",
      "test Acc 0.9371508379888268:\n",
      "14th- epoch: 111, train_loss = 23.15149338170886, train_acc = 0.9484163949697252\n",
      "test Acc 0.9371508379888268:\n",
      "14th- epoch: 112, train_loss = 23.066548317670822, train_acc = 0.9486492780624126\n",
      "test Acc 0.9371508379888268:\n",
      "14th- epoch: 113, train_loss = 22.984063420444727, train_acc = 0.9486492780624126\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 114, train_loss = 22.902010325342417, train_acc = 0.9488821611551002\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 115, train_loss = 22.821476586163044, train_acc = 0.9489986027014439\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 116, train_loss = 22.741411227732897, train_acc = 0.9491150442477876\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 117, train_loss = 22.66325869038701, train_acc = 0.9494643688868188\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 118, train_loss = 22.584962520748377, train_acc = 0.9495808104331626\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 119, train_loss = 22.50880677625537, train_acc = 0.9496972519795063\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 120, train_loss = 22.43238117173314, train_acc = 0.9496972519795063\n",
      "test Acc 0.9371508379888268:\n",
      "14th- epoch: 121, train_loss = 22.357977848500013, train_acc = 0.9496972519795063\n",
      "test Acc 0.9371508379888268:\n",
      "14th- epoch: 122, train_loss = 22.284201472997665, train_acc = 0.9499301350721937\n",
      "test Acc 0.9376163873370578:\n",
      "14th- epoch: 123, train_loss = 22.210961662232876, train_acc = 0.9500465766185375\n",
      "test Acc 0.9376163873370578:\n",
      "14th- epoch: 124, train_loss = 22.140244275331497, train_acc = 0.950279459711225\n",
      "test Acc 0.9376163873370578:\n",
      "14th- epoch: 125, train_loss = 22.068037182092667, train_acc = 0.9503959012575687\n",
      "test Acc 0.9376163873370578:\n",
      "14th- epoch: 126, train_loss = 21.99838650226593, train_acc = 0.9503959012575687\n",
      "test Acc 0.9380819366852886:\n",
      "14th- epoch: 127, train_loss = 21.928932815790176, train_acc = 0.9505123428039124\n",
      "test Acc 0.9380819366852886:\n",
      "14th- epoch: 128, train_loss = 21.86025121808052, train_acc = 0.9505123428039124\n",
      "test Acc 0.9380819366852886:\n",
      "14th- epoch: 129, train_loss = 21.792185313999653, train_acc = 0.9506287843502562\n",
      "test Acc 0.9380819366852886:\n",
      "14th- epoch: 130, train_loss = 21.725872829556465, train_acc = 0.9507452258965999\n",
      "test Acc 0.9385474860335196:\n",
      "14th- epoch: 131, train_loss = 21.65998974069953, train_acc = 0.9509781089892874\n",
      "test Acc 0.9385474860335196:\n",
      "14th- epoch: 132, train_loss = 21.594996120780706, train_acc = 0.9510945505356311\n",
      "test Acc 0.9385474860335196:\n",
      "14th- epoch: 133, train_loss = 21.530431296676397, train_acc = 0.9510945505356311\n",
      "test Acc 0.9385474860335196:\n",
      "14th- epoch: 134, train_loss = 21.46658329665661, train_acc = 0.9512109920819748\n",
      "test Acc 0.9385474860335196:\n",
      "14th- epoch: 135, train_loss = 21.403270713984966, train_acc = 0.9514438751746623\n",
      "test Acc 0.9390130353817505:\n",
      "14th- epoch: 136, train_loss = 21.341037146747112, train_acc = 0.951560316721006\n",
      "test Acc 0.9390130353817505:\n",
      "14th- epoch: 137, train_loss = 21.278999868780375, train_acc = 0.9517931998136935\n",
      "test Acc 0.9390130353817505:\n",
      "14th- epoch: 138, train_loss = 21.21828044578433, train_acc = 0.9517931998136935\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 139, train_loss = 21.15737345442176, train_acc = 0.9519096413600373\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 140, train_loss = 21.098181657493114, train_acc = 0.9521425244527247\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 141, train_loss = 21.03955600783229, train_acc = 0.9522589659990685\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 142, train_loss = 20.981225214898586, train_acc = 0.9526082906380997\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 143, train_loss = 20.923550259321928, train_acc = 0.9528411737307871\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 144, train_loss = 20.866285048425198, train_acc = 0.9530740568234746\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 145, train_loss = 20.81113041192293, train_acc = 0.9530740568234746\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 146, train_loss = 20.75534510985017, train_acc = 0.9531904983698184\n",
      "test Acc 0.9404096834264432:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 147, train_loss = 20.699550546705723, train_acc = 0.9535398230088495\n",
      "test Acc 0.9404096834264432:\n",
      "14th- epoch: 148, train_loss = 20.64452051743865, train_acc = 0.9535398230088495\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 149, train_loss = 20.591279853135347, train_acc = 0.9538891476478808\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 150, train_loss = 20.537641558796167, train_acc = 0.9541220307405682\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 151, train_loss = 20.484059754759073, train_acc = 0.9541220307405682\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 152, train_loss = 20.430850837379694, train_acc = 0.9541220307405682\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 153, train_loss = 20.37955309264362, train_acc = 0.9541220307405682\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 154, train_loss = 20.32724647410214, train_acc = 0.9544713553795995\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 155, train_loss = 20.27645985968411, train_acc = 0.9544713553795995\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 156, train_loss = 20.225198473781347, train_acc = 0.9544713553795995\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 157, train_loss = 20.175166819244623, train_acc = 0.9547042384722869\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 158, train_loss = 20.12554164044559, train_acc = 0.9547042384722869\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 159, train_loss = 20.07617455534637, train_acc = 0.9549371215649743\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 160, train_loss = 20.027748892083764, train_acc = 0.9550535631113182\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 161, train_loss = 19.978975092992187, train_acc = 0.9551700046576619\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 162, train_loss = 19.9301740154624, train_acc = 0.9551700046576619\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 163, train_loss = 19.88350115530193, train_acc = 0.9552864462040056\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 164, train_loss = 19.83636418171227, train_acc = 0.9554028877503493\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 165, train_loss = 19.78991974890232, train_acc = 0.9554028877503493\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 166, train_loss = 19.743623392656446, train_acc = 0.9554028877503493\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 167, train_loss = 19.697951601818204, train_acc = 0.9554028877503493\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 168, train_loss = 19.652843363583088, train_acc = 0.955519329296693\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 169, train_loss = 19.607884623110294, train_acc = 0.9558686539357243\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 170, train_loss = 19.563603322952986, train_acc = 0.955985095482068\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 171, train_loss = 19.51929235830903, train_acc = 0.956450861667443\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 172, train_loss = 19.476529179140925, train_acc = 0.9568001863064741\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 173, train_loss = 19.433381255716085, train_acc = 0.9569166278528178\n",
      "test Acc 0.9408752327746741:\n",
      "14th- epoch: 174, train_loss = 19.38976432569325, train_acc = 0.9569166278528178\n",
      "test Acc 0.9408752327746741:\n",
      "14th- epoch: 175, train_loss = 19.34791488572955, train_acc = 0.9569166278528178\n",
      "test Acc 0.9413407821229051:\n",
      "14th- epoch: 176, train_loss = 19.305624693632126, train_acc = 0.9569166278528178\n",
      "test Acc 0.9413407821229051:\n",
      "14th- epoch: 177, train_loss = 19.264595612883568, train_acc = 0.9570330693991617\n",
      "test Acc 0.9413407821229051:\n",
      "14th- epoch: 178, train_loss = 19.22326296567917, train_acc = 0.9570330693991617\n",
      "test Acc 0.9413407821229051:\n",
      "14th- epoch: 179, train_loss = 19.182208938524127, train_acc = 0.9572659524918491\n",
      "test Acc 0.9413407821229051:\n",
      "14th- epoch: 180, train_loss = 19.14240105636418, train_acc = 0.9572659524918491\n",
      "test Acc 0.9418063314711359:\n",
      "14th- epoch: 181, train_loss = 19.101326026022434, train_acc = 0.9572659524918491\n",
      "test Acc 0.9418063314711359:\n",
      "14th- epoch: 182, train_loss = 19.062097450718284, train_acc = 0.9572659524918491\n",
      "test Acc 0.9422718808193669:\n",
      "14th- epoch: 183, train_loss = 19.022763391956687, train_acc = 0.9572659524918491\n",
      "test Acc 0.9432029795158287:\n",
      "14th- epoch: 184, train_loss = 18.983358604833484, train_acc = 0.9574988355845365\n",
      "test Acc 0.9432029795158287:\n",
      "14th- epoch: 185, train_loss = 18.94488055817783, train_acc = 0.9574988355845365\n",
      "test Acc 0.9432029795158287:\n",
      "14th- epoch: 186, train_loss = 18.906489377841353, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "14th- epoch: 187, train_loss = 18.867670940235257, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "14th- epoch: 188, train_loss = 18.829898722469807, train_acc = 0.9578481602235678\n",
      "test Acc 0.9436685288640596:\n",
      "14th- epoch: 189, train_loss = 18.79301475547254, train_acc = 0.9578481602235678\n",
      "test Acc 0.9436685288640596:\n",
      "14th- epoch: 190, train_loss = 18.756342228502035, train_acc = 0.9579646017699115\n",
      "test Acc 0.9436685288640596:\n",
      "14th- epoch: 191, train_loss = 18.71926842816174, train_acc = 0.9579646017699115\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 192, train_loss = 18.683544166386127, train_acc = 0.9580810433162552\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 193, train_loss = 18.647812781855464, train_acc = 0.9580810433162552\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 194, train_loss = 18.61298476345837, train_acc = 0.9580810433162552\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 195, train_loss = 18.577389469370246, train_acc = 0.9581974848625989\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 196, train_loss = 18.542669855058193, train_acc = 0.9583139264089428\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 197, train_loss = 18.507443824782968, train_acc = 0.9583139264089428\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 198, train_loss = 18.472667053341866, train_acc = 0.9584303679552865\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 199, train_loss = 18.439368752762675, train_acc = 0.9585468095016302\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 200, train_loss = 18.405493902042508, train_acc = 0.9586632510479739\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 201, train_loss = 18.370929462835193, train_acc = 0.9588961341406614\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 202, train_loss = 18.339358972385526, train_acc = 0.9588961341406614\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 203, train_loss = 18.304692428559065, train_acc = 0.9590125756870052\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 204, train_loss = 18.272731000557542, train_acc = 0.9592454587796926\n",
      "test Acc 0.9445996275605214:\n",
      "14th- epoch: 205, train_loss = 18.240247769281268, train_acc = 0.9592454587796926\n",
      "test Acc 0.9445996275605214:\n",
      "14th- epoch: 206, train_loss = 18.20844187773764, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 207, train_loss = 18.17686395905912, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 208, train_loss = 18.14617725275457, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 209, train_loss = 18.11462395451963, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 210, train_loss = 18.084217263385653, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 211, train_loss = 18.052706388756633, train_acc = 0.9593619003260363\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 212, train_loss = 18.02267697826028, train_acc = 0.9593619003260363\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 213, train_loss = 17.99182483740151, train_acc = 0.9593619003260363\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 214, train_loss = 17.962869415059686, train_acc = 0.95947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 215, train_loss = 17.932208662852645, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "14th- epoch: 216, train_loss = 17.90312492661178, train_acc = 0.9595947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 217, train_loss = 17.87404964864254, train_acc = 0.9595947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 218, train_loss = 17.844831371679902, train_acc = 0.9597112249650676\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 219, train_loss = 17.816447174176574, train_acc = 0.9598276665114113\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 220, train_loss = 17.787889698520303, train_acc = 0.959944108057755\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 221, train_loss = 17.759910222142935, train_acc = 0.959944108057755\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 222, train_loss = 17.731248188763857, train_acc = 0.9600605496040987\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 223, train_loss = 17.704942291602492, train_acc = 0.9601769911504425\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 224, train_loss = 17.676614483818412, train_acc = 0.9601769911504425\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 225, train_loss = 17.650447936728597, train_acc = 0.9601769911504425\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 226, train_loss = 17.621995436027646, train_acc = 0.9601769911504425\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 227, train_loss = 17.595469998195767, train_acc = 0.9601769911504425\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 228, train_loss = 17.569037916138768, train_acc = 0.9602934326967862\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 229, train_loss = 17.542159114032984, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 230, train_loss = 17.516323648393154, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 231, train_loss = 17.49084704183042, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 232, train_loss = 17.463647570461035, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 233, train_loss = 17.440052842721343, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 234, train_loss = 17.413770450279117, train_acc = 0.9605263157894737\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 235, train_loss = 17.38943387567997, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 236, train_loss = 17.364432552829385, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 237, train_loss = 17.34009994752705, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 238, train_loss = 17.315692013129592, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 239, train_loss = 17.29065703600645, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 240, train_loss = 17.26632889918983, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 241, train_loss = 17.24300773628056, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 242, train_loss = 17.218652438372374, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 243, train_loss = 17.19493493065238, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 244, train_loss = 17.172146232798696, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 245, train_loss = 17.149634800851345, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 246, train_loss = 17.127802725881338, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 247, train_loss = 17.102810733020306, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 248, train_loss = 17.080242103897035, train_acc = 0.9614578481602236\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 249, train_loss = 17.05762022268027, train_acc = 0.9615742897065673\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 250, train_loss = 17.037233502604067, train_acc = 0.9615742897065673\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 251, train_loss = 17.014491639100015, train_acc = 0.9615742897065673\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 252, train_loss = 16.991747565567493, train_acc = 0.9615742897065673\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 253, train_loss = 16.97082367539406, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 254, train_loss = 16.94951797183603, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 255, train_loss = 16.92785054538399, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 256, train_loss = 16.90662132576108, train_acc = 0.961690731252911\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 257, train_loss = 16.885322687216103, train_acc = 0.9618071727992548\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 258, train_loss = 16.864543561823666, train_acc = 0.9619236143455985\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 259, train_loss = 16.84384576138109, train_acc = 0.962156497438286\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 260, train_loss = 16.82209705095738, train_acc = 0.962156497438286\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 261, train_loss = 16.80194169189781, train_acc = 0.9622729389846297\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 262, train_loss = 16.7818784667179, train_acc = 0.9625058220773172\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 263, train_loss = 16.761402963660657, train_acc = 0.9627387051700047\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 264, train_loss = 16.740086463280022, train_acc = 0.9627387051700047\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 265, train_loss = 16.721307274885476, train_acc = 0.9627387051700047\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 266, train_loss = 16.701516143977642, train_acc = 0.9628551467163484\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 267, train_loss = 16.681881088763475, train_acc = 0.9629715882626921\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 268, train_loss = 16.66205357015133, train_acc = 0.9630880298090359\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 269, train_loss = 16.64445741008967, train_acc = 0.9630880298090359\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 270, train_loss = 16.624844775535166, train_acc = 0.9630880298090359\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 271, train_loss = 16.606448127888143, train_acc = 0.9630880298090359\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 272, train_loss = 16.586117669939995, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 273, train_loss = 16.568172878585756, train_acc = 0.9634373544480671\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 274, train_loss = 16.54931668099016, train_acc = 0.9634373544480671\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 275, train_loss = 16.530800510197878, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 276, train_loss = 16.51202878728509, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 277, train_loss = 16.49337378051132, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 278, train_loss = 16.476291029714048, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 279, train_loss = 16.458742015995085, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 280, train_loss = 16.439819619059563, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 281, train_loss = 16.421991888433695, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 282, train_loss = 16.404456179589033, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 283, train_loss = 16.38731308002025, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 284, train_loss = 16.368412159383297, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 285, train_loss = 16.35197462514043, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 286, train_loss = 16.33452262263745, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 287, train_loss = 16.316933290101588, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 288, train_loss = 16.301796659827232, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 289, train_loss = 16.284686011262238, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 290, train_loss = 16.266716737300158, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 291, train_loss = 16.250952642410994, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 292, train_loss = 16.234580439515412, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 293, train_loss = 16.218918304890394, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 294, train_loss = 16.20238730031997, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 295, train_loss = 16.18399280682206, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 296, train_loss = 16.169247743673623, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 297, train_loss = 16.154045830480754, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 298, train_loss = 16.138050491921604, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 299, train_loss = 16.12286599725485, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 300, train_loss = 16.107180929742754, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 301, train_loss = 16.091869364492595, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 302, train_loss = 16.074453045614064, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 303, train_loss = 16.060720100067556, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 304, train_loss = 16.044868835248053, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 305, train_loss = 16.030038653872907, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 306, train_loss = 16.014902305789292, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 307, train_loss = 16.00015774741769, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 308, train_loss = 15.984109666198492, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 309, train_loss = 15.969066795893013, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 310, train_loss = 15.954775339923799, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 311, train_loss = 15.940377335995436, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 312, train_loss = 15.926667316816747, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 313, train_loss = 15.912495952099562, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 314, train_loss = 15.898244817741215, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 315, train_loss = 15.884458091109991, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 316, train_loss = 15.867533829063177, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 317, train_loss = 15.854992873966694, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 318, train_loss = 15.840318805538118, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 319, train_loss = 15.827571053057909, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 320, train_loss = 15.812234497629106, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 321, train_loss = 15.79677961114794, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 322, train_loss = 15.783406400121748, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 323, train_loss = 15.77116333693266, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 324, train_loss = 15.756225164979696, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 325, train_loss = 15.74491023644805, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 326, train_loss = 15.731418461538851, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 327, train_loss = 15.716437139548361, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 328, train_loss = 15.701792511157691, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 329, train_loss = 15.689536903984845, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 330, train_loss = 15.67599572148174, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 331, train_loss = 15.664987187832594, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 332, train_loss = 15.649977917782962, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 333, train_loss = 15.637076706625521, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 334, train_loss = 15.623319320380688, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 335, train_loss = 15.61305593047291, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 336, train_loss = 15.596780929714441, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 337, train_loss = 15.587270888499916, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 338, train_loss = 15.57301498670131, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 339, train_loss = 15.561663529835641, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 340, train_loss = 15.550446315668523, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 341, train_loss = 15.536501160822809, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 342, train_loss = 15.525315162725747, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 343, train_loss = 15.513725503347814, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 344, train_loss = 15.501270937733352, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 345, train_loss = 15.489082570187747, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 346, train_loss = 15.477295958437026, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 347, train_loss = 15.465867597609758, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 348, train_loss = 15.453500726260245, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 349, train_loss = 15.440368651412427, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 350, train_loss = 15.428410864435136, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 351, train_loss = 15.418081134557724, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 352, train_loss = 15.406432196497917, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 353, train_loss = 15.39487049356103, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 354, train_loss = 15.385988446883857, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 355, train_loss = 15.370008810423315, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 356, train_loss = 15.362130913883448, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 357, train_loss = 15.348004717379808, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 358, train_loss = 15.33873846847564, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 359, train_loss = 15.326631870120764, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 360, train_loss = 15.317735460586846, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 361, train_loss = 15.303946622647345, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 362, train_loss = 15.293784119188786, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 363, train_loss = 15.28410108666867, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 364, train_loss = 15.273177050054073, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 365, train_loss = 15.260539460927248, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 366, train_loss = 15.248501061461866, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 367, train_loss = 15.240558196790516, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 368, train_loss = 15.227910451591015, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 369, train_loss = 15.217883150093257, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 370, train_loss = 15.209681742824614, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 371, train_loss = 15.197071372531354, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 372, train_loss = 15.187416569329798, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 373, train_loss = 15.178484040312469, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 374, train_loss = 15.167046398855746, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 375, train_loss = 15.15582600980997, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 376, train_loss = 15.146920156665146, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 377, train_loss = 15.135943129658699, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 378, train_loss = 15.12828107457608, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 379, train_loss = 15.11512481700629, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 380, train_loss = 15.108242087997496, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 381, train_loss = 15.095507116056979, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 382, train_loss = 15.087003946304321, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 383, train_loss = 15.076337206177413, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 384, train_loss = 15.068013074807823, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 385, train_loss = 15.056129322387278, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 386, train_loss = 15.050546191632748, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 387, train_loss = 15.041123094968498, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 388, train_loss = 15.028037740848958, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 389, train_loss = 15.02119480445981, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 390, train_loss = 15.011822746135294, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 391, train_loss = 14.999878815375268, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 392, train_loss = 14.992038724012673, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 393, train_loss = 14.983858689665794, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 394, train_loss = 14.971230737864971, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 395, train_loss = 14.96464004740119, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 396, train_loss = 14.952907719649374, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 397, train_loss = 14.942245997488499, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 398, train_loss = 14.936472530476749, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 399, train_loss = 14.924579537473619, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 400, train_loss = 14.916452267207205, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 401, train_loss = 14.908064463175833, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 402, train_loss = 14.898899464868009, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 403, train_loss = 14.890662373043597, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 404, train_loss = 14.88097696006298, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 405, train_loss = 14.872859145514667, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 406, train_loss = 14.863166134804487, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 407, train_loss = 14.855933289974928, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 408, train_loss = 14.845033929683268, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 409, train_loss = 14.838521964848042, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 410, train_loss = 14.829127573408186, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 411, train_loss = 14.821491003036499, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 412, train_loss = 14.810077981092036, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 413, train_loss = 14.804891501553357, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 414, train_loss = 14.793753604404628, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 415, train_loss = 14.788090202957392, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 416, train_loss = 14.77828257996589, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 417, train_loss = 14.769008514471352, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 418, train_loss = 14.761820369400084, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 419, train_loss = 14.753483350388706, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 420, train_loss = 14.746586728841066, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 421, train_loss = 14.736064180731773, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 422, train_loss = 14.727272625081241, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 423, train_loss = 14.720585267059505, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 424, train_loss = 14.713854911737144, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 425, train_loss = 14.704732798971236, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 426, train_loss = 14.696643822826445, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 427, train_loss = 14.689188794232905, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 428, train_loss = 14.68196080531925, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 429, train_loss = 14.671218551695347, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 430, train_loss = 14.664147019386292, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 431, train_loss = 14.657873573247343, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 432, train_loss = 14.650126503314823, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 433, train_loss = 14.641415217425674, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 434, train_loss = 14.63282160460949, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 435, train_loss = 14.626936588436365, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 436, train_loss = 14.618077305611223, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 437, train_loss = 14.609753171447664, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 438, train_loss = 14.602410639170557, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 439, train_loss = 14.596200799103826, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 440, train_loss = 14.587130641099066, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 441, train_loss = 14.58038841560483, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 442, train_loss = 14.569935618434101, train_acc = 0.9671634839310667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 443, train_loss = 14.565292948391289, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 444, train_loss = 14.559355138335377, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 445, train_loss = 14.550428675953299, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 446, train_loss = 14.54295473312959, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 447, train_loss = 14.535655912011862, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 448, train_loss = 14.529016247484833, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 449, train_loss = 14.521002853754908, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 450, train_loss = 14.51375438272953, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 451, train_loss = 14.50735824694857, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 452, train_loss = 14.499947555363178, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 453, train_loss = 14.493173702154309, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 454, train_loss = 14.486016602721065, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 455, train_loss = 14.478821465279907, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 456, train_loss = 14.472931208554655, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 457, train_loss = 14.464720398187637, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 458, train_loss = 14.459739480167627, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 459, train_loss = 14.450564328581095, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 460, train_loss = 14.444380715489388, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 461, train_loss = 14.439729405101389, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 462, train_loss = 14.430432280059904, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 463, train_loss = 14.424721048679203, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 464, train_loss = 14.419300563633442, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 465, train_loss = 14.40962415933609, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "14th- epoch: 466, train_loss = 14.406867079436779, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 467, train_loss = 14.394865397363901, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 468, train_loss = 14.39272227883339, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 469, train_loss = 14.382958959788084, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 470, train_loss = 14.3772829673253, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 471, train_loss = 14.369838622864336, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 472, train_loss = 14.364644842687994, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 473, train_loss = 14.359244099352509, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 474, train_loss = 14.351906412746757, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 475, train_loss = 14.346342844422907, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 476, train_loss = 14.339297865983099, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 477, train_loss = 14.334601851645857, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 478, train_loss = 14.323434588965029, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 479, train_loss = 14.320462683681399, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 480, train_loss = 14.312907428946346, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 481, train_loss = 14.30477798730135, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 482, train_loss = 14.304480418562889, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 483, train_loss = 14.29570982977748, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 484, train_loss = 14.286487370729446, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 485, train_loss = 14.278249786701053, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 486, train_loss = 14.275430453475565, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 487, train_loss = 14.270741384476423, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 488, train_loss = 14.263661948498338, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 489, train_loss = 14.257473794277757, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 490, train_loss = 14.251494436059147, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 491, train_loss = 14.245920117944479, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 492, train_loss = 14.238819220568985, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 493, train_loss = 14.233380824327469, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 494, train_loss = 14.228065425064415, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 495, train_loss = 14.219595899339765, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 496, train_loss = 14.218095989432186, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 497, train_loss = 14.208686904516071, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 498, train_loss = 14.205099910497665, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 499, train_loss = 14.19719951832667, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████████████████████████▋                                     | 14/30 [1:33:11<1:46:35, 399.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "15th- epoch: 0, train_loss = 270.6295837163925, train_acc = 0.4679785747554728\n",
      "test Acc 0.4958100558659218:\n",
      "15th- epoch: 1, train_loss = 213.03111672401428, train_acc = 0.5\n",
      "test Acc 0.5:\n",
      "15th- epoch: 2, train_loss = 181.6775143146515, train_acc = 0.5023288309268747\n",
      "test Acc 0.5046554934823091:\n",
      "15th- epoch: 3, train_loss = 165.72511380910873, train_acc = 0.5192128551467163\n",
      "test Acc 0.542830540037244:\n",
      "15th- epoch: 4, train_loss = 153.59956949949265, train_acc = 0.5664881229622729\n",
      "test Acc 0.6024208566108007:\n",
      "15th- epoch: 5, train_loss = 142.55795526504517, train_acc = 0.6130647414997671\n",
      "test Acc 0.6322160148975792:\n",
      "15th- epoch: 6, train_loss = 131.9358406662941, train_acc = 0.6354215183977643\n",
      "test Acc 0.6508379888268156:\n",
      "15th- epoch: 7, train_loss = 121.7620347738266, train_acc = 0.6693060083837913\n",
      "test Acc 0.7467411545623837:\n",
      "15th- epoch: 8, train_loss = 112.25754994153976, train_acc = 0.7454587796925943\n",
      "test Acc 0.7639664804469274:\n",
      "15th- epoch: 9, train_loss = 103.52939629554749, train_acc = 0.7750349324639031\n",
      "test Acc 0.7886405959031657:\n",
      "15th- epoch: 10, train_loss = 95.59415036439896, train_acc = 0.8056590591523055\n",
      "test Acc 0.8184357541899442:\n",
      "15th- epoch: 11, train_loss = 88.47363248467445, train_acc = 0.8230088495575221\n",
      "test Acc 0.8361266294227188:\n",
      "15th- epoch: 12, train_loss = 82.15846109390259, train_acc = 0.8366325104797392\n",
      "test Acc 0.8472998137802608:\n",
      "15th- epoch: 13, train_loss = 76.61518621444702, train_acc = 0.8458313926408942\n",
      "test Acc 0.8538175046554934:\n",
      "15th- epoch: 14, train_loss = 71.8139115869999, train_acc = 0.8534000931532371\n",
      "test Acc 0.8570763500931099:\n",
      "15th- epoch: 15, train_loss = 67.67657485604286, train_acc = 0.8588728458313927\n",
      "test Acc 0.8640595903165735:\n",
      "15th- epoch: 16, train_loss = 64.1022999882698, train_acc = 0.8621332091290173\n",
      "test Acc 0.8677839851024208:\n",
      "15th- epoch: 17, train_loss = 61.00844869017601, train_acc = 0.8659757801583605\n",
      "test Acc 0.8729050279329609:\n",
      "15th- epoch: 18, train_loss = 58.315920650959015, train_acc = 0.874126688402422\n",
      "test Acc 0.8803538175046555:\n",
      "15th- epoch: 19, train_loss = 55.958176255226135, train_acc = 0.8808802980903586\n",
      "test Acc 0.8864059590316573:\n",
      "15th- epoch: 20, train_loss = 53.88265618681908, train_acc = 0.8843735444806707\n",
      "test Acc 0.8901303538175046:\n",
      "15th- epoch: 21, train_loss = 52.045617431402206, train_acc = 0.8875174662319516\n",
      "test Acc 0.8971135940409684:\n",
      "15th- epoch: 22, train_loss = 50.41206754744053, train_acc = 0.8938053097345132\n",
      "test Acc 0.8985102420856611:\n",
      "15th- epoch: 23, train_loss = 48.9524914175272, train_acc = 0.8969492314857941\n",
      "test Acc 0.8999068901303539:\n",
      "15th- epoch: 24, train_loss = 47.64112803339958, train_acc = 0.8981136469492315\n",
      "test Acc 0.9003724394785847:\n",
      "15th- epoch: 25, train_loss = 46.45767097175121, train_acc = 0.8998602701443875\n",
      "test Acc 0.9027001862197392:\n",
      "15th- epoch: 26, train_loss = 45.38347840309143, train_acc = 0.9014904517931999\n",
      "test Acc 0.9036312849162011:\n",
      "15th- epoch: 27, train_loss = 44.40354943275452, train_acc = 0.9028877503493247\n",
      "test Acc 0.9050279329608939:\n",
      "15th- epoch: 28, train_loss = 43.50435329973698, train_acc = 0.9038192827200745\n",
      "test Acc 0.9059590316573557:\n",
      "15th- epoch: 29, train_loss = 42.675854444503784, train_acc = 0.9045179319981369\n",
      "test Acc 0.9068901303538175:\n",
      "15th- epoch: 30, train_loss = 41.907775685191154, train_acc = 0.9070796460176991\n",
      "test Acc 0.9087523277467412:\n",
      "15th- epoch: 31, train_loss = 41.192604303359985, train_acc = 0.9091755938518864\n",
      "test Acc 0.909217877094972:\n",
      "15th- epoch: 32, train_loss = 40.52343472838402, train_acc = 0.9113879832324173\n",
      "test Acc 0.910148975791434:\n",
      "15th- epoch: 33, train_loss = 39.895934984087944, train_acc = 0.9131346064275734\n",
      "test Acc 0.9110800744878957:\n",
      "15th- epoch: 34, train_loss = 39.305677846074104, train_acc = 0.9148812296227294\n",
      "test Acc 0.9120111731843575:\n",
      "15th- epoch: 35, train_loss = 38.74800980091095, train_acc = 0.9168607359105729\n",
      "test Acc 0.9134078212290503:\n",
      "15th- epoch: 36, train_loss = 38.21878261864185, train_acc = 0.917675826734979\n",
      "test Acc 0.914804469273743:\n",
      "15th- epoch: 37, train_loss = 37.71628926694393, train_acc = 0.9191895668374476\n",
      "test Acc 0.9157355679702048:\n",
      "15th- epoch: 38, train_loss = 37.238299787044525, train_acc = 0.9201210992081975\n",
      "test Acc 0.9162011173184358:\n",
      "15th- epoch: 39, train_loss = 36.7814918756485, train_acc = 0.9208197484862599\n",
      "test Acc 0.9171322160148976:\n",
      "15th- epoch: 40, train_loss = 36.344134628772736, train_acc = 0.9218677224033535\n",
      "test Acc 0.9175977653631285:\n",
      "15th- epoch: 41, train_loss = 35.9251816123724, train_acc = 0.9223334885887284\n",
      "test Acc 0.9175977653631285:\n",
      "15th- epoch: 42, train_loss = 35.523848958313465, train_acc = 0.922566371681416\n",
      "test Acc 0.9175977653631285:\n",
      "15th- epoch: 43, train_loss = 35.13830994814634, train_acc = 0.9227992547741034\n",
      "test Acc 0.9180633147113594:\n",
      "15th- epoch: 44, train_loss = 34.767138965427876, train_acc = 0.9230321378667908\n",
      "test Acc 0.9180633147113594:\n",
      "15th- epoch: 45, train_loss = 34.409480169415474, train_acc = 0.9251280857009782\n",
      "test Acc 0.9194599627560521:\n",
      "15th- epoch: 46, train_loss = 34.06444655358791, train_acc = 0.925593851886353\n",
      "test Acc 0.9213221601489758:\n",
      "15th- epoch: 47, train_loss = 33.73218676447868, train_acc = 0.9264089427107592\n",
      "test Acc 0.9217877094972067:\n",
      "15th- epoch: 48, train_loss = 33.411422684788704, train_acc = 0.9276897997205403\n",
      "test Acc 0.9231843575418994:\n",
      "15th- epoch: 49, train_loss = 33.101608753204346, train_acc = 0.9283884489986027\n",
      "test Acc 0.9236499068901304:\n",
      "15th- epoch: 50, train_loss = 32.80142501741648, train_acc = 0.9292035398230089\n",
      "test Acc 0.9236499068901304:\n",
      "15th- epoch: 51, train_loss = 32.511165387928486, train_acc = 0.9303679552864462\n",
      "test Acc 0.9250465549348231:\n",
      "15th- epoch: 52, train_loss = 32.22966771572828, train_acc = 0.9308337214718212\n",
      "test Acc 0.9250465549348231:\n",
      "15th- epoch: 53, train_loss = 31.956940196454525, train_acc = 0.9311830461108523\n",
      "test Acc 0.9250465549348231:\n",
      "15th- epoch: 54, train_loss = 31.692090466618538, train_acc = 0.9312994876571961\n",
      "test Acc 0.9250465549348231:\n",
      "15th- epoch: 55, train_loss = 31.434768557548523, train_acc = 0.9315323707498836\n",
      "test Acc 0.925512104283054:\n",
      "15th- epoch: 56, train_loss = 31.18473868817091, train_acc = 0.9316488122962273\n",
      "test Acc 0.925512104283054:\n",
      "15th- epoch: 57, train_loss = 30.94131498783827, train_acc = 0.9323474615742897\n",
      "test Acc 0.9259776536312849:\n",
      "15th- epoch: 58, train_loss = 30.7032830119133, train_acc = 0.9326967862133209\n",
      "test Acc 0.9259776536312849:\n",
      "15th- epoch: 59, train_loss = 30.47263227403164, train_acc = 0.9330461108523521\n",
      "test Acc 0.9259776536312849:\n",
      "15th- epoch: 60, train_loss = 30.247078448534012, train_acc = 0.9331625523986958\n",
      "test Acc 0.9264432029795159:\n",
      "15th- epoch: 61, train_loss = 30.027311198413372, train_acc = 0.9333954354913834\n",
      "test Acc 0.9269087523277467:\n",
      "15th- epoch: 62, train_loss = 29.812404684722424, train_acc = 0.9335118770377271\n",
      "test Acc 0.9269087523277467:\n",
      "15th- epoch: 63, train_loss = 29.602485708892345, train_acc = 0.9337447601304145\n",
      "test Acc 0.9264432029795159:\n",
      "15th- epoch: 64, train_loss = 29.397953286767006, train_acc = 0.9337447601304145\n",
      "test Acc 0.9273743016759777:\n",
      "15th- epoch: 65, train_loss = 29.197487607598305, train_acc = 0.9340940847694458\n",
      "test Acc 0.9278398510242085:\n",
      "15th- epoch: 66, train_loss = 29.00121296942234, train_acc = 0.9347927340475082\n",
      "test Acc 0.9283054003724395:\n",
      "15th- epoch: 67, train_loss = 28.810041815042496, train_acc = 0.9350256171401956\n",
      "test Acc 0.9292364990689013:\n",
      "15th- epoch: 68, train_loss = 28.622230127453804, train_acc = 0.9358407079646017\n",
      "test Acc 0.9292364990689013:\n",
      "15th- epoch: 69, train_loss = 28.438341177999973, train_acc = 0.9363064741499767\n",
      "test Acc 0.9292364990689013:\n",
      "15th- epoch: 70, train_loss = 28.258382238447666, train_acc = 0.9368886818816954\n",
      "test Acc 0.9292364990689013:\n",
      "15th- epoch: 71, train_loss = 28.082560323178768, train_acc = 0.9372380065207266\n",
      "test Acc 0.9292364990689013:\n",
      "15th- epoch: 72, train_loss = 27.909349359571934, train_acc = 0.9378202142524453\n",
      "test Acc 0.9301675977653632:\n",
      "15th- epoch: 73, train_loss = 27.739652074873447, train_acc = 0.937936655798789\n",
      "test Acc 0.9301675977653632:\n",
      "15th- epoch: 74, train_loss = 27.57310213148594, train_acc = 0.9381695388914765\n",
      "test Acc 0.9301675977653632:\n",
      "15th- epoch: 75, train_loss = 27.409216798841953, train_acc = 0.9382859804378202\n",
      "test Acc 0.930633147113594:\n",
      "15th- epoch: 76, train_loss = 27.24842009693384, train_acc = 0.9387517466231952\n",
      "test Acc 0.931098696461825:\n",
      "15th- epoch: 77, train_loss = 27.09134391695261, train_acc = 0.9389846297158826\n",
      "test Acc 0.931098696461825:\n",
      "15th- epoch: 78, train_loss = 26.93712005019188, train_acc = 0.9392175128085701\n",
      "test Acc 0.931098696461825:\n",
      "15th- epoch: 79, train_loss = 26.785146541893482, train_acc = 0.939683278993945\n",
      "test Acc 0.931098696461825:\n",
      "15th- epoch: 80, train_loss = 26.636107720434666, train_acc = 0.94014904517932\n",
      "test Acc 0.9315642458100558:\n",
      "15th- epoch: 81, train_loss = 26.48953002691269, train_acc = 0.9407312529110387\n",
      "test Acc 0.9315642458100558:\n",
      "15th- epoch: 82, train_loss = 26.34604024887085, train_acc = 0.9408476944573824\n",
      "test Acc 0.9320297951582868:\n",
      "15th- epoch: 83, train_loss = 26.204508282244205, train_acc = 0.9411970190964136\n",
      "test Acc 0.9320297951582868:\n",
      "15th- epoch: 84, train_loss = 26.065859988331795, train_acc = 0.941895668374476\n",
      "test Acc 0.9320297951582868:\n",
      "15th- epoch: 85, train_loss = 25.92919909954071, train_acc = 0.9422449930135072\n",
      "test Acc 0.9320297951582868:\n",
      "15th- epoch: 86, train_loss = 25.794444147497416, train_acc = 0.9425943176525384\n",
      "test Acc 0.9320297951582868:\n",
      "15th- epoch: 87, train_loss = 25.662636451423168, train_acc = 0.9430600838379134\n",
      "test Acc 0.9320297951582868:\n",
      "15th- epoch: 88, train_loss = 25.533353462815285, train_acc = 0.9432929669306008\n",
      "test Acc 0.9320297951582868:\n",
      "15th- epoch: 89, train_loss = 25.405860725790262, train_acc = 0.9437587331159758\n",
      "test Acc 0.9320297951582868:\n",
      "15th- epoch: 90, train_loss = 25.28016260638833, train_acc = 0.9437587331159758\n",
      "test Acc 0.9324953445065177:\n",
      "15th- epoch: 91, train_loss = 25.156920187175274, train_acc = 0.9438751746623195\n",
      "test Acc 0.9324953445065177:\n",
      "15th- epoch: 92, train_loss = 25.03523600846529, train_acc = 0.9439916162086632\n",
      "test Acc 0.9329608938547486:\n",
      "15th- epoch: 93, train_loss = 24.915930025279522, train_acc = 0.9442244993013508\n",
      "test Acc 0.9329608938547486:\n",
      "15th- epoch: 94, train_loss = 24.799111243337393, train_acc = 0.9445738239403819\n",
      "test Acc 0.9329608938547486:\n",
      "15th- epoch: 95, train_loss = 24.68373339995742, train_acc = 0.9445738239403819\n",
      "test Acc 0.9334264432029795:\n",
      "15th- epoch: 96, train_loss = 24.57048226892948, train_acc = 0.9448067070330693\n",
      "test Acc 0.9338919925512105:\n",
      "15th- epoch: 97, train_loss = 24.45860417932272, train_acc = 0.9451560316721006\n",
      "test Acc 0.9338919925512105:\n",
      "15th- epoch: 98, train_loss = 24.348853029310703, train_acc = 0.945388914764788\n",
      "test Acc 0.9338919925512105:\n",
      "15th- epoch: 99, train_loss = 24.24166052043438, train_acc = 0.9455053563111319\n",
      "test Acc 0.9338919925512105:\n",
      "15th- epoch: 100, train_loss = 24.135414220392704, train_acc = 0.9456217978574756\n",
      "test Acc 0.9343575418994413:\n",
      "15th- epoch: 101, train_loss = 24.031481198966503, train_acc = 0.9459711224965067\n",
      "test Acc 0.9348230912476723:\n",
      "15th- epoch: 102, train_loss = 23.92891324311495, train_acc = 0.9460875640428504\n",
      "test Acc 0.9348230912476723:\n",
      "15th- epoch: 103, train_loss = 23.82807905599475, train_acc = 0.946320447135538\n",
      "test Acc 0.9352886405959032:\n",
      "15th- epoch: 104, train_loss = 23.7284590639174, train_acc = 0.9465533302282254\n",
      "test Acc 0.9352886405959032:\n",
      "15th- epoch: 105, train_loss = 23.630140878260136, train_acc = 0.946786213320913\n",
      "test Acc 0.9357541899441341:\n",
      "15th- epoch: 106, train_loss = 23.533510580658913, train_acc = 0.946786213320913\n",
      "test Acc 0.9357541899441341:\n",
      "15th- epoch: 107, train_loss = 23.438943281769753, train_acc = 0.9469026548672567\n",
      "test Acc 0.9357541899441341:\n",
      "15th- epoch: 108, train_loss = 23.345268670469522, train_acc = 0.9471355379599441\n",
      "test Acc 0.936219739292365:\n",
      "15th- epoch: 109, train_loss = 23.252949506044388, train_acc = 0.9476013041453191\n",
      "test Acc 0.9366852886405959:\n",
      "15th- epoch: 110, train_loss = 23.16230958327651, train_acc = 0.9476013041453191\n",
      "test Acc 0.9366852886405959:\n",
      "15th- epoch: 111, train_loss = 23.0730351023376, train_acc = 0.9476013041453191\n",
      "test Acc 0.9371508379888268:\n",
      "15th- epoch: 112, train_loss = 22.98505948111415, train_acc = 0.9477177456916628\n",
      "test Acc 0.9371508379888268:\n",
      "15th- epoch: 113, train_loss = 22.89844184741378, train_acc = 0.9477177456916628\n",
      "test Acc 0.9380819366852886:\n",
      "15th- epoch: 114, train_loss = 22.813049528747797, train_acc = 0.948067070330694\n",
      "test Acc 0.9380819366852886:\n",
      "15th- epoch: 115, train_loss = 22.729231022298336, train_acc = 0.9481835118770378\n",
      "test Acc 0.9385474860335196:\n",
      "15th- epoch: 116, train_loss = 22.646660327911377, train_acc = 0.9484163949697252\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 117, train_loss = 22.56420936062932, train_acc = 0.9487657196087564\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 118, train_loss = 22.48384951800108, train_acc = 0.9491150442477876\n",
      "test Acc 0.9394785847299814:\n",
      "15th- epoch: 119, train_loss = 22.404751420021057, train_acc = 0.9495808104331626\n",
      "test Acc 0.9394785847299814:\n",
      "15th- epoch: 120, train_loss = 22.32633361965418, train_acc = 0.9496972519795063\n",
      "test Acc 0.9394785847299814:\n",
      "15th- epoch: 121, train_loss = 22.249581061303616, train_acc = 0.9499301350721937\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 122, train_loss = 22.173438522964716, train_acc = 0.9500465766185375\n",
      "test Acc 0.9404096834264432:\n",
      "15th- epoch: 123, train_loss = 22.09797538816929, train_acc = 0.950279459711225\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 124, train_loss = 22.023695811629295, train_acc = 0.9505123428039124\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 125, train_loss = 21.950442489236593, train_acc = 0.9506287843502562\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 126, train_loss = 21.878269009292126, train_acc = 0.9509781089892874\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 127, train_loss = 21.807369276881218, train_acc = 0.9510945505356311\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 128, train_loss = 21.737146772444248, train_acc = 0.9512109920819748\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 129, train_loss = 21.667178232222795, train_acc = 0.9512109920819748\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 130, train_loss = 21.598251830786467, train_acc = 0.9513274336283186\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 131, train_loss = 21.5298028960824, train_acc = 0.9513274336283186\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 132, train_loss = 21.461800020188093, train_acc = 0.9516767582673498\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 133, train_loss = 21.395630579441786, train_acc = 0.9517931998136935\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 134, train_loss = 21.32931698486209, train_acc = 0.9519096413600373\n",
      "test Acc 0.9413407821229051:\n",
      "15th- epoch: 135, train_loss = 21.263958398252726, train_acc = 0.952026082906381\n",
      "test Acc 0.9413407821229051:\n",
      "15th- epoch: 136, train_loss = 21.199274886399508, train_acc = 0.952026082906381\n",
      "test Acc 0.9413407821229051:\n",
      "15th- epoch: 137, train_loss = 21.136213149875402, train_acc = 0.9522589659990685\n",
      "test Acc 0.9413407821229051:\n",
      "15th- epoch: 138, train_loss = 21.0733259357512, train_acc = 0.9526082906380997\n",
      "test Acc 0.9413407821229051:\n",
      "15th- epoch: 139, train_loss = 21.010885402560234, train_acc = 0.9527247321844434\n",
      "test Acc 0.9413407821229051:\n",
      "15th- epoch: 140, train_loss = 20.94964561611414, train_acc = 0.9528411737307871\n",
      "test Acc 0.9413407821229051:\n",
      "15th- epoch: 141, train_loss = 20.88883901759982, train_acc = 0.9529576152771309\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 142, train_loss = 20.829204466193914, train_acc = 0.9530740568234746\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 143, train_loss = 20.769831649959087, train_acc = 0.9531904983698184\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 144, train_loss = 20.712630219757557, train_acc = 0.9533069399161621\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 145, train_loss = 20.65439397469163, train_acc = 0.9533069399161621\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 146, train_loss = 20.597670141607523, train_acc = 0.9534233814625058\n",
      "test Acc 0.9418063314711359:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 147, train_loss = 20.54163258895278, train_acc = 0.9535398230088495\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 148, train_loss = 20.48608906008303, train_acc = 0.9536562645551933\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 149, train_loss = 20.431434236466885, train_acc = 0.9541220307405682\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 150, train_loss = 20.377001225948334, train_acc = 0.9542384722869119\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 151, train_loss = 20.323335414752364, train_acc = 0.9543549138332557\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 152, train_loss = 20.27108215354383, train_acc = 0.9544713553795995\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 153, train_loss = 20.21865650638938, train_acc = 0.9545877969259432\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 154, train_loss = 20.165657939389348, train_acc = 0.9550535631113182\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 155, train_loss = 20.114265996962786, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 156, train_loss = 20.06475544720888, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 157, train_loss = 20.014438902959228, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 158, train_loss = 19.963037619367242, train_acc = 0.9554028877503493\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 159, train_loss = 19.914506666362286, train_acc = 0.9554028877503493\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 160, train_loss = 19.86544195562601, train_acc = 0.9552864462040056\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 161, train_loss = 19.818037195131183, train_acc = 0.9552864462040056\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 162, train_loss = 19.76996229402721, train_acc = 0.9552864462040056\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 163, train_loss = 19.72260063700378, train_acc = 0.9552864462040056\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 164, train_loss = 19.676872175186872, train_acc = 0.955519329296693\n",
      "test Acc 0.9436685288640596:\n",
      "15th- epoch: 165, train_loss = 19.630812592804432, train_acc = 0.955519329296693\n",
      "test Acc 0.9436685288640596:\n",
      "15th- epoch: 166, train_loss = 19.584858076646924, train_acc = 0.9556357708430367\n",
      "test Acc 0.9436685288640596:\n",
      "15th- epoch: 167, train_loss = 19.539187014102936, train_acc = 0.9557522123893806\n",
      "test Acc 0.9436685288640596:\n",
      "15th- epoch: 168, train_loss = 19.494302673265338, train_acc = 0.9557522123893806\n",
      "test Acc 0.9436685288640596:\n",
      "15th- epoch: 169, train_loss = 19.451536586508155, train_acc = 0.9557522123893806\n",
      "test Acc 0.9436685288640596:\n",
      "15th- epoch: 170, train_loss = 19.40647328644991, train_acc = 0.9558686539357243\n",
      "test Acc 0.9436685288640596:\n",
      "15th- epoch: 171, train_loss = 19.362695226445794, train_acc = 0.955985095482068\n",
      "test Acc 0.9436685288640596:\n",
      "15th- epoch: 172, train_loss = 19.321106685325503, train_acc = 0.955985095482068\n",
      "test Acc 0.9441340782122905:\n",
      "15th- epoch: 173, train_loss = 19.277691120281816, train_acc = 0.955985095482068\n",
      "test Acc 0.9441340782122905:\n",
      "15th- epoch: 174, train_loss = 19.235690515488386, train_acc = 0.955985095482068\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 175, train_loss = 19.19500352256, train_acc = 0.9562179785747554\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 176, train_loss = 19.153097352012992, train_acc = 0.9563344201210993\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 177, train_loss = 19.111525705084205, train_acc = 0.956450861667443\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 178, train_loss = 19.071451453492045, train_acc = 0.9569166278528178\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 179, train_loss = 19.030694849789143, train_acc = 0.9570330693991617\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 180, train_loss = 18.99121094122529, train_acc = 0.9571495109455054\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 181, train_loss = 18.95162091590464, train_acc = 0.9572659524918491\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 182, train_loss = 18.91412502154708, train_acc = 0.9572659524918491\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 183, train_loss = 18.875322185456753, train_acc = 0.9572659524918491\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 184, train_loss = 18.83681364171207, train_acc = 0.9574988355845365\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 185, train_loss = 18.797005718573928, train_acc = 0.9577317186772241\n",
      "test Acc 0.9450651769087524:\n",
      "15th- epoch: 186, train_loss = 18.76154094748199, train_acc = 0.9577317186772241\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 187, train_loss = 18.72409944422543, train_acc = 0.9577317186772241\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 188, train_loss = 18.686886282637715, train_acc = 0.9579646017699115\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 189, train_loss = 18.651860801503062, train_acc = 0.9579646017699115\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 190, train_loss = 18.615079384297132, train_acc = 0.9579646017699115\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 191, train_loss = 18.578431580215693, train_acc = 0.9580810433162552\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 192, train_loss = 18.543440928682685, train_acc = 0.9584303679552865\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 193, train_loss = 18.50918778218329, train_acc = 0.9584303679552865\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 194, train_loss = 18.47295208275318, train_acc = 0.9585468095016302\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 195, train_loss = 18.43989364616573, train_acc = 0.9586632510479739\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 196, train_loss = 18.4042905587703, train_acc = 0.9586632510479739\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 197, train_loss = 18.372109917923808, train_acc = 0.9586632510479739\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 198, train_loss = 18.336886055767536, train_acc = 0.9587796925943176\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 199, train_loss = 18.30550759844482, train_acc = 0.9587796925943176\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 200, train_loss = 18.271696723997593, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 201, train_loss = 18.239859029650688, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 202, train_loss = 18.207194505259395, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 203, train_loss = 18.176129214465618, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 204, train_loss = 18.143557354807854, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 205, train_loss = 18.112425230443478, train_acc = 0.9588961341406614\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 206, train_loss = 18.081413177773356, train_acc = 0.9590125756870052\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 207, train_loss = 18.049828929826617, train_acc = 0.9591290172333489\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 208, train_loss = 18.01842724904418, train_acc = 0.9593619003260363\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 209, train_loss = 17.98779439367354, train_acc = 0.9593619003260363\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 210, train_loss = 17.95785794965923, train_acc = 0.95947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 211, train_loss = 17.92793820053339, train_acc = 0.9595947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 212, train_loss = 17.89813338778913, train_acc = 0.9595947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 213, train_loss = 17.868970492854714, train_acc = 0.9597112249650676\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 214, train_loss = 17.840346271172166, train_acc = 0.9597112249650676\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 215, train_loss = 17.81154078245163, train_acc = 0.9597112249650676\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 216, train_loss = 17.782046316191554, train_acc = 0.9597112249650676\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 217, train_loss = 17.753990799188614, train_acc = 0.9598276665114113\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 218, train_loss = 17.7266255132854, train_acc = 0.9598276665114113\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 219, train_loss = 17.69931366108358, train_acc = 0.9598276665114113\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 220, train_loss = 17.671448703855276, train_acc = 0.959944108057755\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 221, train_loss = 17.643798971548676, train_acc = 0.959944108057755\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 222, train_loss = 17.617511248216033, train_acc = 0.959944108057755\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 223, train_loss = 17.590289486572146, train_acc = 0.959944108057755\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 224, train_loss = 17.564410414546728, train_acc = 0.9600605496040987\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 225, train_loss = 17.536941332742572, train_acc = 0.9600605496040987\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 226, train_loss = 17.5111310724169, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 227, train_loss = 17.4847291726619, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 228, train_loss = 17.458871066570282, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 229, train_loss = 17.43429410457611, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 230, train_loss = 17.408702183514833, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 231, train_loss = 17.383329164236784, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 232, train_loss = 17.35946868546307, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 233, train_loss = 17.33487837202847, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 234, train_loss = 17.31069432757795, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 235, train_loss = 17.28492569923401, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 236, train_loss = 17.260470679029822, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 237, train_loss = 17.236523373052478, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 238, train_loss = 17.213708201423287, train_acc = 0.9605263157894737\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 239, train_loss = 17.18876895494759, train_acc = 0.9605263157894737\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 240, train_loss = 17.16816918645054, train_acc = 0.9605263157894737\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 241, train_loss = 17.144548361189663, train_acc = 0.9606427573358174\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 242, train_loss = 17.11960771214217, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 243, train_loss = 17.097883774898946, train_acc = 0.9608756404285049\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 244, train_loss = 17.075414600782096, train_acc = 0.9609920819748486\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 245, train_loss = 17.052074807696044, train_acc = 0.9609920819748486\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 246, train_loss = 17.031052742153406, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 247, train_loss = 17.007050215266645, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 248, train_loss = 16.987164668738842, train_acc = 0.9614578481602236\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 249, train_loss = 16.96521293744445, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 250, train_loss = 16.94245005119592, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 251, train_loss = 16.921040286310017, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 252, train_loss = 16.89983395859599, train_acc = 0.9618071727992548\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 253, train_loss = 16.878912827931345, train_acc = 0.9618071727992548\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 254, train_loss = 16.858697979710996, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 255, train_loss = 16.838023123331368, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 256, train_loss = 16.816340199671686, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 257, train_loss = 16.796530053950846, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 258, train_loss = 16.77597373444587, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 259, train_loss = 16.75634452328086, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 260, train_loss = 16.73369184974581, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 261, train_loss = 16.711365439929068, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 262, train_loss = 16.69330532103777, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 263, train_loss = 16.675062882713974, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 264, train_loss = 16.654507749713957, train_acc = 0.9625058220773172\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 265, train_loss = 16.63619660306722, train_acc = 0.9625058220773172\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 266, train_loss = 16.616715514101088, train_acc = 0.9626222636236609\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 267, train_loss = 16.598712231963873, train_acc = 0.9626222636236609\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 268, train_loss = 16.58083613961935, train_acc = 0.9626222636236609\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 269, train_loss = 16.56025432422757, train_acc = 0.9628551467163484\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 270, train_loss = 16.543647301383317, train_acc = 0.9628551467163484\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 271, train_loss = 16.522972907871008, train_acc = 0.9628551467163484\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 272, train_loss = 16.505576801486313, train_acc = 0.9630880298090359\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 273, train_loss = 16.486761772073805, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 274, train_loss = 16.471449446864426, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 275, train_loss = 16.451300262473524, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 276, train_loss = 16.432065525092185, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 277, train_loss = 16.415460559539497, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 278, train_loss = 16.39697850868106, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 279, train_loss = 16.38086826261133, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 280, train_loss = 16.362750764004886, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 281, train_loss = 16.34554496780038, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 282, train_loss = 16.329038053750992, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 283, train_loss = 16.31085315812379, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 284, train_loss = 16.294859091751277, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 285, train_loss = 16.277443083934486, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 286, train_loss = 16.260854511521757, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 287, train_loss = 16.244681512005627, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 288, train_loss = 16.22737147565931, train_acc = 0.9637866790870983\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 289, train_loss = 16.213022978045046, train_acc = 0.9637866790870983\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 290, train_loss = 16.19731566309929, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 291, train_loss = 16.18037478905171, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 292, train_loss = 16.161542552523315, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 293, train_loss = 16.14352483022958, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 294, train_loss = 16.129544218070805, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 295, train_loss = 16.112635500729084, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 296, train_loss = 16.0986580690369, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 297, train_loss = 16.084141940809786, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 298, train_loss = 16.068987923674285, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 299, train_loss = 16.053482729010284, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 300, train_loss = 16.0357588166371, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 301, train_loss = 16.026044751517475, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 302, train_loss = 16.007521369494498, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 303, train_loss = 15.993121954612434, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 304, train_loss = 15.97729641199112, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 305, train_loss = 15.963644813746214, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 306, train_loss = 15.949267924763262, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 307, train_loss = 15.935667365789413, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 308, train_loss = 15.92175383400172, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 309, train_loss = 15.905272698961198, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 310, train_loss = 15.890999536029994, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 311, train_loss = 15.877936284989119, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 312, train_loss = 15.864222633652389, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 313, train_loss = 15.847473438829184, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 314, train_loss = 15.833904191851616, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 315, train_loss = 15.82311858702451, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 316, train_loss = 15.806690472178161, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 317, train_loss = 15.795534708537161, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 318, train_loss = 15.783533908426762, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 319, train_loss = 15.765426794998348, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 320, train_loss = 15.754217274487019, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 321, train_loss = 15.741567100398242, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 322, train_loss = 15.727609782479703, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 323, train_loss = 15.714442885480821, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 324, train_loss = 15.701736838556826, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 325, train_loss = 15.688165857456625, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 326, train_loss = 15.67571014445275, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 327, train_loss = 15.662224969826639, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 328, train_loss = 15.648500182665884, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 329, train_loss = 15.631765217520297, train_acc = 0.9649510945505356\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 330, train_loss = 15.618766245432198, train_acc = 0.9649510945505356\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 331, train_loss = 15.606397561728954, train_acc = 0.9649510945505356\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 332, train_loss = 15.594573955051601, train_acc = 0.9649510945505356\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 333, train_loss = 15.580737325362861, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 334, train_loss = 15.568238910287619, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 335, train_loss = 15.558716320432723, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 336, train_loss = 15.545658067800105, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 337, train_loss = 15.531951646320522, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 338, train_loss = 15.520930577069521, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 339, train_loss = 15.510856701992452, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 340, train_loss = 15.498168144375086, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 341, train_loss = 15.48461614921689, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 342, train_loss = 15.473902047611773, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 343, train_loss = 15.46283495798707, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 344, train_loss = 15.450444966554642, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 345, train_loss = 15.437712394632399, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 346, train_loss = 15.428521439433098, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 347, train_loss = 15.414400729350746, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 348, train_loss = 15.407057701610029, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 349, train_loss = 15.392439472489059, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 350, train_loss = 15.380879738368094, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 351, train_loss = 15.369516558013856, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 352, train_loss = 15.360285934060812, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 353, train_loss = 15.348075721412897, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 354, train_loss = 15.33646469656378, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 355, train_loss = 15.325974944978952, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 356, train_loss = 15.311348751187325, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 357, train_loss = 15.299259494058788, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 358, train_loss = 15.286982447840273, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 359, train_loss = 15.278160559944808, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 360, train_loss = 15.265286445617676, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 361, train_loss = 15.257309299893677, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 362, train_loss = 15.245322611182928, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 363, train_loss = 15.235486031509936, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 364, train_loss = 15.224451437592506, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 365, train_loss = 15.21732937823981, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 366, train_loss = 15.205329257063568, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 367, train_loss = 15.193438906222582, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 368, train_loss = 15.189157526940107, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 369, train_loss = 15.172051976434886, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 370, train_loss = 15.1623944779858, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 371, train_loss = 15.153406740166247, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 372, train_loss = 15.142303891479969, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 373, train_loss = 15.132401086390018, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 374, train_loss = 15.12463618721813, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 375, train_loss = 15.114205318503082, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 376, train_loss = 15.103661668486893, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 377, train_loss = 15.094194958917797, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 378, train_loss = 15.084173504263163, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 379, train_loss = 15.07166228722781, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 380, train_loss = 15.060966312885284, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 381, train_loss = 15.05226744711399, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 382, train_loss = 15.041870982386172, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 383, train_loss = 15.035684287548065, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 384, train_loss = 15.02699553500861, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 385, train_loss = 15.014688067138195, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 386, train_loss = 15.0054203979671, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 387, train_loss = 14.998534427024424, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 388, train_loss = 14.988511312752962, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 389, train_loss = 14.975752986036241, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 390, train_loss = 14.968110285699368, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 391, train_loss = 14.958482346497476, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 392, train_loss = 14.949025969952345, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 393, train_loss = 14.94473612960428, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 394, train_loss = 14.934926647692919, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 395, train_loss = 14.921489826403558, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 396, train_loss = 14.912901354022324, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 397, train_loss = 14.906030789017677, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 398, train_loss = 14.8998465789482, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 399, train_loss = 14.887108608148992, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 400, train_loss = 14.877722441218793, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 401, train_loss = 14.867046470753849, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 402, train_loss = 14.861954357475042, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 403, train_loss = 14.851638291031122, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 404, train_loss = 14.845032290555537, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 405, train_loss = 14.835318476893008, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 406, train_loss = 14.83104012068361, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 407, train_loss = 14.819679904729128, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 408, train_loss = 14.81044349912554, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 409, train_loss = 14.805367608554661, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 410, train_loss = 14.791227634064853, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 411, train_loss = 14.782727502286434, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 412, train_loss = 14.773893848061562, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 413, train_loss = 14.765817162580788, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 414, train_loss = 14.75974786002189, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 415, train_loss = 14.749500677920878, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 416, train_loss = 14.74175386223942, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 417, train_loss = 14.73632121924311, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 418, train_loss = 14.728875458240509, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 419, train_loss = 14.716467815451324, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 420, train_loss = 14.712435293011367, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 421, train_loss = 14.701724561862648, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 422, train_loss = 14.693339605815709, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 423, train_loss = 14.680825832299888, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 424, train_loss = 14.678561576642096, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 425, train_loss = 14.667663027532399, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 426, train_loss = 14.662733618170023, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 427, train_loss = 14.648360514082015, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 428, train_loss = 14.644925490953028, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 429, train_loss = 14.632946110330522, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 430, train_loss = 14.631719720549881, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 431, train_loss = 14.62346429284662, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 432, train_loss = 14.61568062659353, train_acc = 0.9671634839310667\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 433, train_loss = 14.604602567851543, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 434, train_loss = 14.60037690680474, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 435, train_loss = 14.587443773634732, train_acc = 0.9671634839310667\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 436, train_loss = 14.587674147449434, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 437, train_loss = 14.572266194969416, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 438, train_loss = 14.565775625407696, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 439, train_loss = 14.56050943955779, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 440, train_loss = 14.550449717789888, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 441, train_loss = 14.545360076241195, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 442, train_loss = 14.539722233079374, train_acc = 0.9676292501164415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 443, train_loss = 14.52723775152117, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 444, train_loss = 14.521954324096441, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 445, train_loss = 14.514705076813698, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 446, train_loss = 14.508734411559999, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 447, train_loss = 14.501438148319721, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 448, train_loss = 14.492007887922227, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 449, train_loss = 14.488267227075994, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 450, train_loss = 14.4844341725111, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 451, train_loss = 14.471714604645967, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 452, train_loss = 14.470216210000217, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 453, train_loss = 14.464215417392552, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 454, train_loss = 14.451668035238981, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 455, train_loss = 14.445034741424024, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 456, train_loss = 14.443843628279865, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "15th- epoch: 457, train_loss = 14.438026552088559, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 458, train_loss = 14.434079322963953, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 459, train_loss = 14.425859392620623, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "15th- epoch: 460, train_loss = 14.41129124071449, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 461, train_loss = 14.405418722890317, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 462, train_loss = 14.40717117022723, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 463, train_loss = 14.39868350699544, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 464, train_loss = 14.395445923320949, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 465, train_loss = 14.38271351158619, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 466, train_loss = 14.372422229498625, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 467, train_loss = 14.365079022943974, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 468, train_loss = 14.360298376530409, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 469, train_loss = 14.351957811973989, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 470, train_loss = 14.350745697971433, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 471, train_loss = 14.33750763675198, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 472, train_loss = 14.332982055842876, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 473, train_loss = 14.32555372780189, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 474, train_loss = 14.321095695253462, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 475, train_loss = 14.317321771290153, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 476, train_loss = 14.307265265379101, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 477, train_loss = 14.305021004285663, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 478, train_loss = 14.296413410454988, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 479, train_loss = 14.290109088178724, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 480, train_loss = 14.284994799643755, train_acc = 0.9683278993945039\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 481, train_loss = 14.28076965501532, train_acc = 0.9683278993945039\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 482, train_loss = 14.272112791892141, train_acc = 0.9683278993945039\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 483, train_loss = 14.264256577938795, train_acc = 0.9683278993945039\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 484, train_loss = 14.264857994858176, train_acc = 0.9683278993945039\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 485, train_loss = 14.25447978824377, train_acc = 0.9683278993945039\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 486, train_loss = 14.252072469796985, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 487, train_loss = 14.248632048722357, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 488, train_loss = 14.235520794987679, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 489, train_loss = 14.22906177630648, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 490, train_loss = 14.222157379146665, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 491, train_loss = 14.21430425113067, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 492, train_loss = 14.216146316379309, train_acc = 0.9684443409408477\n",
      "test Acc 0.9506517690875232:\n",
      "15th- epoch: 493, train_loss = 14.209263896103948, train_acc = 0.9684443409408477\n",
      "test Acc 0.9506517690875232:\n",
      "15th- epoch: 494, train_loss = 14.204988858196884, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "15th- epoch: 495, train_loss = 14.200561728328466, train_acc = 0.9685607824871915\n",
      "test Acc 0.9506517690875232:\n",
      "15th- epoch: 496, train_loss = 14.198375090956688, train_acc = 0.9685607824871915\n",
      "test Acc 0.9506517690875232:\n",
      "15th- epoch: 497, train_loss = 14.189079360570759, train_acc = 0.9685607824871915\n",
      "test Acc 0.9506517690875232:\n",
      "15th- epoch: 498, train_loss = 14.181414491031319, train_acc = 0.9685607824871915\n",
      "test Acc 0.9506517690875232:\n",
      "15th- epoch: 499, train_loss = 14.173418631311506, train_acc = 0.9685607824871915\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████                                   | 15/30 [1:39:52<1:40:01, 400.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "16th- epoch: 0, train_loss = 280.745853304863, train_acc = 0.40673032137866794\n",
      "test Acc 0.5:\n",
      "16th- epoch: 1, train_loss = 224.1437122821808, train_acc = 0.5016301816488123\n",
      "test Acc 0.5:\n",
      "16th- epoch: 2, train_loss = 183.6201536655426, train_acc = 0.503493246390312\n",
      "test Acc 0.5083798882681564:\n",
      "16th- epoch: 3, train_loss = 165.49496030807495, train_acc = 0.5296925943176526\n",
      "test Acc 0.5605214152700186:\n",
      "16th- epoch: 4, train_loss = 152.0387748479843, train_acc = 0.577899394503959\n",
      "test Acc 0.6056797020484171:\n",
      "16th- epoch: 5, train_loss = 140.15919303894043, train_acc = 0.6143455985095482\n",
      "test Acc 0.633147113594041:\n",
      "16th- epoch: 6, train_loss = 129.14881318807602, train_acc = 0.6429902189101071\n",
      "test Acc 0.6550279329608939:\n",
      "16th- epoch: 7, train_loss = 119.03913855552673, train_acc = 0.6944573823940382\n",
      "test Acc 0.7621042830540037:\n",
      "16th- epoch: 8, train_loss = 109.83869016170502, train_acc = 0.763623660922217\n",
      "test Acc 0.7811918063314711:\n",
      "16th- epoch: 9, train_loss = 101.50758528709412, train_acc = 0.7857475547275268\n",
      "test Acc 0.797951582867784:\n",
      "16th- epoch: 10, train_loss = 94.0101797580719, train_acc = 0.8097345132743363\n",
      "test Acc 0.8142458100558659:\n",
      "16th- epoch: 11, train_loss = 87.31037503480911, train_acc = 0.8195156031672101\n",
      "test Acc 0.824487895716946:\n",
      "16th- epoch: 12, train_loss = 81.3895191848278, train_acc = 0.8295295761527713\n",
      "test Acc 0.8435754189944135:\n",
      "16th- epoch: 13, train_loss = 76.19016218185425, train_acc = 0.8429203539823009\n",
      "test Acc 0.8538175046554934:\n",
      "16th- epoch: 14, train_loss = 71.63257417082787, train_acc = 0.8524685607824872\n",
      "test Acc 0.8589385474860335:\n",
      "16th- epoch: 15, train_loss = 67.63521948456764, train_acc = 0.8579413134606427\n",
      "test Acc 0.8635940409683427:\n",
      "16th- epoch: 16, train_loss = 64.12023168802261, train_acc = 0.8637633907778295\n",
      "test Acc 0.8691806331471136:\n",
      "16th- epoch: 17, train_loss = 61.02939519286156, train_acc = 0.8686539357242664\n",
      "test Acc 0.8766294227188082:\n",
      "16th- epoch: 18, train_loss = 58.3012932240963, train_acc = 0.873660922217047\n",
      "test Acc 0.8817504655493482:\n",
      "16th- epoch: 19, train_loss = 55.897059857845306, train_acc = 0.8793665579878901\n",
      "test Acc 0.8859404096834265:\n",
      "16th- epoch: 20, train_loss = 53.77120262384415, train_acc = 0.8833255705635771\n",
      "test Acc 0.8933891992551211:\n",
      "16th- epoch: 21, train_loss = 51.88219736516476, train_acc = 0.8905449464368886\n",
      "test Acc 0.8966480446927374:\n",
      "16th- epoch: 22, train_loss = 50.20191653072834, train_acc = 0.8935724266418258\n",
      "test Acc 0.9003724394785847:\n",
      "16th- epoch: 23, train_loss = 48.700395971536636, train_acc = 0.8962505822077317\n",
      "test Acc 0.8994413407821229:\n",
      "16th- epoch: 24, train_loss = 47.352854654192924, train_acc = 0.8976478807638566\n",
      "test Acc 0.9008379888268156:\n",
      "16th- epoch: 25, train_loss = 46.1373997181654, train_acc = 0.8992780624126688\n",
      "test Acc 0.9031657355679702:\n",
      "16th- epoch: 26, train_loss = 45.036534160375595, train_acc = 0.9007918025151374\n",
      "test Acc 0.904096834264432:\n",
      "16th- epoch: 27, train_loss = 44.033404782414436, train_acc = 0.9021891010712623\n",
      "test Acc 0.9059590316573557:\n",
      "16th- epoch: 28, train_loss = 43.114011630415916, train_acc = 0.9047508150908244\n",
      "test Acc 0.9082867783985102:\n",
      "16th- epoch: 29, train_loss = 42.26737393438816, train_acc = 0.907545412203074\n",
      "test Acc 0.909217877094972:\n",
      "16th- epoch: 30, train_loss = 41.48608711361885, train_acc = 0.9096413600372613\n",
      "test Acc 0.9120111731843575:\n",
      "16th- epoch: 31, train_loss = 40.759612038731575, train_acc = 0.9122030740568234\n",
      "test Acc 0.9138733705772812:\n",
      "16th- epoch: 32, train_loss = 40.08046714961529, train_acc = 0.9142990218910108\n",
      "test Acc 0.9143389199255121:\n",
      "16th- epoch: 33, train_loss = 39.443710654973984, train_acc = 0.915463437354448\n",
      "test Acc 0.9157355679702048:\n",
      "16th- epoch: 34, train_loss = 38.84672608971596, train_acc = 0.9161620866325105\n",
      "test Acc 0.9157355679702048:\n",
      "16th- epoch: 35, train_loss = 38.28439284861088, train_acc = 0.917675826734979\n",
      "test Acc 0.9157355679702048:\n",
      "16th- epoch: 36, train_loss = 37.753834903240204, train_acc = 0.9188402421984164\n",
      "test Acc 0.914804469273743:\n",
      "16th- epoch: 37, train_loss = 37.251516446471214, train_acc = 0.91988821611551\n",
      "test Acc 0.914804469273743:\n",
      "16th- epoch: 38, train_loss = 36.77302202582359, train_acc = 0.9207033069399162\n",
      "test Acc 0.9152700186219739:\n",
      "16th- epoch: 39, train_loss = 36.31814078986645, train_acc = 0.9214019562179786\n",
      "test Acc 0.9166666666666666:\n",
      "16th- epoch: 40, train_loss = 35.88431876897812, train_acc = 0.9219841639496973\n",
      "test Acc 0.9162011173184358:\n",
      "16th- epoch: 41, train_loss = 35.470049262046814, train_acc = 0.9229156963204471\n",
      "test Acc 0.9171322160148976:\n",
      "16th- epoch: 42, train_loss = 35.07321439683437, train_acc = 0.9231485794131346\n",
      "test Acc 0.9180633147113594:\n",
      "16th- epoch: 43, train_loss = 34.69415544718504, train_acc = 0.9236143455985095\n",
      "test Acc 0.9199255121042831:\n",
      "16th- epoch: 44, train_loss = 34.32963552325964, train_acc = 0.9244294364229158\n",
      "test Acc 0.9203910614525139:\n",
      "16th- epoch: 45, train_loss = 33.97950020432472, train_acc = 0.9248952026082906\n",
      "test Acc 0.9208566108007449:\n",
      "16th- epoch: 46, train_loss = 33.64231742173433, train_acc = 0.9262925011644154\n",
      "test Acc 0.9227188081936686:\n",
      "16th- epoch: 47, train_loss = 33.3178101554513, train_acc = 0.9269911504424779\n",
      "test Acc 0.9231843575418994:\n",
      "16th- epoch: 48, train_loss = 33.00373085588217, train_acc = 0.9279226828132278\n",
      "test Acc 0.9231843575418994:\n",
      "16th- epoch: 49, train_loss = 32.699240282177925, train_acc = 0.9283884489986027\n",
      "test Acc 0.9236499068901304:\n",
      "16th- epoch: 50, train_loss = 32.40479130297899, train_acc = 0.9287377736376339\n",
      "test Acc 0.9236499068901304:\n",
      "16th- epoch: 51, train_loss = 32.11900816112757, train_acc = 0.9289706567303214\n",
      "test Acc 0.9241154562383612:\n",
      "16th- epoch: 52, train_loss = 31.84045633673668, train_acc = 0.9295528644620401\n",
      "test Acc 0.9245810055865922:\n",
      "16th- epoch: 53, train_loss = 31.57102146744728, train_acc = 0.9297857475547275\n",
      "test Acc 0.9250465549348231:\n",
      "16th- epoch: 54, train_loss = 31.308287136256695, train_acc = 0.9303679552864462\n",
      "test Acc 0.9250465549348231:\n",
      "16th- epoch: 55, train_loss = 31.05300009995699, train_acc = 0.9311830461108523\n",
      "test Acc 0.9250465549348231:\n",
      "16th- epoch: 56, train_loss = 30.80455581098795, train_acc = 0.9314159292035398\n",
      "test Acc 0.9250465549348231:\n",
      "16th- epoch: 57, train_loss = 30.561421535909176, train_acc = 0.9314159292035398\n",
      "test Acc 0.9250465549348231:\n",
      "16th- epoch: 58, train_loss = 30.32412227243185, train_acc = 0.9315323707498836\n",
      "test Acc 0.925512104283054:\n",
      "16th- epoch: 59, train_loss = 30.09157431125641, train_acc = 0.9319981369352585\n",
      "test Acc 0.925512104283054:\n",
      "16th- epoch: 60, train_loss = 29.864849403500557, train_acc = 0.9326967862133209\n",
      "test Acc 0.9264432029795159:\n",
      "16th- epoch: 61, train_loss = 29.643460482358932, train_acc = 0.9328132277596647\n",
      "test Acc 0.9264432029795159:\n",
      "16th- epoch: 62, train_loss = 29.427071928977966, train_acc = 0.9330461108523521\n",
      "test Acc 0.9264432029795159:\n",
      "16th- epoch: 63, train_loss = 29.21566066145897, train_acc = 0.9332789939450395\n",
      "test Acc 0.9273743016759777:\n",
      "16th- epoch: 64, train_loss = 29.009416349232197, train_acc = 0.9333954354913834\n",
      "test Acc 0.9278398510242085:\n",
      "16th- epoch: 65, train_loss = 28.807361625134945, train_acc = 0.933977643223102\n",
      "test Acc 0.9283054003724395:\n",
      "16th- epoch: 66, train_loss = 28.610108368098736, train_acc = 0.9345598509548206\n",
      "test Acc 0.9287709497206704:\n",
      "16th- epoch: 67, train_loss = 28.417138800024986, train_acc = 0.9350256171401956\n",
      "test Acc 0.9287709497206704:\n",
      "16th- epoch: 68, train_loss = 28.227974601089954, train_acc = 0.9356078248719143\n",
      "test Acc 0.9287709497206704:\n",
      "16th- epoch: 69, train_loss = 28.042563274502754, train_acc = 0.9359571495109456\n",
      "test Acc 0.9292364990689013:\n",
      "16th- epoch: 70, train_loss = 27.860587254166603, train_acc = 0.936190032603633\n",
      "test Acc 0.9287709497206704:\n",
      "16th- epoch: 71, train_loss = 27.68178378790617, train_acc = 0.9365393572426641\n",
      "test Acc 0.9292364990689013:\n",
      "16th- epoch: 72, train_loss = 27.50619948655367, train_acc = 0.9371215649743828\n",
      "test Acc 0.9292364990689013:\n",
      "16th- epoch: 73, train_loss = 27.33385617285967, train_acc = 0.9374708896134141\n",
      "test Acc 0.9297020484171322:\n",
      "16th- epoch: 74, train_loss = 27.166106015443802, train_acc = 0.9378202142524453\n",
      "test Acc 0.9297020484171322:\n",
      "16th- epoch: 75, train_loss = 27.000813454389572, train_acc = 0.937936655798789\n",
      "test Acc 0.9297020484171322:\n",
      "16th- epoch: 76, train_loss = 26.83845917135477, train_acc = 0.9386353050768514\n",
      "test Acc 0.9301675977653632:\n",
      "16th- epoch: 77, train_loss = 26.680263571441174, train_acc = 0.9391010712622264\n",
      "test Acc 0.9301675977653632:\n",
      "16th- epoch: 78, train_loss = 26.52491921186447, train_acc = 0.9393339543549138\n",
      "test Acc 0.930633147113594:\n",
      "16th- epoch: 79, train_loss = 26.372877903282642, train_acc = 0.9400326036329762\n",
      "test Acc 0.930633147113594:\n",
      "16th- epoch: 80, train_loss = 26.223515406250954, train_acc = 0.9404983698183512\n",
      "test Acc 0.931098696461825:\n",
      "16th- epoch: 81, train_loss = 26.077564645558596, train_acc = 0.9409641360037261\n",
      "test Acc 0.931098696461825:\n",
      "16th- epoch: 82, train_loss = 25.93403021991253, train_acc = 0.9416627852817886\n",
      "test Acc 0.931098696461825:\n",
      "16th- epoch: 83, train_loss = 25.792989321053028, train_acc = 0.9420121099208197\n",
      "test Acc 0.931098696461825:\n",
      "16th- epoch: 84, train_loss = 25.654861856251955, train_acc = 0.9420121099208197\n",
      "test Acc 0.931098696461825:\n",
      "16th- epoch: 85, train_loss = 25.519665479660034, train_acc = 0.9421285514671635\n",
      "test Acc 0.9315642458100558:\n",
      "16th- epoch: 86, train_loss = 25.386357355862856, train_acc = 0.9429436422915697\n",
      "test Acc 0.9320297951582868:\n",
      "16th- epoch: 87, train_loss = 25.255384501069784, train_acc = 0.9431765253842571\n",
      "test Acc 0.9324953445065177:\n",
      "16th- epoch: 88, train_loss = 25.12718676030636, train_acc = 0.9432929669306008\n",
      "test Acc 0.9329608938547486:\n",
      "16th- epoch: 89, train_loss = 25.001422472298145, train_acc = 0.9439916162086632\n",
      "test Acc 0.9334264432029795:\n",
      "16th- epoch: 90, train_loss = 24.877779476344585, train_acc = 0.9442244993013508\n",
      "test Acc 0.9338919925512105:\n",
      "16th- epoch: 91, train_loss = 24.75600380450487, train_acc = 0.9444573823940382\n",
      "test Acc 0.9338919925512105:\n",
      "16th- epoch: 92, train_loss = 24.63644326478243, train_acc = 0.9450395901257569\n",
      "test Acc 0.9338919925512105:\n",
      "16th- epoch: 93, train_loss = 24.518810410052538, train_acc = 0.9455053563111319\n",
      "test Acc 0.9338919925512105:\n",
      "16th- epoch: 94, train_loss = 24.40323944762349, train_acc = 0.945854680950163\n",
      "test Acc 0.9343575418994413:\n",
      "16th- epoch: 95, train_loss = 24.289995837956667, train_acc = 0.9462040055891943\n",
      "test Acc 0.9352886405959032:\n",
      "16th- epoch: 96, train_loss = 24.179207731038332, train_acc = 0.946320447135538\n",
      "test Acc 0.9352886405959032:\n",
      "16th- epoch: 97, train_loss = 24.069930374622345, train_acc = 0.946320447135538\n",
      "test Acc 0.9352886405959032:\n",
      "16th- epoch: 98, train_loss = 23.96289486810565, train_acc = 0.9465533302282254\n",
      "test Acc 0.9352886405959032:\n",
      "16th- epoch: 99, train_loss = 23.8577387817204, train_acc = 0.9465533302282254\n",
      "test Acc 0.9352886405959032:\n",
      "16th- epoch: 100, train_loss = 23.755844194442034, train_acc = 0.9470190964136004\n",
      "test Acc 0.9357541899441341:\n",
      "16th- epoch: 101, train_loss = 23.65226810798049, train_acc = 0.9470190964136004\n",
      "test Acc 0.9357541899441341:\n",
      "16th- epoch: 102, train_loss = 23.552319396287203, train_acc = 0.9470190964136004\n",
      "test Acc 0.9357541899441341:\n",
      "16th- epoch: 103, train_loss = 23.4539256952703, train_acc = 0.9471355379599441\n",
      "test Acc 0.9366852886405959:\n",
      "16th- epoch: 104, train_loss = 23.356972940266132, train_acc = 0.9473684210526315\n",
      "test Acc 0.9366852886405959:\n",
      "16th- epoch: 105, train_loss = 23.26301535964012, train_acc = 0.9476013041453191\n",
      "test Acc 0.9366852886405959:\n",
      "16th- epoch: 106, train_loss = 23.167887803167105, train_acc = 0.9478341872380065\n",
      "test Acc 0.9366852886405959:\n",
      "16th- epoch: 107, train_loss = 23.076461650431156, train_acc = 0.9484163949697252\n",
      "test Acc 0.9366852886405959:\n",
      "16th- epoch: 108, train_loss = 22.984275683760643, train_acc = 0.9485328365160689\n",
      "test Acc 0.9366852886405959:\n",
      "16th- epoch: 109, train_loss = 22.89612501114607, train_acc = 0.9488821611551002\n",
      "test Acc 0.9366852886405959:\n",
      "16th- epoch: 110, train_loss = 22.80620075389743, train_acc = 0.9491150442477876\n",
      "test Acc 0.9366852886405959:\n",
      "16th- epoch: 111, train_loss = 22.721090726554394, train_acc = 0.9491150442477876\n",
      "test Acc 0.9366852886405959:\n",
      "16th- epoch: 112, train_loss = 22.634195744991302, train_acc = 0.9493479273404751\n",
      "test Acc 0.9371508379888268:\n",
      "16th- epoch: 113, train_loss = 22.55238777399063, train_acc = 0.9496972519795063\n",
      "test Acc 0.9380819366852886:\n",
      "16th- epoch: 114, train_loss = 22.467735417187214, train_acc = 0.9496972519795063\n",
      "test Acc 0.9380819366852886:\n",
      "16th- epoch: 115, train_loss = 22.387940626591444, train_acc = 0.94981369352585\n",
      "test Acc 0.9385474860335196:\n",
      "16th- epoch: 116, train_loss = 22.305563282221556, train_acc = 0.9499301350721937\n",
      "test Acc 0.9385474860335196:\n",
      "16th- epoch: 117, train_loss = 22.22863471880555, train_acc = 0.9501630181648812\n",
      "test Acc 0.9385474860335196:\n",
      "16th- epoch: 118, train_loss = 22.149331215769053, train_acc = 0.9503959012575687\n",
      "test Acc 0.9385474860335196:\n",
      "16th- epoch: 119, train_loss = 22.07398245483637, train_acc = 0.9506287843502562\n",
      "test Acc 0.9385474860335196:\n",
      "16th- epoch: 120, train_loss = 21.99610211327672, train_acc = 0.9508616674429436\n",
      "test Acc 0.9385474860335196:\n",
      "16th- epoch: 121, train_loss = 21.921488352119923, train_acc = 0.9513274336283186\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 122, train_loss = 21.848340202122927, train_acc = 0.9513274336283186\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 123, train_loss = 21.775618199259043, train_acc = 0.9512109920819748\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 124, train_loss = 21.7042576931417, train_acc = 0.9514438751746623\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 125, train_loss = 21.63386807963252, train_acc = 0.951560316721006\n",
      "test Acc 0.9394785847299814:\n",
      "16th- epoch: 126, train_loss = 21.56441456824541, train_acc = 0.951560316721006\n",
      "test Acc 0.9394785847299814:\n",
      "16th- epoch: 127, train_loss = 21.49604321271181, train_acc = 0.951560316721006\n",
      "test Acc 0.9394785847299814:\n",
      "16th- epoch: 128, train_loss = 21.430706974118948, train_acc = 0.9516767582673498\n",
      "test Acc 0.9399441340782123:\n",
      "16th- epoch: 129, train_loss = 21.364719204604626, train_acc = 0.9516767582673498\n",
      "test Acc 0.9399441340782123:\n",
      "16th- epoch: 130, train_loss = 21.29504906386137, train_acc = 0.9519096413600373\n",
      "test Acc 0.9404096834264432:\n",
      "16th- epoch: 131, train_loss = 21.23282292857766, train_acc = 0.9521425244527247\n",
      "test Acc 0.9404096834264432:\n",
      "16th- epoch: 132, train_loss = 21.168775636702776, train_acc = 0.9523754075454122\n",
      "test Acc 0.9404096834264432:\n",
      "16th- epoch: 133, train_loss = 21.10641996189952, train_acc = 0.952491849091756\n",
      "test Acc 0.9404096834264432:\n",
      "16th- epoch: 134, train_loss = 21.043134979903698, train_acc = 0.952491849091756\n",
      "test Acc 0.9404096834264432:\n",
      "16th- epoch: 135, train_loss = 20.981562096625566, train_acc = 0.952491849091756\n",
      "test Acc 0.9404096834264432:\n",
      "16th- epoch: 136, train_loss = 20.920164614915848, train_acc = 0.9526082906380997\n",
      "test Acc 0.9408752327746741:\n",
      "16th- epoch: 137, train_loss = 20.861107166856527, train_acc = 0.9527247321844434\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 138, train_loss = 20.802567299455404, train_acc = 0.9528411737307871\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 139, train_loss = 20.74223893508315, train_acc = 0.9531904983698184\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 140, train_loss = 20.685870599001646, train_acc = 0.9534233814625058\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 141, train_loss = 20.6281916834414, train_acc = 0.9534233814625058\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 142, train_loss = 20.572391863912344, train_acc = 0.9535398230088495\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 143, train_loss = 20.516726598143578, train_acc = 0.9537727061015371\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 144, train_loss = 20.461775835603476, train_acc = 0.9540055891942245\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 145, train_loss = 20.406089555472136, train_acc = 0.9540055891942245\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 146, train_loss = 20.350507728755474, train_acc = 0.9541220307405682\n",
      "test Acc 0.9418063314711359:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 147, train_loss = 20.298899706453085, train_acc = 0.9543549138332557\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 148, train_loss = 20.246241558343172, train_acc = 0.9544713553795995\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 149, train_loss = 20.195260982960463, train_acc = 0.9545877969259432\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 150, train_loss = 20.14378432929516, train_acc = 0.9545877969259432\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 151, train_loss = 20.09324225783348, train_acc = 0.9548206800186306\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 152, train_loss = 20.043309012427926, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 153, train_loss = 19.99291480332613, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 154, train_loss = 19.944099938496947, train_acc = 0.9549371215649743\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 155, train_loss = 19.89388425089419, train_acc = 0.9551700046576619\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 156, train_loss = 19.84612594731152, train_acc = 0.9551700046576619\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 157, train_loss = 19.797652488574386, train_acc = 0.9552864462040056\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 158, train_loss = 19.75407055579126, train_acc = 0.955519329296693\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 159, train_loss = 19.70730880089104, train_acc = 0.9556357708430367\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 160, train_loss = 19.66201152652502, train_acc = 0.9556357708430367\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 161, train_loss = 19.616817900910974, train_acc = 0.9558686539357243\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 162, train_loss = 19.572149328887463, train_acc = 0.9561015370284117\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 163, train_loss = 19.524891635403037, train_acc = 0.9561015370284117\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 164, train_loss = 19.479709658771753, train_acc = 0.9561015370284117\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 165, train_loss = 19.437121415510774, train_acc = 0.9563344201210993\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 166, train_loss = 19.39712877944112, train_acc = 0.9563344201210993\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 167, train_loss = 19.351642092689872, train_acc = 0.956450861667443\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 168, train_loss = 19.312648816034198, train_acc = 0.956450861667443\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 169, train_loss = 19.26934905909002, train_acc = 0.9565673032137867\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 170, train_loss = 19.226333731785417, train_acc = 0.9569166278528178\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 171, train_loss = 19.183606741949916, train_acc = 0.9569166278528178\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 172, train_loss = 19.146644609048963, train_acc = 0.9571495109455054\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 173, train_loss = 19.105900797992945, train_acc = 0.9570330693991617\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 174, train_loss = 19.064364068210125, train_acc = 0.9572659524918491\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 175, train_loss = 19.028729803860188, train_acc = 0.9572659524918491\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 176, train_loss = 18.98627140559256, train_acc = 0.9572659524918491\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 177, train_loss = 18.950223000720143, train_acc = 0.9572659524918491\n",
      "test Acc 0.9436685288640596:\n",
      "16th- epoch: 178, train_loss = 18.91039709933102, train_acc = 0.9573823940381928\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 179, train_loss = 18.874688981100917, train_acc = 0.9573823940381928\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 180, train_loss = 18.83614861033857, train_acc = 0.9577317186772241\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 181, train_loss = 18.800839068368077, train_acc = 0.9576152771308803\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 182, train_loss = 18.762977050617337, train_acc = 0.9578481602235678\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 183, train_loss = 18.727392753586173, train_acc = 0.9577317186772241\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 184, train_loss = 18.690108397975564, train_acc = 0.9578481602235678\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 185, train_loss = 18.65390806645155, train_acc = 0.9578481602235678\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 186, train_loss = 18.618734708055854, train_acc = 0.9579646017699115\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 187, train_loss = 18.581720920279622, train_acc = 0.9583139264089428\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 188, train_loss = 18.549408664926887, train_acc = 0.9583139264089428\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 189, train_loss = 18.513700792565942, train_acc = 0.9584303679552865\n",
      "test Acc 0.9445996275605214:\n",
      "16th- epoch: 190, train_loss = 18.481165727600455, train_acc = 0.9585468095016302\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 191, train_loss = 18.446912774816155, train_acc = 0.9585468095016302\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 192, train_loss = 18.413527430966496, train_acc = 0.9585468095016302\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 193, train_loss = 18.379795653745532, train_acc = 0.9586632510479739\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 194, train_loss = 18.348699564114213, train_acc = 0.9586632510479739\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 195, train_loss = 18.314712772145867, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 196, train_loss = 18.282147996127605, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 197, train_loss = 18.252049017697573, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 198, train_loss = 18.21895388327539, train_acc = 0.9590125756870052\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 199, train_loss = 18.1891497541219, train_acc = 0.9591290172333489\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 200, train_loss = 18.15717181749642, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 201, train_loss = 18.127114113420248, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 202, train_loss = 18.096248295158148, train_acc = 0.9592454587796926\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 203, train_loss = 18.06576189212501, train_acc = 0.9592454587796926\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 204, train_loss = 18.03560564853251, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 205, train_loss = 18.00505098886788, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 206, train_loss = 17.976462671533227, train_acc = 0.95947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 207, train_loss = 17.946866646409035, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 208, train_loss = 17.917402986437082, train_acc = 0.95947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 209, train_loss = 17.89058226160705, train_acc = 0.95947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 210, train_loss = 17.86180749721825, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 211, train_loss = 17.832650253549218, train_acc = 0.9598276665114113\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 212, train_loss = 17.805051108822227, train_acc = 0.9600605496040987\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 213, train_loss = 17.777392303571105, train_acc = 0.9605263157894737\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 214, train_loss = 17.750017514452338, train_acc = 0.9606427573358174\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 215, train_loss = 17.723256090655923, train_acc = 0.9607591988821611\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 216, train_loss = 17.69599481858313, train_acc = 0.9606427573358174\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 217, train_loss = 17.669777646660805, train_acc = 0.9606427573358174\n",
      "test Acc 0.9464618249534451:\n",
      "16th- epoch: 218, train_loss = 17.642499037086964, train_acc = 0.9606427573358174\n",
      "test Acc 0.9464618249534451:\n",
      "16th- epoch: 219, train_loss = 17.616794196888804, train_acc = 0.9607591988821611\n",
      "test Acc 0.9464618249534451:\n",
      "16th- epoch: 220, train_loss = 17.591880245134234, train_acc = 0.9607591988821611\n",
      "test Acc 0.9464618249534451:\n",
      "16th- epoch: 221, train_loss = 17.56648856587708, train_acc = 0.9607591988821611\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 222, train_loss = 17.538630159571767, train_acc = 0.9607591988821611\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 223, train_loss = 17.514665447175503, train_acc = 0.9607591988821611\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 224, train_loss = 17.48871804215014, train_acc = 0.9607591988821611\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 225, train_loss = 17.464111303910613, train_acc = 0.9608756404285049\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 226, train_loss = 17.43919142894447, train_acc = 0.9611085235211924\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 227, train_loss = 17.413358878344297, train_acc = 0.9611085235211924\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 228, train_loss = 17.389738829806447, train_acc = 0.9611085235211924\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 229, train_loss = 17.364583732560277, train_acc = 0.9613414066138798\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 230, train_loss = 17.340096982195973, train_acc = 0.9613414066138798\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 231, train_loss = 17.317253904417157, train_acc = 0.9613414066138798\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 232, train_loss = 17.293687967583537, train_acc = 0.9613414066138798\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 233, train_loss = 17.269411792978644, train_acc = 0.9613414066138798\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 234, train_loss = 17.24606701731682, train_acc = 0.9613414066138798\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 235, train_loss = 17.223308024927974, train_acc = 0.9614578481602236\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 236, train_loss = 17.199473651126027, train_acc = 0.9614578481602236\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 237, train_loss = 17.177806235849857, train_acc = 0.9614578481602236\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 238, train_loss = 17.15254600904882, train_acc = 0.9614578481602236\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 239, train_loss = 17.13176766037941, train_acc = 0.9615742897065673\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 240, train_loss = 17.108517514541745, train_acc = 0.961690731252911\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 241, train_loss = 17.085803179070354, train_acc = 0.961690731252911\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 242, train_loss = 17.063333028927445, train_acc = 0.961690731252911\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 243, train_loss = 17.04266706109047, train_acc = 0.9618071727992548\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 244, train_loss = 17.02050850354135, train_acc = 0.9618071727992548\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 245, train_loss = 16.998558077961206, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 246, train_loss = 16.978750862181187, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 247, train_loss = 16.95496914535761, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 248, train_loss = 16.934603091329336, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 249, train_loss = 16.914234146475792, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 250, train_loss = 16.89432596322149, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 251, train_loss = 16.872462440282106, train_acc = 0.9622729389846297\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 252, train_loss = 16.85238029062748, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 253, train_loss = 16.832114829681814, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 254, train_loss = 16.812925565056503, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 255, train_loss = 16.79269115999341, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 256, train_loss = 16.77171280607581, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 257, train_loss = 16.751175862737, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 258, train_loss = 16.73403484839946, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 259, train_loss = 16.713835117407143, train_acc = 0.9623893805309734\n",
      "test Acc 0.9487895716945997:\n",
      "16th- epoch: 260, train_loss = 16.695587650872767, train_acc = 0.9626222636236609\n",
      "test Acc 0.9487895716945997:\n",
      "16th- epoch: 261, train_loss = 16.675059313885868, train_acc = 0.9626222636236609\n",
      "test Acc 0.9487895716945997:\n",
      "16th- epoch: 262, train_loss = 16.655158977024257, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 263, train_loss = 16.636266502551734, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 264, train_loss = 16.618210866115987, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 265, train_loss = 16.597650539129972, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 266, train_loss = 16.5787482149899, train_acc = 0.9628551467163484\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 267, train_loss = 16.562311619520187, train_acc = 0.9630880298090359\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 268, train_loss = 16.544157683849335, train_acc = 0.9632044713553796\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 269, train_loss = 16.525776126421988, train_acc = 0.9632044713553796\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 270, train_loss = 16.50810705590993, train_acc = 0.9632044713553796\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 271, train_loss = 16.490460612811148, train_acc = 0.9632044713553796\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 272, train_loss = 16.47181773558259, train_acc = 0.9632044713553796\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 273, train_loss = 16.454174018464983, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 274, train_loss = 16.43843953963369, train_acc = 0.9633209129017233\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 275, train_loss = 16.417232329957187, train_acc = 0.9635537959944108\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 276, train_loss = 16.402093585580587, train_acc = 0.9635537959944108\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 277, train_loss = 16.384708018042147, train_acc = 0.9635537959944108\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 278, train_loss = 16.365748188458383, train_acc = 0.9637866790870983\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 279, train_loss = 16.352928332053125, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 280, train_loss = 16.334337850101292, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 281, train_loss = 16.31741665210575, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 282, train_loss = 16.301446923054755, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 283, train_loss = 16.28221153188497, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 284, train_loss = 16.266153819859028, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 285, train_loss = 16.2497256109491, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 286, train_loss = 16.23579244222492, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 287, train_loss = 16.218942155130208, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 288, train_loss = 16.20229930523783, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 289, train_loss = 16.185448140837252, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 290, train_loss = 16.169999905861914, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 291, train_loss = 16.15689893439412, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 292, train_loss = 16.139574773609638, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 293, train_loss = 16.125396955758333, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 294, train_loss = 16.110156059265137, train_acc = 0.9642524452724732\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 295, train_loss = 16.093524578027427, train_acc = 0.9642524452724732\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 296, train_loss = 16.078982668928802, train_acc = 0.9643688868188169\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 297, train_loss = 16.063285262323916, train_acc = 0.9643688868188169\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 298, train_loss = 16.049819477833807, train_acc = 0.9643688868188169\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 299, train_loss = 16.033989389427006, train_acc = 0.9643688868188169\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 300, train_loss = 16.017785612493753, train_acc = 0.9643688868188169\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 301, train_loss = 16.00456301588565, train_acc = 0.9643688868188169\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 302, train_loss = 15.98858713824302, train_acc = 0.9643688868188169\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 303, train_loss = 15.975027404725552, train_acc = 0.9643688868188169\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 304, train_loss = 15.95936556905508, train_acc = 0.9643688868188169\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 305, train_loss = 15.946225949563086, train_acc = 0.9643688868188169\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 306, train_loss = 15.93192785140127, train_acc = 0.9644853283651607\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 307, train_loss = 15.917791280895472, train_acc = 0.9644853283651607\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 308, train_loss = 15.901669263839722, train_acc = 0.9646017699115044\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 309, train_loss = 15.889335039071739, train_acc = 0.9647182114578482\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 310, train_loss = 15.87389300391078, train_acc = 0.9647182114578482\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 311, train_loss = 15.860661913640797, train_acc = 0.9646017699115044\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 312, train_loss = 15.847469467669725, train_acc = 0.9647182114578482\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 313, train_loss = 15.833566932938993, train_acc = 0.9647182114578482\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 314, train_loss = 15.819577696733177, train_acc = 0.9647182114578482\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 315, train_loss = 15.804378823377192, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 316, train_loss = 15.791540037840605, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 317, train_loss = 15.776804751716554, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 318, train_loss = 15.764175265096128, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 319, train_loss = 15.753379005007446, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 320, train_loss = 15.738175608217716, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 321, train_loss = 15.724774799309671, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 322, train_loss = 15.711312723346055, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 323, train_loss = 15.698137885890901, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 324, train_loss = 15.6855913316831, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 325, train_loss = 15.673964171670377, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 326, train_loss = 15.659587337635458, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 327, train_loss = 15.649152480065823, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 328, train_loss = 15.636017985641956, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 329, train_loss = 15.623411462642252, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 330, train_loss = 15.608207277022302, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 331, train_loss = 15.59416726604104, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 332, train_loss = 15.584711588919163, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 333, train_loss = 15.574843943119049, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 334, train_loss = 15.558250077068806, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 335, train_loss = 15.546764872036874, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 336, train_loss = 15.537748164497316, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 337, train_loss = 15.521661908365786, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 338, train_loss = 15.510252822190523, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 339, train_loss = 15.500257015228271, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 340, train_loss = 15.486508064903319, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 341, train_loss = 15.476085861213505, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 342, train_loss = 15.464737004600465, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 343, train_loss = 15.451444249600172, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 344, train_loss = 15.44159147888422, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 345, train_loss = 15.429058462381363, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 346, train_loss = 15.418506130576134, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 347, train_loss = 15.406577619723976, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 348, train_loss = 15.394926309585571, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 349, train_loss = 15.383371037431061, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 350, train_loss = 15.372176308184862, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 351, train_loss = 15.359865267761052, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 352, train_loss = 15.349008758552372, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 353, train_loss = 15.336898314766586, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 354, train_loss = 15.326905843801796, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 355, train_loss = 15.315438203513622, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 356, train_loss = 15.30527759063989, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 357, train_loss = 15.294113326817751, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 358, train_loss = 15.283877898938954, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 359, train_loss = 15.272713472135365, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 360, train_loss = 15.260881616733968, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 361, train_loss = 15.2535290280357, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 362, train_loss = 15.240868833847344, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 363, train_loss = 15.231898850761354, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 364, train_loss = 15.221707072108984, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 365, train_loss = 15.211576773785055, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 366, train_loss = 15.198483359999955, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 367, train_loss = 15.187816803343594, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 368, train_loss = 15.177843942306936, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 369, train_loss = 15.168073353357613, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 370, train_loss = 15.158806054852903, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 371, train_loss = 15.147290513850749, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 372, train_loss = 15.138154234737158, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 373, train_loss = 15.12929552514106, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 374, train_loss = 15.119379695504904, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 375, train_loss = 15.108681130222976, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 376, train_loss = 15.100226297043264, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 377, train_loss = 15.08810220938176, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 378, train_loss = 15.079804514534771, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 379, train_loss = 15.069549317471683, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 380, train_loss = 15.06243409961462, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 381, train_loss = 15.050505478866398, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 382, train_loss = 15.041664046235383, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 383, train_loss = 15.031856973655522, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 384, train_loss = 15.02149435505271, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 385, train_loss = 15.013412143103778, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 386, train_loss = 15.002347762696445, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 387, train_loss = 14.995267045684159, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 388, train_loss = 14.984467794187367, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 389, train_loss = 14.977462808601558, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 390, train_loss = 14.966704525053501, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 391, train_loss = 14.956812460906804, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 392, train_loss = 14.949604908935726, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 393, train_loss = 14.939857088029385, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 394, train_loss = 14.933409030549228, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 395, train_loss = 14.923085630871356, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 396, train_loss = 14.915158127434552, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 397, train_loss = 14.903784960508347, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 398, train_loss = 14.896615031175315, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 399, train_loss = 14.887835728935897, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 400, train_loss = 14.87947779148817, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 401, train_loss = 14.869256149046123, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 402, train_loss = 14.86320932302624, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 403, train_loss = 14.852359817363322, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 404, train_loss = 14.845468920655549, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 405, train_loss = 14.835663209669292, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 406, train_loss = 14.828784436918795, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 407, train_loss = 14.817772679962218, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 408, train_loss = 14.810294646769762, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 409, train_loss = 14.803406014107168, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 410, train_loss = 14.794527261517942, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 411, train_loss = 14.785663551650941, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 412, train_loss = 14.778888172470033, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 413, train_loss = 14.76876141410321, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 414, train_loss = 14.761961862444878, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 415, train_loss = 14.75040000770241, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 416, train_loss = 14.745347709394991, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 417, train_loss = 14.73787622153759, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 418, train_loss = 14.726848498918116, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 419, train_loss = 14.72128698322922, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 420, train_loss = 14.711912297643721, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 421, train_loss = 14.704774822108448, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 422, train_loss = 14.699119158089161, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 423, train_loss = 14.690038212575018, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 424, train_loss = 14.681356001645327, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 425, train_loss = 14.676299096085131, train_acc = 0.9671634839310667\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 426, train_loss = 14.664970863610506, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 427, train_loss = 14.658842193894088, train_acc = 0.9671634839310667\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 428, train_loss = 14.649761129170656, train_acc = 0.9671634839310667\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 429, train_loss = 14.64286066684872, train_acc = 0.9672799254774104\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 430, train_loss = 14.63598158210516, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 431, train_loss = 14.629359992686659, train_acc = 0.9672799254774104\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 432, train_loss = 14.621532118413597, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 433, train_loss = 14.613853021059185, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 434, train_loss = 14.604295289609581, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 435, train_loss = 14.599225090350956, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 436, train_loss = 14.59165451163426, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 437, train_loss = 14.583928626030684, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 438, train_loss = 14.577555505093187, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 439, train_loss = 14.56920688226819, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 440, train_loss = 14.561856906861067, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 441, train_loss = 14.554834821727127, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 442, train_loss = 14.548450076486915, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 443, train_loss = 14.538759319577366, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 444, train_loss = 14.533753145486116, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 445, train_loss = 14.524728166405112, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 446, train_loss = 14.51828089216724, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 447, train_loss = 14.512803006917238, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 448, train_loss = 14.503451074007899, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 449, train_loss = 14.49966138228774, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 450, train_loss = 14.49183082813397, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 451, train_loss = 14.482355038169771, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 452, train_loss = 14.477553933858871, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 453, train_loss = 14.470191575586796, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 454, train_loss = 14.463744092732668, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 455, train_loss = 14.458994851913303, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 456, train_loss = 14.449873365461826, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 457, train_loss = 14.441411172505468, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 458, train_loss = 14.437732834368944, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 459, train_loss = 14.428978323936462, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 460, train_loss = 14.42322394484654, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 461, train_loss = 14.416693519800901, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 462, train_loss = 14.410815566778183, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 463, train_loss = 14.402981963008642, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 464, train_loss = 14.395831943955272, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 465, train_loss = 14.389643094036728, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 466, train_loss = 14.382727067917585, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 467, train_loss = 14.375808251556009, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 468, train_loss = 14.370416035410017, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 469, train_loss = 14.366033390164375, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 470, train_loss = 14.357788427267224, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 471, train_loss = 14.351539955940098, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 472, train_loss = 14.346090720500797, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 473, train_loss = 14.338000634219497, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 474, train_loss = 14.33351231366396, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 475, train_loss = 14.326225080993026, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 476, train_loss = 14.31972893839702, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 477, train_loss = 14.312120658811182, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 478, train_loss = 14.308470021933317, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 479, train_loss = 14.30408331984654, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 480, train_loss = 14.294770875480026, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 481, train_loss = 14.291197434067726, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 482, train_loss = 14.283380868379027, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 483, train_loss = 14.27778542554006, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 484, train_loss = 14.27343275770545, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 485, train_loss = 14.264376305043697, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 486, train_loss = 14.260062018875033, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 487, train_loss = 14.253823533654213, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 488, train_loss = 14.24619990075007, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 489, train_loss = 14.240797905717045, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 490, train_loss = 14.238054048269987, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 491, train_loss = 14.230006559286267, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 492, train_loss = 14.224150417838246, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 493, train_loss = 14.22045304113999, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 494, train_loss = 14.213043849915266, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 495, train_loss = 14.20523631433025, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 496, train_loss = 14.201290283352137, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 497, train_loss = 14.196982119232416, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 498, train_loss = 14.188013179693371, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 499, train_loss = 14.18466711556539, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████▎                                | 16/30 [1:46:30<1:33:09, 399.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "17th- epoch: 0, train_loss = 274.5994073152542, train_acc = 0.45016301816488125\n",
      "test Acc 0.4995344506517691:\n",
      "17th- epoch: 1, train_loss = 213.62568199634552, train_acc = 0.5015137401024685\n",
      "test Acc 0.4995344506517691:\n",
      "17th- epoch: 2, train_loss = 179.89456295967102, train_acc = 0.5075687005123428\n",
      "test Acc 0.5172253258845437:\n",
      "17th- epoch: 3, train_loss = 163.96025776863098, train_acc = 0.5337680484396833\n",
      "test Acc 0.5605214152700186:\n",
      "17th- epoch: 4, train_loss = 151.54822272062302, train_acc = 0.5808104331625524\n",
      "test Acc 0.6094040968342644:\n",
      "17th- epoch: 5, train_loss = 140.3834193944931, train_acc = 0.6183046110852353\n",
      "test Acc 0.6345437616387337:\n",
      "17th- epoch: 6, train_loss = 129.92738568782806, train_acc = 0.6408942710759199\n",
      "test Acc 0.6536312849162011:\n",
      "17th- epoch: 7, train_loss = 120.12770396471024, train_acc = 0.6799021891010713\n",
      "test Acc 0.7523277467411545:\n",
      "17th- epoch: 8, train_loss = 111.02914768457413, train_acc = 0.7604797391709361\n",
      "test Acc 0.776536312849162:\n",
      "17th- epoch: 9, train_loss = 102.72553205490112, train_acc = 0.7828365160689333\n",
      "test Acc 0.7965549348230913:\n",
      "17th- epoch: 10, train_loss = 95.23301804065704, train_acc = 0.8042617605961807\n",
      "test Acc 0.8091247672253259:\n",
      "17th- epoch: 11, train_loss = 88.54553470015526, train_acc = 0.8183511877037727\n",
      "test Acc 0.8226256983240223:\n",
      "17th- epoch: 12, train_loss = 82.63193443417549, train_acc = 0.8311597578015836\n",
      "test Acc 0.8426443202979516:\n",
      "17th- epoch: 13, train_loss = 77.44239246845245, train_acc = 0.8448998602701444\n",
      "test Acc 0.8542830540037244:\n",
      "17th- epoch: 14, train_loss = 72.89324727654457, train_acc = 0.854331625523987\n",
      "test Acc 0.861266294227188:\n",
      "17th- epoch: 15, train_loss = 68.90930244326591, train_acc = 0.8615510013972986\n",
      "test Acc 0.8654562383612663:\n",
      "17th- epoch: 16, train_loss = 65.39872026443481, train_acc = 0.8658593386120168\n",
      "test Acc 0.8701117318435754:\n",
      "17th- epoch: 17, train_loss = 62.30394071340561, train_acc = 0.8697019096413601\n",
      "test Acc 0.8743016759776536:\n",
      "17th- epoch: 18, train_loss = 59.56814420223236, train_acc = 0.875873311597578\n",
      "test Acc 0.8836126629422719:\n",
      "17th- epoch: 19, train_loss = 57.14292308688164, train_acc = 0.8813460642757336\n",
      "test Acc 0.8868715083798883:\n",
      "17th- epoch: 20, train_loss = 54.98874191939831, train_acc = 0.8879832324173265\n",
      "test Acc 0.8929236499068901:\n",
      "17th- epoch: 21, train_loss = 53.06864534318447, train_acc = 0.892640894271076\n",
      "test Acc 0.8947858472998138:\n",
      "17th- epoch: 22, train_loss = 51.3519521355629, train_acc = 0.8938053097345132\n",
      "test Acc 0.8975791433891993:\n",
      "17th- epoch: 23, train_loss = 49.81367240846157, train_acc = 0.8957848160223568\n",
      "test Acc 0.9003724394785847:\n",
      "17th- epoch: 24, train_loss = 48.428347423672676, train_acc = 0.8977643223102003\n",
      "test Acc 0.9022346368715084:\n",
      "17th- epoch: 25, train_loss = 47.174486711621284, train_acc = 0.8989287377736377\n",
      "test Acc 0.904096834264432:\n",
      "17th- epoch: 26, train_loss = 46.03480423986912, train_acc = 0.9006753609687936\n",
      "test Acc 0.9050279329608939:\n",
      "17th- epoch: 27, train_loss = 44.99471962451935, train_acc = 0.902771308802981\n",
      "test Acc 0.9059590316573557:\n",
      "17th- epoch: 28, train_loss = 44.04081657528877, train_acc = 0.9041686073591058\n",
      "test Acc 0.9064245810055865:\n",
      "17th- epoch: 29, train_loss = 43.16140903532505, train_acc = 0.9053330228225431\n",
      "test Acc 0.9078212290502793:\n",
      "17th- epoch: 30, train_loss = 42.34635525941849, train_acc = 0.9069632044713554\n",
      "test Acc 0.909217877094972:\n",
      "17th- epoch: 31, train_loss = 41.58761489391327, train_acc = 0.9085933861201677\n",
      "test Acc 0.9087523277467412:\n",
      "17th- epoch: 32, train_loss = 40.879463732242584, train_acc = 0.9096413600372613\n",
      "test Acc 0.9110800744878957:\n",
      "17th- epoch: 33, train_loss = 40.21542578935623, train_acc = 0.9118537494177923\n",
      "test Acc 0.9120111731843575:\n",
      "17th- epoch: 34, train_loss = 39.59332898259163, train_acc = 0.9130181648812297\n",
      "test Acc 0.9134078212290503:\n",
      "17th- epoch: 35, train_loss = 39.00826294720173, train_acc = 0.9148812296227294\n",
      "test Acc 0.9143389199255121:\n",
      "17th- epoch: 36, train_loss = 38.45470434427261, train_acc = 0.9166278528178854\n",
      "test Acc 0.9157355679702048:\n",
      "17th- epoch: 37, train_loss = 37.93060863018036, train_acc = 0.9183744760130415\n",
      "test Acc 0.9162011173184358:\n",
      "17th- epoch: 38, train_loss = 37.4321481436491, train_acc = 0.91988821611551\n",
      "test Acc 0.9175977653631285:\n",
      "17th- epoch: 39, train_loss = 36.95611810684204, train_acc = 0.9207033069399162\n",
      "test Acc 0.9180633147113594:\n",
      "17th- epoch: 40, train_loss = 36.502739146351814, train_acc = 0.9215183977643223\n",
      "test Acc 0.9185288640595903:\n",
      "17th- epoch: 41, train_loss = 36.069239273667336, train_acc = 0.9222170470423847\n",
      "test Acc 0.9194599627560521:\n",
      "17th- epoch: 42, train_loss = 35.65315367281437, train_acc = 0.9230321378667908\n",
      "test Acc 0.9208566108007449:\n",
      "17th- epoch: 43, train_loss = 35.25370194017887, train_acc = 0.9241965533302282\n",
      "test Acc 0.9213221601489758:\n",
      "17th- epoch: 44, train_loss = 34.86879490315914, train_acc = 0.9246623195156032\n",
      "test Acc 0.9217877094972067:\n",
      "17th- epoch: 45, train_loss = 34.499301955103874, train_acc = 0.9251280857009782\n",
      "test Acc 0.9222532588454376:\n",
      "17th- epoch: 46, train_loss = 34.143582068383694, train_acc = 0.9258267349790406\n",
      "test Acc 0.9236499068901304:\n",
      "17th- epoch: 47, train_loss = 33.801241002976894, train_acc = 0.9271075919888216\n",
      "test Acc 0.9241154562383612:\n",
      "17th- epoch: 48, train_loss = 33.47043527662754, train_acc = 0.9275733581741965\n",
      "test Acc 0.9241154562383612:\n",
      "17th- epoch: 49, train_loss = 33.15053279697895, train_acc = 0.927806241266884\n",
      "test Acc 0.9250465549348231:\n",
      "17th- epoch: 50, train_loss = 32.84141547232866, train_acc = 0.9287377736376339\n",
      "test Acc 0.9250465549348231:\n",
      "17th- epoch: 51, train_loss = 32.5422068759799, train_acc = 0.9295528644620401\n",
      "test Acc 0.925512104283054:\n",
      "17th- epoch: 52, train_loss = 32.252993650734425, train_acc = 0.9297857475547275\n",
      "test Acc 0.9264432029795159:\n",
      "17th- epoch: 53, train_loss = 31.972954481840134, train_acc = 0.9302515137401025\n",
      "test Acc 0.9273743016759777:\n",
      "17th- epoch: 54, train_loss = 31.7014337554574, train_acc = 0.9308337214718212\n",
      "test Acc 0.9273743016759777:\n",
      "17th- epoch: 55, train_loss = 31.437986701726913, train_acc = 0.9314159292035398\n",
      "test Acc 0.9273743016759777:\n",
      "17th- epoch: 56, train_loss = 31.18169230222702, train_acc = 0.931765253842571\n",
      "test Acc 0.9273743016759777:\n",
      "17th- epoch: 57, train_loss = 30.932650685310364, train_acc = 0.9319981369352585\n",
      "test Acc 0.9273743016759777:\n",
      "17th- epoch: 58, train_loss = 30.689902737736702, train_acc = 0.932231020027946\n",
      "test Acc 0.9278398510242085:\n",
      "17th- epoch: 59, train_loss = 30.451756350696087, train_acc = 0.9325803446669771\n",
      "test Acc 0.9283054003724395:\n",
      "17th- epoch: 60, train_loss = 30.2215608432889, train_acc = 0.9328132277596647\n",
      "test Acc 0.9278398510242085:\n",
      "17th- epoch: 61, train_loss = 29.99674640595913, train_acc = 0.9331625523986958\n",
      "test Acc 0.9278398510242085:\n",
      "17th- epoch: 62, train_loss = 29.777151681482792, train_acc = 0.933977643223102\n",
      "test Acc 0.9278398510242085:\n",
      "17th- epoch: 63, train_loss = 29.562474690377712, train_acc = 0.9340940847694458\n",
      "test Acc 0.9278398510242085:\n",
      "17th- epoch: 64, train_loss = 29.353149689733982, train_acc = 0.9340940847694458\n",
      "test Acc 0.9278398510242085:\n",
      "17th- epoch: 65, train_loss = 29.14802100509405, train_acc = 0.9344434094084769\n",
      "test Acc 0.9278398510242085:\n",
      "17th- epoch: 66, train_loss = 28.947611823678017, train_acc = 0.9353749417792269\n",
      "test Acc 0.9278398510242085:\n",
      "17th- epoch: 67, train_loss = 28.751612402498722, train_acc = 0.9359571495109456\n",
      "test Acc 0.9278398510242085:\n",
      "17th- epoch: 68, train_loss = 28.55946035683155, train_acc = 0.9363064741499767\n",
      "test Acc 0.9283054003724395:\n",
      "17th- epoch: 69, train_loss = 28.372146107256413, train_acc = 0.9365393572426641\n",
      "test Acc 0.9283054003724395:\n",
      "17th- epoch: 70, train_loss = 28.188410609960556, train_acc = 0.9365393572426641\n",
      "test Acc 0.9283054003724395:\n",
      "17th- epoch: 71, train_loss = 28.007921278476715, train_acc = 0.9370051234280391\n",
      "test Acc 0.9283054003724395:\n",
      "17th- epoch: 72, train_loss = 27.831183172762394, train_acc = 0.9371215649743828\n",
      "test Acc 0.9287709497206704:\n",
      "17th- epoch: 73, train_loss = 27.657714672386646, train_acc = 0.9371215649743828\n",
      "test Acc 0.9287709497206704:\n",
      "17th- epoch: 74, train_loss = 27.488336957991123, train_acc = 0.9372380065207266\n",
      "test Acc 0.9287709497206704:\n",
      "17th- epoch: 75, train_loss = 27.322093211114407, train_acc = 0.9377037727061015\n",
      "test Acc 0.9287709497206704:\n",
      "17th- epoch: 76, train_loss = 27.15914834290743, train_acc = 0.9378202142524453\n",
      "test Acc 0.9292364990689013:\n",
      "17th- epoch: 77, train_loss = 26.99932238459587, train_acc = 0.937936655798789\n",
      "test Acc 0.9292364990689013:\n",
      "17th- epoch: 78, train_loss = 26.842563450336456, train_acc = 0.9380530973451328\n",
      "test Acc 0.9292364990689013:\n",
      "17th- epoch: 79, train_loss = 26.688933599740267, train_acc = 0.9382859804378202\n",
      "test Acc 0.9292364990689013:\n",
      "17th- epoch: 80, train_loss = 26.5382362306118, train_acc = 0.9387517466231952\n",
      "test Acc 0.9292364990689013:\n",
      "17th- epoch: 81, train_loss = 26.390018865466118, train_acc = 0.9388681881695389\n",
      "test Acc 0.9297020484171322:\n",
      "17th- epoch: 82, train_loss = 26.244989555329084, train_acc = 0.9393339543549138\n",
      "test Acc 0.9301675977653632:\n",
      "17th- epoch: 83, train_loss = 26.102271646261215, train_acc = 0.9395668374476013\n",
      "test Acc 0.930633147113594:\n",
      "17th- epoch: 84, train_loss = 25.9615939296782, train_acc = 0.9397997205402888\n",
      "test Acc 0.931098696461825:\n",
      "17th- epoch: 85, train_loss = 25.823663230985403, train_acc = 0.9406148113646949\n",
      "test Acc 0.931098696461825:\n",
      "17th- epoch: 86, train_loss = 25.68790788576007, train_acc = 0.9413134606427573\n",
      "test Acc 0.931098696461825:\n",
      "17th- epoch: 87, train_loss = 25.554719269275665, train_acc = 0.9417792268281323\n",
      "test Acc 0.931098696461825:\n",
      "17th- epoch: 88, train_loss = 25.423993680626154, train_acc = 0.9422449930135072\n",
      "test Acc 0.931098696461825:\n",
      "17th- epoch: 89, train_loss = 25.294635072350502, train_acc = 0.9428272007452259\n",
      "test Acc 0.9320297951582868:\n",
      "17th- epoch: 90, train_loss = 25.167953170835972, train_acc = 0.9430600838379134\n",
      "test Acc 0.9320297951582868:\n",
      "17th- epoch: 91, train_loss = 25.042001720517874, train_acc = 0.9435258500232883\n",
      "test Acc 0.9320297951582868:\n",
      "17th- epoch: 92, train_loss = 24.918050289154053, train_acc = 0.944108057755007\n",
      "test Acc 0.9329608938547486:\n",
      "17th- epoch: 93, train_loss = 24.796268936246634, train_acc = 0.9445738239403819\n",
      "test Acc 0.9329608938547486:\n",
      "17th- epoch: 94, train_loss = 24.67633245885372, train_acc = 0.9446902654867256\n",
      "test Acc 0.9329608938547486:\n",
      "17th- epoch: 95, train_loss = 24.558414310216904, train_acc = 0.9449231485794132\n",
      "test Acc 0.9329608938547486:\n",
      "17th- epoch: 96, train_loss = 24.44284775108099, train_acc = 0.9449231485794132\n",
      "test Acc 0.9329608938547486:\n",
      "17th- epoch: 97, train_loss = 24.32969942316413, train_acc = 0.9449231485794132\n",
      "test Acc 0.9334264432029795:\n",
      "17th- epoch: 98, train_loss = 24.218193471431732, train_acc = 0.9449231485794132\n",
      "test Acc 0.9334264432029795:\n",
      "17th- epoch: 99, train_loss = 24.10891130939126, train_acc = 0.9450395901257569\n",
      "test Acc 0.9338919925512105:\n",
      "17th- epoch: 100, train_loss = 24.001553118228912, train_acc = 0.9450395901257569\n",
      "test Acc 0.9348230912476723:\n",
      "17th- epoch: 101, train_loss = 23.896395225077868, train_acc = 0.945388914764788\n",
      "test Acc 0.9357541899441341:\n",
      "17th- epoch: 102, train_loss = 23.792675033211708, train_acc = 0.945388914764788\n",
      "test Acc 0.936219739292365:\n",
      "17th- epoch: 103, train_loss = 23.690773844718933, train_acc = 0.9459711224965067\n",
      "test Acc 0.936219739292365:\n",
      "17th- epoch: 104, train_loss = 23.59071621671319, train_acc = 0.9465533302282254\n",
      "test Acc 0.9366852886405959:\n",
      "17th- epoch: 105, train_loss = 23.49181304126978, train_acc = 0.9469026548672567\n",
      "test Acc 0.9366852886405959:\n",
      "17th- epoch: 106, train_loss = 23.395185235887766, train_acc = 0.9469026548672567\n",
      "test Acc 0.9371508379888268:\n",
      "17th- epoch: 107, train_loss = 23.30034601315856, train_acc = 0.9476013041453191\n",
      "test Acc 0.9371508379888268:\n",
      "17th- epoch: 108, train_loss = 23.205952394753695, train_acc = 0.9477177456916628\n",
      "test Acc 0.9376163873370578:\n",
      "17th- epoch: 109, train_loss = 23.11374866962433, train_acc = 0.9479506287843502\n",
      "test Acc 0.9376163873370578:\n",
      "17th- epoch: 110, train_loss = 23.023186463862658, train_acc = 0.9481835118770378\n",
      "test Acc 0.9376163873370578:\n",
      "17th- epoch: 111, train_loss = 22.933067232370377, train_acc = 0.9484163949697252\n",
      "test Acc 0.9376163873370578:\n",
      "17th- epoch: 112, train_loss = 22.844711776822805, train_acc = 0.9486492780624126\n",
      "test Acc 0.9376163873370578:\n",
      "17th- epoch: 113, train_loss = 22.757805358618498, train_acc = 0.9487657196087564\n",
      "test Acc 0.9385474860335196:\n",
      "17th- epoch: 114, train_loss = 22.673617098480463, train_acc = 0.9489986027014439\n",
      "test Acc 0.9385474860335196:\n",
      "17th- epoch: 115, train_loss = 22.5903241597116, train_acc = 0.9492314857941313\n",
      "test Acc 0.9385474860335196:\n",
      "17th- epoch: 116, train_loss = 22.50837904214859, train_acc = 0.9496972519795063\n",
      "test Acc 0.9385474860335196:\n",
      "17th- epoch: 117, train_loss = 22.42737990617752, train_acc = 0.94981369352585\n",
      "test Acc 0.9385474860335196:\n",
      "17th- epoch: 118, train_loss = 22.34778507053852, train_acc = 0.94981369352585\n",
      "test Acc 0.9390130353817505:\n",
      "17th- epoch: 119, train_loss = 22.268637388944626, train_acc = 0.9500465766185375\n",
      "test Acc 0.9390130353817505:\n",
      "17th- epoch: 120, train_loss = 22.1917731910944, train_acc = 0.9503959012575687\n",
      "test Acc 0.9390130353817505:\n",
      "17th- epoch: 121, train_loss = 22.11557959765196, train_acc = 0.9505123428039124\n",
      "test Acc 0.9390130353817505:\n",
      "17th- epoch: 122, train_loss = 22.04067377001047, train_acc = 0.9505123428039124\n",
      "test Acc 0.9394785847299814:\n",
      "17th- epoch: 123, train_loss = 21.96703439578414, train_acc = 0.9503959012575687\n",
      "test Acc 0.9394785847299814:\n",
      "17th- epoch: 124, train_loss = 21.894216768443584, train_acc = 0.9506287843502562\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 125, train_loss = 21.822297401726246, train_acc = 0.9508616674429436\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 126, train_loss = 21.752227868884802, train_acc = 0.9510945505356311\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 127, train_loss = 21.682715389877558, train_acc = 0.9513274336283186\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 128, train_loss = 21.613826781511307, train_acc = 0.951560316721006\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 129, train_loss = 21.54551751166582, train_acc = 0.9516767582673498\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 130, train_loss = 21.47880332171917, train_acc = 0.9517931998136935\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 131, train_loss = 21.41282030940056, train_acc = 0.952026082906381\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 132, train_loss = 21.347711965441704, train_acc = 0.952026082906381\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 133, train_loss = 21.283711157739162, train_acc = 0.952026082906381\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 134, train_loss = 21.22010874375701, train_acc = 0.9519096413600373\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 135, train_loss = 21.158026847988367, train_acc = 0.9521425244527247\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 136, train_loss = 21.096176516264677, train_acc = 0.9521425244527247\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 137, train_loss = 21.034975208342075, train_acc = 0.9522589659990685\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 138, train_loss = 20.974354561418295, train_acc = 0.9523754075454122\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 139, train_loss = 20.916125405579805, train_acc = 0.9523754075454122\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 140, train_loss = 20.857175800949335, train_acc = 0.9526082906380997\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 141, train_loss = 20.798348642885685, train_acc = 0.9529576152771309\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 142, train_loss = 20.74141512066126, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 143, train_loss = 20.683401733636856, train_acc = 0.9533069399161621\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 144, train_loss = 20.628368137404323, train_acc = 0.9535398230088495\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 145, train_loss = 20.57284383289516, train_acc = 0.9535398230088495\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 146, train_loss = 20.517983267083764, train_acc = 0.9536562645551933\n",
      "test Acc 0.9399441340782123:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 147, train_loss = 20.46274778805673, train_acc = 0.9536562645551933\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 148, train_loss = 20.409493310377, train_acc = 0.9538891476478808\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 149, train_loss = 20.355748074129224, train_acc = 0.9540055891942245\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 150, train_loss = 20.30315012484789, train_acc = 0.9540055891942245\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 151, train_loss = 20.25065621174872, train_acc = 0.9538891476478808\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 152, train_loss = 20.198437336832285, train_acc = 0.9540055891942245\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 153, train_loss = 20.146666692569852, train_acc = 0.9542384722869119\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 154, train_loss = 20.097759533673525, train_acc = 0.9542384722869119\n",
      "test Acc 0.9408752327746741:\n",
      "17th- epoch: 155, train_loss = 20.047798911109567, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "17th- epoch: 156, train_loss = 19.99715812318027, train_acc = 0.9544713553795995\n",
      "test Acc 0.9408752327746741:\n",
      "17th- epoch: 157, train_loss = 19.94984900392592, train_acc = 0.9550535631113182\n",
      "test Acc 0.9413407821229051:\n",
      "17th- epoch: 158, train_loss = 19.900964507833123, train_acc = 0.9551700046576619\n",
      "test Acc 0.9413407821229051:\n",
      "17th- epoch: 159, train_loss = 19.8532380964607, train_acc = 0.9552864462040056\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 160, train_loss = 19.805901613086462, train_acc = 0.9554028877503493\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 161, train_loss = 19.759268125519156, train_acc = 0.955519329296693\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 162, train_loss = 19.711333131417632, train_acc = 0.9557522123893806\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 163, train_loss = 19.6655628439039, train_acc = 0.9557522123893806\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 164, train_loss = 19.619992036372423, train_acc = 0.9557522123893806\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 165, train_loss = 19.57424865476787, train_acc = 0.9558686539357243\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 166, train_loss = 19.52916031330824, train_acc = 0.9558686539357243\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 167, train_loss = 19.483787026256323, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 168, train_loss = 19.440591985359788, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 169, train_loss = 19.396555418148637, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 170, train_loss = 19.35422538407147, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 171, train_loss = 19.311566112563014, train_acc = 0.9562179785747554\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 172, train_loss = 19.26915462128818, train_acc = 0.9563344201210993\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 173, train_loss = 19.226798007264733, train_acc = 0.956450861667443\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 174, train_loss = 19.186145655810833, train_acc = 0.9565673032137867\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 175, train_loss = 19.143920300528407, train_acc = 0.9566837447601304\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 176, train_loss = 19.103611996397376, train_acc = 0.9566837447601304\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 177, train_loss = 19.064206754788756, train_acc = 0.9568001863064741\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 178, train_loss = 19.024786012247205, train_acc = 0.9571495109455054\n",
      "test Acc 0.9422718808193669:\n",
      "17th- epoch: 179, train_loss = 18.985537411645055, train_acc = 0.9571495109455054\n",
      "test Acc 0.9422718808193669:\n",
      "17th- epoch: 180, train_loss = 18.945224452763796, train_acc = 0.9572659524918491\n",
      "test Acc 0.9422718808193669:\n",
      "17th- epoch: 181, train_loss = 18.906972467899323, train_acc = 0.9572659524918491\n",
      "test Acc 0.9422718808193669:\n",
      "17th- epoch: 182, train_loss = 18.869735600426793, train_acc = 0.9572659524918491\n",
      "test Acc 0.9422718808193669:\n",
      "17th- epoch: 183, train_loss = 18.831585271283984, train_acc = 0.9572659524918491\n",
      "test Acc 0.9422718808193669:\n",
      "17th- epoch: 184, train_loss = 18.793265825137496, train_acc = 0.9573823940381928\n",
      "test Acc 0.9432029795158287:\n",
      "17th- epoch: 185, train_loss = 18.756884703412652, train_acc = 0.9576152771308803\n",
      "test Acc 0.9436685288640596:\n",
      "17th- epoch: 186, train_loss = 18.720023995265365, train_acc = 0.9577317186772241\n",
      "test Acc 0.9436685288640596:\n",
      "17th- epoch: 187, train_loss = 18.68398236297071, train_acc = 0.9579646017699115\n",
      "test Acc 0.9436685288640596:\n",
      "17th- epoch: 188, train_loss = 18.648655323311687, train_acc = 0.9580810433162552\n",
      "test Acc 0.9436685288640596:\n",
      "17th- epoch: 189, train_loss = 18.61225717328489, train_acc = 0.9580810433162552\n",
      "test Acc 0.9436685288640596:\n",
      "17th- epoch: 190, train_loss = 18.576458796858788, train_acc = 0.9580810433162552\n",
      "test Acc 0.9436685288640596:\n",
      "17th- epoch: 191, train_loss = 18.540815783664584, train_acc = 0.9583139264089428\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 192, train_loss = 18.505906807258725, train_acc = 0.9584303679552865\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 193, train_loss = 18.471338680014014, train_acc = 0.9585468095016302\n",
      "test Acc 0.9445996275605214:\n",
      "17th- epoch: 194, train_loss = 18.43785671517253, train_acc = 0.9585468095016302\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 195, train_loss = 18.404114140197635, train_acc = 0.9585468095016302\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 196, train_loss = 18.369400387629867, train_acc = 0.9586632510479739\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 197, train_loss = 18.33690588362515, train_acc = 0.9586632510479739\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 198, train_loss = 18.303327364847064, train_acc = 0.9586632510479739\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 199, train_loss = 18.271382147446275, train_acc = 0.9587796925943176\n",
      "test Acc 0.9459962756052142:\n",
      "17th- epoch: 200, train_loss = 18.238406585529447, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 201, train_loss = 18.205890636891127, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 202, train_loss = 18.175530817359686, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 203, train_loss = 18.142828119918704, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 204, train_loss = 18.11050063930452, train_acc = 0.9590125756870052\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 205, train_loss = 18.078937681391835, train_acc = 0.9590125756870052\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 206, train_loss = 18.04698265902698, train_acc = 0.9590125756870052\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 207, train_loss = 18.01684251241386, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 208, train_loss = 17.985632929950953, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 209, train_loss = 17.956416660919785, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 210, train_loss = 17.927158476784825, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 211, train_loss = 17.89809067733586, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 212, train_loss = 17.867537623271346, train_acc = 0.9597112249650676\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 213, train_loss = 17.839784501120448, train_acc = 0.959944108057755\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 214, train_loss = 17.80974549986422, train_acc = 0.9600605496040987\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 215, train_loss = 17.78259208239615, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 216, train_loss = 17.75491894967854, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 217, train_loss = 17.725383419543505, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 218, train_loss = 17.699032746255398, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 219, train_loss = 17.67225175909698, train_acc = 0.96040987424313\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 220, train_loss = 17.64400540292263, train_acc = 0.96040987424313\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 221, train_loss = 17.616803595796227, train_acc = 0.96040987424313\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 222, train_loss = 17.59011010453105, train_acc = 0.96040987424313\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 223, train_loss = 17.563184255734086, train_acc = 0.9605263157894737\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 224, train_loss = 17.53659414872527, train_acc = 0.9605263157894737\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 225, train_loss = 17.512014467269182, train_acc = 0.9605263157894737\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 226, train_loss = 17.48543491959572, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 227, train_loss = 17.459657410159707, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 228, train_loss = 17.43335842899978, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 229, train_loss = 17.408518766984344, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 230, train_loss = 17.383593657054007, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 231, train_loss = 17.358856945298612, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 232, train_loss = 17.334045781753957, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 233, train_loss = 17.31055696774274, train_acc = 0.9611085235211924\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 234, train_loss = 17.28532590996474, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 235, train_loss = 17.261147147975862, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 236, train_loss = 17.23630044143647, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 237, train_loss = 17.21290681231767, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 238, train_loss = 17.18951331730932, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 239, train_loss = 17.16585674136877, train_acc = 0.961690731252911\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 240, train_loss = 17.143425310961902, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 241, train_loss = 17.118218578398228, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 242, train_loss = 17.096961493603885, train_acc = 0.9619236143455985\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 243, train_loss = 17.07404125109315, train_acc = 0.9619236143455985\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 244, train_loss = 17.05047475453466, train_acc = 0.9620400558919422\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 245, train_loss = 17.0297682126984, train_acc = 0.9620400558919422\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 246, train_loss = 17.00723974686116, train_acc = 0.962156497438286\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 247, train_loss = 16.983818881213665, train_acc = 0.962156497438286\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 248, train_loss = 16.961602092720568, train_acc = 0.962156497438286\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 249, train_loss = 16.94097611308098, train_acc = 0.962156497438286\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 250, train_loss = 16.91999393608421, train_acc = 0.9622729389846297\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 251, train_loss = 16.897593517787755, train_acc = 0.9622729389846297\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 252, train_loss = 16.876837720163167, train_acc = 0.9622729389846297\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 253, train_loss = 16.85559863317758, train_acc = 0.9622729389846297\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 254, train_loss = 16.83345539495349, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 255, train_loss = 16.812156948260963, train_acc = 0.9623893805309734\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 256, train_loss = 16.793069520033896, train_acc = 0.9625058220773172\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 257, train_loss = 16.771069114096463, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 258, train_loss = 16.751347028650343, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 259, train_loss = 16.730834550224245, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 260, train_loss = 16.710568285547197, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 261, train_loss = 16.691951596178114, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 262, train_loss = 16.67119616921991, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 263, train_loss = 16.651466409675777, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 264, train_loss = 16.631064479239285, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 265, train_loss = 16.611759121529758, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 266, train_loss = 16.593982906080782, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 267, train_loss = 16.57410127017647, train_acc = 0.9627387051700047\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 268, train_loss = 16.55462320148945, train_acc = 0.9627387051700047\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 269, train_loss = 16.535171360708773, train_acc = 0.9627387051700047\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 270, train_loss = 16.515931681729853, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 271, train_loss = 16.497674846090376, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 272, train_loss = 16.479357916861773, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 273, train_loss = 16.461448459886014, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 274, train_loss = 16.44359853770584, train_acc = 0.9629715882626921\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 275, train_loss = 16.424345477484167, train_acc = 0.9632044713553796\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 276, train_loss = 16.408143519423902, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 277, train_loss = 16.389691687189043, train_acc = 0.9635537959944108\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 278, train_loss = 16.372363875620067, train_acc = 0.9636702375407545\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 279, train_loss = 16.35555013641715, train_acc = 0.9636702375407545\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 280, train_loss = 16.33922967966646, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 281, train_loss = 16.320111833512783, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 282, train_loss = 16.303641859441996, train_acc = 0.9640195621797858\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 283, train_loss = 16.28549992199987, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 284, train_loss = 16.269206256605685, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 285, train_loss = 16.251428231596947, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 286, train_loss = 16.235472176223993, train_acc = 0.9642524452724732\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 287, train_loss = 16.219770584255457, train_acc = 0.9642524452724732\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 288, train_loss = 16.205315914936364, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 289, train_loss = 16.186598381958902, train_acc = 0.9642524452724732\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 290, train_loss = 16.1702047502622, train_acc = 0.9642524452724732\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 291, train_loss = 16.155167023651302, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 292, train_loss = 16.137696880847216, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 293, train_loss = 16.121362215839326, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 294, train_loss = 16.10529214516282, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 295, train_loss = 16.09008118789643, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 296, train_loss = 16.07556466665119, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 297, train_loss = 16.060114298015833, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 298, train_loss = 16.04503705073148, train_acc = 0.9643688868188169\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 299, train_loss = 16.029533699154854, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 300, train_loss = 16.013770777732134, train_acc = 0.9643688868188169\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 301, train_loss = 15.997651386074722, train_acc = 0.9643688868188169\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 302, train_loss = 15.982507225126028, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 303, train_loss = 15.96827079448849, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 304, train_loss = 15.952315476723015, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 305, train_loss = 15.937774073332548, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 306, train_loss = 15.924881235696375, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 307, train_loss = 15.908304933458567, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 308, train_loss = 15.89571416284889, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 309, train_loss = 15.879816129803658, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 310, train_loss = 15.867436148226261, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 311, train_loss = 15.850713062100112, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 312, train_loss = 15.837675328366458, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 313, train_loss = 15.823653976432979, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 314, train_loss = 15.809851713478565, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 315, train_loss = 15.795437723398209, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 316, train_loss = 15.782825748436153, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 317, train_loss = 15.769330456852913, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 318, train_loss = 15.755678873509169, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 319, train_loss = 15.739752887748182, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 320, train_loss = 15.728132150135934, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 321, train_loss = 15.714998901821673, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 322, train_loss = 15.701780528761446, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 323, train_loss = 15.688268903642893, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 324, train_loss = 15.675343323498964, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 325, train_loss = 15.660238827578723, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 326, train_loss = 15.648157879710197, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 327, train_loss = 15.636052590794861, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 328, train_loss = 15.622632251121104, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 329, train_loss = 15.610953751951456, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 330, train_loss = 15.597736556082964, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 331, train_loss = 15.586360062472522, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 332, train_loss = 15.57398161944002, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 333, train_loss = 15.561034843325615, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 334, train_loss = 15.549078334122896, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "17th- epoch: 335, train_loss = 15.536274635232985, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "17th- epoch: 336, train_loss = 15.5233683725819, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "17th- epoch: 337, train_loss = 15.511145442724228, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "17th- epoch: 338, train_loss = 15.49848982039839, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "17th- epoch: 339, train_loss = 15.486764314584434, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "17th- epoch: 340, train_loss = 15.474838741123676, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "17th- epoch: 341, train_loss = 15.46322126686573, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 342, train_loss = 15.450750510208309, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 343, train_loss = 15.43732687830925, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 344, train_loss = 15.427754946053028, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 345, train_loss = 15.417835188098252, train_acc = 0.965649743828598\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 346, train_loss = 15.405065513215959, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 347, train_loss = 15.393092959187925, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 348, train_loss = 15.38351968023926, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 349, train_loss = 15.3698277072981, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 350, train_loss = 15.361619736999273, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 351, train_loss = 15.34714315738529, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 352, train_loss = 15.336548533290625, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 353, train_loss = 15.325998569838703, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 354, train_loss = 15.31257163733244, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 355, train_loss = 15.30370032042265, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 356, train_loss = 15.292285758070648, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 357, train_loss = 15.280290555208921, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 358, train_loss = 15.26984691247344, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 359, train_loss = 15.262413535267115, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 360, train_loss = 15.247993055731058, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 361, train_loss = 15.238549642264843, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 362, train_loss = 15.2271787552163, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 363, train_loss = 15.217579080723226, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 364, train_loss = 15.20599665492773, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 365, train_loss = 15.198691479861736, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 366, train_loss = 15.188205915503204, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "17th- epoch: 367, train_loss = 15.176309884525836, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 368, train_loss = 15.165164834819734, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 369, train_loss = 15.155950625427067, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 370, train_loss = 15.146294381469488, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 371, train_loss = 15.136910986155272, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 372, train_loss = 15.123954978771508, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 373, train_loss = 15.115175842307508, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 374, train_loss = 15.104736842215061, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 375, train_loss = 15.095360714942217, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 376, train_loss = 15.088112093508244, train_acc = 0.9659990684676293\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 377, train_loss = 15.076628864742815, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 378, train_loss = 15.065534585155547, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 379, train_loss = 15.05682598054409, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 380, train_loss = 15.047254220582545, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 381, train_loss = 15.035711479373276, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 382, train_loss = 15.027825891040266, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 383, train_loss = 15.019628898240626, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 384, train_loss = 15.007789433933794, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 385, train_loss = 14.998071200214326, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 386, train_loss = 14.989875010214746, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 387, train_loss = 14.981060020625591, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 388, train_loss = 14.97110852971673, train_acc = 0.9659990684676293\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 389, train_loss = 14.96263608429581, train_acc = 0.9659990684676293\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 390, train_loss = 14.95260030310601, train_acc = 0.9659990684676293\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 391, train_loss = 14.943385895341635, train_acc = 0.966115510013973\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 392, train_loss = 14.934466999024153, train_acc = 0.966115510013973\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 393, train_loss = 14.927447498776019, train_acc = 0.966115510013973\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 394, train_loss = 14.916194858960807, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 395, train_loss = 14.90706105157733, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 396, train_loss = 14.899566068314016, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 397, train_loss = 14.888211406767368, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 398, train_loss = 14.883348577655852, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 399, train_loss = 14.872945132665336, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 400, train_loss = 14.863118309527636, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 401, train_loss = 14.853205933235586, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 402, train_loss = 14.845575504936278, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 403, train_loss = 14.83629849832505, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 404, train_loss = 14.832191705703735, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "17th- epoch: 405, train_loss = 14.821451786905527, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 406, train_loss = 14.810867975000292, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 407, train_loss = 14.805485013872385, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 408, train_loss = 14.797843313310295, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 409, train_loss = 14.789695838000625, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 410, train_loss = 14.77867537876591, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 411, train_loss = 14.771076310425997, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 412, train_loss = 14.76344961905852, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 413, train_loss = 14.753602508455515, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 414, train_loss = 14.747473489493132, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 415, train_loss = 14.740481365472078, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 416, train_loss = 14.732087390031666, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 417, train_loss = 14.722721680998802, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 418, train_loss = 14.71681223809719, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 419, train_loss = 14.705733574926853, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 420, train_loss = 14.697045186068863, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 421, train_loss = 14.69233767548576, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 422, train_loss = 14.682084949221462, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 423, train_loss = 14.676239404827356, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 424, train_loss = 14.667624334339052, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 425, train_loss = 14.659190809819847, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 426, train_loss = 14.655551488045603, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 427, train_loss = 14.64457810530439, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 428, train_loss = 14.638671691063792, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 429, train_loss = 14.630415198858827, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 430, train_loss = 14.62135441461578, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 431, train_loss = 14.613972845021635, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 432, train_loss = 14.608504442032427, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 433, train_loss = 14.599666194524616, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 434, train_loss = 14.593750199768692, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 435, train_loss = 14.584462776780128, train_acc = 0.9671634839310667\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 436, train_loss = 14.578915511723608, train_acc = 0.9671634839310667\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 437, train_loss = 14.569982703775167, train_acc = 0.9672799254774104\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 438, train_loss = 14.564541406929493, train_acc = 0.9671634839310667\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 439, train_loss = 14.556274890899658, train_acc = 0.9672799254774104\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 440, train_loss = 14.549805844668299, train_acc = 0.9672799254774104\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 441, train_loss = 14.541182704269886, train_acc = 0.9671634839310667\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 442, train_loss = 14.534186472650617, train_acc = 0.9672799254774104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 443, train_loss = 14.526276009622961, train_acc = 0.9672799254774104\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 444, train_loss = 14.520090525504202, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 445, train_loss = 14.5130504979752, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 446, train_loss = 14.507704718504101, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 447, train_loss = 14.499262128025293, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 448, train_loss = 14.491835169494152, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 449, train_loss = 14.485828548669815, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 450, train_loss = 14.479620661586523, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 451, train_loss = 14.472296251449734, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 452, train_loss = 14.466270692646503, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 453, train_loss = 14.459397616330534, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 454, train_loss = 14.451302512083203, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 455, train_loss = 14.444539328571409, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 456, train_loss = 14.437336365226656, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 457, train_loss = 14.432227356825024, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 458, train_loss = 14.424808913376182, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 459, train_loss = 14.420710249338299, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 460, train_loss = 14.413359948899597, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 461, train_loss = 14.403490708675236, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 462, train_loss = 14.397382332477719, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 463, train_loss = 14.392407660838217, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 464, train_loss = 14.385743513703346, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 465, train_loss = 14.378069249447435, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 466, train_loss = 14.372098991181701, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 467, train_loss = 14.36660381173715, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 468, train_loss = 14.35994220385328, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 469, train_loss = 14.35576588055119, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "17th- epoch: 470, train_loss = 14.348444119095802, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 471, train_loss = 14.340876874979585, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 472, train_loss = 14.334980772342533, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 473, train_loss = 14.32781611615792, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 474, train_loss = 14.321306223515421, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 475, train_loss = 14.314440267626196, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 476, train_loss = 14.30984814465046, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 477, train_loss = 14.30456550931558, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 478, train_loss = 14.299778754357249, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 479, train_loss = 14.291736872401088, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 480, train_loss = 14.286900246050209, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 481, train_loss = 14.279845081269741, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 482, train_loss = 14.276699172798544, train_acc = 0.9680950163018165\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 483, train_loss = 14.268542265053838, train_acc = 0.9680950163018165\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 484, train_loss = 14.26237116008997, train_acc = 0.9680950163018165\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 485, train_loss = 14.254106421023607, train_acc = 0.9680950163018165\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 486, train_loss = 14.25096483901143, train_acc = 0.9680950163018165\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 487, train_loss = 14.246131749358028, train_acc = 0.9680950163018165\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 488, train_loss = 14.236851358320564, train_acc = 0.9682114578481602\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 489, train_loss = 14.2337137311697, train_acc = 0.9682114578481602\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 490, train_loss = 14.225153777748346, train_acc = 0.9682114578481602\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 491, train_loss = 14.219445603433996, train_acc = 0.9682114578481602\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 492, train_loss = 14.216083413455635, train_acc = 0.9682114578481602\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 493, train_loss = 14.209892202168703, train_acc = 0.9682114578481602\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 494, train_loss = 14.20450334623456, train_acc = 0.9682114578481602\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 495, train_loss = 14.197486130986363, train_acc = 0.9682114578481602\n",
      "test Acc 0.952513966480447:\n",
      "17th- epoch: 496, train_loss = 14.191446874290705, train_acc = 0.9682114578481602\n",
      "test Acc 0.952513966480447:\n",
      "17th- epoch: 497, train_loss = 14.18634749064222, train_acc = 0.9682114578481602\n",
      "test Acc 0.952513966480447:\n",
      "17th- epoch: 498, train_loss = 14.180198398884386, train_acc = 0.9683278993945039\n",
      "test Acc 0.952513966480447:\n",
      "17th- epoch: 499, train_loss = 14.174495194107294, train_acc = 0.9682114578481602\n",
      "test Acc 0.952513966480447:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████▋                              | 17/30 [1:53:07<1:26:23, 398.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "18th- epoch: 0, train_loss = 273.09930539131165, train_acc = 0.4354913833255706\n",
      "test Acc 0.4972067039106145:\n",
      "18th- epoch: 1, train_loss = 212.01636838912964, train_acc = 0.500465766185375\n",
      "test Acc 0.49906890130353815:\n",
      "18th- epoch: 2, train_loss = 178.7893396615982, train_acc = 0.5071029343269678\n",
      "test Acc 0.5181564245810056:\n",
      "18th- epoch: 3, train_loss = 161.99390745162964, train_acc = 0.5362133209129017\n",
      "test Acc 0.5651769087523277:\n",
      "18th- epoch: 4, train_loss = 149.15514773130417, train_acc = 0.5850023288309268\n",
      "test Acc 0.61731843575419:\n",
      "18th- epoch: 5, train_loss = 137.60117441415787, train_acc = 0.627619934792734\n",
      "test Acc 0.6396648044692738:\n",
      "18th- epoch: 6, train_loss = 126.89208352565765, train_acc = 0.6552165812761993\n",
      "test Acc 0.7388268156424581:\n",
      "18th- epoch: 7, train_loss = 117.13193047046661, train_acc = 0.69981369352585\n",
      "test Acc 0.750465549348231:\n",
      "18th- epoch: 8, train_loss = 108.24830865859985, train_acc = 0.7659524918490918\n",
      "test Acc 0.7797951582867784:\n",
      "18th- epoch: 9, train_loss = 100.13508975505829, train_acc = 0.7911038658593386\n",
      "test Acc 0.7956238361266295:\n",
      "18th- epoch: 10, train_loss = 92.76779520511627, train_acc = 0.8089194224499301\n",
      "test Acc 0.824487895716946:\n",
      "18th- epoch: 11, train_loss = 86.16302210092545, train_acc = 0.8267349790405216\n",
      "test Acc 0.8389199255121043:\n",
      "18th- epoch: 12, train_loss = 80.32087516784668, train_acc = 0.8414066138798323\n",
      "test Acc 0.8552141527001862:\n",
      "18th- epoch: 13, train_loss = 75.2031417787075, train_acc = 0.8518863530507685\n",
      "test Acc 0.861731843575419:\n",
      "18th- epoch: 14, train_loss = 70.74513521790504, train_acc = 0.8580577550069864\n",
      "test Acc 0.8649906890130353:\n",
      "18th- epoch: 15, train_loss = 66.87132167816162, train_acc = 0.8629482999534234\n",
      "test Acc 0.8691806331471136:\n",
      "18th- epoch: 16, train_loss = 63.499012023210526, train_acc = 0.868421052631579\n",
      "test Acc 0.8770949720670391:\n",
      "18th- epoch: 17, train_loss = 60.54901313781738, train_acc = 0.875873311597578\n",
      "test Acc 0.8840782122905028:\n",
      "18th- epoch: 18, train_loss = 57.95451611280441, train_acc = 0.8814625058220773\n",
      "test Acc 0.888268156424581:\n",
      "18th- epoch: 19, train_loss = 55.6641271263361, train_acc = 0.8847228691197019\n",
      "test Acc 0.8896648044692738:\n",
      "18th- epoch: 20, train_loss = 53.63174159824848, train_acc = 0.8869352585002329\n",
      "test Acc 0.8938547486033519:\n",
      "18th- epoch: 21, train_loss = 51.81986586749554, train_acc = 0.8887983232417327\n",
      "test Acc 0.8961824953445066:\n",
      "18th- epoch: 22, train_loss = 50.1985674649477, train_acc = 0.8901956217978575\n",
      "test Acc 0.8980446927374302:\n",
      "18th- epoch: 23, train_loss = 48.746380522847176, train_acc = 0.8919422449930136\n",
      "test Acc 0.898975791433892:\n",
      "18th- epoch: 24, train_loss = 47.43612302839756, train_acc = 0.8947368421052632\n",
      "test Acc 0.904096834264432:\n",
      "18th- epoch: 25, train_loss = 46.244402691721916, train_acc = 0.9010246856078249\n",
      "test Acc 0.9050279329608939:\n",
      "18th- epoch: 26, train_loss = 45.156782165169716, train_acc = 0.9028877503493247\n",
      "test Acc 0.9059590316573557:\n",
      "18th- epoch: 27, train_loss = 44.15935927629471, train_acc = 0.9046343735444806\n",
      "test Acc 0.9082867783985102:\n",
      "18th- epoch: 28, train_loss = 43.241274267435074, train_acc = 0.9061481136469492\n",
      "test Acc 0.909683426443203:\n",
      "18th- epoch: 29, train_loss = 42.3920621573925, train_acc = 0.9073125291103866\n",
      "test Acc 0.909683426443203:\n",
      "18th- epoch: 30, train_loss = 41.603933960199356, train_acc = 0.9090591523055426\n",
      "test Acc 0.9106145251396648:\n",
      "18th- epoch: 31, train_loss = 40.86999376118183, train_acc = 0.9116208663251048\n",
      "test Acc 0.9129422718808193:\n",
      "18th- epoch: 32, train_loss = 40.18466456234455, train_acc = 0.9139496972519795\n",
      "test Acc 0.9143389199255121:\n",
      "18th- epoch: 33, train_loss = 39.54147979617119, train_acc = 0.9152305542617606\n",
      "test Acc 0.9143389199255121:\n",
      "18th- epoch: 34, train_loss = 38.93683850765228, train_acc = 0.9162785281788542\n",
      "test Acc 0.9157355679702048:\n",
      "18th- epoch: 35, train_loss = 38.366107419133186, train_acc = 0.9174429436422916\n",
      "test Acc 0.9157355679702048:\n",
      "18th- epoch: 36, train_loss = 37.824884593486786, train_acc = 0.9187238006520727\n",
      "test Acc 0.9166666666666666:\n",
      "18th- epoch: 37, train_loss = 37.31137311458588, train_acc = 0.9196553330228225\n",
      "test Acc 0.9180633147113594:\n",
      "18th- epoch: 38, train_loss = 36.82317717373371, train_acc = 0.9204704238472287\n",
      "test Acc 0.9189944134078212:\n",
      "18th- epoch: 39, train_loss = 36.359045922756195, train_acc = 0.9217512808570097\n",
      "test Acc 0.9199255121042831:\n",
      "18th- epoch: 40, train_loss = 35.91627079248428, train_acc = 0.9223334885887284\n",
      "test Acc 0.9213221601489758:\n",
      "18th- epoch: 41, train_loss = 35.49366231262684, train_acc = 0.9233814625058221\n",
      "test Acc 0.9217877094972067:\n",
      "18th- epoch: 42, train_loss = 35.08962516486645, train_acc = 0.9241965533302282\n",
      "test Acc 0.9227188081936686:\n",
      "18th- epoch: 43, train_loss = 34.70324797183275, train_acc = 0.9251280857009782\n",
      "test Acc 0.9231843575418994:\n",
      "18th- epoch: 44, train_loss = 34.33263146132231, train_acc = 0.9257102934326968\n",
      "test Acc 0.9245810055865922:\n",
      "18th- epoch: 45, train_loss = 33.97695688903332, train_acc = 0.9266418258034467\n",
      "test Acc 0.9250465549348231:\n",
      "18th- epoch: 46, train_loss = 33.63484548777342, train_acc = 0.9274569166278528\n",
      "test Acc 0.9250465549348231:\n",
      "18th- epoch: 47, train_loss = 33.30563756078482, train_acc = 0.9279226828132278\n",
      "test Acc 0.925512104283054:\n",
      "18th- epoch: 48, train_loss = 32.98801137506962, train_acc = 0.928272007452259\n",
      "test Acc 0.925512104283054:\n",
      "18th- epoch: 49, train_loss = 32.681715823709965, train_acc = 0.9289706567303214\n",
      "test Acc 0.9259776536312849:\n",
      "18th- epoch: 50, train_loss = 32.38499775528908, train_acc = 0.9295528644620401\n",
      "test Acc 0.9264432029795159:\n",
      "18th- epoch: 51, train_loss = 32.09793649613857, train_acc = 0.930018630647415\n",
      "test Acc 0.9264432029795159:\n",
      "18th- epoch: 52, train_loss = 31.82007446885109, train_acc = 0.9306008383791337\n",
      "test Acc 0.9269087523277467:\n",
      "18th- epoch: 53, train_loss = 31.550878703594208, train_acc = 0.9312994876571961\n",
      "test Acc 0.9269087523277467:\n",
      "18th- epoch: 54, train_loss = 31.289403922855854, train_acc = 0.9319981369352585\n",
      "test Acc 0.9269087523277467:\n",
      "18th- epoch: 55, train_loss = 31.036227971315384, train_acc = 0.932231020027946\n",
      "test Acc 0.9269087523277467:\n",
      "18th- epoch: 56, train_loss = 30.789479687809944, train_acc = 0.9326967862133209\n",
      "test Acc 0.9269087523277467:\n",
      "18th- epoch: 57, train_loss = 30.54958736151457, train_acc = 0.9328132277596647\n",
      "test Acc 0.9269087523277467:\n",
      "18th- epoch: 58, train_loss = 30.316158324480057, train_acc = 0.9330461108523521\n",
      "test Acc 0.9269087523277467:\n",
      "18th- epoch: 59, train_loss = 30.08689260482788, train_acc = 0.9332789939450395\n",
      "test Acc 0.9273743016759777:\n",
      "18th- epoch: 60, train_loss = 29.86429014056921, train_acc = 0.9338612016767582\n",
      "test Acc 0.9278398510242085:\n",
      "18th- epoch: 61, train_loss = 29.647550649940968, train_acc = 0.9342105263157895\n",
      "test Acc 0.9278398510242085:\n",
      "18th- epoch: 62, train_loss = 29.435956738889217, train_acc = 0.9343269678621332\n",
      "test Acc 0.9283054003724395:\n",
      "18th- epoch: 63, train_loss = 29.22945947945118, train_acc = 0.9347927340475082\n",
      "test Acc 0.9283054003724395:\n",
      "18th- epoch: 64, train_loss = 29.027623876929283, train_acc = 0.9350256171401956\n",
      "test Acc 0.9287709497206704:\n",
      "18th- epoch: 65, train_loss = 28.830904744565487, train_acc = 0.935724266418258\n",
      "test Acc 0.9287709497206704:\n",
      "18th- epoch: 66, train_loss = 28.6383204087615, train_acc = 0.9356078248719143\n",
      "test Acc 0.9287709497206704:\n",
      "18th- epoch: 67, train_loss = 28.449583023786545, train_acc = 0.9358407079646017\n",
      "test Acc 0.9297020484171322:\n",
      "18th- epoch: 68, train_loss = 28.264166072010994, train_acc = 0.936190032603633\n",
      "test Acc 0.9297020484171322:\n",
      "18th- epoch: 69, train_loss = 28.083646461367607, train_acc = 0.9363064741499767\n",
      "test Acc 0.9297020484171322:\n",
      "18th- epoch: 70, train_loss = 27.90635944902897, train_acc = 0.9370051234280391\n",
      "test Acc 0.9297020484171322:\n",
      "18th- epoch: 71, train_loss = 27.733084686100483, train_acc = 0.9372380065207266\n",
      "test Acc 0.9297020484171322:\n",
      "18th- epoch: 72, train_loss = 27.56303982436657, train_acc = 0.9374708896134141\n",
      "test Acc 0.9297020484171322:\n",
      "18th- epoch: 73, train_loss = 27.396870225667953, train_acc = 0.9374708896134141\n",
      "test Acc 0.9301675977653632:\n",
      "18th- epoch: 74, train_loss = 27.234154224395752, train_acc = 0.9380530973451328\n",
      "test Acc 0.930633147113594:\n",
      "18th- epoch: 75, train_loss = 27.07378998398781, train_acc = 0.9384024219841639\n",
      "test Acc 0.930633147113594:\n",
      "18th- epoch: 76, train_loss = 26.917774438858032, train_acc = 0.9384024219841639\n",
      "test Acc 0.930633147113594:\n",
      "18th- epoch: 77, train_loss = 26.76404160261154, train_acc = 0.9389846297158826\n",
      "test Acc 0.931098696461825:\n",
      "18th- epoch: 78, train_loss = 26.61466082930565, train_acc = 0.9394503959012576\n",
      "test Acc 0.931098696461825:\n",
      "18th- epoch: 79, train_loss = 26.467077374458313, train_acc = 0.9399161620866325\n",
      "test Acc 0.931098696461825:\n",
      "18th- epoch: 80, train_loss = 26.322598330676556, train_acc = 0.94014904517932\n",
      "test Acc 0.9315642458100558:\n",
      "18th- epoch: 81, train_loss = 26.18048280850053, train_acc = 0.9403819282720075\n",
      "test Acc 0.9320297951582868:\n",
      "18th- epoch: 82, train_loss = 26.041231129318476, train_acc = 0.9403819282720075\n",
      "test Acc 0.9320297951582868:\n",
      "18th- epoch: 83, train_loss = 25.904231194406748, train_acc = 0.9403819282720075\n",
      "test Acc 0.9320297951582868:\n",
      "18th- epoch: 84, train_loss = 25.77025332301855, train_acc = 0.9406148113646949\n",
      "test Acc 0.9324953445065177:\n",
      "18th- epoch: 85, train_loss = 25.638175398111343, train_acc = 0.9407312529110387\n",
      "test Acc 0.9329608938547486:\n",
      "18th- epoch: 86, train_loss = 25.509026907384396, train_acc = 0.9410805775500699\n",
      "test Acc 0.9334264432029795:\n",
      "18th- epoch: 87, train_loss = 25.381759449839592, train_acc = 0.941429902189101\n",
      "test Acc 0.9338919925512105:\n",
      "18th- epoch: 88, train_loss = 25.25662738457322, train_acc = 0.9415463437354448\n",
      "test Acc 0.9343575418994413:\n",
      "18th- epoch: 89, train_loss = 25.1337317712605, train_acc = 0.941895668374476\n",
      "test Acc 0.9343575418994413:\n",
      "18th- epoch: 90, train_loss = 25.01335808262229, train_acc = 0.9425943176525384\n",
      "test Acc 0.9343575418994413:\n",
      "18th- epoch: 91, train_loss = 24.895055525004864, train_acc = 0.9430600838379134\n",
      "test Acc 0.9343575418994413:\n",
      "18th- epoch: 92, train_loss = 24.778963532298803, train_acc = 0.9434094084769445\n",
      "test Acc 0.9343575418994413:\n",
      "18th- epoch: 93, train_loss = 24.664583314210176, train_acc = 0.9439916162086632\n",
      "test Acc 0.9352886405959032:\n",
      "18th- epoch: 94, train_loss = 24.552458208054304, train_acc = 0.9446902654867256\n",
      "test Acc 0.936219739292365:\n",
      "18th- epoch: 95, train_loss = 24.44189003482461, train_acc = 0.9449231485794132\n",
      "test Acc 0.936219739292365:\n",
      "18th- epoch: 96, train_loss = 24.333608254790306, train_acc = 0.9455053563111319\n",
      "test Acc 0.936219739292365:\n",
      "18th- epoch: 97, train_loss = 24.22703294456005, train_acc = 0.9456217978574756\n",
      "test Acc 0.9366852886405959:\n",
      "18th- epoch: 98, train_loss = 24.122337967157364, train_acc = 0.9460875640428504\n",
      "test Acc 0.9371508379888268:\n",
      "18th- epoch: 99, train_loss = 24.01980423927307, train_acc = 0.9460875640428504\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 100, train_loss = 23.91841983795166, train_acc = 0.9466697717745691\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 101, train_loss = 23.819249380379915, train_acc = 0.9469026548672567\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 102, train_loss = 23.721356499940157, train_acc = 0.9470190964136004\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 103, train_loss = 23.625343840569258, train_acc = 0.9472519795062878\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 104, train_loss = 23.530801605433226, train_acc = 0.9474848625989754\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 105, train_loss = 23.438122779130936, train_acc = 0.9477177456916628\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 106, train_loss = 23.3462459333241, train_acc = 0.9478341872380065\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 107, train_loss = 23.25616565346718, train_acc = 0.948067070330694\n",
      "test Acc 0.9385474860335196:\n",
      "18th- epoch: 108, train_loss = 23.167235117405653, train_acc = 0.948067070330694\n",
      "test Acc 0.9390130353817505:\n",
      "18th- epoch: 109, train_loss = 23.07986680790782, train_acc = 0.9482999534233815\n",
      "test Acc 0.9390130353817505:\n",
      "18th- epoch: 110, train_loss = 22.993335489183664, train_acc = 0.9486492780624126\n",
      "test Acc 0.9390130353817505:\n",
      "18th- epoch: 111, train_loss = 22.909024946391582, train_acc = 0.9486492780624126\n",
      "test Acc 0.9390130353817505:\n",
      "18th- epoch: 112, train_loss = 22.82512917742133, train_acc = 0.9486492780624126\n",
      "test Acc 0.9394785847299814:\n",
      "18th- epoch: 113, train_loss = 22.743509773164988, train_acc = 0.9488821611551002\n",
      "test Acc 0.9394785847299814:\n",
      "18th- epoch: 114, train_loss = 22.662883076816797, train_acc = 0.9491150442477876\n",
      "test Acc 0.9394785847299814:\n",
      "18th- epoch: 115, train_loss = 22.582967553287745, train_acc = 0.9492314857941313\n",
      "test Acc 0.9394785847299814:\n",
      "18th- epoch: 116, train_loss = 22.50458801537752, train_acc = 0.9493479273404751\n",
      "test Acc 0.9394785847299814:\n",
      "18th- epoch: 117, train_loss = 22.427486144006252, train_acc = 0.9495808104331626\n",
      "test Acc 0.9394785847299814:\n",
      "18th- epoch: 118, train_loss = 22.350853476673365, train_acc = 0.9495808104331626\n",
      "test Acc 0.9399441340782123:\n",
      "18th- epoch: 119, train_loss = 22.27573389187455, train_acc = 0.9496972519795063\n",
      "test Acc 0.9399441340782123:\n",
      "18th- epoch: 120, train_loss = 22.201808225363493, train_acc = 0.9500465766185375\n",
      "test Acc 0.9404096834264432:\n",
      "18th- epoch: 121, train_loss = 22.128637168556452, train_acc = 0.9500465766185375\n",
      "test Acc 0.9404096834264432:\n",
      "18th- epoch: 122, train_loss = 22.056836795061827, train_acc = 0.9505123428039124\n",
      "test Acc 0.9404096834264432:\n",
      "18th- epoch: 123, train_loss = 21.985460083931684, train_acc = 0.9506287843502562\n",
      "test Acc 0.9404096834264432:\n",
      "18th- epoch: 124, train_loss = 21.91582139208913, train_acc = 0.9509781089892874\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 125, train_loss = 21.84619564935565, train_acc = 0.9509781089892874\n",
      "test Acc 0.9413407821229051:\n",
      "18th- epoch: 126, train_loss = 21.778011091053486, train_acc = 0.9509781089892874\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 127, train_loss = 21.71028696745634, train_acc = 0.9509781089892874\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 128, train_loss = 21.643041506409645, train_acc = 0.9510945505356311\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 129, train_loss = 21.577751398086548, train_acc = 0.9513274336283186\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 130, train_loss = 21.51333176344633, train_acc = 0.951560316721006\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 131, train_loss = 21.44978056102991, train_acc = 0.9519096413600373\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 132, train_loss = 21.385478194803, train_acc = 0.9519096413600373\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 133, train_loss = 21.32315343990922, train_acc = 0.9519096413600373\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 134, train_loss = 21.26196524873376, train_acc = 0.9519096413600373\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 135, train_loss = 21.200702775269747, train_acc = 0.9519096413600373\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 136, train_loss = 21.140234757214785, train_acc = 0.952026082906381\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 137, train_loss = 21.08055917546153, train_acc = 0.9521425244527247\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 138, train_loss = 21.021349653601646, train_acc = 0.9522589659990685\n",
      "test Acc 0.9413407821229051:\n",
      "18th- epoch: 139, train_loss = 20.962923876941204, train_acc = 0.9523754075454122\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 140, train_loss = 20.90523000061512, train_acc = 0.9526082906380997\n",
      "test Acc 0.9413407821229051:\n",
      "18th- epoch: 141, train_loss = 20.848339922726154, train_acc = 0.9527247321844434\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 142, train_loss = 20.79227401316166, train_acc = 0.9529576152771309\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 143, train_loss = 20.736316956579685, train_acc = 0.9529576152771309\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 144, train_loss = 20.681432835757732, train_acc = 0.9533069399161621\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 145, train_loss = 20.62654097005725, train_acc = 0.9535398230088495\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 146, train_loss = 20.572859965264797, train_acc = 0.9538891476478808\n",
      "test Acc 0.9408752327746741:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 147, train_loss = 20.519380271434784, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 148, train_loss = 20.46647236123681, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 149, train_loss = 20.414038009941578, train_acc = 0.9544713553795995\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 150, train_loss = 20.36151558160782, train_acc = 0.9545877969259432\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 151, train_loss = 20.310568407177925, train_acc = 0.9547042384722869\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 152, train_loss = 20.25986885651946, train_acc = 0.9547042384722869\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 153, train_loss = 20.21012975461781, train_acc = 0.9547042384722869\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 154, train_loss = 20.15980719961226, train_acc = 0.9547042384722869\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 155, train_loss = 20.110324589535594, train_acc = 0.9547042384722869\n",
      "test Acc 0.9413407821229051:\n",
      "18th- epoch: 156, train_loss = 20.061054041609168, train_acc = 0.9547042384722869\n",
      "test Acc 0.9413407821229051:\n",
      "18th- epoch: 157, train_loss = 20.0130294021219, train_acc = 0.9548206800186306\n",
      "test Acc 0.9413407821229051:\n",
      "18th- epoch: 158, train_loss = 19.96519717015326, train_acc = 0.9550535631113182\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 159, train_loss = 19.917639875784516, train_acc = 0.9551700046576619\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 160, train_loss = 19.871189849451184, train_acc = 0.9552864462040056\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 161, train_loss = 19.824052618816495, train_acc = 0.9552864462040056\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 162, train_loss = 19.777833251282573, train_acc = 0.9554028877503493\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 163, train_loss = 19.73294128291309, train_acc = 0.955519329296693\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 164, train_loss = 19.68768960237503, train_acc = 0.9556357708430367\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 165, train_loss = 19.642584210261703, train_acc = 0.9556357708430367\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 166, train_loss = 19.598303662613034, train_acc = 0.9558686539357243\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 167, train_loss = 19.555047733709216, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 168, train_loss = 19.511832455173135, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 169, train_loss = 19.467970883473754, train_acc = 0.9562179785747554\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 170, train_loss = 19.426016317680478, train_acc = 0.9563344201210993\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 171, train_loss = 19.38389226421714, train_acc = 0.956450861667443\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 172, train_loss = 19.34207796677947, train_acc = 0.9565673032137867\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 173, train_loss = 19.300658443942666, train_acc = 0.9570330693991617\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 174, train_loss = 19.25926741026342, train_acc = 0.9572659524918491\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 175, train_loss = 19.219557559117675, train_acc = 0.9571495109455054\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 176, train_loss = 19.178398195654154, train_acc = 0.9572659524918491\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 177, train_loss = 19.139010226354003, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 178, train_loss = 19.09994042851031, train_acc = 0.9574988355845365\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 179, train_loss = 19.061224246397614, train_acc = 0.9574988355845365\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 180, train_loss = 19.02186588384211, train_acc = 0.9574988355845365\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 181, train_loss = 18.983374379575253, train_acc = 0.9574988355845365\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 182, train_loss = 18.945159686729312, train_acc = 0.9577317186772241\n",
      "test Acc 0.9427374301675978:\n",
      "18th- epoch: 183, train_loss = 18.907875096425414, train_acc = 0.9577317186772241\n",
      "test Acc 0.9427374301675978:\n",
      "18th- epoch: 184, train_loss = 18.870212031528354, train_acc = 0.9577317186772241\n",
      "test Acc 0.9427374301675978:\n",
      "18th- epoch: 185, train_loss = 18.832520006224513, train_acc = 0.9578481602235678\n",
      "test Acc 0.9427374301675978:\n",
      "18th- epoch: 186, train_loss = 18.796291906386614, train_acc = 0.9578481602235678\n",
      "test Acc 0.9432029795158287:\n",
      "18th- epoch: 187, train_loss = 18.759442577138543, train_acc = 0.9579646017699115\n",
      "test Acc 0.9436685288640596:\n",
      "18th- epoch: 188, train_loss = 18.723401840776205, train_acc = 0.9585468095016302\n",
      "test Acc 0.9436685288640596:\n",
      "18th- epoch: 189, train_loss = 18.687193917110562, train_acc = 0.9585468095016302\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 190, train_loss = 18.652393138036132, train_acc = 0.9586632510479739\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 191, train_loss = 18.617111204192042, train_acc = 0.9586632510479739\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 192, train_loss = 18.582195727154613, train_acc = 0.9586632510479739\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 193, train_loss = 18.54776999913156, train_acc = 0.9587796925943176\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 194, train_loss = 18.51370227895677, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 195, train_loss = 18.479500031098723, train_acc = 0.9587796925943176\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 196, train_loss = 18.445957481861115, train_acc = 0.9587796925943176\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 197, train_loss = 18.413414338603616, train_acc = 0.9587796925943176\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 198, train_loss = 18.380369778722525, train_acc = 0.9587796925943176\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 199, train_loss = 18.345623122528195, train_acc = 0.9587796925943176\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 200, train_loss = 18.31307336129248, train_acc = 0.9588961341406614\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 201, train_loss = 18.281056186184287, train_acc = 0.9588961341406614\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 202, train_loss = 18.249019142240286, train_acc = 0.9588961341406614\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 203, train_loss = 18.217689534649253, train_acc = 0.9588961341406614\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 204, train_loss = 18.18632377497852, train_acc = 0.9590125756870052\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 205, train_loss = 18.154382018372416, train_acc = 0.9590125756870052\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 206, train_loss = 18.124389259144664, train_acc = 0.9590125756870052\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 207, train_loss = 18.093675542622805, train_acc = 0.9591290172333489\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 208, train_loss = 18.06374417617917, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 209, train_loss = 18.03301488980651, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 210, train_loss = 18.003627387806773, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 211, train_loss = 17.974852494895458, train_acc = 0.9593619003260363\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 212, train_loss = 17.945199443027377, train_acc = 0.95947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 213, train_loss = 17.916081411764026, train_acc = 0.9595947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 214, train_loss = 17.887091847136617, train_acc = 0.9595947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 215, train_loss = 17.859112894162536, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 216, train_loss = 17.83120334148407, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 217, train_loss = 17.80308086425066, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 218, train_loss = 17.775278002023697, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 219, train_loss = 17.747129483148456, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 220, train_loss = 17.720119807869196, train_acc = 0.9598276665114113\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 221, train_loss = 17.692725656554103, train_acc = 0.959944108057755\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 222, train_loss = 17.66594293899834, train_acc = 0.959944108057755\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 223, train_loss = 17.6401123739779, train_acc = 0.959944108057755\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 224, train_loss = 17.613355634734035, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 225, train_loss = 17.58704778365791, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 226, train_loss = 17.561390792950988, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 227, train_loss = 17.535034084692597, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 228, train_loss = 17.50976457260549, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 229, train_loss = 17.4840935356915, train_acc = 0.96040987424313\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 230, train_loss = 17.45915599912405, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 231, train_loss = 17.43405283987522, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 232, train_loss = 17.409174857661128, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 233, train_loss = 17.38423884101212, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 234, train_loss = 17.359971156343818, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 235, train_loss = 17.335581118240952, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 236, train_loss = 17.312660394236445, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 237, train_loss = 17.287960216403008, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 238, train_loss = 17.26489699445665, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 239, train_loss = 17.241350328549743, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 240, train_loss = 17.219493402168155, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 241, train_loss = 17.19542259722948, train_acc = 0.9611085235211924\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 242, train_loss = 17.172809898853302, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 243, train_loss = 17.150724796578288, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 244, train_loss = 17.12762882001698, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 245, train_loss = 17.104954374954104, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 246, train_loss = 17.083711536601186, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 247, train_loss = 17.061350850388408, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 248, train_loss = 17.039233600720763, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 249, train_loss = 17.01876127719879, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 250, train_loss = 16.99679652042687, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 251, train_loss = 16.97561426460743, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 252, train_loss = 16.95549786929041, train_acc = 0.9615742897065673\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 253, train_loss = 16.934093474410474, train_acc = 0.961690731252911\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 254, train_loss = 16.913478194735944, train_acc = 0.9618071727992548\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 255, train_loss = 16.893172316253185, train_acc = 0.9618071727992548\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 256, train_loss = 16.87224403768778, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 257, train_loss = 16.852243321947753, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 258, train_loss = 16.83208974916488, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 259, train_loss = 16.81284461915493, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 260, train_loss = 16.79282098636031, train_acc = 0.9625058220773172\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 261, train_loss = 16.773281831294298, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 262, train_loss = 16.752750453539193, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 263, train_loss = 16.73447770625353, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 264, train_loss = 16.714581069536507, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 265, train_loss = 16.696131233125925, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 266, train_loss = 16.67700703535229, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 267, train_loss = 16.657607190310955, train_acc = 0.9628551467163484\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 268, train_loss = 16.639238097704947, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 269, train_loss = 16.621102408505976, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 270, train_loss = 16.602804395370185, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 271, train_loss = 16.584373008459806, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 272, train_loss = 16.566315326839685, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 273, train_loss = 16.54881487507373, train_acc = 0.9634373544480671\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 274, train_loss = 16.530640672892332, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 275, train_loss = 16.513113246299326, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 276, train_loss = 16.494820207357407, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 277, train_loss = 16.476836011745036, train_acc = 0.9634373544480671\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 278, train_loss = 16.460032747127116, train_acc = 0.9634373544480671\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 279, train_loss = 16.442505713552237, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 280, train_loss = 16.425919226370752, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 281, train_loss = 16.408551644533873, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 282, train_loss = 16.39279816299677, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 283, train_loss = 16.374167847447097, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 284, train_loss = 16.35826249513775, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 285, train_loss = 16.341308034025133, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 286, train_loss = 16.325884950347245, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 287, train_loss = 16.309805866330862, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 288, train_loss = 16.293587180785835, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 289, train_loss = 16.278175197541714, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 290, train_loss = 16.260681618005037, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 291, train_loss = 16.244672884233296, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 292, train_loss = 16.23017641622573, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 293, train_loss = 16.21298399195075, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 294, train_loss = 16.19908561836928, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 295, train_loss = 16.18253791052848, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 296, train_loss = 16.167358815670013, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 297, train_loss = 16.153125210665166, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 298, train_loss = 16.13779650721699, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 299, train_loss = 16.12191287521273, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 300, train_loss = 16.107472811825573, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 301, train_loss = 16.093021526932716, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 302, train_loss = 16.077677215449512, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 303, train_loss = 16.062702973373234, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 304, train_loss = 16.049319715239108, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 305, train_loss = 16.0353173436597, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 306, train_loss = 16.019549540244043, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 307, train_loss = 16.00581877771765, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 308, train_loss = 15.991199724376202, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 309, train_loss = 15.977229452691972, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 310, train_loss = 15.96378829702735, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 311, train_loss = 15.94976119324565, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 312, train_loss = 15.93598550464958, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 313, train_loss = 15.923583029769361, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 314, train_loss = 15.909168110229075, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 315, train_loss = 15.896103045903146, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 316, train_loss = 15.882790825329721, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 317, train_loss = 15.86836779396981, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 318, train_loss = 15.855119065381587, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 319, train_loss = 15.84155302029103, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 320, train_loss = 15.827250729314983, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 321, train_loss = 15.814667717553675, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 322, train_loss = 15.8016622280702, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 323, train_loss = 15.788235363550484, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 324, train_loss = 15.77619431167841, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 325, train_loss = 15.76364317536354, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 326, train_loss = 15.75100178271532, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 327, train_loss = 15.738092757761478, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 328, train_loss = 15.72501943167299, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 329, train_loss = 15.712262965738773, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 330, train_loss = 15.70069257169962, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 331, train_loss = 15.688116159290075, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 332, train_loss = 15.6760144084692, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 333, train_loss = 15.66350329015404, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 334, train_loss = 15.650613130070269, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 335, train_loss = 15.639705554582179, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 336, train_loss = 15.627691398374736, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 337, train_loss = 15.615937137044966, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 338, train_loss = 15.603920447640121, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 339, train_loss = 15.59122407156974, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 340, train_loss = 15.579950581304729, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 341, train_loss = 15.567893542349339, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 342, train_loss = 15.557238868437707, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 343, train_loss = 15.54654351528734, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 344, train_loss = 15.533134583383799, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 345, train_loss = 15.522025699727237, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 346, train_loss = 15.511599316261709, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 347, train_loss = 15.499777524732053, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 348, train_loss = 15.488366413861513, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 349, train_loss = 15.478082888759673, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 350, train_loss = 15.466339730657637, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 351, train_loss = 15.455550939776003, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 352, train_loss = 15.44394716899842, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 353, train_loss = 15.433101194910705, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 354, train_loss = 15.42204836755991, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 355, train_loss = 15.411786615848541, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 356, train_loss = 15.402478829957545, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 357, train_loss = 15.389610615558922, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 358, train_loss = 15.38019738253206, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 359, train_loss = 15.369948045350611, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 360, train_loss = 15.358490976504982, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 361, train_loss = 15.348237375728786, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 362, train_loss = 15.338425918482244, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 363, train_loss = 15.328599560074508, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 364, train_loss = 15.318172615021467, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 365, train_loss = 15.307703978382051, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 366, train_loss = 15.29728673119098, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 367, train_loss = 15.287900838069618, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 368, train_loss = 15.277213834226131, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 369, train_loss = 15.26772137451917, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 370, train_loss = 15.25753690302372, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 371, train_loss = 15.247750226408243, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 372, train_loss = 15.23815196659416, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 373, train_loss = 15.227059040218592, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 374, train_loss = 15.218049715273082, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 375, train_loss = 15.209275397472084, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 376, train_loss = 15.197764775715768, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 377, train_loss = 15.19056195858866, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 378, train_loss = 15.179503531195223, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 379, train_loss = 15.170494331978261, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 380, train_loss = 15.159637183882296, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 381, train_loss = 15.15248863492161, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 382, train_loss = 15.14125915337354, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 383, train_loss = 15.132235904224217, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 384, train_loss = 15.123070831410587, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 385, train_loss = 15.113683581352234, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 386, train_loss = 15.105746354907751, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 387, train_loss = 15.094525083899498, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 388, train_loss = 15.087275969795883, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 389, train_loss = 15.076864819973707, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 390, train_loss = 15.067776354961097, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 391, train_loss = 15.059898155741394, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 392, train_loss = 15.050432126969099, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 393, train_loss = 15.042810692451894, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 394, train_loss = 15.03375134151429, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 395, train_loss = 15.024519530124962, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 396, train_loss = 15.01622683275491, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 397, train_loss = 15.007568220607936, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 398, train_loss = 14.99870519246906, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 399, train_loss = 14.989529888145626, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 400, train_loss = 14.982797958888113, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 401, train_loss = 14.972275398671627, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 402, train_loss = 14.965289474464953, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 403, train_loss = 14.955334988422692, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 404, train_loss = 14.947957906872034, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 405, train_loss = 14.940039649605751, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 406, train_loss = 14.931809287518263, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 407, train_loss = 14.92450022045523, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 408, train_loss = 14.915279756300151, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 409, train_loss = 14.906276266090572, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 410, train_loss = 14.899171276949346, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 411, train_loss = 14.889897580258548, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 412, train_loss = 14.882954735308886, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 413, train_loss = 14.87470140773803, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 414, train_loss = 14.867249076254666, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 415, train_loss = 14.858648910187185, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 416, train_loss = 14.850785353221, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 417, train_loss = 14.843286073766649, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 418, train_loss = 14.835495722480118, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 419, train_loss = 14.826488754712045, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 420, train_loss = 14.820798769593239, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 421, train_loss = 14.811384466476738, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "18th- epoch: 422, train_loss = 14.80537376087159, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 423, train_loss = 14.796375032514334, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 424, train_loss = 14.78972899261862, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 425, train_loss = 14.78049382288009, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 426, train_loss = 14.774244330823421, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 427, train_loss = 14.76647514756769, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "18th- epoch: 428, train_loss = 14.760165221057832, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "18th- epoch: 429, train_loss = 14.750481870956719, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 430, train_loss = 14.744517643935978, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "18th- epoch: 431, train_loss = 14.736655846238136, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "18th- epoch: 432, train_loss = 14.730276654474437, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "18th- epoch: 433, train_loss = 14.722666806541383, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "18th- epoch: 434, train_loss = 14.71585041563958, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "18th- epoch: 435, train_loss = 14.70729126688093, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 436, train_loss = 14.701751078478992, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 437, train_loss = 14.693137899041176, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 438, train_loss = 14.68535789474845, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 439, train_loss = 14.680139493197203, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 440, train_loss = 14.671344242990017, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 441, train_loss = 14.663993004709482, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 442, train_loss = 14.657440367154777, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 443, train_loss = 14.65092361997813, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 444, train_loss = 14.644681706093252, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 445, train_loss = 14.637875714339316, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 446, train_loss = 14.630289084278047, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 447, train_loss = 14.62282236944884, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 448, train_loss = 14.61661262717098, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 449, train_loss = 14.61030990164727, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 450, train_loss = 14.603967023082078, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 451, train_loss = 14.597058910876513, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 452, train_loss = 14.589118137024343, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 453, train_loss = 14.582453324459493, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 454, train_loss = 14.57656526286155, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 455, train_loss = 14.56971075385809, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 456, train_loss = 14.564828372560441, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 457, train_loss = 14.55727521609515, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 458, train_loss = 14.551232400350273, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 459, train_loss = 14.543734858743846, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 460, train_loss = 14.538283268921077, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 461, train_loss = 14.531393836252391, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 462, train_loss = 14.524539873935282, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 463, train_loss = 14.518583092838526, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 464, train_loss = 14.513733469881117, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 465, train_loss = 14.506897497922182, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 466, train_loss = 14.500194106251001, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 467, train_loss = 14.494534195400774, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 468, train_loss = 14.488605405203998, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 469, train_loss = 14.482330651488155, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 470, train_loss = 14.474555356893688, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 471, train_loss = 14.468487285077572, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 472, train_loss = 14.46331893792376, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 473, train_loss = 14.456554448697716, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 474, train_loss = 14.449447379913181, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 475, train_loss = 14.443781224545091, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 476, train_loss = 14.437957295682281, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 477, train_loss = 14.433222090359777, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 478, train_loss = 14.427756098564714, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 479, train_loss = 14.421189223881811, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 480, train_loss = 14.414947939570993, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 481, train_loss = 14.409366225358099, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 482, train_loss = 14.403883395250887, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 483, train_loss = 14.39657428720966, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 484, train_loss = 14.391899807844311, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 485, train_loss = 14.384633051697165, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 486, train_loss = 14.379486271645874, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 487, train_loss = 14.374919476453215, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 488, train_loss = 14.36836459999904, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 489, train_loss = 14.362945178057998, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 490, train_loss = 14.35892334068194, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 491, train_loss = 14.351873257663101, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 492, train_loss = 14.345344869885594, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 493, train_loss = 14.341601478401572, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 494, train_loss = 14.33426247537136, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 495, train_loss = 14.328604930546135, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 496, train_loss = 14.324396184179932, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 497, train_loss = 14.318258474115282, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 498, train_loss = 14.31181925162673, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "18th- epoch: 499, train_loss = 14.307851730380207, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████                            | 18/30 [1:59:45<1:19:41, 398.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "19th- epoch: 0, train_loss = 274.0733691453934, train_acc = 0.4649510945505356\n",
      "test Acc 0.49441340782122906:\n",
      "19th- epoch: 1, train_loss = 216.9369034767151, train_acc = 0.4983698183511877\n",
      "test Acc 0.4995344506517691:\n",
      "19th- epoch: 2, train_loss = 182.46425247192383, train_acc = 0.5067536096879367\n",
      "test Acc 0.5172253258845437:\n",
      "19th- epoch: 3, train_loss = 165.26662123203278, train_acc = 0.5342338146250583\n",
      "test Acc 0.5623836126629422:\n",
      "19th- epoch: 4, train_loss = 152.5559115409851, train_acc = 0.577899394503959\n",
      "test Acc 0.6052141527001862:\n",
      "19th- epoch: 5, train_loss = 141.4829233288765, train_acc = 0.6086399627387051\n",
      "test Acc 0.6261638733705773:\n",
      "19th- epoch: 6, train_loss = 131.30609941482544, train_acc = 0.6390312063344201\n",
      "test Acc 0.6652700186219739:\n",
      "19th- epoch: 7, train_loss = 121.97045123577118, train_acc = 0.6743129948765719\n",
      "test Acc 0.6783054003724395:\n",
      "19th- epoch: 8, train_loss = 113.3858762383461, train_acc = 0.7169306008383791\n",
      "test Acc 0.7802607076350093:\n",
      "19th- epoch: 9, train_loss = 105.41123938560486, train_acc = 0.7867955286446204\n",
      "test Acc 0.8002793296089385:\n",
      "19th- epoch: 10, train_loss = 97.9764695763588, train_acc = 0.8106660456450862\n",
      "test Acc 0.8133147113594041:\n",
      "19th- epoch: 11, train_loss = 91.11730232834816, train_acc = 0.8178854215183977\n",
      "test Acc 0.8254189944134078:\n",
      "19th- epoch: 12, train_loss = 84.9208742082119, train_acc = 0.8255705635770842\n",
      "test Acc 0.8370577281191807:\n",
      "19th- epoch: 13, train_loss = 79.41028389334679, train_acc = 0.8365160689333955\n",
      "test Acc 0.851024208566108:\n",
      "19th- epoch: 14, train_loss = 74.53336599469185, train_acc = 0.847694457382394\n",
      "test Acc 0.8566108007448789:\n",
      "19th- epoch: 15, train_loss = 70.22225788235664, train_acc = 0.856078248719143\n",
      "test Acc 0.8621973929236499:\n",
      "19th- epoch: 16, train_loss = 66.42321586608887, train_acc = 0.8643455985095482\n",
      "test Acc 0.8701117318435754:\n",
      "19th- epoch: 17, train_loss = 63.085332214832306, train_acc = 0.8701676758267349\n",
      "test Acc 0.8743016759776536:\n",
      "19th- epoch: 18, train_loss = 60.13560777902603, train_acc = 0.8768048439683279\n",
      "test Acc 0.8812849162011173:\n",
      "19th- epoch: 19, train_loss = 57.53411215543747, train_acc = 0.8799487657196088\n",
      "test Acc 0.8864059590316573:\n",
      "19th- epoch: 20, train_loss = 55.23732157051563, train_acc = 0.8828598043782021\n",
      "test Acc 0.8896648044692738:\n",
      "19th- epoch: 21, train_loss = 53.20372433960438, train_acc = 0.8870517000465766\n",
      "test Acc 0.8929236499068901:\n",
      "19th- epoch: 22, train_loss = 51.401647463440895, train_acc = 0.8905449464368886\n",
      "test Acc 0.8952513966480447:\n",
      "19th- epoch: 23, train_loss = 49.79630133509636, train_acc = 0.8919422449930136\n",
      "test Acc 0.8966480446927374:\n",
      "19th- epoch: 24, train_loss = 48.361921563744545, train_acc = 0.8945039590125757\n",
      "test Acc 0.9003724394785847:\n",
      "19th- epoch: 25, train_loss = 47.07266317307949, train_acc = 0.897880763856544\n",
      "test Acc 0.9017690875232774:\n",
      "19th- epoch: 26, train_loss = 45.90851017832756, train_acc = 0.8989287377736377\n",
      "test Acc 0.904096834264432:\n",
      "19th- epoch: 27, train_loss = 44.85209068655968, train_acc = 0.9011411271541686\n",
      "test Acc 0.9064245810055865:\n",
      "19th- epoch: 28, train_loss = 43.88821516931057, train_acc = 0.9035863996273871\n",
      "test Acc 0.9078212290502793:\n",
      "19th- epoch: 29, train_loss = 43.003283858299255, train_acc = 0.9048672566371682\n",
      "test Acc 0.9078212290502793:\n",
      "19th- epoch: 30, train_loss = 42.18727323412895, train_acc = 0.9067303213786679\n",
      "test Acc 0.9082867783985102:\n",
      "19th- epoch: 31, train_loss = 41.43393862247467, train_acc = 0.9082440614811365\n",
      "test Acc 0.909683426443203:\n",
      "19th- epoch: 32, train_loss = 40.73542329668999, train_acc = 0.9097578015836051\n",
      "test Acc 0.910148975791434:\n",
      "19th- epoch: 33, train_loss = 40.08260016143322, train_acc = 0.9112715416860736\n",
      "test Acc 0.910148975791434:\n",
      "19th- epoch: 34, train_loss = 39.470793917775154, train_acc = 0.9122030740568234\n",
      "test Acc 0.9106145251396648:\n",
      "19th- epoch: 35, train_loss = 38.89417614042759, train_acc = 0.9132510479739171\n",
      "test Acc 0.9115456238361266:\n",
      "19th- epoch: 36, train_loss = 38.348939046263695, train_acc = 0.9142990218910108\n",
      "test Acc 0.9120111731843575:\n",
      "19th- epoch: 37, train_loss = 37.832808777689934, train_acc = 0.9155798789007918\n",
      "test Acc 0.9129422718808193:\n",
      "19th- epoch: 38, train_loss = 37.34285859763622, train_acc = 0.9162785281788542\n",
      "test Acc 0.9152700186219739:\n",
      "19th- epoch: 39, train_loss = 36.87590213119984, train_acc = 0.9180251513740102\n",
      "test Acc 0.9152700186219739:\n",
      "19th- epoch: 40, train_loss = 36.43060144782066, train_acc = 0.9195388914764788\n",
      "test Acc 0.9166666666666666:\n",
      "19th- epoch: 41, train_loss = 36.00456927716732, train_acc = 0.9212855146716349\n",
      "test Acc 0.9171322160148976:\n",
      "19th- epoch: 42, train_loss = 35.59672297537327, train_acc = 0.9223334885887284\n",
      "test Acc 0.9171322160148976:\n",
      "19th- epoch: 43, train_loss = 35.205518178641796, train_acc = 0.9236143455985095\n",
      "test Acc 0.9185288640595903:\n",
      "19th- epoch: 44, train_loss = 34.82952167093754, train_acc = 0.9243129948765719\n",
      "test Acc 0.9185288640595903:\n",
      "19th- epoch: 45, train_loss = 34.466686971485615, train_acc = 0.9251280857009782\n",
      "test Acc 0.9194599627560521:\n",
      "19th- epoch: 46, train_loss = 34.117182061076164, train_acc = 0.9253609687936656\n",
      "test Acc 0.9203910614525139:\n",
      "19th- epoch: 47, train_loss = 33.779694713652134, train_acc = 0.9257102934326968\n",
      "test Acc 0.9208566108007449:\n",
      "19th- epoch: 48, train_loss = 33.45388965308666, train_acc = 0.9262925011644154\n",
      "test Acc 0.9213221601489758:\n",
      "19th- epoch: 49, train_loss = 33.13835671544075, train_acc = 0.9269911504424779\n",
      "test Acc 0.9227188081936686:\n",
      "19th- epoch: 50, train_loss = 32.833218313753605, train_acc = 0.9273404750815091\n",
      "test Acc 0.9231843575418994:\n",
      "19th- epoch: 51, train_loss = 32.53697603195906, train_acc = 0.9276897997205403\n",
      "test Acc 0.9231843575418994:\n",
      "19th- epoch: 52, train_loss = 32.249910198152065, train_acc = 0.9279226828132278\n",
      "test Acc 0.9241154562383612:\n",
      "19th- epoch: 53, train_loss = 31.9711981266737, train_acc = 0.9288542151839776\n",
      "test Acc 0.9241154562383612:\n",
      "19th- epoch: 54, train_loss = 31.700700595974922, train_acc = 0.9296693060083838\n",
      "test Acc 0.9245810055865922:\n",
      "19th- epoch: 55, train_loss = 31.437286622822285, train_acc = 0.9301350721937587\n",
      "test Acc 0.925512104283054:\n",
      "19th- epoch: 56, train_loss = 31.181026600301266, train_acc = 0.9303679552864462\n",
      "test Acc 0.925512104283054:\n",
      "19th- epoch: 57, train_loss = 30.931869961321354, train_acc = 0.9309501630181649\n",
      "test Acc 0.925512104283054:\n",
      "19th- epoch: 58, train_loss = 30.68898392468691, train_acc = 0.931765253842571\n",
      "test Acc 0.9269087523277467:\n",
      "19th- epoch: 59, train_loss = 30.452487409114838, train_acc = 0.9324639031206334\n",
      "test Acc 0.9273743016759777:\n",
      "19th- epoch: 60, train_loss = 30.221728213131428, train_acc = 0.9329296693060084\n",
      "test Acc 0.9273743016759777:\n",
      "19th- epoch: 61, train_loss = 29.99647019803524, train_acc = 0.9337447601304145\n",
      "test Acc 0.9278398510242085:\n",
      "19th- epoch: 62, train_loss = 29.77654992043972, train_acc = 0.9338612016767582\n",
      "test Acc 0.9283054003724395:\n",
      "19th- epoch: 63, train_loss = 29.560842499136925, train_acc = 0.9342105263157895\n",
      "test Acc 0.9283054003724395:\n",
      "19th- epoch: 64, train_loss = 29.34920983761549, train_acc = 0.9345598509548206\n",
      "test Acc 0.9283054003724395:\n",
      "19th- epoch: 65, train_loss = 29.142002291977406, train_acc = 0.9350256171401956\n",
      "test Acc 0.9283054003724395:\n",
      "19th- epoch: 66, train_loss = 28.93909875303507, train_acc = 0.9351420586865393\n",
      "test Acc 0.9283054003724395:\n",
      "19th- epoch: 67, train_loss = 28.740492068231106, train_acc = 0.935724266418258\n",
      "test Acc 0.9283054003724395:\n",
      "19th- epoch: 68, train_loss = 28.546354599297047, train_acc = 0.9360735910572893\n",
      "test Acc 0.9283054003724395:\n",
      "19th- epoch: 69, train_loss = 28.357021123170853, train_acc = 0.9363064741499767\n",
      "test Acc 0.9283054003724395:\n",
      "19th- epoch: 70, train_loss = 28.171746529638767, train_acc = 0.9365393572426641\n",
      "test Acc 0.9283054003724395:\n",
      "19th- epoch: 71, train_loss = 27.990213863551617, train_acc = 0.9373544480670704\n",
      "test Acc 0.9287709497206704:\n",
      "19th- epoch: 72, train_loss = 27.81273627281189, train_acc = 0.9372380065207266\n",
      "test Acc 0.9287709497206704:\n",
      "19th- epoch: 73, train_loss = 27.639390788972378, train_acc = 0.9377037727061015\n",
      "test Acc 0.9287709497206704:\n",
      "19th- epoch: 74, train_loss = 27.469178400933743, train_acc = 0.9380530973451328\n",
      "test Acc 0.9287709497206704:\n",
      "19th- epoch: 75, train_loss = 27.30297715961933, train_acc = 0.9381695388914765\n",
      "test Acc 0.9287709497206704:\n",
      "19th- epoch: 76, train_loss = 27.13972069323063, train_acc = 0.9385188635305077\n",
      "test Acc 0.9292364990689013:\n",
      "19th- epoch: 77, train_loss = 26.98071314394474, train_acc = 0.9387517466231952\n",
      "test Acc 0.9297020484171322:\n",
      "19th- epoch: 78, train_loss = 26.823861591517925, train_acc = 0.9387517466231952\n",
      "test Acc 0.9297020484171322:\n",
      "19th- epoch: 79, train_loss = 26.670558467507362, train_acc = 0.9389846297158826\n",
      "test Acc 0.9301675977653632:\n",
      "19th- epoch: 80, train_loss = 26.52031060308218, train_acc = 0.9393339543549138\n",
      "test Acc 0.9301675977653632:\n",
      "19th- epoch: 81, train_loss = 26.372981008142233, train_acc = 0.9399161620866325\n",
      "test Acc 0.930633147113594:\n",
      "19th- epoch: 82, train_loss = 26.227991677820683, train_acc = 0.9404983698183512\n",
      "test Acc 0.930633147113594:\n",
      "19th- epoch: 83, train_loss = 26.086715552955866, train_acc = 0.9409641360037261\n",
      "test Acc 0.930633147113594:\n",
      "19th- epoch: 84, train_loss = 25.947816863656044, train_acc = 0.9411970190964136\n",
      "test Acc 0.930633147113594:\n",
      "19th- epoch: 85, train_loss = 25.8111654445529, train_acc = 0.9416627852817886\n",
      "test Acc 0.930633147113594:\n",
      "19th- epoch: 86, train_loss = 25.677088376134634, train_acc = 0.9422449930135072\n",
      "test Acc 0.930633147113594:\n",
      "19th- epoch: 87, train_loss = 25.545499611645937, train_acc = 0.9427107591988821\n",
      "test Acc 0.931098696461825:\n",
      "19th- epoch: 88, train_loss = 25.41672221943736, train_acc = 0.9429436422915697\n",
      "test Acc 0.931098696461825:\n",
      "19th- epoch: 89, train_loss = 25.29002509638667, train_acc = 0.9430600838379134\n",
      "test Acc 0.931098696461825:\n",
      "19th- epoch: 90, train_loss = 25.16569161787629, train_acc = 0.9431765253842571\n",
      "test Acc 0.9315642458100558:\n",
      "19th- epoch: 91, train_loss = 25.044021900743246, train_acc = 0.9431765253842571\n",
      "test Acc 0.9315642458100558:\n",
      "19th- epoch: 92, train_loss = 24.922894593328238, train_acc = 0.9434094084769445\n",
      "test Acc 0.9320297951582868:\n",
      "19th- epoch: 93, train_loss = 24.805611070245504, train_acc = 0.9435258500232883\n",
      "test Acc 0.9334264432029795:\n",
      "19th- epoch: 94, train_loss = 24.68992257118225, train_acc = 0.9437587331159758\n",
      "test Acc 0.9334264432029795:\n",
      "19th- epoch: 95, train_loss = 24.576975014060736, train_acc = 0.9448067070330693\n",
      "test Acc 0.9334264432029795:\n",
      "19th- epoch: 96, train_loss = 24.46507827192545, train_acc = 0.9448067070330693\n",
      "test Acc 0.9334264432029795:\n",
      "19th- epoch: 97, train_loss = 24.355218321084976, train_acc = 0.9450395901257569\n",
      "test Acc 0.9343575418994413:\n",
      "19th- epoch: 98, train_loss = 24.247108452022076, train_acc = 0.945388914764788\n",
      "test Acc 0.9343575418994413:\n",
      "19th- epoch: 99, train_loss = 24.14100317656994, train_acc = 0.945854680950163\n",
      "test Acc 0.9348230912476723:\n",
      "19th- epoch: 100, train_loss = 24.036755360662937, train_acc = 0.9462040055891943\n",
      "test Acc 0.9357541899441341:\n",
      "19th- epoch: 101, train_loss = 23.93418163061142, train_acc = 0.9465533302282254\n",
      "test Acc 0.9357541899441341:\n",
      "19th- epoch: 102, train_loss = 23.832782343029976, train_acc = 0.9465533302282254\n",
      "test Acc 0.9357541899441341:\n",
      "19th- epoch: 103, train_loss = 23.733537331223488, train_acc = 0.9466697717745691\n",
      "test Acc 0.936219739292365:\n",
      "19th- epoch: 104, train_loss = 23.636079385876656, train_acc = 0.9469026548672567\n",
      "test Acc 0.936219739292365:\n",
      "19th- epoch: 105, train_loss = 23.539652179926634, train_acc = 0.9470190964136004\n",
      "test Acc 0.936219739292365:\n",
      "19th- epoch: 106, train_loss = 23.444919150322676, train_acc = 0.9474848625989754\n",
      "test Acc 0.936219739292365:\n",
      "19th- epoch: 107, train_loss = 23.35158197954297, train_acc = 0.9477177456916628\n",
      "test Acc 0.936219739292365:\n",
      "19th- epoch: 108, train_loss = 23.26003423333168, train_acc = 0.9478341872380065\n",
      "test Acc 0.936219739292365:\n",
      "19th- epoch: 109, train_loss = 23.170492842793465, train_acc = 0.9478341872380065\n",
      "test Acc 0.9366852886405959:\n",
      "19th- epoch: 110, train_loss = 23.08175530284643, train_acc = 0.9478341872380065\n",
      "test Acc 0.9366852886405959:\n",
      "19th- epoch: 111, train_loss = 22.993606254458427, train_acc = 0.9481835118770378\n",
      "test Acc 0.9366852886405959:\n",
      "19th- epoch: 112, train_loss = 22.907585345208645, train_acc = 0.9481835118770378\n",
      "test Acc 0.9366852886405959:\n",
      "19th- epoch: 113, train_loss = 22.822820231318474, train_acc = 0.9484163949697252\n",
      "test Acc 0.9366852886405959:\n",
      "19th- epoch: 114, train_loss = 22.73867381364107, train_acc = 0.9488821611551002\n",
      "test Acc 0.9371508379888268:\n",
      "19th- epoch: 115, train_loss = 22.656598087400198, train_acc = 0.9491150442477876\n",
      "test Acc 0.9371508379888268:\n",
      "19th- epoch: 116, train_loss = 22.574827767908573, train_acc = 0.9493479273404751\n",
      "test Acc 0.9371508379888268:\n",
      "19th- epoch: 117, train_loss = 22.494292866438627, train_acc = 0.9493479273404751\n",
      "test Acc 0.9371508379888268:\n",
      "19th- epoch: 118, train_loss = 22.415093950927258, train_acc = 0.9494643688868188\n",
      "test Acc 0.9376163873370578:\n",
      "19th- epoch: 119, train_loss = 22.33710130304098, train_acc = 0.9496972519795063\n",
      "test Acc 0.9376163873370578:\n",
      "19th- epoch: 120, train_loss = 22.260584633797407, train_acc = 0.9500465766185375\n",
      "test Acc 0.9376163873370578:\n",
      "19th- epoch: 121, train_loss = 22.184527408331633, train_acc = 0.950279459711225\n",
      "test Acc 0.9376163873370578:\n",
      "19th- epoch: 122, train_loss = 22.109293080866337, train_acc = 0.950279459711225\n",
      "test Acc 0.9376163873370578:\n",
      "19th- epoch: 123, train_loss = 22.036392610520124, train_acc = 0.9501630181648812\n",
      "test Acc 0.9376163873370578:\n",
      "19th- epoch: 124, train_loss = 21.96362855657935, train_acc = 0.950279459711225\n",
      "test Acc 0.9380819366852886:\n",
      "19th- epoch: 125, train_loss = 21.890831787139177, train_acc = 0.9503959012575687\n",
      "test Acc 0.9380819366852886:\n",
      "19th- epoch: 126, train_loss = 21.82020803168416, train_acc = 0.9505123428039124\n",
      "test Acc 0.9385474860335196:\n",
      "19th- epoch: 127, train_loss = 21.750331819057465, train_acc = 0.9507452258965999\n",
      "test Acc 0.9390130353817505:\n",
      "19th- epoch: 128, train_loss = 21.680593583732843, train_acc = 0.9510945505356311\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 129, train_loss = 21.61243700608611, train_acc = 0.9510945505356311\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 130, train_loss = 21.544978320598602, train_acc = 0.9510945505356311\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 131, train_loss = 21.47867102175951, train_acc = 0.9512109920819748\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 132, train_loss = 21.41240616887808, train_acc = 0.9514438751746623\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 133, train_loss = 21.34660292416811, train_acc = 0.9516767582673498\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 134, train_loss = 21.282253686338663, train_acc = 0.9519096413600373\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 135, train_loss = 21.219137370586395, train_acc = 0.9522589659990685\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 136, train_loss = 21.15545778721571, train_acc = 0.952491849091756\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 137, train_loss = 21.093695614486933, train_acc = 0.9526082906380997\n",
      "test Acc 0.9399441340782123:\n",
      "19th- epoch: 138, train_loss = 21.03321249037981, train_acc = 0.9526082906380997\n",
      "test Acc 0.9399441340782123:\n",
      "19th- epoch: 139, train_loss = 20.972124230116606, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n",
      "19th- epoch: 140, train_loss = 20.912648394703865, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n",
      "19th- epoch: 141, train_loss = 20.853058099746704, train_acc = 0.9533069399161621\n",
      "test Acc 0.9399441340782123:\n",
      "19th- epoch: 142, train_loss = 20.79415337741375, train_acc = 0.9534233814625058\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 143, train_loss = 20.736189149320126, train_acc = 0.9535398230088495\n",
      "test Acc 0.9418063314711359:\n",
      "19th- epoch: 144, train_loss = 20.678954653441906, train_acc = 0.9535398230088495\n",
      "test Acc 0.9418063314711359:\n",
      "19th- epoch: 145, train_loss = 20.621621076017618, train_acc = 0.9534233814625058\n",
      "test Acc 0.9418063314711359:\n",
      "19th- epoch: 146, train_loss = 20.56573174148798, train_acc = 0.9534233814625058\n",
      "test Acc 0.9418063314711359:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 147, train_loss = 20.5097322948277, train_acc = 0.9535398230088495\n",
      "test Acc 0.9418063314711359:\n",
      "19th- epoch: 148, train_loss = 20.45476510003209, train_acc = 0.9536562645551933\n",
      "test Acc 0.9418063314711359:\n",
      "19th- epoch: 149, train_loss = 20.399455465376377, train_acc = 0.9538891476478808\n",
      "test Acc 0.9422718808193669:\n",
      "19th- epoch: 150, train_loss = 20.34574119001627, train_acc = 0.9541220307405682\n",
      "test Acc 0.9422718808193669:\n",
      "19th- epoch: 151, train_loss = 20.29239797964692, train_acc = 0.9542384722869119\n",
      "test Acc 0.9422718808193669:\n",
      "19th- epoch: 152, train_loss = 20.239941004663706, train_acc = 0.9542384722869119\n",
      "test Acc 0.9422718808193669:\n",
      "19th- epoch: 153, train_loss = 20.187413971871138, train_acc = 0.9543549138332557\n",
      "test Acc 0.9422718808193669:\n",
      "19th- epoch: 154, train_loss = 20.13517176359892, train_acc = 0.9544713553795995\n",
      "test Acc 0.9422718808193669:\n",
      "19th- epoch: 155, train_loss = 20.084856785833836, train_acc = 0.9545877969259432\n",
      "test Acc 0.9427374301675978:\n",
      "19th- epoch: 156, train_loss = 20.03413960710168, train_acc = 0.9547042384722869\n",
      "test Acc 0.9427374301675978:\n",
      "19th- epoch: 157, train_loss = 19.984284296631813, train_acc = 0.9548206800186306\n",
      "test Acc 0.9427374301675978:\n",
      "19th- epoch: 158, train_loss = 19.934917271137238, train_acc = 0.9549371215649743\n",
      "test Acc 0.9427374301675978:\n",
      "19th- epoch: 159, train_loss = 19.886218689382076, train_acc = 0.9551700046576619\n",
      "test Acc 0.9427374301675978:\n",
      "19th- epoch: 160, train_loss = 19.83700867369771, train_acc = 0.9552864462040056\n",
      "test Acc 0.9427374301675978:\n",
      "19th- epoch: 161, train_loss = 19.787371737882495, train_acc = 0.9554028877503493\n",
      "test Acc 0.9427374301675978:\n",
      "19th- epoch: 162, train_loss = 19.740795442834496, train_acc = 0.9556357708430367\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 163, train_loss = 19.693507654592395, train_acc = 0.9557522123893806\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 164, train_loss = 19.646416077390313, train_acc = 0.9556357708430367\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 165, train_loss = 19.60029930062592, train_acc = 0.9557522123893806\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 166, train_loss = 19.55374745838344, train_acc = 0.955985095482068\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 167, train_loss = 19.50865069590509, train_acc = 0.9561015370284117\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 168, train_loss = 19.46407281048596, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 169, train_loss = 19.42058722116053, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 170, train_loss = 19.375397378578782, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 171, train_loss = 19.33186066709459, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 172, train_loss = 19.289158580824733, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 173, train_loss = 19.246341913938522, train_acc = 0.956450861667443\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 174, train_loss = 19.20490770228207, train_acc = 0.9565673032137867\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 175, train_loss = 19.164379969239235, train_acc = 0.9568001863064741\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 176, train_loss = 19.121971672400832, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 177, train_loss = 19.081528330221772, train_acc = 0.9568001863064741\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 178, train_loss = 19.040472861379385, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 179, train_loss = 19.00116465985775, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 180, train_loss = 18.962533216923475, train_acc = 0.9566837447601304\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 181, train_loss = 18.923106452450156, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 182, train_loss = 18.882921105250716, train_acc = 0.9570330693991617\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 183, train_loss = 18.84480041079223, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 184, train_loss = 18.80709483101964, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 185, train_loss = 18.770679835230112, train_acc = 0.9571495109455054\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 186, train_loss = 18.730765061452985, train_acc = 0.9572659524918491\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 187, train_loss = 18.695439755916595, train_acc = 0.9572659524918491\n",
      "test Acc 0.9450651769087524:\n",
      "19th- epoch: 188, train_loss = 18.65956886857748, train_acc = 0.9572659524918491\n",
      "test Acc 0.9450651769087524:\n",
      "19th- epoch: 189, train_loss = 18.62306553311646, train_acc = 0.9572659524918491\n",
      "test Acc 0.9450651769087524:\n",
      "19th- epoch: 190, train_loss = 18.585496401414275, train_acc = 0.9572659524918491\n",
      "test Acc 0.9450651769087524:\n",
      "19th- epoch: 191, train_loss = 18.549773605540395, train_acc = 0.9573823940381928\n",
      "test Acc 0.9450651769087524:\n",
      "19th- epoch: 192, train_loss = 18.515831967815757, train_acc = 0.9573823940381928\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 193, train_loss = 18.481448570266366, train_acc = 0.9576152771308803\n",
      "test Acc 0.9450651769087524:\n",
      "19th- epoch: 194, train_loss = 18.44667143188417, train_acc = 0.9576152771308803\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 195, train_loss = 18.41238858550787, train_acc = 0.9578481602235678\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 196, train_loss = 18.378104457631707, train_acc = 0.9579646017699115\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 197, train_loss = 18.344754483550787, train_acc = 0.9579646017699115\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 198, train_loss = 18.31110773794353, train_acc = 0.9579646017699115\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 199, train_loss = 18.277324127033353, train_acc = 0.9581974848625989\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 200, train_loss = 18.245128475129604, train_acc = 0.9583139264089428\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 201, train_loss = 18.210884423926473, train_acc = 0.9583139264089428\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 202, train_loss = 18.17949694953859, train_acc = 0.9584303679552865\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 203, train_loss = 18.147442353889346, train_acc = 0.9585468095016302\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 204, train_loss = 18.11592928506434, train_acc = 0.9584303679552865\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 205, train_loss = 18.08415142633021, train_acc = 0.9585468095016302\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 206, train_loss = 18.05252075381577, train_acc = 0.9585468095016302\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 207, train_loss = 18.020935025066137, train_acc = 0.9586632510479739\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 208, train_loss = 17.990305051207542, train_acc = 0.9587796925943176\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 209, train_loss = 17.962046451866627, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 210, train_loss = 17.932134818285704, train_acc = 0.9588961341406614\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 211, train_loss = 17.90074914880097, train_acc = 0.9590125756870052\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 212, train_loss = 17.87168121896684, train_acc = 0.9591290172333489\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 213, train_loss = 17.845261499285698, train_acc = 0.9593619003260363\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 214, train_loss = 17.815888142213225, train_acc = 0.9593619003260363\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 215, train_loss = 17.786142826080322, train_acc = 0.95947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 216, train_loss = 17.75962490029633, train_acc = 0.9595947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 217, train_loss = 17.731338003650308, train_acc = 0.9595947834187238\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 218, train_loss = 17.701576743274927, train_acc = 0.9598276665114113\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 219, train_loss = 17.67573127709329, train_acc = 0.959944108057755\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 220, train_loss = 17.646569658070803, train_acc = 0.959944108057755\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 221, train_loss = 17.620013693347573, train_acc = 0.9600605496040987\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 222, train_loss = 17.593095725402236, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 223, train_loss = 17.56766565144062, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 224, train_loss = 17.53996298275888, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 225, train_loss = 17.513766400516033, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 226, train_loss = 17.488759020343423, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 227, train_loss = 17.460578430444002, train_acc = 0.96040987424313\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 228, train_loss = 17.43560212291777, train_acc = 0.96040987424313\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 229, train_loss = 17.408292576670647, train_acc = 0.9605263157894737\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 230, train_loss = 17.383279897272587, train_acc = 0.9605263157894737\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 231, train_loss = 17.36080407910049, train_acc = 0.9605263157894737\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 232, train_loss = 17.33525832183659, train_acc = 0.9606427573358174\n",
      "test Acc 0.9478584729981379:\n",
      "19th- epoch: 233, train_loss = 17.310073478147388, train_acc = 0.9607591988821611\n",
      "test Acc 0.9478584729981379:\n",
      "19th- epoch: 234, train_loss = 17.285339592024684, train_acc = 0.9607591988821611\n",
      "test Acc 0.9478584729981379:\n",
      "19th- epoch: 235, train_loss = 17.263194680213928, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "19th- epoch: 236, train_loss = 17.23756772466004, train_acc = 0.9609920819748486\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 237, train_loss = 17.21509109251201, train_acc = 0.9609920819748486\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 238, train_loss = 17.191019129008055, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 239, train_loss = 17.166161270812154, train_acc = 0.9612249650675361\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 240, train_loss = 17.14448868855834, train_acc = 0.9613414066138798\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 241, train_loss = 17.1197624579072, train_acc = 0.9613414066138798\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 242, train_loss = 17.10008859075606, train_acc = 0.9613414066138798\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 243, train_loss = 17.075608337298036, train_acc = 0.9614578481602236\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 244, train_loss = 17.05342659726739, train_acc = 0.9614578481602236\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 245, train_loss = 17.029290532693267, train_acc = 0.9614578481602236\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 246, train_loss = 17.009365782141685, train_acc = 0.9615742897065673\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 247, train_loss = 16.986114704981446, train_acc = 0.9615742897065673\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 248, train_loss = 16.964627580717206, train_acc = 0.961690731252911\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 249, train_loss = 16.941923988983035, train_acc = 0.9619236143455985\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 250, train_loss = 16.920977087691426, train_acc = 0.9619236143455985\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 251, train_loss = 16.899950234219432, train_acc = 0.9619236143455985\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 252, train_loss = 16.880032368004322, train_acc = 0.9620400558919422\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 253, train_loss = 16.85899136029184, train_acc = 0.9620400558919422\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 254, train_loss = 16.836714450269938, train_acc = 0.9620400558919422\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 255, train_loss = 16.817590597085655, train_acc = 0.9620400558919422\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 256, train_loss = 16.795730113983154, train_acc = 0.962156497438286\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 257, train_loss = 16.77563848067075, train_acc = 0.9622729389846297\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 258, train_loss = 16.75611063092947, train_acc = 0.9625058220773172\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 259, train_loss = 16.737215141765773, train_acc = 0.9626222636236609\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 260, train_loss = 16.717520508915186, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 261, train_loss = 16.69576125498861, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 262, train_loss = 16.676816932857037, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 263, train_loss = 16.658166230656207, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 264, train_loss = 16.637656070291996, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 265, train_loss = 16.619693148881197, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 266, train_loss = 16.59877705667168, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 267, train_loss = 16.581067636609077, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 268, train_loss = 16.56359841953963, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 269, train_loss = 16.54380072746426, train_acc = 0.9629715882626921\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 270, train_loss = 16.524955473840237, train_acc = 0.9630880298090359\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 271, train_loss = 16.50837951898575, train_acc = 0.9632044713553796\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 272, train_loss = 16.488193799741566, train_acc = 0.9632044713553796\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 273, train_loss = 16.472009130753577, train_acc = 0.9633209129017233\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 274, train_loss = 16.45235684234649, train_acc = 0.9636702375407545\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 275, train_loss = 16.436563556082547, train_acc = 0.9636702375407545\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 276, train_loss = 16.416628356091678, train_acc = 0.9635537959944108\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 277, train_loss = 16.40102030336857, train_acc = 0.9636702375407545\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 278, train_loss = 16.37979995086789, train_acc = 0.9636702375407545\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 279, train_loss = 16.365492132492363, train_acc = 0.9636702375407545\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 280, train_loss = 16.34495514910668, train_acc = 0.9637866790870983\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 281, train_loss = 16.32795585412532, train_acc = 0.9637866790870983\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 282, train_loss = 16.31105312332511, train_acc = 0.9640195621797858\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 283, train_loss = 16.294360727071762, train_acc = 0.9640195621797858\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 284, train_loss = 16.279820539057255, train_acc = 0.9640195621797858\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 285, train_loss = 16.26314027234912, train_acc = 0.9640195621797858\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 286, train_loss = 16.244087860919535, train_acc = 0.9641360037261295\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 287, train_loss = 16.229691099375486, train_acc = 0.9644853283651607\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 288, train_loss = 16.21148911397904, train_acc = 0.9643688868188169\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 289, train_loss = 16.19711245317012, train_acc = 0.9643688868188169\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 290, train_loss = 16.180796603672206, train_acc = 0.9644853283651607\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 291, train_loss = 16.162381538189948, train_acc = 0.9646017699115044\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 292, train_loss = 16.14767816197127, train_acc = 0.9646017699115044\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 293, train_loss = 16.132387996651232, train_acc = 0.9644853283651607\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 294, train_loss = 16.117422147653997, train_acc = 0.9644853283651607\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 295, train_loss = 16.101873394101858, train_acc = 0.9646017699115044\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 296, train_loss = 16.083193734288216, train_acc = 0.9647182114578482\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 297, train_loss = 16.068904507905245, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 298, train_loss = 16.053873971104622, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 299, train_loss = 16.03782633971423, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 300, train_loss = 16.022247661836445, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 301, train_loss = 16.009141414426267, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 302, train_loss = 15.994043341837823, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 303, train_loss = 15.978911865502596, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 304, train_loss = 15.963735674507916, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 305, train_loss = 15.949086658656597, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 306, train_loss = 15.934770502150059, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 307, train_loss = 15.91910897474736, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 308, train_loss = 15.904670097865164, train_acc = 0.9649510945505356\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 309, train_loss = 15.891122065484524, train_acc = 0.9649510945505356\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 310, train_loss = 15.877030492760241, train_acc = 0.9649510945505356\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 311, train_loss = 15.8624032093212, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 312, train_loss = 15.84820814896375, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 313, train_loss = 15.833498033694923, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 314, train_loss = 15.819365289993584, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 315, train_loss = 15.805600084364414, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 316, train_loss = 15.792003178037703, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 317, train_loss = 15.777918337844312, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 318, train_loss = 15.76379095762968, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 319, train_loss = 15.751187431626022, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 320, train_loss = 15.737705687992275, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 321, train_loss = 15.72448155283928, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 322, train_loss = 15.711787156760693, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 323, train_loss = 15.697758193127811, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 324, train_loss = 15.684625464491546, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 325, train_loss = 15.672168417833745, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 326, train_loss = 15.658581744879484, train_acc = 0.9653004191895669\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 327, train_loss = 15.64454156998545, train_acc = 0.9654168607359106\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 328, train_loss = 15.631295793689787, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 329, train_loss = 15.618152967654169, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 330, train_loss = 15.60609358176589, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 331, train_loss = 15.593157255090773, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 332, train_loss = 15.580633125267923, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 333, train_loss = 15.56876806449145, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 334, train_loss = 15.555214052088559, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 335, train_loss = 15.542384923435748, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 336, train_loss = 15.530561762861907, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 337, train_loss = 15.519374086521566, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 338, train_loss = 15.505983255803585, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 339, train_loss = 15.49329533148557, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 340, train_loss = 15.481494662351906, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 341, train_loss = 15.470058463513851, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 342, train_loss = 15.45993246883154, train_acc = 0.9659990684676293\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 343, train_loss = 15.446505885571241, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 344, train_loss = 15.435732312500477, train_acc = 0.966115510013973\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 345, train_loss = 15.422349034808576, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 346, train_loss = 15.411527752876282, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 347, train_loss = 15.399578649550676, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 348, train_loss = 15.388708009384573, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 349, train_loss = 15.376560310833156, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 350, train_loss = 15.365537027828395, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 351, train_loss = 15.354514956474304, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 352, train_loss = 15.342683692462742, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 353, train_loss = 15.332488113082945, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 354, train_loss = 15.320583206601441, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 355, train_loss = 15.308101180940866, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 356, train_loss = 15.298768355511129, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 357, train_loss = 15.28792164567858, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 358, train_loss = 15.27599583659321, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 359, train_loss = 15.266179651021957, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 360, train_loss = 15.25470810662955, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 361, train_loss = 15.245261709205806, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 362, train_loss = 15.232346492819488, train_acc = 0.9662319515603167\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 363, train_loss = 15.221318717114627, train_acc = 0.9662319515603167\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 364, train_loss = 15.210030232556164, train_acc = 0.9662319515603167\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 365, train_loss = 15.200645968317986, train_acc = 0.9662319515603167\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 366, train_loss = 15.190483744256198, train_acc = 0.9662319515603167\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 367, train_loss = 15.179032613523304, train_acc = 0.9662319515603167\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 368, train_loss = 15.169589220546186, train_acc = 0.9662319515603167\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 369, train_loss = 15.158755507320166, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 370, train_loss = 15.149446245282888, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 371, train_loss = 15.13825432304293, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 372, train_loss = 15.127445794641972, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 373, train_loss = 15.117728471755981, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 374, train_loss = 15.10852950438857, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 375, train_loss = 15.098860241472721, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 376, train_loss = 15.088025051169097, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 377, train_loss = 15.07791108917445, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 378, train_loss = 15.06778493244201, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 379, train_loss = 15.058454013429582, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 380, train_loss = 15.04960102122277, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 381, train_loss = 15.038918666541576, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 382, train_loss = 15.029386132955551, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 383, train_loss = 15.01919876690954, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 384, train_loss = 15.009341741912067, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 385, train_loss = 15.000430929474533, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 386, train_loss = 14.99084899853915, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 387, train_loss = 14.982001851312816, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 388, train_loss = 14.971086203120649, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 389, train_loss = 14.962991278618574, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 390, train_loss = 14.952318225987256, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 391, train_loss = 14.943522389046848, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 392, train_loss = 14.934145834296942, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 393, train_loss = 14.924970459192991, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 394, train_loss = 14.91546334978193, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 395, train_loss = 14.906933147460222, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 396, train_loss = 14.898237501271069, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 397, train_loss = 14.889366528950632, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 398, train_loss = 14.879370423965156, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 399, train_loss = 14.871347986161709, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 400, train_loss = 14.863158825784922, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 401, train_loss = 14.85287965927273, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 402, train_loss = 14.845367047004402, train_acc = 0.9666977177456917\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 403, train_loss = 14.836115232668817, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 404, train_loss = 14.827830859459937, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 405, train_loss = 14.818430078215897, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 406, train_loss = 14.810284025967121, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 407, train_loss = 14.802142578177154, train_acc = 0.9668141592920354\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 408, train_loss = 14.79302817210555, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 409, train_loss = 14.784537837840617, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 410, train_loss = 14.776043274439871, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 411, train_loss = 14.766266430728137, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 412, train_loss = 14.759326030500233, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 413, train_loss = 14.750699155963957, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 414, train_loss = 14.741942338645458, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 415, train_loss = 14.734161601401865, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 416, train_loss = 14.725436437875032, train_acc = 0.9669306008383791\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 417, train_loss = 14.716879573650658, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 418, train_loss = 14.708615119569004, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 419, train_loss = 14.700738565064967, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 420, train_loss = 14.69250534195453, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 421, train_loss = 14.684844177216291, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 422, train_loss = 14.67690821364522, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 423, train_loss = 14.669344279915094, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 424, train_loss = 14.661075578071177, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 425, train_loss = 14.652938335202634, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 426, train_loss = 14.64481243956834, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 427, train_loss = 14.637100304476917, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 428, train_loss = 14.629416030831635, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 429, train_loss = 14.621571709401906, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 430, train_loss = 14.612941209226847, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 431, train_loss = 14.605716182850301, train_acc = 0.9670470423847228\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 432, train_loss = 14.598744145594537, train_acc = 0.9671634839310667\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 433, train_loss = 14.591058620251715, train_acc = 0.9671634839310667\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 434, train_loss = 14.583153295330703, train_acc = 0.9672799254774104\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 435, train_loss = 14.575605797581375, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 436, train_loss = 14.567966353148222, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 437, train_loss = 14.560358834452927, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 438, train_loss = 14.552653577178717, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 439, train_loss = 14.544997585006058, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 440, train_loss = 14.537855670787394, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 441, train_loss = 14.5316646611318, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 442, train_loss = 14.524582886137068, train_acc = 0.9673963670237541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 443, train_loss = 14.516009114682674, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 444, train_loss = 14.508786119520664, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 445, train_loss = 14.50121637340635, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 446, train_loss = 14.493748187087476, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 447, train_loss = 14.486268294043839, train_acc = 0.9676292501164415\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 448, train_loss = 14.479415942914784, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 449, train_loss = 14.471284146420658, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 450, train_loss = 14.465374353341758, train_acc = 0.9676292501164415\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 451, train_loss = 14.458727985620499, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 452, train_loss = 14.450719987042248, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 453, train_loss = 14.443940430879593, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 454, train_loss = 14.436705280095339, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 455, train_loss = 14.428891743533313, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 456, train_loss = 14.422519492916763, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 457, train_loss = 14.415443759411573, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 458, train_loss = 14.408257051371038, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 459, train_loss = 14.402799806557596, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 460, train_loss = 14.39578227698803, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 461, train_loss = 14.388593233190477, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 462, train_loss = 14.381563712842762, train_acc = 0.9677456916627852\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 463, train_loss = 14.374414048157632, train_acc = 0.9678621332091291\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 464, train_loss = 14.369087650440633, train_acc = 0.9678621332091291\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 465, train_loss = 14.360809247940779, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 466, train_loss = 14.354950178414583, train_acc = 0.9679785747554728\n",
      "test Acc 0.952048417132216:\n",
      "19th- epoch: 467, train_loss = 14.348468518350273, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 468, train_loss = 14.341446644160897, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 469, train_loss = 14.33475317293778, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 470, train_loss = 14.328553915023804, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 471, train_loss = 14.322172509040684, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 472, train_loss = 14.315540311392397, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 473, train_loss = 14.308974129613489, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 474, train_loss = 14.303163163363934, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 475, train_loss = 14.296672441065311, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 476, train_loss = 14.289353938307613, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 477, train_loss = 14.28359155356884, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 478, train_loss = 14.276973174419254, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 479, train_loss = 14.27142259851098, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 480, train_loss = 14.264575684908777, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 481, train_loss = 14.258652010466903, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 482, train_loss = 14.252582129091024, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 483, train_loss = 14.247072902973741, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 484, train_loss = 14.24029729142785, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 485, train_loss = 14.233791843056679, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 486, train_loss = 14.228075681719929, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 487, train_loss = 14.22218245640397, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 488, train_loss = 14.216143088880926, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 489, train_loss = 14.210300883743912, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 490, train_loss = 14.204994683619589, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 491, train_loss = 14.197343934327364, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 492, train_loss = 14.191817653831095, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 493, train_loss = 14.188037786632776, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 494, train_loss = 14.180354820098728, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 495, train_loss = 14.174830675125122, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 496, train_loss = 14.170076245907694, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 497, train_loss = 14.162903887685388, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 498, train_loss = 14.15850834036246, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "19th- epoch: 499, train_loss = 14.153885260224342, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|████████████████████████████████████████████▎                         | 19/30 [2:06:23<1:13:01, 398.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "20th- epoch: 0, train_loss = 273.0134847164154, train_acc = 0.4363064741499767\n",
      "test Acc 0.4930167597765363:\n",
      "20th- epoch: 1, train_loss = 213.74114286899567, train_acc = 0.49685607824871914\n",
      "test Acc 0.49906890130353815:\n",
      "20th- epoch: 2, train_loss = 180.5382844209671, train_acc = 0.503959012575687\n",
      "test Acc 0.5116387337057728:\n",
      "20th- epoch: 3, train_loss = 164.32157611846924, train_acc = 0.5263157894736842\n",
      "test Acc 0.553072625698324:\n",
      "20th- epoch: 4, train_loss = 151.80399721860886, train_acc = 0.572193758733116\n",
      "test Acc 0.6103351955307262:\n",
      "20th- epoch: 5, train_loss = 140.46595335006714, train_acc = 0.6198183511877038\n",
      "test Acc 0.6368715083798883:\n",
      "20th- epoch: 6, train_loss = 129.76527351140976, train_acc = 0.6393805309734514\n",
      "test Acc 0.6531657355679702:\n",
      "20th- epoch: 7, train_loss = 119.80668902397156, train_acc = 0.6859571495109456\n",
      "test Acc 0.7481378026070763:\n",
      "20th- epoch: 8, train_loss = 110.70629549026489, train_acc = 0.7517466231951561\n",
      "test Acc 0.7690875232774674:\n",
      "20th- epoch: 9, train_loss = 102.38512164354324, train_acc = 0.7850489054494644\n",
      "test Acc 0.7946927374301676:\n",
      "20th- epoch: 10, train_loss = 94.81804811954498, train_acc = 0.804145319049837\n",
      "test Acc 0.8086592178770949:\n",
      "20th- epoch: 11, train_loss = 88.05892804265022, train_acc = 0.8180018630647415\n",
      "test Acc 0.8226256983240223:\n",
      "20th- epoch: 12, train_loss = 82.08361485600471, train_acc = 0.8311597578015836\n",
      "test Acc 0.840316573556797:\n",
      "20th- epoch: 13, train_loss = 76.85782593488693, train_acc = 0.8440847694457383\n",
      "test Acc 0.8519553072625698:\n",
      "20th- epoch: 14, train_loss = 72.29175543785095, train_acc = 0.8527014438751747\n",
      "test Acc 0.8570763500931099:\n",
      "20th- epoch: 15, train_loss = 68.30195665359497, train_acc = 0.8610852352119236\n",
      "test Acc 0.8631284916201117:\n",
      "20th- epoch: 16, train_loss = 64.79638877511024, train_acc = 0.8636469492314858\n",
      "test Acc 0.86731843575419:\n",
      "20th- epoch: 17, train_loss = 61.6946165561676, train_acc = 0.8680717279925477\n",
      "test Acc 0.8743016759776536:\n",
      "20th- epoch: 18, train_loss = 58.9391108751297, train_acc = 0.8729622729389847\n",
      "test Acc 0.8798882681564246:\n",
      "20th- epoch: 19, train_loss = 56.485035836696625, train_acc = 0.8775034932463903\n",
      "test Acc 0.8854748603351955:\n",
      "20th- epoch: 20, train_loss = 54.29932190477848, train_acc = 0.882044713553796\n",
      "test Acc 0.8891992551210428:\n",
      "20th- epoch: 21, train_loss = 52.35007709264755, train_acc = 0.8864694923148579\n",
      "test Acc 0.8943202979515829:\n",
      "20th- epoch: 22, train_loss = 50.603692039847374, train_acc = 0.88996273870517\n",
      "test Acc 0.8961824953445066:\n",
      "20th- epoch: 23, train_loss = 49.03567770123482, train_acc = 0.8936888681881695\n",
      "test Acc 0.9013035381750466:\n",
      "20th- epoch: 24, train_loss = 47.62366737425327, train_acc = 0.8990451793199814\n",
      "test Acc 0.9017690875232774:\n",
      "20th- epoch: 25, train_loss = 46.344779908657074, train_acc = 0.9003260363297625\n",
      "test Acc 0.9036312849162011:\n",
      "20th- epoch: 26, train_loss = 45.18468099832535, train_acc = 0.9030041918956684\n",
      "test Acc 0.9050279329608939:\n",
      "20th- epoch: 27, train_loss = 44.12830191850662, train_acc = 0.9047508150908244\n",
      "test Acc 0.9073556797020484:\n",
      "20th- epoch: 28, train_loss = 43.160567715764046, train_acc = 0.9069632044713554\n",
      "test Acc 0.9082867783985102:\n",
      "20th- epoch: 29, train_loss = 42.27026756107807, train_acc = 0.9089427107591989\n",
      "test Acc 0.9106145251396648:\n",
      "20th- epoch: 30, train_loss = 41.45054394006729, train_acc = 0.9111551001397299\n",
      "test Acc 0.9120111731843575:\n",
      "20th- epoch: 31, train_loss = 40.691513419151306, train_acc = 0.9137168141592921\n",
      "test Acc 0.9129422718808193:\n",
      "20th- epoch: 32, train_loss = 39.98539124429226, train_acc = 0.915463437354448\n",
      "test Acc 0.9129422718808193:\n",
      "20th- epoch: 33, train_loss = 39.32626248896122, train_acc = 0.9169771774569166\n",
      "test Acc 0.9129422718808193:\n",
      "20th- epoch: 34, train_loss = 38.71096432209015, train_acc = 0.9186073591057289\n",
      "test Acc 0.9138733705772812:\n",
      "20th- epoch: 35, train_loss = 38.134077206254005, train_acc = 0.9190731252911039\n",
      "test Acc 0.914804469273743:\n",
      "20th- epoch: 36, train_loss = 37.59189660847187, train_acc = 0.9195388914764788\n",
      "test Acc 0.9157355679702048:\n",
      "20th- epoch: 37, train_loss = 37.08034734427929, train_acc = 0.9208197484862599\n",
      "test Acc 0.9175977653631285:\n",
      "20th- epoch: 38, train_loss = 36.59685157239437, train_acc = 0.921634839310666\n",
      "test Acc 0.9180633147113594:\n",
      "20th- epoch: 39, train_loss = 36.138250812888145, train_acc = 0.922100605496041\n",
      "test Acc 0.9189944134078212:\n",
      "20th- epoch: 40, train_loss = 35.70246675610542, train_acc = 0.9238472286911971\n",
      "test Acc 0.9199255121042831:\n",
      "20th- epoch: 41, train_loss = 35.28715844452381, train_acc = 0.9248952026082906\n",
      "test Acc 0.9199255121042831:\n",
      "20th- epoch: 42, train_loss = 34.89143913239241, train_acc = 0.9253609687936656\n",
      "test Acc 0.9213221601489758:\n",
      "20th- epoch: 43, train_loss = 34.51377158612013, train_acc = 0.9259431765253843\n",
      "test Acc 0.9217877094972067:\n",
      "20th- epoch: 44, train_loss = 34.152210116386414, train_acc = 0.9266418258034467\n",
      "test Acc 0.9231843575418994:\n",
      "20th- epoch: 45, train_loss = 33.80526764690876, train_acc = 0.9276897997205403\n",
      "test Acc 0.9236499068901304:\n",
      "20th- epoch: 46, train_loss = 33.47083892673254, train_acc = 0.928272007452259\n",
      "test Acc 0.9236499068901304:\n",
      "20th- epoch: 47, train_loss = 33.14901230484247, train_acc = 0.9286213320912902\n",
      "test Acc 0.9250465549348231:\n",
      "20th- epoch: 48, train_loss = 32.838446624577045, train_acc = 0.9286213320912902\n",
      "test Acc 0.9250465549348231:\n",
      "20th- epoch: 49, train_loss = 32.53881162405014, train_acc = 0.9287377736376339\n",
      "test Acc 0.9250465549348231:\n",
      "20th- epoch: 50, train_loss = 32.24881747364998, train_acc = 0.9293199813693526\n",
      "test Acc 0.9250465549348231:\n",
      "20th- epoch: 51, train_loss = 31.967884428799152, train_acc = 0.9297857475547275\n",
      "test Acc 0.9250465549348231:\n",
      "20th- epoch: 52, train_loss = 31.695551097393036, train_acc = 0.9304843968327899\n",
      "test Acc 0.9250465549348231:\n",
      "20th- epoch: 53, train_loss = 31.43255775421858, train_acc = 0.9311830461108523\n",
      "test Acc 0.9250465549348231:\n",
      "20th- epoch: 54, train_loss = 31.176446482539177, train_acc = 0.931765253842571\n",
      "test Acc 0.925512104283054:\n",
      "20th- epoch: 55, train_loss = 30.92824114859104, train_acc = 0.9323474615742897\n",
      "test Acc 0.925512104283054:\n",
      "20th- epoch: 56, train_loss = 30.686400279402733, train_acc = 0.9328132277596647\n",
      "test Acc 0.9259776536312849:\n",
      "20th- epoch: 57, train_loss = 30.451531752943993, train_acc = 0.9330461108523521\n",
      "test Acc 0.9264432029795159:\n",
      "20th- epoch: 58, train_loss = 30.222683794796467, train_acc = 0.9332789939450395\n",
      "test Acc 0.9273743016759777:\n",
      "20th- epoch: 59, train_loss = 29.99995344132185, train_acc = 0.9336283185840708\n",
      "test Acc 0.9273743016759777:\n",
      "20th- epoch: 60, train_loss = 29.782387763261795, train_acc = 0.9342105263157895\n",
      "test Acc 0.9269087523277467:\n",
      "20th- epoch: 61, train_loss = 29.570292837917805, train_acc = 0.9344434094084769\n",
      "test Acc 0.9278398510242085:\n",
      "20th- epoch: 62, train_loss = 29.363305002450943, train_acc = 0.9349091755938519\n",
      "test Acc 0.9278398510242085:\n",
      "20th- epoch: 63, train_loss = 29.161040499806404, train_acc = 0.935258500232883\n",
      "test Acc 0.9278398510242085:\n",
      "20th- epoch: 64, train_loss = 28.963372074067593, train_acc = 0.935258500232883\n",
      "test Acc 0.9283054003724395:\n",
      "20th- epoch: 65, train_loss = 28.769433327019215, train_acc = 0.9353749417792269\n",
      "test Acc 0.9283054003724395:\n",
      "20th- epoch: 66, train_loss = 28.580004297196865, train_acc = 0.9359571495109456\n",
      "test Acc 0.9283054003724395:\n",
      "20th- epoch: 67, train_loss = 28.394732676446438, train_acc = 0.9364229156963204\n",
      "test Acc 0.9283054003724395:\n",
      "20th- epoch: 68, train_loss = 28.213358603417873, train_acc = 0.936655798789008\n",
      "test Acc 0.9287709497206704:\n",
      "20th- epoch: 69, train_loss = 28.035788536071777, train_acc = 0.9372380065207266\n",
      "test Acc 0.9287709497206704:\n",
      "20th- epoch: 70, train_loss = 27.86125148832798, train_acc = 0.9372380065207266\n",
      "test Acc 0.9301675977653632:\n",
      "20th- epoch: 71, train_loss = 27.690049692988396, train_acc = 0.937936655798789\n",
      "test Acc 0.930633147113594:\n",
      "20th- epoch: 72, train_loss = 27.522362619638443, train_acc = 0.9380530973451328\n",
      "test Acc 0.930633147113594:\n",
      "20th- epoch: 73, train_loss = 27.357468836009502, train_acc = 0.9387517466231952\n",
      "test Acc 0.930633147113594:\n",
      "20th- epoch: 74, train_loss = 27.195898488163948, train_acc = 0.9389846297158826\n",
      "test Acc 0.930633147113594:\n",
      "20th- epoch: 75, train_loss = 27.037258945405483, train_acc = 0.9395668374476013\n",
      "test Acc 0.930633147113594:\n",
      "20th- epoch: 76, train_loss = 26.882057704031467, train_acc = 0.9395668374476013\n",
      "test Acc 0.931098696461825:\n",
      "20th- epoch: 77, train_loss = 26.73009404540062, train_acc = 0.9397997205402888\n",
      "test Acc 0.9315642458100558:\n",
      "20th- epoch: 78, train_loss = 26.58050800859928, train_acc = 0.94014904517932\n",
      "test Acc 0.9315642458100558:\n",
      "20th- epoch: 79, train_loss = 26.43411274254322, train_acc = 0.9402654867256637\n",
      "test Acc 0.9315642458100558:\n",
      "20th- epoch: 80, train_loss = 26.290245816111565, train_acc = 0.9408476944573824\n",
      "test Acc 0.9320297951582868:\n",
      "20th- epoch: 81, train_loss = 26.149352692067623, train_acc = 0.941429902189101\n",
      "test Acc 0.9320297951582868:\n",
      "20th- epoch: 82, train_loss = 26.011262767016888, train_acc = 0.941429902189101\n",
      "test Acc 0.9329608938547486:\n",
      "20th- epoch: 83, train_loss = 25.87588719278574, train_acc = 0.9416627852817886\n",
      "test Acc 0.9329608938547486:\n",
      "20th- epoch: 84, train_loss = 25.743058513849974, train_acc = 0.941895668374476\n",
      "test Acc 0.9329608938547486:\n",
      "20th- epoch: 85, train_loss = 25.613121666014194, train_acc = 0.9420121099208197\n",
      "test Acc 0.9329608938547486:\n",
      "20th- epoch: 86, train_loss = 25.48531260713935, train_acc = 0.942361434559851\n",
      "test Acc 0.9334264432029795:\n",
      "20th- epoch: 87, train_loss = 25.358917448669672, train_acc = 0.9424778761061947\n",
      "test Acc 0.9334264432029795:\n",
      "20th- epoch: 88, train_loss = 25.23518455028534, train_acc = 0.9428272007452259\n",
      "test Acc 0.9338919925512105:\n",
      "20th- epoch: 89, train_loss = 25.113343685865402, train_acc = 0.9429436422915697\n",
      "test Acc 0.9338919925512105:\n",
      "20th- epoch: 90, train_loss = 24.993479814380407, train_acc = 0.9434094084769445\n",
      "test Acc 0.9338919925512105:\n",
      "20th- epoch: 91, train_loss = 24.87610647454858, train_acc = 0.9436422915696321\n",
      "test Acc 0.9338919925512105:\n",
      "20th- epoch: 92, train_loss = 24.760559916496277, train_acc = 0.9438751746623195\n",
      "test Acc 0.9348230912476723:\n",
      "20th- epoch: 93, train_loss = 24.647503577172756, train_acc = 0.9438751746623195\n",
      "test Acc 0.9348230912476723:\n",
      "20th- epoch: 94, train_loss = 24.535545479506254, train_acc = 0.9439916162086632\n",
      "test Acc 0.9352886405959032:\n",
      "20th- epoch: 95, train_loss = 24.42571010068059, train_acc = 0.9444573823940382\n",
      "test Acc 0.9357541899441341:\n",
      "20th- epoch: 96, train_loss = 24.31760561838746, train_acc = 0.9446902654867256\n",
      "test Acc 0.9357541899441341:\n",
      "20th- epoch: 97, train_loss = 24.21276108548045, train_acc = 0.9451560316721006\n",
      "test Acc 0.9357541899441341:\n",
      "20th- epoch: 98, train_loss = 24.108079683035612, train_acc = 0.9452724732184443\n",
      "test Acc 0.936219739292365:\n",
      "20th- epoch: 99, train_loss = 24.004833314567804, train_acc = 0.945388914764788\n",
      "test Acc 0.936219739292365:\n",
      "20th- epoch: 100, train_loss = 23.90389769524336, train_acc = 0.9456217978574756\n",
      "test Acc 0.936219739292365:\n",
      "20th- epoch: 101, train_loss = 23.805340599268675, train_acc = 0.9460875640428504\n",
      "test Acc 0.936219739292365:\n",
      "20th- epoch: 102, train_loss = 23.7081918977201, train_acc = 0.9466697717745691\n",
      "test Acc 0.936219739292365:\n",
      "20th- epoch: 103, train_loss = 23.612304002046585, train_acc = 0.9471355379599441\n",
      "test Acc 0.9371508379888268:\n",
      "20th- epoch: 104, train_loss = 23.51894873008132, train_acc = 0.9473684210526315\n",
      "test Acc 0.9376163873370578:\n",
      "20th- epoch: 105, train_loss = 23.42586897686124, train_acc = 0.9474848625989754\n",
      "test Acc 0.9376163873370578:\n",
      "20th- epoch: 106, train_loss = 23.335141327232122, train_acc = 0.9474848625989754\n",
      "test Acc 0.9376163873370578:\n",
      "20th- epoch: 107, train_loss = 23.244567174464464, train_acc = 0.9478341872380065\n",
      "test Acc 0.9385474860335196:\n",
      "20th- epoch: 108, train_loss = 23.156498458236456, train_acc = 0.9481835118770378\n",
      "test Acc 0.9385474860335196:\n",
      "20th- epoch: 109, train_loss = 23.068565905094147, train_acc = 0.9485328365160689\n",
      "test Acc 0.9390130353817505:\n",
      "20th- epoch: 110, train_loss = 22.983185295015574, train_acc = 0.9488821611551002\n",
      "test Acc 0.9390130353817505:\n",
      "20th- epoch: 111, train_loss = 22.89857891201973, train_acc = 0.9492314857941313\n",
      "test Acc 0.9390130353817505:\n",
      "20th- epoch: 112, train_loss = 22.81517792493105, train_acc = 0.9494643688868188\n",
      "test Acc 0.9390130353817505:\n",
      "20th- epoch: 113, train_loss = 22.733313091099262, train_acc = 0.9495808104331626\n",
      "test Acc 0.9390130353817505:\n",
      "20th- epoch: 114, train_loss = 22.653364080935717, train_acc = 0.9496972519795063\n",
      "test Acc 0.9390130353817505:\n",
      "20th- epoch: 115, train_loss = 22.573803640902042, train_acc = 0.9496972519795063\n",
      "test Acc 0.9390130353817505:\n",
      "20th- epoch: 116, train_loss = 22.495640087872744, train_acc = 0.94981369352585\n",
      "test Acc 0.9390130353817505:\n",
      "20th- epoch: 117, train_loss = 22.418479446321726, train_acc = 0.9499301350721937\n",
      "test Acc 0.9390130353817505:\n",
      "20th- epoch: 118, train_loss = 22.343149282038212, train_acc = 0.950279459711225\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 119, train_loss = 22.26785196363926, train_acc = 0.9503959012575687\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 120, train_loss = 22.193963337689638, train_acc = 0.9506287843502562\n",
      "test Acc 0.9399441340782123:\n",
      "20th- epoch: 121, train_loss = 22.120460093021393, train_acc = 0.9505123428039124\n",
      "test Acc 0.9399441340782123:\n",
      "20th- epoch: 122, train_loss = 22.04844033718109, train_acc = 0.9506287843502562\n",
      "test Acc 0.9404096834264432:\n",
      "20th- epoch: 123, train_loss = 21.97679965943098, train_acc = 0.9507452258965999\n",
      "test Acc 0.9404096834264432:\n",
      "20th- epoch: 124, train_loss = 21.906740579754114, train_acc = 0.9510945505356311\n",
      "test Acc 0.9404096834264432:\n",
      "20th- epoch: 125, train_loss = 21.837411627173424, train_acc = 0.9512109920819748\n",
      "test Acc 0.9404096834264432:\n",
      "20th- epoch: 126, train_loss = 21.769054777920246, train_acc = 0.9514438751746623\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 127, train_loss = 21.70117935910821, train_acc = 0.951560316721006\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 128, train_loss = 21.63519662246108, train_acc = 0.951560316721006\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 129, train_loss = 21.569453790783882, train_acc = 0.951560316721006\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 130, train_loss = 21.5028615295887, train_acc = 0.9516767582673498\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 131, train_loss = 21.438403502106667, train_acc = 0.9517931998136935\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 132, train_loss = 21.376208368688822, train_acc = 0.9517931998136935\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 133, train_loss = 21.312113758176565, train_acc = 0.952026082906381\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 134, train_loss = 21.250319231301546, train_acc = 0.9523754075454122\n",
      "test Acc 0.9413407821229051:\n",
      "20th- epoch: 135, train_loss = 21.18905059993267, train_acc = 0.9523754075454122\n",
      "test Acc 0.9413407821229051:\n",
      "20th- epoch: 136, train_loss = 21.128911040723324, train_acc = 0.952491849091756\n",
      "test Acc 0.9413407821229051:\n",
      "20th- epoch: 137, train_loss = 21.067531548440456, train_acc = 0.9526082906380997\n",
      "test Acc 0.9413407821229051:\n",
      "20th- epoch: 138, train_loss = 21.00904695317149, train_acc = 0.9526082906380997\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 139, train_loss = 20.949173416942358, train_acc = 0.9526082906380997\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 140, train_loss = 20.891979798674583, train_acc = 0.9526082906380997\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 141, train_loss = 20.834145490080118, train_acc = 0.9527247321844434\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 142, train_loss = 20.77721805498004, train_acc = 0.9528411737307871\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 143, train_loss = 20.720900252461433, train_acc = 0.9530740568234746\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 144, train_loss = 20.66629769280553, train_acc = 0.9531904983698184\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 145, train_loss = 20.610778272151947, train_acc = 0.9535398230088495\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 146, train_loss = 20.55577690154314, train_acc = 0.9535398230088495\n",
      "test Acc 0.9418063314711359:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 147, train_loss = 20.50281786546111, train_acc = 0.9535398230088495\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 148, train_loss = 20.44943830370903, train_acc = 0.9536562645551933\n",
      "test Acc 0.9422718808193669:\n",
      "20th- epoch: 149, train_loss = 20.3966860845685, train_acc = 0.9536562645551933\n",
      "test Acc 0.9422718808193669:\n",
      "20th- epoch: 150, train_loss = 20.344541639089584, train_acc = 0.9538891476478808\n",
      "test Acc 0.9422718808193669:\n",
      "20th- epoch: 151, train_loss = 20.292169094085693, train_acc = 0.9540055891942245\n",
      "test Acc 0.9422718808193669:\n",
      "20th- epoch: 152, train_loss = 20.241319593042135, train_acc = 0.9542384722869119\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 153, train_loss = 20.19044592231512, train_acc = 0.9544713553795995\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 154, train_loss = 20.140547540038824, train_acc = 0.9547042384722869\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 155, train_loss = 20.090307399630547, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 156, train_loss = 20.040819810703397, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 157, train_loss = 19.989233439788222, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 158, train_loss = 19.940255761146545, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 159, train_loss = 19.89190734550357, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 160, train_loss = 19.84471565298736, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 161, train_loss = 19.796868389472365, train_acc = 0.9550535631113182\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 162, train_loss = 19.750476917251945, train_acc = 0.9550535631113182\n",
      "test Acc 0.9418063314711359:\n",
      "20th- epoch: 163, train_loss = 19.703586984425783, train_acc = 0.9550535631113182\n",
      "test Acc 0.9422718808193669:\n",
      "20th- epoch: 164, train_loss = 19.658050360158086, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "20th- epoch: 165, train_loss = 19.613347493112087, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "20th- epoch: 166, train_loss = 19.56809032522142, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "20th- epoch: 167, train_loss = 19.522822884842753, train_acc = 0.9554028877503493\n",
      "test Acc 0.9422718808193669:\n",
      "20th- epoch: 168, train_loss = 19.47798920981586, train_acc = 0.9557522123893806\n",
      "test Acc 0.9422718808193669:\n",
      "20th- epoch: 169, train_loss = 19.434148216620088, train_acc = 0.955985095482068\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 170, train_loss = 19.3901151381433, train_acc = 0.9561015370284117\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 171, train_loss = 19.347553299739957, train_acc = 0.9561015370284117\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 172, train_loss = 19.304996818304062, train_acc = 0.9562179785747554\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 173, train_loss = 19.263276111334562, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 174, train_loss = 19.221563352271914, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 175, train_loss = 19.17923192679882, train_acc = 0.9563344201210993\n",
      "test Acc 0.9432029795158287:\n",
      "20th- epoch: 176, train_loss = 19.13893068023026, train_acc = 0.9563344201210993\n",
      "test Acc 0.9432029795158287:\n",
      "20th- epoch: 177, train_loss = 19.098141418769956, train_acc = 0.9563344201210993\n",
      "test Acc 0.9432029795158287:\n",
      "20th- epoch: 178, train_loss = 19.058688420802355, train_acc = 0.9563344201210993\n",
      "test Acc 0.9432029795158287:\n",
      "20th- epoch: 179, train_loss = 19.01913001574576, train_acc = 0.956450861667443\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 180, train_loss = 18.980007400736213, train_acc = 0.956450861667443\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 181, train_loss = 18.940965292975307, train_acc = 0.956450861667443\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 182, train_loss = 18.901640061289072, train_acc = 0.9565673032137867\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 183, train_loss = 18.86377797462046, train_acc = 0.9565673032137867\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 184, train_loss = 18.826036989688873, train_acc = 0.9566837447601304\n",
      "test Acc 0.9441340782122905:\n",
      "20th- epoch: 185, train_loss = 18.78920342028141, train_acc = 0.9566837447601304\n",
      "test Acc 0.9441340782122905:\n",
      "20th- epoch: 186, train_loss = 18.752693904563785, train_acc = 0.9566837447601304\n",
      "test Acc 0.9441340782122905:\n",
      "20th- epoch: 187, train_loss = 18.713783893734217, train_acc = 0.9568001863064741\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 188, train_loss = 18.67836201004684, train_acc = 0.9568001863064741\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 189, train_loss = 18.642846269533038, train_acc = 0.9571495109455054\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 190, train_loss = 18.60702937655151, train_acc = 0.9572659524918491\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 191, train_loss = 18.570174369961023, train_acc = 0.9573823940381928\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 192, train_loss = 18.53704149276018, train_acc = 0.9574988355845365\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 193, train_loss = 18.50085566006601, train_acc = 0.9574988355845365\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 194, train_loss = 18.465998325496912, train_acc = 0.9576152771308803\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 195, train_loss = 18.43048152141273, train_acc = 0.9577317186772241\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 196, train_loss = 18.3975912053138, train_acc = 0.9578481602235678\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 197, train_loss = 18.364646546542645, train_acc = 0.9578481602235678\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 198, train_loss = 18.330998118966818, train_acc = 0.9580810433162552\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 199, train_loss = 18.296623898670077, train_acc = 0.9583139264089428\n",
      "test Acc 0.9450651769087524:\n",
      "20th- epoch: 200, train_loss = 18.266083233058453, train_acc = 0.9584303679552865\n",
      "test Acc 0.9450651769087524:\n",
      "20th- epoch: 201, train_loss = 18.234137408435345, train_acc = 0.9585468095016302\n",
      "test Acc 0.9450651769087524:\n",
      "20th- epoch: 202, train_loss = 18.200505359098315, train_acc = 0.9584303679552865\n",
      "test Acc 0.9450651769087524:\n",
      "20th- epoch: 203, train_loss = 18.169194677844644, train_acc = 0.9587796925943176\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 204, train_loss = 18.13739319331944, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 205, train_loss = 18.1077575199306, train_acc = 0.9587796925943176\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 206, train_loss = 18.07720716483891, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 207, train_loss = 18.045283099636436, train_acc = 0.9590125756870052\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 208, train_loss = 18.015273347496986, train_acc = 0.9590125756870052\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 209, train_loss = 17.98625416867435, train_acc = 0.9591290172333489\n",
      "test Acc 0.946927374301676:\n",
      "20th- epoch: 210, train_loss = 17.9566356446594, train_acc = 0.9591290172333489\n",
      "test Acc 0.946927374301676:\n",
      "20th- epoch: 211, train_loss = 17.92852946743369, train_acc = 0.9592454587796926\n",
      "test Acc 0.946927374301676:\n",
      "20th- epoch: 212, train_loss = 17.898700499907136, train_acc = 0.9592454587796926\n",
      "test Acc 0.946927374301676:\n",
      "20th- epoch: 213, train_loss = 17.870726704597473, train_acc = 0.9593619003260363\n",
      "test Acc 0.946927374301676:\n",
      "20th- epoch: 214, train_loss = 17.840510193258524, train_acc = 0.9593619003260363\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 215, train_loss = 17.812915919348598, train_acc = 0.95947834187238\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 216, train_loss = 17.784476114436984, train_acc = 0.9595947834187238\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 217, train_loss = 17.757359370589256, train_acc = 0.9595947834187238\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 218, train_loss = 17.729618940502405, train_acc = 0.9598276665114113\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 219, train_loss = 17.70188250206411, train_acc = 0.9598276665114113\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 220, train_loss = 17.676100490614772, train_acc = 0.959944108057755\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 221, train_loss = 17.64742734655738, train_acc = 0.9600605496040987\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 222, train_loss = 17.62127119116485, train_acc = 0.9600605496040987\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 223, train_loss = 17.59517797268927, train_acc = 0.9600605496040987\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 224, train_loss = 17.56935982964933, train_acc = 0.9600605496040987\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 225, train_loss = 17.54109531082213, train_acc = 0.9600605496040987\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 226, train_loss = 17.51625562272966, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 227, train_loss = 17.491620248183608, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 228, train_loss = 17.46581949107349, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 229, train_loss = 17.441366938874125, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "20th- epoch: 230, train_loss = 17.415970308706164, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "20th- epoch: 231, train_loss = 17.390264911577106, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "20th- epoch: 232, train_loss = 17.364716969430447, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "20th- epoch: 233, train_loss = 17.340091245248914, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 234, train_loss = 17.316433127969503, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 235, train_loss = 17.292196322232485, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 236, train_loss = 17.26917350664735, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 237, train_loss = 17.245717441663146, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 238, train_loss = 17.221789356321096, train_acc = 0.9609920819748486\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 239, train_loss = 17.19827683083713, train_acc = 0.9611085235211924\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 240, train_loss = 17.176375126466155, train_acc = 0.9612249650675361\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 241, train_loss = 17.152413288131356, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 242, train_loss = 17.131291711702943, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 243, train_loss = 17.1080677267164, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 244, train_loss = 17.086625806987286, train_acc = 0.9614578481602236\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 245, train_loss = 17.062336826696992, train_acc = 0.9614578481602236\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 246, train_loss = 17.041555415838957, train_acc = 0.9614578481602236\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 247, train_loss = 17.01839291024953, train_acc = 0.9615742897065673\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 248, train_loss = 16.996949409134686, train_acc = 0.9615742897065673\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 249, train_loss = 16.97504175361246, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 250, train_loss = 16.95375053677708, train_acc = 0.9620400558919422\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 251, train_loss = 16.933940928429365, train_acc = 0.962156497438286\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 252, train_loss = 16.91271481756121, train_acc = 0.962156497438286\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 253, train_loss = 16.89137799013406, train_acc = 0.9622729389846297\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 254, train_loss = 16.872179391793907, train_acc = 0.9623893805309734\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 255, train_loss = 16.852784016169608, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 256, train_loss = 16.831335564143956, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 257, train_loss = 16.812340567819774, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 258, train_loss = 16.79014852270484, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 259, train_loss = 16.770815882831812, train_acc = 0.9623893805309734\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 260, train_loss = 16.750617601908743, train_acc = 0.9625058220773172\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 261, train_loss = 16.731307866983116, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 262, train_loss = 16.710923329927027, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 263, train_loss = 16.692138771526515, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 264, train_loss = 16.67361641768366, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 265, train_loss = 16.65432647522539, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 266, train_loss = 16.635404317639768, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 267, train_loss = 16.61924168933183, train_acc = 0.9629715882626921\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 268, train_loss = 16.600199713371694, train_acc = 0.9629715882626921\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 269, train_loss = 16.580048844218254, train_acc = 0.9629715882626921\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 270, train_loss = 16.563910917378962, train_acc = 0.9632044713553796\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 271, train_loss = 16.54364071134478, train_acc = 0.9632044713553796\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 272, train_loss = 16.525122477672994, train_acc = 0.9632044713553796\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 273, train_loss = 16.508677129633725, train_acc = 0.9632044713553796\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 274, train_loss = 16.491470254026353, train_acc = 0.9630880298090359\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 275, train_loss = 16.473282950930297, train_acc = 0.9632044713553796\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 276, train_loss = 16.45440969336778, train_acc = 0.9633209129017233\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 277, train_loss = 16.438537792302668, train_acc = 0.9633209129017233\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 278, train_loss = 16.422913788817823, train_acc = 0.9634373544480671\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 279, train_loss = 16.405227809213102, train_acc = 0.9634373544480671\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 280, train_loss = 16.386301442980766, train_acc = 0.9635537959944108\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 281, train_loss = 16.370814685709774, train_acc = 0.9635537959944108\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 282, train_loss = 16.351428111083806, train_acc = 0.9635537959944108\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 283, train_loss = 16.337709974497557, train_acc = 0.9635537959944108\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 284, train_loss = 16.318700092844665, train_acc = 0.9635537959944108\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 285, train_loss = 16.30403649713844, train_acc = 0.9635537959944108\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 286, train_loss = 16.285874125547707, train_acc = 0.9637866790870983\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 287, train_loss = 16.26980608329177, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 288, train_loss = 16.2551772845909, train_acc = 0.963903120633442\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 289, train_loss = 16.237963937222958, train_acc = 0.9640195621797858\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 290, train_loss = 16.221393688581884, train_acc = 0.9640195621797858\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 291, train_loss = 16.20809479057789, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 292, train_loss = 16.190378324128687, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 293, train_loss = 16.17617243807763, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 294, train_loss = 16.15841970127076, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 295, train_loss = 16.145346254110336, train_acc = 0.9641360037261295\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 296, train_loss = 16.128057132475078, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 297, train_loss = 16.11194583028555, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 298, train_loss = 16.100317194126546, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 299, train_loss = 16.082964495755732, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 300, train_loss = 16.069785612635314, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 301, train_loss = 16.052434948273003, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 302, train_loss = 16.041250652633607, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 303, train_loss = 16.023531113751233, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 304, train_loss = 16.008766357786953, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 305, train_loss = 15.996004473417997, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 306, train_loss = 15.979046329855919, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 307, train_loss = 15.968024826608598, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 308, train_loss = 15.95120311062783, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 309, train_loss = 15.939764086157084, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 310, train_loss = 15.922335634939373, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 311, train_loss = 15.911828316748142, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 312, train_loss = 15.894060902297497, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 313, train_loss = 15.883483263663948, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 314, train_loss = 15.867746184580028, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 315, train_loss = 15.857450649142265, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 316, train_loss = 15.839989890344441, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 317, train_loss = 15.830271678976715, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 318, train_loss = 15.814026993699372, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 319, train_loss = 15.803768779151142, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 320, train_loss = 15.787276498042047, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 321, train_loss = 15.777714870870113, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 322, train_loss = 15.760862625204027, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 323, train_loss = 15.750298831611872, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 324, train_loss = 15.735683522187173, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 325, train_loss = 15.72530345339328, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 326, train_loss = 15.709797571413219, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 327, train_loss = 15.700516603887081, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 328, train_loss = 15.684304900467396, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 329, train_loss = 15.674216005951166, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 330, train_loss = 15.662273860536516, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 331, train_loss = 15.646992045454681, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 332, train_loss = 15.636653144843876, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 333, train_loss = 15.622933444567025, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 334, train_loss = 15.611232158727944, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 335, train_loss = 15.600328273139894, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 336, train_loss = 15.585608377121389, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 337, train_loss = 15.576270050369203, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 338, train_loss = 15.559488943777978, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 339, train_loss = 15.551017951220274, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 340, train_loss = 15.535746686160564, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 341, train_loss = 15.527980123646557, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 342, train_loss = 15.511893331073225, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 343, train_loss = 15.503297876566648, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 344, train_loss = 15.492936571128666, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 345, train_loss = 15.477135912515223, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 346, train_loss = 15.469090214930475, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 347, train_loss = 15.454910327680409, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 348, train_loss = 15.443530130200088, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 349, train_loss = 15.435140516608953, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 350, train_loss = 15.420199205167592, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 351, train_loss = 15.40949685126543, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 352, train_loss = 15.397667930461466, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 353, train_loss = 15.388933911919594, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 354, train_loss = 15.37650601286441, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 355, train_loss = 15.36367695685476, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 356, train_loss = 15.353271602652967, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 357, train_loss = 15.341764918528497, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 358, train_loss = 15.33152586221695, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 359, train_loss = 15.322400354780257, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 360, train_loss = 15.310247638262808, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 361, train_loss = 15.303380254656076, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 362, train_loss = 15.289761519990861, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 363, train_loss = 15.28224949259311, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 364, train_loss = 15.267464053817093, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 365, train_loss = 15.258315954357386, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 366, train_loss = 15.25050004851073, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 367, train_loss = 15.241413899697363, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 368, train_loss = 15.227144498378038, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 369, train_loss = 15.21402018610388, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 370, train_loss = 15.20838153641671, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 371, train_loss = 15.19381541479379, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 372, train_loss = 15.183756098151207, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 373, train_loss = 15.17704555299133, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 374, train_loss = 15.161978501826525, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 375, train_loss = 15.156555245630443, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 376, train_loss = 15.142977594397962, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 377, train_loss = 15.133582256734371, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 378, train_loss = 15.124969955533743, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 379, train_loss = 15.116960489191115, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 380, train_loss = 15.103455728851259, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 381, train_loss = 15.094467115588486, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 382, train_loss = 15.08813040703535, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 383, train_loss = 15.079707353375852, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 384, train_loss = 15.06444609630853, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 385, train_loss = 15.055521931499243, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 386, train_loss = 15.048974145203829, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 387, train_loss = 15.037356627173722, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 388, train_loss = 15.031519171781838, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 389, train_loss = 15.023487326689065, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 390, train_loss = 15.008147821761668, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 391, train_loss = 14.99982387945056, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 392, train_loss = 14.990551460534334, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 393, train_loss = 14.980559956282377, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 394, train_loss = 14.977467556484044, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 395, train_loss = 14.967460731975734, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 396, train_loss = 14.95929578319192, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 397, train_loss = 14.945815826766193, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 398, train_loss = 14.942146323621273, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 399, train_loss = 14.927927392534912, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 400, train_loss = 14.923626339994371, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 401, train_loss = 14.91540805902332, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 402, train_loss = 14.901890437118709, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 403, train_loss = 14.896973751485348, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 404, train_loss = 14.884445424191654, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 405, train_loss = 14.879266167990863, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 406, train_loss = 14.871619773097336, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 407, train_loss = 14.857067868113518, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 408, train_loss = 14.849623780697584, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 409, train_loss = 14.841409566812217, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 410, train_loss = 14.83836901653558, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 411, train_loss = 14.828431730158627, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 412, train_loss = 14.821396152488887, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 413, train_loss = 14.8085824130103, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 414, train_loss = 14.802813495509326, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 415, train_loss = 14.795854621566832, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 416, train_loss = 14.788791141472757, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 417, train_loss = 14.77836262434721, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 418, train_loss = 14.76593257393688, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 419, train_loss = 14.759600277990103, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 420, train_loss = 14.754813029430807, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 421, train_loss = 14.747192720882595, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 422, train_loss = 14.739091443829238, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 423, train_loss = 14.731734119355679, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 424, train_loss = 14.719332211650908, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 425, train_loss = 14.715062665753067, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 426, train_loss = 14.707567502744496, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 427, train_loss = 14.698232590220869, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 428, train_loss = 14.688060227781534, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 429, train_loss = 14.6839281572029, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 430, train_loss = 14.676760972477496, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 431, train_loss = 14.665665249340236, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 432, train_loss = 14.661126293241978, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 433, train_loss = 14.652055247686803, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 434, train_loss = 14.645915992558002, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 435, train_loss = 14.638378248549998, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 436, train_loss = 14.630640867166221, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 437, train_loss = 14.622992303222418, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 438, train_loss = 14.612389456480742, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 439, train_loss = 14.608322441577911, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 440, train_loss = 14.597713641822338, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 441, train_loss = 14.593331246636808, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 442, train_loss = 14.586480554193258, train_acc = 0.9670470423847228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 443, train_loss = 14.575428976677358, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 444, train_loss = 14.568429501261562, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 445, train_loss = 14.558164382819086, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 446, train_loss = 14.552990046795458, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 447, train_loss = 14.544590223580599, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 448, train_loss = 14.538207177072763, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 449, train_loss = 14.531210780143738, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 450, train_loss = 14.524324644356966, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 451, train_loss = 14.516186331864446, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 452, train_loss = 14.510386834386736, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 453, train_loss = 14.50215537333861, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 454, train_loss = 14.495289651211351, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 455, train_loss = 14.489497523754835, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 456, train_loss = 14.485835792962462, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 457, train_loss = 14.475590610411018, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 458, train_loss = 14.468203464057297, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 459, train_loss = 14.464704172220081, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 460, train_loss = 14.457166211213917, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 461, train_loss = 14.45021952688694, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 462, train_loss = 14.438316319137812, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 463, train_loss = 14.431702545378357, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 464, train_loss = 14.425293625798076, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 465, train_loss = 14.418946169316769, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 466, train_loss = 14.411280809435993, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 467, train_loss = 14.404284955468029, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 468, train_loss = 14.399399322923273, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 469, train_loss = 14.390668895095587, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 470, train_loss = 14.386130762752146, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 471, train_loss = 14.382445850875229, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 472, train_loss = 14.37404957273975, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 473, train_loss = 14.366828935686499, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 474, train_loss = 14.359304512385279, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 475, train_loss = 14.354205146431923, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 476, train_loss = 14.346229769289494, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 477, train_loss = 14.344698399305344, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 478, train_loss = 14.33186611533165, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 479, train_loss = 14.327098444104195, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 480, train_loss = 14.325300195720047, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 481, train_loss = 14.320876315236092, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 482, train_loss = 14.307023274246603, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 483, train_loss = 14.302060493733734, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 484, train_loss = 14.299851041287184, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 485, train_loss = 14.291093294974416, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 486, train_loss = 14.287286378443241, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 487, train_loss = 14.278115165885538, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 488, train_loss = 14.270208338741213, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 489, train_loss = 14.264273187611252, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 490, train_loss = 14.258113263640553, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 491, train_loss = 14.258020753506571, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 492, train_loss = 14.247743559535593, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 493, train_loss = 14.245945124421269, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 494, train_loss = 14.23993526911363, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 495, train_loss = 14.228116208221763, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 496, train_loss = 14.222447683569044, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 497, train_loss = 14.217285743448883, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 498, train_loss = 14.21277667582035, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 499, train_loss = 14.209193421062082, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████▋                       | 20/30 [2:13:01<1:06:21, 398.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "21th- epoch: 0, train_loss = 267.89991676807404, train_acc = 0.41779226828132277\n",
      "test Acc 0.4888268156424581:\n",
      "21th- epoch: 1, train_loss = 213.13205754756927, train_acc = 0.49534233814625056\n",
      "test Acc 0.49813780260707635:\n",
      "21th- epoch: 2, train_loss = 182.18854641914368, train_acc = 0.5071029343269678\n",
      "test Acc 0.5195530726256983:\n",
      "21th- epoch: 3, train_loss = 165.21413892507553, train_acc = 0.5353982300884956\n",
      "test Acc 0.5605214152700186:\n",
      "21th- epoch: 4, train_loss = 152.7917833328247, train_acc = 0.5754541220307405\n",
      "test Acc 0.6014897579143389:\n",
      "21th- epoch: 5, train_loss = 141.81698727607727, train_acc = 0.6125989753143922\n",
      "test Acc 0.6322160148975792:\n",
      "21th- epoch: 6, train_loss = 131.31930375099182, train_acc = 0.6414764788076386\n",
      "test Acc 0.6527001862197392:\n",
      "21th- epoch: 7, train_loss = 121.2741562128067, train_acc = 0.6884024219841639\n",
      "test Acc 0.7574487895716946:\n",
      "21th- epoch: 8, train_loss = 111.83666205406189, train_acc = 0.7649045179319981\n",
      "test Acc 0.7821229050279329:\n",
      "21th- epoch: 9, train_loss = 103.1306004524231, train_acc = 0.7870284117373079\n",
      "test Acc 0.8040037243947858:\n",
      "21th- epoch: 10, train_loss = 95.24799239635468, train_acc = 0.8093851886353051\n",
      "test Acc 0.8202979515828678:\n",
      "21th- epoch: 11, train_loss = 88.19257447123528, train_acc = 0.8263856544014905\n",
      "test Acc 0.8347299813780261:\n",
      "21th- epoch: 12, train_loss = 81.98989808559418, train_acc = 0.8387284583139264\n",
      "test Acc 0.8528864059590316:\n",
      "21th- epoch: 13, train_loss = 76.57277938723564, train_acc = 0.8500232883092688\n",
      "test Acc 0.8603351955307262:\n",
      "21th- epoch: 14, train_loss = 71.849112033844, train_acc = 0.8565440149045179\n",
      "test Acc 0.8654562383612663:\n",
      "21th- epoch: 15, train_loss = 67.7379951775074, train_acc = 0.8635305076851421\n",
      "test Acc 0.8696461824953445:\n",
      "21th- epoch: 16, train_loss = 64.15355259180069, train_acc = 0.8692361434559851\n",
      "test Acc 0.8729050279329609:\n",
      "21th- epoch: 17, train_loss = 61.01851573586464, train_acc = 0.8722636236609222\n",
      "test Acc 0.8803538175046555:\n",
      "21th- epoch: 18, train_loss = 58.270691603422165, train_acc = 0.878085700978109\n",
      "test Acc 0.8850093109869647:\n",
      "21th- epoch: 19, train_loss = 55.86091071367264, train_acc = 0.8814625058220773\n",
      "test Acc 0.8891992551210428:\n",
      "21th- epoch: 20, train_loss = 53.740761533379555, train_acc = 0.8841406613879832\n",
      "test Acc 0.8919925512104283:\n",
      "21th- epoch: 21, train_loss = 51.86444666981697, train_acc = 0.8876339077782953\n",
      "test Acc 0.8961824953445066:\n",
      "21th- epoch: 22, train_loss = 50.197209253907204, train_acc = 0.8908942710759199\n",
      "test Acc 0.8985102420856611:\n",
      "21th- epoch: 23, train_loss = 48.709421917796135, train_acc = 0.8954354913833256\n",
      "test Acc 0.9017690875232774:\n",
      "21th- epoch: 24, train_loss = 47.37438824772835, train_acc = 0.8986958546809501\n",
      "test Acc 0.9036312849162011:\n",
      "21th- epoch: 25, train_loss = 46.17013965547085, train_acc = 0.9003260363297625\n",
      "test Acc 0.9054934823091247:\n",
      "21th- epoch: 26, train_loss = 45.078332141041756, train_acc = 0.9014904517931999\n",
      "test Acc 0.9054934823091247:\n",
      "21th- epoch: 27, train_loss = 44.08407552540302, train_acc = 0.9028877503493247\n",
      "test Acc 0.9050279329608939:\n",
      "21th- epoch: 28, train_loss = 43.172831535339355, train_acc = 0.9048672566371682\n",
      "test Acc 0.9073556797020484:\n",
      "21th- epoch: 29, train_loss = 42.33234749734402, train_acc = 0.9064974382859804\n",
      "test Acc 0.9082867783985102:\n",
      "21th- epoch: 30, train_loss = 41.55276010930538, train_acc = 0.9083605030274802\n",
      "test Acc 0.909217877094972:\n",
      "21th- epoch: 31, train_loss = 40.8279612660408, train_acc = 0.9097578015836051\n",
      "test Acc 0.9110800744878957:\n",
      "21th- epoch: 32, train_loss = 40.15255318582058, train_acc = 0.911504424778761\n",
      "test Acc 0.9124767225325885:\n",
      "21th- epoch: 33, train_loss = 39.520251750946045, train_acc = 0.9133674895202608\n",
      "test Acc 0.9129422718808193:\n",
      "21th- epoch: 34, train_loss = 38.92647984623909, train_acc = 0.9153469958081043\n",
      "test Acc 0.9134078212290503:\n",
      "21th- epoch: 35, train_loss = 38.36651776731014, train_acc = 0.9170936190032604\n",
      "test Acc 0.9152700186219739:\n",
      "21th- epoch: 36, train_loss = 37.83732968568802, train_acc = 0.918141592920354\n",
      "test Acc 0.9162011173184358:\n",
      "21th- epoch: 37, train_loss = 37.33561632037163, train_acc = 0.9191895668374476\n",
      "test Acc 0.9166666666666666:\n",
      "21th- epoch: 38, train_loss = 36.85873168706894, train_acc = 0.9205868653935724\n",
      "test Acc 0.9171322160148976:\n",
      "21th- epoch: 39, train_loss = 36.40596753358841, train_acc = 0.922566371681416\n",
      "test Acc 0.9175977653631285:\n",
      "21th- epoch: 40, train_loss = 35.974345460534096, train_acc = 0.9230321378667908\n",
      "test Acc 0.9189944134078212:\n",
      "21th- epoch: 41, train_loss = 35.56225956976414, train_acc = 0.9236143455985095\n",
      "test Acc 0.9213221601489758:\n",
      "21th- epoch: 42, train_loss = 35.16835764050484, train_acc = 0.9243129948765719\n",
      "test Acc 0.9217877094972067:\n",
      "21th- epoch: 43, train_loss = 34.79064667969942, train_acc = 0.9247787610619469\n",
      "test Acc 0.9231843575418994:\n",
      "21th- epoch: 44, train_loss = 34.42817445099354, train_acc = 0.9254774103400093\n",
      "test Acc 0.9241154562383612:\n",
      "21th- epoch: 45, train_loss = 34.079315058887005, train_acc = 0.926059618071728\n",
      "test Acc 0.9241154562383612:\n",
      "21th- epoch: 46, train_loss = 33.742920473217964, train_acc = 0.9264089427107592\n",
      "test Acc 0.9241154562383612:\n",
      "21th- epoch: 47, train_loss = 33.41911914199591, train_acc = 0.9264089427107592\n",
      "test Acc 0.9250465549348231:\n",
      "21th- epoch: 48, train_loss = 33.10663461685181, train_acc = 0.927806241266884\n",
      "test Acc 0.925512104283054:\n",
      "21th- epoch: 49, train_loss = 32.804196156561375, train_acc = 0.9281555659059152\n",
      "test Acc 0.925512104283054:\n",
      "21th- epoch: 50, train_loss = 32.512261904776096, train_acc = 0.9287377736376339\n",
      "test Acc 0.9259776536312849:\n",
      "21th- epoch: 51, train_loss = 32.22956845164299, train_acc = 0.9295528644620401\n",
      "test Acc 0.9269087523277467:\n",
      "21th- epoch: 52, train_loss = 31.954918280243874, train_acc = 0.9301350721937587\n",
      "test Acc 0.9269087523277467:\n",
      "21th- epoch: 53, train_loss = 31.689169570803642, train_acc = 0.9309501630181649\n",
      "test Acc 0.9269087523277467:\n",
      "21th- epoch: 54, train_loss = 31.431139521300793, train_acc = 0.9312994876571961\n",
      "test Acc 0.9269087523277467:\n",
      "21th- epoch: 55, train_loss = 31.180234745144844, train_acc = 0.9314159292035398\n",
      "test Acc 0.9273743016759777:\n",
      "21th- epoch: 56, train_loss = 30.936159074306488, train_acc = 0.9315323707498836\n",
      "test Acc 0.9273743016759777:\n",
      "21th- epoch: 57, train_loss = 30.6984588727355, train_acc = 0.9314159292035398\n",
      "test Acc 0.9273743016759777:\n",
      "21th- epoch: 58, train_loss = 30.46712237596512, train_acc = 0.9321145784816023\n",
      "test Acc 0.9278398510242085:\n",
      "21th- epoch: 59, train_loss = 30.241612941026688, train_acc = 0.9326967862133209\n",
      "test Acc 0.9278398510242085:\n",
      "21th- epoch: 60, train_loss = 30.021794192492962, train_acc = 0.9330461108523521\n",
      "test Acc 0.9278398510242085:\n",
      "21th- epoch: 61, train_loss = 29.80754642188549, train_acc = 0.9335118770377271\n",
      "test Acc 0.9278398510242085:\n",
      "21th- epoch: 62, train_loss = 29.598409585654736, train_acc = 0.9336283185840708\n",
      "test Acc 0.9278398510242085:\n",
      "21th- epoch: 63, train_loss = 29.394904650747776, train_acc = 0.933977643223102\n",
      "test Acc 0.9283054003724395:\n",
      "21th- epoch: 64, train_loss = 29.195003286004066, train_acc = 0.9343269678621332\n",
      "test Acc 0.9283054003724395:\n",
      "21th- epoch: 65, train_loss = 28.999180875718594, train_acc = 0.9345598509548206\n",
      "test Acc 0.9287709497206704:\n",
      "21th- epoch: 66, train_loss = 28.807493545114994, train_acc = 0.9349091755938519\n",
      "test Acc 0.9283054003724395:\n",
      "21th- epoch: 67, train_loss = 28.620043702423573, train_acc = 0.9354913833255706\n",
      "test Acc 0.9283054003724395:\n",
      "21th- epoch: 68, train_loss = 28.436631806194782, train_acc = 0.935724266418258\n",
      "test Acc 0.9283054003724395:\n",
      "21th- epoch: 69, train_loss = 28.256922721862793, train_acc = 0.935724266418258\n",
      "test Acc 0.9283054003724395:\n",
      "21th- epoch: 70, train_loss = 28.080464489758015, train_acc = 0.9363064741499767\n",
      "test Acc 0.9287709497206704:\n",
      "21th- epoch: 71, train_loss = 27.9075867831707, train_acc = 0.9365393572426641\n",
      "test Acc 0.9292364990689013:\n",
      "21th- epoch: 72, train_loss = 27.738041318953037, train_acc = 0.9365393572426641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9297020484171322:\n",
      "21th- epoch: 73, train_loss = 27.572047621011734, train_acc = 0.9371215649743828\n",
      "test Acc 0.9297020484171322:\n",
      "21th- epoch: 74, train_loss = 27.409209117293358, train_acc = 0.9374708896134141\n",
      "test Acc 0.9297020484171322:\n",
      "21th- epoch: 75, train_loss = 27.24956103414297, train_acc = 0.9378202142524453\n",
      "test Acc 0.9297020484171322:\n",
      "21th- epoch: 76, train_loss = 27.09265821427107, train_acc = 0.9384024219841639\n",
      "test Acc 0.9301675977653632:\n",
      "21th- epoch: 77, train_loss = 26.937776871025562, train_acc = 0.9388681881695389\n",
      "test Acc 0.931098696461825:\n",
      "21th- epoch: 78, train_loss = 26.78665778785944, train_acc = 0.9391010712622264\n",
      "test Acc 0.931098696461825:\n",
      "21th- epoch: 79, train_loss = 26.638085678219795, train_acc = 0.939683278993945\n",
      "test Acc 0.931098696461825:\n",
      "21th- epoch: 80, train_loss = 26.492220133543015, train_acc = 0.9402654867256637\n",
      "test Acc 0.9315642458100558:\n",
      "21th- epoch: 81, train_loss = 26.34870856255293, train_acc = 0.9403819282720075\n",
      "test Acc 0.9324953445065177:\n",
      "21th- epoch: 82, train_loss = 26.207838397473097, train_acc = 0.9404983698183512\n",
      "test Acc 0.9324953445065177:\n",
      "21th- epoch: 83, train_loss = 26.068975511938334, train_acc = 0.9409641360037261\n",
      "test Acc 0.9329608938547486:\n",
      "21th- epoch: 84, train_loss = 25.932653207331896, train_acc = 0.9409641360037261\n",
      "test Acc 0.9334264432029795:\n",
      "21th- epoch: 85, train_loss = 25.79903283715248, train_acc = 0.9413134606427573\n",
      "test Acc 0.9334264432029795:\n",
      "21th- epoch: 86, train_loss = 25.66808196529746, train_acc = 0.941895668374476\n",
      "test Acc 0.9338919925512105:\n",
      "21th- epoch: 87, train_loss = 25.540089059621096, train_acc = 0.942361434559851\n",
      "test Acc 0.9338919925512105:\n",
      "21th- epoch: 88, train_loss = 25.413748182356358, train_acc = 0.9427107591988821\n",
      "test Acc 0.9338919925512105:\n",
      "21th- epoch: 89, train_loss = 25.289918463677168, train_acc = 0.9429436422915697\n",
      "test Acc 0.9338919925512105:\n",
      "21th- epoch: 90, train_loss = 25.168243687599897, train_acc = 0.9432929669306008\n",
      "test Acc 0.9348230912476723:\n",
      "21th- epoch: 91, train_loss = 25.048793949186802, train_acc = 0.9436422915696321\n",
      "test Acc 0.9352886405959032:\n",
      "21th- epoch: 92, train_loss = 24.931952863931656, train_acc = 0.9438751746623195\n",
      "test Acc 0.9352886405959032:\n",
      "21th- epoch: 93, train_loss = 24.81688080355525, train_acc = 0.9442244993013508\n",
      "test Acc 0.9348230912476723:\n",
      "21th- epoch: 94, train_loss = 24.70405126363039, train_acc = 0.9444573823940382\n",
      "test Acc 0.9348230912476723:\n",
      "21th- epoch: 95, train_loss = 24.592847131192684, train_acc = 0.9444573823940382\n",
      "test Acc 0.9352886405959032:\n",
      "21th- epoch: 96, train_loss = 24.483594082295895, train_acc = 0.9451560316721006\n",
      "test Acc 0.9352886405959032:\n",
      "21th- epoch: 97, train_loss = 24.376819774508476, train_acc = 0.9455053563111319\n",
      "test Acc 0.9352886405959032:\n",
      "21th- epoch: 98, train_loss = 24.2709742449224, train_acc = 0.9457382394038193\n",
      "test Acc 0.9352886405959032:\n",
      "21th- epoch: 99, train_loss = 24.167298775166273, train_acc = 0.9460875640428504\n",
      "test Acc 0.9352886405959032:\n",
      "21th- epoch: 100, train_loss = 24.064793925732374, train_acc = 0.9462040055891943\n",
      "test Acc 0.9352886405959032:\n",
      "21th- epoch: 101, train_loss = 23.964674256742, train_acc = 0.9464368886818817\n",
      "test Acc 0.9357541899441341:\n",
      "21th- epoch: 102, train_loss = 23.86590151116252, train_acc = 0.9465533302282254\n",
      "test Acc 0.9357541899441341:\n",
      "21th- epoch: 103, train_loss = 23.768706019967794, train_acc = 0.9465533302282254\n",
      "test Acc 0.936219739292365:\n",
      "21th- epoch: 104, train_loss = 23.672820139676332, train_acc = 0.9466697717745691\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 105, train_loss = 23.578321918845177, train_acc = 0.9469026548672567\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 106, train_loss = 23.48531709238887, train_acc = 0.9469026548672567\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 107, train_loss = 23.394244126975536, train_acc = 0.946786213320913\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 108, train_loss = 23.304429173469543, train_acc = 0.9470190964136004\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 109, train_loss = 23.2163024879992, train_acc = 0.9471355379599441\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 110, train_loss = 23.129080057144165, train_acc = 0.9471355379599441\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 111, train_loss = 23.043257150799036, train_acc = 0.9473684210526315\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 112, train_loss = 22.95854315161705, train_acc = 0.9476013041453191\n",
      "test Acc 0.9366852886405959:\n",
      "21th- epoch: 113, train_loss = 22.87521940842271, train_acc = 0.9477177456916628\n",
      "test Acc 0.9366852886405959:\n",
      "21th- epoch: 114, train_loss = 22.793255299329758, train_acc = 0.9477177456916628\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 115, train_loss = 22.712409269064665, train_acc = 0.9479506287843502\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 116, train_loss = 22.63213660567999, train_acc = 0.9481835118770378\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 117, train_loss = 22.553107604384422, train_acc = 0.9481835118770378\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 118, train_loss = 22.4755052998662, train_acc = 0.9485328365160689\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 119, train_loss = 22.39910214021802, train_acc = 0.9487657196087564\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 120, train_loss = 22.323650188744068, train_acc = 0.9488821611551002\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 121, train_loss = 22.248944904655218, train_acc = 0.9489986027014439\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 122, train_loss = 22.175613917410374, train_acc = 0.9492314857941313\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 123, train_loss = 22.1029558442533, train_acc = 0.9493479273404751\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 124, train_loss = 22.03157563135028, train_acc = 0.9495808104331626\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 125, train_loss = 21.96079971641302, train_acc = 0.9495808104331626\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 126, train_loss = 21.891340769827366, train_acc = 0.94981369352585\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 127, train_loss = 21.822497747838497, train_acc = 0.94981369352585\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 128, train_loss = 21.75429479405284, train_acc = 0.9501630181648812\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 129, train_loss = 21.687234446406364, train_acc = 0.9506287843502562\n",
      "test Acc 0.9380819366852886:\n",
      "21th- epoch: 130, train_loss = 21.620945747941732, train_acc = 0.9507452258965999\n",
      "test Acc 0.9380819366852886:\n",
      "21th- epoch: 131, train_loss = 21.555437594652176, train_acc = 0.9508616674429436\n",
      "test Acc 0.9385474860335196:\n",
      "21th- epoch: 132, train_loss = 21.49039536714554, train_acc = 0.9508616674429436\n",
      "test Acc 0.9385474860335196:\n",
      "21th- epoch: 133, train_loss = 21.426725655794144, train_acc = 0.9510945505356311\n",
      "test Acc 0.9385474860335196:\n",
      "21th- epoch: 134, train_loss = 21.363804180175066, train_acc = 0.9513274336283186\n",
      "test Acc 0.9385474860335196:\n",
      "21th- epoch: 135, train_loss = 21.30119663849473, train_acc = 0.951560316721006\n",
      "test Acc 0.9385474860335196:\n",
      "21th- epoch: 136, train_loss = 21.23928025737405, train_acc = 0.9516767582673498\n",
      "test Acc 0.9390130353817505:\n",
      "21th- epoch: 137, train_loss = 21.17704325169325, train_acc = 0.9519096413600373\n",
      "test Acc 0.9394785847299814:\n",
      "21th- epoch: 138, train_loss = 21.11710410565138, train_acc = 0.952026082906381\n",
      "test Acc 0.9394785847299814:\n",
      "21th- epoch: 139, train_loss = 21.056504230946302, train_acc = 0.9522589659990685\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 140, train_loss = 20.996767535805702, train_acc = 0.952491849091756\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 141, train_loss = 20.938731770962477, train_acc = 0.9526082906380997\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 142, train_loss = 20.88056803494692, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 143, train_loss = 20.82338782772422, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 144, train_loss = 20.76694217324257, train_acc = 0.9528411737307871\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 145, train_loss = 20.71109839528799, train_acc = 0.9528411737307871\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 146, train_loss = 20.65530689433217, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 147, train_loss = 20.600825797766447, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 148, train_loss = 20.54543878696859, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 149, train_loss = 20.49191806279123, train_acc = 0.9534233814625058\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 150, train_loss = 20.439336584880948, train_acc = 0.9536562645551933\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 151, train_loss = 20.387319542467594, train_acc = 0.9540055891942245\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 152, train_loss = 20.335159620270133, train_acc = 0.9542384722869119\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 153, train_loss = 20.282856779173017, train_acc = 0.9543549138332557\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 154, train_loss = 20.231455458328128, train_acc = 0.9543549138332557\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 155, train_loss = 20.18056952394545, train_acc = 0.9543549138332557\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 156, train_loss = 20.131232595071197, train_acc = 0.9543549138332557\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 157, train_loss = 20.08209573291242, train_acc = 0.9544713553795995\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 158, train_loss = 20.033130696043372, train_acc = 0.9545877969259432\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 159, train_loss = 19.984678341075778, train_acc = 0.9547042384722869\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 160, train_loss = 19.936887940391898, train_acc = 0.9547042384722869\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 161, train_loss = 19.8889932744205, train_acc = 0.9548206800186306\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 162, train_loss = 19.84117455780506, train_acc = 0.9547042384722869\n",
      "test Acc 0.9408752327746741:\n",
      "21th- epoch: 163, train_loss = 19.795450903475285, train_acc = 0.9547042384722869\n",
      "test Acc 0.9408752327746741:\n",
      "21th- epoch: 164, train_loss = 19.749204581603408, train_acc = 0.9547042384722869\n",
      "test Acc 0.9408752327746741:\n",
      "21th- epoch: 165, train_loss = 19.70411472953856, train_acc = 0.9548206800186306\n",
      "test Acc 0.9408752327746741:\n",
      "21th- epoch: 166, train_loss = 19.659090330824256, train_acc = 0.9550535631113182\n",
      "test Acc 0.9408752327746741:\n",
      "21th- epoch: 167, train_loss = 19.61468697525561, train_acc = 0.9550535631113182\n",
      "test Acc 0.9408752327746741:\n",
      "21th- epoch: 168, train_loss = 19.569133950397372, train_acc = 0.9551700046576619\n",
      "test Acc 0.9408752327746741:\n",
      "21th- epoch: 169, train_loss = 19.525898246094584, train_acc = 0.9552864462040056\n",
      "test Acc 0.9408752327746741:\n",
      "21th- epoch: 170, train_loss = 19.482281897217035, train_acc = 0.9552864462040056\n",
      "test Acc 0.9418063314711359:\n",
      "21th- epoch: 171, train_loss = 19.43896390683949, train_acc = 0.9552864462040056\n",
      "test Acc 0.9418063314711359:\n",
      "21th- epoch: 172, train_loss = 19.39681979827583, train_acc = 0.9556357708430367\n",
      "test Acc 0.9418063314711359:\n",
      "21th- epoch: 173, train_loss = 19.3543857652694, train_acc = 0.9557522123893806\n",
      "test Acc 0.9418063314711359:\n",
      "21th- epoch: 174, train_loss = 19.312291426584125, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "21th- epoch: 175, train_loss = 19.27172549813986, train_acc = 0.9561015370284117\n",
      "test Acc 0.9427374301675978:\n",
      "21th- epoch: 176, train_loss = 19.230123510584235, train_acc = 0.9562179785747554\n",
      "test Acc 0.9427374301675978:\n",
      "21th- epoch: 177, train_loss = 19.189659705385566, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "21th- epoch: 178, train_loss = 19.149320786818862, train_acc = 0.956450861667443\n",
      "test Acc 0.9427374301675978:\n",
      "21th- epoch: 179, train_loss = 19.109505485743284, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "21th- epoch: 180, train_loss = 19.069291906431317, train_acc = 0.956450861667443\n",
      "test Acc 0.9427374301675978:\n",
      "21th- epoch: 181, train_loss = 19.03030971623957, train_acc = 0.9565673032137867\n",
      "test Acc 0.9427374301675978:\n",
      "21th- epoch: 182, train_loss = 18.991925006732345, train_acc = 0.9565673032137867\n",
      "test Acc 0.9427374301675978:\n",
      "21th- epoch: 183, train_loss = 18.952540554106236, train_acc = 0.9568001863064741\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 184, train_loss = 18.9152960665524, train_acc = 0.9570330693991617\n",
      "test Acc 0.9427374301675978:\n",
      "21th- epoch: 185, train_loss = 18.8776716273278, train_acc = 0.9570330693991617\n",
      "test Acc 0.9427374301675978:\n",
      "21th- epoch: 186, train_loss = 18.83903518691659, train_acc = 0.9571495109455054\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 187, train_loss = 18.80093669332564, train_acc = 0.9573823940381928\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 188, train_loss = 18.764365019276738, train_acc = 0.9574988355845365\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 189, train_loss = 18.727443350479007, train_acc = 0.9574988355845365\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 190, train_loss = 18.690942384302616, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 191, train_loss = 18.654869275167584, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 192, train_loss = 18.619739957153797, train_acc = 0.9577317186772241\n",
      "test Acc 0.9441340782122905:\n",
      "21th- epoch: 193, train_loss = 18.58491250127554, train_acc = 0.9580810433162552\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 194, train_loss = 18.54900518618524, train_acc = 0.9580810433162552\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 195, train_loss = 18.51485644839704, train_acc = 0.9580810433162552\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 196, train_loss = 18.48143626563251, train_acc = 0.9580810433162552\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 197, train_loss = 18.446891201660037, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 198, train_loss = 18.413929229602218, train_acc = 0.9585468095016302\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 199, train_loss = 18.37988928332925, train_acc = 0.9587796925943176\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 200, train_loss = 18.346689285710454, train_acc = 0.9587796925943176\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 201, train_loss = 18.314311226829886, train_acc = 0.9587796925943176\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 202, train_loss = 18.281654063612223, train_acc = 0.9588961341406614\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 203, train_loss = 18.2483759727329, train_acc = 0.9588961341406614\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 204, train_loss = 18.216301439329982, train_acc = 0.9588961341406614\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 205, train_loss = 18.18431281298399, train_acc = 0.9591290172333489\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 206, train_loss = 18.15367359481752, train_acc = 0.9592454587796926\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 207, train_loss = 18.12190233170986, train_acc = 0.95947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 208, train_loss = 18.091687189415097, train_acc = 0.95947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 209, train_loss = 18.061005039140582, train_acc = 0.95947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "21th- epoch: 210, train_loss = 18.03011597134173, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "21th- epoch: 211, train_loss = 17.999264534562826, train_acc = 0.9595947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "21th- epoch: 212, train_loss = 17.969509856775403, train_acc = 0.9597112249650676\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 213, train_loss = 17.939783411100507, train_acc = 0.9598276665114113\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 214, train_loss = 17.91100462153554, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 215, train_loss = 17.88154268823564, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 216, train_loss = 17.853555265814066, train_acc = 0.959944108057755\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 217, train_loss = 17.824154226109385, train_acc = 0.959944108057755\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 218, train_loss = 17.796390064060688, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 219, train_loss = 17.767694015055895, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 220, train_loss = 17.740858441218734, train_acc = 0.959944108057755\n",
      "test Acc 0.9473929236499069:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 221, train_loss = 17.71184661798179, train_acc = 0.959944108057755\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 222, train_loss = 17.68477621115744, train_acc = 0.9600605496040987\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 223, train_loss = 17.65768091380596, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 224, train_loss = 17.631962383165956, train_acc = 0.9601769911504425\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 225, train_loss = 17.6048002820462, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 226, train_loss = 17.578817712143064, train_acc = 0.9605263157894737\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 227, train_loss = 17.55199840851128, train_acc = 0.9605263157894737\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 228, train_loss = 17.525153847411275, train_acc = 0.9606427573358174\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 229, train_loss = 17.498958561569452, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 230, train_loss = 17.473282819613814, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 231, train_loss = 17.44770596548915, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 232, train_loss = 17.423170275054872, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 233, train_loss = 17.3979964395985, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 234, train_loss = 17.37297189515084, train_acc = 0.9607591988821611\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 235, train_loss = 17.348865292035043, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 236, train_loss = 17.32414152380079, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 237, train_loss = 17.299319592304528, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 238, train_loss = 17.27560470625758, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 239, train_loss = 17.253020722419024, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 240, train_loss = 17.228448946028948, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 241, train_loss = 17.204669998027384, train_acc = 0.9612249650675361\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 242, train_loss = 17.18204020243138, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 243, train_loss = 17.159086298197508, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 244, train_loss = 17.135492437519133, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 245, train_loss = 17.113062188960612, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 246, train_loss = 17.089840463362634, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 247, train_loss = 17.067755124531686, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 248, train_loss = 17.044915922917426, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 249, train_loss = 17.02304754126817, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 250, train_loss = 17.001240097917616, train_acc = 0.961690731252911\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 251, train_loss = 16.979367253370583, train_acc = 0.961690731252911\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 252, train_loss = 16.95823350455612, train_acc = 0.961690731252911\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 253, train_loss = 16.93638544064015, train_acc = 0.961690731252911\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 254, train_loss = 16.915943760424852, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 255, train_loss = 16.89540837984532, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 256, train_loss = 16.87354331742972, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 257, train_loss = 16.852540493942797, train_acc = 0.9619236143455985\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 258, train_loss = 16.831406391225755, train_acc = 0.9619236143455985\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 259, train_loss = 16.81087542977184, train_acc = 0.9619236143455985\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 260, train_loss = 16.79043739568442, train_acc = 0.9620400558919422\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 261, train_loss = 16.77028228249401, train_acc = 0.9622729389846297\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 262, train_loss = 16.749800316989422, train_acc = 0.9623893805309734\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 263, train_loss = 16.73106527607888, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 264, train_loss = 16.711846659891307, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 265, train_loss = 16.691854673437774, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 266, train_loss = 16.671897619962692, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 267, train_loss = 16.65371120441705, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 268, train_loss = 16.63323118444532, train_acc = 0.9627387051700047\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 269, train_loss = 16.615032660774887, train_acc = 0.9627387051700047\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 270, train_loss = 16.5968580506742, train_acc = 0.9627387051700047\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 271, train_loss = 16.578001690097153, train_acc = 0.9628551467163484\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 272, train_loss = 16.55872453842312, train_acc = 0.9628551467163484\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 273, train_loss = 16.538872580975294, train_acc = 0.9628551467163484\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 274, train_loss = 16.521651373244822, train_acc = 0.9628551467163484\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 275, train_loss = 16.503386713564396, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 276, train_loss = 16.484279085882008, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 277, train_loss = 16.468046206980944, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 278, train_loss = 16.4499399587512, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 279, train_loss = 16.431489744223654, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 280, train_loss = 16.41374766547233, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 281, train_loss = 16.39667047187686, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 282, train_loss = 16.378352742642164, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 283, train_loss = 16.36108887102455, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 284, train_loss = 16.34470370505005, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 285, train_loss = 16.32690019160509, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 286, train_loss = 16.309761873446405, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 287, train_loss = 16.29348590876907, train_acc = 0.9636702375407545\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 288, train_loss = 16.276549749076366, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 289, train_loss = 16.26083809044212, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 290, train_loss = 16.243086385540664, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 291, train_loss = 16.226919041015208, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 292, train_loss = 16.210579223930836, train_acc = 0.9637866790870983\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 293, train_loss = 16.194159283302724, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 294, train_loss = 16.17833134997636, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 295, train_loss = 16.161550247110426, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 296, train_loss = 16.145570154301822, train_acc = 0.9640195621797858\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 297, train_loss = 16.12952545005828, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 298, train_loss = 16.114634681493044, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 299, train_loss = 16.100392206571996, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 300, train_loss = 16.083696119487286, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 301, train_loss = 16.067903887480497, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 302, train_loss = 16.05288179218769, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 303, train_loss = 16.03771549835801, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 304, train_loss = 16.022460486739874, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 305, train_loss = 16.007640916854143, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 306, train_loss = 15.993301977403462, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 307, train_loss = 15.978711345233023, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 308, train_loss = 15.963631595484912, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 309, train_loss = 15.948607605881989, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 310, train_loss = 15.934398687444627, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 311, train_loss = 15.920388423837721, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 312, train_loss = 15.905059316195548, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 313, train_loss = 15.890423312783241, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 314, train_loss = 15.877458557486534, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 315, train_loss = 15.863231706432998, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 316, train_loss = 15.84834152739495, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 317, train_loss = 15.835102173499763, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 318, train_loss = 15.82005304004997, train_acc = 0.9648346530041919\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 319, train_loss = 15.807284992188215, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 320, train_loss = 15.791511516086757, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 321, train_loss = 15.779535695910454, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 322, train_loss = 15.766809437423944, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 323, train_loss = 15.75314021576196, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 324, train_loss = 15.737213748507202, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 325, train_loss = 15.72723238542676, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 326, train_loss = 15.713513866998255, train_acc = 0.9649510945505356\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 327, train_loss = 15.698072049766779, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 328, train_loss = 15.685066845268011, train_acc = 0.9650675360968793\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 329, train_loss = 15.671963516622782, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 330, train_loss = 15.65752697456628, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 331, train_loss = 15.646457183174789, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 332, train_loss = 15.634245767258108, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 333, train_loss = 15.62010096386075, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 334, train_loss = 15.60654054954648, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 335, train_loss = 15.59501254092902, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 336, train_loss = 15.582570523954928, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 337, train_loss = 15.570772677659988, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 338, train_loss = 15.559247019700706, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 339, train_loss = 15.546044458635151, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 340, train_loss = 15.534125925041735, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 341, train_loss = 15.520511555485427, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 342, train_loss = 15.50903717521578, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 343, train_loss = 15.49688519909978, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 344, train_loss = 15.484343186952174, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 345, train_loss = 15.4719797084108, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 346, train_loss = 15.462433191947639, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 347, train_loss = 15.448800981976092, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 348, train_loss = 15.43803736101836, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 349, train_loss = 15.42545469943434, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 350, train_loss = 15.416753995232284, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 351, train_loss = 15.401833743788302, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 352, train_loss = 15.39181147236377, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 353, train_loss = 15.382080436684191, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 354, train_loss = 15.367835438810289, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 355, train_loss = 15.358381384052336, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 356, train_loss = 15.347409815527499, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 357, train_loss = 15.334239856339991, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 358, train_loss = 15.325217223726213, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 359, train_loss = 15.312924814410508, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 360, train_loss = 15.302650965750217, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 361, train_loss = 15.293458670377731, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 362, train_loss = 15.281759518198669, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 363, train_loss = 15.271897033788264, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 364, train_loss = 15.257004282437265, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 365, train_loss = 15.24930203333497, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 366, train_loss = 15.23886609915644, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 367, train_loss = 15.225562620908022, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 368, train_loss = 15.215571059845388, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 369, train_loss = 15.20406583789736, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 370, train_loss = 15.194181584753096, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 371, train_loss = 15.184272003360093, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 372, train_loss = 15.175046316348016, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 373, train_loss = 15.163894259370863, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 374, train_loss = 15.153040130622685, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 375, train_loss = 15.143442064523697, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 376, train_loss = 15.137554912827909, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 377, train_loss = 15.123505093157291, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 378, train_loss = 15.112241878174245, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 379, train_loss = 15.101903025060892, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 380, train_loss = 15.093077019788325, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 381, train_loss = 15.08250944595784, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 382, train_loss = 15.07603209093213, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 383, train_loss = 15.063342752866447, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 384, train_loss = 15.05788781028241, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 385, train_loss = 15.047824216075242, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 386, train_loss = 15.03814957011491, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 387, train_loss = 15.028318326920271, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 388, train_loss = 15.018671465106308, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 389, train_loss = 15.009399086236954, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 390, train_loss = 14.995469366200268, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 391, train_loss = 14.986654874868691, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 392, train_loss = 14.9791637994349, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 393, train_loss = 14.971744420938194, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 394, train_loss = 14.958791897632182, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 395, train_loss = 14.952807971276343, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 396, train_loss = 14.943793657235801, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 397, train_loss = 14.931122570298612, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 398, train_loss = 14.922512861900032, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 399, train_loss = 14.91461633425206, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 400, train_loss = 14.906318745575845, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 401, train_loss = 14.894119075499475, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 402, train_loss = 14.888840187340975, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 403, train_loss = 14.88079346343875, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 404, train_loss = 14.866602404974401, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 405, train_loss = 14.858957391232252, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 406, train_loss = 14.849878317676485, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 407, train_loss = 14.843272178433836, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 408, train_loss = 14.837016511708498, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 409, train_loss = 14.828822407871485, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 410, train_loss = 14.820291352458298, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 411, train_loss = 14.806429278105497, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 412, train_loss = 14.801015373319387, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 413, train_loss = 14.794017896987498, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 414, train_loss = 14.788347802124918, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 415, train_loss = 14.774475004523993, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 416, train_loss = 14.766798163764179, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 417, train_loss = 14.757606121711433, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 418, train_loss = 14.752653788775206, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 419, train_loss = 14.745217377785593, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 420, train_loss = 14.736330592539161, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 421, train_loss = 14.72940531373024, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 422, train_loss = 14.721621209289879, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 423, train_loss = 14.709391223732382, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 424, train_loss = 14.70051247999072, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 425, train_loss = 14.693698262330145, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 426, train_loss = 14.685779883060604, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 427, train_loss = 14.678113455418497, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 428, train_loss = 14.672528529074043, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 429, train_loss = 14.662676889449358, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 430, train_loss = 14.659525631461293, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 431, train_loss = 14.647373907268047, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 432, train_loss = 14.639958617743105, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 433, train_loss = 14.636450625956059, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 434, train_loss = 14.623069602996111, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 435, train_loss = 14.615558674093336, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "21th- epoch: 436, train_loss = 14.613290985580534, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 437, train_loss = 14.605616625398397, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 438, train_loss = 14.598239263985306, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 439, train_loss = 14.587665040045977, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 440, train_loss = 14.580016274005175, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 441, train_loss = 14.575984302908182, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 442, train_loss = 14.565300470683724, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 443, train_loss = 14.557112308684736, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 444, train_loss = 14.553780697286129, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 445, train_loss = 14.542611353099346, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 446, train_loss = 14.534535056445748, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 447, train_loss = 14.533044307027012, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 448, train_loss = 14.521187065634876, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 449, train_loss = 14.515150129795074, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 450, train_loss = 14.507989339530468, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 451, train_loss = 14.500466542784125, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 452, train_loss = 14.493571644183248, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 453, train_loss = 14.486759569495916, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 454, train_loss = 14.480159764643759, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 455, train_loss = 14.473349408712238, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 456, train_loss = 14.466256850864738, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 457, train_loss = 14.461518093943596, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "21th- epoch: 458, train_loss = 14.453355997800827, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "21th- epoch: 459, train_loss = 14.451475867535919, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 460, train_loss = 14.444706121925265, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 461, train_loss = 14.43296056240797, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 462, train_loss = 14.426216553896666, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 463, train_loss = 14.419540759176016, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 464, train_loss = 14.414952530059963, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 465, train_loss = 14.408882959280163, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 466, train_loss = 14.406553418841213, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 467, train_loss = 14.396659197751433, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 468, train_loss = 14.392557445913553, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 469, train_loss = 14.37957397988066, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 470, train_loss = 14.379010930657387, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 471, train_loss = 14.370487487409264, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 472, train_loss = 14.360903237015009, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 473, train_loss = 14.354838695377111, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 474, train_loss = 14.348341513425112, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 475, train_loss = 14.348107002675533, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 476, train_loss = 14.339136779308319, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 477, train_loss = 14.330707603599876, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 478, train_loss = 14.323691302444786, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 479, train_loss = 14.323576278984547, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 480, train_loss = 14.311220524366945, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 481, train_loss = 14.306895207613707, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 482, train_loss = 14.300082301255316, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 483, train_loss = 14.292350890580565, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 484, train_loss = 14.289770306553692, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 485, train_loss = 14.281606772448868, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 486, train_loss = 14.281323418021202, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 487, train_loss = 14.271157083567232, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 488, train_loss = 14.263551545795053, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 489, train_loss = 14.258703952189535, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 490, train_loss = 14.252281921450049, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 491, train_loss = 14.246384768281132, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 492, train_loss = 14.240721706300974, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 493, train_loss = 14.23648731643334, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 494, train_loss = 14.229658680502325, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 495, train_loss = 14.224550500512123, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 496, train_loss = 14.217263711150736, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 497, train_loss = 14.212235193699598, train_acc = 0.9686772240335352\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 498, train_loss = 14.204966629389673, train_acc = 0.9686772240335352\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 499, train_loss = 14.205305099487305, train_acc = 0.9686772240335352\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████▍                     | 21/30 [2:19:39<59:43, 398.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "22th- epoch: 0, train_loss = 273.5849093198776, train_acc = 0.43735444806707036\n",
      "test Acc 0.4962756052141527:\n",
      "22th- epoch: 1, train_loss = 214.03650844097137, train_acc = 0.4998835584536563\n",
      "test Acc 0.5:\n",
      "22th- epoch: 2, train_loss = 180.36017668247223, train_acc = 0.5030274802049371\n",
      "test Acc 0.505586592178771:\n",
      "22th- epoch: 3, train_loss = 165.23092997074127, train_acc = 0.5189799720540289\n",
      "test Acc 0.5349162011173184:\n",
      "22th- epoch: 4, train_loss = 153.63349670171738, train_acc = 0.5563577084303679\n",
      "test Acc 0.5837988826815642:\n",
      "22th- epoch: 5, train_loss = 143.19382864236832, train_acc = 0.6030507685142059\n",
      "test Acc 0.6187150837988827:\n",
      "22th- epoch: 6, train_loss = 133.2842394709587, train_acc = 0.6392640894271076\n",
      "test Acc 0.7113594040968343:\n",
      "22th- epoch: 7, train_loss = 123.85695332288742, train_acc = 0.6922449930135072\n",
      "test Acc 0.7239292364990689:\n",
      "22th- epoch: 8, train_loss = 115.05297130346298, train_acc = 0.7366092221704704\n",
      "test Acc 0.7518621973929237:\n",
      "22th- epoch: 9, train_loss = 106.9061284661293, train_acc = 0.7602468560782487\n",
      "test Acc 0.7760707635009311:\n",
      "22th- epoch: 10, train_loss = 99.42228776216507, train_acc = 0.7853982300884956\n",
      "test Acc 0.8016759776536313:\n",
      "22th- epoch: 11, train_loss = 92.59636092185974, train_acc = 0.8107824871914299\n",
      "test Acc 0.824487895716946:\n",
      "22th- epoch: 12, train_loss = 86.44249001145363, train_acc = 0.824406148113647\n",
      "test Acc 0.8319366852886406:\n",
      "22th- epoch: 13, train_loss = 80.92834517359734, train_acc = 0.8339543549138333\n",
      "test Acc 0.8477653631284916:\n",
      "22th- epoch: 14, train_loss = 76.02146753668785, train_acc = 0.8448998602701444\n",
      "test Acc 0.8570763500931099:\n",
      "22th- epoch: 15, train_loss = 71.67840135097504, train_acc = 0.8553795994410806\n",
      "test Acc 0.8626629422718808:\n",
      "22th- epoch: 16, train_loss = 67.846638828516, train_acc = 0.8624825337680484\n",
      "test Acc 0.8687150837988827:\n",
      "22th- epoch: 17, train_loss = 64.46268075704575, train_acc = 0.8665579878900792\n",
      "test Acc 0.8729050279329609:\n",
      "22th- epoch: 18, train_loss = 61.47858580946922, train_acc = 0.8688868188169538\n",
      "test Acc 0.8752327746741154:\n",
      "22th- epoch: 19, train_loss = 58.836977541446686, train_acc = 0.8740102468560782\n",
      "test Acc 0.88268156424581:\n",
      "22th- epoch: 20, train_loss = 56.48563066124916, train_acc = 0.8797158826269212\n",
      "test Acc 0.8868715083798883:\n",
      "22th- epoch: 21, train_loss = 54.38107417523861, train_acc = 0.882510479739171\n",
      "test Acc 0.8910614525139665:\n",
      "22th- epoch: 22, train_loss = 52.499527618288994, train_acc = 0.8850721937587331\n",
      "test Acc 0.8943202979515829:\n",
      "22th- epoch: 23, train_loss = 50.80767402052879, train_acc = 0.8889147647880764\n",
      "test Acc 0.8999068901303539:\n",
      "22th- epoch: 24, train_loss = 49.28121840953827, train_acc = 0.8959012575687005\n",
      "test Acc 0.9008379888268156:\n",
      "22th- epoch: 25, train_loss = 47.90276423096657, train_acc = 0.8981136469492315\n",
      "test Acc 0.9027001862197392:\n",
      "22th- epoch: 26, train_loss = 46.65483899414539, train_acc = 0.9005589194224499\n",
      "test Acc 0.904096834264432:\n",
      "22th- epoch: 27, train_loss = 45.517574578523636, train_acc = 0.9021891010712623\n",
      "test Acc 0.9050279329608939:\n",
      "22th- epoch: 28, train_loss = 44.478769183158875, train_acc = 0.9038192827200745\n",
      "test Acc 0.9064245810055865:\n",
      "22th- epoch: 29, train_loss = 43.52572497725487, train_acc = 0.9054494643688868\n",
      "test Acc 0.9087523277467412:\n",
      "22th- epoch: 30, train_loss = 42.64825177192688, train_acc = 0.9073125291103866\n",
      "test Acc 0.909683426443203:\n",
      "22th- epoch: 31, train_loss = 41.83620837330818, train_acc = 0.9087098276665114\n",
      "test Acc 0.9106145251396648:\n",
      "22th- epoch: 32, train_loss = 41.08172160387039, train_acc = 0.9103400093153237\n",
      "test Acc 0.9115456238361266:\n",
      "22th- epoch: 33, train_loss = 40.379022270441055, train_acc = 0.9122030740568234\n",
      "test Acc 0.9124767225325885:\n",
      "22th- epoch: 34, train_loss = 39.722345381975174, train_acc = 0.9142990218910108\n",
      "test Acc 0.9129422718808193:\n",
      "22th- epoch: 35, train_loss = 39.107131749391556, train_acc = 0.9161620866325105\n",
      "test Acc 0.9129422718808193:\n",
      "22th- epoch: 36, train_loss = 38.528131410479546, train_acc = 0.9169771774569166\n",
      "test Acc 0.914804469273743:\n",
      "22th- epoch: 37, train_loss = 37.98076370358467, train_acc = 0.9190731252911039\n",
      "test Acc 0.9162011173184358:\n",
      "22th- epoch: 38, train_loss = 37.4619534611702, train_acc = 0.9200046576618538\n",
      "test Acc 0.9171322160148976:\n",
      "22th- epoch: 39, train_loss = 36.96959410607815, train_acc = 0.9218677224033535\n",
      "test Acc 0.9162011173184358:\n",
      "22th- epoch: 40, train_loss = 36.500709265470505, train_acc = 0.922566371681416\n",
      "test Acc 0.9171322160148976:\n",
      "22th- epoch: 41, train_loss = 36.053807735443115, train_acc = 0.9236143455985095\n",
      "test Acc 0.9189944134078212:\n",
      "22th- epoch: 42, train_loss = 35.62521183490753, train_acc = 0.9240801117838845\n",
      "test Acc 0.9203910614525139:\n",
      "22th- epoch: 43, train_loss = 35.2161682844162, train_acc = 0.9245458779692595\n",
      "test Acc 0.9208566108007449:\n",
      "22th- epoch: 44, train_loss = 34.824826791882515, train_acc = 0.9250116441546343\n",
      "test Acc 0.9222532588454376:\n",
      "22th- epoch: 45, train_loss = 34.44964545965195, train_acc = 0.926059618071728\n",
      "test Acc 0.9231843575418994:\n",
      "22th- epoch: 46, train_loss = 34.089884378015995, train_acc = 0.9273404750815091\n",
      "test Acc 0.9241154562383612:\n",
      "22th- epoch: 47, train_loss = 33.74601914733648, train_acc = 0.9279226828132278\n",
      "test Acc 0.9241154562383612:\n",
      "22th- epoch: 48, train_loss = 33.414766892790794, train_acc = 0.9283884489986027\n",
      "test Acc 0.9241154562383612:\n",
      "22th- epoch: 49, train_loss = 33.095114924013615, train_acc = 0.9292035398230089\n",
      "test Acc 0.9241154562383612:\n",
      "22th- epoch: 50, train_loss = 32.78793793171644, train_acc = 0.9299021891010713\n",
      "test Acc 0.9259776536312849:\n",
      "22th- epoch: 51, train_loss = 32.49241986870766, train_acc = 0.9302515137401025\n",
      "test Acc 0.9259776536312849:\n",
      "22th- epoch: 52, train_loss = 32.20776551216841, train_acc = 0.9304843968327899\n",
      "test Acc 0.9264432029795159:\n",
      "22th- epoch: 53, train_loss = 31.93212378770113, train_acc = 0.9307172799254774\n",
      "test Acc 0.9264432029795159:\n",
      "22th- epoch: 54, train_loss = 31.66564928740263, train_acc = 0.9311830461108523\n",
      "test Acc 0.9273743016759777:\n",
      "22th- epoch: 55, train_loss = 31.406698495149612, train_acc = 0.9311830461108523\n",
      "test Acc 0.9278398510242085:\n",
      "22th- epoch: 56, train_loss = 31.15533396601677, train_acc = 0.9321145784816023\n",
      "test Acc 0.9278398510242085:\n",
      "22th- epoch: 57, train_loss = 30.91127125173807, train_acc = 0.9323474615742897\n",
      "test Acc 0.9278398510242085:\n",
      "22th- epoch: 58, train_loss = 30.67481129616499, train_acc = 0.9328132277596647\n",
      "test Acc 0.9278398510242085:\n",
      "22th- epoch: 59, train_loss = 30.443089842796326, train_acc = 0.9336283185840708\n",
      "test Acc 0.9278398510242085:\n",
      "22th- epoch: 60, train_loss = 30.217421740293503, train_acc = 0.9336283185840708\n",
      "test Acc 0.9278398510242085:\n",
      "22th- epoch: 61, train_loss = 29.99932260066271, train_acc = 0.9336283185840708\n",
      "test Acc 0.9278398510242085:\n",
      "22th- epoch: 62, train_loss = 29.787248820066452, train_acc = 0.933977643223102\n",
      "test Acc 0.9278398510242085:\n",
      "22th- epoch: 63, train_loss = 29.579940140247345, train_acc = 0.9347927340475082\n",
      "test Acc 0.9278398510242085:\n",
      "22th- epoch: 64, train_loss = 29.37840723246336, train_acc = 0.9350256171401956\n",
      "test Acc 0.9278398510242085:\n",
      "22th- epoch: 65, train_loss = 29.181425720453262, train_acc = 0.9353749417792269\n",
      "test Acc 0.9278398510242085:\n",
      "22th- epoch: 66, train_loss = 28.988876588642597, train_acc = 0.9358407079646017\n",
      "test Acc 0.9278398510242085:\n",
      "22th- epoch: 67, train_loss = 28.800914883613586, train_acc = 0.9359571495109456\n",
      "test Acc 0.9283054003724395:\n",
      "22th- epoch: 68, train_loss = 28.616859637200832, train_acc = 0.9360735910572893\n",
      "test Acc 0.9292364990689013:\n",
      "22th- epoch: 69, train_loss = 28.4369036257267, train_acc = 0.9363064741499767\n",
      "test Acc 0.9292364990689013:\n",
      "22th- epoch: 70, train_loss = 28.260750606656075, train_acc = 0.9370051234280391\n",
      "test Acc 0.9292364990689013:\n",
      "22th- epoch: 71, train_loss = 28.08833608031273, train_acc = 0.9370051234280391\n",
      "test Acc 0.9297020484171322:\n",
      "22th- epoch: 72, train_loss = 27.919167831540108, train_acc = 0.9373544480670704\n",
      "test Acc 0.9297020484171322:\n",
      "22th- epoch: 73, train_loss = 27.75395441800356, train_acc = 0.9373544480670704\n",
      "test Acc 0.9297020484171322:\n",
      "22th- epoch: 74, train_loss = 27.59146661311388, train_acc = 0.9375873311597578\n",
      "test Acc 0.9292364990689013:\n",
      "22th- epoch: 75, train_loss = 27.43196038901806, train_acc = 0.9382859804378202\n",
      "test Acc 0.9292364990689013:\n",
      "22th- epoch: 76, train_loss = 27.274836733937263, train_acc = 0.9382859804378202\n",
      "test Acc 0.9292364990689013:\n",
      "22th- epoch: 77, train_loss = 27.120575934648514, train_acc = 0.9384024219841639\n",
      "test Acc 0.9292364990689013:\n",
      "22th- epoch: 78, train_loss = 26.96909411251545, train_acc = 0.9389846297158826\n",
      "test Acc 0.9292364990689013:\n",
      "22th- epoch: 79, train_loss = 26.82085883617401, train_acc = 0.9395668374476013\n",
      "test Acc 0.9297020484171322:\n",
      "22th- epoch: 80, train_loss = 26.67433237284422, train_acc = 0.9400326036329762\n",
      "test Acc 0.9301675977653632:\n",
      "22th- epoch: 81, train_loss = 26.53127569705248, train_acc = 0.9402654867256637\n",
      "test Acc 0.930633147113594:\n",
      "22th- epoch: 82, train_loss = 26.390053421258926, train_acc = 0.9404983698183512\n",
      "test Acc 0.931098696461825:\n",
      "22th- epoch: 83, train_loss = 26.252348721027374, train_acc = 0.9410805775500699\n",
      "test Acc 0.9315642458100558:\n",
      "22th- epoch: 84, train_loss = 26.116873376071453, train_acc = 0.941429902189101\n",
      "test Acc 0.9320297951582868:\n",
      "22th- epoch: 85, train_loss = 25.984010636806488, train_acc = 0.9416627852817886\n",
      "test Acc 0.9320297951582868:\n",
      "22th- epoch: 86, train_loss = 25.85366028547287, train_acc = 0.9420121099208197\n",
      "test Acc 0.9320297951582868:\n",
      "22th- epoch: 87, train_loss = 25.724995113909245, train_acc = 0.9428272007452259\n",
      "test Acc 0.9324953445065177:\n",
      "22th- epoch: 88, train_loss = 25.59914195537567, train_acc = 0.9434094084769445\n",
      "test Acc 0.9324953445065177:\n",
      "22th- epoch: 89, train_loss = 25.47519014775753, train_acc = 0.9437587331159758\n",
      "test Acc 0.9329608938547486:\n",
      "22th- epoch: 90, train_loss = 25.353082079440355, train_acc = 0.9438751746623195\n",
      "test Acc 0.9329608938547486:\n",
      "22th- epoch: 91, train_loss = 25.232954937964678, train_acc = 0.9439916162086632\n",
      "test Acc 0.9329608938547486:\n",
      "22th- epoch: 92, train_loss = 25.114378560334444, train_acc = 0.9439916162086632\n",
      "test Acc 0.9338919925512105:\n",
      "22th- epoch: 93, train_loss = 24.998887680470943, train_acc = 0.9442244993013508\n",
      "test Acc 0.9338919925512105:\n",
      "22th- epoch: 94, train_loss = 24.885177966207266, train_acc = 0.9443409408476945\n",
      "test Acc 0.9348230912476723:\n",
      "22th- epoch: 95, train_loss = 24.77289581298828, train_acc = 0.9445738239403819\n",
      "test Acc 0.9348230912476723:\n",
      "22th- epoch: 96, train_loss = 24.662683084607124, train_acc = 0.9445738239403819\n",
      "test Acc 0.9348230912476723:\n",
      "22th- epoch: 97, train_loss = 24.55485386028886, train_acc = 0.9445738239403819\n",
      "test Acc 0.9348230912476723:\n",
      "22th- epoch: 98, train_loss = 24.44799778237939, train_acc = 0.9446902654867256\n",
      "test Acc 0.9348230912476723:\n",
      "22th- epoch: 99, train_loss = 24.343494590371847, train_acc = 0.945388914764788\n",
      "test Acc 0.9348230912476723:\n",
      "22th- epoch: 100, train_loss = 24.240176003426313, train_acc = 0.9455053563111319\n",
      "test Acc 0.9348230912476723:\n",
      "22th- epoch: 101, train_loss = 24.138312470167875, train_acc = 0.9457382394038193\n",
      "test Acc 0.9357541899441341:\n",
      "22th- epoch: 102, train_loss = 24.03874608129263, train_acc = 0.9459711224965067\n",
      "test Acc 0.9357541899441341:\n",
      "22th- epoch: 103, train_loss = 23.940289679914713, train_acc = 0.9459711224965067\n",
      "test Acc 0.9357541899441341:\n",
      "22th- epoch: 104, train_loss = 23.8432921692729, train_acc = 0.9460875640428504\n",
      "test Acc 0.936219739292365:\n",
      "22th- epoch: 105, train_loss = 23.747817054390907, train_acc = 0.9460875640428504\n",
      "test Acc 0.936219739292365:\n",
      "22th- epoch: 106, train_loss = 23.65375730022788, train_acc = 0.946320447135538\n",
      "test Acc 0.9366852886405959:\n",
      "22th- epoch: 107, train_loss = 23.56076830998063, train_acc = 0.946786213320913\n",
      "test Acc 0.9366852886405959:\n",
      "22th- epoch: 108, train_loss = 23.46952359750867, train_acc = 0.9470190964136004\n",
      "test Acc 0.9366852886405959:\n",
      "22th- epoch: 109, train_loss = 23.379612542688847, train_acc = 0.9473684210526315\n",
      "test Acc 0.9366852886405959:\n",
      "22th- epoch: 110, train_loss = 23.29081140831113, train_acc = 0.9474848625989754\n",
      "test Acc 0.9371508379888268:\n",
      "22th- epoch: 111, train_loss = 23.202526215463877, train_acc = 0.9479506287843502\n",
      "test Acc 0.9376163873370578:\n",
      "22th- epoch: 112, train_loss = 23.116493359208107, train_acc = 0.9482999534233815\n",
      "test Acc 0.9376163873370578:\n",
      "22th- epoch: 113, train_loss = 23.03061093762517, train_acc = 0.9486492780624126\n",
      "test Acc 0.9376163873370578:\n",
      "22th- epoch: 114, train_loss = 22.947059351950884, train_acc = 0.9487657196087564\n",
      "test Acc 0.9376163873370578:\n",
      "22th- epoch: 115, train_loss = 22.863799013197422, train_acc = 0.9485328365160689\n",
      "test Acc 0.9376163873370578:\n",
      "22th- epoch: 116, train_loss = 22.78165167942643, train_acc = 0.9487657196087564\n",
      "test Acc 0.9376163873370578:\n",
      "22th- epoch: 117, train_loss = 22.70183229446411, train_acc = 0.9489986027014439\n",
      "test Acc 0.9380819366852886:\n",
      "22th- epoch: 118, train_loss = 22.621946550905704, train_acc = 0.9493479273404751\n",
      "test Acc 0.9380819366852886:\n",
      "22th- epoch: 119, train_loss = 22.543818313628435, train_acc = 0.9493479273404751\n",
      "test Acc 0.9380819366852886:\n",
      "22th- epoch: 120, train_loss = 22.4666488468647, train_acc = 0.9494643688868188\n",
      "test Acc 0.9380819366852886:\n",
      "22th- epoch: 121, train_loss = 22.390025470405817, train_acc = 0.9495808104331626\n",
      "test Acc 0.9380819366852886:\n",
      "22th- epoch: 122, train_loss = 22.31480671837926, train_acc = 0.9496972519795063\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 123, train_loss = 22.240402974188328, train_acc = 0.9495808104331626\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 124, train_loss = 22.167130414396524, train_acc = 0.9495808104331626\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 125, train_loss = 22.094827741384506, train_acc = 0.9495808104331626\n",
      "test Acc 0.9390130353817505:\n",
      "22th- epoch: 126, train_loss = 22.023739743977785, train_acc = 0.94981369352585\n",
      "test Acc 0.9390130353817505:\n",
      "22th- epoch: 127, train_loss = 21.952782809734344, train_acc = 0.94981369352585\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 128, train_loss = 21.883822962641716, train_acc = 0.9500465766185375\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 129, train_loss = 21.814901366829872, train_acc = 0.9503959012575687\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 130, train_loss = 21.74716281890869, train_acc = 0.9505123428039124\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 131, train_loss = 21.67982041090727, train_acc = 0.9506287843502562\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 132, train_loss = 21.614231657236814, train_acc = 0.9507452258965999\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 133, train_loss = 21.547313425689936, train_acc = 0.9508616674429436\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 134, train_loss = 21.48252896219492, train_acc = 0.9510945505356311\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 135, train_loss = 21.41830560937524, train_acc = 0.9513274336283186\n",
      "test Acc 0.9390130353817505:\n",
      "22th- epoch: 136, train_loss = 21.35557558014989, train_acc = 0.9513274336283186\n",
      "test Acc 0.9390130353817505:\n",
      "22th- epoch: 137, train_loss = 21.293336179107428, train_acc = 0.9513274336283186\n",
      "test Acc 0.9390130353817505:\n",
      "22th- epoch: 138, train_loss = 21.231204323470592, train_acc = 0.951560316721006\n",
      "test Acc 0.9390130353817505:\n",
      "22th- epoch: 139, train_loss = 21.170198038220406, train_acc = 0.9517931998136935\n",
      "test Acc 0.9399441340782123:\n",
      "22th- epoch: 140, train_loss = 21.111371979117393, train_acc = 0.952026082906381\n",
      "test Acc 0.9399441340782123:\n",
      "22th- epoch: 141, train_loss = 21.051480002701283, train_acc = 0.9522589659990685\n",
      "test Acc 0.9399441340782123:\n",
      "22th- epoch: 142, train_loss = 20.990494467318058, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "22th- epoch: 143, train_loss = 20.933664973825216, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "22th- epoch: 144, train_loss = 20.875510908663273, train_acc = 0.9528411737307871\n",
      "test Acc 0.9399441340782123:\n",
      "22th- epoch: 145, train_loss = 20.81842628493905, train_acc = 0.9530740568234746\n",
      "test Acc 0.9399441340782123:\n",
      "22th- epoch: 146, train_loss = 20.76158119738102, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 147, train_loss = 20.705517079681158, train_acc = 0.9533069399161621\n",
      "test Acc 0.9399441340782123:\n",
      "22th- epoch: 148, train_loss = 20.649312164634466, train_acc = 0.9534233814625058\n",
      "test Acc 0.9404096834264432:\n",
      "22th- epoch: 149, train_loss = 20.594930488616228, train_acc = 0.9534233814625058\n",
      "test Acc 0.9404096834264432:\n",
      "22th- epoch: 150, train_loss = 20.54063595086336, train_acc = 0.9534233814625058\n",
      "test Acc 0.9408752327746741:\n",
      "22th- epoch: 151, train_loss = 20.485608085989952, train_acc = 0.9535398230088495\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 152, train_loss = 20.432113837450743, train_acc = 0.9536562645551933\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 153, train_loss = 20.37890213355422, train_acc = 0.9538891476478808\n",
      "test Acc 0.9422718808193669:\n",
      "22th- epoch: 154, train_loss = 20.326430283486843, train_acc = 0.9540055891942245\n",
      "test Acc 0.9422718808193669:\n",
      "22th- epoch: 155, train_loss = 20.275357022881508, train_acc = 0.9540055891942245\n",
      "test Acc 0.9422718808193669:\n",
      "22th- epoch: 156, train_loss = 20.2237616404891, train_acc = 0.9542384722869119\n",
      "test Acc 0.9422718808193669:\n",
      "22th- epoch: 157, train_loss = 20.172982711344957, train_acc = 0.9543549138332557\n",
      "test Acc 0.9422718808193669:\n",
      "22th- epoch: 158, train_loss = 20.123469967395067, train_acc = 0.9544713553795995\n",
      "test Acc 0.9422718808193669:\n",
      "22th- epoch: 159, train_loss = 20.0727527923882, train_acc = 0.9545877969259432\n",
      "test Acc 0.9422718808193669:\n",
      "22th- epoch: 160, train_loss = 20.023505752906203, train_acc = 0.9545877969259432\n",
      "test Acc 0.9422718808193669:\n",
      "22th- epoch: 161, train_loss = 19.974364629015326, train_acc = 0.9545877969259432\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 162, train_loss = 19.926601799204946, train_acc = 0.9547042384722869\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 163, train_loss = 19.879023341462016, train_acc = 0.9548206800186306\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 164, train_loss = 19.831384932622313, train_acc = 0.9548206800186306\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 165, train_loss = 19.78439670242369, train_acc = 0.9548206800186306\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 166, train_loss = 19.73627936281264, train_acc = 0.9548206800186306\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 167, train_loss = 19.689610961824656, train_acc = 0.9548206800186306\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 168, train_loss = 19.643873235210776, train_acc = 0.9550535631113182\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 169, train_loss = 19.59793454222381, train_acc = 0.9552864462040056\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 170, train_loss = 19.553250093013048, train_acc = 0.9554028877503493\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 171, train_loss = 19.509134965017438, train_acc = 0.9554028877503493\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 172, train_loss = 19.465577309951186, train_acc = 0.9556357708430367\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 173, train_loss = 19.42313559539616, train_acc = 0.9556357708430367\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 174, train_loss = 19.37899194099009, train_acc = 0.9557522123893806\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 175, train_loss = 19.336206192150712, train_acc = 0.9558686539357243\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 176, train_loss = 19.29437943175435, train_acc = 0.9558686539357243\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 177, train_loss = 19.25228627026081, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 178, train_loss = 19.211024275049567, train_acc = 0.956450861667443\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 179, train_loss = 19.17006258480251, train_acc = 0.956450861667443\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 180, train_loss = 19.128794388845563, train_acc = 0.9566837447601304\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 181, train_loss = 19.088643476366997, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "22th- epoch: 182, train_loss = 19.049433041363955, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "22th- epoch: 183, train_loss = 19.00995003245771, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "22th- epoch: 184, train_loss = 18.97119185142219, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "22th- epoch: 185, train_loss = 18.931593731045723, train_acc = 0.9569166278528178\n",
      "test Acc 0.9441340782122905:\n",
      "22th- epoch: 186, train_loss = 18.894020771607757, train_acc = 0.9570330693991617\n",
      "test Acc 0.9441340782122905:\n",
      "22th- epoch: 187, train_loss = 18.855851285159588, train_acc = 0.9570330693991617\n",
      "test Acc 0.9441340782122905:\n",
      "22th- epoch: 188, train_loss = 18.819141222164035, train_acc = 0.9571495109455054\n",
      "test Acc 0.9441340782122905:\n",
      "22th- epoch: 189, train_loss = 18.781972927972674, train_acc = 0.9571495109455054\n",
      "test Acc 0.9450651769087524:\n",
      "22th- epoch: 190, train_loss = 18.743765546008945, train_acc = 0.9574988355845365\n",
      "test Acc 0.9455307262569832:\n",
      "22th- epoch: 191, train_loss = 18.70890132524073, train_acc = 0.9574988355845365\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 192, train_loss = 18.672430800274014, train_acc = 0.9574988355845365\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 193, train_loss = 18.635241286829114, train_acc = 0.9576152771308803\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 194, train_loss = 18.600044248625636, train_acc = 0.9577317186772241\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 195, train_loss = 18.5646797940135, train_acc = 0.9579646017699115\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 196, train_loss = 18.529845589771867, train_acc = 0.9580810433162552\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 197, train_loss = 18.495498163625598, train_acc = 0.9579646017699115\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 198, train_loss = 18.460533617064357, train_acc = 0.9579646017699115\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 199, train_loss = 18.426380889490247, train_acc = 0.9580810433162552\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 200, train_loss = 18.393560314550996, train_acc = 0.9580810433162552\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 201, train_loss = 18.359829150140285, train_acc = 0.9580810433162552\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 202, train_loss = 18.327717328444123, train_acc = 0.9580810433162552\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 203, train_loss = 18.293917888775468, train_acc = 0.9580810433162552\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 204, train_loss = 18.26319962181151, train_acc = 0.9581974848625989\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 205, train_loss = 18.230365144088864, train_acc = 0.9581974848625989\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 206, train_loss = 18.198807664215565, train_acc = 0.9581974848625989\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 207, train_loss = 18.1669153701514, train_acc = 0.9581974848625989\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 208, train_loss = 18.13562865369022, train_acc = 0.9581974848625989\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 209, train_loss = 18.105146568268538, train_acc = 0.9583139264089428\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 210, train_loss = 18.073884861543775, train_acc = 0.9583139264089428\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 211, train_loss = 18.04350826703012, train_acc = 0.9583139264089428\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 212, train_loss = 18.013478523120284, train_acc = 0.9583139264089428\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 213, train_loss = 17.984104985371232, train_acc = 0.9585468095016302\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 214, train_loss = 17.95373760908842, train_acc = 0.9585468095016302\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 215, train_loss = 17.925272963941097, train_acc = 0.9585468095016302\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 216, train_loss = 17.895814342424273, train_acc = 0.9585468095016302\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 217, train_loss = 17.867541566491127, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 218, train_loss = 17.839153280481696, train_acc = 0.9587796925943176\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 219, train_loss = 17.8104181420058, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 220, train_loss = 17.782502273097634, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 221, train_loss = 17.754912991076708, train_acc = 0.9592454587796926\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 222, train_loss = 17.72700359672308, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 223, train_loss = 17.6997391525656, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 224, train_loss = 17.672163855284452, train_acc = 0.9595947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 225, train_loss = 17.64512825757265, train_acc = 0.9595947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 226, train_loss = 17.619486514478922, train_acc = 0.9597112249650676\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 227, train_loss = 17.59266014583409, train_acc = 0.9600605496040987\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 228, train_loss = 17.56651191972196, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 229, train_loss = 17.540533335879445, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 230, train_loss = 17.514484068378806, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 231, train_loss = 17.49006986245513, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 232, train_loss = 17.464612377807498, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 233, train_loss = 17.439268773421645, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 234, train_loss = 17.414386812597513, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 235, train_loss = 17.389169320464134, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 236, train_loss = 17.36399126239121, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 237, train_loss = 17.340801371261477, train_acc = 0.9605263157894737\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 238, train_loss = 17.315436059609056, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 239, train_loss = 17.291468733921647, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 240, train_loss = 17.26868904568255, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 241, train_loss = 17.24462934024632, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 242, train_loss = 17.221412170678377, train_acc = 0.9608756404285049\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 243, train_loss = 17.197897439822555, train_acc = 0.9608756404285049\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 244, train_loss = 17.175022188574076, train_acc = 0.9609920819748486\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 245, train_loss = 17.151559801772237, train_acc = 0.9609920819748486\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 246, train_loss = 17.127420108765364, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 247, train_loss = 17.10542337782681, train_acc = 0.9612249650675361\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 248, train_loss = 17.082889333367348, train_acc = 0.9613414066138798\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 249, train_loss = 17.06102753058076, train_acc = 0.9613414066138798\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 250, train_loss = 17.038792761042714, train_acc = 0.9613414066138798\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 251, train_loss = 17.01765082217753, train_acc = 0.9615742897065673\n",
      "test Acc 0.9487895716945997:\n",
      "22th- epoch: 252, train_loss = 16.995596112683415, train_acc = 0.9615742897065673\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 253, train_loss = 16.97550961561501, train_acc = 0.9615742897065673\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 254, train_loss = 16.953175652772188, train_acc = 0.9615742897065673\n",
      "test Acc 0.9487895716945997:\n",
      "22th- epoch: 255, train_loss = 16.932481605559587, train_acc = 0.961690731252911\n",
      "test Acc 0.9487895716945997:\n",
      "22th- epoch: 256, train_loss = 16.911121644079685, train_acc = 0.9618071727992548\n",
      "test Acc 0.9487895716945997:\n",
      "22th- epoch: 257, train_loss = 16.891700265929103, train_acc = 0.9618071727992548\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 258, train_loss = 16.87077532708645, train_acc = 0.9619236143455985\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 259, train_loss = 16.8494670689106, train_acc = 0.9619236143455985\n",
      "test Acc 0.9487895716945997:\n",
      "22th- epoch: 260, train_loss = 16.83051500376314, train_acc = 0.9620400558919422\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 261, train_loss = 16.808629747480154, train_acc = 0.962156497438286\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 262, train_loss = 16.78964390233159, train_acc = 0.962156497438286\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 263, train_loss = 16.769249740988016, train_acc = 0.9622729389846297\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 264, train_loss = 16.750071726739407, train_acc = 0.9622729389846297\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 265, train_loss = 16.73004309553653, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 266, train_loss = 16.710248213261366, train_acc = 0.9625058220773172\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 267, train_loss = 16.691205696202815, train_acc = 0.9625058220773172\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 268, train_loss = 16.67130204755813, train_acc = 0.9627387051700047\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 269, train_loss = 16.65310075506568, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 270, train_loss = 16.633763725869358, train_acc = 0.9629715882626921\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 271, train_loss = 16.614725671708584, train_acc = 0.9630880298090359\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 272, train_loss = 16.596430082805455, train_acc = 0.9632044713553796\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 273, train_loss = 16.577199461869895, train_acc = 0.9633209129017233\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 274, train_loss = 16.559448967687786, train_acc = 0.9633209129017233\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 275, train_loss = 16.540893234312534, train_acc = 0.9633209129017233\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 276, train_loss = 16.524179288186133, train_acc = 0.9633209129017233\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 277, train_loss = 16.50521247740835, train_acc = 0.9633209129017233\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 278, train_loss = 16.48818515520543, train_acc = 0.9634373544480671\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 279, train_loss = 16.468950941227376, train_acc = 0.9635537959944108\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 280, train_loss = 16.451829553581774, train_acc = 0.9635537959944108\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 281, train_loss = 16.434665616601706, train_acc = 0.9635537959944108\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 282, train_loss = 16.41643065586686, train_acc = 0.9635537959944108\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 283, train_loss = 16.398878504522145, train_acc = 0.9635537959944108\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 284, train_loss = 16.38239349797368, train_acc = 0.9636702375407545\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 285, train_loss = 16.365983966737986, train_acc = 0.9637866790870983\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 286, train_loss = 16.34805495943874, train_acc = 0.9637866790870983\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 287, train_loss = 16.331920200027525, train_acc = 0.9637866790870983\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 288, train_loss = 16.31469724699855, train_acc = 0.9637866790870983\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 289, train_loss = 16.29789613094181, train_acc = 0.9637866790870983\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 290, train_loss = 16.281443511135876, train_acc = 0.9640195621797858\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 291, train_loss = 16.26468264684081, train_acc = 0.9640195621797858\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 292, train_loss = 16.2497071987018, train_acc = 0.9641360037261295\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 293, train_loss = 16.233127135783434, train_acc = 0.9642524452724732\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 294, train_loss = 16.216889237053692, train_acc = 0.9642524452724732\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 295, train_loss = 16.2011692924425, train_acc = 0.9643688868188169\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 296, train_loss = 16.18527403753251, train_acc = 0.9643688868188169\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 297, train_loss = 16.170158992521465, train_acc = 0.9644853283651607\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 298, train_loss = 16.153993827290833, train_acc = 0.9646017699115044\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 299, train_loss = 16.13844121620059, train_acc = 0.9646017699115044\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 300, train_loss = 16.123356874100864, train_acc = 0.9647182114578482\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 301, train_loss = 16.109096408821642, train_acc = 0.9647182114578482\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 302, train_loss = 16.09303245227784, train_acc = 0.9647182114578482\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 303, train_loss = 16.077675826847553, train_acc = 0.9647182114578482\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 304, train_loss = 16.062838587909937, train_acc = 0.9647182114578482\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 305, train_loss = 16.048374348320067, train_acc = 0.9647182114578482\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 306, train_loss = 16.033131033182144, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 307, train_loss = 16.017645299434662, train_acc = 0.9647182114578482\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 308, train_loss = 16.005159488879144, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 309, train_loss = 15.989562850445509, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 310, train_loss = 15.974805948324502, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 311, train_loss = 15.959974055178463, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 312, train_loss = 15.945821949280798, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 313, train_loss = 15.932394303381443, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 314, train_loss = 15.918619871139526, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 315, train_loss = 15.903499701060355, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 316, train_loss = 15.889660046435893, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 317, train_loss = 15.876988341100514, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 318, train_loss = 15.862498664297163, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 319, train_loss = 15.848828244023025, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 320, train_loss = 15.835189404897392, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 321, train_loss = 15.822079113684595, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 322, train_loss = 15.809734667651355, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 323, train_loss = 15.795304180122912, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 324, train_loss = 15.781853795982897, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 325, train_loss = 15.769569352269173, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 326, train_loss = 15.75449800491333, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 327, train_loss = 15.742837402969599, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 328, train_loss = 15.730242143385112, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 329, train_loss = 15.716803159564734, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 330, train_loss = 15.705456492491066, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 331, train_loss = 15.690681081265211, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 332, train_loss = 15.678676846437156, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 333, train_loss = 15.666864592581987, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 334, train_loss = 15.651938444934785, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 335, train_loss = 15.640732414089143, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 336, train_loss = 15.628373143263161, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 337, train_loss = 15.615847130306065, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 338, train_loss = 15.602911033667624, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 339, train_loss = 15.591089561581612, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 340, train_loss = 15.579341634176672, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 341, train_loss = 15.5666349446401, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 342, train_loss = 15.555047329515219, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 343, train_loss = 15.543807606212795, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 344, train_loss = 15.529648370109499, train_acc = 0.9655333022822543\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 345, train_loss = 15.519089818932116, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 346, train_loss = 15.50733847077936, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 347, train_loss = 15.496792643330991, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 348, train_loss = 15.484579793177545, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 349, train_loss = 15.472674272023141, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 350, train_loss = 15.461205366998911, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 351, train_loss = 15.450555269606411, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 352, train_loss = 15.439597970806062, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 353, train_loss = 15.427750047296286, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 354, train_loss = 15.416314057074487, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 355, train_loss = 15.405262720771134, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 356, train_loss = 15.39364757295698, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 357, train_loss = 15.383666108362377, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 358, train_loss = 15.37266951892525, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 359, train_loss = 15.36266366019845, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 360, train_loss = 15.350067160092294, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 361, train_loss = 15.339748941361904, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 362, train_loss = 15.329197292216122, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 363, train_loss = 15.318632294423878, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 364, train_loss = 15.306413117796183, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 365, train_loss = 15.296950970776379, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 366, train_loss = 15.285667804069817, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 367, train_loss = 15.275338728912175, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 368, train_loss = 15.263358178548515, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 369, train_loss = 15.252280849032104, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 370, train_loss = 15.243055760860443, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 371, train_loss = 15.231920818798244, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 372, train_loss = 15.222224305383861, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 373, train_loss = 15.211967423558235, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 374, train_loss = 15.201894684694707, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 375, train_loss = 15.19028637278825, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 376, train_loss = 15.182323669083416, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 377, train_loss = 15.171265975572169, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 378, train_loss = 15.162747573107481, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 379, train_loss = 15.153091415762901, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 380, train_loss = 15.141953275538981, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 381, train_loss = 15.132936246693134, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 382, train_loss = 15.122518735937774, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 383, train_loss = 15.111522405408323, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 384, train_loss = 15.101833411492407, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 385, train_loss = 15.092213342897594, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 386, train_loss = 15.081772583536804, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 387, train_loss = 15.07174817007035, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 388, train_loss = 15.062458373606205, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 389, train_loss = 15.052845613099635, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 390, train_loss = 15.044124905951321, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 391, train_loss = 15.03437801077962, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 392, train_loss = 15.025533036328852, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 393, train_loss = 15.015821666456759, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 394, train_loss = 15.005785449407995, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 395, train_loss = 14.99900169018656, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 396, train_loss = 14.986882232129574, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 397, train_loss = 14.980115390382707, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 398, train_loss = 14.971464559435844, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 399, train_loss = 14.9619993371889, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 400, train_loss = 14.95107148308307, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 401, train_loss = 14.943715198896825, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 402, train_loss = 14.935126741416752, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 403, train_loss = 14.926040007732809, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 404, train_loss = 14.917201932519674, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 405, train_loss = 14.907882127910852, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 406, train_loss = 14.899281318299472, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 407, train_loss = 14.8908950695768, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 408, train_loss = 14.882203469984233, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 409, train_loss = 14.874334176070988, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 410, train_loss = 14.865792624652386, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 411, train_loss = 14.857520469464362, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 412, train_loss = 14.848560365848243, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 413, train_loss = 14.84076998475939, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 414, train_loss = 14.831159866414964, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 415, train_loss = 14.82248343527317, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 416, train_loss = 14.814463128335774, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 417, train_loss = 14.807372950017452, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 418, train_loss = 14.797738081775606, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 419, train_loss = 14.790205639787018, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 420, train_loss = 14.781969282776117, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 421, train_loss = 14.774143663235009, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 422, train_loss = 14.767082776874304, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 423, train_loss = 14.757944167591631, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 424, train_loss = 14.750965119339526, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 425, train_loss = 14.742152038030326, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 426, train_loss = 14.734317912720144, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 427, train_loss = 14.726177033036947, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 428, train_loss = 14.71837465185672, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 429, train_loss = 14.710939698852599, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 430, train_loss = 14.702650244347751, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 431, train_loss = 14.69631014764309, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 432, train_loss = 14.687174235470593, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 433, train_loss = 14.680163107812405, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 434, train_loss = 14.673664156347513, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 435, train_loss = 14.66325651947409, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 436, train_loss = 14.656670120544732, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 437, train_loss = 14.6503155073151, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 438, train_loss = 14.643037162721157, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 439, train_loss = 14.635171331465244, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 440, train_loss = 14.627936464734375, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 441, train_loss = 14.619891424663365, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 442, train_loss = 14.612506092526019, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 443, train_loss = 14.6058105006814, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 444, train_loss = 14.597913641482592, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 445, train_loss = 14.591977335512638, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 446, train_loss = 14.58508912473917, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 447, train_loss = 14.576569217257202, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 448, train_loss = 14.570900484919548, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 449, train_loss = 14.563169653527439, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 450, train_loss = 14.555059072561562, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 451, train_loss = 14.54885994270444, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 452, train_loss = 14.541287551634014, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 453, train_loss = 14.533481805585325, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 454, train_loss = 14.52853550389409, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 455, train_loss = 14.521106615662575, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 456, train_loss = 14.515721668489277, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 457, train_loss = 14.507418151944876, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 458, train_loss = 14.49955652281642, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "22th- epoch: 459, train_loss = 14.492847818881273, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 460, train_loss = 14.487386409193277, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 461, train_loss = 14.48106262087822, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 462, train_loss = 14.471143431961536, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 463, train_loss = 14.46734232828021, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 464, train_loss = 14.459195157978684, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 465, train_loss = 14.453299959655851, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 466, train_loss = 14.446434639394283, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 467, train_loss = 14.441512808203697, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 468, train_loss = 14.43342388421297, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 469, train_loss = 14.42842840636149, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 470, train_loss = 14.421561371535063, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 471, train_loss = 14.41361745679751, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 472, train_loss = 14.408541528042406, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 473, train_loss = 14.402376210782677, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 474, train_loss = 14.397149161901325, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 475, train_loss = 14.3900200673379, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 476, train_loss = 14.38268561894074, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 477, train_loss = 14.376246070954949, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 478, train_loss = 14.371670587453991, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 479, train_loss = 14.36434848094359, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 480, train_loss = 14.356994966510683, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 481, train_loss = 14.352407230529934, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 482, train_loss = 14.346944139804691, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 483, train_loss = 14.338539133314043, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 484, train_loss = 14.334489037748426, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 485, train_loss = 14.32801782572642, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 486, train_loss = 14.322129202540964, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 487, train_loss = 14.315143547952175, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 488, train_loss = 14.309943412896246, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 489, train_loss = 14.30284709110856, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 490, train_loss = 14.29760068282485, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 491, train_loss = 14.292673885822296, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 492, train_loss = 14.286693991627544, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 493, train_loss = 14.277845737989992, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 494, train_loss = 14.273057533893734, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 495, train_loss = 14.267392011824995, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 496, train_loss = 14.261850765440613, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 497, train_loss = 14.255202440079302, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 498, train_loss = 14.250345561653376, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "22th- epoch: 499, train_loss = 14.244172098580748, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|████████████████████████████████████████████████████▊                   | 22/30 [2:26:22<53:15, 399.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "23th- epoch: 0, train_loss = 268.8464607000351, train_acc = 0.445854680950163\n",
      "test Acc 0.49860335195530725:\n",
      "23th- epoch: 1, train_loss = 209.30217134952545, train_acc = 0.5008150908244061\n",
      "test Acc 0.4995344506517691:\n",
      "23th- epoch: 2, train_loss = 177.74098324775696, train_acc = 0.5088495575221239\n",
      "test Acc 0.527001862197393:\n",
      "23th- epoch: 3, train_loss = 161.427077293396, train_acc = 0.5449464368886818\n",
      "test Acc 0.5758845437616388:\n",
      "23th- epoch: 4, train_loss = 148.76319521665573, train_acc = 0.5890777829529577\n",
      "test Acc 0.6266294227188082:\n",
      "23th- epoch: 5, train_loss = 137.1122626066208, train_acc = 0.6339077782952958\n",
      "test Acc 0.6461824953445066:\n",
      "23th- epoch: 6, train_loss = 126.1553612947464, train_acc = 0.6549836981835119\n",
      "test Acc 0.7416201117318436:\n",
      "23th- epoch: 7, train_loss = 116.07955545186996, train_acc = 0.7069166278528178\n",
      "test Acc 0.7569832402234636:\n",
      "23th- epoch: 8, train_loss = 106.94980055093765, train_acc = 0.7708430367955287\n",
      "test Acc 0.7825884543761639:\n",
      "23th- epoch: 9, train_loss = 98.7538788318634, train_acc = 0.7972752678155566\n",
      "test Acc 0.8012104283054003:\n",
      "23th- epoch: 10, train_loss = 91.43582701683044, train_acc = 0.8148579413134607\n",
      "test Acc 0.8230912476722533:\n",
      "23th- epoch: 11, train_loss = 84.98029094934464, train_acc = 0.8280158360503027\n",
      "test Acc 0.8361266294227188:\n",
      "23th- epoch: 12, train_loss = 79.32809576392174, train_acc = 0.8387284583139264\n",
      "test Acc 0.8486964618249534:\n",
      "23th- epoch: 13, train_loss = 74.39022070169449, train_acc = 0.8488588728458314\n",
      "test Acc 0.861266294227188:\n",
      "23th- epoch: 14, train_loss = 70.0842869579792, train_acc = 0.8575919888216116\n",
      "test Acc 0.8687150837988827:\n",
      "23th- epoch: 15, train_loss = 66.31231594085693, train_acc = 0.8624825337680484\n",
      "test Acc 0.87243947858473:\n",
      "23th- epoch: 16, train_loss = 63.000801771879196, train_acc = 0.8687703772706101\n",
      "test Acc 0.87756052141527:\n",
      "23th- epoch: 17, train_loss = 60.08111751079559, train_acc = 0.8715649743828598\n",
      "test Acc 0.8798882681564246:\n",
      "23th- epoch: 18, train_loss = 57.50431641936302, train_acc = 0.8761061946902655\n",
      "test Acc 0.8873370577281192:\n",
      "23th- epoch: 19, train_loss = 55.223021522164345, train_acc = 0.8809967396367023\n",
      "test Acc 0.8905959031657356:\n",
      "23th- epoch: 20, train_loss = 53.19986107945442, train_acc = 0.8855379599441081\n",
      "test Acc 0.8929236499068901:\n",
      "23th- epoch: 21, train_loss = 51.40094116330147, train_acc = 0.8886818816953889\n",
      "test Acc 0.8933891992551211:\n",
      "23th- epoch: 22, train_loss = 49.79620718955994, train_acc = 0.8932231020027946\n",
      "test Acc 0.8999068901303539:\n",
      "23th- epoch: 23, train_loss = 48.35802161693573, train_acc = 0.8986958546809501\n",
      "test Acc 0.9003724394785847:\n",
      "23th- epoch: 24, train_loss = 47.06412421166897, train_acc = 0.9004424778761062\n",
      "test Acc 0.9017690875232774:\n",
      "23th- epoch: 25, train_loss = 45.89143781363964, train_acc = 0.9021891010712623\n",
      "test Acc 0.9027001862197392:\n",
      "23th- epoch: 26, train_loss = 44.82501810789108, train_acc = 0.9044014904517932\n",
      "test Acc 0.904562383612663:\n",
      "23th- epoch: 27, train_loss = 43.851154088974, train_acc = 0.9056823474615743\n",
      "test Acc 0.9073556797020484:\n",
      "23th- epoch: 28, train_loss = 42.956582337617874, train_acc = 0.9074289706567303\n",
      "test Acc 0.9082867783985102:\n",
      "23th- epoch: 29, train_loss = 42.13045392930508, train_acc = 0.9082440614811365\n",
      "test Acc 0.9087523277467412:\n",
      "23th- epoch: 30, train_loss = 41.363913506269455, train_acc = 0.9088262692128551\n",
      "test Acc 0.909217877094972:\n",
      "23th- epoch: 31, train_loss = 40.65108361840248, train_acc = 0.9098742431299488\n",
      "test Acc 0.9110800744878957:\n",
      "23th- epoch: 32, train_loss = 39.98445452749729, train_acc = 0.9117373078714486\n",
      "test Acc 0.9120111731843575:\n",
      "23th- epoch: 33, train_loss = 39.3604174554348, train_acc = 0.9134839310666045\n",
      "test Acc 0.9129422718808193:\n",
      "23th- epoch: 34, train_loss = 38.77264881134033, train_acc = 0.9148812296227294\n",
      "test Acc 0.9134078212290503:\n",
      "23th- epoch: 35, train_loss = 38.21768769621849, train_acc = 0.9160456450861667\n",
      "test Acc 0.9152700186219739:\n",
      "23th- epoch: 36, train_loss = 37.69219422340393, train_acc = 0.9174429436422916\n",
      "test Acc 0.9157355679702048:\n",
      "23th- epoch: 37, train_loss = 37.19359791278839, train_acc = 0.9188402421984164\n",
      "test Acc 0.9166666666666666:\n",
      "23th- epoch: 38, train_loss = 36.719494730234146, train_acc = 0.9204704238472287\n",
      "test Acc 0.9166666666666666:\n",
      "23th- epoch: 39, train_loss = 36.26769596338272, train_acc = 0.9217512808570097\n",
      "test Acc 0.9166666666666666:\n",
      "23th- epoch: 40, train_loss = 35.835957288742065, train_acc = 0.9226828132277597\n",
      "test Acc 0.9180633147113594:\n",
      "23th- epoch: 41, train_loss = 35.42261217534542, train_acc = 0.9232650209594784\n",
      "test Acc 0.9185288640595903:\n",
      "23th- epoch: 42, train_loss = 35.02583657205105, train_acc = 0.9241965533302282\n",
      "test Acc 0.9199255121042831:\n",
      "23th- epoch: 43, train_loss = 34.64531873911619, train_acc = 0.9251280857009782\n",
      "test Acc 0.9217877094972067:\n",
      "23th- epoch: 44, train_loss = 34.279418252408504, train_acc = 0.926059618071728\n",
      "test Acc 0.9222532588454376:\n",
      "23th- epoch: 45, train_loss = 33.9275975972414, train_acc = 0.9267582673497904\n",
      "test Acc 0.9227188081936686:\n",
      "23th- epoch: 46, train_loss = 33.58846390992403, train_acc = 0.9276897997205403\n",
      "test Acc 0.9227188081936686:\n",
      "23th- epoch: 47, train_loss = 33.2610939219594, train_acc = 0.9283884489986027\n",
      "test Acc 0.9236499068901304:\n",
      "23th- epoch: 48, train_loss = 32.94495453685522, train_acc = 0.9289706567303214\n",
      "test Acc 0.9236499068901304:\n",
      "23th- epoch: 49, train_loss = 32.63856951147318, train_acc = 0.9292035398230089\n",
      "test Acc 0.9245810055865922:\n",
      "23th- epoch: 50, train_loss = 32.34240270406008, train_acc = 0.9293199813693526\n",
      "test Acc 0.9245810055865922:\n",
      "23th- epoch: 51, train_loss = 32.055993281304836, train_acc = 0.9299021891010713\n",
      "test Acc 0.9250465549348231:\n",
      "23th- epoch: 52, train_loss = 31.778637282550335, train_acc = 0.9306008383791337\n",
      "test Acc 0.925512104283054:\n",
      "23th- epoch: 53, train_loss = 31.510222107172012, train_acc = 0.9308337214718212\n",
      "test Acc 0.9264432029795159:\n",
      "23th- epoch: 54, train_loss = 31.248726442456245, train_acc = 0.9314159292035398\n",
      "test Acc 0.9264432029795159:\n",
      "23th- epoch: 55, train_loss = 30.994994059205055, train_acc = 0.9319981369352585\n",
      "test Acc 0.9269087523277467:\n",
      "23th- epoch: 56, train_loss = 30.74779934436083, train_acc = 0.9323474615742897\n",
      "test Acc 0.9269087523277467:\n",
      "23th- epoch: 57, train_loss = 30.50712350010872, train_acc = 0.9326967862133209\n",
      "test Acc 0.9273743016759777:\n",
      "23th- epoch: 58, train_loss = 30.27290680259466, train_acc = 0.9326967862133209\n",
      "test Acc 0.9273743016759777:\n",
      "23th- epoch: 59, train_loss = 30.04442958533764, train_acc = 0.9329296693060084\n",
      "test Acc 0.9273743016759777:\n",
      "23th- epoch: 60, train_loss = 29.821330696344376, train_acc = 0.9331625523986958\n",
      "test Acc 0.9273743016759777:\n",
      "23th- epoch: 61, train_loss = 29.603850200772285, train_acc = 0.9337447601304145\n",
      "test Acc 0.9273743016759777:\n",
      "23th- epoch: 62, train_loss = 29.391457691788673, train_acc = 0.9344434094084769\n",
      "test Acc 0.9273743016759777:\n",
      "23th- epoch: 63, train_loss = 29.184679619967937, train_acc = 0.9350256171401956\n",
      "test Acc 0.9273743016759777:\n",
      "23th- epoch: 64, train_loss = 28.981926269829273, train_acc = 0.9351420586865393\n",
      "test Acc 0.9283054003724395:\n",
      "23th- epoch: 65, train_loss = 28.783099845051765, train_acc = 0.9353749417792269\n",
      "test Acc 0.9278398510242085:\n",
      "23th- epoch: 66, train_loss = 28.588922828435898, train_acc = 0.935724266418258\n",
      "test Acc 0.9283054003724395:\n",
      "23th- epoch: 67, train_loss = 28.398730047047138, train_acc = 0.9358407079646017\n",
      "test Acc 0.9287709497206704:\n",
      "23th- epoch: 68, train_loss = 28.212316378951073, train_acc = 0.936190032603633\n",
      "test Acc 0.9287709497206704:\n",
      "23th- epoch: 69, train_loss = 28.03020177781582, train_acc = 0.936190032603633\n",
      "test Acc 0.9287709497206704:\n",
      "23th- epoch: 70, train_loss = 27.85113763809204, train_acc = 0.9364229156963204\n",
      "test Acc 0.9287709497206704:\n",
      "23th- epoch: 71, train_loss = 27.676278598606586, train_acc = 0.936655798789008\n",
      "test Acc 0.9287709497206704:\n",
      "23th- epoch: 72, train_loss = 27.505282409489155, train_acc = 0.9370051234280391\n",
      "test Acc 0.9287709497206704:\n",
      "23th- epoch: 73, train_loss = 27.33794391900301, train_acc = 0.9371215649743828\n",
      "test Acc 0.9287709497206704:\n",
      "23th- epoch: 74, train_loss = 27.173778604716063, train_acc = 0.9377037727061015\n",
      "test Acc 0.9287709497206704:\n",
      "23th- epoch: 75, train_loss = 27.013320945203304, train_acc = 0.9381695388914765\n",
      "test Acc 0.9287709497206704:\n",
      "23th- epoch: 76, train_loss = 26.85590135678649, train_acc = 0.9384024219841639\n",
      "test Acc 0.9287709497206704:\n",
      "23th- epoch: 77, train_loss = 26.702198561280966, train_acc = 0.9388681881695389\n",
      "test Acc 0.9287709497206704:\n",
      "23th- epoch: 78, train_loss = 26.551427092403173, train_acc = 0.9392175128085701\n",
      "test Acc 0.9287709497206704:\n",
      "23th- epoch: 79, train_loss = 26.403870429843664, train_acc = 0.9395668374476013\n",
      "test Acc 0.9287709497206704:\n",
      "23th- epoch: 80, train_loss = 26.259331557899714, train_acc = 0.9400326036329762\n",
      "test Acc 0.9297020484171322:\n",
      "23th- epoch: 81, train_loss = 26.1169840618968, train_acc = 0.9407312529110387\n",
      "test Acc 0.9297020484171322:\n",
      "23th- epoch: 82, train_loss = 25.977031599730253, train_acc = 0.9415463437354448\n",
      "test Acc 0.9297020484171322:\n",
      "23th- epoch: 83, train_loss = 25.840024929493666, train_acc = 0.941895668374476\n",
      "test Acc 0.9301675977653632:\n",
      "23th- epoch: 84, train_loss = 25.70587757602334, train_acc = 0.9424778761061947\n",
      "test Acc 0.930633147113594:\n",
      "23th- epoch: 85, train_loss = 25.573723040521145, train_acc = 0.9430600838379134\n",
      "test Acc 0.9315642458100558:\n",
      "23th- epoch: 86, train_loss = 25.443899605423212, train_acc = 0.9435258500232883\n",
      "test Acc 0.9320297951582868:\n",
      "23th- epoch: 87, train_loss = 25.316882867366076, train_acc = 0.9437587331159758\n",
      "test Acc 0.9324953445065177:\n",
      "23th- epoch: 88, train_loss = 25.192110747098923, train_acc = 0.9444573823940382\n",
      "test Acc 0.9324953445065177:\n",
      "23th- epoch: 89, train_loss = 25.069198355078697, train_acc = 0.9445738239403819\n",
      "test Acc 0.9324953445065177:\n",
      "23th- epoch: 90, train_loss = 24.948361035436392, train_acc = 0.9448067070330693\n",
      "test Acc 0.9324953445065177:\n",
      "23th- epoch: 91, train_loss = 24.83025874570012, train_acc = 0.945388914764788\n",
      "test Acc 0.9324953445065177:\n",
      "23th- epoch: 92, train_loss = 24.713611837476492, train_acc = 0.9455053563111319\n",
      "test Acc 0.9324953445065177:\n",
      "23th- epoch: 93, train_loss = 24.59969410672784, train_acc = 0.9456217978574756\n",
      "test Acc 0.9329608938547486:\n",
      "23th- epoch: 94, train_loss = 24.48759751394391, train_acc = 0.9460875640428504\n",
      "test Acc 0.9334264432029795:\n",
      "23th- epoch: 95, train_loss = 24.37738197296858, train_acc = 0.9462040055891943\n",
      "test Acc 0.9334264432029795:\n",
      "23th- epoch: 96, train_loss = 24.268883291631937, train_acc = 0.946320447135538\n",
      "test Acc 0.9334264432029795:\n",
      "23th- epoch: 97, train_loss = 24.162567276507616, train_acc = 0.946320447135538\n",
      "test Acc 0.9334264432029795:\n",
      "23th- epoch: 98, train_loss = 24.05816901102662, train_acc = 0.9465533302282254\n",
      "test Acc 0.9338919925512105:\n",
      "23th- epoch: 99, train_loss = 23.9553308673203, train_acc = 0.9470190964136004\n",
      "test Acc 0.9338919925512105:\n",
      "23th- epoch: 100, train_loss = 23.854356680065393, train_acc = 0.9469026548672567\n",
      "test Acc 0.9343575418994413:\n",
      "23th- epoch: 101, train_loss = 23.755151987075806, train_acc = 0.9471355379599441\n",
      "test Acc 0.9343575418994413:\n",
      "23th- epoch: 102, train_loss = 23.65826180949807, train_acc = 0.9472519795062878\n",
      "test Acc 0.9343575418994413:\n",
      "23th- epoch: 103, train_loss = 23.56221727654338, train_acc = 0.9472519795062878\n",
      "test Acc 0.9348230912476723:\n",
      "23th- epoch: 104, train_loss = 23.46797428280115, train_acc = 0.9473684210526315\n",
      "test Acc 0.9348230912476723:\n",
      "23th- epoch: 105, train_loss = 23.375671915709972, train_acc = 0.9474848625989754\n",
      "test Acc 0.9348230912476723:\n",
      "23th- epoch: 106, train_loss = 23.283757209777832, train_acc = 0.9476013041453191\n",
      "test Acc 0.9348230912476723:\n",
      "23th- epoch: 107, train_loss = 23.193935826420784, train_acc = 0.9478341872380065\n",
      "test Acc 0.9352886405959032:\n",
      "23th- epoch: 108, train_loss = 23.105784978717566, train_acc = 0.948067070330694\n",
      "test Acc 0.9352886405959032:\n",
      "23th- epoch: 109, train_loss = 23.02030484378338, train_acc = 0.948067070330694\n",
      "test Acc 0.9352886405959032:\n",
      "23th- epoch: 110, train_loss = 22.93414006009698, train_acc = 0.9481835118770378\n",
      "test Acc 0.9352886405959032:\n",
      "23th- epoch: 111, train_loss = 22.8498707562685, train_acc = 0.9482999534233815\n",
      "test Acc 0.9352886405959032:\n",
      "23th- epoch: 112, train_loss = 22.766076121479273, train_acc = 0.9485328365160689\n",
      "test Acc 0.9352886405959032:\n",
      "23th- epoch: 113, train_loss = 22.684876836836338, train_acc = 0.9486492780624126\n",
      "test Acc 0.9357541899441341:\n",
      "23th- epoch: 114, train_loss = 22.604949686676264, train_acc = 0.9491150442477876\n",
      "test Acc 0.936219739292365:\n",
      "23th- epoch: 115, train_loss = 22.52509957551956, train_acc = 0.9494643688868188\n",
      "test Acc 0.9366852886405959:\n",
      "23th- epoch: 116, train_loss = 22.447037391364574, train_acc = 0.9494643688868188\n",
      "test Acc 0.9371508379888268:\n",
      "23th- epoch: 117, train_loss = 22.370156437158585, train_acc = 0.9496972519795063\n",
      "test Acc 0.9371508379888268:\n",
      "23th- epoch: 118, train_loss = 22.295088164508343, train_acc = 0.9499301350721937\n",
      "test Acc 0.9371508379888268:\n",
      "23th- epoch: 119, train_loss = 22.219621185213327, train_acc = 0.9501630181648812\n",
      "test Acc 0.9380819366852886:\n",
      "23th- epoch: 120, train_loss = 22.146642804145813, train_acc = 0.9503959012575687\n",
      "test Acc 0.9380819366852886:\n",
      "23th- epoch: 121, train_loss = 22.073133178055286, train_acc = 0.9505123428039124\n",
      "test Acc 0.9380819366852886:\n",
      "23th- epoch: 122, train_loss = 22.001262448728085, train_acc = 0.9508616674429436\n",
      "test Acc 0.9380819366852886:\n",
      "23th- epoch: 123, train_loss = 21.93058430403471, train_acc = 0.9510945505356311\n",
      "test Acc 0.9380819366852886:\n",
      "23th- epoch: 124, train_loss = 21.860651288181543, train_acc = 0.9510945505356311\n",
      "test Acc 0.9380819366852886:\n",
      "23th- epoch: 125, train_loss = 21.791061144322157, train_acc = 0.9513274336283186\n",
      "test Acc 0.9380819366852886:\n",
      "23th- epoch: 126, train_loss = 21.72357026860118, train_acc = 0.951560316721006\n",
      "test Acc 0.9376163873370578:\n",
      "23th- epoch: 127, train_loss = 21.656299449503422, train_acc = 0.9516767582673498\n",
      "test Acc 0.9376163873370578:\n",
      "23th- epoch: 128, train_loss = 21.589408822357655, train_acc = 0.9517931998136935\n",
      "test Acc 0.9376163873370578:\n",
      "23th- epoch: 129, train_loss = 21.523679208010435, train_acc = 0.9517931998136935\n",
      "test Acc 0.9376163873370578:\n",
      "23th- epoch: 130, train_loss = 21.458054557442665, train_acc = 0.9519096413600373\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 131, train_loss = 21.39427276700735, train_acc = 0.952026082906381\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 132, train_loss = 21.33101898431778, train_acc = 0.9521425244527247\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 133, train_loss = 21.267908863723278, train_acc = 0.9522589659990685\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 134, train_loss = 21.20570718497038, train_acc = 0.9523754075454122\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 135, train_loss = 21.143708866089582, train_acc = 0.9523754075454122\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 136, train_loss = 21.082555934786797, train_acc = 0.952491849091756\n",
      "test Acc 0.9394785847299814:\n",
      "23th- epoch: 137, train_loss = 21.021908592432737, train_acc = 0.9528411737307871\n",
      "test Acc 0.9394785847299814:\n",
      "23th- epoch: 138, train_loss = 20.962780479341745, train_acc = 0.9528411737307871\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 139, train_loss = 20.903868321329355, train_acc = 0.9528411737307871\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 140, train_loss = 20.84480820596218, train_acc = 0.9530740568234746\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 141, train_loss = 20.78834157809615, train_acc = 0.9530740568234746\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 142, train_loss = 20.73117658495903, train_acc = 0.9530740568234746\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 143, train_loss = 20.674857299774885, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 144, train_loss = 20.62058324739337, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 145, train_loss = 20.564746025949717, train_acc = 0.9534233814625058\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 146, train_loss = 20.51029538549483, train_acc = 0.9535398230088495\n",
      "test Acc 0.9399441340782123:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 147, train_loss = 20.457690885290504, train_acc = 0.9536562645551933\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 148, train_loss = 20.40353307686746, train_acc = 0.9537727061015371\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 149, train_loss = 20.351146822795272, train_acc = 0.9538891476478808\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 150, train_loss = 20.29938660748303, train_acc = 0.9538891476478808\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 151, train_loss = 20.247000435367227, train_acc = 0.9542384722869119\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 152, train_loss = 20.196746760979295, train_acc = 0.9543549138332557\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 153, train_loss = 20.14512417279184, train_acc = 0.9543549138332557\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 154, train_loss = 20.096251679584384, train_acc = 0.9543549138332557\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 155, train_loss = 20.045571306720376, train_acc = 0.9544713553795995\n",
      "test Acc 0.9404096834264432:\n",
      "23th- epoch: 156, train_loss = 19.996590605005622, train_acc = 0.9550535631113182\n",
      "test Acc 0.9404096834264432:\n",
      "23th- epoch: 157, train_loss = 19.947718497365713, train_acc = 0.9551700046576619\n",
      "test Acc 0.9404096834264432:\n",
      "23th- epoch: 158, train_loss = 19.89973232895136, train_acc = 0.9552864462040056\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 159, train_loss = 19.85143464244902, train_acc = 0.9556357708430367\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 160, train_loss = 19.805199071764946, train_acc = 0.9556357708430367\n",
      "test Acc 0.9394785847299814:\n",
      "23th- epoch: 161, train_loss = 19.75822501257062, train_acc = 0.9557522123893806\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 162, train_loss = 19.712247721850872, train_acc = 0.9557522123893806\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 163, train_loss = 19.666638545691967, train_acc = 0.9558686539357243\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 164, train_loss = 19.620843280106783, train_acc = 0.9558686539357243\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 165, train_loss = 19.576893215999007, train_acc = 0.955985095482068\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 166, train_loss = 19.53183875605464, train_acc = 0.9563344201210993\n",
      "test Acc 0.9404096834264432:\n",
      "23th- epoch: 167, train_loss = 19.48844000324607, train_acc = 0.9563344201210993\n",
      "test Acc 0.9404096834264432:\n",
      "23th- epoch: 168, train_loss = 19.4441777523607, train_acc = 0.9563344201210993\n",
      "test Acc 0.9404096834264432:\n",
      "23th- epoch: 169, train_loss = 19.4011820089072, train_acc = 0.956450861667443\n",
      "test Acc 0.9404096834264432:\n",
      "23th- epoch: 170, train_loss = 19.35884333960712, train_acc = 0.9566837447601304\n",
      "test Acc 0.9404096834264432:\n",
      "23th- epoch: 171, train_loss = 19.316017046570778, train_acc = 0.9568001863064741\n",
      "test Acc 0.9408752327746741:\n",
      "23th- epoch: 172, train_loss = 19.27521277591586, train_acc = 0.9570330693991617\n",
      "test Acc 0.9408752327746741:\n",
      "23th- epoch: 173, train_loss = 19.231825107708573, train_acc = 0.9570330693991617\n",
      "test Acc 0.9408752327746741:\n",
      "23th- epoch: 174, train_loss = 19.19184415228665, train_acc = 0.9572659524918491\n",
      "test Acc 0.9408752327746741:\n",
      "23th- epoch: 175, train_loss = 19.149513540789485, train_acc = 0.9573823940381928\n",
      "test Acc 0.9408752327746741:\n",
      "23th- epoch: 176, train_loss = 19.110782908275723, train_acc = 0.9572659524918491\n",
      "test Acc 0.9413407821229051:\n",
      "23th- epoch: 177, train_loss = 19.07005733437836, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 178, train_loss = 19.03082213550806, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 179, train_loss = 18.990766080096364, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 180, train_loss = 18.95251245982945, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 181, train_loss = 18.914321495220065, train_acc = 0.9576152771308803\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 182, train_loss = 18.875544829294086, train_acc = 0.9577317186772241\n",
      "test Acc 0.9427374301675978:\n",
      "23th- epoch: 183, train_loss = 18.83759847469628, train_acc = 0.9579646017699115\n",
      "test Acc 0.9427374301675978:\n",
      "23th- epoch: 184, train_loss = 18.800070330500603, train_acc = 0.9580810433162552\n",
      "test Acc 0.9427374301675978:\n",
      "23th- epoch: 185, train_loss = 18.76383133046329, train_acc = 0.9580810433162552\n",
      "test Acc 0.9427374301675978:\n",
      "23th- epoch: 186, train_loss = 18.7267956584692, train_acc = 0.9580810433162552\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 187, train_loss = 18.68967500142753, train_acc = 0.9581974848625989\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 188, train_loss = 18.65395009331405, train_acc = 0.9581974848625989\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 189, train_loss = 18.61892068386078, train_acc = 0.9581974848625989\n",
      "test Acc 0.9436685288640596:\n",
      "23th- epoch: 190, train_loss = 18.582264510914683, train_acc = 0.9584303679552865\n",
      "test Acc 0.9441340782122905:\n",
      "23th- epoch: 191, train_loss = 18.5476298276335, train_acc = 0.9584303679552865\n",
      "test Acc 0.9441340782122905:\n",
      "23th- epoch: 192, train_loss = 18.51247556693852, train_acc = 0.9584303679552865\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 193, train_loss = 18.47862883284688, train_acc = 0.9585468095016302\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 194, train_loss = 18.44487432204187, train_acc = 0.9585468095016302\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 195, train_loss = 18.410831052809954, train_acc = 0.9586632510479739\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 196, train_loss = 18.37501539848745, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "23th- epoch: 197, train_loss = 18.34352777712047, train_acc = 0.9590125756870052\n",
      "test Acc 0.9450651769087524:\n",
      "23th- epoch: 198, train_loss = 18.30881043151021, train_acc = 0.9591290172333489\n",
      "test Acc 0.9450651769087524:\n",
      "23th- epoch: 199, train_loss = 18.2766457144171, train_acc = 0.9591290172333489\n",
      "test Acc 0.9450651769087524:\n",
      "23th- epoch: 200, train_loss = 18.243220588192344, train_acc = 0.9591290172333489\n",
      "test Acc 0.9450651769087524:\n",
      "23th- epoch: 201, train_loss = 18.210051951929927, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "23th- epoch: 202, train_loss = 18.178951194509864, train_acc = 0.9592454587796926\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 203, train_loss = 18.146390788257122, train_acc = 0.9592454587796926\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 204, train_loss = 18.11462007649243, train_acc = 0.9593619003260363\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 205, train_loss = 18.082799101248384, train_acc = 0.9593619003260363\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 206, train_loss = 18.05212851986289, train_acc = 0.95947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 207, train_loss = 18.02030908688903, train_acc = 0.9595947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 208, train_loss = 17.991147926077247, train_acc = 0.9595947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 209, train_loss = 17.95970750413835, train_acc = 0.9595947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 210, train_loss = 17.93039710074663, train_acc = 0.9595947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 211, train_loss = 17.902046682313085, train_acc = 0.9595947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 212, train_loss = 17.87137221544981, train_acc = 0.9597112249650676\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 213, train_loss = 17.841425884515047, train_acc = 0.9597112249650676\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 214, train_loss = 17.811934730038047, train_acc = 0.9597112249650676\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 215, train_loss = 17.7826528865844, train_acc = 0.9598276665114113\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 216, train_loss = 17.75640171021223, train_acc = 0.9597112249650676\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 217, train_loss = 17.726141026243567, train_acc = 0.9597112249650676\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 218, train_loss = 17.698892548680305, train_acc = 0.9598276665114113\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 219, train_loss = 17.670854991301894, train_acc = 0.959944108057755\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 220, train_loss = 17.64402285963297, train_acc = 0.9598276665114113\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 221, train_loss = 17.615437483415008, train_acc = 0.9598276665114113\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 222, train_loss = 17.589831730350852, train_acc = 0.9598276665114113\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 223, train_loss = 17.56152254715562, train_acc = 0.9598276665114113\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 224, train_loss = 17.53619455359876, train_acc = 0.959944108057755\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 225, train_loss = 17.50816455669701, train_acc = 0.9601769911504425\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 226, train_loss = 17.484057003632188, train_acc = 0.9601769911504425\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 227, train_loss = 17.456282766535878, train_acc = 0.9601769911504425\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 228, train_loss = 17.431075057014823, train_acc = 0.9602934326967862\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 229, train_loss = 17.404351523146033, train_acc = 0.9602934326967862\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 230, train_loss = 17.378863150253892, train_acc = 0.9602934326967862\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 231, train_loss = 17.354523353278637, train_acc = 0.9602934326967862\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 232, train_loss = 17.32946990430355, train_acc = 0.9602934326967862\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 233, train_loss = 17.303924364969134, train_acc = 0.9602934326967862\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 234, train_loss = 17.280387330800295, train_acc = 0.9605263157894737\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 235, train_loss = 17.25608916580677, train_acc = 0.9605263157894737\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 236, train_loss = 17.231847843155265, train_acc = 0.9606427573358174\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 237, train_loss = 17.207434866577387, train_acc = 0.9607591988821611\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 238, train_loss = 17.18340403214097, train_acc = 0.9608756404285049\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 239, train_loss = 17.159547697752714, train_acc = 0.9609920819748486\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 240, train_loss = 17.1367707811296, train_acc = 0.9608756404285049\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 241, train_loss = 17.11260398477316, train_acc = 0.9608756404285049\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 242, train_loss = 17.089996649883687, train_acc = 0.9609920819748486\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 243, train_loss = 17.06720920652151, train_acc = 0.9612249650675361\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 244, train_loss = 17.044610999524593, train_acc = 0.9611085235211924\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 245, train_loss = 17.020866077393293, train_acc = 0.9611085235211924\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 246, train_loss = 16.999819613061845, train_acc = 0.9612249650675361\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 247, train_loss = 16.977083417586982, train_acc = 0.9612249650675361\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 248, train_loss = 16.955648231320083, train_acc = 0.9614578481602236\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 249, train_loss = 16.933533932082355, train_acc = 0.9615742897065673\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 250, train_loss = 16.91108298767358, train_acc = 0.9619236143455985\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 251, train_loss = 16.888209437020123, train_acc = 0.9620400558919422\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 252, train_loss = 16.869197316467762, train_acc = 0.9620400558919422\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 253, train_loss = 16.847157972864807, train_acc = 0.962156497438286\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 254, train_loss = 16.82538513839245, train_acc = 0.962156497438286\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 255, train_loss = 16.80503707472235, train_acc = 0.9622729389846297\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 256, train_loss = 16.784060712903738, train_acc = 0.9622729389846297\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 257, train_loss = 16.76394098252058, train_acc = 0.9623893805309734\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 258, train_loss = 16.742622992955148, train_acc = 0.9623893805309734\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 259, train_loss = 16.72374717053026, train_acc = 0.9625058220773172\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 260, train_loss = 16.703922185115516, train_acc = 0.9625058220773172\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 261, train_loss = 16.682935554534197, train_acc = 0.9625058220773172\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 262, train_loss = 16.663293004967272, train_acc = 0.9625058220773172\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 263, train_loss = 16.643605516292155, train_acc = 0.9625058220773172\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 264, train_loss = 16.62401621695608, train_acc = 0.9625058220773172\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 265, train_loss = 16.605326286517084, train_acc = 0.9626222636236609\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 266, train_loss = 16.58452778775245, train_acc = 0.9627387051700047\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 267, train_loss = 16.56647689267993, train_acc = 0.9629715882626921\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 268, train_loss = 16.547141193412244, train_acc = 0.9630880298090359\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 269, train_loss = 16.528437602333724, train_acc = 0.9630880298090359\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 270, train_loss = 16.51068279054016, train_acc = 0.9629715882626921\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 271, train_loss = 16.492074586451054, train_acc = 0.9629715882626921\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 272, train_loss = 16.47339349333197, train_acc = 0.9629715882626921\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 273, train_loss = 16.45533615257591, train_acc = 0.9633209129017233\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 274, train_loss = 16.436285187490284, train_acc = 0.9633209129017233\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 275, train_loss = 16.417428366839886, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 276, train_loss = 16.3998578004539, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 277, train_loss = 16.381555289961398, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 278, train_loss = 16.363781238906085, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 279, train_loss = 16.34737134631723, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 280, train_loss = 16.327917009592056, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 281, train_loss = 16.311363887041807, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 282, train_loss = 16.293646506033838, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 283, train_loss = 16.277466694824398, train_acc = 0.9637866790870983\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 284, train_loss = 16.258945365436375, train_acc = 0.9637866790870983\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 285, train_loss = 16.242612823843956, train_acc = 0.9637866790870983\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 286, train_loss = 16.224632926285267, train_acc = 0.9637866790870983\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 287, train_loss = 16.208493716083467, train_acc = 0.963903120633442\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 288, train_loss = 16.191964148543775, train_acc = 0.9640195621797858\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 289, train_loss = 16.17358387541026, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 290, train_loss = 16.15890399646014, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 291, train_loss = 16.141791340894997, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 292, train_loss = 16.125640475191176, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 293, train_loss = 16.109512007795274, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 294, train_loss = 16.09592057298869, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 295, train_loss = 16.078513752669096, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 296, train_loss = 16.062913763336837, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 297, train_loss = 16.046268523670733, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 298, train_loss = 16.03122374881059, train_acc = 0.9643688868188169\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 299, train_loss = 16.014369756914675, train_acc = 0.9643688868188169\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 300, train_loss = 16.00228863209486, train_acc = 0.9643688868188169\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 301, train_loss = 15.984347127377987, train_acc = 0.9643688868188169\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 302, train_loss = 15.969872963614762, train_acc = 0.9643688868188169\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 303, train_loss = 15.955317810177803, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 304, train_loss = 15.938824616372585, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 305, train_loss = 15.924747616052628, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 306, train_loss = 15.909630891866982, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 307, train_loss = 15.89484568592161, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 308, train_loss = 15.879188326187432, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 309, train_loss = 15.865589025430381, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 310, train_loss = 15.849950703792274, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 311, train_loss = 15.836090535856783, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 312, train_loss = 15.821892087347806, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 313, train_loss = 15.806604853831232, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 314, train_loss = 15.792276352643967, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 315, train_loss = 15.780240737833083, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 316, train_loss = 15.764784290455282, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 317, train_loss = 15.750699694268405, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 318, train_loss = 15.737043615430593, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 319, train_loss = 15.722418375313282, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 320, train_loss = 15.71109276264906, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 321, train_loss = 15.696721288375556, train_acc = 0.9654168607359106\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 322, train_loss = 15.682945281267166, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 323, train_loss = 15.670082815922797, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 324, train_loss = 15.654523474164307, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 325, train_loss = 15.643637836910784, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 326, train_loss = 15.629311700351536, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 327, train_loss = 15.616894013248384, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 328, train_loss = 15.603829733096063, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 329, train_loss = 15.591259370557964, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 330, train_loss = 15.57859992608428, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 331, train_loss = 15.56451518740505, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 332, train_loss = 15.550712551921606, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 333, train_loss = 15.537698983214796, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 334, train_loss = 15.526245801709592, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 335, train_loss = 15.512530762702227, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 336, train_loss = 15.501302100718021, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 337, train_loss = 15.488007144071162, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 338, train_loss = 15.476016014814377, train_acc = 0.9654168607359106\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 339, train_loss = 15.464854621328413, train_acc = 0.9654168607359106\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 340, train_loss = 15.451557225547731, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 341, train_loss = 15.440445479005575, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 342, train_loss = 15.42789425700903, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 343, train_loss = 15.414819260127842, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 344, train_loss = 15.404891718178988, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 345, train_loss = 15.393798424862325, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 346, train_loss = 15.380458227358758, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 347, train_loss = 15.36875332146883, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 348, train_loss = 15.357749044895172, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 349, train_loss = 15.345035813748837, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 350, train_loss = 15.3352210810408, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 351, train_loss = 15.320682801306248, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 352, train_loss = 15.312794922851026, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 353, train_loss = 15.2982406206429, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 354, train_loss = 15.287298289127648, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 355, train_loss = 15.276146220974624, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 356, train_loss = 15.266058526933193, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 357, train_loss = 15.252556473948061, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 358, train_loss = 15.242332325316966, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 359, train_loss = 15.231233336031437, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 360, train_loss = 15.222904124297202, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 361, train_loss = 15.20913602039218, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 362, train_loss = 15.198320916853845, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 363, train_loss = 15.188738741911948, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 364, train_loss = 15.177510698325932, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 365, train_loss = 15.166164427995682, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 366, train_loss = 15.155388708226383, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 367, train_loss = 15.145760740153491, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 368, train_loss = 15.135307718999684, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 369, train_loss = 15.123806718736887, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 370, train_loss = 15.115280353464186, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 371, train_loss = 15.105065965093672, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 372, train_loss = 15.093302194960415, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 373, train_loss = 15.0834128446877, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 374, train_loss = 15.073586366139352, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 375, train_loss = 15.06216595042497, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 376, train_loss = 15.051251077093184, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 377, train_loss = 15.043245906941593, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 378, train_loss = 15.031890127807856, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 379, train_loss = 15.022259059362113, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 380, train_loss = 15.013181529007852, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 381, train_loss = 15.005259088240564, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 382, train_loss = 14.9954031445086, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 383, train_loss = 14.983764749020338, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 384, train_loss = 14.974823602475226, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 385, train_loss = 14.965660479851067, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 386, train_loss = 14.95386893581599, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 387, train_loss = 14.945974932052195, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 388, train_loss = 14.936686646193266, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 389, train_loss = 14.92564603406936, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 390, train_loss = 14.918740708380938, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 391, train_loss = 14.908941726200283, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 392, train_loss = 14.897490094415843, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 393, train_loss = 14.89123088028282, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 394, train_loss = 14.880736991763115, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 395, train_loss = 14.870606853626668, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 396, train_loss = 14.86140725761652, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 397, train_loss = 14.85453653242439, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 398, train_loss = 14.845949550159276, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 399, train_loss = 14.834729433991015, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 400, train_loss = 14.82784849498421, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 401, train_loss = 14.815792658366263, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 402, train_loss = 14.810918587259948, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 403, train_loss = 14.80021903757006, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 404, train_loss = 14.789793339557946, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 405, train_loss = 14.78169497102499, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 406, train_loss = 14.77498981449753, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 407, train_loss = 14.767038787715137, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 408, train_loss = 14.759196135215461, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 409, train_loss = 14.750232038088143, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 410, train_loss = 14.737789567559958, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 411, train_loss = 14.731280487030745, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 412, train_loss = 14.724297136999667, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 413, train_loss = 14.715512292925268, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 414, train_loss = 14.704391380306333, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 415, train_loss = 14.70012592151761, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 416, train_loss = 14.69108788156882, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 417, train_loss = 14.682728813495487, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 418, train_loss = 14.674232283141464, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 419, train_loss = 14.665586090181023, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 420, train_loss = 14.65837380150333, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 421, train_loss = 14.649989475961775, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 422, train_loss = 14.641159081365913, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 423, train_loss = 14.632214189972728, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 424, train_loss = 14.62530693039298, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 425, train_loss = 14.618967685848475, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 426, train_loss = 14.609896063804626, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 427, train_loss = 14.60268630599603, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 428, train_loss = 14.59324627975002, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 429, train_loss = 14.58595838630572, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 430, train_loss = 14.57852272177115, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 431, train_loss = 14.5709461546503, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 432, train_loss = 14.564649185631424, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 433, train_loss = 14.554303746670485, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 434, train_loss = 14.54898639023304, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 435, train_loss = 14.540734509471804, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 436, train_loss = 14.532945109996945, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 437, train_loss = 14.526417436543852, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 438, train_loss = 14.518115546554327, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 439, train_loss = 14.511993328575045, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 440, train_loss = 14.50232316693291, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 441, train_loss = 14.496007524430752, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 442, train_loss = 14.488822098821402, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 443, train_loss = 14.48203415935859, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 444, train_loss = 14.474761541932821, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 445, train_loss = 14.466500187758356, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 446, train_loss = 14.462869267910719, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 447, train_loss = 14.454149194061756, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "23th- epoch: 448, train_loss = 14.445046591106802, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "23th- epoch: 449, train_loss = 14.439453600440174, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "23th- epoch: 450, train_loss = 14.43167549977079, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "23th- epoch: 451, train_loss = 14.425073998514563, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "23th- epoch: 452, train_loss = 14.419443788472563, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 453, train_loss = 14.410655282437801, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 454, train_loss = 14.405589482281357, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 455, train_loss = 14.397205721586943, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 456, train_loss = 14.393049389123917, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 457, train_loss = 14.384009627159685, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 458, train_loss = 14.376952869351953, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 459, train_loss = 14.373591870069504, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 460, train_loss = 14.365397228393704, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 461, train_loss = 14.357250208500773, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 462, train_loss = 14.352599112782627, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 463, train_loss = 14.34392841393128, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 464, train_loss = 14.337663783226162, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 465, train_loss = 14.330264117568731, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 466, train_loss = 14.324416724499315, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 467, train_loss = 14.317244234029204, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 468, train_loss = 14.31206031749025, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 469, train_loss = 14.305609177798033, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 470, train_loss = 14.298500979784876, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 471, train_loss = 14.292667591478676, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 472, train_loss = 14.285772936884314, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 473, train_loss = 14.279954688157886, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 474, train_loss = 14.2728312141262, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 475, train_loss = 14.268177147954702, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 476, train_loss = 14.261258034501225, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 477, train_loss = 14.258125940803438, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 478, train_loss = 14.24782558530569, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 479, train_loss = 14.242892132606357, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 480, train_loss = 14.235839553177357, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 481, train_loss = 14.229914490133524, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 482, train_loss = 14.223735927138478, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 483, train_loss = 14.218683934304863, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 484, train_loss = 14.212215289473534, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 485, train_loss = 14.20720187947154, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 486, train_loss = 14.199085286352783, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 487, train_loss = 14.195559460669756, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 488, train_loss = 14.188439432531595, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 489, train_loss = 14.183109868317842, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 490, train_loss = 14.176966944243759, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 491, train_loss = 14.171863859985024, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 492, train_loss = 14.166482672095299, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 493, train_loss = 14.161129323299974, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 494, train_loss = 14.152999124024063, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "23th- epoch: 495, train_loss = 14.14969164505601, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 496, train_loss = 14.142849755939096, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "23th- epoch: 497, train_loss = 14.137599941343069, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "23th- epoch: 498, train_loss = 14.131177278701216, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "23th- epoch: 499, train_loss = 14.124834217131138, train_acc = 0.9683278993945039\n",
      "test Acc 0.952048417132216:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████████████████████████████▏                | 23/30 [2:32:59<46:31, 398.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "24th- epoch: 0, train_loss = 271.89624774456024, train_acc = 0.39997671169073123\n",
      "test Acc 0.4925512104283054:\n",
      "24th- epoch: 1, train_loss = 215.56006860733032, train_acc = 0.4970889613414066\n",
      "test Acc 0.49906890130353815:\n",
      "24th- epoch: 2, train_loss = 181.31878316402435, train_acc = 0.5059385188635305\n",
      "test Acc 0.5218808193668529:\n",
      "24th- epoch: 3, train_loss = 164.09228771924973, train_acc = 0.5454122030740568\n",
      "test Acc 0.5786778398510242:\n",
      "24th- epoch: 4, train_loss = 151.14225363731384, train_acc = 0.5889613414066138\n",
      "test Acc 0.6135940409683427:\n",
      "24th- epoch: 5, train_loss = 139.61936795711517, train_acc = 0.622380065207266\n",
      "test Acc 0.6359404096834265:\n",
      "24th- epoch: 6, train_loss = 129.16272574663162, train_acc = 0.6424080111783884\n",
      "test Acc 0.6638733705772812:\n",
      "24th- epoch: 7, train_loss = 119.66637271642685, train_acc = 0.6851420586865393\n",
      "test Acc 0.7402234636871509:\n",
      "24th- epoch: 8, train_loss = 111.05738627910614, train_acc = 0.7405682347461574\n",
      "test Acc 0.7541899441340782:\n",
      "24th- epoch: 9, train_loss = 103.19310408830643, train_acc = 0.7715416860735911\n",
      "test Acc 0.7835195530726257:\n",
      "24th- epoch: 10, train_loss = 96.00991660356522, train_acc = 0.7986725663716814\n",
      "test Acc 0.8081936685288641:\n",
      "24th- epoch: 11, train_loss = 89.48900729417801, train_acc = 0.8161387983232418\n",
      "test Acc 0.8258845437616388:\n",
      "24th- epoch: 12, train_loss = 83.62589874863625, train_acc = 0.8277829529576153\n",
      "test Acc 0.8365921787709497:\n",
      "24th- epoch: 13, train_loss = 78.40727111697197, train_acc = 0.8400093153237075\n",
      "test Acc 0.8542830540037244:\n",
      "24th- epoch: 14, train_loss = 73.78617894649506, train_acc = 0.851653469958081\n",
      "test Acc 0.8594040968342644:\n",
      "24th- epoch: 15, train_loss = 69.7063213288784, train_acc = 0.8608523521192362\n",
      "test Acc 0.86731843575419:\n",
      "24th- epoch: 16, train_loss = 66.1039582490921, train_acc = 0.8632976245924546\n",
      "test Acc 0.87243947858473:\n",
      "24th- epoch: 17, train_loss = 62.919907957315445, train_acc = 0.8660922217047042\n",
      "test Acc 0.8752327746741154:\n",
      "24th- epoch: 18, train_loss = 60.09523415565491, train_acc = 0.8699347927340475\n",
      "test Acc 0.87756052141527:\n",
      "24th- epoch: 19, train_loss = 57.584303975105286, train_acc = 0.8770377270610153\n",
      "test Acc 0.8840782122905028:\n",
      "24th- epoch: 20, train_loss = 55.35196752846241, train_acc = 0.8812296227293899\n",
      "test Acc 0.8878026070763501:\n",
      "24th- epoch: 21, train_loss = 53.360938370227814, train_acc = 0.8868188169538892\n",
      "test Acc 0.8915270018621974:\n",
      "24th- epoch: 22, train_loss = 51.57958999276161, train_acc = 0.8919422449930136\n",
      "test Acc 0.8961824953445066:\n",
      "24th- epoch: 23, train_loss = 49.98381234705448, train_acc = 0.8946204005589194\n",
      "test Acc 0.8975791433891993:\n",
      "24th- epoch: 24, train_loss = 48.54861354827881, train_acc = 0.8969492314857941\n",
      "test Acc 0.9008379888268156:\n",
      "24th- epoch: 25, train_loss = 47.25191514194012, train_acc = 0.898346530041919\n",
      "test Acc 0.9017690875232774:\n",
      "24th- epoch: 26, train_loss = 46.07675510644913, train_acc = 0.9004424778761062\n",
      "test Acc 0.9027001862197392:\n",
      "24th- epoch: 27, train_loss = 45.00628054141998, train_acc = 0.9024219841639497\n",
      "test Acc 0.9050279329608939:\n",
      "24th- epoch: 28, train_loss = 44.02543540298939, train_acc = 0.9044014904517932\n",
      "test Acc 0.9059590316573557:\n",
      "24th- epoch: 29, train_loss = 43.12344716489315, train_acc = 0.9059152305542617\n",
      "test Acc 0.9078212290502793:\n",
      "24th- epoch: 30, train_loss = 42.291329711675644, train_acc = 0.9076618537494178\n",
      "test Acc 0.909683426443203:\n",
      "24th- epoch: 31, train_loss = 41.51932217180729, train_acc = 0.9089427107591989\n",
      "test Acc 0.910148975791434:\n",
      "24th- epoch: 32, train_loss = 40.80066341161728, train_acc = 0.911504424778761\n",
      "test Acc 0.9110800744878957:\n",
      "24th- epoch: 33, train_loss = 40.12911531329155, train_acc = 0.9134839310666045\n",
      "test Acc 0.9115456238361266:\n",
      "24th- epoch: 34, train_loss = 39.4993401914835, train_acc = 0.9147647880763856\n",
      "test Acc 0.9120111731843575:\n",
      "24th- epoch: 35, train_loss = 38.906581684947014, train_acc = 0.916394969725198\n",
      "test Acc 0.9134078212290503:\n",
      "24th- epoch: 36, train_loss = 38.34582310914993, train_acc = 0.9173265020959478\n",
      "test Acc 0.9157355679702048:\n",
      "24th- epoch: 37, train_loss = 37.81471088528633, train_acc = 0.9189566837447601\n",
      "test Acc 0.9157355679702048:\n",
      "24th- epoch: 38, train_loss = 37.31017903983593, train_acc = 0.9196553330228225\n",
      "test Acc 0.9162011173184358:\n",
      "24th- epoch: 39, train_loss = 36.82956622540951, train_acc = 0.9205868653935724\n",
      "test Acc 0.9180633147113594:\n",
      "24th- epoch: 40, train_loss = 36.37111775577068, train_acc = 0.9212855146716349\n",
      "test Acc 0.9185288640595903:\n",
      "24th- epoch: 41, train_loss = 35.9331344217062, train_acc = 0.9218677224033535\n",
      "test Acc 0.9199255121042831:\n",
      "24th- epoch: 42, train_loss = 35.514693304896355, train_acc = 0.922566371681416\n",
      "test Acc 0.9199255121042831:\n",
      "24th- epoch: 43, train_loss = 35.113354466855526, train_acc = 0.9231485794131346\n",
      "test Acc 0.9203910614525139:\n",
      "24th- epoch: 44, train_loss = 34.72770246118307, train_acc = 0.9234979040521658\n",
      "test Acc 0.9203910614525139:\n",
      "24th- epoch: 45, train_loss = 34.357513435184956, train_acc = 0.9244294364229158\n",
      "test Acc 0.9208566108007449:\n",
      "24th- epoch: 46, train_loss = 34.00070704519749, train_acc = 0.9258267349790406\n",
      "test Acc 0.9217877094972067:\n",
      "24th- epoch: 47, train_loss = 33.65634331852198, train_acc = 0.9262925011644154\n",
      "test Acc 0.9217877094972067:\n",
      "24th- epoch: 48, train_loss = 33.32507590204477, train_acc = 0.9269911504424779\n",
      "test Acc 0.9217877094972067:\n",
      "24th- epoch: 49, train_loss = 33.00516475737095, train_acc = 0.9279226828132278\n",
      "test Acc 0.9222532588454376:\n",
      "24th- epoch: 50, train_loss = 32.69596419483423, train_acc = 0.9286213320912902\n",
      "test Acc 0.9231843575418994:\n",
      "24th- epoch: 51, train_loss = 32.39659810066223, train_acc = 0.9293199813693526\n",
      "test Acc 0.9236499068901304:\n",
      "24th- epoch: 52, train_loss = 32.106256313622, train_acc = 0.9295528644620401\n",
      "test Acc 0.9241154562383612:\n",
      "24th- epoch: 53, train_loss = 31.8251718506217, train_acc = 0.930018630647415\n",
      "test Acc 0.9241154562383612:\n",
      "24th- epoch: 54, train_loss = 31.552195847034454, train_acc = 0.9306008383791337\n",
      "test Acc 0.9245810055865922:\n",
      "24th- epoch: 55, train_loss = 31.287253446877003, train_acc = 0.9307172799254774\n",
      "test Acc 0.925512104283054:\n",
      "24th- epoch: 56, train_loss = 31.029678530991077, train_acc = 0.9309501630181649\n",
      "test Acc 0.9259776536312849:\n",
      "24th- epoch: 57, train_loss = 30.779050067067146, train_acc = 0.9311830461108523\n",
      "test Acc 0.9264432029795159:\n",
      "24th- epoch: 58, train_loss = 30.534998804330826, train_acc = 0.9312994876571961\n",
      "test Acc 0.9264432029795159:\n",
      "24th- epoch: 59, train_loss = 30.297679975628853, train_acc = 0.9318816953889147\n",
      "test Acc 0.9264432029795159:\n",
      "24th- epoch: 60, train_loss = 30.06692149490118, train_acc = 0.932231020027946\n",
      "test Acc 0.9269087523277467:\n",
      "24th- epoch: 61, train_loss = 29.841446109116077, train_acc = 0.9325803446669771\n",
      "test Acc 0.9269087523277467:\n",
      "24th- epoch: 62, train_loss = 29.621940694749355, train_acc = 0.9330461108523521\n",
      "test Acc 0.9269087523277467:\n",
      "24th- epoch: 63, train_loss = 29.407358936965466, train_acc = 0.9331625523986958\n",
      "test Acc 0.9273743016759777:\n",
      "24th- epoch: 64, train_loss = 29.197549529373646, train_acc = 0.9335118770377271\n",
      "test Acc 0.9273743016759777:\n",
      "24th- epoch: 65, train_loss = 28.993089489638805, train_acc = 0.9336283185840708\n",
      "test Acc 0.9278398510242085:\n",
      "24th- epoch: 66, train_loss = 28.79303376376629, train_acc = 0.933977643223102\n",
      "test Acc 0.9278398510242085:\n",
      "24th- epoch: 67, train_loss = 28.597310721874237, train_acc = 0.9343269678621332\n",
      "test Acc 0.9278398510242085:\n",
      "24th- epoch: 68, train_loss = 28.406112872064114, train_acc = 0.9346762925011645\n",
      "test Acc 0.9278398510242085:\n",
      "24th- epoch: 69, train_loss = 28.218296766281128, train_acc = 0.9353749417792269\n",
      "test Acc 0.9278398510242085:\n",
      "24th- epoch: 70, train_loss = 28.034969933331013, train_acc = 0.935724266418258\n",
      "test Acc 0.9273743016759777:\n",
      "24th- epoch: 71, train_loss = 27.85548783838749, train_acc = 0.9358407079646017\n",
      "test Acc 0.9273743016759777:\n",
      "24th- epoch: 72, train_loss = 27.679462552070618, train_acc = 0.9360735910572893\n",
      "test Acc 0.9278398510242085:\n",
      "24th- epoch: 73, train_loss = 27.507385432720184, train_acc = 0.9365393572426641\n",
      "test Acc 0.9283054003724395:\n",
      "24th- epoch: 74, train_loss = 27.33893060684204, train_acc = 0.936655798789008\n",
      "test Acc 0.9287709497206704:\n",
      "24th- epoch: 75, train_loss = 27.173731118440628, train_acc = 0.9370051234280391\n",
      "test Acc 0.9287709497206704:\n",
      "24th- epoch: 76, train_loss = 27.011359311640263, train_acc = 0.9372380065207266\n",
      "test Acc 0.9287709497206704:\n",
      "24th- epoch: 77, train_loss = 26.852286994457245, train_acc = 0.9378202142524453\n",
      "test Acc 0.9297020484171322:\n",
      "24th- epoch: 78, train_loss = 26.69688367843628, train_acc = 0.9380530973451328\n",
      "test Acc 0.9301675977653632:\n",
      "24th- epoch: 79, train_loss = 26.544299606233835, train_acc = 0.9382859804378202\n",
      "test Acc 0.9301675977653632:\n",
      "24th- epoch: 80, train_loss = 26.39514010027051, train_acc = 0.9386353050768514\n",
      "test Acc 0.930633147113594:\n",
      "24th- epoch: 81, train_loss = 26.24897839128971, train_acc = 0.9389846297158826\n",
      "test Acc 0.930633147113594:\n",
      "24th- epoch: 82, train_loss = 26.105783093720675, train_acc = 0.9395668374476013\n",
      "test Acc 0.930633147113594:\n",
      "24th- epoch: 83, train_loss = 25.96481517702341, train_acc = 0.9404983698183512\n",
      "test Acc 0.930633147113594:\n",
      "24th- epoch: 84, train_loss = 25.827242489904165, train_acc = 0.9409641360037261\n",
      "test Acc 0.930633147113594:\n",
      "24th- epoch: 85, train_loss = 25.692120868712664, train_acc = 0.9417792268281323\n",
      "test Acc 0.930633147113594:\n",
      "24th- epoch: 86, train_loss = 25.559763472527266, train_acc = 0.9422449930135072\n",
      "test Acc 0.931098696461825:\n",
      "24th- epoch: 87, train_loss = 25.429624672979116, train_acc = 0.9431765253842571\n",
      "test Acc 0.931098696461825:\n",
      "24th- epoch: 88, train_loss = 25.301258862018585, train_acc = 0.9435258500232883\n",
      "test Acc 0.9315642458100558:\n",
      "24th- epoch: 89, train_loss = 25.17664771527052, train_acc = 0.9435258500232883\n",
      "test Acc 0.9315642458100558:\n",
      "24th- epoch: 90, train_loss = 25.053002689033747, train_acc = 0.9443409408476945\n",
      "test Acc 0.9315642458100558:\n",
      "24th- epoch: 91, train_loss = 24.93226471915841, train_acc = 0.9445738239403819\n",
      "test Acc 0.9320297951582868:\n",
      "24th- epoch: 92, train_loss = 24.813596542924643, train_acc = 0.9448067070330693\n",
      "test Acc 0.9320297951582868:\n",
      "24th- epoch: 93, train_loss = 24.696725994348526, train_acc = 0.9450395901257569\n",
      "test Acc 0.9324953445065177:\n",
      "24th- epoch: 94, train_loss = 24.58223605528474, train_acc = 0.9451560316721006\n",
      "test Acc 0.9324953445065177:\n",
      "24th- epoch: 95, train_loss = 24.469608761370182, train_acc = 0.9456217978574756\n",
      "test Acc 0.9329608938547486:\n",
      "24th- epoch: 96, train_loss = 24.35893927514553, train_acc = 0.9457382394038193\n",
      "test Acc 0.9329608938547486:\n",
      "24th- epoch: 97, train_loss = 24.250693026930094, train_acc = 0.9459711224965067\n",
      "test Acc 0.9338919925512105:\n",
      "24th- epoch: 98, train_loss = 24.143977843225002, train_acc = 0.9459711224965067\n",
      "test Acc 0.9338919925512105:\n",
      "24th- epoch: 99, train_loss = 24.03935819864273, train_acc = 0.9462040055891943\n",
      "test Acc 0.9338919925512105:\n",
      "24th- epoch: 100, train_loss = 23.936465851962566, train_acc = 0.9462040055891943\n",
      "test Acc 0.9338919925512105:\n",
      "24th- epoch: 101, train_loss = 23.834914788603783, train_acc = 0.9464368886818817\n",
      "test Acc 0.9338919925512105:\n",
      "24th- epoch: 102, train_loss = 23.73540686070919, train_acc = 0.9466697717745691\n",
      "test Acc 0.9343575418994413:\n",
      "24th- epoch: 103, train_loss = 23.63761369511485, train_acc = 0.9465533302282254\n",
      "test Acc 0.9343575418994413:\n",
      "24th- epoch: 104, train_loss = 23.541441790759563, train_acc = 0.9469026548672567\n",
      "test Acc 0.9348230912476723:\n",
      "24th- epoch: 105, train_loss = 23.446572199463844, train_acc = 0.9470190964136004\n",
      "test Acc 0.9348230912476723:\n",
      "24th- epoch: 106, train_loss = 23.35431347042322, train_acc = 0.9472519795062878\n",
      "test Acc 0.9352886405959032:\n",
      "24th- epoch: 107, train_loss = 23.26209209114313, train_acc = 0.9472519795062878\n",
      "test Acc 0.9352886405959032:\n",
      "24th- epoch: 108, train_loss = 23.172147557139397, train_acc = 0.9472519795062878\n",
      "test Acc 0.9352886405959032:\n",
      "24th- epoch: 109, train_loss = 23.08393247053027, train_acc = 0.9474848625989754\n",
      "test Acc 0.9352886405959032:\n",
      "24th- epoch: 110, train_loss = 22.996758863329887, train_acc = 0.9477177456916628\n",
      "test Acc 0.9352886405959032:\n",
      "24th- epoch: 111, train_loss = 22.91063265874982, train_acc = 0.9477177456916628\n",
      "test Acc 0.9352886405959032:\n",
      "24th- epoch: 112, train_loss = 22.825585953891277, train_acc = 0.9478341872380065\n",
      "test Acc 0.9352886405959032:\n",
      "24th- epoch: 113, train_loss = 22.74232641980052, train_acc = 0.948067070330694\n",
      "test Acc 0.9352886405959032:\n",
      "24th- epoch: 114, train_loss = 22.65962454676628, train_acc = 0.948067070330694\n",
      "test Acc 0.9357541899441341:\n",
      "24th- epoch: 115, train_loss = 22.578820139169693, train_acc = 0.9484163949697252\n",
      "test Acc 0.9357541899441341:\n",
      "24th- epoch: 116, train_loss = 22.49916471913457, train_acc = 0.9492314857941313\n",
      "test Acc 0.9357541899441341:\n",
      "24th- epoch: 117, train_loss = 22.420400761067867, train_acc = 0.9496972519795063\n",
      "test Acc 0.936219739292365:\n",
      "24th- epoch: 118, train_loss = 22.34228478744626, train_acc = 0.94981369352585\n",
      "test Acc 0.936219739292365:\n",
      "24th- epoch: 119, train_loss = 22.26615248993039, train_acc = 0.9500465766185375\n",
      "test Acc 0.9366852886405959:\n",
      "24th- epoch: 120, train_loss = 22.190578941255808, train_acc = 0.950279459711225\n",
      "test Acc 0.9366852886405959:\n",
      "24th- epoch: 121, train_loss = 22.11553417891264, train_acc = 0.9505123428039124\n",
      "test Acc 0.9376163873370578:\n",
      "24th- epoch: 122, train_loss = 22.042858358472586, train_acc = 0.9507452258965999\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 123, train_loss = 21.96935625001788, train_acc = 0.9508616674429436\n",
      "test Acc 0.9385474860335196:\n",
      "24th- epoch: 124, train_loss = 21.89868124946952, train_acc = 0.9508616674429436\n",
      "test Acc 0.9385474860335196:\n",
      "24th- epoch: 125, train_loss = 21.82833381742239, train_acc = 0.9510945505356311\n",
      "test Acc 0.9385474860335196:\n",
      "24th- epoch: 126, train_loss = 21.758280336856842, train_acc = 0.9513274336283186\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 127, train_loss = 21.689642060548067, train_acc = 0.9513274336283186\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 128, train_loss = 21.621549874544144, train_acc = 0.9514438751746623\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 129, train_loss = 21.554465975612402, train_acc = 0.951560316721006\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 130, train_loss = 21.488104425370693, train_acc = 0.9516767582673498\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 131, train_loss = 21.42271515727043, train_acc = 0.9519096413600373\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 132, train_loss = 21.357938036322594, train_acc = 0.9521425244527247\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 133, train_loss = 21.293620638549328, train_acc = 0.952026082906381\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 134, train_loss = 21.23129203543067, train_acc = 0.9522589659990685\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 135, train_loss = 21.16847337037325, train_acc = 0.9523754075454122\n",
      "test Acc 0.9390130353817505:\n",
      "24th- epoch: 136, train_loss = 21.106495052576065, train_acc = 0.952491849091756\n",
      "test Acc 0.9390130353817505:\n",
      "24th- epoch: 137, train_loss = 21.045843940228224, train_acc = 0.9526082906380997\n",
      "test Acc 0.9390130353817505:\n",
      "24th- epoch: 138, train_loss = 20.98552453890443, train_acc = 0.9527247321844434\n",
      "test Acc 0.9390130353817505:\n",
      "24th- epoch: 139, train_loss = 20.92581793665886, train_acc = 0.9528411737307871\n",
      "test Acc 0.9394785847299814:\n",
      "24th- epoch: 140, train_loss = 20.866952046751976, train_acc = 0.9530740568234746\n",
      "test Acc 0.9399441340782123:\n",
      "24th- epoch: 141, train_loss = 20.809655174613, train_acc = 0.9533069399161621\n",
      "test Acc 0.9399441340782123:\n",
      "24th- epoch: 142, train_loss = 20.751747474074364, train_acc = 0.9534233814625058\n",
      "test Acc 0.9399441340782123:\n",
      "24th- epoch: 143, train_loss = 20.695701878517866, train_acc = 0.9534233814625058\n",
      "test Acc 0.9399441340782123:\n",
      "24th- epoch: 144, train_loss = 20.63958326727152, train_acc = 0.9535398230088495\n",
      "test Acc 0.9399441340782123:\n",
      "24th- epoch: 145, train_loss = 20.583518128842115, train_acc = 0.9537727061015371\n",
      "test Acc 0.9399441340782123:\n",
      "24th- epoch: 146, train_loss = 20.5288907289505, train_acc = 0.9538891476478808\n",
      "test Acc 0.9399441340782123:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 147, train_loss = 20.47434864938259, train_acc = 0.9538891476478808\n",
      "test Acc 0.9404096834264432:\n",
      "24th- epoch: 148, train_loss = 20.42115818336606, train_acc = 0.9541220307405682\n",
      "test Acc 0.9404096834264432:\n",
      "24th- epoch: 149, train_loss = 20.3672742433846, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 150, train_loss = 20.31458828225732, train_acc = 0.9544713553795995\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 151, train_loss = 20.262642480432987, train_acc = 0.9545877969259432\n",
      "test Acc 0.9404096834264432:\n",
      "24th- epoch: 152, train_loss = 20.21140739135444, train_acc = 0.9545877969259432\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 153, train_loss = 20.159822018817067, train_acc = 0.9547042384722869\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 154, train_loss = 20.10947346687317, train_acc = 0.9551700046576619\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 155, train_loss = 20.059352533891797, train_acc = 0.9552864462040056\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 156, train_loss = 20.0099630728364, train_acc = 0.9552864462040056\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 157, train_loss = 19.960635425522923, train_acc = 0.9554028877503493\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 158, train_loss = 19.912441009655595, train_acc = 0.9556357708430367\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 159, train_loss = 19.864043470472097, train_acc = 0.9556357708430367\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 160, train_loss = 19.816384460777044, train_acc = 0.9557522123893806\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 161, train_loss = 19.76947590522468, train_acc = 0.9557522123893806\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 162, train_loss = 19.72263596765697, train_acc = 0.9558686539357243\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 163, train_loss = 19.676802756264806, train_acc = 0.9558686539357243\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 164, train_loss = 19.63124811090529, train_acc = 0.955985095482068\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 165, train_loss = 19.585875744000077, train_acc = 0.955985095482068\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 166, train_loss = 19.54104238189757, train_acc = 0.9561015370284117\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 167, train_loss = 19.49698737449944, train_acc = 0.9563344201210993\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 168, train_loss = 19.453332198783755, train_acc = 0.9563344201210993\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 169, train_loss = 19.409483270719647, train_acc = 0.956450861667443\n",
      "test Acc 0.9413407821229051:\n",
      "24th- epoch: 170, train_loss = 19.366460727527738, train_acc = 0.9565673032137867\n",
      "test Acc 0.9413407821229051:\n",
      "24th- epoch: 171, train_loss = 19.32423552684486, train_acc = 0.9566837447601304\n",
      "test Acc 0.9413407821229051:\n",
      "24th- epoch: 172, train_loss = 19.28156611137092, train_acc = 0.9566837447601304\n",
      "test Acc 0.9413407821229051:\n",
      "24th- epoch: 173, train_loss = 19.240295682102442, train_acc = 0.9566837447601304\n",
      "test Acc 0.9413407821229051:\n",
      "24th- epoch: 174, train_loss = 19.198287937790155, train_acc = 0.9566837447601304\n",
      "test Acc 0.9413407821229051:\n",
      "24th- epoch: 175, train_loss = 19.157178012654185, train_acc = 0.9570330693991617\n",
      "test Acc 0.9418063314711359:\n",
      "24th- epoch: 176, train_loss = 19.116627551615238, train_acc = 0.9571495109455054\n",
      "test Acc 0.9418063314711359:\n",
      "24th- epoch: 177, train_loss = 19.076202979311347, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "24th- epoch: 178, train_loss = 19.036647871136665, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "24th- epoch: 179, train_loss = 18.996633427217603, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "24th- epoch: 180, train_loss = 18.957811187952757, train_acc = 0.9574988355845365\n",
      "test Acc 0.9422718808193669:\n",
      "24th- epoch: 181, train_loss = 18.91876764036715, train_acc = 0.9574988355845365\n",
      "test Acc 0.9422718808193669:\n",
      "24th- epoch: 182, train_loss = 18.88051071576774, train_acc = 0.9576152771308803\n",
      "test Acc 0.9422718808193669:\n",
      "24th- epoch: 183, train_loss = 18.841741951182485, train_acc = 0.9576152771308803\n",
      "test Acc 0.9427374301675978:\n",
      "24th- epoch: 184, train_loss = 18.80447323806584, train_acc = 0.9576152771308803\n",
      "test Acc 0.9432029795158287:\n",
      "24th- epoch: 185, train_loss = 18.766887191683054, train_acc = 0.9576152771308803\n",
      "test Acc 0.9432029795158287:\n",
      "24th- epoch: 186, train_loss = 18.729529928416014, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "24th- epoch: 187, train_loss = 18.69339712150395, train_acc = 0.9577317186772241\n",
      "test Acc 0.9441340782122905:\n",
      "24th- epoch: 188, train_loss = 18.657028388231993, train_acc = 0.9578481602235678\n",
      "test Acc 0.9441340782122905:\n",
      "24th- epoch: 189, train_loss = 18.62016472965479, train_acc = 0.9579646017699115\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 190, train_loss = 18.585239751264453, train_acc = 0.9580810433162552\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 191, train_loss = 18.550398701801896, train_acc = 0.9581974848625989\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 192, train_loss = 18.514865456148982, train_acc = 0.9583139264089428\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 193, train_loss = 18.48026649467647, train_acc = 0.9583139264089428\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 194, train_loss = 18.44626029022038, train_acc = 0.9583139264089428\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 195, train_loss = 18.411760428920388, train_acc = 0.9584303679552865\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 196, train_loss = 18.378198703750968, train_acc = 0.9585468095016302\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 197, train_loss = 18.344067011028528, train_acc = 0.9585468095016302\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 198, train_loss = 18.311428125947714, train_acc = 0.9585468095016302\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 199, train_loss = 18.278782127425075, train_acc = 0.9585468095016302\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 200, train_loss = 18.245817579329014, train_acc = 0.9585468095016302\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 201, train_loss = 18.21319324336946, train_acc = 0.9587796925943176\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 202, train_loss = 18.181154316291213, train_acc = 0.9587796925943176\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 203, train_loss = 18.149869265034795, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 204, train_loss = 18.117964262142777, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 205, train_loss = 18.086571453139186, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 206, train_loss = 18.05647754855454, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 207, train_loss = 18.025121698156, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 208, train_loss = 17.995613902807236, train_acc = 0.9590125756870052\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 209, train_loss = 17.965645326301455, train_acc = 0.9590125756870052\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 210, train_loss = 17.935308933258057, train_acc = 0.9591290172333489\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 211, train_loss = 17.90513152629137, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 212, train_loss = 17.876729359850287, train_acc = 0.95947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 213, train_loss = 17.846496606245637, train_acc = 0.9595947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 214, train_loss = 17.818223709240556, train_acc = 0.959944108057755\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 215, train_loss = 17.789779722690582, train_acc = 0.959944108057755\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 216, train_loss = 17.761404374614358, train_acc = 0.959944108057755\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 217, train_loss = 17.732997931540012, train_acc = 0.959944108057755\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 218, train_loss = 17.70584437996149, train_acc = 0.9600605496040987\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 219, train_loss = 17.67844640277326, train_acc = 0.9600605496040987\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 220, train_loss = 17.650481624528766, train_acc = 0.9600605496040987\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 221, train_loss = 17.622899800539017, train_acc = 0.9601769911504425\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 222, train_loss = 17.59686348028481, train_acc = 0.9601769911504425\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 223, train_loss = 17.57001742348075, train_acc = 0.9602934326967862\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 224, train_loss = 17.54365848749876, train_acc = 0.96040987424313\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 225, train_loss = 17.51723281107843, train_acc = 0.9605263157894737\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 226, train_loss = 17.491193341091275, train_acc = 0.9606427573358174\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 227, train_loss = 17.465232346206903, train_acc = 0.9606427573358174\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 228, train_loss = 17.439431505277753, train_acc = 0.9607591988821611\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 229, train_loss = 17.414281951263547, train_acc = 0.9607591988821611\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 230, train_loss = 17.38948900066316, train_acc = 0.9608756404285049\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 231, train_loss = 17.364892894402146, train_acc = 0.9608756404285049\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 232, train_loss = 17.339118788018823, train_acc = 0.9608756404285049\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 233, train_loss = 17.315929295495152, train_acc = 0.9608756404285049\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 234, train_loss = 17.29100678488612, train_acc = 0.9608756404285049\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 235, train_loss = 17.26636948250234, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 236, train_loss = 17.243092246353626, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 237, train_loss = 17.218692099675536, train_acc = 0.9608756404285049\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 238, train_loss = 17.195772802457213, train_acc = 0.9609920819748486\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 239, train_loss = 17.17334021255374, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 240, train_loss = 17.148519663140178, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 241, train_loss = 17.125347202643752, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 242, train_loss = 17.10372489131987, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 243, train_loss = 17.080505615100265, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 244, train_loss = 17.058165637776256, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 245, train_loss = 17.035762643441558, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 246, train_loss = 17.0135444002226, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 247, train_loss = 16.991879506967962, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 248, train_loss = 16.970441177487373, train_acc = 0.9613414066138798\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 249, train_loss = 16.94870436191559, train_acc = 0.9614578481602236\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 250, train_loss = 16.927027866244316, train_acc = 0.9614578481602236\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 251, train_loss = 16.906036692671478, train_acc = 0.9615742897065673\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 252, train_loss = 16.884305774234235, train_acc = 0.9615742897065673\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 253, train_loss = 16.862970179878175, train_acc = 0.9615742897065673\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 254, train_loss = 16.842204897664487, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 255, train_loss = 16.821730659343302, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 256, train_loss = 16.801041569560766, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 257, train_loss = 16.78166299685836, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 258, train_loss = 16.760467525571585, train_acc = 0.962156497438286\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 259, train_loss = 16.740171167068183, train_acc = 0.9623893805309734\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 260, train_loss = 16.719950201921165, train_acc = 0.9625058220773172\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 261, train_loss = 16.701107318513095, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 262, train_loss = 16.68096701335162, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 263, train_loss = 16.66153536364436, train_acc = 0.9626222636236609\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 264, train_loss = 16.642405628226697, train_acc = 0.9627387051700047\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 265, train_loss = 16.623840159736574, train_acc = 0.9628551467163484\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 266, train_loss = 16.605270251631737, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 267, train_loss = 16.585765860043466, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 268, train_loss = 16.567938596010208, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 269, train_loss = 16.54806151986122, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 270, train_loss = 16.528991227038205, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 271, train_loss = 16.510815183632076, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 272, train_loss = 16.493275941349566, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 273, train_loss = 16.475234725512564, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 274, train_loss = 16.455921822227538, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 275, train_loss = 16.43806190509349, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 276, train_loss = 16.420296747237444, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 277, train_loss = 16.40348435100168, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 278, train_loss = 16.385925174690783, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 279, train_loss = 16.367933493107557, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 280, train_loss = 16.35100921150297, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 281, train_loss = 16.335071083158255, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 282, train_loss = 16.31782902404666, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 283, train_loss = 16.301843132823706, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 284, train_loss = 16.28499868977815, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 285, train_loss = 16.267365793697536, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 286, train_loss = 16.25156536605209, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 287, train_loss = 16.234328381717205, train_acc = 0.9634373544480671\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 288, train_loss = 16.21838256996125, train_acc = 0.9636702375407545\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 289, train_loss = 16.20198806747794, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 290, train_loss = 16.184332695789635, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 291, train_loss = 16.168896298855543, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 292, train_loss = 16.153749861754477, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 293, train_loss = 16.137729191221297, train_acc = 0.9641360037261295\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 294, train_loss = 16.122363354079425, train_acc = 0.9641360037261295\n",
      "test Acc 0.9483240223463687:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 295, train_loss = 16.1064227335155, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 296, train_loss = 16.09101988375187, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 297, train_loss = 16.074869466014206, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 298, train_loss = 16.060388355515897, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 299, train_loss = 16.045184643007815, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 300, train_loss = 16.03049007896334, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 301, train_loss = 16.015128057450056, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 302, train_loss = 16.0006911912933, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 303, train_loss = 15.985406319610775, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 304, train_loss = 15.969780125655234, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 305, train_loss = 15.956508189439774, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 306, train_loss = 15.939470797777176, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 307, train_loss = 15.926451563835144, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 308, train_loss = 15.91271011903882, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 309, train_loss = 15.898126013576984, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 310, train_loss = 15.88404390309006, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 311, train_loss = 15.869154028594494, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 312, train_loss = 15.854710434563458, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 313, train_loss = 15.842351735569537, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 314, train_loss = 15.826816932298243, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 315, train_loss = 15.811742796562612, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 316, train_loss = 15.79694430436939, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 317, train_loss = 15.78338351752609, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 318, train_loss = 15.769055566750467, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 319, train_loss = 15.756499644368887, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 320, train_loss = 15.743356596678495, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 321, train_loss = 15.730468372814357, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 322, train_loss = 15.713808495551348, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 323, train_loss = 15.699495729990304, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 324, train_loss = 15.687920360825956, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 325, train_loss = 15.673080903477967, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 326, train_loss = 15.661325831897557, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 327, train_loss = 15.646405946463346, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 328, train_loss = 15.63511140178889, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 329, train_loss = 15.620725303888321, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 330, train_loss = 15.608645089901984, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 331, train_loss = 15.596194665879011, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 332, train_loss = 15.583565362729132, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 333, train_loss = 15.571096456609666, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 334, train_loss = 15.55864978209138, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 335, train_loss = 15.546846960671246, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 336, train_loss = 15.532917827367783, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 337, train_loss = 15.521852638572454, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 338, train_loss = 15.509599548764527, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 339, train_loss = 15.498349248431623, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 340, train_loss = 15.48507600557059, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 341, train_loss = 15.47300835326314, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 342, train_loss = 15.461717030964792, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 343, train_loss = 15.451616481877863, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 344, train_loss = 15.43703390005976, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 345, train_loss = 15.426055751740932, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 346, train_loss = 15.413989226333797, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 347, train_loss = 15.403441697359085, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 348, train_loss = 15.391131967306137, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 349, train_loss = 15.381166197359562, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 350, train_loss = 15.369277380406857, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 351, train_loss = 15.35744197666645, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 352, train_loss = 15.345876564271748, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 353, train_loss = 15.335076868534088, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 354, train_loss = 15.323940592817962, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 355, train_loss = 15.313020317815244, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 356, train_loss = 15.301829975098372, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 357, train_loss = 15.29145900066942, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 358, train_loss = 15.279217614792287, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 359, train_loss = 15.269657357595861, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 360, train_loss = 15.258492558263242, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 361, train_loss = 15.24726511631161, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 362, train_loss = 15.238650855608284, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 363, train_loss = 15.225652047432959, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 364, train_loss = 15.216616618447006, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 365, train_loss = 15.205074940808117, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 366, train_loss = 15.195025159977376, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 367, train_loss = 15.18635040242225, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 368, train_loss = 15.174604534171522, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 369, train_loss = 15.163978758268058, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 370, train_loss = 15.154966283589602, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 371, train_loss = 15.144624975509942, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 372, train_loss = 15.134063117206097, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 373, train_loss = 15.124325570650399, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 374, train_loss = 15.113956958055496, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 375, train_loss = 15.10488311946392, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 376, train_loss = 15.093733351677656, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 377, train_loss = 15.08472242206335, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 378, train_loss = 15.074349209666252, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 379, train_loss = 15.065852417610586, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 380, train_loss = 15.054444239474833, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 381, train_loss = 15.045925927348435, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 382, train_loss = 15.035440180450678, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 383, train_loss = 15.026383326388896, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 384, train_loss = 15.017448275350034, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 385, train_loss = 15.005766361020505, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 386, train_loss = 14.997091920115054, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 387, train_loss = 14.988149382174015, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 388, train_loss = 14.979011320509017, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 389, train_loss = 14.96898824069649, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 390, train_loss = 14.96254217904061, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 391, train_loss = 14.951071161776781, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 392, train_loss = 14.943216919898987, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 393, train_loss = 14.931932792067528, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 394, train_loss = 14.923386880196631, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 395, train_loss = 14.913367693312466, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 396, train_loss = 14.904940315522254, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 397, train_loss = 14.896298446692526, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 398, train_loss = 14.887670633383095, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 399, train_loss = 14.879565861076117, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 400, train_loss = 14.869706322439015, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 401, train_loss = 14.86226745788008, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 402, train_loss = 14.850891339592636, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 403, train_loss = 14.843649458140135, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 404, train_loss = 14.83452817518264, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 405, train_loss = 14.826828885823488, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 406, train_loss = 14.818278352729976, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 407, train_loss = 14.810443912632763, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 408, train_loss = 14.801076718606055, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 409, train_loss = 14.790533644147217, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 410, train_loss = 14.782391421496868, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 411, train_loss = 14.774874289520085, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 412, train_loss = 14.765182516537607, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 413, train_loss = 14.757750692777336, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 414, train_loss = 14.750069956295192, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 415, train_loss = 14.740967694669962, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 416, train_loss = 14.73439731169492, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 417, train_loss = 14.724311016499996, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 418, train_loss = 14.716824133880436, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 419, train_loss = 14.708534579724073, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 420, train_loss = 14.698857876472175, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 421, train_loss = 14.692733071744442, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 422, train_loss = 14.684796349145472, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 423, train_loss = 14.676456424407661, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 424, train_loss = 14.669054638594389, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 425, train_loss = 14.660740035586059, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 426, train_loss = 14.65596563089639, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 427, train_loss = 14.64492539409548, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "24th- epoch: 428, train_loss = 14.637432482093573, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 429, train_loss = 14.631283980794251, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "24th- epoch: 430, train_loss = 14.623284392990172, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 431, train_loss = 14.614697790704668, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 432, train_loss = 14.60632226523012, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 433, train_loss = 14.599847693927586, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 434, train_loss = 14.591982319019735, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 435, train_loss = 14.584821688942611, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 436, train_loss = 14.576887390576303, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 437, train_loss = 14.569374532438815, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 438, train_loss = 14.56238779053092, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 439, train_loss = 14.554538588039577, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 440, train_loss = 14.547114093787968, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 441, train_loss = 14.539334748871624, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 442, train_loss = 14.533604920841753, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 443, train_loss = 14.524814829230309, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 444, train_loss = 14.518778648227453, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 445, train_loss = 14.51208283752203, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 446, train_loss = 14.503687231335789, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 447, train_loss = 14.495948305819184, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 448, train_loss = 14.489169288426638, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 449, train_loss = 14.481686947401613, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 450, train_loss = 14.475022362079471, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 451, train_loss = 14.467628499958664, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 452, train_loss = 14.461105192545801, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 453, train_loss = 14.454527715686709, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 454, train_loss = 14.445898238569498, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 455, train_loss = 14.440235264599323, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 456, train_loss = 14.43194979056716, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 457, train_loss = 14.426645446568727, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 458, train_loss = 14.418461131397635, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 459, train_loss = 14.412551928311586, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 460, train_loss = 14.403949575964361, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 461, train_loss = 14.39832478761673, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 462, train_loss = 14.391699396073818, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 463, train_loss = 14.384939979761839, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 464, train_loss = 14.380847997963428, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 465, train_loss = 14.371639803051949, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 466, train_loss = 14.365442910697311, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 467, train_loss = 14.35967788984999, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 468, train_loss = 14.352479040622711, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 469, train_loss = 14.3464912250638, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 470, train_loss = 14.340048829559237, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 471, train_loss = 14.33346118638292, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 472, train_loss = 14.325966177973896, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 473, train_loss = 14.321148429065943, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 474, train_loss = 14.31490928446874, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 475, train_loss = 14.308183082845062, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 476, train_loss = 14.300501444842666, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 477, train_loss = 14.294739651028067, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 478, train_loss = 14.288759654853493, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 479, train_loss = 14.283460145350546, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 480, train_loss = 14.276481521781534, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 481, train_loss = 14.271151331719011, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 482, train_loss = 14.26345936441794, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 483, train_loss = 14.258306786417961, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 484, train_loss = 14.250561021268368, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 485, train_loss = 14.245096186641604, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 486, train_loss = 14.239347281400114, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 487, train_loss = 14.233075994998217, train_acc = 0.9683278993945039\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 488, train_loss = 14.227670565247536, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 489, train_loss = 14.221292616333812, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 490, train_loss = 14.215583874378353, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 491, train_loss = 14.209210419561714, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 492, train_loss = 14.202413957566023, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 493, train_loss = 14.19793533300981, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 494, train_loss = 14.192843608558178, train_acc = 0.9684443409408477\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 495, train_loss = 14.186621644999832, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 496, train_loss = 14.179201805498451, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 497, train_loss = 14.174225227441639, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 498, train_loss = 14.168419394642115, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n",
      "24th- epoch: 499, train_loss = 14.162819581571966, train_acc = 0.9685607824871915\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████▌              | 24/30 [2:39:37<39:51, 398.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "25th- epoch: 0, train_loss = 273.3110851049423, train_acc = 0.45051234280391245\n",
      "test Acc 0.49813780260707635:\n",
      "25th- epoch: 1, train_loss = 214.79655289649963, train_acc = 0.4998835584536563\n",
      "test Acc 0.4995344506517691:\n",
      "25th- epoch: 2, train_loss = 179.8835985660553, train_acc = 0.5064042850489054\n",
      "test Acc 0.5144320297951583:\n",
      "25th- epoch: 3, train_loss = 162.83220356702805, train_acc = 0.5346995808104331\n",
      "test Acc 0.5614525139664804:\n",
      "25th- epoch: 4, train_loss = 149.37037640810013, train_acc = 0.5862831858407079\n",
      "test Acc 0.6131284916201117:\n",
      "25th- epoch: 5, train_loss = 137.4279350042343, train_acc = 0.6221471821145785\n",
      "test Acc 0.6415270018621974:\n",
      "25th- epoch: 6, train_loss = 126.60600370168686, train_acc = 0.6547508150908244\n",
      "test Acc 0.6703910614525139:\n",
      "25th- epoch: 7, train_loss = 116.89266419410706, train_acc = 0.7014438751746623\n",
      "test Acc 0.7569832402234636:\n",
      "25th- epoch: 8, train_loss = 108.20266318321228, train_acc = 0.7695621797857476\n",
      "test Acc 0.7844506517690876:\n",
      "25th- epoch: 9, train_loss = 100.370660841465, train_acc = 0.7963437354448067\n",
      "test Acc 0.8035381750465549:\n",
      "25th- epoch: 10, train_loss = 93.25248438119888, train_acc = 0.8095016301816488\n",
      "test Acc 0.8165735567970205:\n",
      "25th- epoch: 11, train_loss = 86.83735111355782, train_acc = 0.8191662785281788\n",
      "test Acc 0.8263500931098696:\n",
      "25th- epoch: 12, train_loss = 81.11219882965088, train_acc = 0.8310433162552399\n",
      "test Acc 0.8426443202979516:\n",
      "25th- epoch: 13, train_loss = 76.03080376982689, train_acc = 0.8431532370749883\n",
      "test Acc 0.8524208566108007:\n",
      "25th- epoch: 14, train_loss = 71.54239422082901, train_acc = 0.852119236143456\n",
      "test Acc 0.8584729981378026:\n",
      "25th- epoch: 15, train_loss = 67.58882334828377, train_acc = 0.8595714951094551\n",
      "test Acc 0.8645251396648045:\n",
      "25th- epoch: 16, train_loss = 64.09797111153603, train_acc = 0.8636469492314858\n",
      "test Acc 0.8682495344506518:\n",
      "25th- epoch: 17, train_loss = 61.02044519782066, train_acc = 0.8690032603632977\n",
      "test Acc 0.8794227188081937:\n",
      "25th- epoch: 18, train_loss = 58.30110168457031, train_acc = 0.8755239869585468\n",
      "test Acc 0.8854748603351955:\n",
      "25th- epoch: 19, train_loss = 55.89367899298668, train_acc = 0.8804145319049836\n",
      "test Acc 0.8905959031657356:\n",
      "25th- epoch: 20, train_loss = 53.752871587872505, train_acc = 0.8828598043782021\n",
      "test Acc 0.8924581005586593:\n",
      "25th- epoch: 21, train_loss = 51.84881289303303, train_acc = 0.8858872845831393\n",
      "test Acc 0.8943202979515829:\n",
      "25th- epoch: 22, train_loss = 50.15351319313049, train_acc = 0.8897298556124825\n",
      "test Acc 0.8985102420856611:\n",
      "25th- epoch: 23, train_loss = 48.635840609669685, train_acc = 0.892175128085701\n",
      "test Acc 0.9017690875232774:\n",
      "25th- epoch: 24, train_loss = 47.2711124420166, train_acc = 0.8975314392175128\n",
      "test Acc 0.9022346368715084:\n",
      "25th- epoch: 25, train_loss = 46.03695188462734, train_acc = 0.9003260363297625\n",
      "test Acc 0.9036312849162011:\n",
      "25th- epoch: 26, train_loss = 44.915034130215645, train_acc = 0.901374010246856\n",
      "test Acc 0.9054934823091247:\n",
      "25th- epoch: 27, train_loss = 43.89047293365002, train_acc = 0.9039357242664182\n",
      "test Acc 0.9073556797020484:\n",
      "25th- epoch: 28, train_loss = 42.95038349926472, train_acc = 0.9049836981835119\n",
      "test Acc 0.9078212290502793:\n",
      "25th- epoch: 29, train_loss = 42.08560195565224, train_acc = 0.9068467629250117\n",
      "test Acc 0.909683426443203:\n",
      "25th- epoch: 30, train_loss = 41.286704421043396, train_acc = 0.9082440614811365\n",
      "test Acc 0.9110800744878957:\n",
      "25th- epoch: 31, train_loss = 40.54550687968731, train_acc = 0.9116208663251048\n",
      "test Acc 0.9138733705772812:\n",
      "25th- epoch: 32, train_loss = 39.854622051119804, train_acc = 0.9137168141592921\n",
      "test Acc 0.914804469273743:\n",
      "25th- epoch: 33, train_loss = 39.20801022648811, train_acc = 0.9160456450861667\n",
      "test Acc 0.9152700186219739:\n",
      "25th- epoch: 34, train_loss = 38.601514011621475, train_acc = 0.9174429436422916\n",
      "test Acc 0.9171322160148976:\n",
      "25th- epoch: 35, train_loss = 38.03049436211586, train_acc = 0.9187238006520727\n",
      "test Acc 0.9175977653631285:\n",
      "25th- epoch: 36, train_loss = 37.49177813529968, train_acc = 0.9210526315789473\n",
      "test Acc 0.9185288640595903:\n",
      "25th- epoch: 37, train_loss = 36.98237678408623, train_acc = 0.921634839310666\n",
      "test Acc 0.9189944134078212:\n",
      "25th- epoch: 38, train_loss = 36.49888177216053, train_acc = 0.922100605496041\n",
      "test Acc 0.9194599627560521:\n",
      "25th- epoch: 39, train_loss = 36.03949062526226, train_acc = 0.9223334885887284\n",
      "test Acc 0.9194599627560521:\n",
      "25th- epoch: 40, train_loss = 35.60269705951214, train_acc = 0.9236143455985095\n",
      "test Acc 0.9217877094972067:\n",
      "25th- epoch: 41, train_loss = 35.185769468545914, train_acc = 0.9246623195156032\n",
      "test Acc 0.9227188081936686:\n",
      "25th- epoch: 42, train_loss = 34.78752705454826, train_acc = 0.9252445272473219\n",
      "test Acc 0.9241154562383612:\n",
      "25th- epoch: 43, train_loss = 34.40773621201515, train_acc = 0.9257102934326968\n",
      "test Acc 0.9250465549348231:\n",
      "25th- epoch: 44, train_loss = 34.04375374317169, train_acc = 0.9258267349790406\n",
      "test Acc 0.925512104283054:\n",
      "25th- epoch: 45, train_loss = 33.69486702233553, train_acc = 0.926525384257103\n",
      "test Acc 0.9259776536312849:\n",
      "25th- epoch: 46, train_loss = 33.36026307940483, train_acc = 0.9273404750815091\n",
      "test Acc 0.9264432029795159:\n",
      "25th- epoch: 47, train_loss = 33.03852876275778, train_acc = 0.927806241266884\n",
      "test Acc 0.9269087523277467:\n",
      "25th- epoch: 48, train_loss = 32.728596940636635, train_acc = 0.9287377736376339\n",
      "test Acc 0.9269087523277467:\n",
      "25th- epoch: 49, train_loss = 32.43020862340927, train_acc = 0.9294364229156963\n",
      "test Acc 0.9273743016759777:\n",
      "25th- epoch: 50, train_loss = 32.14204981178045, train_acc = 0.9299021891010713\n",
      "test Acc 0.9273743016759777:\n",
      "25th- epoch: 51, train_loss = 31.863635681569576, train_acc = 0.9308337214718212\n",
      "test Acc 0.9269087523277467:\n",
      "25th- epoch: 52, train_loss = 31.594181962311268, train_acc = 0.9308337214718212\n",
      "test Acc 0.9273743016759777:\n",
      "25th- epoch: 53, train_loss = 31.33279225975275, train_acc = 0.9312994876571961\n",
      "test Acc 0.9273743016759777:\n",
      "25th- epoch: 54, train_loss = 31.079293571412563, train_acc = 0.9319981369352585\n",
      "test Acc 0.9273743016759777:\n",
      "25th- epoch: 55, train_loss = 30.833308577537537, train_acc = 0.932231020027946\n",
      "test Acc 0.9273743016759777:\n",
      "25th- epoch: 56, train_loss = 30.594859190285206, train_acc = 0.9329296693060084\n",
      "test Acc 0.9273743016759777:\n",
      "25th- epoch: 57, train_loss = 30.36267575621605, train_acc = 0.9333954354913834\n",
      "test Acc 0.9273743016759777:\n",
      "25th- epoch: 58, train_loss = 30.136791415512562, train_acc = 0.9336283185840708\n",
      "test Acc 0.9283054003724395:\n",
      "25th- epoch: 59, train_loss = 29.916773177683353, train_acc = 0.933977643223102\n",
      "test Acc 0.9283054003724395:\n",
      "25th- epoch: 60, train_loss = 29.702164813876152, train_acc = 0.9344434094084769\n",
      "test Acc 0.9283054003724395:\n",
      "25th- epoch: 61, train_loss = 29.493053749203682, train_acc = 0.9347927340475082\n",
      "test Acc 0.9283054003724395:\n",
      "25th- epoch: 62, train_loss = 29.288864105939865, train_acc = 0.9350256171401956\n",
      "test Acc 0.9283054003724395:\n",
      "25th- epoch: 63, train_loss = 29.09062346816063, train_acc = 0.9354913833255706\n",
      "test Acc 0.9283054003724395:\n",
      "25th- epoch: 64, train_loss = 28.895589374005795, train_acc = 0.9358407079646017\n",
      "test Acc 0.9287709497206704:\n",
      "25th- epoch: 65, train_loss = 28.706023514270782, train_acc = 0.935724266418258\n",
      "test Acc 0.9287709497206704:\n",
      "25th- epoch: 66, train_loss = 28.52033057063818, train_acc = 0.9360735910572893\n",
      "test Acc 0.9287709497206704:\n",
      "25th- epoch: 67, train_loss = 28.339060723781586, train_acc = 0.9363064741499767\n",
      "test Acc 0.9292364990689013:\n",
      "25th- epoch: 68, train_loss = 28.161124289035797, train_acc = 0.9368886818816954\n",
      "test Acc 0.9292364990689013:\n",
      "25th- epoch: 69, train_loss = 27.98733301460743, train_acc = 0.9368886818816954\n",
      "test Acc 0.9297020484171322:\n",
      "25th- epoch: 70, train_loss = 27.81684922426939, train_acc = 0.9373544480670704\n",
      "test Acc 0.9297020484171322:\n",
      "25th- epoch: 71, train_loss = 27.648424722254276, train_acc = 0.937936655798789\n",
      "test Acc 0.9297020484171322:\n",
      "25th- epoch: 72, train_loss = 27.483939707279205, train_acc = 0.9384024219841639\n",
      "test Acc 0.9297020484171322:\n",
      "25th- epoch: 73, train_loss = 27.32177947461605, train_acc = 0.9385188635305077\n",
      "test Acc 0.930633147113594:\n",
      "25th- epoch: 74, train_loss = 27.162619195878506, train_acc = 0.9387517466231952\n",
      "test Acc 0.931098696461825:\n",
      "25th- epoch: 75, train_loss = 27.00672822445631, train_acc = 0.9391010712622264\n",
      "test Acc 0.9320297951582868:\n",
      "25th- epoch: 76, train_loss = 26.853694658726454, train_acc = 0.9395668374476013\n",
      "test Acc 0.9324953445065177:\n",
      "25th- epoch: 77, train_loss = 26.70394057035446, train_acc = 0.9397997205402888\n",
      "test Acc 0.9324953445065177:\n",
      "25th- epoch: 78, train_loss = 26.556847546249628, train_acc = 0.94014904517932\n",
      "test Acc 0.9324953445065177:\n",
      "25th- epoch: 79, train_loss = 26.412411853671074, train_acc = 0.9406148113646949\n",
      "test Acc 0.9329608938547486:\n",
      "25th- epoch: 80, train_loss = 26.2705111913383, train_acc = 0.9409641360037261\n",
      "test Acc 0.9329608938547486:\n",
      "25th- epoch: 81, train_loss = 26.131331264972687, train_acc = 0.941429902189101\n",
      "test Acc 0.9329608938547486:\n",
      "25th- epoch: 82, train_loss = 25.99472874030471, train_acc = 0.9417792268281323\n",
      "test Acc 0.9334264432029795:\n",
      "25th- epoch: 83, train_loss = 25.860032465308905, train_acc = 0.9421285514671635\n",
      "test Acc 0.9334264432029795:\n",
      "25th- epoch: 84, train_loss = 25.728511843830347, train_acc = 0.9424778761061947\n",
      "test Acc 0.9334264432029795:\n",
      "25th- epoch: 85, train_loss = 25.597929414361715, train_acc = 0.9427107591988821\n",
      "test Acc 0.9334264432029795:\n",
      "25th- epoch: 86, train_loss = 25.4699444770813, train_acc = 0.9430600838379134\n",
      "test Acc 0.9334264432029795:\n",
      "25th- epoch: 87, train_loss = 25.344003275036812, train_acc = 0.9431765253842571\n",
      "test Acc 0.9334264432029795:\n",
      "25th- epoch: 88, train_loss = 25.219901274889708, train_acc = 0.9434094084769445\n",
      "test Acc 0.9334264432029795:\n",
      "25th- epoch: 89, train_loss = 25.096996370702982, train_acc = 0.9437587331159758\n",
      "test Acc 0.9338919925512105:\n",
      "25th- epoch: 90, train_loss = 24.976450610905886, train_acc = 0.9437587331159758\n",
      "test Acc 0.9338919925512105:\n",
      "25th- epoch: 91, train_loss = 24.858036909252405, train_acc = 0.9438751746623195\n",
      "test Acc 0.9343575418994413:\n",
      "25th- epoch: 92, train_loss = 24.74169310927391, train_acc = 0.9439916162086632\n",
      "test Acc 0.9343575418994413:\n",
      "25th- epoch: 93, train_loss = 24.62739897146821, train_acc = 0.9443409408476945\n",
      "test Acc 0.9343575418994413:\n",
      "25th- epoch: 94, train_loss = 24.514128055423498, train_acc = 0.9445738239403819\n",
      "test Acc 0.9343575418994413:\n",
      "25th- epoch: 95, train_loss = 24.403412133455276, train_acc = 0.9448067070330693\n",
      "test Acc 0.9343575418994413:\n",
      "25th- epoch: 96, train_loss = 24.294140711426735, train_acc = 0.9449231485794132\n",
      "test Acc 0.9343575418994413:\n",
      "25th- epoch: 97, train_loss = 24.18690226972103, train_acc = 0.9449231485794132\n",
      "test Acc 0.9348230912476723:\n",
      "25th- epoch: 98, train_loss = 24.0815307572484, train_acc = 0.9450395901257569\n",
      "test Acc 0.9348230912476723:\n",
      "25th- epoch: 99, train_loss = 23.97837634012103, train_acc = 0.9452724732184443\n",
      "test Acc 0.9352886405959032:\n",
      "25th- epoch: 100, train_loss = 23.87668550759554, train_acc = 0.9455053563111319\n",
      "test Acc 0.9352886405959032:\n",
      "25th- epoch: 101, train_loss = 23.776727702468634, train_acc = 0.9457382394038193\n",
      "test Acc 0.9352886405959032:\n",
      "25th- epoch: 102, train_loss = 23.67802630737424, train_acc = 0.9459711224965067\n",
      "test Acc 0.9357541899441341:\n",
      "25th- epoch: 103, train_loss = 23.581367656588554, train_acc = 0.9464368886818817\n",
      "test Acc 0.9357541899441341:\n",
      "25th- epoch: 104, train_loss = 23.486616391688585, train_acc = 0.9466697717745691\n",
      "test Acc 0.9357541899441341:\n",
      "25th- epoch: 105, train_loss = 23.393458034843206, train_acc = 0.9469026548672567\n",
      "test Acc 0.9357541899441341:\n",
      "25th- epoch: 106, train_loss = 23.3008378110826, train_acc = 0.9470190964136004\n",
      "test Acc 0.9357541899441341:\n",
      "25th- epoch: 107, train_loss = 23.210276279598475, train_acc = 0.9473684210526315\n",
      "test Acc 0.9357541899441341:\n",
      "25th- epoch: 108, train_loss = 23.120349150151014, train_acc = 0.9472519795062878\n",
      "test Acc 0.936219739292365:\n",
      "25th- epoch: 109, train_loss = 23.033172596246004, train_acc = 0.9476013041453191\n",
      "test Acc 0.9371508379888268:\n",
      "25th- epoch: 110, train_loss = 22.945603411644697, train_acc = 0.9477177456916628\n",
      "test Acc 0.9371508379888268:\n",
      "25th- epoch: 111, train_loss = 22.86052517592907, train_acc = 0.9479506287843502\n",
      "test Acc 0.9376163873370578:\n",
      "25th- epoch: 112, train_loss = 22.775514028966427, train_acc = 0.9481835118770378\n",
      "test Acc 0.9376163873370578:\n",
      "25th- epoch: 113, train_loss = 22.692019037902355, train_acc = 0.9484163949697252\n",
      "test Acc 0.9376163873370578:\n",
      "25th- epoch: 114, train_loss = 22.610169403254986, train_acc = 0.9484163949697252\n",
      "test Acc 0.9376163873370578:\n",
      "25th- epoch: 115, train_loss = 22.5279124006629, train_acc = 0.9485328365160689\n",
      "test Acc 0.9380819366852886:\n",
      "25th- epoch: 116, train_loss = 22.44793203100562, train_acc = 0.9487657196087564\n",
      "test Acc 0.9380819366852886:\n",
      "25th- epoch: 117, train_loss = 22.368181820958853, train_acc = 0.9487657196087564\n",
      "test Acc 0.9380819366852886:\n",
      "25th- epoch: 118, train_loss = 22.29010334983468, train_acc = 0.9489986027014439\n",
      "test Acc 0.9380819366852886:\n",
      "25th- epoch: 119, train_loss = 22.212818801403046, train_acc = 0.9492314857941313\n",
      "test Acc 0.9380819366852886:\n",
      "25th- epoch: 120, train_loss = 22.13677565380931, train_acc = 0.9493479273404751\n",
      "test Acc 0.9380819366852886:\n",
      "25th- epoch: 121, train_loss = 22.062129124999046, train_acc = 0.94981369352585\n",
      "test Acc 0.9380819366852886:\n",
      "25th- epoch: 122, train_loss = 21.987997356802225, train_acc = 0.9499301350721937\n",
      "test Acc 0.9380819366852886:\n",
      "25th- epoch: 123, train_loss = 21.914267525076866, train_acc = 0.9499301350721937\n",
      "test Acc 0.9380819366852886:\n",
      "25th- epoch: 124, train_loss = 21.843344166874886, train_acc = 0.9501630181648812\n",
      "test Acc 0.9385474860335196:\n",
      "25th- epoch: 125, train_loss = 21.773222152143717, train_acc = 0.9503959012575687\n",
      "test Acc 0.9385474860335196:\n",
      "25th- epoch: 126, train_loss = 21.703315004706383, train_acc = 0.9507452258965999\n",
      "test Acc 0.9385474860335196:\n",
      "25th- epoch: 127, train_loss = 21.634028006345034, train_acc = 0.9507452258965999\n",
      "test Acc 0.9385474860335196:\n",
      "25th- epoch: 128, train_loss = 21.56659149378538, train_acc = 0.9512109920819748\n",
      "test Acc 0.9385474860335196:\n",
      "25th- epoch: 129, train_loss = 21.49972538650036, train_acc = 0.9512109920819748\n",
      "test Acc 0.9385474860335196:\n",
      "25th- epoch: 130, train_loss = 21.434043001383543, train_acc = 0.9514438751746623\n",
      "test Acc 0.9385474860335196:\n",
      "25th- epoch: 131, train_loss = 21.3686212785542, train_acc = 0.9516767582673498\n",
      "test Acc 0.9385474860335196:\n",
      "25th- epoch: 132, train_loss = 21.30455221235752, train_acc = 0.9519096413600373\n",
      "test Acc 0.9385474860335196:\n",
      "25th- epoch: 133, train_loss = 21.24078132584691, train_acc = 0.952026082906381\n",
      "test Acc 0.9390130353817505:\n",
      "25th- epoch: 134, train_loss = 21.177964340895414, train_acc = 0.9521425244527247\n",
      "test Acc 0.9394785847299814:\n",
      "25th- epoch: 135, train_loss = 21.115110140293837, train_acc = 0.9522589659990685\n",
      "test Acc 0.9399441340782123:\n",
      "25th- epoch: 136, train_loss = 21.05301419273019, train_acc = 0.9526082906380997\n",
      "test Acc 0.9404096834264432:\n",
      "25th- epoch: 137, train_loss = 20.992149151861668, train_acc = 0.9527247321844434\n",
      "test Acc 0.9408752327746741:\n",
      "25th- epoch: 138, train_loss = 20.930978141725063, train_acc = 0.9530740568234746\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 139, train_loss = 20.87119648233056, train_acc = 0.9533069399161621\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 140, train_loss = 20.81179579719901, train_acc = 0.9534233814625058\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 141, train_loss = 20.752596836537123, train_acc = 0.9533069399161621\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 142, train_loss = 20.695704478770494, train_acc = 0.9533069399161621\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 143, train_loss = 20.63771006092429, train_acc = 0.9533069399161621\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 144, train_loss = 20.581493701785803, train_acc = 0.9535398230088495\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 145, train_loss = 20.525772595778108, train_acc = 0.9537727061015371\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 146, train_loss = 20.471113543957472, train_acc = 0.9538891476478808\n",
      "test Acc 0.9413407821229051:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 147, train_loss = 20.41688616760075, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "25th- epoch: 148, train_loss = 20.362661939114332, train_acc = 0.9541220307405682\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 149, train_loss = 20.308496730402112, train_acc = 0.9543549138332557\n",
      "test Acc 0.9422718808193669:\n",
      "25th- epoch: 150, train_loss = 20.256025910377502, train_acc = 0.9543549138332557\n",
      "test Acc 0.9422718808193669:\n",
      "25th- epoch: 151, train_loss = 20.20340839214623, train_acc = 0.9544713553795995\n",
      "test Acc 0.9427374301675978:\n",
      "25th- epoch: 152, train_loss = 20.152607521042228, train_acc = 0.9544713553795995\n",
      "test Acc 0.9427374301675978:\n",
      "25th- epoch: 153, train_loss = 20.101117307320237, train_acc = 0.9545877969259432\n",
      "test Acc 0.9427374301675978:\n",
      "25th- epoch: 154, train_loss = 20.050888756290078, train_acc = 0.9548206800186306\n",
      "test Acc 0.9427374301675978:\n",
      "25th- epoch: 155, train_loss = 20.001756861805916, train_acc = 0.9549371215649743\n",
      "test Acc 0.9427374301675978:\n",
      "25th- epoch: 156, train_loss = 19.952681241557002, train_acc = 0.9549371215649743\n",
      "test Acc 0.9427374301675978:\n",
      "25th- epoch: 157, train_loss = 19.90357474051416, train_acc = 0.9550535631113182\n",
      "test Acc 0.9427374301675978:\n",
      "25th- epoch: 158, train_loss = 19.855735540390015, train_acc = 0.9550535631113182\n",
      "test Acc 0.9427374301675978:\n",
      "25th- epoch: 159, train_loss = 19.808125784620643, train_acc = 0.9551700046576619\n",
      "test Acc 0.9427374301675978:\n",
      "25th- epoch: 160, train_loss = 19.760304847732186, train_acc = 0.9552864462040056\n",
      "test Acc 0.9427374301675978:\n",
      "25th- epoch: 161, train_loss = 19.713053576648235, train_acc = 0.9552864462040056\n",
      "test Acc 0.9432029795158287:\n",
      "25th- epoch: 162, train_loss = 19.666760155931115, train_acc = 0.9556357708430367\n",
      "test Acc 0.9432029795158287:\n",
      "25th- epoch: 163, train_loss = 19.61873533949256, train_acc = 0.955519329296693\n",
      "test Acc 0.9436685288640596:\n",
      "25th- epoch: 164, train_loss = 19.575026400387287, train_acc = 0.9556357708430367\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 165, train_loss = 19.530013909563422, train_acc = 0.9557522123893806\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 166, train_loss = 19.485570274293423, train_acc = 0.9558686539357243\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 167, train_loss = 19.442326160147786, train_acc = 0.955985095482068\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 168, train_loss = 19.399006394669414, train_acc = 0.955985095482068\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 169, train_loss = 19.35508511774242, train_acc = 0.955985095482068\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 170, train_loss = 19.313878482207656, train_acc = 0.9561015370284117\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 171, train_loss = 19.269922820851207, train_acc = 0.9563344201210993\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 172, train_loss = 19.228915045037866, train_acc = 0.9563344201210993\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 173, train_loss = 19.186210295185447, train_acc = 0.9565673032137867\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 174, train_loss = 19.146060433238745, train_acc = 0.9568001863064741\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 175, train_loss = 19.10434233210981, train_acc = 0.9568001863064741\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 176, train_loss = 19.065691320225596, train_acc = 0.9568001863064741\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 177, train_loss = 19.024885518476367, train_acc = 0.9568001863064741\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 178, train_loss = 18.98580407910049, train_acc = 0.9571495109455054\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 179, train_loss = 18.945996914058924, train_acc = 0.9570330693991617\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 180, train_loss = 18.90711922571063, train_acc = 0.9571495109455054\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 181, train_loss = 18.869728228077292, train_acc = 0.9571495109455054\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 182, train_loss = 18.829227989539504, train_acc = 0.9574988355845365\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 183, train_loss = 18.79371284879744, train_acc = 0.9576152771308803\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 184, train_loss = 18.754576897248626, train_acc = 0.9576152771308803\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 185, train_loss = 18.718199195340276, train_acc = 0.9576152771308803\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 186, train_loss = 18.68246011994779, train_acc = 0.9576152771308803\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 187, train_loss = 18.64613943733275, train_acc = 0.9577317186772241\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 188, train_loss = 18.609050562605262, train_acc = 0.9577317186772241\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 189, train_loss = 18.573710564523935, train_acc = 0.9578481602235678\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 190, train_loss = 18.538300620391965, train_acc = 0.9578481602235678\n",
      "test Acc 0.9464618249534451:\n",
      "25th- epoch: 191, train_loss = 18.50285188667476, train_acc = 0.9579646017699115\n",
      "test Acc 0.9464618249534451:\n",
      "25th- epoch: 192, train_loss = 18.468333626165986, train_acc = 0.9579646017699115\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 193, train_loss = 18.431525761261582, train_acc = 0.9584303679552865\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 194, train_loss = 18.39895505644381, train_acc = 0.9584303679552865\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 195, train_loss = 18.364742560312152, train_acc = 0.9584303679552865\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 196, train_loss = 18.32984727062285, train_acc = 0.9584303679552865\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 197, train_loss = 18.297971634194255, train_acc = 0.9584303679552865\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 198, train_loss = 18.2636285033077, train_acc = 0.9586632510479739\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 199, train_loss = 18.231797559186816, train_acc = 0.9587796925943176\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 200, train_loss = 18.199003513902426, train_acc = 0.9587796925943176\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 201, train_loss = 18.167131831869483, train_acc = 0.9588961341406614\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 202, train_loss = 18.13590981066227, train_acc = 0.9588961341406614\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 203, train_loss = 18.102816389873624, train_acc = 0.9590125756870052\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 204, train_loss = 18.07207333855331, train_acc = 0.9591290172333489\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 205, train_loss = 18.04268920607865, train_acc = 0.9591290172333489\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 206, train_loss = 18.010791312903166, train_acc = 0.9591290172333489\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 207, train_loss = 17.979563677683473, train_acc = 0.9591290172333489\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 208, train_loss = 17.948022300377488, train_acc = 0.95947834187238\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 209, train_loss = 17.919423036277294, train_acc = 0.95947834187238\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 210, train_loss = 17.88959469459951, train_acc = 0.9597112249650676\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 211, train_loss = 17.861434292048216, train_acc = 0.9598276665114113\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 212, train_loss = 17.830449787899852, train_acc = 0.959944108057755\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 213, train_loss = 17.802280582487583, train_acc = 0.9600605496040987\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 214, train_loss = 17.774239810183644, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 215, train_loss = 17.744936687871814, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 216, train_loss = 17.71563191525638, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 217, train_loss = 17.689469315111637, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 218, train_loss = 17.66082072816789, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 219, train_loss = 17.634923161938787, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 220, train_loss = 17.605739759281278, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 221, train_loss = 17.579685412347317, train_acc = 0.9605263157894737\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 222, train_loss = 17.553043508902192, train_acc = 0.9606427573358174\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 223, train_loss = 17.524639753624797, train_acc = 0.9606427573358174\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 224, train_loss = 17.499486926943064, train_acc = 0.9606427573358174\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 225, train_loss = 17.472177490592003, train_acc = 0.9606427573358174\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 226, train_loss = 17.445481261238456, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 227, train_loss = 17.418754214420915, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 228, train_loss = 17.39368818514049, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 229, train_loss = 17.369886241853237, train_acc = 0.9609920819748486\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 230, train_loss = 17.344188267365098, train_acc = 0.9609920819748486\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 231, train_loss = 17.318877775222063, train_acc = 0.9611085235211924\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 232, train_loss = 17.294379524886608, train_acc = 0.9611085235211924\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 233, train_loss = 17.267833860591054, train_acc = 0.9612249650675361\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 234, train_loss = 17.243989519774914, train_acc = 0.9613414066138798\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 235, train_loss = 17.221003068611026, train_acc = 0.9613414066138798\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 236, train_loss = 17.196669194847345, train_acc = 0.9613414066138798\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 237, train_loss = 17.17284999974072, train_acc = 0.9614578481602236\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 238, train_loss = 17.149759830906987, train_acc = 0.9614578481602236\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 239, train_loss = 17.126605132594705, train_acc = 0.9614578481602236\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 240, train_loss = 17.1034882850945, train_acc = 0.9614578481602236\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 241, train_loss = 17.07826090976596, train_acc = 0.9615742897065673\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 242, train_loss = 17.05627241358161, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 243, train_loss = 17.033868200145662, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 244, train_loss = 17.011365063488483, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 245, train_loss = 16.990091708488762, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 246, train_loss = 16.968103662133217, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 247, train_loss = 16.945038908161223, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 248, train_loss = 16.923581236042082, train_acc = 0.9619236143455985\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 249, train_loss = 16.901808229275048, train_acc = 0.9620400558919422\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 250, train_loss = 16.881520934402943, train_acc = 0.962156497438286\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 251, train_loss = 16.858599990606308, train_acc = 0.9622729389846297\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 252, train_loss = 16.83868230972439, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 253, train_loss = 16.816949381493032, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 254, train_loss = 16.796832896769047, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 255, train_loss = 16.777459085918963, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 256, train_loss = 16.755371953360736, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 257, train_loss = 16.735295053571463, train_acc = 0.9625058220773172\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 258, train_loss = 16.71570396516472, train_acc = 0.9625058220773172\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 259, train_loss = 16.695886582136154, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 260, train_loss = 16.67531294748187, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 261, train_loss = 16.654462388716638, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 262, train_loss = 16.63460002001375, train_acc = 0.9628551467163484\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 263, train_loss = 16.61596886906773, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 264, train_loss = 16.596508593298495, train_acc = 0.9630880298090359\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 265, train_loss = 16.57695798855275, train_acc = 0.9632044713553796\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 266, train_loss = 16.557591586373746, train_acc = 0.9632044713553796\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 267, train_loss = 16.539087432436645, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 268, train_loss = 16.519748794846237, train_acc = 0.9632044713553796\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 269, train_loss = 16.50129972398281, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 270, train_loss = 16.48224951978773, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 271, train_loss = 16.463941582478583, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 272, train_loss = 16.445475339889526, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 273, train_loss = 16.428587824106216, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 274, train_loss = 16.409169887192547, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 275, train_loss = 16.392892636358738, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 276, train_loss = 16.373224186711013, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 277, train_loss = 16.357052396051586, train_acc = 0.9633209129017233\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 278, train_loss = 16.339513479731977, train_acc = 0.9635537959944108\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 279, train_loss = 16.321402763016522, train_acc = 0.9635537959944108\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 280, train_loss = 16.303573168814182, train_acc = 0.9635537959944108\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 281, train_loss = 16.28713463526219, train_acc = 0.9636702375407545\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 282, train_loss = 16.269988011568785, train_acc = 0.9636702375407545\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 283, train_loss = 16.252797027118504, train_acc = 0.9636702375407545\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 284, train_loss = 16.23658174648881, train_acc = 0.9637866790870983\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 285, train_loss = 16.21908021438867, train_acc = 0.963903120633442\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 286, train_loss = 16.202304533682764, train_acc = 0.963903120633442\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 287, train_loss = 16.186788607388735, train_acc = 0.963903120633442\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 288, train_loss = 16.16937794536352, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 289, train_loss = 16.154054661281407, train_acc = 0.9641360037261295\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 290, train_loss = 16.137176075018942, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 291, train_loss = 16.120930216275156, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 292, train_loss = 16.10379906464368, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 293, train_loss = 16.088943033479154, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 294, train_loss = 16.07360049430281, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 295, train_loss = 16.058200602419674, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 296, train_loss = 16.041102029383183, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 297, train_loss = 16.02608554903418, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 298, train_loss = 16.011995300650597, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 299, train_loss = 15.99464960116893, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "25th- epoch: 300, train_loss = 15.98130726441741, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "25th- epoch: 301, train_loss = 15.965355369262397, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "25th- epoch: 302, train_loss = 15.951367291621864, train_acc = 0.9646017699115044\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 303, train_loss = 15.935319238342345, train_acc = 0.9646017699115044\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 304, train_loss = 15.920352306216955, train_acc = 0.9646017699115044\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 305, train_loss = 15.90589791443199, train_acc = 0.9647182114578482\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 306, train_loss = 15.891812931746244, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 307, train_loss = 15.877213546074927, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 308, train_loss = 15.862142973579466, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 309, train_loss = 15.848257911391556, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 310, train_loss = 15.834591851569712, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 311, train_loss = 15.820612759329379, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 312, train_loss = 15.805996366776526, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 313, train_loss = 15.791572163812816, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 314, train_loss = 15.777883960865438, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 315, train_loss = 15.764714299701154, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 316, train_loss = 15.749344933778048, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 317, train_loss = 15.73567120730877, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 318, train_loss = 15.722041406668723, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 319, train_loss = 15.708977729082108, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 320, train_loss = 15.695407018996775, train_acc = 0.9655333022822543\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 321, train_loss = 15.682019293308258, train_acc = 0.9655333022822543\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 322, train_loss = 15.668046549893916, train_acc = 0.9655333022822543\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 323, train_loss = 15.655602500773966, train_acc = 0.9655333022822543\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 324, train_loss = 15.642565444111824, train_acc = 0.9655333022822543\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 325, train_loss = 15.628369451500475, train_acc = 0.9655333022822543\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 326, train_loss = 15.616305944509804, train_acc = 0.9655333022822543\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 327, train_loss = 15.60349512565881, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 328, train_loss = 15.590646130032837, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 329, train_loss = 15.577041680924594, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 330, train_loss = 15.565750765614212, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 331, train_loss = 15.552850021980703, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 332, train_loss = 15.540769443847239, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 333, train_loss = 15.52746693789959, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 334, train_loss = 15.516454846598208, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 335, train_loss = 15.503195449709892, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 336, train_loss = 15.490513357333839, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 337, train_loss = 15.478623447008431, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 338, train_loss = 15.466658213175833, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 339, train_loss = 15.453803550451994, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 340, train_loss = 15.442127658985555, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 341, train_loss = 15.429777223616838, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 342, train_loss = 15.418153158389032, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 343, train_loss = 15.407417231239378, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 344, train_loss = 15.394378396682441, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 345, train_loss = 15.382375214248896, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 346, train_loss = 15.37156283762306, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 347, train_loss = 15.35975032672286, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 348, train_loss = 15.347838425077498, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 349, train_loss = 15.336462680250406, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 350, train_loss = 15.325846325606108, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 351, train_loss = 15.313498987816274, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 352, train_loss = 15.302250009030104, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 353, train_loss = 15.291230779141188, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 354, train_loss = 15.279604934155941, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 355, train_loss = 15.26919486373663, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 356, train_loss = 15.258082777261734, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 357, train_loss = 15.247414973564446, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 358, train_loss = 15.235867287963629, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 359, train_loss = 15.225071766413748, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 360, train_loss = 15.213620788417757, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 361, train_loss = 15.204632258974016, train_acc = 0.9662319515603167\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 362, train_loss = 15.19318538531661, train_acc = 0.9662319515603167\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 363, train_loss = 15.182091247290373, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 364, train_loss = 15.172585867345333, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 365, train_loss = 15.160937763750553, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 366, train_loss = 15.15037627518177, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 367, train_loss = 15.141584401018918, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 368, train_loss = 15.130021713674068, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 369, train_loss = 15.119197369553149, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 370, train_loss = 15.110145377926528, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 371, train_loss = 15.098773785866797, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 372, train_loss = 15.089128848165274, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 373, train_loss = 15.07893566135317, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 374, train_loss = 15.06903659272939, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 375, train_loss = 15.058864493854344, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 376, train_loss = 15.049734405241907, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 377, train_loss = 15.038748886436224, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 378, train_loss = 15.029378176666796, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 379, train_loss = 15.020016173832119, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 380, train_loss = 15.008778866380453, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 381, train_loss = 14.999969433993101, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 382, train_loss = 14.990869189612567, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 383, train_loss = 14.979925782419741, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 384, train_loss = 14.970970194786787, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 385, train_loss = 14.96139455307275, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 386, train_loss = 14.952624646015465, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 387, train_loss = 14.943956550210714, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 388, train_loss = 14.933814530260861, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 389, train_loss = 14.924277092330158, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 390, train_loss = 14.914783529005945, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 391, train_loss = 14.906568635255098, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 392, train_loss = 14.89826297108084, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 393, train_loss = 14.887334254570305, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 394, train_loss = 14.879136054776609, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 395, train_loss = 14.871312126517296, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 396, train_loss = 14.860101609490812, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 397, train_loss = 14.854252900928259, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 398, train_loss = 14.842698902823031, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 399, train_loss = 14.835755445063114, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 400, train_loss = 14.825366242788732, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 401, train_loss = 14.818403487093747, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 402, train_loss = 14.80787929147482, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 403, train_loss = 14.800819584168494, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 404, train_loss = 14.791304711252451, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 405, train_loss = 14.782889920286834, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 406, train_loss = 14.773999962955713, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 407, train_loss = 14.764854392968118, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 408, train_loss = 14.755952305160463, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 409, train_loss = 14.748817871324718, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 410, train_loss = 14.74050859734416, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 411, train_loss = 14.733289147727191, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 412, train_loss = 14.722654942423105, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 413, train_loss = 14.716257493942976, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 414, train_loss = 14.70641865953803, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 415, train_loss = 14.698789309710264, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 416, train_loss = 14.691818967461586, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 417, train_loss = 14.683482580818236, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 418, train_loss = 14.675294336862862, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 419, train_loss = 14.66764164622873, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 420, train_loss = 14.65829315688461, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 421, train_loss = 14.649896995164454, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 422, train_loss = 14.640748843550682, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 423, train_loss = 14.632268376648426, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 424, train_loss = 14.62322200089693, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 425, train_loss = 14.616960496641695, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 426, train_loss = 14.60932903084904, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 427, train_loss = 14.600238530430943, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 428, train_loss = 14.591023729648441, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 429, train_loss = 14.585323076695204, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 430, train_loss = 14.577846519649029, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 431, train_loss = 14.569211181253195, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 432, train_loss = 14.561619512736797, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 433, train_loss = 14.553732486907393, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 434, train_loss = 14.545711137354374, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 435, train_loss = 14.537984697613865, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 436, train_loss = 14.530316845979542, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 437, train_loss = 14.524499326944351, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 438, train_loss = 14.516558276955038, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 439, train_loss = 14.509747674223036, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 440, train_loss = 14.503684920724481, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 441, train_loss = 14.494833078235388, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 442, train_loss = 14.486078590154648, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 443, train_loss = 14.481036864221096, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 444, train_loss = 14.472007740288973, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 445, train_loss = 14.465882199350744, train_acc = 0.9675128085700978\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 446, train_loss = 14.456758337561041, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 447, train_loss = 14.451551090925932, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 448, train_loss = 14.445102540310472, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 449, train_loss = 14.437958209309727, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 450, train_loss = 14.429341215640306, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 451, train_loss = 14.423291703220457, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 452, train_loss = 14.417122756596655, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 453, train_loss = 14.408986470196396, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 454, train_loss = 14.400235102977604, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 455, train_loss = 14.395343588199466, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 456, train_loss = 14.386892133858055, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 457, train_loss = 14.37973652034998, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 458, train_loss = 14.37436514860019, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 459, train_loss = 14.365484192967415, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 460, train_loss = 14.36012618849054, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 461, train_loss = 14.354105360805988, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 462, train_loss = 14.34548906236887, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 463, train_loss = 14.340715136379004, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 464, train_loss = 14.332845870405436, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 465, train_loss = 14.32617412880063, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 466, train_loss = 14.318629594985396, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 467, train_loss = 14.312949801329523, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "25th- epoch: 468, train_loss = 14.306637659668922, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 469, train_loss = 14.300324881915003, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 470, train_loss = 14.292355986777693, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 471, train_loss = 14.286536196712404, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 472, train_loss = 14.279481404926628, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 473, train_loss = 14.273371117655188, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 474, train_loss = 14.267257703933865, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 475, train_loss = 14.26165983080864, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 476, train_loss = 14.255053736269474, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 477, train_loss = 14.248711576219648, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 478, train_loss = 14.241405954118818, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 479, train_loss = 14.234959396068007, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 480, train_loss = 14.230635963380337, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 481, train_loss = 14.224110485520214, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 482, train_loss = 14.217135629151016, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 483, train_loss = 14.211233655456454, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 484, train_loss = 14.204203849192709, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 485, train_loss = 14.199025936424732, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 486, train_loss = 14.192276641726494, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 487, train_loss = 14.18709010630846, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 488, train_loss = 14.181833664420992, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 489, train_loss = 14.174321321304888, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 490, train_loss = 14.16777903959155, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 491, train_loss = 14.162106884177774, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 492, train_loss = 14.15754089364782, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 493, train_loss = 14.150852804537863, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 494, train_loss = 14.145509712398052, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 495, train_loss = 14.139286039862782, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 496, train_loss = 14.13361573824659, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 497, train_loss = 14.128114046063274, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 498, train_loss = 14.1211595274508, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 499, train_loss = 14.116281190421432, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████            | 25/30 [2:46:18<33:16, 399.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "26th- epoch: 0, train_loss = 270.41244971752167, train_acc = 0.48113646949231487\n",
      "test Acc 0.49441340782122906:\n",
      "26th- epoch: 1, train_loss = 213.21552550792694, train_acc = 0.49755472752678154\n",
      "test Acc 0.49860335195530725:\n",
      "26th- epoch: 2, train_loss = 180.37683200836182, train_acc = 0.5041918956683745\n",
      "test Acc 0.5218808193668529:\n",
      "26th- epoch: 3, train_loss = 163.17393720149994, train_acc = 0.5390079180251514\n",
      "test Acc 0.5707635009310987:\n",
      "26th- epoch: 4, train_loss = 150.20744198560715, train_acc = 0.5812761993479273\n",
      "test Acc 0.6061452513966481:\n",
      "26th- epoch: 5, train_loss = 138.5800657272339, train_acc = 0.624126688402422\n",
      "test Acc 0.6378026070763501:\n",
      "26th- epoch: 6, train_loss = 127.81229656934738, train_acc = 0.6504424778761062\n",
      "test Acc 0.6671322160148976:\n",
      "26th- epoch: 7, train_loss = 117.9548989534378, train_acc = 0.691895668374476\n",
      "test Acc 0.75:\n",
      "26th- epoch: 8, train_loss = 108.96412807703018, train_acc = 0.7578015836050302\n",
      "test Acc 0.7756052141527002:\n",
      "26th- epoch: 9, train_loss = 100.76937520503998, train_acc = 0.7955286446204005\n",
      "test Acc 0.8016759776536313:\n",
      "26th- epoch: 10, train_loss = 93.34402990341187, train_acc = 0.8110153702841174\n",
      "test Acc 0.8216945996275605:\n",
      "26th- epoch: 11, train_loss = 86.6864660680294, train_acc = 0.8220773171867722\n",
      "test Acc 0.8282122905027933:\n",
      "26th- epoch: 12, train_loss = 80.80207893252373, train_acc = 0.832324173265021\n",
      "test Acc 0.8482309124767226:\n",
      "26th- epoch: 13, train_loss = 75.64619159698486, train_acc = 0.8447834187238007\n",
      "test Acc 0.8547486033519553:\n",
      "26th- epoch: 14, train_loss = 71.14095902442932, train_acc = 0.8551467163483931\n",
      "test Acc 0.8631284916201117:\n",
      "26th- epoch: 15, train_loss = 67.21729865670204, train_acc = 0.8632976245924546\n",
      "test Acc 0.87243947858473:\n",
      "26th- epoch: 16, train_loss = 63.78459405899048, train_acc = 0.8685374941779227\n",
      "test Acc 0.8784916201117319:\n",
      "26th- epoch: 17, train_loss = 60.770530343055725, train_acc = 0.8755239869585468\n",
      "test Acc 0.8822160148975792:\n",
      "26th- epoch: 18, train_loss = 58.11965677142143, train_acc = 0.8811131811830462\n",
      "test Acc 0.8878026070763501:\n",
      "26th- epoch: 19, train_loss = 55.781290009617805, train_acc = 0.8848393106660456\n",
      "test Acc 0.888268156424581:\n",
      "26th- epoch: 20, train_loss = 53.711090847849846, train_acc = 0.8871681415929203\n",
      "test Acc 0.8952513966480447:\n",
      "26th- epoch: 21, train_loss = 51.87349507212639, train_acc = 0.8932231020027946\n",
      "test Acc 0.8971135940409684:\n",
      "26th- epoch: 22, train_loss = 50.2336759865284, train_acc = 0.8954354913833256\n",
      "test Acc 0.8994413407821229:\n",
      "26th- epoch: 23, train_loss = 48.76746101677418, train_acc = 0.8963670237540755\n",
      "test Acc 0.9022346368715084:\n",
      "26th- epoch: 24, train_loss = 47.45052967965603, train_acc = 0.8981136469492315\n",
      "test Acc 0.9022346368715084:\n",
      "26th- epoch: 25, train_loss = 46.25910057127476, train_acc = 0.900093153237075\n",
      "test Acc 0.904096834264432:\n",
      "26th- epoch: 26, train_loss = 45.1757909655571, train_acc = 0.9010246856078249\n",
      "test Acc 0.9059590316573557:\n",
      "26th- epoch: 27, train_loss = 44.186479449272156, train_acc = 0.9032370749883558\n",
      "test Acc 0.9078212290502793:\n",
      "26th- epoch: 28, train_loss = 43.27942444384098, train_acc = 0.9053330228225431\n",
      "test Acc 0.9087523277467412:\n",
      "26th- epoch: 29, train_loss = 42.44450168311596, train_acc = 0.9071960875640428\n",
      "test Acc 0.9087523277467412:\n",
      "26th- epoch: 30, train_loss = 41.67237223684788, train_acc = 0.9085933861201677\n",
      "test Acc 0.910148975791434:\n",
      "26th- epoch: 31, train_loss = 40.95559488236904, train_acc = 0.9099906846762925\n",
      "test Acc 0.9120111731843575:\n",
      "26th- epoch: 32, train_loss = 40.2878932505846, train_acc = 0.911504424778761\n",
      "test Acc 0.9120111731843575:\n",
      "26th- epoch: 33, train_loss = 39.66213344037533, train_acc = 0.9136003726129484\n",
      "test Acc 0.9124767225325885:\n",
      "26th- epoch: 34, train_loss = 39.073124408721924, train_acc = 0.9147647880763856\n",
      "test Acc 0.9134078212290503:\n",
      "26th- epoch: 35, train_loss = 38.51756279170513, train_acc = 0.9156963204471356\n",
      "test Acc 0.9138733705772812:\n",
      "26th- epoch: 36, train_loss = 37.99193878471851, train_acc = 0.9175593851886353\n",
      "test Acc 0.9152700186219739:\n",
      "26th- epoch: 37, train_loss = 37.49336598813534, train_acc = 0.9187238006520727\n",
      "test Acc 0.9162011173184358:\n",
      "26th- epoch: 38, train_loss = 37.01981483399868, train_acc = 0.9195388914764788\n",
      "test Acc 0.9157355679702048:\n",
      "26th- epoch: 39, train_loss = 36.5694805085659, train_acc = 0.9205868653935724\n",
      "test Acc 0.9166666666666666:\n",
      "26th- epoch: 40, train_loss = 36.13991330564022, train_acc = 0.9209361900326036\n",
      "test Acc 0.9171322160148976:\n",
      "26th- epoch: 41, train_loss = 35.728981375694275, train_acc = 0.9211690731252911\n",
      "test Acc 0.9189944134078212:\n",
      "26th- epoch: 42, train_loss = 35.33566103130579, train_acc = 0.9219841639496973\n",
      "test Acc 0.9194599627560521:\n",
      "26th- epoch: 43, train_loss = 34.958375945687294, train_acc = 0.9226828132277597\n",
      "test Acc 0.9203910614525139:\n",
      "26th- epoch: 44, train_loss = 34.59688836336136, train_acc = 0.9238472286911971\n",
      "test Acc 0.9203910614525139:\n",
      "26th- epoch: 45, train_loss = 34.248893208801746, train_acc = 0.9246623195156032\n",
      "test Acc 0.9227188081936686:\n",
      "26th- epoch: 46, train_loss = 33.91426503658295, train_acc = 0.925593851886353\n",
      "test Acc 0.9236499068901304:\n",
      "26th- epoch: 47, train_loss = 33.59082591533661, train_acc = 0.9262925011644154\n",
      "test Acc 0.9241154562383612:\n",
      "26th- epoch: 48, train_loss = 33.27831295877695, train_acc = 0.9269911504424779\n",
      "test Acc 0.9245810055865922:\n",
      "26th- epoch: 49, train_loss = 32.976328901946545, train_acc = 0.9274569166278528\n",
      "test Acc 0.9245810055865922:\n",
      "26th- epoch: 50, train_loss = 32.683438532054424, train_acc = 0.9283884489986027\n",
      "test Acc 0.9250465549348231:\n",
      "26th- epoch: 51, train_loss = 32.3997033983469, train_acc = 0.9287377736376339\n",
      "test Acc 0.925512104283054:\n",
      "26th- epoch: 52, train_loss = 32.12486019730568, train_acc = 0.9290870982766651\n",
      "test Acc 0.925512104283054:\n",
      "26th- epoch: 53, train_loss = 31.858632415533066, train_acc = 0.9294364229156963\n",
      "test Acc 0.925512104283054:\n",
      "26th- epoch: 54, train_loss = 31.599769562482834, train_acc = 0.9301350721937587\n",
      "test Acc 0.925512104283054:\n",
      "26th- epoch: 55, train_loss = 31.348027981817722, train_acc = 0.9307172799254774\n",
      "test Acc 0.9259776536312849:\n",
      "26th- epoch: 56, train_loss = 31.102392323315144, train_acc = 0.9311830461108523\n",
      "test Acc 0.9259776536312849:\n",
      "26th- epoch: 57, train_loss = 30.863691106438637, train_acc = 0.9316488122962273\n",
      "test Acc 0.9259776536312849:\n",
      "26th- epoch: 58, train_loss = 30.631413981318474, train_acc = 0.9319981369352585\n",
      "test Acc 0.9264432029795159:\n",
      "26th- epoch: 59, train_loss = 30.4051396176219, train_acc = 0.9323474615742897\n",
      "test Acc 0.9264432029795159:\n",
      "26th- epoch: 60, train_loss = 30.184291273355484, train_acc = 0.9325803446669771\n",
      "test Acc 0.9269087523277467:\n",
      "26th- epoch: 61, train_loss = 29.969051457941532, train_acc = 0.9326967862133209\n",
      "test Acc 0.9273743016759777:\n",
      "26th- epoch: 62, train_loss = 29.759063310921192, train_acc = 0.9328132277596647\n",
      "test Acc 0.9278398510242085:\n",
      "26th- epoch: 63, train_loss = 29.553727947175503, train_acc = 0.9332789939450395\n",
      "test Acc 0.9273743016759777:\n",
      "26th- epoch: 64, train_loss = 29.35338169336319, train_acc = 0.9340940847694458\n",
      "test Acc 0.9273743016759777:\n",
      "26th- epoch: 65, train_loss = 29.15799367427826, train_acc = 0.9346762925011645\n",
      "test Acc 0.9278398510242085:\n",
      "26th- epoch: 66, train_loss = 28.966332726180553, train_acc = 0.9349091755938519\n",
      "test Acc 0.9278398510242085:\n",
      "26th- epoch: 67, train_loss = 28.77913372218609, train_acc = 0.9354913833255706\n",
      "test Acc 0.9283054003724395:\n",
      "26th- epoch: 68, train_loss = 28.59538295865059, train_acc = 0.9358407079646017\n",
      "test Acc 0.9287709497206704:\n",
      "26th- epoch: 69, train_loss = 28.415948532521725, train_acc = 0.936190032603633\n",
      "test Acc 0.9292364990689013:\n",
      "26th- epoch: 70, train_loss = 28.239945232868195, train_acc = 0.9368886818816954\n",
      "test Acc 0.9292364990689013:\n",
      "26th- epoch: 71, train_loss = 28.067298397421837, train_acc = 0.9373544480670704\n",
      "test Acc 0.9292364990689013:\n",
      "26th- epoch: 72, train_loss = 27.897963792085648, train_acc = 0.9374708896134141\n",
      "test Acc 0.9297020484171322:\n",
      "26th- epoch: 73, train_loss = 27.732551217079163, train_acc = 0.9375873311597578\n",
      "test Acc 0.9297020484171322:\n",
      "26th- epoch: 74, train_loss = 27.57007908821106, train_acc = 0.937936655798789\n",
      "test Acc 0.9297020484171322:\n",
      "26th- epoch: 75, train_loss = 27.411182142794132, train_acc = 0.9385188635305077\n",
      "test Acc 0.9297020484171322:\n",
      "26th- epoch: 76, train_loss = 27.25518486648798, train_acc = 0.9384024219841639\n",
      "test Acc 0.9292364990689013:\n",
      "26th- epoch: 77, train_loss = 27.102067194879055, train_acc = 0.9384024219841639\n",
      "test Acc 0.9297020484171322:\n",
      "26th- epoch: 78, train_loss = 26.95190355181694, train_acc = 0.9389846297158826\n",
      "test Acc 0.9297020484171322:\n",
      "26th- epoch: 79, train_loss = 26.80461774766445, train_acc = 0.9391010712622264\n",
      "test Acc 0.9297020484171322:\n",
      "26th- epoch: 80, train_loss = 26.660073027014732, train_acc = 0.9393339543549138\n",
      "test Acc 0.9297020484171322:\n",
      "26th- epoch: 81, train_loss = 26.51784773916006, train_acc = 0.939683278993945\n",
      "test Acc 0.930633147113594:\n",
      "26th- epoch: 82, train_loss = 26.377885803580284, train_acc = 0.9400326036329762\n",
      "test Acc 0.930633147113594:\n",
      "26th- epoch: 83, train_loss = 26.240788608789444, train_acc = 0.9403819282720075\n",
      "test Acc 0.931098696461825:\n",
      "26th- epoch: 84, train_loss = 26.10549995675683, train_acc = 0.9407312529110387\n",
      "test Acc 0.931098696461825:\n",
      "26th- epoch: 85, train_loss = 25.973205272108316, train_acc = 0.941429902189101\n",
      "test Acc 0.9315642458100558:\n",
      "26th- epoch: 86, train_loss = 25.842336017638445, train_acc = 0.941895668374476\n",
      "test Acc 0.9315642458100558:\n",
      "26th- epoch: 87, train_loss = 25.71457850188017, train_acc = 0.9420121099208197\n",
      "test Acc 0.9315642458100558:\n",
      "26th- epoch: 88, train_loss = 25.58862106502056, train_acc = 0.9425943176525384\n",
      "test Acc 0.9315642458100558:\n",
      "26th- epoch: 89, train_loss = 25.46389292180538, train_acc = 0.9430600838379134\n",
      "test Acc 0.9315642458100558:\n",
      "26th- epoch: 90, train_loss = 25.342020500451326, train_acc = 0.9432929669306008\n",
      "test Acc 0.9315642458100558:\n",
      "26th- epoch: 91, train_loss = 25.22159817814827, train_acc = 0.9437587331159758\n",
      "test Acc 0.9315642458100558:\n",
      "26th- epoch: 92, train_loss = 25.103627111762762, train_acc = 0.9443409408476945\n",
      "test Acc 0.9315642458100558:\n",
      "26th- epoch: 93, train_loss = 24.9880536980927, train_acc = 0.9445738239403819\n",
      "test Acc 0.9320297951582868:\n",
      "26th- epoch: 94, train_loss = 24.874001439660788, train_acc = 0.9450395901257569\n",
      "test Acc 0.9315642458100558:\n",
      "26th- epoch: 95, train_loss = 24.762425012886524, train_acc = 0.9452724732184443\n",
      "test Acc 0.9315642458100558:\n",
      "26th- epoch: 96, train_loss = 24.652776040136814, train_acc = 0.9455053563111319\n",
      "test Acc 0.9315642458100558:\n",
      "26th- epoch: 97, train_loss = 24.543800815939903, train_acc = 0.945854680950163\n",
      "test Acc 0.9320297951582868:\n",
      "26th- epoch: 98, train_loss = 24.436743553727865, train_acc = 0.9460875640428504\n",
      "test Acc 0.9324953445065177:\n",
      "26th- epoch: 99, train_loss = 24.330552902072668, train_acc = 0.946320447135538\n",
      "test Acc 0.9329608938547486:\n",
      "26th- epoch: 100, train_loss = 24.22727708145976, train_acc = 0.9466697717745691\n",
      "test Acc 0.9334264432029795:\n",
      "26th- epoch: 101, train_loss = 24.126761980354786, train_acc = 0.9470190964136004\n",
      "test Acc 0.9338919925512105:\n",
      "26th- epoch: 102, train_loss = 24.024826273322105, train_acc = 0.9470190964136004\n",
      "test Acc 0.9343575418994413:\n",
      "26th- epoch: 103, train_loss = 23.927226949483156, train_acc = 0.9470190964136004\n",
      "test Acc 0.9343575418994413:\n",
      "26th- epoch: 104, train_loss = 23.82831897214055, train_acc = 0.9473684210526315\n",
      "test Acc 0.9343575418994413:\n",
      "26th- epoch: 105, train_loss = 23.73371270671487, train_acc = 0.9476013041453191\n",
      "test Acc 0.9343575418994413:\n",
      "26th- epoch: 106, train_loss = 23.639078836888075, train_acc = 0.9477177456916628\n",
      "test Acc 0.9343575418994413:\n",
      "26th- epoch: 107, train_loss = 23.544658455997705, train_acc = 0.9477177456916628\n",
      "test Acc 0.9343575418994413:\n",
      "26th- epoch: 108, train_loss = 23.454879838973284, train_acc = 0.9477177456916628\n",
      "test Acc 0.9348230912476723:\n",
      "26th- epoch: 109, train_loss = 23.364582009613514, train_acc = 0.948067070330694\n",
      "test Acc 0.9348230912476723:\n",
      "26th- epoch: 110, train_loss = 23.276096876710653, train_acc = 0.9481835118770378\n",
      "test Acc 0.9348230912476723:\n",
      "26th- epoch: 111, train_loss = 23.18794571980834, train_acc = 0.9484163949697252\n",
      "test Acc 0.9357541899441341:\n",
      "26th- epoch: 112, train_loss = 23.101376939564943, train_acc = 0.9485328365160689\n",
      "test Acc 0.9357541899441341:\n",
      "26th- epoch: 113, train_loss = 23.016830813139677, train_acc = 0.9485328365160689\n",
      "test Acc 0.936219739292365:\n",
      "26th- epoch: 114, train_loss = 22.932866651564837, train_acc = 0.9485328365160689\n",
      "test Acc 0.936219739292365:\n",
      "26th- epoch: 115, train_loss = 22.84982854500413, train_acc = 0.9487657196087564\n",
      "test Acc 0.936219739292365:\n",
      "26th- epoch: 116, train_loss = 22.76967929676175, train_acc = 0.9488821611551002\n",
      "test Acc 0.936219739292365:\n",
      "26th- epoch: 117, train_loss = 22.68924153968692, train_acc = 0.9488821611551002\n",
      "test Acc 0.936219739292365:\n",
      "26th- epoch: 118, train_loss = 22.610048089176416, train_acc = 0.9489986027014439\n",
      "test Acc 0.936219739292365:\n",
      "26th- epoch: 119, train_loss = 22.53166638314724, train_acc = 0.9492314857941313\n",
      "test Acc 0.936219739292365:\n",
      "26th- epoch: 120, train_loss = 22.45490473881364, train_acc = 0.9491150442477876\n",
      "test Acc 0.9371508379888268:\n",
      "26th- epoch: 121, train_loss = 22.37870693579316, train_acc = 0.9495808104331626\n",
      "test Acc 0.9371508379888268:\n",
      "26th- epoch: 122, train_loss = 22.303253196179867, train_acc = 0.9496972519795063\n",
      "test Acc 0.9371508379888268:\n",
      "26th- epoch: 123, train_loss = 22.2291302010417, train_acc = 0.9499301350721937\n",
      "test Acc 0.9371508379888268:\n",
      "26th- epoch: 124, train_loss = 22.155503623187542, train_acc = 0.9499301350721937\n",
      "test Acc 0.9376163873370578:\n",
      "26th- epoch: 125, train_loss = 22.082900192588568, train_acc = 0.9500465766185375\n",
      "test Acc 0.9376163873370578:\n",
      "26th- epoch: 126, train_loss = 22.011253394186497, train_acc = 0.9501630181648812\n",
      "test Acc 0.9376163873370578:\n",
      "26th- epoch: 127, train_loss = 21.941262807697058, train_acc = 0.950279459711225\n",
      "test Acc 0.9376163873370578:\n",
      "26th- epoch: 128, train_loss = 21.87155007943511, train_acc = 0.9503959012575687\n",
      "test Acc 0.9376163873370578:\n",
      "26th- epoch: 129, train_loss = 21.802324321120977, train_acc = 0.9503959012575687\n",
      "test Acc 0.9376163873370578:\n",
      "26th- epoch: 130, train_loss = 21.73438101261854, train_acc = 0.9507452258965999\n",
      "test Acc 0.9376163873370578:\n",
      "26th- epoch: 131, train_loss = 21.667125392705202, train_acc = 0.9507452258965999\n",
      "test Acc 0.9385474860335196:\n",
      "26th- epoch: 132, train_loss = 21.600868843495846, train_acc = 0.9508616674429436\n",
      "test Acc 0.9385474860335196:\n",
      "26th- epoch: 133, train_loss = 21.53494591638446, train_acc = 0.9509781089892874\n",
      "test Acc 0.9390130353817505:\n",
      "26th- epoch: 134, train_loss = 21.470488917082548, train_acc = 0.9510945505356311\n",
      "test Acc 0.9394785847299814:\n",
      "26th- epoch: 135, train_loss = 21.406575668603182, train_acc = 0.9510945505356311\n",
      "test Acc 0.9394785847299814:\n",
      "26th- epoch: 136, train_loss = 21.342991050332785, train_acc = 0.9510945505356311\n",
      "test Acc 0.9394785847299814:\n",
      "26th- epoch: 137, train_loss = 21.279818944633007, train_acc = 0.9510945505356311\n",
      "test Acc 0.9394785847299814:\n",
      "26th- epoch: 138, train_loss = 21.218074589967728, train_acc = 0.9512109920819748\n",
      "test Acc 0.9394785847299814:\n",
      "26th- epoch: 139, train_loss = 21.15687982365489, train_acc = 0.9512109920819748\n",
      "test Acc 0.9394785847299814:\n",
      "26th- epoch: 140, train_loss = 21.09652867168188, train_acc = 0.9512109920819748\n",
      "test Acc 0.9394785847299814:\n",
      "26th- epoch: 141, train_loss = 21.036266416311264, train_acc = 0.9514438751746623\n",
      "test Acc 0.9394785847299814:\n",
      "26th- epoch: 142, train_loss = 20.976617857813835, train_acc = 0.951560316721006\n",
      "test Acc 0.9394785847299814:\n",
      "26th- epoch: 143, train_loss = 20.918442651629448, train_acc = 0.9517931998136935\n",
      "test Acc 0.9399441340782123:\n",
      "26th- epoch: 144, train_loss = 20.86077342182398, train_acc = 0.9519096413600373\n",
      "test Acc 0.9399441340782123:\n",
      "26th- epoch: 145, train_loss = 20.801247142255306, train_acc = 0.9522589659990685\n",
      "test Acc 0.9399441340782123:\n",
      "26th- epoch: 146, train_loss = 20.74525311216712, train_acc = 0.9526082906380997\n",
      "test Acc 0.9399441340782123:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 147, train_loss = 20.690725602209568, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "26th- epoch: 148, train_loss = 20.634742252528667, train_acc = 0.9528411737307871\n",
      "test Acc 0.9404096834264432:\n",
      "26th- epoch: 149, train_loss = 20.579038459807634, train_acc = 0.9529576152771309\n",
      "test Acc 0.9408752327746741:\n",
      "26th- epoch: 150, train_loss = 20.52529600262642, train_acc = 0.9530740568234746\n",
      "test Acc 0.9408752327746741:\n",
      "26th- epoch: 151, train_loss = 20.47357353195548, train_acc = 0.9533069399161621\n",
      "test Acc 0.9408752327746741:\n",
      "26th- epoch: 152, train_loss = 20.41984048113227, train_acc = 0.9535398230088495\n",
      "test Acc 0.9408752327746741:\n",
      "26th- epoch: 153, train_loss = 20.365327950567007, train_acc = 0.9537727061015371\n",
      "test Acc 0.9408752327746741:\n",
      "26th- epoch: 154, train_loss = 20.313790474087, train_acc = 0.9537727061015371\n",
      "test Acc 0.9408752327746741:\n",
      "26th- epoch: 155, train_loss = 20.262119859457016, train_acc = 0.9538891476478808\n",
      "test Acc 0.9408752327746741:\n",
      "26th- epoch: 156, train_loss = 20.212735649198294, train_acc = 0.9541220307405682\n",
      "test Acc 0.9413407821229051:\n",
      "26th- epoch: 157, train_loss = 20.161044090986252, train_acc = 0.9542384722869119\n",
      "test Acc 0.9418063314711359:\n",
      "26th- epoch: 158, train_loss = 20.112960785627365, train_acc = 0.9544713553795995\n",
      "test Acc 0.9418063314711359:\n",
      "26th- epoch: 159, train_loss = 20.06274415180087, train_acc = 0.9544713553795995\n",
      "test Acc 0.9418063314711359:\n",
      "26th- epoch: 160, train_loss = 20.013485558331013, train_acc = 0.9547042384722869\n",
      "test Acc 0.9418063314711359:\n",
      "26th- epoch: 161, train_loss = 19.964635459706187, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "26th- epoch: 162, train_loss = 19.91739902459085, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "26th- epoch: 163, train_loss = 19.86815201304853, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "26th- epoch: 164, train_loss = 19.822693480178714, train_acc = 0.9554028877503493\n",
      "test Acc 0.9418063314711359:\n",
      "26th- epoch: 165, train_loss = 19.774749478325248, train_acc = 0.9552864462040056\n",
      "test Acc 0.9418063314711359:\n",
      "26th- epoch: 166, train_loss = 19.72989253140986, train_acc = 0.9554028877503493\n",
      "test Acc 0.9422718808193669:\n",
      "26th- epoch: 167, train_loss = 19.682462291792035, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "26th- epoch: 168, train_loss = 19.63902434334159, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "26th- epoch: 169, train_loss = 19.59327451325953, train_acc = 0.955519329296693\n",
      "test Acc 0.9422718808193669:\n",
      "26th- epoch: 170, train_loss = 19.548351798206568, train_acc = 0.9556357708430367\n",
      "test Acc 0.9422718808193669:\n",
      "26th- epoch: 171, train_loss = 19.50565262697637, train_acc = 0.9556357708430367\n",
      "test Acc 0.9422718808193669:\n",
      "26th- epoch: 172, train_loss = 19.461558235809207, train_acc = 0.955519329296693\n",
      "test Acc 0.9427374301675978:\n",
      "26th- epoch: 173, train_loss = 19.416921908035874, train_acc = 0.9557522123893806\n",
      "test Acc 0.9427374301675978:\n",
      "26th- epoch: 174, train_loss = 19.375897828489542, train_acc = 0.9561015370284117\n",
      "test Acc 0.9427374301675978:\n",
      "26th- epoch: 175, train_loss = 19.332178527489305, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "26th- epoch: 176, train_loss = 19.291407456621528, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "26th- epoch: 177, train_loss = 19.2503368165344, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "26th- epoch: 178, train_loss = 19.208255598321557, train_acc = 0.956450861667443\n",
      "test Acc 0.9427374301675978:\n",
      "26th- epoch: 179, train_loss = 19.16739492304623, train_acc = 0.9565673032137867\n",
      "test Acc 0.9432029795158287:\n",
      "26th- epoch: 180, train_loss = 19.128279926255345, train_acc = 0.9565673032137867\n",
      "test Acc 0.9432029795158287:\n",
      "26th- epoch: 181, train_loss = 19.08745041489601, train_acc = 0.9568001863064741\n",
      "test Acc 0.9432029795158287:\n",
      "26th- epoch: 182, train_loss = 19.047882681712508, train_acc = 0.9570330693991617\n",
      "test Acc 0.9432029795158287:\n",
      "26th- epoch: 183, train_loss = 19.008343640714884, train_acc = 0.9570330693991617\n",
      "test Acc 0.9432029795158287:\n",
      "26th- epoch: 184, train_loss = 18.96948708035052, train_acc = 0.9573823940381928\n",
      "test Acc 0.9436685288640596:\n",
      "26th- epoch: 185, train_loss = 18.931079683825374, train_acc = 0.9574988355845365\n",
      "test Acc 0.9436685288640596:\n",
      "26th- epoch: 186, train_loss = 18.89310516230762, train_acc = 0.9579646017699115\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 187, train_loss = 18.855392161756754, train_acc = 0.9580810433162552\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 188, train_loss = 18.817688949406147, train_acc = 0.9581974848625989\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 189, train_loss = 18.78059315867722, train_acc = 0.9580810433162552\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 190, train_loss = 18.743671588599682, train_acc = 0.9583139264089428\n",
      "test Acc 0.9445996275605214:\n",
      "26th- epoch: 191, train_loss = 18.708631264045835, train_acc = 0.9583139264089428\n",
      "test Acc 0.9450651769087524:\n",
      "26th- epoch: 192, train_loss = 18.67159583233297, train_acc = 0.9583139264089428\n",
      "test Acc 0.9450651769087524:\n",
      "26th- epoch: 193, train_loss = 18.635069610551, train_acc = 0.9583139264089428\n",
      "test Acc 0.9450651769087524:\n",
      "26th- epoch: 194, train_loss = 18.601465709507465, train_acc = 0.9583139264089428\n",
      "test Acc 0.9459962756052142:\n",
      "26th- epoch: 195, train_loss = 18.564611738547683, train_acc = 0.9583139264089428\n",
      "test Acc 0.9459962756052142:\n",
      "26th- epoch: 196, train_loss = 18.530060913413763, train_acc = 0.9583139264089428\n",
      "test Acc 0.9459962756052142:\n",
      "26th- epoch: 197, train_loss = 18.495181061327457, train_acc = 0.9584303679552865\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 198, train_loss = 18.462787875905633, train_acc = 0.9585468095016302\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 199, train_loss = 18.428708033636212, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 200, train_loss = 18.393154254183173, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 201, train_loss = 18.35972475633025, train_acc = 0.9590125756870052\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 202, train_loss = 18.3262093719095, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 203, train_loss = 18.29529339261353, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 204, train_loss = 18.263160325586796, train_acc = 0.9592454587796926\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 205, train_loss = 18.229816241189837, train_acc = 0.9592454587796926\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 206, train_loss = 18.198171105235815, train_acc = 0.9592454587796926\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 207, train_loss = 18.165429359301925, train_acc = 0.9593619003260363\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 208, train_loss = 18.134685518220067, train_acc = 0.9593619003260363\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 209, train_loss = 18.10315679386258, train_acc = 0.9593619003260363\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 210, train_loss = 18.071175230666995, train_acc = 0.9593619003260363\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 211, train_loss = 18.04110372811556, train_acc = 0.9593619003260363\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 212, train_loss = 18.010692400857806, train_acc = 0.9593619003260363\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 213, train_loss = 17.98181293718517, train_acc = 0.9595947834187238\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 214, train_loss = 17.95271442271769, train_acc = 0.9595947834187238\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 215, train_loss = 17.92293907701969, train_acc = 0.9595947834187238\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 216, train_loss = 17.892010122537613, train_acc = 0.9597112249650676\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 217, train_loss = 17.862558050081134, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 218, train_loss = 17.835195219144225, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 219, train_loss = 17.807824021205306, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 220, train_loss = 17.778977662324905, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 221, train_loss = 17.74849277921021, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 222, train_loss = 17.720807436853647, train_acc = 0.959944108057755\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 223, train_loss = 17.69326569326222, train_acc = 0.959944108057755\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 224, train_loss = 17.665878331288695, train_acc = 0.9600605496040987\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 225, train_loss = 17.641324307769537, train_acc = 0.9600605496040987\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 226, train_loss = 17.612700605764985, train_acc = 0.9600605496040987\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 227, train_loss = 17.586319083347917, train_acc = 0.9601769911504425\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 228, train_loss = 17.56235865689814, train_acc = 0.9601769911504425\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 229, train_loss = 17.534122528508306, train_acc = 0.9601769911504425\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 230, train_loss = 17.507595874369144, train_acc = 0.9601769911504425\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 231, train_loss = 17.4816204123199, train_acc = 0.9602934326967862\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 232, train_loss = 17.456704204902053, train_acc = 0.9602934326967862\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 233, train_loss = 17.432891063392162, train_acc = 0.9602934326967862\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 234, train_loss = 17.406387619674206, train_acc = 0.96040987424313\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 235, train_loss = 17.38081611134112, train_acc = 0.9605263157894737\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 236, train_loss = 17.35873588360846, train_acc = 0.9605263157894737\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 237, train_loss = 17.332009848207235, train_acc = 0.9605263157894737\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 238, train_loss = 17.307535350322723, train_acc = 0.9605263157894737\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 239, train_loss = 17.286104008555412, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 240, train_loss = 17.25990654528141, train_acc = 0.9609920819748486\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 241, train_loss = 17.235220979899168, train_acc = 0.9609920819748486\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 242, train_loss = 17.213557997718453, train_acc = 0.9609920819748486\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 243, train_loss = 17.187451420351863, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 244, train_loss = 17.167533196508884, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 245, train_loss = 17.141805998981, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 246, train_loss = 17.11980204284191, train_acc = 0.9613414066138798\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 247, train_loss = 17.09657389856875, train_acc = 0.9614578481602236\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 248, train_loss = 17.072958322241902, train_acc = 0.961690731252911\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 249, train_loss = 17.051465222612023, train_acc = 0.9618071727992548\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 250, train_loss = 17.03043711744249, train_acc = 0.9619236143455985\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 251, train_loss = 17.0076220119372, train_acc = 0.9619236143455985\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 252, train_loss = 16.984068191610277, train_acc = 0.9619236143455985\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 253, train_loss = 16.96254536509514, train_acc = 0.9619236143455985\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 254, train_loss = 16.94285295624286, train_acc = 0.9619236143455985\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 255, train_loss = 16.919616661034524, train_acc = 0.9620400558919422\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 256, train_loss = 16.900824185460806, train_acc = 0.9620400558919422\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 257, train_loss = 16.878461970947683, train_acc = 0.962156497438286\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 258, train_loss = 16.858522955328226, train_acc = 0.962156497438286\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 259, train_loss = 16.836065892130136, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 260, train_loss = 16.81727051641792, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 261, train_loss = 16.79741821810603, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 262, train_loss = 16.77536343038082, train_acc = 0.9625058220773172\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 263, train_loss = 16.754362222738564, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 264, train_loss = 16.7369095524773, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 265, train_loss = 16.71576217096299, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 266, train_loss = 16.69589636195451, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 267, train_loss = 16.675993324257433, train_acc = 0.9628551467163484\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 268, train_loss = 16.65822507813573, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 269, train_loss = 16.638427185826004, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 270, train_loss = 16.617896079085767, train_acc = 0.9630880298090359\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 271, train_loss = 16.599964030086994, train_acc = 0.9630880298090359\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 272, train_loss = 16.580852230079472, train_acc = 0.9630880298090359\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 273, train_loss = 16.561985346488655, train_acc = 0.9630880298090359\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 274, train_loss = 16.543593580834568, train_acc = 0.9630880298090359\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 275, train_loss = 16.524197596125305, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 276, train_loss = 16.506316599436104, train_acc = 0.9632044713553796\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 277, train_loss = 16.488839201629162, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 278, train_loss = 16.47092094272375, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 279, train_loss = 16.453652904368937, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 280, train_loss = 16.43544834572822, train_acc = 0.9634373544480671\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 281, train_loss = 16.418100097216666, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 282, train_loss = 16.400046247057617, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 283, train_loss = 16.38270081114024, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 284, train_loss = 16.364723205566406, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 285, train_loss = 16.347325542010367, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 286, train_loss = 16.33074076194316, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 287, train_loss = 16.313798029907048, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 288, train_loss = 16.296789075247943, train_acc = 0.963903120633442\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 289, train_loss = 16.279318913817406, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 290, train_loss = 16.26305860374123, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 291, train_loss = 16.246739719994366, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 292, train_loss = 16.22999631613493, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 293, train_loss = 16.214165500365198, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 294, train_loss = 16.197769756428897, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 295, train_loss = 16.182138714008033, train_acc = 0.9640195621797858\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 296, train_loss = 16.16538852918893, train_acc = 0.9641360037261295\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 297, train_loss = 16.150837044231594, train_acc = 0.9641360037261295\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 298, train_loss = 16.133922576904297, train_acc = 0.9641360037261295\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 299, train_loss = 16.117054973728955, train_acc = 0.9641360037261295\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 300, train_loss = 16.102171911858022, train_acc = 0.9641360037261295\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 301, train_loss = 16.087374534457922, train_acc = 0.9642524452724732\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 302, train_loss = 16.071618993766606, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 303, train_loss = 16.055421710945666, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 304, train_loss = 16.04047930520028, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 305, train_loss = 16.025463621132076, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 306, train_loss = 16.010371156036854, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 307, train_loss = 15.994125579483807, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 308, train_loss = 15.980117144994438, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 309, train_loss = 15.966283243149519, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 310, train_loss = 15.950839158147573, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 311, train_loss = 15.935745023190975, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 312, train_loss = 15.921808745712042, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 313, train_loss = 15.90694571658969, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 314, train_loss = 15.893002280034125, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 315, train_loss = 15.878708329983056, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 316, train_loss = 15.863652970641851, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 317, train_loss = 15.849973655305803, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 318, train_loss = 15.835697789676487, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 319, train_loss = 15.82161255646497, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 320, train_loss = 15.808327472768724, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 321, train_loss = 15.794687957502902, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 322, train_loss = 15.78037644829601, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 323, train_loss = 15.767435225658119, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 324, train_loss = 15.752304683439434, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 325, train_loss = 15.739804282784462, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 326, train_loss = 15.726157233119011, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 327, train_loss = 15.712253339588642, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 328, train_loss = 15.700293547473848, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 329, train_loss = 15.686647458933294, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 330, train_loss = 15.673769391141832, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 331, train_loss = 15.659882768057287, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 332, train_loss = 15.647180045954883, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 333, train_loss = 15.6350112631917, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 334, train_loss = 15.621690488420427, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 335, train_loss = 15.609396290034056, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 336, train_loss = 15.596937564201653, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 337, train_loss = 15.584844975732267, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 338, train_loss = 15.571547570638359, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 339, train_loss = 15.560283713042736, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 340, train_loss = 15.548635165207088, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 341, train_loss = 15.534990162588656, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 342, train_loss = 15.523637308739126, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 343, train_loss = 15.51122919563204, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 344, train_loss = 15.499036916531622, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 345, train_loss = 15.48540857899934, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 346, train_loss = 15.474718580953777, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 347, train_loss = 15.462828480638564, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 348, train_loss = 15.451129055581987, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 349, train_loss = 15.43982357904315, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 350, train_loss = 15.428131323307753, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 351, train_loss = 15.415304407477379, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 352, train_loss = 15.404166557826102, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 353, train_loss = 15.393371402285993, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 354, train_loss = 15.381353820674121, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 355, train_loss = 15.37082859966904, train_acc = 0.9655333022822543\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 356, train_loss = 15.357678189873695, train_acc = 0.965649743828598\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 357, train_loss = 15.34847656544298, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 358, train_loss = 15.336828005500138, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 359, train_loss = 15.325447061099112, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 360, train_loss = 15.313692306168377, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 361, train_loss = 15.303845434449613, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 362, train_loss = 15.292404558509588, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 363, train_loss = 15.281863047741354, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 364, train_loss = 15.270684626884758, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 365, train_loss = 15.259782619774342, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 366, train_loss = 15.249663735739887, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 367, train_loss = 15.23893075529486, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 368, train_loss = 15.22812806814909, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 369, train_loss = 15.217153046280146, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 370, train_loss = 15.207056964747608, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 371, train_loss = 15.196633093059063, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 372, train_loss = 15.186202716082335, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 373, train_loss = 15.175704679451883, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 374, train_loss = 15.1666313810274, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 375, train_loss = 15.156950439326465, train_acc = 0.966115510013973\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 376, train_loss = 15.145290511660278, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 377, train_loss = 15.134763347916305, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 378, train_loss = 15.126775306649506, train_acc = 0.966115510013973\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 379, train_loss = 15.115497666411102, train_acc = 0.966115510013973\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 380, train_loss = 15.10684262868017, train_acc = 0.966115510013973\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 381, train_loss = 15.09568879660219, train_acc = 0.966115510013973\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 382, train_loss = 15.087377686053514, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 383, train_loss = 15.077037303708494, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 384, train_loss = 15.066460873000324, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 385, train_loss = 15.057398715056479, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 386, train_loss = 15.048538477160037, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 387, train_loss = 15.036467544734478, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 388, train_loss = 15.027575884014368, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 389, train_loss = 15.01909248251468, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 390, train_loss = 15.009270681999624, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 391, train_loss = 14.99913177639246, train_acc = 0.9662319515603167\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 392, train_loss = 14.989744585938752, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 393, train_loss = 14.981587856076658, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 394, train_loss = 14.97322925273329, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 395, train_loss = 14.963315769098699, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 396, train_loss = 14.954579911194742, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 397, train_loss = 14.944532286375761, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 398, train_loss = 14.936296491883695, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 399, train_loss = 14.92571438010782, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 400, train_loss = 14.918586109764874, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 401, train_loss = 14.910019095055759, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 402, train_loss = 14.90032145101577, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 403, train_loss = 14.891020129434764, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 404, train_loss = 14.880258374847472, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 405, train_loss = 14.872725534252822, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 406, train_loss = 14.864630106836557, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 407, train_loss = 14.856130440719426, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 408, train_loss = 14.846583562903106, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 409, train_loss = 14.839228720404208, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 410, train_loss = 14.830711096525192, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 411, train_loss = 14.821724916808307, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 412, train_loss = 14.813660473562777, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 413, train_loss = 14.805007587186992, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 414, train_loss = 14.796505172736943, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 415, train_loss = 14.787693304009736, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 416, train_loss = 14.780422702431679, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 417, train_loss = 14.770105626434088, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 418, train_loss = 14.764265533536673, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 419, train_loss = 14.755805551074445, train_acc = 0.9664648346530041\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 420, train_loss = 14.746692135930061, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 421, train_loss = 14.737783106975257, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 422, train_loss = 14.731294956058264, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 423, train_loss = 14.721776313148439, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 424, train_loss = 14.715997842140496, train_acc = 0.966581276199348\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 425, train_loss = 14.707693934440613, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 426, train_loss = 14.69901109766215, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 427, train_loss = 14.691625983454287, train_acc = 0.9666977177456917\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 428, train_loss = 14.683834116905928, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 429, train_loss = 14.675305572338402, train_acc = 0.9668141592920354\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 430, train_loss = 14.667895925231278, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 431, train_loss = 14.660327170044184, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 432, train_loss = 14.65316818933934, train_acc = 0.9669306008383791\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 433, train_loss = 14.645449851639569, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 434, train_loss = 14.640088112093508, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 435, train_loss = 14.63045162614435, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 436, train_loss = 14.623620158992708, train_acc = 0.9672799254774104\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 437, train_loss = 14.614555585198104, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 438, train_loss = 14.608977600000799, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 439, train_loss = 14.601153034716845, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 440, train_loss = 14.593110863119364, train_acc = 0.9673963670237541\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 441, train_loss = 14.586450524628162, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 442, train_loss = 14.578604756388813, train_acc = 0.9673963670237541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 443, train_loss = 14.570796745363623, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 444, train_loss = 14.563534999731928, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 445, train_loss = 14.556563843041658, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 446, train_loss = 14.54876003274694, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 447, train_loss = 14.543332433793694, train_acc = 0.9673963670237541\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 448, train_loss = 14.53565769130364, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 449, train_loss = 14.528836713638157, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 450, train_loss = 14.522648628801107, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 451, train_loss = 14.513442032039165, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 452, train_loss = 14.507713662926108, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 453, train_loss = 14.50244185095653, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 454, train_loss = 14.492139535490423, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 455, train_loss = 14.487128914799541, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 456, train_loss = 14.48146379366517, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 457, train_loss = 14.47385590011254, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 458, train_loss = 14.466263139154762, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 459, train_loss = 14.460019661579281, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 460, train_loss = 14.45224000280723, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 461, train_loss = 14.446261948440224, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 462, train_loss = 14.439148022327572, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 463, train_loss = 14.43212158838287, train_acc = 0.9676292501164415\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 464, train_loss = 14.426889521535486, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 465, train_loss = 14.419499123003334, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 466, train_loss = 14.412826122250408, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 467, train_loss = 14.407152520027012, train_acc = 0.9677456916627852\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 468, train_loss = 14.400195648428053, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 469, train_loss = 14.393265960272402, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 470, train_loss = 14.388124988880008, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 471, train_loss = 14.379754366818815, train_acc = 0.9679785747554728\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 472, train_loss = 14.372983107808977, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 473, train_loss = 14.368458376731724, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 474, train_loss = 14.361065825913101, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 475, train_loss = 14.353724582586437, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 476, train_loss = 14.34945690492168, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 477, train_loss = 14.342211335897446, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 478, train_loss = 14.33695591846481, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 479, train_loss = 14.329323196318, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 480, train_loss = 14.323849117849022, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 481, train_loss = 14.319001195486635, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 482, train_loss = 14.313081808388233, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 483, train_loss = 14.303942190948874, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 484, train_loss = 14.2996745579876, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 485, train_loss = 14.293648874852806, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 486, train_loss = 14.287506343331188, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 487, train_loss = 14.283860849682242, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 488, train_loss = 14.276547902729362, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 489, train_loss = 14.270940856542438, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 490, train_loss = 14.26516086468473, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 491, train_loss = 14.25819430500269, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 492, train_loss = 14.25342696532607, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 493, train_loss = 14.247103074099869, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 494, train_loss = 14.241919832769781, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 495, train_loss = 14.236444856971502, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 496, train_loss = 14.228780610021204, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 497, train_loss = 14.223355028778315, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 498, train_loss = 14.219826024025679, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 499, train_loss = 14.210774717386812, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|██████████████████████████████████████████████████████████████▍         | 26/30 [2:52:57<26:37, 399.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "27th- epoch: 0, train_loss = 272.2879630327225, train_acc = 0.44993013507219376\n",
      "test Acc 0.49534450651769085:\n",
      "27th- epoch: 1, train_loss = 213.84575426578522, train_acc = 0.4997671169073125\n",
      "test Acc 0.5:\n",
      "27th- epoch: 2, train_loss = 179.10413718223572, train_acc = 0.5075687005123428\n",
      "test Acc 0.5176908752327747:\n",
      "27th- epoch: 3, train_loss = 162.42631191015244, train_acc = 0.5386585933861202\n",
      "test Acc 0.569366852886406:\n",
      "27th- epoch: 4, train_loss = 149.48957240581512, train_acc = 0.5887284583139264\n",
      "test Acc 0.6089385474860335:\n",
      "27th- epoch: 5, train_loss = 137.8546946644783, train_acc = 0.6155100139729855\n",
      "test Acc 0.63268156424581:\n",
      "27th- epoch: 6, train_loss = 127.09526640176773, train_acc = 0.6443875174662319\n",
      "test Acc 0.7239292364990689:\n",
      "27th- epoch: 7, train_loss = 117.13881641626358, train_acc = 0.7072659524918491\n",
      "test Acc 0.7546554934823091:\n",
      "27th- epoch: 8, train_loss = 107.99844658374786, train_acc = 0.7594317652538426\n",
      "test Acc 0.7779329608938548:\n",
      "27th- epoch: 9, train_loss = 99.71689569950104, train_acc = 0.7837680484396833\n",
      "test Acc 0.8054003724394786:\n",
      "27th- epoch: 10, train_loss = 92.29087120294571, train_acc = 0.8112482533768048\n",
      "test Acc 0.8198324022346368:\n",
      "27th- epoch: 11, train_loss = 85.72210904955864, train_acc = 0.8247554727526781\n",
      "test Acc 0.8324022346368715:\n",
      "27th- epoch: 12, train_loss = 79.96514284610748, train_acc = 0.8341872380065207\n",
      "test Acc 0.8486964618249534:\n",
      "27th- epoch: 13, train_loss = 74.91144809126854, train_acc = 0.8475780158360503\n",
      "test Acc 0.8547486033519553:\n",
      "27th- epoch: 14, train_loss = 70.49510771036148, train_acc = 0.857359105728924\n",
      "test Acc 0.8640595903165735:\n",
      "27th- epoch: 15, train_loss = 66.63072472810745, train_acc = 0.8663251047973917\n",
      "test Acc 0.8696461824953445:\n",
      "27th- epoch: 16, train_loss = 63.23588714003563, train_acc = 0.8715649743828598\n",
      "test Acc 0.8743016759776536:\n",
      "27th- epoch: 17, train_loss = 60.25419923663139, train_acc = 0.8764555193292967\n",
      "test Acc 0.8798882681564246:\n",
      "27th- epoch: 18, train_loss = 57.632303327322006, train_acc = 0.8801816488122962\n",
      "test Acc 0.8859404096834265:\n",
      "27th- epoch: 19, train_loss = 55.318108186125755, train_acc = 0.8841406613879832\n",
      "test Acc 0.8915270018621974:\n",
      "27th- epoch: 20, train_loss = 53.26967544853687, train_acc = 0.8883325570563577\n",
      "test Acc 0.8961824953445066:\n",
      "27th- epoch: 21, train_loss = 51.456616044044495, train_acc = 0.8934559850954821\n",
      "test Acc 0.8994413407821229:\n",
      "27th- epoch: 22, train_loss = 49.848587319254875, train_acc = 0.8962505822077317\n",
      "test Acc 0.9008379888268156:\n",
      "27th- epoch: 23, train_loss = 48.41521291434765, train_acc = 0.8984629715882627\n",
      "test Acc 0.9013035381750466:\n",
      "27th- epoch: 24, train_loss = 47.12831036746502, train_acc = 0.9005589194224499\n",
      "test Acc 0.904096834264432:\n",
      "27th- epoch: 25, train_loss = 45.96700923144817, train_acc = 0.9020726595249184\n",
      "test Acc 0.9050279329608939:\n",
      "27th- epoch: 26, train_loss = 44.91212624311447, train_acc = 0.9042850489054495\n",
      "test Acc 0.9073556797020484:\n",
      "27th- epoch: 27, train_loss = 43.950709372758865, train_acc = 0.9053330228225431\n",
      "test Acc 0.9087523277467412:\n",
      "27th- epoch: 28, train_loss = 43.072204545140266, train_acc = 0.9068467629250117\n",
      "test Acc 0.9087523277467412:\n",
      "27th- epoch: 29, train_loss = 42.26487146317959, train_acc = 0.9081276199347927\n",
      "test Acc 0.909217877094972:\n",
      "27th- epoch: 30, train_loss = 41.516985312104225, train_acc = 0.9095249184909175\n",
      "test Acc 0.910148975791434:\n",
      "27th- epoch: 31, train_loss = 40.82061153650284, train_acc = 0.9105728924080112\n",
      "test Acc 0.9110800744878957:\n",
      "27th- epoch: 32, train_loss = 40.17005552351475, train_acc = 0.9117373078714486\n",
      "test Acc 0.9124767225325885:\n",
      "27th- epoch: 33, train_loss = 39.560798823833466, train_acc = 0.9126688402421984\n",
      "test Acc 0.9138733705772812:\n",
      "27th- epoch: 34, train_loss = 38.98808406293392, train_acc = 0.9138332557056358\n",
      "test Acc 0.9138733705772812:\n",
      "27th- epoch: 35, train_loss = 38.4481418132782, train_acc = 0.9156963204471356\n",
      "test Acc 0.914804469273743:\n",
      "27th- epoch: 36, train_loss = 37.93643121421337, train_acc = 0.9168607359105729\n",
      "test Acc 0.9152700186219739:\n",
      "27th- epoch: 37, train_loss = 37.45092715322971, train_acc = 0.9180251513740102\n",
      "test Acc 0.9162011173184358:\n",
      "27th- epoch: 38, train_loss = 36.98813149333, train_acc = 0.9194224499301351\n",
      "test Acc 0.9162011173184358:\n",
      "27th- epoch: 39, train_loss = 36.546906515955925, train_acc = 0.9204704238472287\n",
      "test Acc 0.9175977653631285:\n",
      "27th- epoch: 40, train_loss = 36.12464663386345, train_acc = 0.9218677224033535\n",
      "test Acc 0.9185288640595903:\n",
      "27th- epoch: 41, train_loss = 35.720961675047874, train_acc = 0.9224499301350721\n",
      "test Acc 0.9199255121042831:\n",
      "27th- epoch: 42, train_loss = 35.3328061401844, train_acc = 0.9233814625058221\n",
      "test Acc 0.9203910614525139:\n",
      "27th- epoch: 43, train_loss = 34.96067249029875, train_acc = 0.9245458779692595\n",
      "test Acc 0.9213221601489758:\n",
      "27th- epoch: 44, train_loss = 34.60216034948826, train_acc = 0.9251280857009782\n",
      "test Acc 0.9236499068901304:\n",
      "27th- epoch: 45, train_loss = 34.25703264027834, train_acc = 0.9257102934326968\n",
      "test Acc 0.9245810055865922:\n",
      "27th- epoch: 46, train_loss = 33.923936285078526, train_acc = 0.9261760596180717\n",
      "test Acc 0.9250465549348231:\n",
      "27th- epoch: 47, train_loss = 33.60183844715357, train_acc = 0.9268747088961341\n",
      "test Acc 0.925512104283054:\n",
      "27th- epoch: 48, train_loss = 33.291197285056114, train_acc = 0.9279226828132278\n",
      "test Acc 0.9259776536312849:\n",
      "27th- epoch: 49, train_loss = 32.9896580055356, train_acc = 0.9286213320912902\n",
      "test Acc 0.9264432029795159:\n",
      "27th- epoch: 50, train_loss = 32.697888918221, train_acc = 0.9292035398230089\n",
      "test Acc 0.9269087523277467:\n",
      "27th- epoch: 51, train_loss = 32.414273634552956, train_acc = 0.9294364229156963\n",
      "test Acc 0.9269087523277467:\n",
      "27th- epoch: 52, train_loss = 32.13981629163027, train_acc = 0.9299021891010713\n",
      "test Acc 0.9269087523277467:\n",
      "27th- epoch: 53, train_loss = 31.873698331415653, train_acc = 0.9299021891010713\n",
      "test Acc 0.9273743016759777:\n",
      "27th- epoch: 54, train_loss = 31.6139697432518, train_acc = 0.9306008383791337\n",
      "test Acc 0.9273743016759777:\n",
      "27th- epoch: 55, train_loss = 31.361582070589066, train_acc = 0.9306008383791337\n",
      "test Acc 0.9273743016759777:\n",
      "27th- epoch: 56, train_loss = 31.116142831742764, train_acc = 0.9314159292035398\n",
      "test Acc 0.9273743016759777:\n",
      "27th- epoch: 57, train_loss = 30.876779183745384, train_acc = 0.9321145784816023\n",
      "test Acc 0.9273743016759777:\n",
      "27th- epoch: 58, train_loss = 30.64291237294674, train_acc = 0.9324639031206334\n",
      "test Acc 0.9278398510242085:\n",
      "27th- epoch: 59, train_loss = 30.414845548570156, train_acc = 0.9325803446669771\n",
      "test Acc 0.9283054003724395:\n",
      "27th- epoch: 60, train_loss = 30.19255579262972, train_acc = 0.9326967862133209\n",
      "test Acc 0.9283054003724395:\n",
      "27th- epoch: 61, train_loss = 29.974839739501476, train_acc = 0.9331625523986958\n",
      "test Acc 0.9283054003724395:\n",
      "27th- epoch: 62, train_loss = 29.762700006365776, train_acc = 0.9333954354913834\n",
      "test Acc 0.9283054003724395:\n",
      "27th- epoch: 63, train_loss = 29.554996594786644, train_acc = 0.9340940847694458\n",
      "test Acc 0.9278398510242085:\n",
      "27th- epoch: 64, train_loss = 29.35244619846344, train_acc = 0.9346762925011645\n",
      "test Acc 0.9278398510242085:\n",
      "27th- epoch: 65, train_loss = 29.153715930879116, train_acc = 0.9351420586865393\n",
      "test Acc 0.9278398510242085:\n",
      "27th- epoch: 66, train_loss = 28.95894732326269, train_acc = 0.9360735910572893\n",
      "test Acc 0.9287709497206704:\n",
      "27th- epoch: 67, train_loss = 28.767599292099476, train_acc = 0.9365393572426641\n",
      "test Acc 0.9287709497206704:\n",
      "27th- epoch: 68, train_loss = 28.580455988645554, train_acc = 0.9367722403353517\n",
      "test Acc 0.9287709497206704:\n",
      "27th- epoch: 69, train_loss = 28.396818719804287, train_acc = 0.9367722403353517\n",
      "test Acc 0.9287709497206704:\n",
      "27th- epoch: 70, train_loss = 28.216936461627483, train_acc = 0.9368886818816954\n",
      "test Acc 0.9287709497206704:\n",
      "27th- epoch: 71, train_loss = 28.040848575532436, train_acc = 0.9372380065207266\n",
      "test Acc 0.9287709497206704:\n",
      "27th- epoch: 72, train_loss = 27.867585383355618, train_acc = 0.9378202142524453\n",
      "test Acc 0.9292364990689013:\n",
      "27th- epoch: 73, train_loss = 27.69877129793167, train_acc = 0.9382859804378202\n",
      "test Acc 0.9297020484171322:\n",
      "27th- epoch: 74, train_loss = 27.533518061041832, train_acc = 0.9387517466231952\n",
      "test Acc 0.930633147113594:\n",
      "27th- epoch: 75, train_loss = 27.371314577758312, train_acc = 0.9391010712622264\n",
      "test Acc 0.930633147113594:\n",
      "27th- epoch: 76, train_loss = 27.212469957768917, train_acc = 0.9392175128085701\n",
      "test Acc 0.930633147113594:\n",
      "27th- epoch: 77, train_loss = 27.055981904268265, train_acc = 0.9392175128085701\n",
      "test Acc 0.930633147113594:\n",
      "27th- epoch: 78, train_loss = 26.902807533740997, train_acc = 0.9392175128085701\n",
      "test Acc 0.930633147113594:\n",
      "27th- epoch: 79, train_loss = 26.751671135425568, train_acc = 0.9394503959012576\n",
      "test Acc 0.9315642458100558:\n",
      "27th- epoch: 80, train_loss = 26.604066140949726, train_acc = 0.9400326036329762\n",
      "test Acc 0.9315642458100558:\n",
      "27th- epoch: 81, train_loss = 26.45832598209381, train_acc = 0.9404983698183512\n",
      "test Acc 0.9315642458100558:\n",
      "27th- epoch: 82, train_loss = 26.315706826746464, train_acc = 0.9407312529110387\n",
      "test Acc 0.9315642458100558:\n",
      "27th- epoch: 83, train_loss = 26.175416368991137, train_acc = 0.9410805775500699\n",
      "test Acc 0.9329608938547486:\n",
      "27th- epoch: 84, train_loss = 26.037486862391233, train_acc = 0.9416627852817886\n",
      "test Acc 0.9329608938547486:\n",
      "27th- epoch: 85, train_loss = 25.902134396135807, train_acc = 0.9417792268281323\n",
      "test Acc 0.9329608938547486:\n",
      "27th- epoch: 86, train_loss = 25.769276723265648, train_acc = 0.9420121099208197\n",
      "test Acc 0.9329608938547486:\n",
      "27th- epoch: 87, train_loss = 25.63804107159376, train_acc = 0.9420121099208197\n",
      "test Acc 0.9329608938547486:\n",
      "27th- epoch: 88, train_loss = 25.509856402873993, train_acc = 0.9422449930135072\n",
      "test Acc 0.9329608938547486:\n",
      "27th- epoch: 89, train_loss = 25.38374439626932, train_acc = 0.9424778761061947\n",
      "test Acc 0.9329608938547486:\n",
      "27th- epoch: 90, train_loss = 25.26027052104473, train_acc = 0.9429436422915697\n",
      "test Acc 0.9329608938547486:\n",
      "27th- epoch: 91, train_loss = 25.13845808431506, train_acc = 0.9431765253842571\n",
      "test Acc 0.9338919925512105:\n",
      "27th- epoch: 92, train_loss = 25.01905159652233, train_acc = 0.9438751746623195\n",
      "test Acc 0.9338919925512105:\n",
      "27th- epoch: 93, train_loss = 24.901616517454386, train_acc = 0.9443409408476945\n",
      "test Acc 0.9338919925512105:\n",
      "27th- epoch: 94, train_loss = 24.786096535623074, train_acc = 0.9445738239403819\n",
      "test Acc 0.9348230912476723:\n",
      "27th- epoch: 95, train_loss = 24.673510044813156, train_acc = 0.9448067070330693\n",
      "test Acc 0.9348230912476723:\n",
      "27th- epoch: 96, train_loss = 24.56235371902585, train_acc = 0.9451560316721006\n",
      "test Acc 0.9348230912476723:\n",
      "27th- epoch: 97, train_loss = 24.45340684056282, train_acc = 0.9455053563111319\n",
      "test Acc 0.9352886405959032:\n",
      "27th- epoch: 98, train_loss = 24.34601279348135, train_acc = 0.9462040055891943\n",
      "test Acc 0.9352886405959032:\n",
      "27th- epoch: 99, train_loss = 24.240489281713963, train_acc = 0.9462040055891943\n",
      "test Acc 0.9352886405959032:\n",
      "27th- epoch: 100, train_loss = 24.13717219233513, train_acc = 0.946320447135538\n",
      "test Acc 0.9357541899441341:\n",
      "27th- epoch: 101, train_loss = 24.03524736687541, train_acc = 0.9464368886818817\n",
      "test Acc 0.9357541899441341:\n",
      "27th- epoch: 102, train_loss = 23.935102693736553, train_acc = 0.9466697717745691\n",
      "test Acc 0.9357541899441341:\n",
      "27th- epoch: 103, train_loss = 23.836750134825706, train_acc = 0.946786213320913\n",
      "test Acc 0.9357541899441341:\n",
      "27th- epoch: 104, train_loss = 23.74029529094696, train_acc = 0.946786213320913\n",
      "test Acc 0.9357541899441341:\n",
      "27th- epoch: 105, train_loss = 23.645081616938114, train_acc = 0.9469026548672567\n",
      "test Acc 0.9357541899441341:\n",
      "27th- epoch: 106, train_loss = 23.551329128444195, train_acc = 0.9472519795062878\n",
      "test Acc 0.9357541899441341:\n",
      "27th- epoch: 107, train_loss = 23.459722246974707, train_acc = 0.9473684210526315\n",
      "test Acc 0.9357541899441341:\n",
      "27th- epoch: 108, train_loss = 23.36908584088087, train_acc = 0.9477177456916628\n",
      "test Acc 0.9357541899441341:\n",
      "27th- epoch: 109, train_loss = 23.280177053064108, train_acc = 0.9478341872380065\n",
      "test Acc 0.936219739292365:\n",
      "27th- epoch: 110, train_loss = 23.192797150462866, train_acc = 0.9479506287843502\n",
      "test Acc 0.9371508379888268:\n",
      "27th- epoch: 111, train_loss = 23.106249321252108, train_acc = 0.9481835118770378\n",
      "test Acc 0.9371508379888268:\n",
      "27th- epoch: 112, train_loss = 23.02186805382371, train_acc = 0.9481835118770378\n",
      "test Acc 0.9371508379888268:\n",
      "27th- epoch: 113, train_loss = 22.938118405640125, train_acc = 0.9482999534233815\n",
      "test Acc 0.9380819366852886:\n",
      "27th- epoch: 114, train_loss = 22.85588389635086, train_acc = 0.9486492780624126\n",
      "test Acc 0.9380819366852886:\n",
      "27th- epoch: 115, train_loss = 22.77490818873048, train_acc = 0.9488821611551002\n",
      "test Acc 0.9380819366852886:\n",
      "27th- epoch: 116, train_loss = 22.694684702903032, train_acc = 0.9489986027014439\n",
      "test Acc 0.9380819366852886:\n",
      "27th- epoch: 117, train_loss = 22.615712944418192, train_acc = 0.9493479273404751\n",
      "test Acc 0.9380819366852886:\n",
      "27th- epoch: 118, train_loss = 22.53831199929118, train_acc = 0.9494643688868188\n",
      "test Acc 0.9380819366852886:\n",
      "27th- epoch: 119, train_loss = 22.461074993014336, train_acc = 0.9495808104331626\n",
      "test Acc 0.9380819366852886:\n",
      "27th- epoch: 120, train_loss = 22.385710775852203, train_acc = 0.94981369352585\n",
      "test Acc 0.9371508379888268:\n",
      "27th- epoch: 121, train_loss = 22.3108645118773, train_acc = 0.94981369352585\n",
      "test Acc 0.9371508379888268:\n",
      "27th- epoch: 122, train_loss = 22.237613324075937, train_acc = 0.94981369352585\n",
      "test Acc 0.9371508379888268:\n",
      "27th- epoch: 123, train_loss = 22.164298940449953, train_acc = 0.94981369352585\n",
      "test Acc 0.9371508379888268:\n",
      "27th- epoch: 124, train_loss = 22.092696949839592, train_acc = 0.94981369352585\n",
      "test Acc 0.9371508379888268:\n",
      "27th- epoch: 125, train_loss = 22.02178332954645, train_acc = 0.9499301350721937\n",
      "test Acc 0.9371508379888268:\n",
      "27th- epoch: 126, train_loss = 21.951144937425852, train_acc = 0.9499301350721937\n",
      "test Acc 0.9376163873370578:\n",
      "27th- epoch: 127, train_loss = 21.88153411075473, train_acc = 0.9500465766185375\n",
      "test Acc 0.9380819366852886:\n",
      "27th- epoch: 128, train_loss = 21.812534004449844, train_acc = 0.9501630181648812\n",
      "test Acc 0.9380819366852886:\n",
      "27th- epoch: 129, train_loss = 21.745010796934366, train_acc = 0.9501630181648812\n",
      "test Acc 0.9385474860335196:\n",
      "27th- epoch: 130, train_loss = 21.677646223455667, train_acc = 0.9501630181648812\n",
      "test Acc 0.9385474860335196:\n",
      "27th- epoch: 131, train_loss = 21.612358070909977, train_acc = 0.9503959012575687\n",
      "test Acc 0.9390130353817505:\n",
      "27th- epoch: 132, train_loss = 21.546915877610445, train_acc = 0.9507452258965999\n",
      "test Acc 0.9390130353817505:\n",
      "27th- epoch: 133, train_loss = 21.482295993715525, train_acc = 0.9508616674429436\n",
      "test Acc 0.9399441340782123:\n",
      "27th- epoch: 134, train_loss = 21.41881662234664, train_acc = 0.9512109920819748\n",
      "test Acc 0.9399441340782123:\n",
      "27th- epoch: 135, train_loss = 21.355770383030176, train_acc = 0.951560316721006\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 136, train_loss = 21.292790092527866, train_acc = 0.9517931998136935\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 137, train_loss = 21.230341002345085, train_acc = 0.9517931998136935\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 138, train_loss = 21.16833472624421, train_acc = 0.9519096413600373\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 139, train_loss = 21.108243223279715, train_acc = 0.9521425244527247\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 140, train_loss = 21.04875696450472, train_acc = 0.9522589659990685\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 141, train_loss = 20.989883989095688, train_acc = 0.9522589659990685\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 142, train_loss = 20.93108446151018, train_acc = 0.9522589659990685\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 143, train_loss = 20.87307096272707, train_acc = 0.9522589659990685\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 144, train_loss = 20.816532522439957, train_acc = 0.9523754075454122\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 145, train_loss = 20.759489495307207, train_acc = 0.9527247321844434\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 146, train_loss = 20.704021848738194, train_acc = 0.9527247321844434\n",
      "test Acc 0.9408752327746741:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 147, train_loss = 20.64774764329195, train_acc = 0.9530740568234746\n",
      "test Acc 0.9408752327746741:\n",
      "27th- epoch: 148, train_loss = 20.591882955282927, train_acc = 0.9530740568234746\n",
      "test Acc 0.9408752327746741:\n",
      "27th- epoch: 149, train_loss = 20.538229431957006, train_acc = 0.9533069399161621\n",
      "test Acc 0.9408752327746741:\n",
      "27th- epoch: 150, train_loss = 20.484198957681656, train_acc = 0.9533069399161621\n",
      "test Acc 0.9408752327746741:\n",
      "27th- epoch: 151, train_loss = 20.43079562857747, train_acc = 0.9534233814625058\n",
      "test Acc 0.9413407821229051:\n",
      "27th- epoch: 152, train_loss = 20.378000430762768, train_acc = 0.9535398230088495\n",
      "test Acc 0.9413407821229051:\n",
      "27th- epoch: 153, train_loss = 20.325832076370716, train_acc = 0.9536562645551933\n",
      "test Acc 0.9413407821229051:\n",
      "27th- epoch: 154, train_loss = 20.27360985800624, train_acc = 0.9537727061015371\n",
      "test Acc 0.9413407821229051:\n",
      "27th- epoch: 155, train_loss = 20.222942400723696, train_acc = 0.9540055891942245\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 156, train_loss = 20.17256955243647, train_acc = 0.9540055891942245\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 157, train_loss = 20.121953854337335, train_acc = 0.9540055891942245\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 158, train_loss = 20.07249720953405, train_acc = 0.9544713553795995\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 159, train_loss = 20.023845782503486, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 160, train_loss = 19.974469639360905, train_acc = 0.9549371215649743\n",
      "test Acc 0.9422718808193669:\n",
      "27th- epoch: 161, train_loss = 19.9250752273947, train_acc = 0.9550535631113182\n",
      "test Acc 0.9422718808193669:\n",
      "27th- epoch: 162, train_loss = 19.876269666478038, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "27th- epoch: 163, train_loss = 19.829274706542492, train_acc = 0.9554028877503493\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 164, train_loss = 19.78142865933478, train_acc = 0.9554028877503493\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 165, train_loss = 19.735468247905374, train_acc = 0.9552864462040056\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 166, train_loss = 19.689593290910125, train_acc = 0.9552864462040056\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 167, train_loss = 19.644009670242667, train_acc = 0.9552864462040056\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 168, train_loss = 19.598881857469678, train_acc = 0.9552864462040056\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 169, train_loss = 19.553928846493363, train_acc = 0.9554028877503493\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 170, train_loss = 19.50961411371827, train_acc = 0.9554028877503493\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 171, train_loss = 19.465403554961085, train_acc = 0.955519329296693\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 172, train_loss = 19.422512659803033, train_acc = 0.9558686539357243\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 173, train_loss = 19.37878100760281, train_acc = 0.9561015370284117\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 174, train_loss = 19.336099207401276, train_acc = 0.9562179785747554\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 175, train_loss = 19.293085800483823, train_acc = 0.9562179785747554\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 176, train_loss = 19.251211950555444, train_acc = 0.9562179785747554\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 177, train_loss = 19.209121050313115, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 178, train_loss = 19.168302660807967, train_acc = 0.9565673032137867\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 179, train_loss = 19.127435887232423, train_acc = 0.9565673032137867\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 180, train_loss = 19.08590615540743, train_acc = 0.9566837447601304\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 181, train_loss = 19.045711655169725, train_acc = 0.9566837447601304\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 182, train_loss = 19.00752739980817, train_acc = 0.9568001863064741\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 183, train_loss = 18.968024423345923, train_acc = 0.9569166278528178\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 184, train_loss = 18.928197521716356, train_acc = 0.9571495109455054\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 185, train_loss = 18.890653675422072, train_acc = 0.9571495109455054\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 186, train_loss = 18.851073132827878, train_acc = 0.9571495109455054\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 187, train_loss = 18.813344864174724, train_acc = 0.9572659524918491\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 188, train_loss = 18.776458848267794, train_acc = 0.9573823940381928\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 189, train_loss = 18.739463072270155, train_acc = 0.9574988355845365\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 190, train_loss = 18.701971903443336, train_acc = 0.9577317186772241\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 191, train_loss = 18.66518446430564, train_acc = 0.9578481602235678\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 192, train_loss = 18.62790697440505, train_acc = 0.9579646017699115\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 193, train_loss = 18.592722218483686, train_acc = 0.9579646017699115\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 194, train_loss = 18.557425757870078, train_acc = 0.9579646017699115\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 195, train_loss = 18.5213083922863, train_acc = 0.9579646017699115\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 196, train_loss = 18.48624192364514, train_acc = 0.9580810433162552\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 197, train_loss = 18.451176011934876, train_acc = 0.9580810433162552\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 198, train_loss = 18.416871946305037, train_acc = 0.9580810433162552\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 199, train_loss = 18.38383497670293, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 200, train_loss = 18.34980288334191, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 201, train_loss = 18.316875860095024, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 202, train_loss = 18.28312986716628, train_acc = 0.9585468095016302\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 203, train_loss = 18.249804640188813, train_acc = 0.9586632510479739\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 204, train_loss = 18.217671301215887, train_acc = 0.9590125756870052\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 205, train_loss = 18.185350514948368, train_acc = 0.9590125756870052\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 206, train_loss = 18.15204691514373, train_acc = 0.9590125756870052\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 207, train_loss = 18.120177682489157, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 208, train_loss = 18.089333539828658, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 209, train_loss = 18.05770025588572, train_acc = 0.9592454587796926\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 210, train_loss = 18.027100199833512, train_acc = 0.9593619003260363\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 211, train_loss = 17.9963657297194, train_acc = 0.9593619003260363\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 212, train_loss = 17.966347908601165, train_acc = 0.95947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 213, train_loss = 17.935864275321364, train_acc = 0.9595947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 214, train_loss = 17.90708787739277, train_acc = 0.9595947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 215, train_loss = 17.87646763585508, train_acc = 0.9595947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 216, train_loss = 17.84769173897803, train_acc = 0.9595947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 217, train_loss = 17.818685971200466, train_acc = 0.9595947834187238\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 218, train_loss = 17.78903054818511, train_acc = 0.9597112249650676\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 219, train_loss = 17.761524124071002, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 220, train_loss = 17.733616204932332, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 221, train_loss = 17.705523781478405, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 222, train_loss = 17.678644021973014, train_acc = 0.959944108057755\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 223, train_loss = 17.650369128212333, train_acc = 0.959944108057755\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 224, train_loss = 17.623482579365373, train_acc = 0.9600605496040987\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 225, train_loss = 17.59625772945583, train_acc = 0.9601769911504425\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 226, train_loss = 17.56954698264599, train_acc = 0.9601769911504425\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 227, train_loss = 17.542987851426005, train_acc = 0.9602934326967862\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 228, train_loss = 17.516975170001388, train_acc = 0.9602934326967862\n",
      "test Acc 0.9473929236499069:\n",
      "27th- epoch: 229, train_loss = 17.490470414981246, train_acc = 0.96040987424313\n",
      "test Acc 0.9473929236499069:\n",
      "27th- epoch: 230, train_loss = 17.46454735659063, train_acc = 0.9605263157894737\n",
      "test Acc 0.9483240223463687:\n",
      "27th- epoch: 231, train_loss = 17.43990700878203, train_acc = 0.9605263157894737\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 232, train_loss = 17.413731699809432, train_acc = 0.9607591988821611\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 233, train_loss = 17.389360485598445, train_acc = 0.9609920819748486\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 234, train_loss = 17.363468604162335, train_acc = 0.9609920819748486\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 235, train_loss = 17.339960215613246, train_acc = 0.9609920819748486\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 236, train_loss = 17.3140384927392, train_acc = 0.9609920819748486\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 237, train_loss = 17.288990603759885, train_acc = 0.9609920819748486\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 238, train_loss = 17.26529184728861, train_acc = 0.9609920819748486\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 239, train_loss = 17.24205287732184, train_acc = 0.9613414066138798\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 240, train_loss = 17.217833129689097, train_acc = 0.9613414066138798\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 241, train_loss = 17.19330153800547, train_acc = 0.9613414066138798\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 242, train_loss = 17.169177308678627, train_acc = 0.9613414066138798\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 243, train_loss = 17.146791433915496, train_acc = 0.9613414066138798\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 244, train_loss = 17.122566618025303, train_acc = 0.9613414066138798\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 245, train_loss = 17.100357176735997, train_acc = 0.9614578481602236\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 246, train_loss = 17.077013252303004, train_acc = 0.9614578481602236\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 247, train_loss = 17.055117279291153, train_acc = 0.9614578481602236\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 248, train_loss = 17.03126378543675, train_acc = 0.961690731252911\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 249, train_loss = 17.01017260365188, train_acc = 0.9618071727992548\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 250, train_loss = 16.98793882317841, train_acc = 0.9620400558919422\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 251, train_loss = 16.96590968593955, train_acc = 0.962156497438286\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 252, train_loss = 16.94433240033686, train_acc = 0.962156497438286\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 253, train_loss = 16.92203995678574, train_acc = 0.962156497438286\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 254, train_loss = 16.90087150130421, train_acc = 0.9623893805309734\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 255, train_loss = 16.88107110839337, train_acc = 0.9625058220773172\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 256, train_loss = 16.8591528525576, train_acc = 0.9625058220773172\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 257, train_loss = 16.83751733507961, train_acc = 0.9625058220773172\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 258, train_loss = 16.816916870884597, train_acc = 0.9625058220773172\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 259, train_loss = 16.796586233191192, train_acc = 0.9625058220773172\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 260, train_loss = 16.775722515769303, train_acc = 0.9625058220773172\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 261, train_loss = 16.755289406515658, train_acc = 0.9625058220773172\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 262, train_loss = 16.735505464486778, train_acc = 0.9625058220773172\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 263, train_loss = 16.714919790625572, train_acc = 0.9625058220773172\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 264, train_loss = 16.6953087747097, train_acc = 0.9625058220773172\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 265, train_loss = 16.67598354909569, train_acc = 0.9625058220773172\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 266, train_loss = 16.65534157771617, train_acc = 0.9626222636236609\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 267, train_loss = 16.6366496225819, train_acc = 0.9626222636236609\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 268, train_loss = 16.61584437545389, train_acc = 0.9626222636236609\n",
      "test Acc 0.9487895716945997:\n",
      "27th- epoch: 269, train_loss = 16.597932621836662, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 270, train_loss = 16.579085945151746, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 271, train_loss = 16.55876935366541, train_acc = 0.9628551467163484\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 272, train_loss = 16.541238916106522, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 273, train_loss = 16.522351660765707, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 274, train_loss = 16.5044515626505, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 275, train_loss = 16.48465632647276, train_acc = 0.9630880298090359\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 276, train_loss = 16.467250647954643, train_acc = 0.9630880298090359\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 277, train_loss = 16.448979842476547, train_acc = 0.9634373544480671\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 278, train_loss = 16.431754254736006, train_acc = 0.9634373544480671\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 279, train_loss = 16.412918177433312, train_acc = 0.9635537959944108\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 280, train_loss = 16.39506895467639, train_acc = 0.9636702375407545\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 281, train_loss = 16.376160408370197, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 282, train_loss = 16.35865827370435, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 283, train_loss = 16.342777925543487, train_acc = 0.963903120633442\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 284, train_loss = 16.324463098309934, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 285, train_loss = 16.30691040214151, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 286, train_loss = 16.290544766001403, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 287, train_loss = 16.272241580300033, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 288, train_loss = 16.25692538637668, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 289, train_loss = 16.238357287831604, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 290, train_loss = 16.22368739452213, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 291, train_loss = 16.20611155871302, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 292, train_loss = 16.188139081932604, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 293, train_loss = 16.172953746281564, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 294, train_loss = 16.15702807251364, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 295, train_loss = 16.141523045487702, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 296, train_loss = 16.12507316377014, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 297, train_loss = 16.10927447024733, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 298, train_loss = 16.09337594360113, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 299, train_loss = 16.07774603087455, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 300, train_loss = 16.062743444927037, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 301, train_loss = 16.046616916544735, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 302, train_loss = 16.031107276678085, train_acc = 0.9642524452724732\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 303, train_loss = 16.017077025957406, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 304, train_loss = 16.001688729971647, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 305, train_loss = 15.986291109584272, train_acc = 0.9643688868188169\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 306, train_loss = 15.97107757255435, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 307, train_loss = 15.956512262113392, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 308, train_loss = 15.940976991318166, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 309, train_loss = 15.92738790716976, train_acc = 0.9644853283651607\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 310, train_loss = 15.911380457691848, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 311, train_loss = 15.897914408706129, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 312, train_loss = 15.882590590976179, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 313, train_loss = 15.868211069144309, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 314, train_loss = 15.854097362607718, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 315, train_loss = 15.841879036277533, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 316, train_loss = 15.825599607080221, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 317, train_loss = 15.811927434056997, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 318, train_loss = 15.798403958790004, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 319, train_loss = 15.783666470088065, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 320, train_loss = 15.770316270180047, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 321, train_loss = 15.755968612618744, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 322, train_loss = 15.743650996126235, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 323, train_loss = 15.730012544430792, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 324, train_loss = 15.715851594693959, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 325, train_loss = 15.701615761965513, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 326, train_loss = 15.687176479957998, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 327, train_loss = 15.674917188473046, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 328, train_loss = 15.659912556409836, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 329, train_loss = 15.646809478290379, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 330, train_loss = 15.63450504746288, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 331, train_loss = 15.62312622833997, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 332, train_loss = 15.607991439290345, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 333, train_loss = 15.59513356629759, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 334, train_loss = 15.582632388919592, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 335, train_loss = 15.570361827500165, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 336, train_loss = 15.55748700723052, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 337, train_loss = 15.544206508435309, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 338, train_loss = 15.532524433918297, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 339, train_loss = 15.519431707449257, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 340, train_loss = 15.508710451424122, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 341, train_loss = 15.49535958841443, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 342, train_loss = 15.483090310357511, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 343, train_loss = 15.471460622735322, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 344, train_loss = 15.459754668176174, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 345, train_loss = 15.445688067935407, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 346, train_loss = 15.434338554739952, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 347, train_loss = 15.423518811352551, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 348, train_loss = 15.411074875853956, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 349, train_loss = 15.400924358516932, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 350, train_loss = 15.388570758514106, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 351, train_loss = 15.37574986089021, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 352, train_loss = 15.363124837167561, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 353, train_loss = 15.35338919609785, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 354, train_loss = 15.34306466486305, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 355, train_loss = 15.330587119795382, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 356, train_loss = 15.320308517664671, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 357, train_loss = 15.307358809746802, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 358, train_loss = 15.29783071950078, train_acc = 0.9653004191895669\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 359, train_loss = 15.287237224169075, train_acc = 0.9654168607359106\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 360, train_loss = 15.275362781248987, train_acc = 0.9654168607359106\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 361, train_loss = 15.264403656125069, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 362, train_loss = 15.252945747226477, train_acc = 0.9655333022822543\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 363, train_loss = 15.241769708693027, train_acc = 0.965649743828598\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 364, train_loss = 15.230848725885153, train_acc = 0.965649743828598\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 365, train_loss = 15.22051127627492, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 366, train_loss = 15.209936142899096, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 367, train_loss = 15.197695839218795, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 368, train_loss = 15.189024322666228, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 369, train_loss = 15.177562020719051, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 370, train_loss = 15.167548063211143, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 371, train_loss = 15.156232575885952, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 372, train_loss = 15.14580772165209, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 373, train_loss = 15.13642751146108, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 374, train_loss = 15.12605619430542, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 375, train_loss = 15.115921903401613, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 376, train_loss = 15.105438715778291, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 377, train_loss = 15.09585328027606, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 378, train_loss = 15.084757581353188, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 379, train_loss = 15.07526230905205, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 380, train_loss = 15.06396909058094, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 381, train_loss = 15.05511884111911, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 382, train_loss = 15.045291856862605, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 383, train_loss = 15.035902693867683, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 384, train_loss = 15.024942256510258, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 385, train_loss = 15.017856133170426, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 386, train_loss = 15.006755623966455, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 387, train_loss = 14.995552469976246, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 388, train_loss = 14.987691085785627, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 389, train_loss = 14.977792668156326, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 390, train_loss = 14.967900800518692, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 391, train_loss = 14.958412081934512, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 392, train_loss = 14.948112414218485, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 393, train_loss = 14.939836678095162, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 394, train_loss = 14.930405884049833, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 395, train_loss = 14.920795950107276, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 396, train_loss = 14.912245716899633, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 397, train_loss = 14.902169328182936, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 398, train_loss = 14.892747485078871, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 399, train_loss = 14.884784989990294, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 400, train_loss = 14.874833236448467, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 401, train_loss = 14.86691281478852, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 402, train_loss = 14.857298091985285, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 403, train_loss = 14.848538991063833, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 404, train_loss = 14.841762670315802, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 405, train_loss = 14.831050008535385, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 406, train_loss = 14.823083237744868, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 407, train_loss = 14.813926793634892, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 408, train_loss = 14.805011618882418, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 409, train_loss = 14.79491367843002, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 410, train_loss = 14.787380936555564, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 411, train_loss = 14.778147337026894, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 412, train_loss = 14.769256670959294, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 413, train_loss = 14.76091064978391, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 414, train_loss = 14.753980878740549, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 415, train_loss = 14.744078441523015, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 416, train_loss = 14.73568665329367, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 417, train_loss = 14.728291674517095, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 418, train_loss = 14.719308980740607, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 419, train_loss = 14.711242792196572, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 420, train_loss = 14.701291769742966, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 421, train_loss = 14.695097022689879, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 422, train_loss = 14.687453436665237, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 423, train_loss = 14.678858424536884, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 424, train_loss = 14.669781766831875, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 425, train_loss = 14.66103760804981, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 426, train_loss = 14.653536614961922, train_acc = 0.9668141592920354\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 427, train_loss = 14.64477301388979, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 428, train_loss = 14.637201006524265, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 429, train_loss = 14.628730699419975, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 430, train_loss = 14.621093690395355, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 431, train_loss = 14.613072581589222, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 432, train_loss = 14.605908102355897, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 433, train_loss = 14.596881046891212, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 434, train_loss = 14.588672862388194, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 435, train_loss = 14.582248330116272, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 436, train_loss = 14.575127775780857, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 437, train_loss = 14.567309780977666, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 438, train_loss = 14.558940228074789, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 439, train_loss = 14.550232307054102, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 440, train_loss = 14.542745714075863, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 441, train_loss = 14.53624180238694, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 442, train_loss = 14.52830483391881, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 443, train_loss = 14.52154615148902, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 444, train_loss = 14.514056249056011, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 445, train_loss = 14.50592327490449, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 446, train_loss = 14.499129717703909, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 447, train_loss = 14.490452012512833, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 448, train_loss = 14.485478356480598, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 449, train_loss = 14.477410396095365, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 450, train_loss = 14.469008432235569, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 451, train_loss = 14.463225380983204, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 452, train_loss = 14.45474203536287, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 453, train_loss = 14.447868561837822, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 454, train_loss = 14.442062535788864, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 455, train_loss = 14.433843705803156, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 456, train_loss = 14.428634647279978, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 457, train_loss = 14.420954031404108, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 458, train_loss = 14.414204047527164, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 459, train_loss = 14.407145829405636, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 460, train_loss = 14.399931944906712, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 461, train_loss = 14.393530866596848, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 462, train_loss = 14.384938170667738, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 463, train_loss = 14.379036027938128, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 464, train_loss = 14.372900577727705, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 465, train_loss = 14.365739531815052, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 466, train_loss = 14.360474020242691, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 467, train_loss = 14.352651674300432, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 468, train_loss = 14.34438811475411, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 469, train_loss = 14.338344430085272, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 470, train_loss = 14.333237949758768, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 471, train_loss = 14.326934549957514, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 472, train_loss = 14.320060133934021, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 473, train_loss = 14.312347332481295, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 474, train_loss = 14.307065673172474, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 475, train_loss = 14.300406757742167, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 476, train_loss = 14.293522644788027, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 477, train_loss = 14.288383224513382, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 478, train_loss = 14.280995806213468, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 479, train_loss = 14.274409785866737, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 480, train_loss = 14.268266019877046, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 481, train_loss = 14.262085132300854, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 482, train_loss = 14.256213080137968, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 483, train_loss = 14.248068364802748, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 484, train_loss = 14.24331453954801, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 485, train_loss = 14.237430269364268, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 486, train_loss = 14.23075088346377, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 487, train_loss = 14.22484041005373, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 488, train_loss = 14.219282444566488, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 489, train_loss = 14.214072653558105, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 490, train_loss = 14.207321232650429, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 491, train_loss = 14.200185814406723, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 492, train_loss = 14.193516377359629, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 493, train_loss = 14.188517430331558, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 494, train_loss = 14.181407557334751, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 495, train_loss = 14.17685546213761, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 496, train_loss = 14.170447605196387, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 497, train_loss = 14.16486556455493, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 498, train_loss = 14.1602520220913, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "27th- epoch: 499, train_loss = 14.153305219020694, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████▊       | 27/30 [2:59:37<19:58, 399.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "28th- epoch: 0, train_loss = 274.7389233112335, train_acc = 0.435724266418258\n",
      "test Acc 0.49813780260707635:\n",
      "28th- epoch: 1, train_loss = 214.18860626220703, train_acc = 0.5005822077317187\n",
      "test Acc 0.5:\n",
      "28th- epoch: 2, train_loss = 179.93782317638397, train_acc = 0.5032603632976246\n",
      "test Acc 0.5093109869646183:\n",
      "28th- epoch: 3, train_loss = 163.3326325416565, train_acc = 0.5326036329762459\n",
      "test Acc 0.5661080074487895:\n",
      "28th- epoch: 4, train_loss = 150.78110390901566, train_acc = 0.5854680950163018\n",
      "test Acc 0.6135940409683427:\n",
      "28th- epoch: 5, train_loss = 139.49111622571945, train_acc = 0.6195854680950164\n",
      "test Acc 0.6359404096834265:\n",
      "28th- epoch: 6, train_loss = 129.0281280875206, train_acc = 0.637750349324639\n",
      "test Acc 0.648975791433892:\n",
      "28th- epoch: 7, train_loss = 119.38698869943619, train_acc = 0.6717512808570097\n",
      "test Acc 0.75:\n",
      "28th- epoch: 8, train_loss = 110.5218710899353, train_acc = 0.7503493246390313\n",
      "test Acc 0.7774674115456238:\n",
      "28th- epoch: 9, train_loss = 102.36892795562744, train_acc = 0.7824871914299022\n",
      "test Acc 0.7984171322160148:\n",
      "28th- epoch: 10, train_loss = 94.89287775754929, train_acc = 0.8100838379133675\n",
      "test Acc 0.8198324022346368:\n",
      "28th- epoch: 11, train_loss = 88.15836718678474, train_acc = 0.8220773171867722\n",
      "test Acc 0.8272811918063314:\n",
      "28th- epoch: 12, train_loss = 82.1590011715889, train_acc = 0.8305775500698649\n",
      "test Acc 0.8421787709497207:\n",
      "28th- epoch: 13, train_loss = 76.8632718026638, train_acc = 0.8425710293432697\n",
      "test Acc 0.8533519553072626:\n",
      "28th- epoch: 14, train_loss = 72.21005147695541, train_acc = 0.8540987424312995\n",
      "test Acc 0.8580074487895717:\n",
      "28th- epoch: 15, train_loss = 68.14323383569717, train_acc = 0.8625989753143922\n",
      "test Acc 0.8663873370577281:\n",
      "28th- epoch: 16, train_loss = 64.58596688508987, train_acc = 0.8656264555193293\n",
      "test Acc 0.8719739292364991:\n",
      "28th- epoch: 17, train_loss = 61.47613659501076, train_acc = 0.8717978574755473\n",
      "test Acc 0.87756052141527:\n",
      "28th- epoch: 18, train_loss = 58.74592614173889, train_acc = 0.8768048439683279\n",
      "test Acc 0.88268156424581:\n",
      "28th- epoch: 19, train_loss = 56.35025332868099, train_acc = 0.8790172333488588\n",
      "test Acc 0.8873370577281192:\n",
      "28th- epoch: 20, train_loss = 54.23079811036587, train_acc = 0.8833255705635771\n",
      "test Acc 0.8915270018621974:\n",
      "28th- epoch: 21, train_loss = 52.356856659054756, train_acc = 0.8900791802515138\n",
      "test Acc 0.8961824953445066:\n",
      "28th- epoch: 22, train_loss = 50.690409019589424, train_acc = 0.8940381928272008\n",
      "test Acc 0.8999068901303539:\n",
      "28th- epoch: 23, train_loss = 49.19785022735596, train_acc = 0.8963670237540755\n",
      "test Acc 0.9003724394785847:\n",
      "28th- epoch: 24, train_loss = 47.85215191543102, train_acc = 0.8974149976711691\n",
      "test Acc 0.9017690875232774:\n",
      "28th- epoch: 25, train_loss = 46.63596360385418, train_acc = 0.8982300884955752\n",
      "test Acc 0.9036312849162011:\n",
      "28th- epoch: 26, train_loss = 45.52855667471886, train_acc = 0.8997438285980438\n",
      "test Acc 0.9050279329608939:\n",
      "28th- epoch: 27, train_loss = 44.513764411211014, train_acc = 0.9020726595249184\n",
      "test Acc 0.9059590316573557:\n",
      "28th- epoch: 28, train_loss = 43.58199551701546, train_acc = 0.9034699580810434\n",
      "test Acc 0.9073556797020484:\n",
      "28th- epoch: 29, train_loss = 42.72164948284626, train_acc = 0.9055659059152306\n",
      "test Acc 0.9078212290502793:\n",
      "28th- epoch: 30, train_loss = 41.92334121465683, train_acc = 0.9074289706567303\n",
      "test Acc 0.909217877094972:\n",
      "28th- epoch: 31, train_loss = 41.17912332713604, train_acc = 0.9091755938518864\n",
      "test Acc 0.9087523277467412:\n",
      "28th- epoch: 32, train_loss = 40.48324526846409, train_acc = 0.9120866325104797\n",
      "test Acc 0.9106145251396648:\n",
      "28th- epoch: 33, train_loss = 39.83000913262367, train_acc = 0.9132510479739171\n",
      "test Acc 0.9129422718808193:\n",
      "28th- epoch: 34, train_loss = 39.21406243741512, train_acc = 0.9156963204471356\n",
      "test Acc 0.9138733705772812:\n",
      "28th- epoch: 35, train_loss = 38.63201378285885, train_acc = 0.9168607359105729\n",
      "test Acc 0.9138733705772812:\n",
      "28th- epoch: 36, train_loss = 38.081734016537666, train_acc = 0.9186073591057289\n",
      "test Acc 0.9166666666666666:\n",
      "28th- epoch: 37, train_loss = 37.559370934963226, train_acc = 0.9196553330228225\n",
      "test Acc 0.9171322160148976:\n",
      "28th- epoch: 38, train_loss = 37.062688902020454, train_acc = 0.9209361900326036\n",
      "test Acc 0.9185288640595903:\n",
      "28th- epoch: 39, train_loss = 36.591076612472534, train_acc = 0.9217512808570097\n",
      "test Acc 0.9185288640595903:\n",
      "28th- epoch: 40, train_loss = 36.14160892367363, train_acc = 0.9227992547741034\n",
      "test Acc 0.9189944134078212:\n",
      "28th- epoch: 41, train_loss = 35.713781125843525, train_acc = 0.9234979040521658\n",
      "test Acc 0.9194599627560521:\n",
      "28th- epoch: 42, train_loss = 35.30489521473646, train_acc = 0.9238472286911971\n",
      "test Acc 0.9199255121042831:\n",
      "28th- epoch: 43, train_loss = 34.91282180696726, train_acc = 0.9246623195156032\n",
      "test Acc 0.9208566108007449:\n",
      "28th- epoch: 44, train_loss = 34.53706866502762, train_acc = 0.9251280857009782\n",
      "test Acc 0.9217877094972067:\n",
      "28th- epoch: 45, train_loss = 34.17618151754141, train_acc = 0.9259431765253843\n",
      "test Acc 0.9222532588454376:\n",
      "28th- epoch: 46, train_loss = 33.82918629050255, train_acc = 0.9269911504424779\n",
      "test Acc 0.9236499068901304:\n",
      "28th- epoch: 47, train_loss = 33.494312793016434, train_acc = 0.9283884489986027\n",
      "test Acc 0.9241154562383612:\n",
      "28th- epoch: 48, train_loss = 33.17167626321316, train_acc = 0.9287377736376339\n",
      "test Acc 0.9241154562383612:\n",
      "28th- epoch: 49, train_loss = 32.86035884171724, train_acc = 0.9292035398230089\n",
      "test Acc 0.9250465549348231:\n",
      "28th- epoch: 50, train_loss = 32.55947536230087, train_acc = 0.9294364229156963\n",
      "test Acc 0.925512104283054:\n",
      "28th- epoch: 51, train_loss = 32.26713491231203, train_acc = 0.9301350721937587\n",
      "test Acc 0.9264432029795159:\n",
      "28th- epoch: 52, train_loss = 31.983537025749683, train_acc = 0.9306008383791337\n",
      "test Acc 0.9264432029795159:\n",
      "28th- epoch: 53, train_loss = 31.70836379379034, train_acc = 0.9309501630181649\n",
      "test Acc 0.9264432029795159:\n",
      "28th- epoch: 54, train_loss = 31.442075185477734, train_acc = 0.9311830461108523\n",
      "test Acc 0.9269087523277467:\n",
      "28th- epoch: 55, train_loss = 31.18333362787962, train_acc = 0.9315323707498836\n",
      "test Acc 0.9269087523277467:\n",
      "28th- epoch: 56, train_loss = 30.932056918740273, train_acc = 0.931765253842571\n",
      "test Acc 0.9269087523277467:\n",
      "28th- epoch: 57, train_loss = 30.687698878347874, train_acc = 0.9321145784816023\n",
      "test Acc 0.9278398510242085:\n",
      "28th- epoch: 58, train_loss = 30.450242079794407, train_acc = 0.9323474615742897\n",
      "test Acc 0.9278398510242085:\n",
      "28th- epoch: 59, train_loss = 30.218368254601955, train_acc = 0.9329296693060084\n",
      "test Acc 0.9278398510242085:\n",
      "28th- epoch: 60, train_loss = 29.99195473641157, train_acc = 0.9332789939450395\n",
      "test Acc 0.9278398510242085:\n",
      "28th- epoch: 61, train_loss = 29.772151947021484, train_acc = 0.9338612016767582\n",
      "test Acc 0.9278398510242085:\n",
      "28th- epoch: 62, train_loss = 29.55778568983078, train_acc = 0.9342105263157895\n",
      "test Acc 0.9283054003724395:\n",
      "28th- epoch: 63, train_loss = 29.34796192497015, train_acc = 0.9344434094084769\n",
      "test Acc 0.9278398510242085:\n",
      "28th- epoch: 64, train_loss = 29.143609181046486, train_acc = 0.9350256171401956\n",
      "test Acc 0.9283054003724395:\n",
      "28th- epoch: 65, train_loss = 28.943720944225788, train_acc = 0.9354913833255706\n",
      "test Acc 0.9283054003724395:\n",
      "28th- epoch: 66, train_loss = 28.748636484146118, train_acc = 0.9359571495109456\n",
      "test Acc 0.9278398510242085:\n",
      "28th- epoch: 67, train_loss = 28.558102913200855, train_acc = 0.9363064741499767\n",
      "test Acc 0.9283054003724395:\n",
      "28th- epoch: 68, train_loss = 28.37181567400694, train_acc = 0.9367722403353517\n",
      "test Acc 0.9283054003724395:\n",
      "28th- epoch: 69, train_loss = 28.188895046710968, train_acc = 0.9368886818816954\n",
      "test Acc 0.9283054003724395:\n",
      "28th- epoch: 70, train_loss = 28.01046860963106, train_acc = 0.9371215649743828\n",
      "test Acc 0.9287709497206704:\n",
      "28th- epoch: 71, train_loss = 27.834739729762077, train_acc = 0.9374708896134141\n",
      "test Acc 0.9287709497206704:\n",
      "28th- epoch: 72, train_loss = 27.663114868104458, train_acc = 0.9378202142524453\n",
      "test Acc 0.9287709497206704:\n",
      "28th- epoch: 73, train_loss = 27.494724921882153, train_acc = 0.9381695388914765\n",
      "test Acc 0.9292364990689013:\n",
      "28th- epoch: 74, train_loss = 27.329774029552937, train_acc = 0.9388681881695389\n",
      "test Acc 0.9301675977653632:\n",
      "28th- epoch: 75, train_loss = 27.168142840266228, train_acc = 0.9388681881695389\n",
      "test Acc 0.930633147113594:\n",
      "28th- epoch: 76, train_loss = 27.00927872955799, train_acc = 0.9391010712622264\n",
      "test Acc 0.930633147113594:\n",
      "28th- epoch: 77, train_loss = 26.85338194668293, train_acc = 0.9397997205402888\n",
      "test Acc 0.931098696461825:\n",
      "28th- epoch: 78, train_loss = 26.700277253985405, train_acc = 0.9400326036329762\n",
      "test Acc 0.9320297951582868:\n",
      "28th- epoch: 79, train_loss = 26.54975938051939, train_acc = 0.9402654867256637\n",
      "test Acc 0.9320297951582868:\n",
      "28th- epoch: 80, train_loss = 26.40154229849577, train_acc = 0.9403819282720075\n",
      "test Acc 0.9320297951582868:\n",
      "28th- epoch: 81, train_loss = 26.25586999952793, train_acc = 0.9413134606427573\n",
      "test Acc 0.9320297951582868:\n",
      "28th- epoch: 82, train_loss = 26.113294046372175, train_acc = 0.9415463437354448\n",
      "test Acc 0.9320297951582868:\n",
      "28th- epoch: 83, train_loss = 25.97263915464282, train_acc = 0.9417792268281323\n",
      "test Acc 0.9320297951582868:\n",
      "28th- epoch: 84, train_loss = 25.834872018545866, train_acc = 0.9424778761061947\n",
      "test Acc 0.9320297951582868:\n",
      "28th- epoch: 85, train_loss = 25.699056185781956, train_acc = 0.9430600838379134\n",
      "test Acc 0.9320297951582868:\n",
      "28th- epoch: 86, train_loss = 25.56630140170455, train_acc = 0.9430600838379134\n",
      "test Acc 0.9324953445065177:\n",
      "28th- epoch: 87, train_loss = 25.43451113253832, train_acc = 0.9435258500232883\n",
      "test Acc 0.9324953445065177:\n",
      "28th- epoch: 88, train_loss = 25.30585863441229, train_acc = 0.9436422915696321\n",
      "test Acc 0.9324953445065177:\n",
      "28th- epoch: 89, train_loss = 25.179228730499744, train_acc = 0.9437587331159758\n",
      "test Acc 0.9324953445065177:\n",
      "28th- epoch: 90, train_loss = 25.054935846477747, train_acc = 0.9439916162086632\n",
      "test Acc 0.9324953445065177:\n",
      "28th- epoch: 91, train_loss = 24.9334557056427, train_acc = 0.944108057755007\n",
      "test Acc 0.9324953445065177:\n",
      "28th- epoch: 92, train_loss = 24.81312756240368, train_acc = 0.9445738239403819\n",
      "test Acc 0.9334264432029795:\n",
      "28th- epoch: 93, train_loss = 24.69539814069867, train_acc = 0.9446902654867256\n",
      "test Acc 0.9338919925512105:\n",
      "28th- epoch: 94, train_loss = 24.580266498029232, train_acc = 0.9450395901257569\n",
      "test Acc 0.9343575418994413:\n",
      "28th- epoch: 95, train_loss = 24.467017356306314, train_acc = 0.9455053563111319\n",
      "test Acc 0.9343575418994413:\n",
      "28th- epoch: 96, train_loss = 24.35510951280594, train_acc = 0.9459711224965067\n",
      "test Acc 0.9343575418994413:\n",
      "28th- epoch: 97, train_loss = 24.245799031108618, train_acc = 0.9462040055891943\n",
      "test Acc 0.9343575418994413:\n",
      "28th- epoch: 98, train_loss = 24.138990573585033, train_acc = 0.9465533302282254\n",
      "test Acc 0.9343575418994413:\n",
      "28th- epoch: 99, train_loss = 24.032521814107895, train_acc = 0.9466697717745691\n",
      "test Acc 0.9343575418994413:\n",
      "28th- epoch: 100, train_loss = 23.928742863237858, train_acc = 0.9469026548672567\n",
      "test Acc 0.9348230912476723:\n",
      "28th- epoch: 101, train_loss = 23.826891724020243, train_acc = 0.9471355379599441\n",
      "test Acc 0.9352886405959032:\n",
      "28th- epoch: 102, train_loss = 23.726146556437016, train_acc = 0.9472519795062878\n",
      "test Acc 0.9357541899441341:\n",
      "28th- epoch: 103, train_loss = 23.62704312428832, train_acc = 0.9473684210526315\n",
      "test Acc 0.9357541899441341:\n",
      "28th- epoch: 104, train_loss = 23.528912000358105, train_acc = 0.9474848625989754\n",
      "test Acc 0.9357541899441341:\n",
      "28th- epoch: 105, train_loss = 23.43326736614108, train_acc = 0.9477177456916628\n",
      "test Acc 0.936219739292365:\n",
      "28th- epoch: 106, train_loss = 23.339378464967012, train_acc = 0.948067070330694\n",
      "test Acc 0.936219739292365:\n",
      "28th- epoch: 107, train_loss = 23.246459901332855, train_acc = 0.948067070330694\n",
      "test Acc 0.9366852886405959:\n",
      "28th- epoch: 108, train_loss = 23.155760645866394, train_acc = 0.9484163949697252\n",
      "test Acc 0.9366852886405959:\n",
      "28th- epoch: 109, train_loss = 23.065299410372972, train_acc = 0.9488821611551002\n",
      "test Acc 0.9366852886405959:\n",
      "28th- epoch: 110, train_loss = 22.976998649537563, train_acc = 0.9488821611551002\n",
      "test Acc 0.9376163873370578:\n",
      "28th- epoch: 111, train_loss = 22.889679461717606, train_acc = 0.9489986027014439\n",
      "test Acc 0.9385474860335196:\n",
      "28th- epoch: 112, train_loss = 22.80439494550228, train_acc = 0.9492314857941313\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 113, train_loss = 22.719268031418324, train_acc = 0.9494643688868188\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 114, train_loss = 22.63588086143136, train_acc = 0.94981369352585\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 115, train_loss = 22.553693249821663, train_acc = 0.94981369352585\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 116, train_loss = 22.471717540174723, train_acc = 0.9499301350721937\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 117, train_loss = 22.392646174877882, train_acc = 0.9499301350721937\n",
      "test Acc 0.9399441340782123:\n",
      "28th- epoch: 118, train_loss = 22.314094554632902, train_acc = 0.9499301350721937\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 119, train_loss = 22.235714379698038, train_acc = 0.9500465766185375\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 120, train_loss = 22.159123223274946, train_acc = 0.9501630181648812\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 121, train_loss = 22.084323067218065, train_acc = 0.950279459711225\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 122, train_loss = 22.009576838463545, train_acc = 0.950279459711225\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 123, train_loss = 21.936540134251118, train_acc = 0.950279459711225\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 124, train_loss = 21.86373485252261, train_acc = 0.9503959012575687\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 125, train_loss = 21.792155627161264, train_acc = 0.9507452258965999\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 126, train_loss = 21.72318745031953, train_acc = 0.9507452258965999\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 127, train_loss = 21.652088459581137, train_acc = 0.9510945505356311\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 128, train_loss = 21.583667770028114, train_acc = 0.9516767582673498\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 129, train_loss = 21.516594104468822, train_acc = 0.9516767582673498\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 130, train_loss = 21.449212960898876, train_acc = 0.951560316721006\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 131, train_loss = 21.382958944886923, train_acc = 0.9517931998136935\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 132, train_loss = 21.31807366013527, train_acc = 0.952026082906381\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 133, train_loss = 21.25313113629818, train_acc = 0.9521425244527247\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 134, train_loss = 21.190150674432516, train_acc = 0.952491849091756\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 135, train_loss = 21.12729785963893, train_acc = 0.9528411737307871\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 136, train_loss = 21.065131705254316, train_acc = 0.9529576152771309\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 137, train_loss = 21.003485292196274, train_acc = 0.9531904983698184\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 138, train_loss = 20.943347841501236, train_acc = 0.9533069399161621\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 139, train_loss = 20.883837580680847, train_acc = 0.9535398230088495\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 140, train_loss = 20.824339874088764, train_acc = 0.9536562645551933\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 141, train_loss = 20.765949748456478, train_acc = 0.9536562645551933\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 142, train_loss = 20.708999574184418, train_acc = 0.9537727061015371\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 143, train_loss = 20.651184108108282, train_acc = 0.9537727061015371\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 144, train_loss = 20.595536917448044, train_acc = 0.9537727061015371\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 145, train_loss = 20.539422068744898, train_acc = 0.9538891476478808\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 146, train_loss = 20.48439810797572, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 147, train_loss = 20.430581353604794, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 148, train_loss = 20.37741144001484, train_acc = 0.9541220307405682\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 149, train_loss = 20.32351402565837, train_acc = 0.9544713553795995\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 150, train_loss = 20.27111379429698, train_acc = 0.9545877969259432\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 151, train_loss = 20.219020806252956, train_acc = 0.9545877969259432\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 152, train_loss = 20.166735101491213, train_acc = 0.9544713553795995\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 153, train_loss = 20.11665429919958, train_acc = 0.9545877969259432\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 154, train_loss = 20.06674599274993, train_acc = 0.9549371215649743\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 155, train_loss = 20.015550326555967, train_acc = 0.9552864462040056\n",
      "test Acc 0.9408752327746741:\n",
      "28th- epoch: 156, train_loss = 19.96717069298029, train_acc = 0.9554028877503493\n",
      "test Acc 0.9413407821229051:\n",
      "28th- epoch: 157, train_loss = 19.918168175965548, train_acc = 0.9554028877503493\n",
      "test Acc 0.9413407821229051:\n",
      "28th- epoch: 158, train_loss = 19.870095930993557, train_acc = 0.9554028877503493\n",
      "test Acc 0.9413407821229051:\n",
      "28th- epoch: 159, train_loss = 19.82261698320508, train_acc = 0.9554028877503493\n",
      "test Acc 0.9418063314711359:\n",
      "28th- epoch: 160, train_loss = 19.774715825915337, train_acc = 0.9554028877503493\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 161, train_loss = 19.728745533153415, train_acc = 0.955519329296693\n",
      "test Acc 0.9427374301675978:\n",
      "28th- epoch: 162, train_loss = 19.68298002332449, train_acc = 0.9557522123893806\n",
      "test Acc 0.9427374301675978:\n",
      "28th- epoch: 163, train_loss = 19.63677152991295, train_acc = 0.9557522123893806\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 164, train_loss = 19.591498175635934, train_acc = 0.9558686539357243\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 165, train_loss = 19.54568206332624, train_acc = 0.9558686539357243\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 166, train_loss = 19.501427695155144, train_acc = 0.9558686539357243\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 167, train_loss = 19.457855058833957, train_acc = 0.955985095482068\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 168, train_loss = 19.414446594193578, train_acc = 0.9562179785747554\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 169, train_loss = 19.372005907818675, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 170, train_loss = 19.328299017623067, train_acc = 0.9562179785747554\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 171, train_loss = 19.28642682172358, train_acc = 0.9562179785747554\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 172, train_loss = 19.245281491428614, train_acc = 0.956450861667443\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 173, train_loss = 19.20265993103385, train_acc = 0.956450861667443\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 174, train_loss = 19.163006452843547, train_acc = 0.9568001863064741\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 175, train_loss = 19.121766731142998, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 176, train_loss = 19.08171309903264, train_acc = 0.9570330693991617\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 177, train_loss = 19.04156326316297, train_acc = 0.9571495109455054\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 178, train_loss = 19.002451298758388, train_acc = 0.9572659524918491\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 179, train_loss = 18.963407643139362, train_acc = 0.9573823940381928\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 180, train_loss = 18.923746747896075, train_acc = 0.9574988355845365\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 181, train_loss = 18.885350082069635, train_acc = 0.9574988355845365\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 182, train_loss = 18.84685550443828, train_acc = 0.9574988355845365\n",
      "test Acc 0.9445996275605214:\n",
      "28th- epoch: 183, train_loss = 18.808879470452666, train_acc = 0.9574988355845365\n",
      "test Acc 0.9445996275605214:\n",
      "28th- epoch: 184, train_loss = 18.77220566943288, train_acc = 0.9574988355845365\n",
      "test Acc 0.9445996275605214:\n",
      "28th- epoch: 185, train_loss = 18.736185824498534, train_acc = 0.9577317186772241\n",
      "test Acc 0.9445996275605214:\n",
      "28th- epoch: 186, train_loss = 18.698703480884433, train_acc = 0.9578481602235678\n",
      "test Acc 0.9445996275605214:\n",
      "28th- epoch: 187, train_loss = 18.6627951990813, train_acc = 0.9579646017699115\n",
      "test Acc 0.9445996275605214:\n",
      "28th- epoch: 188, train_loss = 18.626335432752967, train_acc = 0.9581974848625989\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 189, train_loss = 18.591420939192176, train_acc = 0.9581974848625989\n",
      "test Acc 0.9455307262569832:\n",
      "28th- epoch: 190, train_loss = 18.555615715682507, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "28th- epoch: 191, train_loss = 18.520822633057833, train_acc = 0.9584303679552865\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 192, train_loss = 18.4850190076977, train_acc = 0.9584303679552865\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 193, train_loss = 18.45111537538469, train_acc = 0.9583139264089428\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 194, train_loss = 18.41759547032416, train_acc = 0.9583139264089428\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 195, train_loss = 18.382898084819317, train_acc = 0.9584303679552865\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 196, train_loss = 18.34917719848454, train_acc = 0.9584303679552865\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 197, train_loss = 18.31691556982696, train_acc = 0.9584303679552865\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 198, train_loss = 18.282201716676354, train_acc = 0.9586632510479739\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 199, train_loss = 18.250687649473548, train_acc = 0.9586632510479739\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 200, train_loss = 18.217876186594367, train_acc = 0.9587796925943176\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 201, train_loss = 18.185655815526843, train_acc = 0.9588961341406614\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 202, train_loss = 18.15439235791564, train_acc = 0.9588961341406614\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 203, train_loss = 18.122290706261992, train_acc = 0.9588961341406614\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 204, train_loss = 18.092328492552042, train_acc = 0.9588961341406614\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 205, train_loss = 18.06031719967723, train_acc = 0.9590125756870052\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 206, train_loss = 18.02976388297975, train_acc = 0.9591290172333489\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 207, train_loss = 18.00023881532252, train_acc = 0.9590125756870052\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 208, train_loss = 17.969570638611913, train_acc = 0.9590125756870052\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 209, train_loss = 17.939812107011676, train_acc = 0.9590125756870052\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 210, train_loss = 17.908986689522862, train_acc = 0.9592454587796926\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 211, train_loss = 17.880150439217687, train_acc = 0.9592454587796926\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 212, train_loss = 17.852710401639342, train_acc = 0.9592454587796926\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 213, train_loss = 17.822840847074986, train_acc = 0.9592454587796926\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 214, train_loss = 17.793257584795356, train_acc = 0.9592454587796926\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 215, train_loss = 17.764588944613934, train_acc = 0.9592454587796926\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 216, train_loss = 17.73787440545857, train_acc = 0.9592454587796926\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 217, train_loss = 17.70914730988443, train_acc = 0.9592454587796926\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 218, train_loss = 17.680885704234242, train_acc = 0.9592454587796926\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 219, train_loss = 17.653559921309352, train_acc = 0.9593619003260363\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 220, train_loss = 17.625937201082706, train_acc = 0.95947834187238\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 221, train_loss = 17.599132103845477, train_acc = 0.9595947834187238\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 222, train_loss = 17.572326961904764, train_acc = 0.9597112249650676\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 223, train_loss = 17.545570101588964, train_acc = 0.9597112249650676\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 224, train_loss = 17.519230062142015, train_acc = 0.9598276665114113\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 225, train_loss = 17.493491096422076, train_acc = 0.959944108057755\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 226, train_loss = 17.468072248622775, train_acc = 0.9600605496040987\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 227, train_loss = 17.442391565069556, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 228, train_loss = 17.41611577384174, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 229, train_loss = 17.390191992744803, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 230, train_loss = 17.365781700238585, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 231, train_loss = 17.34083938971162, train_acc = 0.9601769911504425\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 232, train_loss = 17.315631130710244, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 233, train_loss = 17.2920646648854, train_acc = 0.96040987424313\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 234, train_loss = 17.26843105442822, train_acc = 0.9606427573358174\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 235, train_loss = 17.243904953822494, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 236, train_loss = 17.219777818769217, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 237, train_loss = 17.195857083424926, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 238, train_loss = 17.17371372319758, train_acc = 0.9609920819748486\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 239, train_loss = 17.14915873669088, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 240, train_loss = 17.126722114160657, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 241, train_loss = 17.10334608145058, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 242, train_loss = 17.08062818273902, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 243, train_loss = 17.05837540514767, train_acc = 0.9611085235211924\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 244, train_loss = 17.03594458848238, train_acc = 0.9612249650675361\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 245, train_loss = 17.014203863218427, train_acc = 0.9612249650675361\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 246, train_loss = 16.991543363779783, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 247, train_loss = 16.9696353841573, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 248, train_loss = 16.949184285476804, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 249, train_loss = 16.92833915166557, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 250, train_loss = 16.90618592314422, train_acc = 0.961690731252911\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 251, train_loss = 16.88452539406717, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 252, train_loss = 16.86367834545672, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 253, train_loss = 16.842252416536212, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 254, train_loss = 16.824036589823663, train_acc = 0.962156497438286\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 255, train_loss = 16.802705951035023, train_acc = 0.9622729389846297\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 256, train_loss = 16.783358172513545, train_acc = 0.9622729389846297\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 257, train_loss = 16.762058899737895, train_acc = 0.9622729389846297\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 258, train_loss = 16.742046087048948, train_acc = 0.9623893805309734\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 259, train_loss = 16.72189815621823, train_acc = 0.9623893805309734\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 260, train_loss = 16.70254275854677, train_acc = 0.9623893805309734\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 261, train_loss = 16.682753561995924, train_acc = 0.9627387051700047\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 262, train_loss = 16.663414520211518, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 263, train_loss = 16.643845573067665, train_acc = 0.9629715882626921\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 264, train_loss = 16.625622713007033, train_acc = 0.9629715882626921\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 265, train_loss = 16.60544669535011, train_acc = 0.9629715882626921\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 266, train_loss = 16.58804924879223, train_acc = 0.9629715882626921\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 267, train_loss = 16.5695588728413, train_acc = 0.9629715882626921\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 268, train_loss = 16.54945557191968, train_acc = 0.9630880298090359\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 269, train_loss = 16.532354245893657, train_acc = 0.9632044713553796\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 270, train_loss = 16.512903205119073, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 271, train_loss = 16.497375370003283, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 272, train_loss = 16.476740586571395, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 273, train_loss = 16.458128303289413, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 274, train_loss = 16.442812368273735, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 275, train_loss = 16.425402686931193, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 276, train_loss = 16.407519466243684, train_acc = 0.9636702375407545\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 277, train_loss = 16.389388490468264, train_acc = 0.9636702375407545\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 278, train_loss = 16.372311347164214, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 279, train_loss = 16.35415660496801, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 280, train_loss = 16.33838615566492, train_acc = 0.963903120633442\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 281, train_loss = 16.319981057196856, train_acc = 0.963903120633442\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 282, train_loss = 16.304167211055756, train_acc = 0.9641360037261295\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 283, train_loss = 16.28690970595926, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 284, train_loss = 16.271672046743333, train_acc = 0.9641360037261295\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 285, train_loss = 16.255333767272532, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 286, train_loss = 16.238639091141522, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 287, train_loss = 16.222613535821438, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 288, train_loss = 16.205236364156008, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 289, train_loss = 16.190222558565438, train_acc = 0.9642524452724732\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 290, train_loss = 16.173195800743997, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 291, train_loss = 16.156618606299162, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 292, train_loss = 16.142023555003107, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 293, train_loss = 16.126579362899065, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 294, train_loss = 16.11087484564632, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 295, train_loss = 16.09624084830284, train_acc = 0.9643688868188169\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 296, train_loss = 16.07972563058138, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 297, train_loss = 16.0646726032719, train_acc = 0.9644853283651607\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 298, train_loss = 16.049563487060368, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 299, train_loss = 16.037232919596136, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 300, train_loss = 16.02020325139165, train_acc = 0.9646017699115044\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 301, train_loss = 16.005647861398757, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 302, train_loss = 15.99058344680816, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 303, train_loss = 15.976220198906958, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 304, train_loss = 15.961605737917125, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 305, train_loss = 15.946624959819019, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 306, train_loss = 15.93433082755655, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 307, train_loss = 15.91769739985466, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 308, train_loss = 15.905639979057014, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 309, train_loss = 15.889360061846673, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 310, train_loss = 15.876123377121985, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 311, train_loss = 15.86251312494278, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 312, train_loss = 15.84863415453583, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 313, train_loss = 15.835281766951084, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 314, train_loss = 15.822145781479776, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 315, train_loss = 15.807465050369501, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 316, train_loss = 15.793683984316885, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 317, train_loss = 15.781329550780356, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 318, train_loss = 15.767461710609496, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 319, train_loss = 15.754707150161266, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 320, train_loss = 15.743655095808208, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 321, train_loss = 15.728151858784258, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 322, train_loss = 15.716195044107735, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 323, train_loss = 15.702117050997913, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 324, train_loss = 15.692835189402103, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 325, train_loss = 15.676966805942357, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 326, train_loss = 15.665152345784009, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 327, train_loss = 15.65148242469877, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 328, train_loss = 15.639330734498799, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 329, train_loss = 15.62696931231767, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 330, train_loss = 15.61468602810055, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 331, train_loss = 15.603727221488953, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 332, train_loss = 15.589870046824217, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 333, train_loss = 15.579457790590823, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 334, train_loss = 15.56659143511206, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 335, train_loss = 15.5527452128008, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 336, train_loss = 15.543408396653831, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 337, train_loss = 15.531459360383451, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 338, train_loss = 15.51870319340378, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 339, train_loss = 15.50815273821354, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 340, train_loss = 15.494959608651698, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 341, train_loss = 15.482534498907626, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 342, train_loss = 15.472389210946858, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 343, train_loss = 15.45874721929431, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 344, train_loss = 15.44773678202182, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 345, train_loss = 15.438212676905096, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 346, train_loss = 15.426427103579044, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 347, train_loss = 15.41506075579673, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 348, train_loss = 15.40477255359292, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 349, train_loss = 15.392970371060073, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 350, train_loss = 15.382033037953079, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 351, train_loss = 15.370599531568587, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 352, train_loss = 15.360282090492547, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 353, train_loss = 15.34937717486173, train_acc = 0.9658826269212856\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 354, train_loss = 15.339625302702188, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 355, train_loss = 15.327061240561306, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 356, train_loss = 15.31719842273742, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 357, train_loss = 15.306228033266962, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 358, train_loss = 15.294552809558809, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 359, train_loss = 15.284513919614255, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 360, train_loss = 15.273455087095499, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 361, train_loss = 15.263259324245155, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 362, train_loss = 15.253768212161958, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 363, train_loss = 15.242230801843107, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 364, train_loss = 15.233042056672275, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 365, train_loss = 15.22247688472271, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 366, train_loss = 15.211704045534134, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 367, train_loss = 15.202566613443196, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 368, train_loss = 15.192082070745528, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 369, train_loss = 15.18200533092022, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 370, train_loss = 15.172428268939257, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 371, train_loss = 15.163608450442553, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 372, train_loss = 15.154135731048882, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 373, train_loss = 15.143359817564487, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 374, train_loss = 15.134559596888721, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 375, train_loss = 15.123980698175728, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 376, train_loss = 15.113424436189234, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 377, train_loss = 15.105104882270098, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 378, train_loss = 15.09459089115262, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 379, train_loss = 15.086955706588924, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 380, train_loss = 15.077618669718504, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 381, train_loss = 15.066753282211721, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 382, train_loss = 15.057004666887224, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 383, train_loss = 15.049467910081148, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 384, train_loss = 15.040390039794147, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 385, train_loss = 15.030737772583961, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 386, train_loss = 15.024000712670386, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 387, train_loss = 15.011789909563959, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 388, train_loss = 15.003757919184864, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 389, train_loss = 14.994284146465361, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 390, train_loss = 14.984717971645296, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 391, train_loss = 14.974900480359793, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 392, train_loss = 14.967135122977197, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 393, train_loss = 14.958833101205528, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 394, train_loss = 14.94995728880167, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 395, train_loss = 14.940660609863698, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 396, train_loss = 14.932572026737034, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 397, train_loss = 14.922785989008844, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 398, train_loss = 14.915976692922413, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 399, train_loss = 14.90549526270479, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 400, train_loss = 14.897223629057407, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 401, train_loss = 14.889606357552111, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 402, train_loss = 14.88172520045191, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 403, train_loss = 14.872963494621217, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 404, train_loss = 14.86433921661228, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 405, train_loss = 14.855155077762902, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 406, train_loss = 14.848035760223866, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 407, train_loss = 14.838251772336662, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 408, train_loss = 14.830972671508789, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 409, train_loss = 14.8230837052688, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 410, train_loss = 14.814404510892928, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 411, train_loss = 14.807176620699465, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 412, train_loss = 14.796993348747492, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 413, train_loss = 14.790941293351352, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "28th- epoch: 414, train_loss = 14.782951732166111, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 415, train_loss = 14.775461592711508, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 416, train_loss = 14.766210311092436, train_acc = 0.9666977177456917\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 417, train_loss = 14.758939881809056, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 418, train_loss = 14.750017902813852, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 419, train_loss = 14.74250894319266, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 420, train_loss = 14.734666424803436, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 421, train_loss = 14.728157973848283, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 422, train_loss = 14.720031581819057, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 423, train_loss = 14.712354297749698, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 424, train_loss = 14.705344035290182, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 425, train_loss = 14.69731339905411, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 426, train_loss = 14.689995989203453, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 427, train_loss = 14.682558222673833, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 428, train_loss = 14.675098017789423, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 429, train_loss = 14.668049718253314, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 430, train_loss = 14.65997579973191, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 431, train_loss = 14.653269599191844, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 432, train_loss = 14.64657308999449, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 433, train_loss = 14.638881049118936, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 434, train_loss = 14.630942891351879, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 435, train_loss = 14.624962780624628, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 436, train_loss = 14.615798454731703, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 437, train_loss = 14.609812102280557, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 438, train_loss = 14.603492621332407, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 439, train_loss = 14.595564159564674, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 440, train_loss = 14.587387110106647, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 441, train_loss = 14.581459832377732, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 442, train_loss = 14.57354390481487, train_acc = 0.9678621332091291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 443, train_loss = 14.567598670721054, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 444, train_loss = 14.561782783363014, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 445, train_loss = 14.553771818522364, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 446, train_loss = 14.54659386863932, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 447, train_loss = 14.541133923921734, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 448, train_loss = 14.53258333588019, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 449, train_loss = 14.526526088360697, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 450, train_loss = 14.519838657230139, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 451, train_loss = 14.51275055622682, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 452, train_loss = 14.507625014986843, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 453, train_loss = 14.501295004040003, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 454, train_loss = 14.4937819740735, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 455, train_loss = 14.488226804882288, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 456, train_loss = 14.480488456785679, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 457, train_loss = 14.474529566708952, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 458, train_loss = 14.46723348274827, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 459, train_loss = 14.460787519812584, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 460, train_loss = 14.45495835551992, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 461, train_loss = 14.449523411691189, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 462, train_loss = 14.441708873957396, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 463, train_loss = 14.435932172928005, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 464, train_loss = 14.428386771585792, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 465, train_loss = 14.422987672034651, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 466, train_loss = 14.416172999888659, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 467, train_loss = 14.409670209046453, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 468, train_loss = 14.404544650111347, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 469, train_loss = 14.397315693553537, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 470, train_loss = 14.393262551631778, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 471, train_loss = 14.387012208346277, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 472, train_loss = 14.380702847149223, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 473, train_loss = 14.372687297407538, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 474, train_loss = 14.368528807070106, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 475, train_loss = 14.362417587544769, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 476, train_loss = 14.355567374732345, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 477, train_loss = 14.350190736353397, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 478, train_loss = 14.344435567501932, train_acc = 0.9683278993945039\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 479, train_loss = 14.338019486516714, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 480, train_loss = 14.330901224166155, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 481, train_loss = 14.325000144541264, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 482, train_loss = 14.320870292838663, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 483, train_loss = 14.314649181906134, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 484, train_loss = 14.309167230967432, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 485, train_loss = 14.303247465286404, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 486, train_loss = 14.297156809363514, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 487, train_loss = 14.291459409985691, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 488, train_loss = 14.286175259854645, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 489, train_loss = 14.280582379549742, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 490, train_loss = 14.275628930423409, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 491, train_loss = 14.268477252218872, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 492, train_loss = 14.262508320156485, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 493, train_loss = 14.25808585435152, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 494, train_loss = 14.25279446830973, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 495, train_loss = 14.247694072779268, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 496, train_loss = 14.241281220223755, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 497, train_loss = 14.236668749246746, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 498, train_loss = 14.230219209101051, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "28th- epoch: 499, train_loss = 14.22510465234518, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████▏    | 28/30 [3:06:15<13:17, 398.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "29th- epoch: 0, train_loss = 270.7087686061859, train_acc = 0.41802515137401025\n",
      "test Acc 0.49860335195530725:\n",
      "29th- epoch: 1, train_loss = 208.2754247188568, train_acc = 0.5001164415463437\n",
      "test Acc 0.4995344506517691:\n",
      "29th- epoch: 2, train_loss = 177.51581931114197, train_acc = 0.5066371681415929\n",
      "test Acc 0.5167597765363129:\n",
      "29th- epoch: 3, train_loss = 162.5352588891983, train_acc = 0.5352817885421518\n",
      "test Acc 0.5656424581005587:\n",
      "29th- epoch: 4, train_loss = 150.75280112028122, train_acc = 0.5769678621332092\n",
      "test Acc 0.6070763500931099:\n",
      "29th- epoch: 5, train_loss = 140.12892508506775, train_acc = 0.6109687936655799\n",
      "test Acc 0.6233705772811918:\n",
      "29th- epoch: 6, train_loss = 130.20381498336792, train_acc = 0.6326269212855147\n",
      "test Acc 0.7257914338919925:\n",
      "29th- epoch: 7, train_loss = 120.99223500490189, train_acc = 0.7008616674429436\n",
      "test Acc 0.7383612662942272:\n",
      "29th- epoch: 8, train_loss = 112.45712012052536, train_acc = 0.7439450395901258\n",
      "test Acc 0.7541899441340782:\n",
      "29th- epoch: 9, train_loss = 104.54797339439392, train_acc = 0.7725896599906846\n",
      "test Acc 0.7886405959031657:\n",
      "29th- epoch: 10, train_loss = 97.21711111068726, train_acc = 0.8007685142058687\n",
      "test Acc 0.8095903165735568:\n",
      "29th- epoch: 11, train_loss = 90.4946368932724, train_acc = 0.8149743828598044\n",
      "test Acc 0.8263500931098696:\n",
      "29th- epoch: 12, train_loss = 84.38554573059082, train_acc = 0.8266185374941779\n",
      "test Acc 0.8365921787709497:\n",
      "29th- epoch: 13, train_loss = 78.89159151911736, train_acc = 0.8389613414066138\n",
      "test Acc 0.8528864059590316:\n",
      "29th- epoch: 14, train_loss = 74.00554823875427, train_acc = 0.852119236143456\n",
      "test Acc 0.8594040968342644:\n",
      "29th- epoch: 15, train_loss = 69.69222554564476, train_acc = 0.8625989753143922\n",
      "test Acc 0.86731843575419:\n",
      "29th- epoch: 16, train_loss = 65.90233677625656, train_acc = 0.8678388448998603\n",
      "test Acc 0.8701117318435754:\n",
      "29th- epoch: 17, train_loss = 62.581677198410034, train_acc = 0.8727293898462971\n",
      "test Acc 0.8761638733705773:\n",
      "29th- epoch: 18, train_loss = 59.66215589642525, train_acc = 0.8766884024219842\n",
      "test Acc 0.8822160148975792:\n",
      "29th- epoch: 19, train_loss = 57.085883051157, train_acc = 0.8808802980903586\n",
      "test Acc 0.8864059590316573:\n",
      "29th- epoch: 20, train_loss = 54.81329794228077, train_acc = 0.8855379599441081\n",
      "test Acc 0.8915270018621974:\n",
      "29th- epoch: 21, train_loss = 52.80815809965134, train_acc = 0.8883325570563577\n",
      "test Acc 0.8938547486033519:\n",
      "29th- epoch: 22, train_loss = 51.03172096610069, train_acc = 0.8903120633442012\n",
      "test Acc 0.8961824953445066:\n",
      "29th- epoch: 23, train_loss = 49.450129345059395, train_acc = 0.8924080111783884\n",
      "test Acc 0.9008379888268156:\n",
      "29th- epoch: 24, train_loss = 48.03537429869175, train_acc = 0.897880763856544\n",
      "test Acc 0.904096834264432:\n",
      "29th- epoch: 25, train_loss = 46.76426184177399, train_acc = 0.9002095947834188\n",
      "test Acc 0.9054934823091247:\n",
      "29th- epoch: 26, train_loss = 45.616704761981964, train_acc = 0.901374010246856\n",
      "test Acc 0.9059590316573557:\n",
      "29th- epoch: 27, train_loss = 44.574504509568214, train_acc = 0.9032370749883558\n",
      "test Acc 0.9064245810055865:\n",
      "29th- epoch: 28, train_loss = 43.62578508257866, train_acc = 0.9045179319981369\n",
      "test Acc 0.9078212290502793:\n",
      "29th- epoch: 29, train_loss = 42.756852492690086, train_acc = 0.9055659059152306\n",
      "test Acc 0.909217877094972:\n",
      "29th- epoch: 30, train_loss = 41.95501954853535, train_acc = 0.9071960875640428\n",
      "test Acc 0.910148975791434:\n",
      "29th- epoch: 31, train_loss = 41.211084738373756, train_acc = 0.9087098276665114\n",
      "test Acc 0.9115456238361266:\n",
      "29th- epoch: 32, train_loss = 40.51751784980297, train_acc = 0.9111551001397299\n",
      "test Acc 0.9120111731843575:\n",
      "29th- epoch: 33, train_loss = 39.86778128147125, train_acc = 0.9120866325104797\n",
      "test Acc 0.9120111731843575:\n",
      "29th- epoch: 34, train_loss = 39.25751155614853, train_acc = 0.9134839310666045\n",
      "test Acc 0.9129422718808193:\n",
      "29th- epoch: 35, train_loss = 38.68197472393513, train_acc = 0.915463437354448\n",
      "test Acc 0.9152700186219739:\n",
      "29th- epoch: 36, train_loss = 38.13504947721958, train_acc = 0.9169771774569166\n",
      "test Acc 0.9157355679702048:\n",
      "29th- epoch: 37, train_loss = 37.6144463121891, train_acc = 0.9177922682813228\n",
      "test Acc 0.9166666666666666:\n",
      "29th- epoch: 38, train_loss = 37.120511919260025, train_acc = 0.9193060083837913\n",
      "test Acc 0.9180633147113594:\n",
      "29th- epoch: 39, train_loss = 36.65131747722626, train_acc = 0.9205868653935724\n",
      "test Acc 0.9185288640595903:\n",
      "29th- epoch: 40, train_loss = 36.20419143140316, train_acc = 0.9209361900326036\n",
      "test Acc 0.9194599627560521:\n",
      "29th- epoch: 41, train_loss = 35.77729286253452, train_acc = 0.9223334885887284\n",
      "test Acc 0.9199255121042831:\n",
      "29th- epoch: 42, train_loss = 35.36875891685486, train_acc = 0.9232650209594784\n",
      "test Acc 0.9208566108007449:\n",
      "29th- epoch: 43, train_loss = 34.97741800546646, train_acc = 0.9244294364229158\n",
      "test Acc 0.9217877094972067:\n",
      "29th- epoch: 44, train_loss = 34.60013926029205, train_acc = 0.9252445272473219\n",
      "test Acc 0.9231843575418994:\n",
      "29th- epoch: 45, train_loss = 34.23738230019808, train_acc = 0.9258267349790406\n",
      "test Acc 0.9241154562383612:\n",
      "29th- epoch: 46, train_loss = 33.88734021782875, train_acc = 0.9269911504424779\n",
      "test Acc 0.9241154562383612:\n",
      "29th- epoch: 47, train_loss = 33.549267791211605, train_acc = 0.9272240335351654\n",
      "test Acc 0.9259776536312849:\n",
      "29th- epoch: 48, train_loss = 33.222961381077766, train_acc = 0.928272007452259\n",
      "test Acc 0.9259776536312849:\n",
      "29th- epoch: 49, train_loss = 32.907211273908615, train_acc = 0.9289706567303214\n",
      "test Acc 0.9259776536312849:\n",
      "29th- epoch: 50, train_loss = 32.60206522792578, train_acc = 0.9296693060083838\n",
      "test Acc 0.9264432029795159:\n",
      "29th- epoch: 51, train_loss = 32.30638337880373, train_acc = 0.930018630647415\n",
      "test Acc 0.9269087523277467:\n",
      "29th- epoch: 52, train_loss = 32.02072682231665, train_acc = 0.9301350721937587\n",
      "test Acc 0.9269087523277467:\n",
      "29th- epoch: 53, train_loss = 31.743849009275436, train_acc = 0.9302515137401025\n",
      "test Acc 0.9273743016759777:\n",
      "29th- epoch: 54, train_loss = 31.474943667650223, train_acc = 0.9303679552864462\n",
      "test Acc 0.9273743016759777:\n",
      "29th- epoch: 55, train_loss = 31.21271162480116, train_acc = 0.9310666045645086\n",
      "test Acc 0.9273743016759777:\n",
      "29th- epoch: 56, train_loss = 30.95882498472929, train_acc = 0.931765253842571\n",
      "test Acc 0.9273743016759777:\n",
      "29th- epoch: 57, train_loss = 30.71116152405739, train_acc = 0.9323474615742897\n",
      "test Acc 0.9273743016759777:\n",
      "29th- epoch: 58, train_loss = 30.470403283834457, train_acc = 0.9329296693060084\n",
      "test Acc 0.9278398510242085:\n",
      "29th- epoch: 59, train_loss = 30.235995054244995, train_acc = 0.9336283185840708\n",
      "test Acc 0.9278398510242085:\n",
      "29th- epoch: 60, train_loss = 30.007883578538895, train_acc = 0.9338612016767582\n",
      "test Acc 0.9278398510242085:\n",
      "29th- epoch: 61, train_loss = 29.785327568650246, train_acc = 0.9340940847694458\n",
      "test Acc 0.9278398510242085:\n",
      "29th- epoch: 62, train_loss = 29.56818351149559, train_acc = 0.9344434094084769\n",
      "test Acc 0.9283054003724395:\n",
      "29th- epoch: 63, train_loss = 29.35565534979105, train_acc = 0.9347927340475082\n",
      "test Acc 0.9283054003724395:\n",
      "29th- epoch: 64, train_loss = 29.14868189394474, train_acc = 0.9354913833255706\n",
      "test Acc 0.9287709497206704:\n",
      "29th- epoch: 65, train_loss = 28.946174427866936, train_acc = 0.9356078248719143\n",
      "test Acc 0.9287709497206704:\n",
      "29th- epoch: 66, train_loss = 28.747700169682503, train_acc = 0.9359571495109456\n",
      "test Acc 0.9287709497206704:\n",
      "29th- epoch: 67, train_loss = 28.55401886254549, train_acc = 0.9365393572426641\n",
      "test Acc 0.9292364990689013:\n",
      "29th- epoch: 68, train_loss = 28.36427739262581, train_acc = 0.9367722403353517\n",
      "test Acc 0.9292364990689013:\n",
      "29th- epoch: 69, train_loss = 28.178143426775932, train_acc = 0.9373544480670704\n",
      "test Acc 0.9297020484171322:\n",
      "29th- epoch: 70, train_loss = 27.99665004760027, train_acc = 0.9377037727061015\n",
      "test Acc 0.930633147113594:\n",
      "29th- epoch: 71, train_loss = 27.818925939500332, train_acc = 0.9375873311597578\n",
      "test Acc 0.930633147113594:\n",
      "29th- epoch: 72, train_loss = 27.644975796341896, train_acc = 0.9377037727061015\n",
      "test Acc 0.930633147113594:\n",
      "29th- epoch: 73, train_loss = 27.474471144378185, train_acc = 0.9378202142524453\n",
      "test Acc 0.930633147113594:\n",
      "29th- epoch: 74, train_loss = 27.30695005506277, train_acc = 0.9380530973451328\n",
      "test Acc 0.930633147113594:\n",
      "29th- epoch: 75, train_loss = 27.142501533031464, train_acc = 0.9382859804378202\n",
      "test Acc 0.930633147113594:\n",
      "29th- epoch: 76, train_loss = 26.981540627777576, train_acc = 0.9391010712622264\n",
      "test Acc 0.931098696461825:\n",
      "29th- epoch: 77, train_loss = 26.82259524613619, train_acc = 0.9393339543549138\n",
      "test Acc 0.931098696461825:\n",
      "29th- epoch: 78, train_loss = 26.667034454643726, train_acc = 0.939683278993945\n",
      "test Acc 0.931098696461825:\n",
      "29th- epoch: 79, train_loss = 26.514476522803307, train_acc = 0.94014904517932\n",
      "test Acc 0.931098696461825:\n",
      "29th- epoch: 80, train_loss = 26.364696763455868, train_acc = 0.9403819282720075\n",
      "test Acc 0.9315642458100558:\n",
      "29th- epoch: 81, train_loss = 26.217479646205902, train_acc = 0.9403819282720075\n",
      "test Acc 0.9320297951582868:\n",
      "29th- epoch: 82, train_loss = 26.073272213339806, train_acc = 0.9404983698183512\n",
      "test Acc 0.9320297951582868:\n",
      "29th- epoch: 83, train_loss = 25.9312294870615, train_acc = 0.9409641360037261\n",
      "test Acc 0.9320297951582868:\n",
      "29th- epoch: 84, train_loss = 25.7917565330863, train_acc = 0.9411970190964136\n",
      "test Acc 0.9320297951582868:\n",
      "29th- epoch: 85, train_loss = 25.655261393636465, train_acc = 0.9413134606427573\n",
      "test Acc 0.9320297951582868:\n",
      "29th- epoch: 86, train_loss = 25.52117843180895, train_acc = 0.9420121099208197\n",
      "test Acc 0.9329608938547486:\n",
      "29th- epoch: 87, train_loss = 25.38967141881585, train_acc = 0.9424778761061947\n",
      "test Acc 0.9329608938547486:\n",
      "29th- epoch: 88, train_loss = 25.26060963794589, train_acc = 0.9428272007452259\n",
      "test Acc 0.9329608938547486:\n",
      "29th- epoch: 89, train_loss = 25.133869666606188, train_acc = 0.9430600838379134\n",
      "test Acc 0.9329608938547486:\n",
      "29th- epoch: 90, train_loss = 25.010212182998657, train_acc = 0.9431765253842571\n",
      "test Acc 0.9334264432029795:\n",
      "29th- epoch: 91, train_loss = 24.888789650052786, train_acc = 0.9436422915696321\n",
      "test Acc 0.9338919925512105:\n",
      "29th- epoch: 92, train_loss = 24.77034893631935, train_acc = 0.9442244993013508\n",
      "test Acc 0.9343575418994413:\n",
      "29th- epoch: 93, train_loss = 24.652208402752876, train_acc = 0.9443409408476945\n",
      "test Acc 0.9343575418994413:\n",
      "29th- epoch: 94, train_loss = 24.537589363753796, train_acc = 0.9445738239403819\n",
      "test Acc 0.9348230912476723:\n",
      "29th- epoch: 95, train_loss = 24.42440974712372, train_acc = 0.9450395901257569\n",
      "test Acc 0.9348230912476723:\n",
      "29th- epoch: 96, train_loss = 24.31382416561246, train_acc = 0.9451560316721006\n",
      "test Acc 0.9348230912476723:\n",
      "29th- epoch: 97, train_loss = 24.204662159085274, train_acc = 0.945388914764788\n",
      "test Acc 0.9348230912476723:\n",
      "29th- epoch: 98, train_loss = 24.098925538361073, train_acc = 0.9456217978574756\n",
      "test Acc 0.9352886405959032:\n",
      "29th- epoch: 99, train_loss = 23.992559272795916, train_acc = 0.9459711224965067\n",
      "test Acc 0.9352886405959032:\n",
      "29th- epoch: 100, train_loss = 23.889134887605906, train_acc = 0.9460875640428504\n",
      "test Acc 0.9357541899441341:\n",
      "29th- epoch: 101, train_loss = 23.787626933306456, train_acc = 0.9466697717745691\n",
      "test Acc 0.936219739292365:\n",
      "29th- epoch: 102, train_loss = 23.68795333430171, train_acc = 0.946786213320913\n",
      "test Acc 0.9366852886405959:\n",
      "29th- epoch: 103, train_loss = 23.589352045208216, train_acc = 0.9470190964136004\n",
      "test Acc 0.9366852886405959:\n",
      "29th- epoch: 104, train_loss = 23.493026163429022, train_acc = 0.9473684210526315\n",
      "test Acc 0.9366852886405959:\n",
      "29th- epoch: 105, train_loss = 23.398125786334276, train_acc = 0.9476013041453191\n",
      "test Acc 0.9371508379888268:\n",
      "29th- epoch: 106, train_loss = 23.305041026324034, train_acc = 0.948067070330694\n",
      "test Acc 0.9371508379888268:\n",
      "29th- epoch: 107, train_loss = 23.213946785777807, train_acc = 0.9482999534233815\n",
      "test Acc 0.9376163873370578:\n",
      "29th- epoch: 108, train_loss = 23.122801806777716, train_acc = 0.9486492780624126\n",
      "test Acc 0.9380819366852886:\n",
      "29th- epoch: 109, train_loss = 23.033233538269997, train_acc = 0.9486492780624126\n",
      "test Acc 0.9380819366852886:\n",
      "29th- epoch: 110, train_loss = 22.94640351459384, train_acc = 0.9487657196087564\n",
      "test Acc 0.9380819366852886:\n",
      "29th- epoch: 111, train_loss = 22.85904050990939, train_acc = 0.9487657196087564\n",
      "test Acc 0.9380819366852886:\n",
      "29th- epoch: 112, train_loss = 22.7745199277997, train_acc = 0.9488821611551002\n",
      "test Acc 0.9380819366852886:\n",
      "29th- epoch: 113, train_loss = 22.691334161907434, train_acc = 0.9487657196087564\n",
      "test Acc 0.9380819366852886:\n",
      "29th- epoch: 114, train_loss = 22.609178077429533, train_acc = 0.9487657196087564\n",
      "test Acc 0.9380819366852886:\n",
      "29th- epoch: 115, train_loss = 22.52758427336812, train_acc = 0.9487657196087564\n",
      "test Acc 0.9380819366852886:\n",
      "29th- epoch: 116, train_loss = 22.449022263288498, train_acc = 0.9492314857941313\n",
      "test Acc 0.9380819366852886:\n",
      "29th- epoch: 117, train_loss = 22.370228745043278, train_acc = 0.9492314857941313\n",
      "test Acc 0.9380819366852886:\n",
      "29th- epoch: 118, train_loss = 22.292691610753536, train_acc = 0.9492314857941313\n",
      "test Acc 0.9380819366852886:\n",
      "29th- epoch: 119, train_loss = 22.2149292640388, train_acc = 0.9496972519795063\n",
      "test Acc 0.9380819366852886:\n",
      "29th- epoch: 120, train_loss = 22.1406760700047, train_acc = 0.9501630181648812\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 121, train_loss = 22.065817166119814, train_acc = 0.950279459711225\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 122, train_loss = 21.990433149039745, train_acc = 0.9505123428039124\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 123, train_loss = 21.918004523962736, train_acc = 0.9508616674429436\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 124, train_loss = 21.847508545964956, train_acc = 0.9509781089892874\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 125, train_loss = 21.776933528482914, train_acc = 0.9513274336283186\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 126, train_loss = 21.706769164651632, train_acc = 0.9514438751746623\n",
      "test Acc 0.9394785847299814:\n",
      "29th- epoch: 127, train_loss = 21.636343378573656, train_acc = 0.951560316721006\n",
      "test Acc 0.9399441340782123:\n",
      "29th- epoch: 128, train_loss = 21.568018034100533, train_acc = 0.9516767582673498\n",
      "test Acc 0.9399441340782123:\n",
      "29th- epoch: 129, train_loss = 21.501147847622633, train_acc = 0.9519096413600373\n",
      "test Acc 0.9404096834264432:\n",
      "29th- epoch: 130, train_loss = 21.435501355677843, train_acc = 0.952026082906381\n",
      "test Acc 0.9404096834264432:\n",
      "29th- epoch: 131, train_loss = 21.368689488619566, train_acc = 0.9521425244527247\n",
      "test Acc 0.9404096834264432:\n",
      "29th- epoch: 132, train_loss = 21.30353742465377, train_acc = 0.9521425244527247\n",
      "test Acc 0.9404096834264432:\n",
      "29th- epoch: 133, train_loss = 21.23945141583681, train_acc = 0.9523754075454122\n",
      "test Acc 0.9404096834264432:\n",
      "29th- epoch: 134, train_loss = 21.17785343900323, train_acc = 0.952491849091756\n",
      "test Acc 0.9399441340782123:\n",
      "29th- epoch: 135, train_loss = 21.114481262862682, train_acc = 0.952491849091756\n",
      "test Acc 0.9404096834264432:\n",
      "29th- epoch: 136, train_loss = 21.05221225321293, train_acc = 0.9526082906380997\n",
      "test Acc 0.9399441340782123:\n",
      "29th- epoch: 137, train_loss = 20.990828558802605, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "29th- epoch: 138, train_loss = 20.931186094880104, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n",
      "29th- epoch: 139, train_loss = 20.870285753160715, train_acc = 0.9531904983698184\n",
      "test Acc 0.9404096834264432:\n",
      "29th- epoch: 140, train_loss = 20.811000000685453, train_acc = 0.9533069399161621\n",
      "test Acc 0.9408752327746741:\n",
      "29th- epoch: 141, train_loss = 20.75233357027173, train_acc = 0.9533069399161621\n",
      "test Acc 0.9408752327746741:\n",
      "29th- epoch: 142, train_loss = 20.694164749234915, train_acc = 0.9535398230088495\n",
      "test Acc 0.9408752327746741:\n",
      "29th- epoch: 143, train_loss = 20.63621625676751, train_acc = 0.9535398230088495\n",
      "test Acc 0.9408752327746741:\n",
      "29th- epoch: 144, train_loss = 20.57974675297737, train_acc = 0.9536562645551933\n",
      "test Acc 0.9408752327746741:\n",
      "29th- epoch: 145, train_loss = 20.5227113366127, train_acc = 0.9537727061015371\n",
      "test Acc 0.9413407821229051:\n",
      "29th- epoch: 146, train_loss = 20.46696477010846, train_acc = 0.9540055891942245\n",
      "test Acc 0.9413407821229051:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 147, train_loss = 20.411993235349655, train_acc = 0.9542384722869119\n",
      "test Acc 0.9413407821229051:\n",
      "29th- epoch: 148, train_loss = 20.357414707541466, train_acc = 0.9543549138332557\n",
      "test Acc 0.9413407821229051:\n",
      "29th- epoch: 149, train_loss = 20.303496174514294, train_acc = 0.9544713553795995\n",
      "test Acc 0.9413407821229051:\n",
      "29th- epoch: 150, train_loss = 20.250540286302567, train_acc = 0.9547042384722869\n",
      "test Acc 0.9418063314711359:\n",
      "29th- epoch: 151, train_loss = 20.197809033095837, train_acc = 0.9547042384722869\n",
      "test Acc 0.9418063314711359:\n",
      "29th- epoch: 152, train_loss = 20.145853150635958, train_acc = 0.9547042384722869\n",
      "test Acc 0.9422718808193669:\n",
      "29th- epoch: 153, train_loss = 20.094659473747015, train_acc = 0.9549371215649743\n",
      "test Acc 0.9422718808193669:\n",
      "29th- epoch: 154, train_loss = 20.043494876474142, train_acc = 0.9549371215649743\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 155, train_loss = 19.992725044488907, train_acc = 0.9551700046576619\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 156, train_loss = 19.94155950471759, train_acc = 0.9551700046576619\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 157, train_loss = 19.892730947583914, train_acc = 0.9551700046576619\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 158, train_loss = 19.843469884246588, train_acc = 0.9554028877503493\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 159, train_loss = 19.794445011764765, train_acc = 0.9554028877503493\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 160, train_loss = 19.74709425866604, train_acc = 0.955519329296693\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 161, train_loss = 19.699508260935545, train_acc = 0.9556357708430367\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 162, train_loss = 19.654027925804257, train_acc = 0.9558686539357243\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 163, train_loss = 19.606702649965882, train_acc = 0.955985095482068\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 164, train_loss = 19.560731019824743, train_acc = 0.9562179785747554\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 165, train_loss = 19.514789629727602, train_acc = 0.9563344201210993\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 166, train_loss = 19.468260060995817, train_acc = 0.9566837447601304\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 167, train_loss = 19.424178754910827, train_acc = 0.9566837447601304\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 168, train_loss = 19.379989054054022, train_acc = 0.9566837447601304\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 169, train_loss = 19.335628183558583, train_acc = 0.9565673032137867\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 170, train_loss = 19.291791655123234, train_acc = 0.9566837447601304\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 171, train_loss = 19.24874950759113, train_acc = 0.9568001863064741\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 172, train_loss = 19.205733185634017, train_acc = 0.9568001863064741\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 173, train_loss = 19.162161009386182, train_acc = 0.9569166278528178\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 174, train_loss = 19.121997890993953, train_acc = 0.9571495109455054\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 175, train_loss = 19.08099966496229, train_acc = 0.9571495109455054\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 176, train_loss = 19.038809364661574, train_acc = 0.9572659524918491\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 177, train_loss = 18.997030276805162, train_acc = 0.9574988355845365\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 178, train_loss = 18.956298945471644, train_acc = 0.9576152771308803\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 179, train_loss = 18.91767522878945, train_acc = 0.9576152771308803\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 180, train_loss = 18.875689523294568, train_acc = 0.9577317186772241\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 181, train_loss = 18.83760354295373, train_acc = 0.9579646017699115\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 182, train_loss = 18.797688184306026, train_acc = 0.9579646017699115\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 183, train_loss = 18.76124053634703, train_acc = 0.9580810433162552\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 184, train_loss = 18.72168404981494, train_acc = 0.9579646017699115\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 185, train_loss = 18.68675541691482, train_acc = 0.9583139264089428\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 186, train_loss = 18.647225426509976, train_acc = 0.9583139264089428\n",
      "test Acc 0.9459962756052142:\n",
      "29th- epoch: 187, train_loss = 18.61181285046041, train_acc = 0.9583139264089428\n",
      "test Acc 0.9459962756052142:\n",
      "29th- epoch: 188, train_loss = 18.572981575503945, train_acc = 0.9583139264089428\n",
      "test Acc 0.9459962756052142:\n",
      "29th- epoch: 189, train_loss = 18.539341252297163, train_acc = 0.9583139264089428\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 190, train_loss = 18.502873765304685, train_acc = 0.9585468095016302\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 191, train_loss = 18.4662961717695, train_acc = 0.9585468095016302\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 192, train_loss = 18.433067921549082, train_acc = 0.9586632510479739\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 193, train_loss = 18.397624103352427, train_acc = 0.9586632510479739\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 194, train_loss = 18.36361421458423, train_acc = 0.9586632510479739\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 195, train_loss = 18.326764510944486, train_acc = 0.9587796925943176\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 196, train_loss = 18.294463699683547, train_acc = 0.9587796925943176\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 197, train_loss = 18.26130256615579, train_acc = 0.9587796925943176\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 198, train_loss = 18.22833070717752, train_acc = 0.9587796925943176\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 199, train_loss = 18.19442874006927, train_acc = 0.9587796925943176\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 200, train_loss = 18.160304645076394, train_acc = 0.9587796925943176\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 201, train_loss = 18.129826746881008, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 202, train_loss = 18.097681848332286, train_acc = 0.9588961341406614\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 203, train_loss = 18.063415644690394, train_acc = 0.9590125756870052\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 204, train_loss = 18.034029219299555, train_acc = 0.9590125756870052\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 205, train_loss = 18.003210097551346, train_acc = 0.9590125756870052\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 206, train_loss = 17.972078632563353, train_acc = 0.9590125756870052\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 207, train_loss = 17.941517028957605, train_acc = 0.9590125756870052\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 208, train_loss = 17.91136554814875, train_acc = 0.9590125756870052\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 209, train_loss = 17.881361154839396, train_acc = 0.9591290172333489\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 210, train_loss = 17.85150507465005, train_acc = 0.9592454587796926\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 211, train_loss = 17.821926278993487, train_acc = 0.9592454587796926\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 212, train_loss = 17.792088143527508, train_acc = 0.9592454587796926\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 213, train_loss = 17.76323714852333, train_acc = 0.9593619003260363\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 214, train_loss = 17.734499618411064, train_acc = 0.9593619003260363\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 215, train_loss = 17.705610079690814, train_acc = 0.9593619003260363\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 216, train_loss = 17.677029559388757, train_acc = 0.95947834187238\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 217, train_loss = 17.64887216873467, train_acc = 0.95947834187238\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 218, train_loss = 17.620492592453957, train_acc = 0.95947834187238\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 219, train_loss = 17.593070210888982, train_acc = 0.9595947834187238\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 220, train_loss = 17.56592569127679, train_acc = 0.9595947834187238\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 221, train_loss = 17.53912547789514, train_acc = 0.9598276665114113\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 222, train_loss = 17.511410899460316, train_acc = 0.959944108057755\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 223, train_loss = 17.486003182828426, train_acc = 0.959944108057755\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 224, train_loss = 17.459443924948573, train_acc = 0.9598276665114113\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 225, train_loss = 17.4322628993541, train_acc = 0.959944108057755\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 226, train_loss = 17.40757766738534, train_acc = 0.959944108057755\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 227, train_loss = 17.38106838800013, train_acc = 0.9600605496040987\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 228, train_loss = 17.355688029900193, train_acc = 0.9602934326967862\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 229, train_loss = 17.330192426219583, train_acc = 0.9605263157894737\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 230, train_loss = 17.30479064397514, train_acc = 0.9606427573358174\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 231, train_loss = 17.279346199706197, train_acc = 0.9608756404285049\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 232, train_loss = 17.252910809591413, train_acc = 0.9611085235211924\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 233, train_loss = 17.22781229391694, train_acc = 0.9611085235211924\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 234, train_loss = 17.204673612490296, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 235, train_loss = 17.180158672854304, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 236, train_loss = 17.15598315373063, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 237, train_loss = 17.13303724862635, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 238, train_loss = 17.1090043541044, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 239, train_loss = 17.08440650254488, train_acc = 0.9613414066138798\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 240, train_loss = 17.063673604279757, train_acc = 0.9614578481602236\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 241, train_loss = 17.040994280949235, train_acc = 0.9615742897065673\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 242, train_loss = 17.01577891036868, train_acc = 0.9615742897065673\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 243, train_loss = 16.993697756901383, train_acc = 0.9615742897065673\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 244, train_loss = 16.973618062213063, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 245, train_loss = 16.949408520944417, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 246, train_loss = 16.926910583861172, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 247, train_loss = 16.906754727475345, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 248, train_loss = 16.885950884781778, train_acc = 0.9622729389846297\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 249, train_loss = 16.863538842648268, train_acc = 0.9622729389846297\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 250, train_loss = 16.84151917602867, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 251, train_loss = 16.8189034787938, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 252, train_loss = 16.79836079478264, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 253, train_loss = 16.777910602279007, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 254, train_loss = 16.75573709141463, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 255, train_loss = 16.734872673638165, train_acc = 0.9625058220773172\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 256, train_loss = 16.716193945147097, train_acc = 0.9625058220773172\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 257, train_loss = 16.695164973847568, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 258, train_loss = 16.674509502016008, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 259, train_loss = 16.65337173640728, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 260, train_loss = 16.634388859383762, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 261, train_loss = 16.61400024127215, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 262, train_loss = 16.593767877668142, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 263, train_loss = 16.573954991064966, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 264, train_loss = 16.556521055288613, train_acc = 0.9626222636236609\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 265, train_loss = 16.535838771611452, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 266, train_loss = 16.51664798334241, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 267, train_loss = 16.49980489630252, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 268, train_loss = 16.478356029838324, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 269, train_loss = 16.459705983288586, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 270, train_loss = 16.441246832720935, train_acc = 0.9630880298090359\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 271, train_loss = 16.423535149544477, train_acc = 0.9630880298090359\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 272, train_loss = 16.40547175426036, train_acc = 0.9633209129017233\n",
      "test Acc 0.9497206703910615:\n",
      "29th- epoch: 273, train_loss = 16.387541892938316, train_acc = 0.9634373544480671\n",
      "test Acc 0.9501862197392924:\n",
      "29th- epoch: 274, train_loss = 16.36845612898469, train_acc = 0.9635537959944108\n",
      "test Acc 0.9506517690875232:\n",
      "29th- epoch: 275, train_loss = 16.351358293555677, train_acc = 0.9635537959944108\n",
      "test Acc 0.9506517690875232:\n",
      "29th- epoch: 276, train_loss = 16.333449125289917, train_acc = 0.9635537959944108\n",
      "test Acc 0.9506517690875232:\n",
      "29th- epoch: 277, train_loss = 16.314844106324017, train_acc = 0.9636702375407545\n",
      "test Acc 0.9506517690875232:\n",
      "29th- epoch: 278, train_loss = 16.297094895504415, train_acc = 0.9636702375407545\n",
      "test Acc 0.9506517690875232:\n",
      "29th- epoch: 279, train_loss = 16.280108475126326, train_acc = 0.9637866790870983\n",
      "test Acc 0.9506517690875232:\n",
      "29th- epoch: 280, train_loss = 16.262861664406955, train_acc = 0.963903120633442\n",
      "test Acc 0.9506517690875232:\n",
      "29th- epoch: 281, train_loss = 16.2462887018919, train_acc = 0.9640195621797858\n",
      "test Acc 0.9506517690875232:\n",
      "29th- epoch: 282, train_loss = 16.228319848887622, train_acc = 0.9641360037261295\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 283, train_loss = 16.211083973757923, train_acc = 0.9641360037261295\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 284, train_loss = 16.19520402699709, train_acc = 0.9641360037261295\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 285, train_loss = 16.1779080433771, train_acc = 0.9641360037261295\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 286, train_loss = 16.162277568131685, train_acc = 0.9641360037261295\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 287, train_loss = 16.143226752988994, train_acc = 0.9641360037261295\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 288, train_loss = 16.127960841171443, train_acc = 0.9642524452724732\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 289, train_loss = 16.11144319269806, train_acc = 0.9643688868188169\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 290, train_loss = 16.094881378114223, train_acc = 0.9643688868188169\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 291, train_loss = 16.078084596432745, train_acc = 0.9643688868188169\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 292, train_loss = 16.061954773962498, train_acc = 0.9643688868188169\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 293, train_loss = 16.047057355754077, train_acc = 0.9644853283651607\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 294, train_loss = 16.03051760327071, train_acc = 0.9646017699115044\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 295, train_loss = 16.015285930596292, train_acc = 0.9646017699115044\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 296, train_loss = 15.998266172595322, train_acc = 0.9647182114578482\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 297, train_loss = 15.985833409242332, train_acc = 0.9647182114578482\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 298, train_loss = 15.968599702231586, train_acc = 0.9646017699115044\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 299, train_loss = 15.954791965894401, train_acc = 0.9647182114578482\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 300, train_loss = 15.93839925993234, train_acc = 0.9647182114578482\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 301, train_loss = 15.922877196222544, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 302, train_loss = 15.907771103084087, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 303, train_loss = 15.892773461528122, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 304, train_loss = 15.879699756391346, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 305, train_loss = 15.862469962798059, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 306, train_loss = 15.850622926838696, train_acc = 0.9649510945505356\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 307, train_loss = 15.833681855350733, train_acc = 0.9649510945505356\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 308, train_loss = 15.819063412956893, train_acc = 0.9649510945505356\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 309, train_loss = 15.804576396010816, train_acc = 0.9649510945505356\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 310, train_loss = 15.79175931867212, train_acc = 0.9649510945505356\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 311, train_loss = 15.775975975207984, train_acc = 0.9649510945505356\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 312, train_loss = 15.763009938411415, train_acc = 0.9650675360968793\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 313, train_loss = 15.748214385472238, train_acc = 0.9650675360968793\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 314, train_loss = 15.734070145525038, train_acc = 0.9650675360968793\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 315, train_loss = 15.721125659532845, train_acc = 0.9650675360968793\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 316, train_loss = 15.705434027127922, train_acc = 0.9651839776432231\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 317, train_loss = 15.693657831288874, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 318, train_loss = 15.680617774836719, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 319, train_loss = 15.666857328265905, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 320, train_loss = 15.65307753533125, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 321, train_loss = 15.63892986252904, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 322, train_loss = 15.62722933664918, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 323, train_loss = 15.61399872880429, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 324, train_loss = 15.600066486746073, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 325, train_loss = 15.588025969453156, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 326, train_loss = 15.574517562054098, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 327, train_loss = 15.562496401369572, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 328, train_loss = 15.547380038537085, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 329, train_loss = 15.534708457998931, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 330, train_loss = 15.52226695138961, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 331, train_loss = 15.511284288018942, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 332, train_loss = 15.495500425808132, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 333, train_loss = 15.485181945376098, train_acc = 0.9655333022822543\n",
      "test Acc 0.9506517690875232:\n",
      "29th- epoch: 334, train_loss = 15.472408668138087, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 335, train_loss = 15.459971931762993, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 336, train_loss = 15.446590731851757, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 337, train_loss = 15.43584477994591, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 338, train_loss = 15.424378778785467, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 339, train_loss = 15.409890008158982, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 340, train_loss = 15.39875716343522, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 341, train_loss = 15.38715107459575, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 342, train_loss = 15.376134636811912, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 343, train_loss = 15.363966002129018, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 344, train_loss = 15.35403458494693, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 345, train_loss = 15.341562638990581, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 346, train_loss = 15.32807853538543, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 347, train_loss = 15.317859132774174, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 348, train_loss = 15.305103976279497, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 349, train_loss = 15.295209516771138, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 350, train_loss = 15.283568711020052, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 351, train_loss = 15.273301939480007, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 352, train_loss = 15.260901421308517, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 353, train_loss = 15.24891272932291, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 354, train_loss = 15.238032341003418, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 355, train_loss = 15.227884974330664, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 356, train_loss = 15.217434193007648, train_acc = 0.9658826269212856\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 357, train_loss = 15.206555902026594, train_acc = 0.9658826269212856\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 358, train_loss = 15.196064763702452, train_acc = 0.9658826269212856\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 359, train_loss = 15.185997436754405, train_acc = 0.9658826269212856\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 360, train_loss = 15.174393299035728, train_acc = 0.9658826269212856\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 361, train_loss = 15.16390695143491, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 362, train_loss = 15.152127284556627, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 363, train_loss = 15.141630847938359, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 364, train_loss = 15.131497657857835, train_acc = 0.9659990684676293\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 365, train_loss = 15.120713114738464, train_acc = 0.9659990684676293\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 366, train_loss = 15.111493700183928, train_acc = 0.9659990684676293\n",
      "test Acc 0.9511173184357542:\n",
      "29th- epoch: 367, train_loss = 15.099277633242309, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 368, train_loss = 15.089002876542509, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 369, train_loss = 15.07931633386761, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 370, train_loss = 15.069923740811646, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 371, train_loss = 15.060990892350674, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 372, train_loss = 15.048012820072472, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 373, train_loss = 15.03885804116726, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 374, train_loss = 15.029990862123668, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 375, train_loss = 15.02052862662822, train_acc = 0.966115510013973\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 376, train_loss = 15.010930166579783, train_acc = 0.9662319515603167\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 377, train_loss = 14.999424356035888, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 378, train_loss = 14.989706321619451, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 379, train_loss = 14.979702979326248, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 380, train_loss = 14.972112358547747, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 381, train_loss = 14.961879454553127, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 382, train_loss = 14.952278486452997, train_acc = 0.9663483931066604\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 383, train_loss = 14.941245975904167, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 384, train_loss = 14.934756729751825, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 385, train_loss = 14.923759276978672, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 386, train_loss = 14.914770890958607, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 387, train_loss = 14.906840541400015, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 388, train_loss = 14.895938371308148, train_acc = 0.9664648346530041\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 389, train_loss = 14.886609624139965, train_acc = 0.9664648346530041\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 390, train_loss = 14.877595599740744, train_acc = 0.9663483931066604\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 391, train_loss = 14.869685771875083, train_acc = 0.9664648346530041\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 392, train_loss = 14.860735629685223, train_acc = 0.9664648346530041\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 393, train_loss = 14.852123346179724, train_acc = 0.966581276199348\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 394, train_loss = 14.843338214792311, train_acc = 0.9664648346530041\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 395, train_loss = 14.834228177554905, train_acc = 0.9664648346530041\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 396, train_loss = 14.82449759915471, train_acc = 0.9664648346530041\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 397, train_loss = 14.815751657821238, train_acc = 0.9664648346530041\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 398, train_loss = 14.806340579874814, train_acc = 0.966581276199348\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 399, train_loss = 14.798257608897984, train_acc = 0.9664648346530041\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 400, train_loss = 14.788813314400613, train_acc = 0.9666977177456917\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 401, train_loss = 14.779820452444255, train_acc = 0.9668141592920354\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 402, train_loss = 14.77258866559714, train_acc = 0.9666977177456917\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 403, train_loss = 14.763618825934827, train_acc = 0.9666977177456917\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 404, train_loss = 14.755057158879936, train_acc = 0.9666977177456917\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 405, train_loss = 14.745534622110426, train_acc = 0.9666977177456917\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 406, train_loss = 14.738263620994985, train_acc = 0.9666977177456917\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 407, train_loss = 14.729607186280191, train_acc = 0.9666977177456917\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 408, train_loss = 14.72115832567215, train_acc = 0.9666977177456917\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 409, train_loss = 14.712210384197533, train_acc = 0.9666977177456917\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 410, train_loss = 14.705070063471794, train_acc = 0.9668141592920354\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 411, train_loss = 14.697208651341498, train_acc = 0.9666977177456917\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 412, train_loss = 14.689910986460745, train_acc = 0.9666977177456917\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 413, train_loss = 14.677349727600813, train_acc = 0.9669306008383791\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 414, train_loss = 14.670862653292716, train_acc = 0.9669306008383791\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 415, train_loss = 14.662640797905624, train_acc = 0.9670470423847228\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 416, train_loss = 14.65498547628522, train_acc = 0.9670470423847228\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 417, train_loss = 14.647596507333219, train_acc = 0.9670470423847228\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 418, train_loss = 14.64021807629615, train_acc = 0.9670470423847228\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 419, train_loss = 14.63238347042352, train_acc = 0.9670470423847228\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 420, train_loss = 14.622764420695603, train_acc = 0.9672799254774104\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 421, train_loss = 14.614953600801528, train_acc = 0.9671634839310667\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 422, train_loss = 14.6075205989182, train_acc = 0.9672799254774104\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 423, train_loss = 14.600422892719507, train_acc = 0.9672799254774104\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 424, train_loss = 14.593345950357616, train_acc = 0.9672799254774104\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 425, train_loss = 14.586293172091246, train_acc = 0.9672799254774104\n",
      "test Acc 0.952513966480447:\n",
      "29th- epoch: 426, train_loss = 14.577910390682518, train_acc = 0.9672799254774104\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 427, train_loss = 14.569474272429943, train_acc = 0.9672799254774104\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 428, train_loss = 14.561126270331442, train_acc = 0.9672799254774104\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 429, train_loss = 14.555257975123823, train_acc = 0.9672799254774104\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 430, train_loss = 14.547593518160284, train_acc = 0.9671634839310667\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 431, train_loss = 14.538765455596149, train_acc = 0.9671634839310667\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 432, train_loss = 14.529126105364412, train_acc = 0.9673963670237541\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 433, train_loss = 14.52324054017663, train_acc = 0.9675128085700978\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 434, train_loss = 14.516058808658272, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 435, train_loss = 14.50443060323596, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 436, train_loss = 14.50056038191542, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 437, train_loss = 14.491846868302673, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 438, train_loss = 14.48451463272795, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 439, train_loss = 14.477729926351458, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 440, train_loss = 14.469460689928383, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 441, train_loss = 14.462430653627962, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 442, train_loss = 14.456337835639715, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 443, train_loss = 14.44947391981259, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 444, train_loss = 14.442540972027928, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 445, train_loss = 14.434697481337935, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 446, train_loss = 14.427382938563824, train_acc = 0.9675128085700978\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 447, train_loss = 14.423712884541601, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 448, train_loss = 14.413721018936485, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 449, train_loss = 14.408579719718546, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 450, train_loss = 14.39756582910195, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 451, train_loss = 14.396218445152044, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 452, train_loss = 14.384492043405771, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 453, train_loss = 14.379839976783842, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 454, train_loss = 14.372963052242994, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 455, train_loss = 14.365246499422938, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 456, train_loss = 14.357230253517628, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 457, train_loss = 14.352186154574156, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 458, train_loss = 14.343524990137666, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 459, train_loss = 14.339239450637251, train_acc = 0.9676292501164415\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 460, train_loss = 14.332024881150573, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 461, train_loss = 14.325770006980747, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 462, train_loss = 14.321447599679232, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 463, train_loss = 14.312251263763756, train_acc = 0.9677456916627852\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 464, train_loss = 14.305782767478377, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 465, train_loss = 14.300854274537414, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 466, train_loss = 14.293702916707844, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 467, train_loss = 14.28735309233889, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 468, train_loss = 14.280987210571766, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 469, train_loss = 14.27375794062391, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 470, train_loss = 14.269082898739725, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 471, train_loss = 14.260586994234473, train_acc = 0.9678621332091291\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 472, train_loss = 14.255697533488274, train_acc = 0.9679785747554728\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 473, train_loss = 14.249198842793703, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 474, train_loss = 14.242075502872467, train_acc = 0.9680950163018165\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 475, train_loss = 14.236869805958122, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 476, train_loss = 14.232298105955124, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 477, train_loss = 14.224460443016142, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 478, train_loss = 14.218841633293778, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 479, train_loss = 14.211974711623043, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 480, train_loss = 14.208080308046192, train_acc = 0.9682114578481602\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 481, train_loss = 14.200620505958796, train_acc = 0.9683278993945039\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 482, train_loss = 14.195245490875095, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 483, train_loss = 14.19139871886, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 484, train_loss = 14.184194322675467, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 485, train_loss = 14.17880510399118, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 486, train_loss = 14.170644998550415, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 487, train_loss = 14.165521793067455, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 488, train_loss = 14.160208318382502, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 489, train_loss = 14.153725949581712, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 490, train_loss = 14.146918936166912, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 491, train_loss = 14.143295381218195, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 492, train_loss = 14.137961270753294, train_acc = 0.9684443409408477\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 493, train_loss = 14.13092644372955, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 494, train_loss = 14.126960518304259, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 495, train_loss = 14.12175776436925, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 496, train_loss = 14.113370476756245, train_acc = 0.9685607824871915\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 497, train_loss = 14.108941087964922, train_acc = 0.9686772240335352\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 498, train_loss = 14.105439936276525, train_acc = 0.9686772240335352\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 499, train_loss = 14.096903659403324, train_acc = 0.9686772240335352\n",
      "test Acc 0.9515828677839852:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████▌  | 29/30 [3:12:54<06:38, 398.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "30th- epoch: 0, train_loss = 275.1577503681183, train_acc = 0.45353982300884954\n",
      "test Acc 0.4972067039106145:\n",
      "30th- epoch: 1, train_loss = 218.24992871284485, train_acc = 0.4995342338146251\n",
      "test Acc 0.49906890130353815:\n",
      "30th- epoch: 2, train_loss = 183.35182547569275, train_acc = 0.5024452724732185\n",
      "test Acc 0.5083798882681564:\n",
      "30th- epoch: 3, train_loss = 165.95274138450623, train_acc = 0.524219841639497\n",
      "test Acc 0.5465549348230913:\n",
      "30th- epoch: 4, train_loss = 152.80524361133575, train_acc = 0.567768979972054\n",
      "test Acc 0.5986964618249534:\n",
      "30th- epoch: 5, train_loss = 141.04218620061874, train_acc = 0.6134140661387983\n",
      "test Acc 0.6345437616387337:\n",
      "30th- epoch: 6, train_loss = 130.0637320280075, train_acc = 0.6481136469492315\n",
      "test Acc 0.6657355679702048:\n",
      "30th- epoch: 7, train_loss = 119.99019855260849, train_acc = 0.6913134606427573\n",
      "test Acc 0.7546554934823091:\n",
      "30th- epoch: 8, train_loss = 110.90393149852753, train_acc = 0.7649045179319981\n",
      "test Acc 0.7774674115456238:\n",
      "30th- epoch: 9, train_loss = 102.74080455303192, train_acc = 0.7876106194690266\n",
      "test Acc 0.7956238361266295:\n",
      "30th- epoch: 10, train_loss = 95.40684705972672, train_acc = 0.808570097810899\n",
      "test Acc 0.8165735567970205:\n",
      "30th- epoch: 11, train_loss = 88.844009578228, train_acc = 0.8192827200745226\n",
      "test Acc 0.8268156424581006:\n",
      "30th- epoch: 12, train_loss = 82.99285396933556, train_acc = 0.8310433162552399\n",
      "test Acc 0.839851024208566:\n",
      "30th- epoch: 13, train_loss = 77.82064792513847, train_acc = 0.8417559385188635\n",
      "test Acc 0.8533519553072626:\n",
      "30th- epoch: 14, train_loss = 73.25469693541527, train_acc = 0.8525850023288309\n",
      "test Acc 0.861266294227188:\n",
      "30th- epoch: 15, train_loss = 69.21815124154091, train_acc = 0.8629482999534234\n",
      "test Acc 0.866852886405959:\n",
      "30th- epoch: 16, train_loss = 65.65054962038994, train_acc = 0.8687703772706101\n",
      "test Acc 0.8738361266294227:\n",
      "30th- epoch: 17, train_loss = 62.48316738009453, train_acc = 0.8731951560316721\n",
      "test Acc 0.8817504655493482:\n",
      "30th- epoch: 18, train_loss = 59.66783678531647, train_acc = 0.8762226362366092\n",
      "test Acc 0.8840782122905028:\n",
      "30th- epoch: 19, train_loss = 57.16562241315842, train_acc = 0.8814625058220773\n",
      "test Acc 0.8878026070763501:\n",
      "30th- epoch: 20, train_loss = 54.936036333441734, train_acc = 0.8847228691197019\n",
      "test Acc 0.8938547486033519:\n",
      "30th- epoch: 21, train_loss = 52.949217051267624, train_acc = 0.8886818816953889\n",
      "test Acc 0.8975791433891993:\n",
      "30th- epoch: 22, train_loss = 51.17838096618652, train_acc = 0.8922915696320447\n",
      "test Acc 0.8980446927374302:\n",
      "30th- epoch: 23, train_loss = 49.59717512130737, train_acc = 0.8942710759198882\n",
      "test Acc 0.8994413407821229:\n",
      "30th- epoch: 24, train_loss = 48.180290162563324, train_acc = 0.8970656730321379\n",
      "test Acc 0.9027001862197392:\n",
      "30th- epoch: 25, train_loss = 46.904459193348885, train_acc = 0.9011411271541686\n",
      "test Acc 0.9027001862197392:\n",
      "30th- epoch: 26, train_loss = 45.74983340501785, train_acc = 0.9025384257102934\n",
      "test Acc 0.9050279329608939:\n",
      "30th- epoch: 27, train_loss = 44.70259527862072, train_acc = 0.9034699580810434\n",
      "test Acc 0.9059590316573557:\n",
      "30th- epoch: 28, train_loss = 43.74583521485329, train_acc = 0.9052165812761993\n",
      "test Acc 0.9054934823091247:\n",
      "30th- epoch: 29, train_loss = 42.86771468818188, train_acc = 0.9064974382859804\n",
      "test Acc 0.9073556797020484:\n",
      "30th- epoch: 30, train_loss = 42.05832540988922, train_acc = 0.908011178388449\n",
      "test Acc 0.9078212290502793:\n",
      "30th- epoch: 31, train_loss = 41.30752803385258, train_acc = 0.9096413600372613\n",
      "test Acc 0.909683426443203:\n",
      "30th- epoch: 32, train_loss = 40.60744747519493, train_acc = 0.911504424778761\n",
      "test Acc 0.9120111731843575:\n",
      "30th- epoch: 33, train_loss = 39.9531981498003, train_acc = 0.9127852817885421\n",
      "test Acc 0.9129422718808193:\n",
      "30th- epoch: 34, train_loss = 39.33960497379303, train_acc = 0.9146483465300419\n",
      "test Acc 0.9129422718808193:\n",
      "30th- epoch: 35, train_loss = 38.76140978932381, train_acc = 0.9174429436422916\n",
      "test Acc 0.9143389199255121:\n",
      "30th- epoch: 36, train_loss = 38.215914741158485, train_acc = 0.9188402421984164\n",
      "test Acc 0.914804469273743:\n",
      "30th- epoch: 37, train_loss = 37.69794641435146, train_acc = 0.9196553330228225\n",
      "test Acc 0.9166666666666666:\n",
      "30th- epoch: 38, train_loss = 37.20408749580383, train_acc = 0.9203539823008849\n",
      "test Acc 0.9166666666666666:\n",
      "30th- epoch: 39, train_loss = 36.736164942383766, train_acc = 0.9215183977643223\n",
      "test Acc 0.9175977653631285:\n",
      "30th- epoch: 40, train_loss = 36.29134598374367, train_acc = 0.9226828132277597\n",
      "test Acc 0.9180633147113594:\n",
      "30th- epoch: 41, train_loss = 35.8667703717947, train_acc = 0.9236143455985095\n",
      "test Acc 0.9180633147113594:\n",
      "30th- epoch: 42, train_loss = 35.46182198822498, train_acc = 0.9239636702375408\n",
      "test Acc 0.9180633147113594:\n",
      "30th- epoch: 43, train_loss = 35.07447051256895, train_acc = 0.9241965533302282\n",
      "test Acc 0.9203910614525139:\n",
      "30th- epoch: 44, train_loss = 34.70342955738306, train_acc = 0.9250116441546343\n",
      "test Acc 0.9217877094972067:\n",
      "30th- epoch: 45, train_loss = 34.34737899899483, train_acc = 0.9257102934326968\n",
      "test Acc 0.9222532588454376:\n",
      "30th- epoch: 46, train_loss = 34.0053816139698, train_acc = 0.9264089427107592\n",
      "test Acc 0.9227188081936686:\n",
      "30th- epoch: 47, train_loss = 33.67638706415892, train_acc = 0.9271075919888216\n",
      "test Acc 0.9231843575418994:\n",
      "30th- epoch: 48, train_loss = 33.35953960567713, train_acc = 0.927806241266884\n",
      "test Acc 0.9241154562383612:\n",
      "30th- epoch: 49, train_loss = 33.05297631025314, train_acc = 0.9285048905449464\n",
      "test Acc 0.9245810055865922:\n",
      "30th- epoch: 50, train_loss = 32.75678443163633, train_acc = 0.9289706567303214\n",
      "test Acc 0.9245810055865922:\n",
      "30th- epoch: 51, train_loss = 32.471227921545506, train_acc = 0.9294364229156963\n",
      "test Acc 0.925512104283054:\n",
      "30th- epoch: 52, train_loss = 32.1943332105875, train_acc = 0.930018630647415\n",
      "test Acc 0.925512104283054:\n",
      "30th- epoch: 53, train_loss = 31.925977617502213, train_acc = 0.9303679552864462\n",
      "test Acc 0.925512104283054:\n",
      "30th- epoch: 54, train_loss = 31.66510270535946, train_acc = 0.9304843968327899\n",
      "test Acc 0.925512104283054:\n",
      "30th- epoch: 55, train_loss = 31.411867193877697, train_acc = 0.9310666045645086\n",
      "test Acc 0.9259776536312849:\n",
      "30th- epoch: 56, train_loss = 31.165706418454647, train_acc = 0.9314159292035398\n",
      "test Acc 0.9264432029795159:\n",
      "30th- epoch: 57, train_loss = 30.925983510911465, train_acc = 0.9321145784816023\n",
      "test Acc 0.9269087523277467:\n",
      "30th- epoch: 58, train_loss = 30.692252278327942, train_acc = 0.9326967862133209\n",
      "test Acc 0.9283054003724395:\n",
      "30th- epoch: 59, train_loss = 30.465341836214066, train_acc = 0.9331625523986958\n",
      "test Acc 0.9283054003724395:\n",
      "30th- epoch: 60, train_loss = 30.243592403829098, train_acc = 0.9332789939450395\n",
      "test Acc 0.9283054003724395:\n",
      "30th- epoch: 61, train_loss = 30.027163848280907, train_acc = 0.9337447601304145\n",
      "test Acc 0.9287709497206704:\n",
      "30th- epoch: 62, train_loss = 29.81557760387659, train_acc = 0.9342105263157895\n",
      "test Acc 0.9287709497206704:\n",
      "30th- epoch: 63, train_loss = 29.608549527823925, train_acc = 0.9342105263157895\n",
      "test Acc 0.9287709497206704:\n",
      "30th- epoch: 64, train_loss = 29.40592932701111, train_acc = 0.9343269678621332\n",
      "test Acc 0.9287709497206704:\n",
      "30th- epoch: 65, train_loss = 29.208081535995007, train_acc = 0.9344434094084769\n",
      "test Acc 0.9287709497206704:\n",
      "30th- epoch: 66, train_loss = 29.013548746705055, train_acc = 0.9350256171401956\n",
      "test Acc 0.9287709497206704:\n",
      "30th- epoch: 67, train_loss = 28.82385439425707, train_acc = 0.9351420586865393\n",
      "test Acc 0.9287709497206704:\n",
      "30th- epoch: 68, train_loss = 28.63770592957735, train_acc = 0.9354913833255706\n",
      "test Acc 0.9292364990689013:\n",
      "30th- epoch: 69, train_loss = 28.45579931885004, train_acc = 0.935724266418258\n",
      "test Acc 0.9297020484171322:\n",
      "30th- epoch: 70, train_loss = 28.276941440999508, train_acc = 0.935724266418258\n",
      "test Acc 0.9301675977653632:\n",
      "30th- epoch: 71, train_loss = 28.102287493646145, train_acc = 0.9359571495109456\n",
      "test Acc 0.9301675977653632:\n",
      "30th- epoch: 72, train_loss = 27.930966176092625, train_acc = 0.9364229156963204\n",
      "test Acc 0.9301675977653632:\n",
      "30th- epoch: 73, train_loss = 27.762604638934135, train_acc = 0.9367722403353517\n",
      "test Acc 0.9301675977653632:\n",
      "30th- epoch: 74, train_loss = 27.597207866609097, train_acc = 0.9368886818816954\n",
      "test Acc 0.9301675977653632:\n",
      "30th- epoch: 75, train_loss = 27.43502912670374, train_acc = 0.9372380065207266\n",
      "test Acc 0.9301675977653632:\n",
      "30th- epoch: 76, train_loss = 27.27529163658619, train_acc = 0.9373544480670704\n",
      "test Acc 0.9301675977653632:\n",
      "30th- epoch: 77, train_loss = 27.119190469384193, train_acc = 0.9377037727061015\n",
      "test Acc 0.9297020484171322:\n",
      "30th- epoch: 78, train_loss = 26.96549518406391, train_acc = 0.9380530973451328\n",
      "test Acc 0.9297020484171322:\n",
      "30th- epoch: 79, train_loss = 26.815166264772415, train_acc = 0.9387517466231952\n",
      "test Acc 0.9301675977653632:\n",
      "30th- epoch: 80, train_loss = 26.667484529316425, train_acc = 0.9395668374476013\n",
      "test Acc 0.9297020484171322:\n",
      "30th- epoch: 81, train_loss = 26.52102790772915, train_acc = 0.9397997205402888\n",
      "test Acc 0.930633147113594:\n",
      "30th- epoch: 82, train_loss = 26.378107503056526, train_acc = 0.9400326036329762\n",
      "test Acc 0.931098696461825:\n",
      "30th- epoch: 83, train_loss = 26.23724925145507, train_acc = 0.9404983698183512\n",
      "test Acc 0.931098696461825:\n",
      "30th- epoch: 84, train_loss = 26.09950502961874, train_acc = 0.9404983698183512\n",
      "test Acc 0.931098696461825:\n",
      "30th- epoch: 85, train_loss = 25.964317854493856, train_acc = 0.9407312529110387\n",
      "test Acc 0.931098696461825:\n",
      "30th- epoch: 86, train_loss = 25.8301069624722, train_acc = 0.9411970190964136\n",
      "test Acc 0.931098696461825:\n",
      "30th- epoch: 87, train_loss = 25.69946353137493, train_acc = 0.941429902189101\n",
      "test Acc 0.9315642458100558:\n",
      "30th- epoch: 88, train_loss = 25.5706737190485, train_acc = 0.9416627852817886\n",
      "test Acc 0.9315642458100558:\n",
      "30th- epoch: 89, train_loss = 25.443871054798365, train_acc = 0.941895668374476\n",
      "test Acc 0.9315642458100558:\n",
      "30th- epoch: 90, train_loss = 25.319500382989645, train_acc = 0.9425943176525384\n",
      "test Acc 0.9315642458100558:\n",
      "30th- epoch: 91, train_loss = 25.19685834273696, train_acc = 0.9428272007452259\n",
      "test Acc 0.9315642458100558:\n",
      "30th- epoch: 92, train_loss = 25.076643519103527, train_acc = 0.9435258500232883\n",
      "test Acc 0.9320297951582868:\n",
      "30th- epoch: 93, train_loss = 24.958544727414846, train_acc = 0.9435258500232883\n",
      "test Acc 0.9320297951582868:\n",
      "30th- epoch: 94, train_loss = 24.841059654951096, train_acc = 0.9437587331159758\n",
      "test Acc 0.9320297951582868:\n",
      "30th- epoch: 95, train_loss = 24.7261835411191, train_acc = 0.9442244993013508\n",
      "test Acc 0.9324953445065177:\n",
      "30th- epoch: 96, train_loss = 24.61279085278511, train_acc = 0.9443409408476945\n",
      "test Acc 0.9329608938547486:\n",
      "30th- epoch: 97, train_loss = 24.501478917896748, train_acc = 0.9448067070330693\n",
      "test Acc 0.9329608938547486:\n",
      "30th- epoch: 98, train_loss = 24.39212327450514, train_acc = 0.9448067070330693\n",
      "test Acc 0.9329608938547486:\n",
      "30th- epoch: 99, train_loss = 24.28542250394821, train_acc = 0.9449231485794132\n",
      "test Acc 0.9334264432029795:\n",
      "30th- epoch: 100, train_loss = 24.18008280918002, train_acc = 0.9451560316721006\n",
      "test Acc 0.9334264432029795:\n",
      "30th- epoch: 101, train_loss = 24.076505947858095, train_acc = 0.9452724732184443\n",
      "test Acc 0.9338919925512105:\n",
      "30th- epoch: 102, train_loss = 23.97488310933113, train_acc = 0.9455053563111319\n",
      "test Acc 0.9338919925512105:\n",
      "30th- epoch: 103, train_loss = 23.8756952136755, train_acc = 0.9457382394038193\n",
      "test Acc 0.9338919925512105:\n",
      "30th- epoch: 104, train_loss = 23.7770263440907, train_acc = 0.9460875640428504\n",
      "test Acc 0.9338919925512105:\n",
      "30th- epoch: 105, train_loss = 23.679264228791, train_acc = 0.946786213320913\n",
      "test Acc 0.9343575418994413:\n",
      "30th- epoch: 106, train_loss = 23.58471879735589, train_acc = 0.9469026548672567\n",
      "test Acc 0.9352886405959032:\n",
      "30th- epoch: 107, train_loss = 23.489722855389118, train_acc = 0.9469026548672567\n",
      "test Acc 0.9352886405959032:\n",
      "30th- epoch: 108, train_loss = 23.39738478884101, train_acc = 0.9470190964136004\n",
      "test Acc 0.9352886405959032:\n",
      "30th- epoch: 109, train_loss = 23.307448588311672, train_acc = 0.9470190964136004\n",
      "test Acc 0.9357541899441341:\n",
      "30th- epoch: 110, train_loss = 23.217802606523037, train_acc = 0.9474848625989754\n",
      "test Acc 0.9357541899441341:\n",
      "30th- epoch: 111, train_loss = 23.128787372261286, train_acc = 0.9478341872380065\n",
      "test Acc 0.936219739292365:\n",
      "30th- epoch: 112, train_loss = 23.043337158858776, train_acc = 0.9478341872380065\n",
      "test Acc 0.9366852886405959:\n",
      "30th- epoch: 113, train_loss = 22.95690730959177, train_acc = 0.948067070330694\n",
      "test Acc 0.9366852886405959:\n",
      "30th- epoch: 114, train_loss = 22.87372988462448, train_acc = 0.9484163949697252\n",
      "test Acc 0.9366852886405959:\n",
      "30th- epoch: 115, train_loss = 22.789985962212086, train_acc = 0.9484163949697252\n",
      "test Acc 0.9366852886405959:\n",
      "30th- epoch: 116, train_loss = 22.709464266896248, train_acc = 0.9486492780624126\n",
      "test Acc 0.9371508379888268:\n",
      "30th- epoch: 117, train_loss = 22.629354506731033, train_acc = 0.9488821611551002\n",
      "test Acc 0.9376163873370578:\n",
      "30th- epoch: 118, train_loss = 22.55030284821987, train_acc = 0.9489986027014439\n",
      "test Acc 0.9380819366852886:\n",
      "30th- epoch: 119, train_loss = 22.472022853791714, train_acc = 0.9491150442477876\n",
      "test Acc 0.9385474860335196:\n",
      "30th- epoch: 120, train_loss = 22.395009513944387, train_acc = 0.9492314857941313\n",
      "test Acc 0.9385474860335196:\n",
      "30th- epoch: 121, train_loss = 22.31840305775404, train_acc = 0.9492314857941313\n",
      "test Acc 0.9385474860335196:\n",
      "30th- epoch: 122, train_loss = 22.245014615356922, train_acc = 0.9494643688868188\n",
      "test Acc 0.9385474860335196:\n",
      "30th- epoch: 123, train_loss = 22.17093888297677, train_acc = 0.9494643688868188\n",
      "test Acc 0.9385474860335196:\n",
      "30th- epoch: 124, train_loss = 22.097890976816416, train_acc = 0.9495808104331626\n",
      "test Acc 0.9390130353817505:\n",
      "30th- epoch: 125, train_loss = 22.026423178613186, train_acc = 0.9496972519795063\n",
      "test Acc 0.9390130353817505:\n",
      "30th- epoch: 126, train_loss = 21.955329190939665, train_acc = 0.9499301350721937\n",
      "test Acc 0.9394785847299814:\n",
      "30th- epoch: 127, train_loss = 21.88542190939188, train_acc = 0.9499301350721937\n",
      "test Acc 0.9394785847299814:\n",
      "30th- epoch: 128, train_loss = 21.816673409193754, train_acc = 0.950279459711225\n",
      "test Acc 0.9394785847299814:\n",
      "30th- epoch: 129, train_loss = 21.748579125851393, train_acc = 0.9503959012575687\n",
      "test Acc 0.9394785847299814:\n",
      "30th- epoch: 130, train_loss = 21.682270042598248, train_acc = 0.9503959012575687\n",
      "test Acc 0.9399441340782123:\n",
      "30th- epoch: 131, train_loss = 21.614301964640617, train_acc = 0.9505123428039124\n",
      "test Acc 0.9399441340782123:\n",
      "30th- epoch: 132, train_loss = 21.55052885785699, train_acc = 0.9505123428039124\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 133, train_loss = 21.484623342752457, train_acc = 0.9505123428039124\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 134, train_loss = 21.421049654483795, train_acc = 0.9507452258965999\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 135, train_loss = 21.357924915850163, train_acc = 0.9508616674429436\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 136, train_loss = 21.29599265381694, train_acc = 0.9510945505356311\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 137, train_loss = 21.234109356999397, train_acc = 0.9513274336283186\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 138, train_loss = 21.17296053096652, train_acc = 0.9513274336283186\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 139, train_loss = 21.113365475088358, train_acc = 0.9514438751746623\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 140, train_loss = 21.05335985124111, train_acc = 0.9521425244527247\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 141, train_loss = 20.9943935200572, train_acc = 0.9523754075454122\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 142, train_loss = 20.936373364180326, train_acc = 0.9523754075454122\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 143, train_loss = 20.87811092287302, train_acc = 0.952491849091756\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 144, train_loss = 20.821146059781313, train_acc = 0.9526082906380997\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 145, train_loss = 20.76562624424696, train_acc = 0.9527247321844434\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 146, train_loss = 20.710113987326622, train_acc = 0.9530740568234746\n",
      "test Acc 0.9408752327746741:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 147, train_loss = 20.65340630710125, train_acc = 0.9533069399161621\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 148, train_loss = 20.59879305586219, train_acc = 0.9533069399161621\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 149, train_loss = 20.545610666275024, train_acc = 0.9534233814625058\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 150, train_loss = 20.491111904382706, train_acc = 0.9534233814625058\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 151, train_loss = 20.43780729547143, train_acc = 0.9535398230088495\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 152, train_loss = 20.38763179630041, train_acc = 0.9536562645551933\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 153, train_loss = 20.335680548101664, train_acc = 0.9536562645551933\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 154, train_loss = 20.282532339915633, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 155, train_loss = 20.233296303078532, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 156, train_loss = 20.183480566367507, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 157, train_loss = 20.13410048186779, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 158, train_loss = 20.082895761355758, train_acc = 0.9540055891942245\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 159, train_loss = 20.036522349342704, train_acc = 0.9538891476478808\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 160, train_loss = 19.98866888321936, train_acc = 0.9538891476478808\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 161, train_loss = 19.940819093957543, train_acc = 0.9540055891942245\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 162, train_loss = 19.89383445121348, train_acc = 0.9541220307405682\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 163, train_loss = 19.845524977892637, train_acc = 0.9544713553795995\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 164, train_loss = 19.800154810771346, train_acc = 0.9548206800186306\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 165, train_loss = 19.754604630172253, train_acc = 0.9548206800186306\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 166, train_loss = 19.70868186093867, train_acc = 0.9548206800186306\n",
      "test Acc 0.9413407821229051:\n",
      "30th- epoch: 167, train_loss = 19.661736899986863, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "30th- epoch: 168, train_loss = 19.618953198194504, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "30th- epoch: 169, train_loss = 19.574788564816117, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "30th- epoch: 170, train_loss = 19.53052444383502, train_acc = 0.9549371215649743\n",
      "test Acc 0.9418063314711359:\n",
      "30th- epoch: 171, train_loss = 19.486423771828413, train_acc = 0.9549371215649743\n",
      "test Acc 0.9422718808193669:\n",
      "30th- epoch: 172, train_loss = 19.444485111162066, train_acc = 0.9549371215649743\n",
      "test Acc 0.9422718808193669:\n",
      "30th- epoch: 173, train_loss = 19.40155759640038, train_acc = 0.9551700046576619\n",
      "test Acc 0.9427374301675978:\n",
      "30th- epoch: 174, train_loss = 19.35924299247563, train_acc = 0.9551700046576619\n",
      "test Acc 0.9427374301675978:\n",
      "30th- epoch: 175, train_loss = 19.31831549666822, train_acc = 0.955519329296693\n",
      "test Acc 0.9427374301675978:\n",
      "30th- epoch: 176, train_loss = 19.276207141578197, train_acc = 0.955519329296693\n",
      "test Acc 0.9427374301675978:\n",
      "30th- epoch: 177, train_loss = 19.23413902334869, train_acc = 0.9556357708430367\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 178, train_loss = 19.195290191099048, train_acc = 0.9557522123893806\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 179, train_loss = 19.15464821830392, train_acc = 0.955985095482068\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 180, train_loss = 19.115080969408154, train_acc = 0.9561015370284117\n",
      "test Acc 0.9436685288640596:\n",
      "30th- epoch: 181, train_loss = 19.075630512088537, train_acc = 0.9561015370284117\n",
      "test Acc 0.9436685288640596:\n",
      "30th- epoch: 182, train_loss = 19.036759505048394, train_acc = 0.9562179785747554\n",
      "test Acc 0.9436685288640596:\n",
      "30th- epoch: 183, train_loss = 18.99808856099844, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "30th- epoch: 184, train_loss = 18.96104503981769, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "30th- epoch: 185, train_loss = 18.922664476558566, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "30th- epoch: 186, train_loss = 18.88534996472299, train_acc = 0.9565673032137867\n",
      "test Acc 0.9441340782122905:\n",
      "30th- epoch: 187, train_loss = 18.847562696784735, train_acc = 0.9566837447601304\n",
      "test Acc 0.9441340782122905:\n",
      "30th- epoch: 188, train_loss = 18.811926720663905, train_acc = 0.9568001863064741\n",
      "test Acc 0.9441340782122905:\n",
      "30th- epoch: 189, train_loss = 18.77547337114811, train_acc = 0.9570330693991617\n",
      "test Acc 0.9441340782122905:\n",
      "30th- epoch: 190, train_loss = 18.739405488595366, train_acc = 0.9572659524918491\n",
      "test Acc 0.9441340782122905:\n",
      "30th- epoch: 191, train_loss = 18.703115537762642, train_acc = 0.9572659524918491\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 192, train_loss = 18.667467249557376, train_acc = 0.9573823940381928\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 193, train_loss = 18.63185746781528, train_acc = 0.9576152771308803\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 194, train_loss = 18.59728562273085, train_acc = 0.9579646017699115\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 195, train_loss = 18.562742771580815, train_acc = 0.9579646017699115\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 196, train_loss = 18.528347086161375, train_acc = 0.9581974848625989\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 197, train_loss = 18.49521316215396, train_acc = 0.9581974848625989\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 198, train_loss = 18.460684528574347, train_acc = 0.9585468095016302\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 199, train_loss = 18.428492633625865, train_acc = 0.9584303679552865\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 200, train_loss = 18.394580321386456, train_acc = 0.9585468095016302\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 201, train_loss = 18.362279310822487, train_acc = 0.9585468095016302\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 202, train_loss = 18.329698944464326, train_acc = 0.9585468095016302\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 203, train_loss = 18.295854041352868, train_acc = 0.9585468095016302\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 204, train_loss = 18.264781836420298, train_acc = 0.9584303679552865\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 205, train_loss = 18.234020119532943, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 206, train_loss = 18.200825087726116, train_acc = 0.9586632510479739\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 207, train_loss = 18.16983321495354, train_acc = 0.9586632510479739\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 208, train_loss = 18.140202343463898, train_acc = 0.9584303679552865\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 209, train_loss = 18.109390633180737, train_acc = 0.9586632510479739\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 210, train_loss = 18.077688856050372, train_acc = 0.9586632510479739\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 211, train_loss = 18.0484262611717, train_acc = 0.9587796925943176\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 212, train_loss = 18.017412254586816, train_acc = 0.9588961341406614\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 213, train_loss = 17.988992555066943, train_acc = 0.9587796925943176\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 214, train_loss = 17.957592625170946, train_acc = 0.9588961341406614\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 215, train_loss = 17.93023374862969, train_acc = 0.9591290172333489\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 216, train_loss = 17.9011548217386, train_acc = 0.9592454587796926\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 217, train_loss = 17.872338991612196, train_acc = 0.9592454587796926\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 218, train_loss = 17.84370367974043, train_acc = 0.9592454587796926\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 219, train_loss = 17.815460335463285, train_acc = 0.95947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 220, train_loss = 17.787854751572013, train_acc = 0.95947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 221, train_loss = 17.760633796453476, train_acc = 0.9595947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 222, train_loss = 17.73198400810361, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 223, train_loss = 17.706057799980044, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 224, train_loss = 17.67789245583117, train_acc = 0.9597112249650676\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 225, train_loss = 17.651227924972773, train_acc = 0.9598276665114113\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 226, train_loss = 17.624398788437247, train_acc = 0.959944108057755\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 227, train_loss = 17.59755412861705, train_acc = 0.959944108057755\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 228, train_loss = 17.572030479088426, train_acc = 0.9600605496040987\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 229, train_loss = 17.545617366209626, train_acc = 0.9600605496040987\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 230, train_loss = 17.520448502153158, train_acc = 0.9601769911504425\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 231, train_loss = 17.495100785046816, train_acc = 0.9602934326967862\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 232, train_loss = 17.46938776783645, train_acc = 0.96040987424313\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 233, train_loss = 17.443277714774013, train_acc = 0.9605263157894737\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 234, train_loss = 17.419276474043727, train_acc = 0.9606427573358174\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 235, train_loss = 17.394608564674854, train_acc = 0.9606427573358174\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 236, train_loss = 17.370360070839524, train_acc = 0.9606427573358174\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 237, train_loss = 17.344870710745454, train_acc = 0.9606427573358174\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 238, train_loss = 17.321039719507098, train_acc = 0.9607591988821611\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 239, train_loss = 17.29732397943735, train_acc = 0.9608756404285049\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 240, train_loss = 17.27397516462952, train_acc = 0.9608756404285049\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 241, train_loss = 17.249807957559824, train_acc = 0.9608756404285049\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 242, train_loss = 17.225618235766888, train_acc = 0.9609920819748486\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 243, train_loss = 17.202935934998095, train_acc = 0.9609920819748486\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 244, train_loss = 17.17962529603392, train_acc = 0.9612249650675361\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 245, train_loss = 17.157287339679897, train_acc = 0.9612249650675361\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 246, train_loss = 17.133714980445802, train_acc = 0.9613414066138798\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 247, train_loss = 17.112025145441294, train_acc = 0.9613414066138798\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 248, train_loss = 17.089511367492378, train_acc = 0.9614578481602236\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 249, train_loss = 17.067059793509543, train_acc = 0.961690731252911\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 250, train_loss = 17.045381446368992, train_acc = 0.9618071727992548\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 251, train_loss = 17.022898013703525, train_acc = 0.9618071727992548\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 252, train_loss = 17.000753252767026, train_acc = 0.9619236143455985\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 253, train_loss = 16.979781919158995, train_acc = 0.9619236143455985\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 254, train_loss = 16.958590105175972, train_acc = 0.9619236143455985\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 255, train_loss = 16.937053374014795, train_acc = 0.9619236143455985\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 256, train_loss = 16.91626162547618, train_acc = 0.9620400558919422\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 257, train_loss = 16.89435153733939, train_acc = 0.962156497438286\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 258, train_loss = 16.873854300938547, train_acc = 0.962156497438286\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 259, train_loss = 16.85299959499389, train_acc = 0.9623893805309734\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 260, train_loss = 16.833443351089954, train_acc = 0.9623893805309734\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 261, train_loss = 16.812428697012365, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 262, train_loss = 16.791604910045862, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 263, train_loss = 16.77260489668697, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 264, train_loss = 16.751402084715664, train_acc = 0.9627387051700047\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 265, train_loss = 16.73292652890086, train_acc = 0.9627387051700047\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 266, train_loss = 16.711957498453557, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 267, train_loss = 16.69342606049031, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 268, train_loss = 16.672743764705956, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 269, train_loss = 16.654195476323366, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 270, train_loss = 16.63479697331786, train_acc = 0.9628551467163484\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 271, train_loss = 16.615774183534086, train_acc = 0.9629715882626921\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 272, train_loss = 16.597196734510362, train_acc = 0.9630880298090359\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 273, train_loss = 16.578218032605946, train_acc = 0.9632044713553796\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 274, train_loss = 16.560061211697757, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 275, train_loss = 16.541274703107774, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 276, train_loss = 16.521689015440643, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 277, train_loss = 16.503157100640237, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 278, train_loss = 16.48477623704821, train_acc = 0.9633209129017233\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 279, train_loss = 16.467005908489227, train_acc = 0.9633209129017233\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 280, train_loss = 16.44876097422093, train_acc = 0.9632044713553796\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 281, train_loss = 16.431707085110247, train_acc = 0.9632044713553796\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 282, train_loss = 16.413557306863368, train_acc = 0.9634373544480671\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 283, train_loss = 16.395658738911152, train_acc = 0.9635537959944108\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 284, train_loss = 16.378836050629616, train_acc = 0.9635537959944108\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 285, train_loss = 16.361414692364633, train_acc = 0.9636702375407545\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 286, train_loss = 16.344265175051987, train_acc = 0.9636702375407545\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 287, train_loss = 16.325714197009802, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 288, train_loss = 16.30958802718669, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 289, train_loss = 16.292935608886182, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 290, train_loss = 16.275009736418724, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 291, train_loss = 16.259346019476652, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 292, train_loss = 16.2420802609995, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 293, train_loss = 16.225988012738526, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 294, train_loss = 16.209628324955702, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 295, train_loss = 16.193424730561674, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 296, train_loss = 16.177657230757177, train_acc = 0.9641360037261295\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 297, train_loss = 16.160702380351722, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 298, train_loss = 16.145650467835367, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 299, train_loss = 16.128482929430902, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 300, train_loss = 16.11227645445615, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 301, train_loss = 16.097456332296133, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 302, train_loss = 16.080978124402463, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 303, train_loss = 16.066369850188494, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 304, train_loss = 16.051141913980246, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 305, train_loss = 16.03592459205538, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 306, train_loss = 16.019287679344416, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 307, train_loss = 16.004138693213463, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 308, train_loss = 15.98950161319226, train_acc = 0.9642524452724732\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 309, train_loss = 15.974843367934227, train_acc = 0.9643688868188169\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 310, train_loss = 15.960498529486358, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 311, train_loss = 15.944902024231851, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 312, train_loss = 15.930795274674892, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 313, train_loss = 15.916175295598805, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 314, train_loss = 15.901371591724455, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 315, train_loss = 15.886747281998396, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 316, train_loss = 15.872824345715344, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 317, train_loss = 15.857122365385294, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 318, train_loss = 15.84440450090915, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 319, train_loss = 15.82954457681626, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 320, train_loss = 15.81536986026913, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 321, train_loss = 15.801725931465626, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 322, train_loss = 15.786466289311647, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 323, train_loss = 15.774123809300363, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 324, train_loss = 15.760713015682995, train_acc = 0.9648346530041919\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 325, train_loss = 15.746437289752066, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 326, train_loss = 15.733371566049755, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 327, train_loss = 15.72001373860985, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 328, train_loss = 15.705521286465228, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 329, train_loss = 15.692924628965557, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 330, train_loss = 15.679541560821235, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 331, train_loss = 15.666303337551653, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 332, train_loss = 15.652091407217085, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 333, train_loss = 15.63995719421655, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 334, train_loss = 15.625594966113567, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 335, train_loss = 15.613658096641302, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 336, train_loss = 15.600335519760847, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 337, train_loss = 15.587337848730385, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 338, train_loss = 15.574862937442958, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 339, train_loss = 15.56309271696955, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 340, train_loss = 15.549994288943708, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 341, train_loss = 15.53779489826411, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 342, train_loss = 15.524976409971714, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 343, train_loss = 15.511920654214919, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 344, train_loss = 15.50000989343971, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 345, train_loss = 15.486934839747846, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 346, train_loss = 15.474585335701704, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 347, train_loss = 15.463618290610611, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 348, train_loss = 15.450922351330519, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 349, train_loss = 15.43813159596175, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 350, train_loss = 15.42851272970438, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 351, train_loss = 15.415872965939343, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 352, train_loss = 15.404266182333231, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 353, train_loss = 15.392356893979013, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 354, train_loss = 15.380071894265711, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 355, train_loss = 15.369597717188299, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 356, train_loss = 15.35718264337629, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 357, train_loss = 15.34631833434105, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 358, train_loss = 15.333625733852386, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 359, train_loss = 15.323745280504227, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 360, train_loss = 15.311447313986719, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 361, train_loss = 15.3014324195683, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 362, train_loss = 15.289356882683933, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 363, train_loss = 15.279260949231684, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 364, train_loss = 15.267911154776812, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 365, train_loss = 15.257126868702471, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 366, train_loss = 15.242650494910777, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 367, train_loss = 15.228164690546691, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 368, train_loss = 15.21753949020058, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 369, train_loss = 15.207198618911207, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 370, train_loss = 15.196325206197798, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 371, train_loss = 15.18625304941088, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 372, train_loss = 15.17500129621476, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 373, train_loss = 15.166102624498308, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 374, train_loss = 15.154403239488602, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 375, train_loss = 15.143640884198248, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 376, train_loss = 15.133944398723543, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 377, train_loss = 15.120627328753471, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 378, train_loss = 15.1103221392259, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 379, train_loss = 15.100127842277288, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 380, train_loss = 15.088837469927967, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 381, train_loss = 15.078377439640462, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 382, train_loss = 15.069084425456822, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 383, train_loss = 15.058996976353228, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 384, train_loss = 15.049222719855607, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 385, train_loss = 15.040139552205801, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 386, train_loss = 15.028689169324934, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 387, train_loss = 15.01996057946235, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 388, train_loss = 15.009789917618036, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 389, train_loss = 14.9995574997738, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 390, train_loss = 14.990486085414886, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 391, train_loss = 14.98048724513501, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 392, train_loss = 14.9707354856655, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 393, train_loss = 14.962017905898392, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 394, train_loss = 14.952184355817735, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 395, train_loss = 14.942364084534347, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 396, train_loss = 14.931622449308634, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 397, train_loss = 14.921429461799562, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 398, train_loss = 14.91110875736922, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 399, train_loss = 14.903423145413399, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 400, train_loss = 14.893691916950047, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 401, train_loss = 14.882471542805433, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 402, train_loss = 14.875641868449748, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 403, train_loss = 14.865870811976492, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 404, train_loss = 14.857624483294785, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 405, train_loss = 14.847282897680998, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 406, train_loss = 14.838977333158255, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 407, train_loss = 14.830865710042417, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 408, train_loss = 14.820234556682408, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 409, train_loss = 14.811776327900589, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 410, train_loss = 14.80181370396167, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 411, train_loss = 14.7946907421574, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 412, train_loss = 14.785423475317657, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "30th- epoch: 413, train_loss = 14.776850634254515, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "30th- epoch: 414, train_loss = 14.767522152513266, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "30th- epoch: 415, train_loss = 14.758853990584612, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "30th- epoch: 416, train_loss = 14.74966786056757, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "30th- epoch: 417, train_loss = 14.742017707321793, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "30th- epoch: 418, train_loss = 14.732480184640735, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "30th- epoch: 419, train_loss = 14.724430789705366, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "30th- epoch: 420, train_loss = 14.71483987942338, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "30th- epoch: 421, train_loss = 14.707216788083315, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "30th- epoch: 422, train_loss = 14.699001621454954, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "30th- epoch: 423, train_loss = 14.69008323783055, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 424, train_loss = 14.680888590868562, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 425, train_loss = 14.673707568552345, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 426, train_loss = 14.66281666001305, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 427, train_loss = 14.656498532742262, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 428, train_loss = 14.648646457586437, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 429, train_loss = 14.641296353191137, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 430, train_loss = 14.63313768291846, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 431, train_loss = 14.62535256659612, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 432, train_loss = 14.616781310644, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 433, train_loss = 14.60642654588446, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 434, train_loss = 14.600124726537615, train_acc = 0.9670470423847228\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 435, train_loss = 14.592261753976345, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 436, train_loss = 14.583208665251732, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 437, train_loss = 14.576654041651636, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 438, train_loss = 14.569093292113394, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 439, train_loss = 14.5615842952393, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 440, train_loss = 14.553631775081158, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 441, train_loss = 14.545517895370722, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 442, train_loss = 14.53831017529592, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 443, train_loss = 14.53126047551632, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 444, train_loss = 14.524098029825836, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 445, train_loss = 14.516196390148252, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 446, train_loss = 14.508545027580112, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 447, train_loss = 14.499295888002962, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 448, train_loss = 14.492977203335613, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 449, train_loss = 14.48391841351986, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 450, train_loss = 14.478419554885477, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 451, train_loss = 14.46973946178332, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 452, train_loss = 14.461775310337543, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 453, train_loss = 14.455425377935171, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 454, train_loss = 14.44846415007487, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 455, train_loss = 14.441225384827703, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 456, train_loss = 14.433282971382141, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 457, train_loss = 14.426664404571056, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 458, train_loss = 14.418841888662428, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 459, train_loss = 14.412567025516182, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 460, train_loss = 14.406697286758572, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 461, train_loss = 14.399831327144057, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 462, train_loss = 14.391918825451285, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 463, train_loss = 14.384166738484055, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 464, train_loss = 14.376236719544977, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 465, train_loss = 14.368496384471655, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 466, train_loss = 14.36112072924152, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 467, train_loss = 14.356777677778155, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 468, train_loss = 14.347470035310835, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 469, train_loss = 14.340660944581032, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 470, train_loss = 14.335278816521168, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 471, train_loss = 14.328400621656328, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 472, train_loss = 14.31861699745059, train_acc = 0.9675128085700978\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 473, train_loss = 14.312646077480167, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 474, train_loss = 14.3068318949081, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 475, train_loss = 14.299666217062622, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "30th- epoch: 476, train_loss = 14.293220188468695, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 477, train_loss = 14.28524856036529, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 478, train_loss = 14.27945801615715, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 479, train_loss = 14.272927768528461, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 480, train_loss = 14.266974522266537, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 481, train_loss = 14.261011142283678, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 482, train_loss = 14.254451248794794, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 483, train_loss = 14.247668139636517, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 484, train_loss = 14.241044666618109, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 485, train_loss = 14.235179734881967, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 486, train_loss = 14.228789504617453, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 487, train_loss = 14.221907325088978, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 488, train_loss = 14.217418768908828, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 489, train_loss = 14.209399700164795, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 490, train_loss = 14.203059037681669, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 491, train_loss = 14.198546148836613, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 492, train_loss = 14.190848300699145, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 493, train_loss = 14.18592863669619, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 494, train_loss = 14.178423711564392, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 495, train_loss = 14.172450660262257, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 496, train_loss = 14.165844826493412, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 497, train_loss = 14.162318868096918, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 498, train_loss = 14.154220536351204, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 499, train_loss = 14.149945626500994, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 30/30 [3:19:34<00:00, 399.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3h 19min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    img_path = 'D:virus/image/1gram_512_pca/image_arr.npy'\n",
    "    label_path = 'D:virus/image/1gram_512_pca/label_arr.npy'\n",
    "    \n",
    "    data_a, label_a = np.load(img_path), np.load(label_path)\n",
    "    \n",
    "    idx = np.argsort(label_a)\n",
    "    \n",
    "    sorted_data = data_a[idx]\n",
    "    sorted_label = sorted(label_a)\n",
    "        \n",
    "    BATCH_SIZE = 64\n",
    "    TOTAL = 30\n",
    "    EPOCH = 500\n",
    "    NUM_CLASS = 9\n",
    "    LR = 0.005\n",
    "    SEED = [s for s in range(TOTAL)]\n",
    "    INPUT_NODES = 512                   \n",
    "    \n",
    "    CUDA_N = 'cuda:0'\n",
    "    \n",
    "    # creating data indices for spliting\n",
    "    full_dataset = CustomDataset(sorted_data, sorted_label)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # spliting\n",
    "    torch.manual_seed(10)\n",
    "    train_dataset, test_dataset = data.random_split(full_dataset, [train_size, test_size])\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    loss_total = []\n",
    "    acc_total = []\n",
    "    pred_total = []\n",
    "    true_total = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(TOTAL)):\n",
    "        \n",
    "        device = torch.device(CUDA_N if torch.cuda.is_available() else 'cpu')\n",
    "        torch.manual_seed(SEED[i])\n",
    "        net = MCSP(INPUT_NODES, NUM_CLASS)           \n",
    "        net.to(device)\n",
    "        print(net)\n",
    "        \n",
    "        softmax = nn.Softmax()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=LR, momentum = 0.1)\n",
    "        \n",
    "        loss_list = []\n",
    "        train_acc_list = []\n",
    "        test_acc_list = []\n",
    "        \n",
    "        pred_temp = []\n",
    "        true_temp = []\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            net.train()\n",
    "            running_loss = 0\n",
    "            total = train_size\n",
    "            correct = 0 \n",
    "            \n",
    "            for step, image_and_label in enumerate(train_loader):\n",
    "                inputs, labels = image_and_label            \n",
    "                inputs, labels = inputs.type(torch.FloatTensor).to(device), labels.type(torch.LongTensor).to(device)\n",
    "                \n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, pred = torch.max(outputs, dim=1)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            train_acc = correct/total\n",
    "            loss_list.append(running_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "            print('{}th- epoch: {}, train_loss = {}, train_acc = {}'.format(i+1, epoch, running_loss, train_acc))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                correct = 0\n",
    "                total = test_size\n",
    "                pt, tt = [], []\n",
    "                \n",
    "                for step_t, image_and_label_t in enumerate(test_loader):\n",
    "                    inputs_t, labels_t = image_and_label_t            \n",
    "                    inputs_t, labels_t = inputs_t.type(torch.FloatTensor).to(device), labels_t.type(torch.LongTensor).to(device)\n",
    "                    \n",
    "                    outputs_t = net(inputs_t)\n",
    "                    outputs_t = softmax(outputs_t)\n",
    "                    \n",
    "                    # test accuracy\n",
    "                    _, pred_t = torch.max(outputs_t, dim = 1)\n",
    "                    \n",
    "                    pt.append(pred_t)\n",
    "                    tt.append(labels_t)\n",
    "                    \n",
    "                    correct += (pred_t == labels_t).sum().item()\n",
    "                    \n",
    "                pred_temp.append(torch.cat(pt))\n",
    "                true_temp.append(torch.cat(tt))\n",
    "                \n",
    "                test_acc = correct/total\n",
    "                test_acc_list.append(test_acc)\n",
    "                \n",
    "                print('test Acc {}:'.format(test_acc))\n",
    "                \n",
    "        best_result_index = np.argmax(np.array(test_acc_list))\n",
    "        loss_total.append(loss_list[best_result_index])\n",
    "        acc_total.append(test_acc_list[best_result_index])\n",
    "        pred_total.append(pred_temp[best_result_index].tolist())\n",
    "        true_total.append(true_temp[best_result_index].tolist())\n",
    "        \n",
    "    file_name = 'res/Algorithm1_1gram'\n",
    "    torch.save(net.state_dict(), file_name +'.pth')\n",
    "    \n",
    "    loss_DF = pd.DataFrame(loss_total)\n",
    "    loss_DF.to_csv(file_name+\" loss.csv\")\n",
    "    \n",
    "    acc_DF = pd.DataFrame(acc_total)\n",
    "    acc_DF.to_csv(file_name +\" acc.csv\")\n",
    "    \n",
    "    pred_DF = pd.DataFrame(pred_total)\n",
    "    pred_DF.to_csv(file_name +\" pred.csv\")\n",
    "    \n",
    "    true_DF = pd.DataFrame(true_total)\n",
    "    true_DF.to_csv(file_name +\" true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
